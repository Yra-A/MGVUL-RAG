{
  "CVE-2006-3635": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for invalid Register Stack Engine (RSE) state in the ia64 subsystem.",
        "trigger_condition": "A local user leverages the mishandling of invalid RSE state to cause a denial of service by consuming stack space and crashing the system.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check the number of physical registers stacked by the Register Stack Engine (RSE) before applying a patch, leading to a vulnerability that can be exploited by a local user to crash the system."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a conditional check to verify the number of physical registers stacked by the RSE before applying the patch. This ensures that the patch is only applied when needed, preventing the exploitation of the vulnerability by a local user. In this case, the solution involves adding a code block that checks the number of physical registers stacked by the RSE and conditionally calls the patch function based on the result.",
      "GPT_analysis": "The modification in the code snippet is necessary to address a vulnerability (CVE-2006-3635) related to the mishandling of invalid Register Stack Engine (RSE) state in the ia64 subsystem of the Linux kernel. By adding the code block that checks the number of physical registers stacked by the Register Stack Engine and then conditionally calling `ia64_patch_rse`, the vulnerability can be mitigated.\n\nThe vulnerability allows local users to cause a denial of service by exploiting the mishandling of invalid RSE state, leading to stack consumption and system crashes. By properly checking the number of physical registers stacked by the RSE and only applying the patch when necessary, the code can prevent the exploitation of this vulnerability and ensure the system's stability and security.",
      "GPT_purpose": "Initialize various components and settings related to the IA-64 architecture during system setup.",
      "GPT_function": "\n1. Initialize architecture setup.\n2. Patch virtual to physical memory mappings.\n3. Initialize EFI.\n4. Initialize I/O ports.\n5. Initialize machine vector from command line.\n6. Parse early parameters.\n7. Setup early console.\n8. Initialize ACPI tables.\n9. Initialize ACPI NUMA.\n10. Initialize ACPI boot process.\n11. Find memory.\n12. Initialize SAL system table.\n13. Initialize CPU and MMU context.\n14. Check SAL cache flush.\n15. Initialize Machine Check Abort Handling.\n16. Setup platform.\n17. Initialize paging.",
      "CVE_id": "CVE-2006-3635",
      "code_before_change": "void __init\nsetup_arch (char **cmdline_p)\n{\n\tunw_init();\n\n\tia64_patch_vtop((u64) __start___vtop_patchlist, (u64) __end___vtop_patchlist);\n\n\t*cmdline_p = __va(ia64_boot_param->command_line);\n\tstrlcpy(boot_command_line, *cmdline_p, COMMAND_LINE_SIZE);\n\n\tefi_init();\n\tio_port_init();\n\n#ifdef CONFIG_IA64_GENERIC\n\t/* machvec needs to be parsed from the command line\n\t * before parse_early_param() is called to ensure\n\t * that ia64_mv is initialised before any command line\n\t * settings may cause console setup to occur\n\t */\n\tmachvec_init_from_cmdline(*cmdline_p);\n#endif\n\n\tparse_early_param();\n\n\tif (early_console_setup(*cmdline_p) == 0)\n\t\tmark_bsp_online();\n\n#ifdef CONFIG_ACPI\n\t/* Initialize the ACPI boot-time table parser */\n\tacpi_table_init();\n# ifdef CONFIG_ACPI_NUMA\n\tacpi_numa_init();\n\tper_cpu_scan_finalize((cpus_weight(early_cpu_possible_map) == 0 ?\n\t\t32 : cpus_weight(early_cpu_possible_map)), additional_cpus);\n# endif\n#else\n# ifdef CONFIG_SMP\n\tsmp_build_cpu_map();\t/* happens, e.g., with the Ski simulator */\n# endif\n#endif /* CONFIG_APCI_BOOT */\n\n\tfind_memory();\n\n\t/* process SAL system table: */\n\tia64_sal_init(__va(efi.sal_systab));\n\n#ifdef CONFIG_SMP\n\tcpu_physical_id(0) = hard_smp_processor_id();\n#endif\n\n\tcpu_init();\t/* initialize the bootstrap CPU */\n\tmmu_context_init();\t/* initialize context_id bitmap */\n\n\tcheck_sal_cache_flush();\n\n#ifdef CONFIG_ACPI\n\tacpi_boot_init();\n#endif\n\n#ifdef CONFIG_VT\n\tif (!conswitchp) {\n# if defined(CONFIG_DUMMY_CONSOLE)\n\t\tconswitchp = &dummy_con;\n# endif\n# if defined(CONFIG_VGA_CONSOLE)\n\t\t/*\n\t\t * Non-legacy systems may route legacy VGA MMIO range to system\n\t\t * memory.  vga_con probes the MMIO hole, so memory looks like\n\t\t * a VGA device to it.  The EFI memory map can tell us if it's\n\t\t * memory so we can avoid this problem.\n\t\t */\n\t\tif (efi_mem_type(0xA0000) != EFI_CONVENTIONAL_MEMORY)\n\t\t\tconswitchp = &vga_con;\n# endif\n\t}\n#endif\n\n\t/* enable IA-64 Machine Check Abort Handling unless disabled */\n\tif (!nomca)\n\t\tia64_mca_init();\n\n\tplatform_setup(cmdline_p);\n\tpaging_init();\n}",
      "code_after_change": "void __init\nsetup_arch (char **cmdline_p)\n{\n\tunw_init();\n\n\tia64_patch_vtop((u64) __start___vtop_patchlist, (u64) __end___vtop_patchlist);\n\n\t*cmdline_p = __va(ia64_boot_param->command_line);\n\tstrlcpy(boot_command_line, *cmdline_p, COMMAND_LINE_SIZE);\n\n\tefi_init();\n\tio_port_init();\n\n#ifdef CONFIG_IA64_GENERIC\n\t/* machvec needs to be parsed from the command line\n\t * before parse_early_param() is called to ensure\n\t * that ia64_mv is initialised before any command line\n\t * settings may cause console setup to occur\n\t */\n\tmachvec_init_from_cmdline(*cmdline_p);\n#endif\n\n\tparse_early_param();\n\n\tif (early_console_setup(*cmdline_p) == 0)\n\t\tmark_bsp_online();\n\n#ifdef CONFIG_ACPI\n\t/* Initialize the ACPI boot-time table parser */\n\tacpi_table_init();\n# ifdef CONFIG_ACPI_NUMA\n\tacpi_numa_init();\n\tper_cpu_scan_finalize((cpus_weight(early_cpu_possible_map) == 0 ?\n\t\t32 : cpus_weight(early_cpu_possible_map)), additional_cpus);\n# endif\n#else\n# ifdef CONFIG_SMP\n\tsmp_build_cpu_map();\t/* happens, e.g., with the Ski simulator */\n# endif\n#endif /* CONFIG_APCI_BOOT */\n\n\tfind_memory();\n\n\t/* process SAL system table: */\n\tia64_sal_init(__va(efi.sal_systab));\n\n#ifdef CONFIG_ITANIUM\n\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n#else\n\t{\n\t\tu64 num_phys_stacked;\n\n\t\tif (ia64_pal_rse_info(&num_phys_stacked, 0) == 0 && num_phys_stacked > 96)\n\t\t\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n\t}\n#endif\n\n#ifdef CONFIG_SMP\n\tcpu_physical_id(0) = hard_smp_processor_id();\n#endif\n\n\tcpu_init();\t/* initialize the bootstrap CPU */\n\tmmu_context_init();\t/* initialize context_id bitmap */\n\n\tcheck_sal_cache_flush();\n\n#ifdef CONFIG_ACPI\n\tacpi_boot_init();\n#endif\n\n#ifdef CONFIG_VT\n\tif (!conswitchp) {\n# if defined(CONFIG_DUMMY_CONSOLE)\n\t\tconswitchp = &dummy_con;\n# endif\n# if defined(CONFIG_VGA_CONSOLE)\n\t\t/*\n\t\t * Non-legacy systems may route legacy VGA MMIO range to system\n\t\t * memory.  vga_con probes the MMIO hole, so memory looks like\n\t\t * a VGA device to it.  The EFI memory map can tell us if it's\n\t\t * memory so we can avoid this problem.\n\t\t */\n\t\tif (efi_mem_type(0xA0000) != EFI_CONVENTIONAL_MEMORY)\n\t\t\tconswitchp = &vga_con;\n# endif\n\t}\n#endif\n\n\t/* enable IA-64 Machine Check Abort Handling unless disabled */\n\tif (!nomca)\n\t\tia64_mca_init();\n\n\tplatform_setup(cmdline_p);\n\tpaging_init();\n}",
      "modified_lines": {
        "added": [
          "#ifdef CONFIG_ITANIUM",
          "\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);",
          "#else",
          "\t{",
          "\t\tu64 num_phys_stacked;",
          "",
          "\t\tif (ia64_pal_rse_info(&num_phys_stacked, 0) == 0 && num_phys_stacked > 96)",
          "\t\t\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);",
          "\t}",
          "#endif",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper handling for invalid Register Stack Engine (RSE) state in the ia64 subsystem.",
      "trigger_condition": "A local user leverages the mishandling of invalid RSE state to cause a denial of service by consuming stack space and crashing the system.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check the number of physical registers stacked by the Register Stack Engine (RSE) before applying a patch, leading to a vulnerability that can be exploited by a local user to crash the system.",
      "id": 0,
      "code_after_change_normalized": "void VAR1\nFUN1 (char **VAR2)\n{\nFUN2();\nFUN3((VAR3) VAR4, (VAR3) VAR5);\n*VAR2 = FUN4(VAR6->VAR7);\nFUN5(VAR8, *VAR2, VAR9);\nFUN6();\nFUN7();\n#ifdef VAR10\nFUN8(*VAR2);\n#VAR11\nFUN9();\nif (FUN10(*VAR2) == 0)\nFUN11();\n#ifdef VAR12\nFUN12();\n# ifdef VAR13\nFUN13();\nFUN14((FUN15(VAR14) == 0 ?\n32 : FUN15(VAR14)), VAR15);\n# VAR11\n#else\n# ifdef VAR16\nFUN16();\t\n# VAR11\n#VAR11 \nFUN17();\nFUN18(FUN4(VAR17.VAR18));\n#ifdef VAR19\nFUN19((VAR3) VAR20, (VAR3) VAR21);\n#else\n{\nu64 VAR22;\nif (FUN20(&VAR22, 0) == 0 && VAR22 > 96)\nFUN19((VAR3) VAR20, (VAR3) VAR21);\n}\n#VAR11\n#ifdef VAR16\nFUN21(0) = FUN22();\n#VAR11\nFUN23();\t\nFUN24();\t\nFUN25();\n#ifdef VAR12\nFUN26();\n#VAR11\n#ifdef VAR23\nif (!VAR24) {\n# if FUN27(VAR25)\nVAR24 = &VAR26;\n# VAR11\n# if FUN27(VAR27)\nif (FUN28(VAR28) != VAR29)\nVAR24 = &VAR30;\n# VAR11\n}\n#VAR11\nif (!VAR31)\nFUN29();\nFUN30(VAR2);\nFUN31();\n}\n",
      "code_before_change_normalized": "void VAR1\nFUN1 (char **VAR2)\n{\nFUN2();\nFUN3((VAR3) VAR4, (VAR3) VAR5);\n*VAR2 = FUN4(VAR6->VAR7);\nFUN5(VAR8, *VAR2, VAR9);\nFUN6();\nFUN7();\n#ifdef VAR10\nFUN8(*VAR2);\n#VAR11\nFUN9();\nif (FUN10(*VAR2) == 0)\nFUN11();\n#ifdef VAR12\nFUN12();\n# ifdef VAR13\nFUN13();\nFUN14((FUN15(VAR14) == 0 ?\n32 : FUN15(VAR14)), VAR15);\n# VAR11\n#else\n# ifdef VAR16\nFUN16();\t\n# VAR11\n#VAR11 \nFUN17();\nFUN18(FUN4(VAR17.VAR18));\n#ifdef VAR16\nFUN19(0) = FUN20();\n#VAR11\nFUN21();\t\nFUN22();\t\nFUN23();\n#ifdef VAR12\nFUN24();\n#VAR11\n#ifdef VAR19\nif (!VAR20) {\n# if FUN25(VAR21)\nVAR20 = &VAR22;\n# VAR11\n# if FUN25(VAR23)\nif (FUN26(VAR24) != VAR25)\nVAR20 = &VAR26;\n# VAR11\n}\n#VAR11\nif (!VAR27)\nFUN27();\nFUN28(VAR2);\nFUN29();\n}\n",
      "code_after_change_raw": "void __init\nsetup_arch (char **cmdline_p)\n{\nunw_init();\nia64_patch_vtop((u64) __start___vtop_patchlist, (u64) __end___vtop_patchlist);\n*cmdline_p = __va(ia64_boot_param->command_line);\nstrlcpy(boot_command_line, *cmdline_p, COMMAND_LINE_SIZE);\nefi_init();\nio_port_init();\n#ifdef CONFIG_IA64_GENERIC\nmachvec_init_from_cmdline(*cmdline_p);\n#endif\nparse_early_param();\nif (early_console_setup(*cmdline_p) == 0)\nmark_bsp_online();\n#ifdef CONFIG_ACPI\nacpi_table_init();\n# ifdef CONFIG_ACPI_NUMA\nacpi_numa_init();\nper_cpu_scan_finalize((cpus_weight(early_cpu_possible_map) == 0 ?\n32 : cpus_weight(early_cpu_possible_map)), additional_cpus);\n# endif\n#else\n# ifdef CONFIG_SMP\nsmp_build_cpu_map();\t\n# endif\n#endif \nfind_memory();\nia64_sal_init(__va(efi.sal_systab));\n#ifdef CONFIG_ITANIUM\nia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n#else\n{\nu64 num_phys_stacked;\nif (ia64_pal_rse_info(&num_phys_stacked, 0) == 0 && num_phys_stacked > 96)\nia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n}\n#endif\n#ifdef CONFIG_SMP\ncpu_physical_id(0) = hard_smp_processor_id();\n#endif\ncpu_init();\t\nmmu_context_init();\t\ncheck_sal_cache_flush();\n#ifdef CONFIG_ACPI\nacpi_boot_init();\n#endif\n#ifdef CONFIG_VT\nif (!conswitchp) {\n# if defined(CONFIG_DUMMY_CONSOLE)\nconswitchp = &dummy_con;\n# endif\n# if defined(CONFIG_VGA_CONSOLE)\nif (efi_mem_type(0xA0000) != EFI_CONVENTIONAL_MEMORY)\nconswitchp = &vga_con;\n# endif\n}\n#endif\nif (!nomca)\nia64_mca_init();\nplatform_setup(cmdline_p);\npaging_init();\n}\n",
      "code_before_change_raw": "void __init\nsetup_arch (char **cmdline_p)\n{\nunw_init();\nia64_patch_vtop((u64) __start___vtop_patchlist, (u64) __end___vtop_patchlist);\n*cmdline_p = __va(ia64_boot_param->command_line);\nstrlcpy(boot_command_line, *cmdline_p, COMMAND_LINE_SIZE);\nefi_init();\nio_port_init();\n#ifdef CONFIG_IA64_GENERIC\nmachvec_init_from_cmdline(*cmdline_p);\n#endif\nparse_early_param();\nif (early_console_setup(*cmdline_p) == 0)\nmark_bsp_online();\n#ifdef CONFIG_ACPI\nacpi_table_init();\n# ifdef CONFIG_ACPI_NUMA\nacpi_numa_init();\nper_cpu_scan_finalize((cpus_weight(early_cpu_possible_map) == 0 ?\n32 : cpus_weight(early_cpu_possible_map)), additional_cpus);\n# endif\n#else\n# ifdef CONFIG_SMP\nsmp_build_cpu_map();\t\n# endif\n#endif \nfind_memory();\nia64_sal_init(__va(efi.sal_systab));\n#ifdef CONFIG_SMP\ncpu_physical_id(0) = hard_smp_processor_id();\n#endif\ncpu_init();\t\nmmu_context_init();\t\ncheck_sal_cache_flush();\n#ifdef CONFIG_ACPI\nacpi_boot_init();\n#endif\n#ifdef CONFIG_VT\nif (!conswitchp) {\n# if defined(CONFIG_DUMMY_CONSOLE)\nconswitchp = &dummy_con;\n# endif\n# if defined(CONFIG_VGA_CONSOLE)\nif (efi_mem_type(0xA0000) != EFI_CONVENTIONAL_MEMORY)\nconswitchp = &vga_con;\n# endif\n}\n#endif\nif (!nomca)\nia64_mca_init();\nplatform_setup(cmdline_p);\npaging_init();\n}\n"
    }
  ],
  "CVE-2007-6761": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper initialization of videobuf_mapping data structures.",
        "trigger_condition": "Local users can trigger an incorrect count value and videobuf leak via unspecified vectors due to uninitialized videobuf_mapping structures.",
        "specific_code_behavior_causing_vulnerability": "The code fails to initialize the videobuf_mapping structure, leading to potential memory leaks, incorrect count values, and security vulnerabilities. This can be exploited by local users to manipulate the data structures and cause unexpected behavior."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper initialization of the videobuf_mapping structure. By using kzalloc instead of kmalloc, the videobuf_mapping structure will be allocated with zeroed memory, preventing uninitialized data issues. This solution ensures that all fields of the videobuf_mapping structure are correctly set before being used, reducing the risk of memory leaks, incorrect count values, and security vulnerabilities.",
      "GPT_analysis": "The modification is necessary to fix a vulnerability in the code related to the initialization of the `videobuf_mapping` data structure. The vulnerability allows local users to trigger an incorrect count value and videobuf leak via unspecified vectors. By using `kzalloc` instead of `kmalloc`, the `videobuf_mapping` structure will be properly initialized with zeroed memory, preventing any potential issues related to uninitialized data.\n\nInitializing the `videobuf_mapping` structure is crucial to ensure that all its fields are properly set before being used in the code. Failure to initialize the structure can lead to unpredictable behavior, memory leaks, or security vulnerabilities. In this case, the vulnerability CVE-2007-6761 is specifically related to the incorrect initialization of the `videobuf_mapping` structure, which can be exploited by local users to trigger unexpected behavior.\n\nBy using `kzalloc` to allocate memory for the `videobuf_mapping` structure, all its fields will be initialized to zero, providing a clean and safe starting point for the structure's usage. This helps prevent any potential issues that may arise from using uninitialized memory and contributes to overall code robustness and security.",
      "GPT_purpose": "Map videobuf memory for mmap operation in a videobuf queue.",
      "GPT_function": "\n1. Map video buffer memory to user space using mmap.\n2. Check for valid buffer offset and memory type.\n3. Create a mapping structure and update buffer list.\n4. Set up virtual memory area operations and flags.\n5. Remap the memory range if necessary.\n6. Handle potential errors and memory allocation.\n7. Log information about the mapping process.\n8. Open the video buffer virtual memory area.",
      "CVE_id": "CVE-2007-6761",
      "code_before_change": "static int __videobuf_mmap_mapper(struct videobuf_queue *q,\n\t\t\t struct vm_area_struct *vma)\n{\n\tstruct videbuf_vmalloc_memory *mem;\n\tstruct videobuf_mapping *map;\n\tunsigned int first;\n\tint retval;\n\tunsigned long offset = vma->vm_pgoff << PAGE_SHIFT;\n\n\tif (! (vma->vm_flags & VM_WRITE) || ! (vma->vm_flags & VM_SHARED))\n\t\treturn -EINVAL;\n\n\t/* look for first buffer to map */\n\tfor (first = 0; first < VIDEO_MAX_FRAME; first++) {\n\t\tif (NULL == q->bufs[first])\n\t\t\tcontinue;\n\n\t\tif (V4L2_MEMORY_MMAP != q->bufs[first]->memory)\n\t\t\tcontinue;\n\t\tif (q->bufs[first]->boff == offset)\n\t\t\tbreak;\n\t}\n\tif (VIDEO_MAX_FRAME == first) {\n\t\tdprintk(1,\"mmap app bug: offset invalid [offset=0x%lx]\\n\",\n\t\t\t(vma->vm_pgoff << PAGE_SHIFT));\n\t\treturn -EINVAL;\n\t}\n\n\t/* create mapping + update buffer list */\n\tmap = q->bufs[first]->map = kmalloc(sizeof(struct videobuf_mapping),GFP_KERNEL);\n\tif (NULL == map)\n\t\treturn -ENOMEM;\n\n\tmap->start = vma->vm_start;\n\tmap->end   = vma->vm_end;\n\tmap->q     = q;\n\n\tq->bufs[first]->baddr = vma->vm_start;\n\n\tvma->vm_ops          = &videobuf_vm_ops;\n\tvma->vm_flags       |= VM_DONTEXPAND | VM_RESERVED;\n\tvma->vm_private_data = map;\n\n\tmem=q->bufs[first]->priv;\n\tBUG_ON (!mem);\n\tMAGIC_CHECK(mem->magic,MAGIC_VMAL_MEM);\n\n\t/* Try to remap memory */\n\tretval=remap_vmalloc_range(vma, mem->vmalloc,0);\n\tif (retval<0) {\n\t\tdprintk(1,\"mmap: postponing remap_vmalloc_range\\n\");\n\n\t\tmem->vma=kmalloc(sizeof(*vma),GFP_KERNEL);\n\t\tif (!mem->vma) {\n\t\t\tkfree(map);\n\t\t\tq->bufs[first]->map=NULL;\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tmemcpy(mem->vma,vma,sizeof(*vma));\n\t}\n\n\tdprintk(1,\"mmap %p: q=%p %08lx-%08lx (%lx) pgoff %08lx buf %d\\n\",\n\t\tmap,q,vma->vm_start,vma->vm_end,\n\t\t(long int) q->bufs[first]->bsize,\n\t\tvma->vm_pgoff,first);\n\n\tvideobuf_vm_open(vma);\n\n\treturn (0);\n}",
      "code_after_change": "static int __videobuf_mmap_mapper(struct videobuf_queue *q,\n\t\t\t struct vm_area_struct *vma)\n{\n\tstruct videbuf_vmalloc_memory *mem;\n\tstruct videobuf_mapping *map;\n\tunsigned int first;\n\tint retval;\n\tunsigned long offset = vma->vm_pgoff << PAGE_SHIFT;\n\n\tif (! (vma->vm_flags & VM_WRITE) || ! (vma->vm_flags & VM_SHARED))\n\t\treturn -EINVAL;\n\n\t/* look for first buffer to map */\n\tfor (first = 0; first < VIDEO_MAX_FRAME; first++) {\n\t\tif (NULL == q->bufs[first])\n\t\t\tcontinue;\n\n\t\tif (V4L2_MEMORY_MMAP != q->bufs[first]->memory)\n\t\t\tcontinue;\n\t\tif (q->bufs[first]->boff == offset)\n\t\t\tbreak;\n\t}\n\tif (VIDEO_MAX_FRAME == first) {\n\t\tdprintk(1,\"mmap app bug: offset invalid [offset=0x%lx]\\n\",\n\t\t\t(vma->vm_pgoff << PAGE_SHIFT));\n\t\treturn -EINVAL;\n\t}\n\n\t/* create mapping + update buffer list */\n\tmap = q->bufs[first]->map = kzalloc(sizeof(struct videobuf_mapping),GFP_KERNEL);\n\tif (NULL == map)\n\t\treturn -ENOMEM;\n\n\tmap->start = vma->vm_start;\n\tmap->end   = vma->vm_end;\n\tmap->q     = q;\n\n\tq->bufs[first]->baddr = vma->vm_start;\n\n\tvma->vm_ops          = &videobuf_vm_ops;\n\tvma->vm_flags       |= VM_DONTEXPAND | VM_RESERVED;\n\tvma->vm_private_data = map;\n\n\tmem=q->bufs[first]->priv;\n\tBUG_ON (!mem);\n\tMAGIC_CHECK(mem->magic,MAGIC_VMAL_MEM);\n\n\t/* Try to remap memory */\n\tretval=remap_vmalloc_range(vma, mem->vmalloc,0);\n\tif (retval<0) {\n\t\tdprintk(1,\"mmap: postponing remap_vmalloc_range\\n\");\n\n\t\tmem->vma=kmalloc(sizeof(*vma),GFP_KERNEL);\n\t\tif (!mem->vma) {\n\t\t\tkfree(map);\n\t\t\tq->bufs[first]->map=NULL;\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tmemcpy(mem->vma,vma,sizeof(*vma));\n\t}\n\n\tdprintk(1,\"mmap %p: q=%p %08lx-%08lx (%lx) pgoff %08lx buf %d\\n\",\n\t\tmap,q,vma->vm_start,vma->vm_end,\n\t\t(long int) q->bufs[first]->bsize,\n\t\tvma->vm_pgoff,first);\n\n\tvideobuf_vm_open(vma);\n\n\treturn (0);\n}",
      "modified_lines": {
        "added": [
          "\tmap = q->bufs[first]->map = kzalloc(sizeof(struct videobuf_mapping),GFP_KERNEL);"
        ],
        "deleted": [
          "\tmap = q->bufs[first]->map = kmalloc(sizeof(struct videobuf_mapping),GFP_KERNEL);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper initialization of videobuf_mapping data structures.",
      "trigger_condition": "Local users can trigger an incorrect count value and videobuf leak via unspecified vectors due to uninitialized videobuf_mapping structures.",
      "specific_code_behavior_causing_vulnerability": "The code fails to initialize the videobuf_mapping structure, leading to potential memory leaks, incorrect count values, and security vulnerabilities. This can be exploited by local users to manipulate the data structures and cause unexpected behavior.",
      "id": 1,
      "code_after_change_normalized": "static int FUN1(struct videobuf_queue *VAR1,\nstruct vm_area_struct *VAR2)\n{\nstruct videbuf_vmalloc_memory *VAR3;\nstruct videobuf_mapping *VAR4;\nunsigned int VAR5;\nint VAR6;\nunsigned long VAR7 = VAR2->VAR8 << VAR9;\nif (! (VAR2->VAR10 & VAR11) || ! (VAR2->VAR10 & VAR12))\nreturn -VAR13;\nfor (VAR5 = 0; VAR5 < VAR14; VAR5++) {\nif (NULL == VAR1->VAR15[VAR5])\ncontinue;\nif (VAR16 != VAR1->VAR15[VAR5]->VAR17)\ncontinue;\nif (VAR1->VAR15[VAR5]->VAR18 == VAR7)\nbreak;\n}\nif (VAR14 == VAR5) {\nFUN2(1,\"STR\",\n(VAR2->VAR8 << VAR9));\nreturn -VAR13;\n}\nVAR4 = VAR1->VAR15[VAR5]->VAR4 = FUN3(sizeof(struct VAR19),VAR20);\nif (NULL == VAR4)\nreturn -VAR21;\nVAR4->VAR22 = VAR2->VAR23;\nVAR4->VAR24   = VAR2->VAR25;\nVAR4->VAR1     = VAR1;\nVAR1->VAR15[VAR5]->VAR26 = VAR2->VAR23;\nVAR2->VAR27          = &VAR28;\nVAR2->VAR10       |= VAR29 | VAR30;\nVAR2->VAR31 = VAR4;\nVAR3=VAR1->VAR15[VAR5]->VAR32;\nFUN4 (!VAR3);\nFUN5(VAR3->VAR33,VAR34);\nVAR6=FUN6(VAR2, VAR3->VAR35,0);\nif (VAR6<0) {\nFUN2(1,\"STR\");\nVAR3->VAR2=FUN7(sizeof(*VAR2),VAR20);\nif (!VAR3->VAR2) {\nFUN8(VAR4);\nVAR1->VAR15[VAR5]->VAR4=NULL;\nreturn -VAR21;\n}\nFUN9(VAR3->VAR2,VAR2,sizeof(*VAR2));\n}\nFUN2(1,\"STR\",\nVAR4,VAR1,VAR2->VAR23,VAR2->VAR25,\n(long int) VAR1->VAR15[VAR5]->VAR36,\nVAR2->VAR8,VAR5);\nFUN10(VAR2);\nreturn (0);\n}\n",
      "code_before_change_normalized": "static int FUN1(struct videobuf_queue *VAR1,\nstruct vm_area_struct *VAR2)\n{\nstruct videbuf_vmalloc_memory *VAR3;\nstruct videobuf_mapping *VAR4;\nunsigned int VAR5;\nint VAR6;\nunsigned long VAR7 = VAR2->VAR8 << VAR9;\nif (! (VAR2->VAR10 & VAR11) || ! (VAR2->VAR10 & VAR12))\nreturn -VAR13;\nfor (VAR5 = 0; VAR5 < VAR14; VAR5++) {\nif (NULL == VAR1->VAR15[VAR5])\ncontinue;\nif (VAR16 != VAR1->VAR15[VAR5]->VAR17)\ncontinue;\nif (VAR1->VAR15[VAR5]->VAR18 == VAR7)\nbreak;\n}\nif (VAR14 == VAR5) {\nFUN2(1,\"STR\",\n(VAR2->VAR8 << VAR9));\nreturn -VAR13;\n}\nVAR4 = VAR1->VAR15[VAR5]->VAR4 = FUN3(sizeof(struct VAR19),VAR20);\nif (NULL == VAR4)\nreturn -VAR21;\nVAR4->VAR22 = VAR2->VAR23;\nVAR4->VAR24   = VAR2->VAR25;\nVAR4->VAR1     = VAR1;\nVAR1->VAR15[VAR5]->VAR26 = VAR2->VAR23;\nVAR2->VAR27          = &VAR28;\nVAR2->VAR10       |= VAR29 | VAR30;\nVAR2->VAR31 = VAR4;\nVAR3=VAR1->VAR15[VAR5]->VAR32;\nFUN4 (!VAR3);\nFUN5(VAR3->VAR33,VAR34);\nVAR6=FUN6(VAR2, VAR3->VAR35,0);\nif (VAR6<0) {\nFUN2(1,\"STR\");\nVAR3->VAR2=FUN3(sizeof(*VAR2),VAR20);\nif (!VAR3->VAR2) {\nFUN7(VAR4);\nVAR1->VAR15[VAR5]->VAR4=NULL;\nreturn -VAR21;\n}\nFUN8(VAR3->VAR2,VAR2,sizeof(*VAR2));\n}\nFUN2(1,\"STR\",\nVAR4,VAR1,VAR2->VAR23,VAR2->VAR25,\n(long int) VAR1->VAR15[VAR5]->VAR36,\nVAR2->VAR8,VAR5);\nFUN9(VAR2);\nreturn (0);\n}\n",
      "code_after_change_raw": "static int __videobuf_mmap_mapper(struct videobuf_queue *q,\nstruct vm_area_struct *vma)\n{\nstruct videbuf_vmalloc_memory *mem;\nstruct videobuf_mapping *map;\nunsigned int first;\nint retval;\nunsigned long offset = vma->vm_pgoff << PAGE_SHIFT;\nif (! (vma->vm_flags & VM_WRITE) || ! (vma->vm_flags & VM_SHARED))\nreturn -EINVAL;\nfor (first = 0; first < VIDEO_MAX_FRAME; first++) {\nif (NULL == q->bufs[first])\ncontinue;\nif (V4L2_MEMORY_MMAP != q->bufs[first]->memory)\ncontinue;\nif (q->bufs[first]->boff == offset)\nbreak;\n}\nif (VIDEO_MAX_FRAME == first) {\ndprintk(1,\"mmap app bug: offset invalid [offset=0x%lx]\\n\",\n(vma->vm_pgoff << PAGE_SHIFT));\nreturn -EINVAL;\n}\nmap = q->bufs[first]->map = kzalloc(sizeof(struct videobuf_mapping),GFP_KERNEL);\nif (NULL == map)\nreturn -ENOMEM;\nmap->start = vma->vm_start;\nmap->end   = vma->vm_end;\nmap->q     = q;\nq->bufs[first]->baddr = vma->vm_start;\nvma->vm_ops          = &videobuf_vm_ops;\nvma->vm_flags       |= VM_DONTEXPAND | VM_RESERVED;\nvma->vm_private_data = map;\nmem=q->bufs[first]->priv;\nBUG_ON (!mem);\nMAGIC_CHECK(mem->magic,MAGIC_VMAL_MEM);\nretval=remap_vmalloc_range(vma, mem->vmalloc,0);\nif (retval<0) {\ndprintk(1,\"mmap: postponing remap_vmalloc_range\\n\");\nmem->vma=kmalloc(sizeof(*vma),GFP_KERNEL);\nif (!mem->vma) {\nkfree(map);\nq->bufs[first]->map=NULL;\nreturn -ENOMEM;\n}\nmemcpy(mem->vma,vma,sizeof(*vma));\n}\ndprintk(1,\"mmap %p: q=%p %08lx-%08lx (%lx) pgoff %08lx buf %d\\n\",\nmap,q,vma->vm_start,vma->vm_end,\n(long int) q->bufs[first]->bsize,\nvma->vm_pgoff,first);\nvideobuf_vm_open(vma);\nreturn (0);\n}\n",
      "code_before_change_raw": "static int __videobuf_mmap_mapper(struct videobuf_queue *q,\nstruct vm_area_struct *vma)\n{\nstruct videbuf_vmalloc_memory *mem;\nstruct videobuf_mapping *map;\nunsigned int first;\nint retval;\nunsigned long offset = vma->vm_pgoff << PAGE_SHIFT;\nif (! (vma->vm_flags & VM_WRITE) || ! (vma->vm_flags & VM_SHARED))\nreturn -EINVAL;\nfor (first = 0; first < VIDEO_MAX_FRAME; first++) {\nif (NULL == q->bufs[first])\ncontinue;\nif (V4L2_MEMORY_MMAP != q->bufs[first]->memory)\ncontinue;\nif (q->bufs[first]->boff == offset)\nbreak;\n}\nif (VIDEO_MAX_FRAME == first) {\ndprintk(1,\"mmap app bug: offset invalid [offset=0x%lx]\\n\",\n(vma->vm_pgoff << PAGE_SHIFT));\nreturn -EINVAL;\n}\nmap = q->bufs[first]->map = kmalloc(sizeof(struct videobuf_mapping),GFP_KERNEL);\nif (NULL == map)\nreturn -ENOMEM;\nmap->start = vma->vm_start;\nmap->end   = vma->vm_end;\nmap->q     = q;\nq->bufs[first]->baddr = vma->vm_start;\nvma->vm_ops          = &videobuf_vm_ops;\nvma->vm_flags       |= VM_DONTEXPAND | VM_RESERVED;\nvma->vm_private_data = map;\nmem=q->bufs[first]->priv;\nBUG_ON (!mem);\nMAGIC_CHECK(mem->magic,MAGIC_VMAL_MEM);\nretval=remap_vmalloc_range(vma, mem->vmalloc,0);\nif (retval<0) {\ndprintk(1,\"mmap: postponing remap_vmalloc_range\\n\");\nmem->vma=kmalloc(sizeof(*vma),GFP_KERNEL);\nif (!mem->vma) {\nkfree(map);\nq->bufs[first]->map=NULL;\nreturn -ENOMEM;\n}\nmemcpy(mem->vma,vma,sizeof(*vma));\n}\ndprintk(1,\"mmap %p: q=%p %08lx-%08lx (%lx) pgoff %08lx buf %d\\n\",\nmap,q,vma->vm_start,vma->vm_end,\n(long int) q->bufs[first]->bsize,\nvma->vm_pgoff,first);\nvideobuf_vm_open(vma);\nreturn (0);\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of initialization of videobuf_mapping data structures before access.",
        "trigger_condition": "Local users trigger an incorrect count value and videobuf leak by accessing uninitialized data structures.",
        "specific_code_behavior_causing_vulnerability": "The code does not initialize the videobuf_mapping data structures, leading to potential uninitialized or incorrect values in the count field. This can result in a videobuf leak when the count is incremented."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper initialization of the videobuf_mapping data structures before accessing them. In this case, the solution involves modifying the code to initialize the data structures to prevent uninitialized or incorrect values. By initializing the data structures correctly, the code can avoid the vulnerability and ensure the count value is handled properly.",
      "GPT_analysis": "The modification is necessary to address the vulnerability described in CVE-2007-6761. In the original code snippet, the videobuf_mapping data structure is not initialized before being accessed in the videobuf_vm_open function. This can lead to uninitialized or incorrect values in the data structure, specifically in the count field.\n\nBy modifying the code to use the %u format specifier for printing the count value, you ensure that the count value is correctly interpreted as an unsigned integer. This helps prevent potential issues related to uninitialized or incorrect count values, which could lead to a videobuf leak when the count is incremented.\n\nIn summary, the modification ensures that the count value is properly handled and displayed as an unsigned integer, addressing the vulnerability and improving the code's robustness.",
      "GPT_purpose": "Open a virtual memory area for video buffer mapping.",
      "GPT_function": "\n1. Open a virtual memory area for videobuf mapping.\n2. Increment the count value in the videobuf_mapping structure.\n3. Print debug information about the opened virtual memory area.",
      "CVE_id": "CVE-2007-6761",
      "code_before_change": "static void\nvideobuf_vm_open(struct vm_area_struct *vma)\n{\n\tstruct videobuf_mapping *map = vma->vm_private_data;\n\n\tdprintk(2,\"vm_open %p [count=%d,vma=%08lx-%08lx]\\n\",map,\n\t\tmap->count,vma->vm_start,vma->vm_end);\n\n\tmap->count++;\n}",
      "code_after_change": "static void\nvideobuf_vm_open(struct vm_area_struct *vma)\n{\n\tstruct videobuf_mapping *map = vma->vm_private_data;\n\n\tdprintk(2,\"vm_open %p [count=%u,vma=%08lx-%08lx]\\n\",map,\n\t\tmap->count,vma->vm_start,vma->vm_end);\n\n\tmap->count++;\n}",
      "modified_lines": {
        "added": [
          "\tdprintk(2,\"vm_open %p [count=%u,vma=%08lx-%08lx]\\n\",map,"
        ],
        "deleted": [
          "\tdprintk(2,\"vm_open %p [count=%d,vma=%08lx-%08lx]\\n\",map,"
        ]
      },
      "preconditions_for_vulnerability": "Lack of initialization of videobuf_mapping data structures before access.",
      "trigger_condition": "Local users trigger an incorrect count value and videobuf leak by accessing uninitialized data structures.",
      "specific_code_behavior_causing_vulnerability": "The code does not initialize the videobuf_mapping data structures, leading to potential uninitialized or incorrect values in the count field. This can result in a videobuf leak when the count is incremented.",
      "id": 2,
      "code_after_change_normalized": "static void\nFUN1(struct vm_area_struct *VAR1)\n{\nstruct videobuf_mapping *VAR2 = VAR1->VAR3;\nFUN2(2,\"STR\",VAR2,\nVAR2->VAR4,VAR1->VAR5,VAR1->VAR6);\nVAR2->VAR4++;\n}\n",
      "code_before_change_normalized": "static void\nFUN1(struct vm_area_struct *VAR1)\n{\nstruct videobuf_mapping *VAR2 = VAR1->VAR3;\nFUN2(2,\"STR\",VAR2,\nVAR2->VAR4,VAR1->VAR5,VAR1->VAR6);\nVAR2->VAR4++;\n}\n",
      "code_after_change_raw": "static void\nvideobuf_vm_open(struct vm_area_struct *vma)\n{\nstruct videobuf_mapping *map = vma->vm_private_data;\ndprintk(2,\"vm_open %p [count=%u,vma=%08lx-%08lx]\\n\",map,\nmap->count,vma->vm_start,vma->vm_end);\nmap->count++;\n}\n",
      "code_before_change_raw": "static void\nvideobuf_vm_open(struct vm_area_struct *vma)\n{\nstruct videobuf_mapping *map = vma->vm_private_data;\ndprintk(2,\"vm_open %p [count=%d,vma=%08lx-%08lx]\\n\",map,\nmap->count,vma->vm_start,vma->vm_end);\nmap->count++;\n}\n"
    }
  ],
  "CVE-2007-6762": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper array bounds checking in a loop that populates an array based on user input.",
        "trigger_condition": "The loop condition allows the array index to exceed the maximum allowed index, leading to potential buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not correctly check the array index against the maximum allowed index, allowing it to go out of bounds and potentially overflow the array.",
        "specific_solution_to_fix_vulnerability": "To mitigate the vulnerability, it is necessary to ensure that the array index is properly checked against the maximum allowed index within the loop. By modifying the condition to check for equality (>=) instead of just greater than (>), the code prevents the array index from going out of bounds. Additionally, filling the remaining elements of the array with a default value after the loop ensures that all elements are properly initialized and prevents potential buffer overflows."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to prevent an off-by-one bug that could lead to overflowing the `doi_def->tags[]` array. In the original code, the condition `if (iter > CIPSO_V4_TAG_MAXCNT)` is used to check if the `iter` variable exceeds the maximum allowed index for the `doi_def->tags[]` array. However, this condition should be `if (iter >= CIPSO_V4_TAG_MAXCNT)` to ensure that the array index does not go out of bounds.\n\nBy changing the condition to `if (iter >= CIPSO_V4_TAG_MAXCNT)`, the code will correctly handle the case where `iter` reaches the maximum allowed index and prevent writing beyond the bounds of the `doi_def->tags[]` array. Additionally, the modification adds a `while` loop to fill the remaining elements of the array with `CIPSO_V4_TAG_INVALID` if the loop exits before reaching the maximum count, ensuring that all elements are properly initialized.\n\nOverall, these changes help to address the vulnerability CVE-2007-6762 by ensuring that the array bounds are properly checked and handled, preventing potential buffer overflows.",
      "GPT_purpose": "Add Common CIPSOv4 data to a structure.",
      "GPT_function": "\n1. Extracts the DOI value from the netlink attributes.\n2. Validates the nested attributes using a specific policy.\n3. Iterates over the nested attributes to extract tag values into the doi_def->tags[] array, potentially causing an overflow issue.",
      "CVE_id": "CVE-2007-6762",
      "code_before_change": "static int netlbl_cipsov4_add_common(struct genl_info *info,\n\t\t\t\t     struct cipso_v4_doi *doi_def)\n{\n\tstruct nlattr *nla;\n\tint nla_rem;\n\tu32 iter = 0;\n\n\tdoi_def->doi = nla_get_u32(info->attrs[NLBL_CIPSOV4_A_DOI]);\n\n\tif (nla_validate_nested(info->attrs[NLBL_CIPSOV4_A_TAGLST],\n\t\t\t\tNLBL_CIPSOV4_A_MAX,\n\t\t\t\tnetlbl_cipsov4_genl_policy) != 0)\n\t\treturn -EINVAL;\n\n\tnla_for_each_nested(nla, info->attrs[NLBL_CIPSOV4_A_TAGLST], nla_rem)\n\t\tif (nla->nla_type == NLBL_CIPSOV4_A_TAG) {\n\t\t\tif (iter > CIPSO_V4_TAG_MAXCNT)\n\t\t\t\treturn -EINVAL;\n\t\t\tdoi_def->tags[iter++] = nla_get_u8(nla);\n\t\t}\n\tif (iter < CIPSO_V4_TAG_MAXCNT)\n\t\tdoi_def->tags[iter] = CIPSO_V4_TAG_INVALID;\n\n\treturn 0;\n}",
      "code_after_change": "static int netlbl_cipsov4_add_common(struct genl_info *info,\n\t\t\t\t     struct cipso_v4_doi *doi_def)\n{\n\tstruct nlattr *nla;\n\tint nla_rem;\n\tu32 iter = 0;\n\n\tdoi_def->doi = nla_get_u32(info->attrs[NLBL_CIPSOV4_A_DOI]);\n\n\tif (nla_validate_nested(info->attrs[NLBL_CIPSOV4_A_TAGLST],\n\t\t\t\tNLBL_CIPSOV4_A_MAX,\n\t\t\t\tnetlbl_cipsov4_genl_policy) != 0)\n\t\treturn -EINVAL;\n\n\tnla_for_each_nested(nla, info->attrs[NLBL_CIPSOV4_A_TAGLST], nla_rem)\n\t\tif (nla->nla_type == NLBL_CIPSOV4_A_TAG) {\n\t\t\tif (iter >= CIPSO_V4_TAG_MAXCNT)\n\t\t\t\treturn -EINVAL;\n\t\t\tdoi_def->tags[iter++] = nla_get_u8(nla);\n\t\t}\n\twhile (iter < CIPSO_V4_TAG_MAXCNT)\n\t\tdoi_def->tags[iter++] = CIPSO_V4_TAG_INVALID;\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\t\tif (iter >= CIPSO_V4_TAG_MAXCNT)",
          "\twhile (iter < CIPSO_V4_TAG_MAXCNT)",
          "\t\tdoi_def->tags[iter++] = CIPSO_V4_TAG_INVALID;"
        ],
        "deleted": [
          "\t\t\tif (iter > CIPSO_V4_TAG_MAXCNT)",
          "\tif (iter < CIPSO_V4_TAG_MAXCNT)",
          "\t\tdoi_def->tags[iter] = CIPSO_V4_TAG_INVALID;"
        ]
      },
      "preconditions_for_vulnerability": "Improper array bounds checking in a loop that populates an array based on user input.",
      "trigger_condition": "The loop condition allows the array index to exceed the maximum allowed index, leading to potential buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not correctly check the array index against the maximum allowed index, allowing it to go out of bounds and potentially overflow the array.",
      "id": 3,
      "code_after_change_normalized": "static int FUN1(struct genl_info *VAR1,\nstruct cipso_v4_doi *VAR2)\n{\nstruct nlattr *VAR3;\nint VAR4;\nu32 VAR5 = 0;\nVAR2->VAR6 = FUN2(VAR1->VAR7[VAR8]);\nif (FUN3(VAR1->VAR7[VAR9],\nVAR10,\nVAR11) != 0)\nreturn -VAR12;\nFUN4(VAR3, VAR1->VAR7[VAR9], VAR4)\nif (VAR3->VAR13 == VAR14) {\nif (VAR5 >= VAR15)\nreturn -VAR12;\nVAR2->VAR16[VAR5++] = FUN5(VAR3);\n}\nwhile (VAR5 < VAR15)\nVAR2->VAR16[VAR5++] = VAR17;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct genl_info *VAR1,\nstruct cipso_v4_doi *VAR2)\n{\nstruct nlattr *VAR3;\nint VAR4;\nu32 VAR5 = 0;\nVAR2->VAR6 = FUN2(VAR1->VAR7[VAR8]);\nif (FUN3(VAR1->VAR7[VAR9],\nVAR10,\nVAR11) != 0)\nreturn -VAR12;\nFUN4(VAR3, VAR1->VAR7[VAR9], VAR4)\nif (VAR3->VAR13 == VAR14) {\nif (VAR5 > VAR15)\nreturn -VAR12;\nVAR2->VAR16[VAR5++] = FUN5(VAR3);\n}\nif (VAR5 < VAR15)\nVAR2->VAR16[VAR5] = VAR17;\nreturn 0;\n}\n",
      "code_after_change_raw": "static int netlbl_cipsov4_add_common(struct genl_info *info,\nstruct cipso_v4_doi *doi_def)\n{\nstruct nlattr *nla;\nint nla_rem;\nu32 iter = 0;\ndoi_def->doi = nla_get_u32(info->attrs[NLBL_CIPSOV4_A_DOI]);\nif (nla_validate_nested(info->attrs[NLBL_CIPSOV4_A_TAGLST],\nNLBL_CIPSOV4_A_MAX,\nnetlbl_cipsov4_genl_policy) != 0)\nreturn -EINVAL;\nnla_for_each_nested(nla, info->attrs[NLBL_CIPSOV4_A_TAGLST], nla_rem)\nif (nla->nla_type == NLBL_CIPSOV4_A_TAG) {\nif (iter >= CIPSO_V4_TAG_MAXCNT)\nreturn -EINVAL;\ndoi_def->tags[iter++] = nla_get_u8(nla);\n}\nwhile (iter < CIPSO_V4_TAG_MAXCNT)\ndoi_def->tags[iter++] = CIPSO_V4_TAG_INVALID;\nreturn 0;\n}\n",
      "code_before_change_raw": "static int netlbl_cipsov4_add_common(struct genl_info *info,\nstruct cipso_v4_doi *doi_def)\n{\nstruct nlattr *nla;\nint nla_rem;\nu32 iter = 0;\ndoi_def->doi = nla_get_u32(info->attrs[NLBL_CIPSOV4_A_DOI]);\nif (nla_validate_nested(info->attrs[NLBL_CIPSOV4_A_TAGLST],\nNLBL_CIPSOV4_A_MAX,\nnetlbl_cipsov4_genl_policy) != 0)\nreturn -EINVAL;\nnla_for_each_nested(nla, info->attrs[NLBL_CIPSOV4_A_TAGLST], nla_rem)\nif (nla->nla_type == NLBL_CIPSOV4_A_TAG) {\nif (iter > CIPSO_V4_TAG_MAXCNT)\nreturn -EINVAL;\ndoi_def->tags[iter++] = nla_get_u8(nla);\n}\nif (iter < CIPSO_V4_TAG_MAXCNT)\ndoi_def->tags[iter] = CIPSO_V4_TAG_INVALID;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2009-2692": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incomplete initialization of function pointers in socket operations proto_ops structures.",
        "trigger_condition": "Local user utilizes mmap to map page zero with arbitrary code and invokes an unavailable operation, such as the sendpage operation on a specific socket type.",
        "specific_code_behavior_causing_vulnerability": "The code directly calls the sendpage operation on the socket's operations structure without proper initialization of all function pointers in the proto_ops structure. This can lead to a NULL pointer dereference and privilege escalation if an unavailable operation is triggered.",
        "solution": "To mitigate the vulnerability, it is necessary to replace the direct call to the sendpage operation on the socket's operations structure with a safer alternative, such as kernel_sendpage. This ensures that the operation is handled securely and eliminates the risk of NULL pointer dereference and unauthorized privilege escalation. The modification involves updating the code to use a more robust and properly initialized function for the sendpage operation."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2009-2692 by replacing the direct call to `sock->ops->sendpage` with a safer alternative. In the vulnerable code snippet, the `sendpage` operation is called directly on the socket's operations structure (`sock->ops->sendpage`). This vulnerability arises from the fact that not all function pointers in the `proto_ops` structure are properly initialized, leading to a potential NULL pointer dereference when invoking an unavailable operation.\n\nBy modifying the code to use `kernel_sendpage` instead of directly accessing `sock->ops->sendpage`, we eliminate the risk of triggering a NULL pointer dereference and gaining unauthorized privileges. `kernel_sendpage` is a safer alternative that ensures the operation is handled correctly and securely, mitigating the vulnerability associated with the direct call to `sock->ops->sendpage`.",
      "GPT_purpose": "Sending a page of data over a socket.",
      "GPT_function": "\n1. Send a page using a socket.\n2. Set flags based on file flags.\n3. Return the result of sending the page.",
      "CVE_id": "CVE-2009-2692",
      "code_before_change": "static ssize_t sock_sendpage(struct file *file, struct page *page,\n\t\t\t     int offset, size_t size, loff_t *ppos, int more)\n{\n\tstruct socket *sock;\n\tint flags;\n\n\tsock = file->private_data;\n\n\tflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\n\tif (more)\n\t\tflags |= MSG_MORE;\n\n\treturn sock->ops->sendpage(sock, page, offset, size, flags);\n}",
      "code_after_change": "static ssize_t sock_sendpage(struct file *file, struct page *page,\n\t\t\t     int offset, size_t size, loff_t *ppos, int more)\n{\n\tstruct socket *sock;\n\tint flags;\n\n\tsock = file->private_data;\n\n\tflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\n\tif (more)\n\t\tflags |= MSG_MORE;\n\n\treturn kernel_sendpage(sock, page, offset, size, flags);\n}",
      "modified_lines": {
        "added": [
          "\treturn kernel_sendpage(sock, page, offset, size, flags);"
        ],
        "deleted": [
          "\treturn sock->ops->sendpage(sock, page, offset, size, flags);"
        ]
      },
      "preconditions_for_vulnerability": "Incomplete initialization of function pointers in socket operations proto_ops structures.",
      "trigger_condition": "Local user utilizes mmap to map page zero with arbitrary code and invokes an unavailable operation, such as the sendpage operation on a specific socket type.",
      "specific_code_behavior_causing_vulnerability": "The code directly calls the sendpage operation on the socket's operations structure without proper initialization of all function pointers in the proto_ops structure. This can lead to a NULL pointer dereference and privilege escalation if an unavailable operation is triggered.",
      "solution": "To mitigate the vulnerability, it is necessary to replace the direct call to the sendpage operation on the socket's operations structure with a safer alternative, such as kernel_sendpage. This ensures that the operation is handled securely and eliminates the risk of NULL pointer dereference and unauthorized privilege escalation. The modification involves updating the code to use a more robust and properly initialized function for the sendpage operation.",
      "id": 4,
      "code_after_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, struct VAR2 *VAR2,\nint VAR3, size_t VAR4, loff_t *VAR5, int VAR6)\n{\nstruct socket *VAR7;\nint VAR8;\nVAR7 = VAR1->VAR9;\nVAR8 = !(VAR1->VAR10 & VAR11) ? 0 : VAR12;\nif (VAR6)\nVAR8 |= VAR13;\nreturn FUN2(VAR7, VAR2, VAR3, VAR4, VAR8);\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, struct VAR2 *VAR2,\nint VAR3, size_t VAR4, loff_t *VAR5, int VAR6)\n{\nstruct socket *VAR7;\nint VAR8;\nVAR7 = VAR1->VAR9;\nVAR8 = !(VAR1->VAR10 & VAR11) ? 0 : VAR12;\nif (VAR6)\nVAR8 |= VAR13;\nreturn VAR7->VAR14->FUN2(VAR7, VAR2, VAR3, VAR4, VAR8);\n}\n",
      "code_after_change_raw": "static ssize_t sock_sendpage(struct file *file, struct page *page,\nint offset, size_t size, loff_t *ppos, int more)\n{\nstruct socket *sock;\nint flags;\nsock = file->private_data;\nflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\nif (more)\nflags |= MSG_MORE;\nreturn kernel_sendpage(sock, page, offset, size, flags);\n}\n",
      "code_before_change_raw": "static ssize_t sock_sendpage(struct file *file, struct page *page,\nint offset, size_t size, loff_t *ppos, int more)\n{\nstruct socket *sock;\nint flags;\nsock = file->private_data;\nflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\nif (more)\nflags |= MSG_MORE;\nreturn sock->ops->sendpage(sock, page, offset, size, flags);\n}\n"
    }
  ],
  "CVE-2010-5332": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for array bounds checking when searching for a free entry in the array.",
        "trigger_condition": "When no free entry is found in the array, the loop terminates without updating the index variable, leading to a potential out-of-bounds array access.",
        "specific_code_behavior_causing_vulnerability": "The code does not handle the scenario where no free entry is available in the array, causing the index variable to remain uninitialized and potentially leading to an out-of-bounds access when registering a new MAC address."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check after the loop to verify if a free entry was found. If no free entry is available, an appropriate error code should be set, and the function should exit without attempting to access the array using an invalid index. This solution ensures that the code handles the case of no free entries properly and prevents the out-of-bounds array access vulnerability.",
      "GPT_analysis": "The modification is necessary to prevent an out-of-bounds array access vulnerability in the code. In the original code snippet, if there are no free entries available in the array, the loop terminates without updating the `free` variable. This can lead to accessing the array out of bounds when trying to register a new MAC address.\n\nBy adding the check `if (free < 0)` after the loop, we ensure that if no free entry is found, an appropriate error code is set, and the function exits without attempting to access the array using an invalid index. This modification helps to prevent the vulnerability described in CVE-2010-5332 by handling the case where no free entry is available in the array.",
      "GPT_purpose": "Registering MAC addresses in a table for a Mellanox ConnectX-4 device port.",
      "GPT_function": "\n1. Registering a MAC address in the mlx4 device.\n2. Searching for a free entry in the MAC table.\n3. Handling the registration and error cases for MAC addresses.",
      "CVE_id": "CVE-2010-5332",
      "code_before_change": "int mlx4_register_mac(struct mlx4_dev *dev, u8 port, u64 mac, int *index)\n{\n\tstruct mlx4_mac_table *table = &mlx4_priv(dev)->port[port].mac_table;\n\tint i, err = 0;\n\tint free = -1;\n\n\tmlx4_dbg(dev, \"Registering MAC: 0x%llx\\n\", (unsigned long long) mac);\n\tmutex_lock(&table->mutex);\n\tfor (i = 0; i < MLX4_MAX_MAC_NUM - 1; i++) {\n\t\tif (free < 0 && !table->refs[i]) {\n\t\t\tfree = i;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (mac == (MLX4_MAC_MASK & be64_to_cpu(table->entries[i]))) {\n\t\t\t/* MAC already registered, increase refernce count */\n\t\t\t*index = i;\n\t\t\t++table->refs[i];\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmlx4_dbg(dev, \"Free MAC index is %d\\n\", free);\n\n\tif (table->total == table->max) {\n\t\t/* No free mac entries */\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t/* Register new MAC */\n\ttable->refs[free] = 1;\n\ttable->entries[free] = cpu_to_be64(mac | MLX4_MAC_VALID);\n\n\terr = mlx4_set_port_mac_table(dev, port, table->entries);\n\tif (unlikely(err)) {\n\t\tmlx4_err(dev, \"Failed adding MAC: 0x%llx\\n\", (unsigned long long) mac);\n\t\ttable->refs[free] = 0;\n\t\ttable->entries[free] = 0;\n\t\tgoto out;\n\t}\n\n\t*index = free;\n\t++table->total;\nout:\n\tmutex_unlock(&table->mutex);\n\treturn err;\n}",
      "code_after_change": "int mlx4_register_mac(struct mlx4_dev *dev, u8 port, u64 mac, int *index)\n{\n\tstruct mlx4_mac_table *table = &mlx4_priv(dev)->port[port].mac_table;\n\tint i, err = 0;\n\tint free = -1;\n\n\tmlx4_dbg(dev, \"Registering MAC: 0x%llx\\n\", (unsigned long long) mac);\n\tmutex_lock(&table->mutex);\n\tfor (i = 0; i < MLX4_MAX_MAC_NUM - 1; i++) {\n\t\tif (free < 0 && !table->refs[i]) {\n\t\t\tfree = i;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (mac == (MLX4_MAC_MASK & be64_to_cpu(table->entries[i]))) {\n\t\t\t/* MAC already registered, increase refernce count */\n\t\t\t*index = i;\n\t\t\t++table->refs[i];\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (free < 0) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmlx4_dbg(dev, \"Free MAC index is %d\\n\", free);\n\n\tif (table->total == table->max) {\n\t\t/* No free mac entries */\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t/* Register new MAC */\n\ttable->refs[free] = 1;\n\ttable->entries[free] = cpu_to_be64(mac | MLX4_MAC_VALID);\n\n\terr = mlx4_set_port_mac_table(dev, port, table->entries);\n\tif (unlikely(err)) {\n\t\tmlx4_err(dev, \"Failed adding MAC: 0x%llx\\n\", (unsigned long long) mac);\n\t\ttable->refs[free] = 0;\n\t\ttable->entries[free] = 0;\n\t\tgoto out;\n\t}\n\n\t*index = free;\n\t++table->total;\nout:\n\tmutex_unlock(&table->mutex);\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "",
          "\tif (free < 0) {",
          "\t\terr = -ENOMEM;",
          "\t\tgoto out;",
          "\t}",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper handling for array bounds checking when searching for a free entry in the array.",
      "trigger_condition": "When no free entry is found in the array, the loop terminates without updating the index variable, leading to a potential out-of-bounds array access.",
      "specific_code_behavior_causing_vulnerability": "The code does not handle the scenario where no free entry is available in the array, causing the index variable to remain uninitialized and potentially leading to an out-of-bounds access when registering a new MAC address.",
      "id": 5,
      "code_after_change_normalized": "int FUN1(struct mlx4_dev *VAR1, u8 VAR2, u64 VAR3, int *VAR4)\n{\nstruct mlx4_mac_table *VAR5 = &FUN2(VAR1)->VAR2[VAR2].VAR6;\nint VAR7, VAR8 = 0;\nint VAR9 = -1;\nFUN3(VAR1, \"STR\", (unsigned long long) VAR3);\nFUN4(&VAR5->VAR10);\nfor (VAR7 = 0; VAR7 < VAR11 - 1; VAR7++) {\nif (VAR9 < 0 && !VAR5->VAR12[VAR7]) {\nVAR9 = VAR7;\ncontinue;\n}\nif (VAR3 == (VAR13 & FUN5(VAR5->VAR14[VAR7]))) {\n*VAR4 = VAR7;\n++VAR5->VAR12[VAR7];\ngoto VAR15;\n}\n}\nif (VAR9 < 0) {\nVAR8 = -VAR16;\ngoto VAR15;\n}\nFUN3(VAR1, \"STR\", VAR9);\nif (VAR5->VAR17 == VAR5->VAR18) {\nVAR8 = -VAR19;\ngoto VAR15;\n}\nVAR5->VAR12[VAR9] = 1;\nVAR5->VAR14[VAR9] = FUN6(VAR3 | VAR20);\nVAR8 = FUN7(VAR1, VAR2, VAR5->VAR14);\nif (FUN8(VAR8)) {\nFUN9(VAR1, \"STR\", (unsigned long long) VAR3);\nVAR5->VAR12[VAR9] = 0;\nVAR5->VAR14[VAR9] = 0;\ngoto VAR15;\n}\n*VAR4 = VAR9;\n++VAR5->VAR17;\nVAR15:\nFUN10(&VAR5->VAR10);\nreturn VAR8;\n}\n",
      "code_before_change_normalized": "int FUN1(struct mlx4_dev *VAR1, u8 VAR2, u64 VAR3, int *VAR4)\n{\nstruct mlx4_mac_table *VAR5 = &FUN2(VAR1)->VAR2[VAR2].VAR6;\nint VAR7, VAR8 = 0;\nint VAR9 = -1;\nFUN3(VAR1, \"STR\", (unsigned long long) VAR3);\nFUN4(&VAR5->VAR10);\nfor (VAR7 = 0; VAR7 < VAR11 - 1; VAR7++) {\nif (VAR9 < 0 && !VAR5->VAR12[VAR7]) {\nVAR9 = VAR7;\ncontinue;\n}\nif (VAR3 == (VAR13 & FUN5(VAR5->VAR14[VAR7]))) {\n*VAR4 = VAR7;\n++VAR5->VAR12[VAR7];\ngoto VAR15;\n}\n}\nFUN3(VAR1, \"STR\", VAR9);\nif (VAR5->VAR16 == VAR5->VAR17) {\nVAR8 = -VAR18;\ngoto VAR15;\n}\nVAR5->VAR12[VAR9] = 1;\nVAR5->VAR14[VAR9] = FUN6(VAR3 | VAR19);\nVAR8 = FUN7(VAR1, VAR2, VAR5->VAR14);\nif (FUN8(VAR8)) {\nFUN9(VAR1, \"STR\", (unsigned long long) VAR3);\nVAR5->VAR12[VAR9] = 0;\nVAR5->VAR14[VAR9] = 0;\ngoto VAR15;\n}\n*VAR4 = VAR9;\n++VAR5->VAR16;\nVAR15:\nFUN10(&VAR5->VAR10);\nreturn VAR8;\n}\n",
      "code_after_change_raw": "int mlx4_register_mac(struct mlx4_dev *dev, u8 port, u64 mac, int *index)\n{\nstruct mlx4_mac_table *table = &mlx4_priv(dev)->port[port].mac_table;\nint i, err = 0;\nint free = -1;\nmlx4_dbg(dev, \"Registering MAC: 0x%llx\\n\", (unsigned long long) mac);\nmutex_lock(&table->mutex);\nfor (i = 0; i < MLX4_MAX_MAC_NUM - 1; i++) {\nif (free < 0 && !table->refs[i]) {\nfree = i;\ncontinue;\n}\nif (mac == (MLX4_MAC_MASK & be64_to_cpu(table->entries[i]))) {\n*index = i;\n++table->refs[i];\ngoto out;\n}\n}\nif (free < 0) {\nerr = -ENOMEM;\ngoto out;\n}\nmlx4_dbg(dev, \"Free MAC index is %d\\n\", free);\nif (table->total == table->max) {\nerr = -ENOSPC;\ngoto out;\n}\ntable->refs[free] = 1;\ntable->entries[free] = cpu_to_be64(mac | MLX4_MAC_VALID);\nerr = mlx4_set_port_mac_table(dev, port, table->entries);\nif (unlikely(err)) {\nmlx4_err(dev, \"Failed adding MAC: 0x%llx\\n\", (unsigned long long) mac);\ntable->refs[free] = 0;\ntable->entries[free] = 0;\ngoto out;\n}\n*index = free;\n++table->total;\nout:\nmutex_unlock(&table->mutex);\nreturn err;\n}\n",
      "code_before_change_raw": "int mlx4_register_mac(struct mlx4_dev *dev, u8 port, u64 mac, int *index)\n{\nstruct mlx4_mac_table *table = &mlx4_priv(dev)->port[port].mac_table;\nint i, err = 0;\nint free = -1;\nmlx4_dbg(dev, \"Registering MAC: 0x%llx\\n\", (unsigned long long) mac);\nmutex_lock(&table->mutex);\nfor (i = 0; i < MLX4_MAX_MAC_NUM - 1; i++) {\nif (free < 0 && !table->refs[i]) {\nfree = i;\ncontinue;\n}\nif (mac == (MLX4_MAC_MASK & be64_to_cpu(table->entries[i]))) {\n*index = i;\n++table->refs[i];\ngoto out;\n}\n}\nmlx4_dbg(dev, \"Free MAC index is %d\\n\", free);\nif (table->total == table->max) {\nerr = -ENOSPC;\ngoto out;\n}\ntable->refs[free] = 1;\ntable->entries[free] = cpu_to_be64(mac | MLX4_MAC_VALID);\nerr = mlx4_set_port_mac_table(dev, port, table->entries);\nif (unlikely(err)) {\nmlx4_err(dev, \"Failed adding MAC: 0x%llx\\n\", (unsigned long long) mac);\ntable->refs[free] = 0;\ntable->entries[free] = 0;\ngoto out;\n}\n*index = free;\n++table->total;\nout:\nmutex_unlock(&table->mutex);\nreturn err;\n}\n"
    }
  ],
  "CVE-2011-4098": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Reliance on the page cache for block preallocation without proper initialization.",
        "trigger_condition": "Insufficient memory situation during block preallocation process.",
        "specific_code_behavior_causing_vulnerability": "The code preallocates blocks without zeroing out the data, leading to a denial of service vulnerability when insufficient memory is encountered.",
        "specific_solution": "To mitigate the vulnerability, it is necessary to zero out the allocated data blocks before using them. This ensures proper initialization of the blocks and prevents exposure of sensitive data or unexpected behavior due to uninitialized data. In this case, the solution involves adding a call to sb_issue_zeroout function to zero out the allocated data blocks before proceeding with further operations."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2011-4098 in the GFS2 filesystem code snippet. The vulnerability arises from the fallocate implementation in the GFS2 filesystem relying on the page cache, which can lead to a denial of service by preallocating blocks in certain situations involving insufficient memory.\n\nThe modification introduces a call to `sb_issue_zeroout` function to zero out the allocated data blocks before using them. This helps to ensure that the allocated blocks are properly initialized and do not contain any sensitive data from previous usage. By zeroing out the blocks, the risk of exposing sensitive information or causing unexpected behavior due to uninitialized data is mitigated.\n\nIn summary, the modification adds a necessary step to securely initialize the allocated data blocks, thereby addressing the vulnerability and enhancing the security and reliability of the GFS2 filesystem implementation.",
      "GPT_purpose": "Allocate blocks for the GFS2 filesystem inode, handling tree growth and data block allocation based on the height and state of the filesystem structure.",
      "GPT_function": "\n1. Allocate blocks for the GFS2 filesystem.\n2. Handle the allocation of indirect blocks.\n3. Implement a state machine for growing the tree height and depth.\n4. Add data blocks to the tree.\n5. Update the inode height and block information.\n6. Set buffer information for the allocated blocks.",
      "CVE_id": "CVE-2011-4098",
      "code_before_change": "static int gfs2_bmap_alloc(struct inode *inode, const sector_t lblock,\n\t\t\t   struct buffer_head *bh_map, struct metapath *mp,\n\t\t\t   const unsigned int sheight,\n\t\t\t   const unsigned int height,\n\t\t\t   const unsigned int maxlen)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct buffer_head *dibh = mp->mp_bh[0];\n\tu64 bn, dblock = 0;\n\tunsigned n, i, blks, alloced = 0, iblks = 0, branch_start = 0;\n\tunsigned dblks = 0;\n\tunsigned ptrs_per_blk;\n\tconst unsigned end_of_metadata = height - 1;\n\tint eob = 0;\n\tenum alloc_state state;\n\t__be64 *ptr;\n\t__be64 zero_bn = 0;\n\n\tBUG_ON(sheight < 1);\n\tBUG_ON(dibh == NULL);\n\n\tgfs2_trans_add_bh(ip->i_gl, dibh, 1);\n\n\tif (height == sheight) {\n\t\tstruct buffer_head *bh;\n\t\t/* Bottom indirect block exists, find unalloced extent size */\n\t\tptr = metapointer(end_of_metadata, mp);\n\t\tbh = mp->mp_bh[end_of_metadata];\n\t\tdblks = gfs2_extent_length(bh->b_data, bh->b_size, ptr, maxlen,\n\t\t\t\t\t   &eob);\n\t\tBUG_ON(dblks < 1);\n\t\tstate = ALLOC_DATA;\n\t} else {\n\t\t/* Need to allocate indirect blocks */\n\t\tptrs_per_blk = height > 1 ? sdp->sd_inptrs : sdp->sd_diptrs;\n\t\tdblks = min(maxlen, ptrs_per_blk - mp->mp_list[end_of_metadata]);\n\t\tif (height == ip->i_height) {\n\t\t\t/* Writing into existing tree, extend tree down */\n\t\t\tiblks = height - sheight;\n\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t} else {\n\t\t\t/* Building up tree height */\n\t\t\tstate = ALLOC_GROW_HEIGHT;\n\t\t\tiblks = height - ip->i_height;\n\t\t\tbranch_start = metapath_branch_start(mp);\n\t\t\tiblks += (height - branch_start);\n\t\t}\n\t}\n\n\t/* start of the second part of the function (state machine) */\n\n\tblks = dblks + iblks;\n\ti = sheight;\n\tdo {\n\t\tint error;\n\t\tn = blks - alloced;\n\t\terror = gfs2_alloc_block(ip, &bn, &n);\n\t\tif (error)\n\t\t\treturn error;\n\t\talloced += n;\n\t\tif (state != ALLOC_DATA || gfs2_is_jdata(ip))\n\t\t\tgfs2_trans_add_unrevoke(sdp, bn, n);\n\t\tswitch (state) {\n\t\t/* Growing height of tree */\n\t\tcase ALLOC_GROW_HEIGHT:\n\t\t\tif (i == 1) {\n\t\t\t\tptr = (__be64 *)(dibh->b_data +\n\t\t\t\t\t\t sizeof(struct gfs2_dinode));\n\t\t\t\tzero_bn = *ptr;\n\t\t\t}\n\t\t\tfor (; i - 1 < height - ip->i_height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i, 0, bn++);\n\t\t\tif (i - 1 == height - ip->i_height) {\n\t\t\t\ti--;\n\t\t\t\tgfs2_buffer_copy_tail(mp->mp_bh[i],\n\t\t\t\t\t\tsizeof(struct gfs2_meta_header),\n\t\t\t\t\t\tdibh, sizeof(struct gfs2_dinode));\n\t\t\t\tgfs2_buffer_clear_tail(dibh,\n\t\t\t\t\t\tsizeof(struct gfs2_dinode) +\n\t\t\t\t\t\tsizeof(__be64));\n\t\t\t\tptr = (__be64 *)(mp->mp_bh[i]->b_data +\n\t\t\t\t\tsizeof(struct gfs2_meta_header));\n\t\t\t\t*ptr = zero_bn;\n\t\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t\t\tfor(i = branch_start; i < height; i++) {\n\t\t\t\t\tif (mp->mp_bh[i] == NULL)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tbrelse(mp->mp_bh[i]);\n\t\t\t\t\tmp->mp_bh[i] = NULL;\n\t\t\t\t}\n\t\t\t\ti = branch_start;\n\t\t\t}\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Branching from existing tree */\n\t\tcase ALLOC_GROW_DEPTH:\n\t\t\tif (i > 1 && i < height)\n\t\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[i-1], 1);\n\t\t\tfor (; i < height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i,\n\t\t\t\t\t\t   mp->mp_list[i-1], bn++);\n\t\t\tif (i == height)\n\t\t\t\tstate = ALLOC_DATA;\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Tree complete, adding data blocks */\n\t\tcase ALLOC_DATA:\n\t\t\tBUG_ON(n > dblks);\n\t\t\tBUG_ON(mp->mp_bh[end_of_metadata] == NULL);\n\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[end_of_metadata], 1);\n\t\t\tdblks = n;\n\t\t\tptr = metapointer(end_of_metadata, mp);\n\t\t\tdblock = bn;\n\t\t\twhile (n-- > 0)\n\t\t\t\t*ptr++ = cpu_to_be64(bn++);\n\t\t\tbreak;\n\t\t}\n\t} while ((state != ALLOC_DATA) || !dblock);\n\n\tip->i_height = height;\n\tgfs2_add_inode_blocks(&ip->i_inode, alloced);\n\tgfs2_dinode_out(ip, mp->mp_bh[0]->b_data);\n\tmap_bh(bh_map, inode->i_sb, dblock);\n\tbh_map->b_size = dblks << inode->i_blkbits;\n\tset_buffer_new(bh_map);\n\treturn 0;\n}",
      "code_after_change": "static int gfs2_bmap_alloc(struct inode *inode, const sector_t lblock,\n\t\t\t   struct buffer_head *bh_map, struct metapath *mp,\n\t\t\t   const unsigned int sheight,\n\t\t\t   const unsigned int height,\n\t\t\t   const unsigned int maxlen)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct super_block *sb = sdp->sd_vfs;\n\tstruct buffer_head *dibh = mp->mp_bh[0];\n\tu64 bn, dblock = 0;\n\tunsigned n, i, blks, alloced = 0, iblks = 0, branch_start = 0;\n\tunsigned dblks = 0;\n\tunsigned ptrs_per_blk;\n\tconst unsigned end_of_metadata = height - 1;\n\tint ret;\n\tint eob = 0;\n\tenum alloc_state state;\n\t__be64 *ptr;\n\t__be64 zero_bn = 0;\n\n\tBUG_ON(sheight < 1);\n\tBUG_ON(dibh == NULL);\n\n\tgfs2_trans_add_bh(ip->i_gl, dibh, 1);\n\n\tif (height == sheight) {\n\t\tstruct buffer_head *bh;\n\t\t/* Bottom indirect block exists, find unalloced extent size */\n\t\tptr = metapointer(end_of_metadata, mp);\n\t\tbh = mp->mp_bh[end_of_metadata];\n\t\tdblks = gfs2_extent_length(bh->b_data, bh->b_size, ptr, maxlen,\n\t\t\t\t\t   &eob);\n\t\tBUG_ON(dblks < 1);\n\t\tstate = ALLOC_DATA;\n\t} else {\n\t\t/* Need to allocate indirect blocks */\n\t\tptrs_per_blk = height > 1 ? sdp->sd_inptrs : sdp->sd_diptrs;\n\t\tdblks = min(maxlen, ptrs_per_blk - mp->mp_list[end_of_metadata]);\n\t\tif (height == ip->i_height) {\n\t\t\t/* Writing into existing tree, extend tree down */\n\t\t\tiblks = height - sheight;\n\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t} else {\n\t\t\t/* Building up tree height */\n\t\t\tstate = ALLOC_GROW_HEIGHT;\n\t\t\tiblks = height - ip->i_height;\n\t\t\tbranch_start = metapath_branch_start(mp);\n\t\t\tiblks += (height - branch_start);\n\t\t}\n\t}\n\n\t/* start of the second part of the function (state machine) */\n\n\tblks = dblks + iblks;\n\ti = sheight;\n\tdo {\n\t\tint error;\n\t\tn = blks - alloced;\n\t\terror = gfs2_alloc_block(ip, &bn, &n);\n\t\tif (error)\n\t\t\treturn error;\n\t\talloced += n;\n\t\tif (state != ALLOC_DATA || gfs2_is_jdata(ip))\n\t\t\tgfs2_trans_add_unrevoke(sdp, bn, n);\n\t\tswitch (state) {\n\t\t/* Growing height of tree */\n\t\tcase ALLOC_GROW_HEIGHT:\n\t\t\tif (i == 1) {\n\t\t\t\tptr = (__be64 *)(dibh->b_data +\n\t\t\t\t\t\t sizeof(struct gfs2_dinode));\n\t\t\t\tzero_bn = *ptr;\n\t\t\t}\n\t\t\tfor (; i - 1 < height - ip->i_height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i, 0, bn++);\n\t\t\tif (i - 1 == height - ip->i_height) {\n\t\t\t\ti--;\n\t\t\t\tgfs2_buffer_copy_tail(mp->mp_bh[i],\n\t\t\t\t\t\tsizeof(struct gfs2_meta_header),\n\t\t\t\t\t\tdibh, sizeof(struct gfs2_dinode));\n\t\t\t\tgfs2_buffer_clear_tail(dibh,\n\t\t\t\t\t\tsizeof(struct gfs2_dinode) +\n\t\t\t\t\t\tsizeof(__be64));\n\t\t\t\tptr = (__be64 *)(mp->mp_bh[i]->b_data +\n\t\t\t\t\tsizeof(struct gfs2_meta_header));\n\t\t\t\t*ptr = zero_bn;\n\t\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t\t\tfor(i = branch_start; i < height; i++) {\n\t\t\t\t\tif (mp->mp_bh[i] == NULL)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tbrelse(mp->mp_bh[i]);\n\t\t\t\t\tmp->mp_bh[i] = NULL;\n\t\t\t\t}\n\t\t\t\ti = branch_start;\n\t\t\t}\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Branching from existing tree */\n\t\tcase ALLOC_GROW_DEPTH:\n\t\t\tif (i > 1 && i < height)\n\t\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[i-1], 1);\n\t\t\tfor (; i < height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i,\n\t\t\t\t\t\t   mp->mp_list[i-1], bn++);\n\t\t\tif (i == height)\n\t\t\t\tstate = ALLOC_DATA;\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Tree complete, adding data blocks */\n\t\tcase ALLOC_DATA:\n\t\t\tBUG_ON(n > dblks);\n\t\t\tBUG_ON(mp->mp_bh[end_of_metadata] == NULL);\n\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[end_of_metadata], 1);\n\t\t\tdblks = n;\n\t\t\tptr = metapointer(end_of_metadata, mp);\n\t\t\tdblock = bn;\n\t\t\twhile (n-- > 0)\n\t\t\t\t*ptr++ = cpu_to_be64(bn++);\n\t\t\tif (buffer_zeronew(bh_map)) {\n\t\t\t\tret = sb_issue_zeroout(sb, dblock, dblks,\n\t\t\t\t\t\t       GFP_NOFS);\n\t\t\t\tif (ret) {\n\t\t\t\t\tfs_err(sdp,\n\t\t\t\t\t       \"Failed to zero data buffers\\n\");\n\t\t\t\t\tclear_buffer_zeronew(bh_map);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t} while ((state != ALLOC_DATA) || !dblock);\n\n\tip->i_height = height;\n\tgfs2_add_inode_blocks(&ip->i_inode, alloced);\n\tgfs2_dinode_out(ip, mp->mp_bh[0]->b_data);\n\tmap_bh(bh_map, inode->i_sb, dblock);\n\tbh_map->b_size = dblks << inode->i_blkbits;\n\tset_buffer_new(bh_map);\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tstruct super_block *sb = sdp->sd_vfs;",
          "\tint ret;",
          "\t\t\tif (buffer_zeronew(bh_map)) {",
          "\t\t\t\tret = sb_issue_zeroout(sb, dblock, dblks,",
          "\t\t\t\t\t\t       GFP_NOFS);",
          "\t\t\t\tif (ret) {",
          "\t\t\t\t\tfs_err(sdp,",
          "\t\t\t\t\t       \"Failed to zero data buffers\\n\");",
          "\t\t\t\t\tclear_buffer_zeronew(bh_map);",
          "\t\t\t\t}",
          "\t\t\t}"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Reliance on the page cache for block preallocation without proper initialization.",
      "trigger_condition": "Insufficient memory situation during block preallocation process.",
      "specific_code_behavior_causing_vulnerability": "The code preallocates blocks without zeroing out the data, leading to a denial of service vulnerability when insufficient memory is encountered.",
      "id": 6,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1, const sector_t VAR2,\nstruct buffer_head *VAR3, struct metapath *VAR4,\nconst unsigned int VAR5,\nconst unsigned int VAR6,\nconst unsigned int VAR7)\n{\nstruct gfs2_inode *VAR8 = FUN2(VAR1);\nstruct gfs2_sbd *VAR9 = FUN3(VAR1);\nstruct super_block *VAR10 = VAR9->VAR11;\nstruct buffer_head *VAR12 = VAR4->VAR13[0];\nu64 VAR14, VAR15 = 0;\nunsigned VAR16, VAR17, VAR18, VAR19 = 0, VAR20 = 0, VAR21 = 0;\nunsigned VAR22 = 0;\nunsigned VAR23;\nconst unsigned VAR24 = VAR6 - 1;\nint VAR25;\nint VAR26 = 0;\nenum alloc_state VAR27;\n__be64 *VAR28;\n__be64 VAR29 = 0;\nFUN4(VAR5 < 1);\nFUN4(VAR12 == NULL);\nFUN5(VAR8->VAR30, VAR12, 1);\nif (VAR6 == VAR5) {\nstruct buffer_head *VAR31;\nVAR28 = FUN6(VAR24, VAR4);\nVAR31 = VAR4->VAR13[VAR24];\nVAR22 = FUN7(VAR31->VAR32, VAR31->VAR33, VAR28, VAR7,\n&VAR26);\nFUN4(VAR22 < 1);\nVAR27 = VAR34;\n} else {\nVAR23 = VAR6 > 1 ? VAR9->VAR35 : VAR9->VAR36;\nVAR22 = FUN8(VAR7, VAR23 - VAR4->VAR37[VAR24]);\nif (VAR6 == VAR8->VAR38) {\nVAR20 = VAR6 - VAR5;\nVAR27 = VAR39;\n} else {\nVAR27 = VAR40;\nVAR20 = VAR6 - VAR8->VAR38;\nVAR21 = FUN9(VAR4);\nVAR20 += (VAR6 - VAR21);\n}\n}\nVAR18 = VAR22 + VAR20;\nVAR17 = VAR5;\ndo {\nint VAR41;\nVAR16 = VAR18 - VAR19;\nVAR41 = FUN10(VAR8, &VAR14, &VAR16);\nif (VAR41)\nreturn VAR41;\nVAR19 += VAR16;\nif (VAR27 != VAR34 || FUN11(VAR8))\nFUN12(VAR9, VAR14, VAR16);\nswitch (VAR27) {\ncase VAR40:\nif (VAR17 == 1) {\nVAR28 = (VAR42 *)(VAR12->VAR32 +\nsizeof(struct VAR43));\nVAR29 = *VAR28;\n}\nfor (; VAR17 - 1 < VAR6 - VAR8->VAR38 && VAR16 > 0; VAR17++, VAR16--)\nFUN13(VAR4, VAR8->VAR30, VAR17, 0, VAR14++);\nif (VAR17 - 1 == VAR6 - VAR8->VAR38) {\nVAR17--;\nFUN14(VAR4->VAR13[VAR17],\nsizeof(struct VAR44),\nVAR12, sizeof(struct VAR43));\nFUN15(VAR12,\nsizeof(struct VAR43) +\nsizeof(VAR42));\nVAR28 = (VAR42 *)(VAR4->VAR13[VAR17]->VAR32 +\nsizeof(struct VAR44));\n*VAR28 = VAR29;\nVAR27 = VAR39;\nfor(VAR17 = VAR21; VAR17 < VAR6; VAR17++) {\nif (VAR4->VAR13[VAR17] == NULL)\nbreak;\nFUN16(VAR4->VAR13[VAR17]);\nVAR4->VAR13[VAR17] = NULL;\n}\nVAR17 = VAR21;\n}\nif (VAR16 == 0)\nbreak;\ncase VAR39:\nif (VAR17 > 1 && VAR17 < VAR6)\nFUN5(VAR8->VAR30, VAR4->VAR13[VAR17-1], 1);\nfor (; VAR17 < VAR6 && VAR16 > 0; VAR17++, VAR16--)\nFUN13(VAR4, VAR8->VAR30, VAR17,\nVAR4->VAR37[VAR17-1], VAR14++);\nif (VAR17 == VAR6)\nVAR27 = VAR34;\nif (VAR16 == 0)\nbreak;\ncase VAR34:\nFUN4(VAR16 > VAR22);\nFUN4(VAR4->VAR13[VAR24] == NULL);\nFUN5(VAR8->VAR30, VAR4->VAR13[VAR24], 1);\nVAR22 = VAR16;\nVAR28 = FUN6(VAR24, VAR4);\nVAR15 = VAR14;\nwhile (VAR16-- > 0)\n*VAR28++ = FUN17(VAR14++);\nif (FUN18(VAR3)) {\nVAR25 = FUN19(VAR10, VAR15, VAR22,\nVAR45);\nif (VAR25) {\nFUN20(VAR9,\n\"STR\");\nFUN21(VAR3);\n}\n}\nbreak;\n}\n} while ((VAR27 != VAR34) || !VAR15);\nVAR8->VAR38 = VAR6;\nFUN22(&VAR8->VAR46, VAR19);\nFUN23(VAR8, VAR4->VAR13[0]->VAR32);\nFUN24(VAR3, VAR1->VAR47, VAR15);\nVAR3->VAR33 = VAR22 << VAR1->VAR48;\nFUN25(VAR3);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1, const sector_t VAR2,\nstruct buffer_head *VAR3, struct metapath *VAR4,\nconst unsigned int VAR5,\nconst unsigned int VAR6,\nconst unsigned int VAR7)\n{\nstruct gfs2_inode *VAR8 = FUN2(VAR1);\nstruct gfs2_sbd *VAR9 = FUN3(VAR1);\nstruct buffer_head *VAR10 = VAR4->VAR11[0];\nu64 VAR12, VAR13 = 0;\nunsigned VAR14, VAR15, VAR16, VAR17 = 0, VAR18 = 0, VAR19 = 0;\nunsigned VAR20 = 0;\nunsigned VAR21;\nconst unsigned VAR22 = VAR6 - 1;\nint VAR23 = 0;\nenum alloc_state VAR24;\n__be64 *VAR25;\n__be64 VAR26 = 0;\nFUN4(VAR5 < 1);\nFUN4(VAR10 == NULL);\nFUN5(VAR8->VAR27, VAR10, 1);\nif (VAR6 == VAR5) {\nstruct buffer_head *VAR28;\nVAR25 = FUN6(VAR22, VAR4);\nVAR28 = VAR4->VAR11[VAR22];\nVAR20 = FUN7(VAR28->VAR29, VAR28->VAR30, VAR25, VAR7,\n&VAR23);\nFUN4(VAR20 < 1);\nVAR24 = VAR31;\n} else {\nVAR21 = VAR6 > 1 ? VAR9->VAR32 : VAR9->VAR33;\nVAR20 = FUN8(VAR7, VAR21 - VAR4->VAR34[VAR22]);\nif (VAR6 == VAR8->VAR35) {\nVAR18 = VAR6 - VAR5;\nVAR24 = VAR36;\n} else {\nVAR24 = VAR37;\nVAR18 = VAR6 - VAR8->VAR35;\nVAR19 = FUN9(VAR4);\nVAR18 += (VAR6 - VAR19);\n}\n}\nVAR16 = VAR20 + VAR18;\nVAR15 = VAR5;\ndo {\nint VAR38;\nVAR14 = VAR16 - VAR17;\nVAR38 = FUN10(VAR8, &VAR12, &VAR14);\nif (VAR38)\nreturn VAR38;\nVAR17 += VAR14;\nif (VAR24 != VAR31 || FUN11(VAR8))\nFUN12(VAR9, VAR12, VAR14);\nswitch (VAR24) {\ncase VAR37:\nif (VAR15 == 1) {\nVAR25 = (VAR39 *)(VAR10->VAR29 +\nsizeof(struct VAR40));\nVAR26 = *VAR25;\n}\nfor (; VAR15 - 1 < VAR6 - VAR8->VAR35 && VAR14 > 0; VAR15++, VAR14--)\nFUN13(VAR4, VAR8->VAR27, VAR15, 0, VAR12++);\nif (VAR15 - 1 == VAR6 - VAR8->VAR35) {\nVAR15--;\nFUN14(VAR4->VAR11[VAR15],\nsizeof(struct VAR41),\nVAR10, sizeof(struct VAR40));\nFUN15(VAR10,\nsizeof(struct VAR40) +\nsizeof(VAR39));\nVAR25 = (VAR39 *)(VAR4->VAR11[VAR15]->VAR29 +\nsizeof(struct VAR41));\n*VAR25 = VAR26;\nVAR24 = VAR36;\nfor(VAR15 = VAR19; VAR15 < VAR6; VAR15++) {\nif (VAR4->VAR11[VAR15] == NULL)\nbreak;\nFUN16(VAR4->VAR11[VAR15]);\nVAR4->VAR11[VAR15] = NULL;\n}\nVAR15 = VAR19;\n}\nif (VAR14 == 0)\nbreak;\ncase VAR36:\nif (VAR15 > 1 && VAR15 < VAR6)\nFUN5(VAR8->VAR27, VAR4->VAR11[VAR15-1], 1);\nfor (; VAR15 < VAR6 && VAR14 > 0; VAR15++, VAR14--)\nFUN13(VAR4, VAR8->VAR27, VAR15,\nVAR4->VAR34[VAR15-1], VAR12++);\nif (VAR15 == VAR6)\nVAR24 = VAR31;\nif (VAR14 == 0)\nbreak;\ncase VAR31:\nFUN4(VAR14 > VAR20);\nFUN4(VAR4->VAR11[VAR22] == NULL);\nFUN5(VAR8->VAR27, VAR4->VAR11[VAR22], 1);\nVAR20 = VAR14;\nVAR25 = FUN6(VAR22, VAR4);\nVAR13 = VAR12;\nwhile (VAR14-- > 0)\n*VAR25++ = FUN17(VAR12++);\nbreak;\n}\n} while ((VAR24 != VAR31) || !VAR13);\nVAR8->VAR35 = VAR6;\nFUN18(&VAR8->VAR42, VAR17);\nFUN19(VAR8, VAR4->VAR11[0]->VAR29);\nFUN20(VAR3, VAR1->VAR43, VAR13);\nVAR3->VAR30 = VAR20 << VAR1->VAR44;\nFUN21(VAR3);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int gfs2_bmap_alloc(struct inode *inode, const sector_t lblock,\nstruct buffer_head *bh_map, struct metapath *mp,\nconst unsigned int sheight,\nconst unsigned int height,\nconst unsigned int maxlen)\n{\nstruct gfs2_inode *ip = GFS2_I(inode);\nstruct gfs2_sbd *sdp = GFS2_SB(inode);\nstruct super_block *sb = sdp->sd_vfs;\nstruct buffer_head *dibh = mp->mp_bh[0];\nu64 bn, dblock = 0;\nunsigned n, i, blks, alloced = 0, iblks = 0, branch_start = 0;\nunsigned dblks = 0;\nunsigned ptrs_per_blk;\nconst unsigned end_of_metadata = height - 1;\nint ret;\nint eob = 0;\nenum alloc_state state;\n__be64 *ptr;\n__be64 zero_bn = 0;\nBUG_ON(sheight < 1);\nBUG_ON(dibh == NULL);\ngfs2_trans_add_bh(ip->i_gl, dibh, 1);\nif (height == sheight) {\nstruct buffer_head *bh;\nptr = metapointer(end_of_metadata, mp);\nbh = mp->mp_bh[end_of_metadata];\ndblks = gfs2_extent_length(bh->b_data, bh->b_size, ptr, maxlen,\n&eob);\nBUG_ON(dblks < 1);\nstate = ALLOC_DATA;\n} else {\nptrs_per_blk = height > 1 ? sdp->sd_inptrs : sdp->sd_diptrs;\ndblks = min(maxlen, ptrs_per_blk - mp->mp_list[end_of_metadata]);\nif (height == ip->i_height) {\niblks = height - sheight;\nstate = ALLOC_GROW_DEPTH;\n} else {\nstate = ALLOC_GROW_HEIGHT;\niblks = height - ip->i_height;\nbranch_start = metapath_branch_start(mp);\niblks += (height - branch_start);\n}\n}\nblks = dblks + iblks;\ni = sheight;\ndo {\nint error;\nn = blks - alloced;\nerror = gfs2_alloc_block(ip, &bn, &n);\nif (error)\nreturn error;\nalloced += n;\nif (state != ALLOC_DATA || gfs2_is_jdata(ip))\ngfs2_trans_add_unrevoke(sdp, bn, n);\nswitch (state) {\ncase ALLOC_GROW_HEIGHT:\nif (i == 1) {\nptr = (__be64 *)(dibh->b_data +\nsizeof(struct gfs2_dinode));\nzero_bn = *ptr;\n}\nfor (; i - 1 < height - ip->i_height && n > 0; i++, n--)\ngfs2_indirect_init(mp, ip->i_gl, i, 0, bn++);\nif (i - 1 == height - ip->i_height) {\ni--;\ngfs2_buffer_copy_tail(mp->mp_bh[i],\nsizeof(struct gfs2_meta_header),\ndibh, sizeof(struct gfs2_dinode));\ngfs2_buffer_clear_tail(dibh,\nsizeof(struct gfs2_dinode) +\nsizeof(__be64));\nptr = (__be64 *)(mp->mp_bh[i]->b_data +\nsizeof(struct gfs2_meta_header));\n*ptr = zero_bn;\nstate = ALLOC_GROW_DEPTH;\nfor(i = branch_start; i < height; i++) {\nif (mp->mp_bh[i] == NULL)\nbreak;\nbrelse(mp->mp_bh[i]);\nmp->mp_bh[i] = NULL;\n}\ni = branch_start;\n}\nif (n == 0)\nbreak;\ncase ALLOC_GROW_DEPTH:\nif (i > 1 && i < height)\ngfs2_trans_add_bh(ip->i_gl, mp->mp_bh[i-1], 1);\nfor (; i < height && n > 0; i++, n--)\ngfs2_indirect_init(mp, ip->i_gl, i,\nmp->mp_list[i-1], bn++);\nif (i == height)\nstate = ALLOC_DATA;\nif (n == 0)\nbreak;\ncase ALLOC_DATA:\nBUG_ON(n > dblks);\nBUG_ON(mp->mp_bh[end_of_metadata] == NULL);\ngfs2_trans_add_bh(ip->i_gl, mp->mp_bh[end_of_metadata], 1);\ndblks = n;\nptr = metapointer(end_of_metadata, mp);\ndblock = bn;\nwhile (n-- > 0)\n*ptr++ = cpu_to_be64(bn++);\nif (buffer_zeronew(bh_map)) {\nret = sb_issue_zeroout(sb, dblock, dblks,\nGFP_NOFS);\nif (ret) {\nfs_err(sdp,\n\"Failed to zero data buffers\\n\");\nclear_buffer_zeronew(bh_map);\n}\n}\nbreak;\n}\n} while ((state != ALLOC_DATA) || !dblock);\nip->i_height = height;\ngfs2_add_inode_blocks(&ip->i_inode, alloced);\ngfs2_dinode_out(ip, mp->mp_bh[0]->b_data);\nmap_bh(bh_map, inode->i_sb, dblock);\nbh_map->b_size = dblks << inode->i_blkbits;\nset_buffer_new(bh_map);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int gfs2_bmap_alloc(struct inode *inode, const sector_t lblock,\nstruct buffer_head *bh_map, struct metapath *mp,\nconst unsigned int sheight,\nconst unsigned int height,\nconst unsigned int maxlen)\n{\nstruct gfs2_inode *ip = GFS2_I(inode);\nstruct gfs2_sbd *sdp = GFS2_SB(inode);\nstruct buffer_head *dibh = mp->mp_bh[0];\nu64 bn, dblock = 0;\nunsigned n, i, blks, alloced = 0, iblks = 0, branch_start = 0;\nunsigned dblks = 0;\nunsigned ptrs_per_blk;\nconst unsigned end_of_metadata = height - 1;\nint eob = 0;\nenum alloc_state state;\n__be64 *ptr;\n__be64 zero_bn = 0;\nBUG_ON(sheight < 1);\nBUG_ON(dibh == NULL);\ngfs2_trans_add_bh(ip->i_gl, dibh, 1);\nif (height == sheight) {\nstruct buffer_head *bh;\nptr = metapointer(end_of_metadata, mp);\nbh = mp->mp_bh[end_of_metadata];\ndblks = gfs2_extent_length(bh->b_data, bh->b_size, ptr, maxlen,\n&eob);\nBUG_ON(dblks < 1);\nstate = ALLOC_DATA;\n} else {\nptrs_per_blk = height > 1 ? sdp->sd_inptrs : sdp->sd_diptrs;\ndblks = min(maxlen, ptrs_per_blk - mp->mp_list[end_of_metadata]);\nif (height == ip->i_height) {\niblks = height - sheight;\nstate = ALLOC_GROW_DEPTH;\n} else {\nstate = ALLOC_GROW_HEIGHT;\niblks = height - ip->i_height;\nbranch_start = metapath_branch_start(mp);\niblks += (height - branch_start);\n}\n}\nblks = dblks + iblks;\ni = sheight;\ndo {\nint error;\nn = blks - alloced;\nerror = gfs2_alloc_block(ip, &bn, &n);\nif (error)\nreturn error;\nalloced += n;\nif (state != ALLOC_DATA || gfs2_is_jdata(ip))\ngfs2_trans_add_unrevoke(sdp, bn, n);\nswitch (state) {\ncase ALLOC_GROW_HEIGHT:\nif (i == 1) {\nptr = (__be64 *)(dibh->b_data +\nsizeof(struct gfs2_dinode));\nzero_bn = *ptr;\n}\nfor (; i - 1 < height - ip->i_height && n > 0; i++, n--)\ngfs2_indirect_init(mp, ip->i_gl, i, 0, bn++);\nif (i - 1 == height - ip->i_height) {\ni--;\ngfs2_buffer_copy_tail(mp->mp_bh[i],\nsizeof(struct gfs2_meta_header),\ndibh, sizeof(struct gfs2_dinode));\ngfs2_buffer_clear_tail(dibh,\nsizeof(struct gfs2_dinode) +\nsizeof(__be64));\nptr = (__be64 *)(mp->mp_bh[i]->b_data +\nsizeof(struct gfs2_meta_header));\n*ptr = zero_bn;\nstate = ALLOC_GROW_DEPTH;\nfor(i = branch_start; i < height; i++) {\nif (mp->mp_bh[i] == NULL)\nbreak;\nbrelse(mp->mp_bh[i]);\nmp->mp_bh[i] = NULL;\n}\ni = branch_start;\n}\nif (n == 0)\nbreak;\ncase ALLOC_GROW_DEPTH:\nif (i > 1 && i < height)\ngfs2_trans_add_bh(ip->i_gl, mp->mp_bh[i-1], 1);\nfor (; i < height && n > 0; i++, n--)\ngfs2_indirect_init(mp, ip->i_gl, i,\nmp->mp_list[i-1], bn++);\nif (i == height)\nstate = ALLOC_DATA;\nif (n == 0)\nbreak;\ncase ALLOC_DATA:\nBUG_ON(n > dblks);\nBUG_ON(mp->mp_bh[end_of_metadata] == NULL);\ngfs2_trans_add_bh(ip->i_gl, mp->mp_bh[end_of_metadata], 1);\ndblks = n;\nptr = metapointer(end_of_metadata, mp);\ndblock = bn;\nwhile (n-- > 0)\n*ptr++ = cpu_to_be64(bn++);\nbreak;\n}\n} while ((state != ALLOC_DATA) || !dblock);\nip->i_height = height;\ngfs2_add_inode_blocks(&ip->i_inode, alloced);\ngfs2_dinode_out(ip, mp->mp_bh[0]->b_data);\nmap_bh(bh_map, inode->i_sb, dblock);\nbh_map->b_size = dblks << inode->i_blkbits;\nset_buffer_new(bh_map);\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Reliance on the page cache for fallocate implementation, leading to potential denial of service due to preallocating blocks in memory-constrained situations.",
        "trigger_condition": "Insufficient memory availability during block preallocation, causing a denial of service due to reliance on the page cache.",
        "specific_code_behavior_causing_vulnerability": "The code does not limit the size of the chunk being allocated, potentially consuming excessive memory and leading to a denial of service in memory-constrained scenarios."
      },
      "solution": "To mitigate the vulnerability, it is necessary to introduce a limit on the size of the chunk being allocated to prevent excessive memory consumption. This ensures that the code allocates chunks within a safe limit, reducing the risk of running out of memory and causing a denial of service. Additionally, adjusting the calculation of the maximum reservation size to consider the newly introduced limit further enhances system security and stability.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2011-4098 in the code snippet. The vulnerability arises from the fallocate implementation in the GFS2 filesystem relying on the page cache, which can lead to a denial of service by preallocating blocks in certain situations involving insufficient memory.\n\nThe modification introduces a new variable `max_chunk_size` that limits the size of the chunk being allocated to prevent excessive memory consumption. By ensuring that the chunk size does not exceed a certain limit (`max_chunk_size`), the code mitigates the risk of running out of memory and causing a denial of service.\n\nAdditionally, the modification adjusts the calculation of the maximum reservation size to consider the newly introduced `max_chunk_size`. This ensures that the code allocates chunks within a safe limit, reducing the likelihood of memory-related issues and enhancing the overall security and stability of the system.",
      "GPT_purpose": "Perform file preallocation in the GFS2 filesystem.",
      "GPT_function": "\n1. Perform file preallocation using the fallocate system call in the GFS2 filesystem.\n2. Calculate the necessary data and indirect blocks for preallocation.\n3. Handle error conditions and release resources appropriately.",
      "CVE_id": "CVE-2011-4098",
      "code_before_change": "static long gfs2_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t   loff_t len)\n{\n\tstruct inode *inode = file->f_path.dentry->d_inode;\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tunsigned int data_blocks = 0, ind_blocks = 0, rblocks;\n\tloff_t bytes, max_bytes;\n\tstruct gfs2_alloc *al;\n\tint error;\n\tloff_t bsize_mask = ~((loff_t)sdp->sd_sb.sb_bsize - 1);\n\tloff_t next = (offset + len - 1) >> sdp->sd_sb.sb_bsize_shift;\n\tnext = (next + 1) << sdp->sd_sb.sb_bsize_shift;\n\n\t/* We only support the FALLOC_FL_KEEP_SIZE mode */\n\tif (mode & ~FALLOC_FL_KEEP_SIZE)\n\t\treturn -EOPNOTSUPP;\n\n\toffset &= bsize_mask;\n\n\tlen = next - offset;\n\tbytes = sdp->sd_max_rg_data * sdp->sd_sb.sb_bsize / 2;\n\tif (!bytes)\n\t\tbytes = UINT_MAX;\n\tbytes &= bsize_mask;\n\tif (bytes == 0)\n\t\tbytes = sdp->sd_sb.sb_bsize;\n\n\tgfs2_holder_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &ip->i_gh);\n\terror = gfs2_glock_nq(&ip->i_gh);\n\tif (unlikely(error))\n\t\tgoto out_uninit;\n\n\tif (!gfs2_write_alloc_required(ip, offset, len))\n\t\tgoto out_unlock;\n\n\twhile (len > 0) {\n\t\tif (len < bytes)\n\t\t\tbytes = len;\n\t\tal = gfs2_alloc_get(ip);\n\t\tif (!al) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terror = gfs2_quota_lock_check(ip);\n\t\tif (error)\n\t\t\tgoto out_alloc_put;\n\nretry:\n\t\tgfs2_write_calc_reserv(ip, bytes, &data_blocks, &ind_blocks);\n\n\t\tal->al_requested = data_blocks + ind_blocks;\n\t\terror = gfs2_inplace_reserve(ip);\n\t\tif (error) {\n\t\t\tif (error == -ENOSPC && bytes > sdp->sd_sb.sb_bsize) {\n\t\t\t\tbytes >>= 1;\n\t\t\t\tbytes &= bsize_mask;\n\t\t\t\tif (bytes == 0)\n\t\t\t\t\tbytes = sdp->sd_sb.sb_bsize;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tgoto out_qunlock;\n\t\t}\n\t\tmax_bytes = bytes;\n\t\tcalc_max_reserv(ip, len, &max_bytes, &data_blocks, &ind_blocks);\n\t\tal->al_requested = data_blocks + ind_blocks;\n\n\t\trblocks = RES_DINODE + ind_blocks + RES_STATFS + RES_QUOTA +\n\t\t\t  RES_RG_HDR + gfs2_rg_blocks(ip);\n\t\tif (gfs2_is_jdata(ip))\n\t\t\trblocks += data_blocks ? data_blocks : 1;\n\n\t\terror = gfs2_trans_begin(sdp, rblocks,\n\t\t\t\t\t PAGE_CACHE_SIZE/sdp->sd_sb.sb_bsize);\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\terror = fallocate_chunk(inode, offset, max_bytes, mode);\n\t\tgfs2_trans_end(sdp);\n\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\tlen -= max_bytes;\n\t\toffset += max_bytes;\n\t\tgfs2_inplace_release(ip);\n\t\tgfs2_quota_unlock(ip);\n\t\tgfs2_alloc_put(ip);\n\t}\n\tgoto out_unlock;\n\nout_trans_fail:\n\tgfs2_inplace_release(ip);\nout_qunlock:\n\tgfs2_quota_unlock(ip);\nout_alloc_put:\n\tgfs2_alloc_put(ip);\nout_unlock:\n\tgfs2_glock_dq(&ip->i_gh);\nout_uninit:\n\tgfs2_holder_uninit(&ip->i_gh);\n\treturn error;\n}",
      "code_after_change": "static long gfs2_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t   loff_t len)\n{\n\tstruct inode *inode = file->f_path.dentry->d_inode;\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tunsigned int data_blocks = 0, ind_blocks = 0, rblocks;\n\tloff_t bytes, max_bytes;\n\tstruct gfs2_alloc *al;\n\tint error;\n\tloff_t bsize_mask = ~((loff_t)sdp->sd_sb.sb_bsize - 1);\n\tloff_t next = (offset + len - 1) >> sdp->sd_sb.sb_bsize_shift;\n\tloff_t max_chunk_size = UINT_MAX & bsize_mask;\n\tnext = (next + 1) << sdp->sd_sb.sb_bsize_shift;\n\n\t/* We only support the FALLOC_FL_KEEP_SIZE mode */\n\tif (mode & ~FALLOC_FL_KEEP_SIZE)\n\t\treturn -EOPNOTSUPP;\n\n\toffset &= bsize_mask;\n\n\tlen = next - offset;\n\tbytes = sdp->sd_max_rg_data * sdp->sd_sb.sb_bsize / 2;\n\tif (!bytes)\n\t\tbytes = UINT_MAX;\n\tbytes &= bsize_mask;\n\tif (bytes == 0)\n\t\tbytes = sdp->sd_sb.sb_bsize;\n\n\tgfs2_holder_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &ip->i_gh);\n\terror = gfs2_glock_nq(&ip->i_gh);\n\tif (unlikely(error))\n\t\tgoto out_uninit;\n\n\tif (!gfs2_write_alloc_required(ip, offset, len))\n\t\tgoto out_unlock;\n\n\twhile (len > 0) {\n\t\tif (len < bytes)\n\t\t\tbytes = len;\n\t\tal = gfs2_alloc_get(ip);\n\t\tif (!al) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terror = gfs2_quota_lock_check(ip);\n\t\tif (error)\n\t\t\tgoto out_alloc_put;\n\nretry:\n\t\tgfs2_write_calc_reserv(ip, bytes, &data_blocks, &ind_blocks);\n\n\t\tal->al_requested = data_blocks + ind_blocks;\n\t\terror = gfs2_inplace_reserve(ip);\n\t\tif (error) {\n\t\t\tif (error == -ENOSPC && bytes > sdp->sd_sb.sb_bsize) {\n\t\t\t\tbytes >>= 1;\n\t\t\t\tbytes &= bsize_mask;\n\t\t\t\tif (bytes == 0)\n\t\t\t\t\tbytes = sdp->sd_sb.sb_bsize;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tgoto out_qunlock;\n\t\t}\n\t\tmax_bytes = bytes;\n\t\tcalc_max_reserv(ip, (len > max_chunk_size)? max_chunk_size: len,\n\t\t\t\t&max_bytes, &data_blocks, &ind_blocks);\n\t\tal->al_requested = data_blocks + ind_blocks;\n\n\t\trblocks = RES_DINODE + ind_blocks + RES_STATFS + RES_QUOTA +\n\t\t\t  RES_RG_HDR + gfs2_rg_blocks(ip);\n\t\tif (gfs2_is_jdata(ip))\n\t\t\trblocks += data_blocks ? data_blocks : 1;\n\n\t\terror = gfs2_trans_begin(sdp, rblocks,\n\t\t\t\t\t PAGE_CACHE_SIZE/sdp->sd_sb.sb_bsize);\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\terror = fallocate_chunk(inode, offset, max_bytes, mode);\n\t\tgfs2_trans_end(sdp);\n\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\tlen -= max_bytes;\n\t\toffset += max_bytes;\n\t\tgfs2_inplace_release(ip);\n\t\tgfs2_quota_unlock(ip);\n\t\tgfs2_alloc_put(ip);\n\t}\n\tgoto out_unlock;\n\nout_trans_fail:\n\tgfs2_inplace_release(ip);\nout_qunlock:\n\tgfs2_quota_unlock(ip);\nout_alloc_put:\n\tgfs2_alloc_put(ip);\nout_unlock:\n\tgfs2_glock_dq(&ip->i_gh);\nout_uninit:\n\tgfs2_holder_uninit(&ip->i_gh);\n\treturn error;\n}",
      "modified_lines": {
        "added": [
          "\tloff_t max_chunk_size = UINT_MAX & bsize_mask;",
          "\t\tcalc_max_reserv(ip, (len > max_chunk_size)? max_chunk_size: len,",
          "\t\t\t\t&max_bytes, &data_blocks, &ind_blocks);"
        ],
        "deleted": [
          "\t\tcalc_max_reserv(ip, len, &max_bytes, &data_blocks, &ind_blocks);"
        ]
      },
      "preconditions_for_vulnerability": "Reliance on the page cache for fallocate implementation, leading to potential denial of service due to preallocating blocks in memory-constrained situations.",
      "trigger_condition": "Insufficient memory availability during block preallocation, causing a denial of service due to reliance on the page cache.",
      "specific_code_behavior_causing_vulnerability": "The code does not limit the size of the chunk being allocated, potentially consuming excessive memory and leading to a denial of service in memory-constrained scenarios.",
      "id": 7,
      "code_after_change_normalized": "static long FUN1(struct VAR1 *VAR1, int VAR2, loff_t VAR3,\nloff_t VAR4)\n{\nstruct VAR5 *VAR5 = VAR1->VAR6.VAR7->VAR8;\nstruct gfs2_sbd *VAR9 = FUN2(VAR5);\nstruct gfs2_inode *VAR10 = FUN3(VAR5);\nunsigned int VAR11 = 0, VAR12 = 0, VAR13;\nloff_t VAR14, VAR15;\nstruct gfs2_alloc *VAR16;\nint VAR17;\nloff_t VAR18 = ~((VAR19)VAR9->VAR20.VAR21 - 1);\nloff_t VAR22 = (VAR3 + VAR4 - 1) >> VAR9->VAR20.VAR23;\nloff_t VAR24 = VAR25 & VAR18;\nVAR22 = (VAR22 + 1) << VAR9->VAR20.VAR23;\nif (VAR2 & ~VAR26)\nreturn -VAR27;\nVAR3 &= VAR18;\nVAR4 = VAR22 - VAR3;\nVAR14 = VAR9->VAR28 * VAR9->VAR20.VAR21 / 2;\nif (!VAR14)\nVAR14 = VAR25;\nVAR14 &= VAR18;\nif (VAR14 == 0)\nVAR14 = VAR9->VAR20.VAR21;\nFUN4(VAR10->VAR29, VAR30, 0, &VAR10->VAR31);\nVAR17 = FUN5(&VAR10->VAR31);\nif (FUN6(VAR17))\ngoto VAR32;\nif (!FUN7(VAR10, VAR3, VAR4))\ngoto VAR33;\nwhile (VAR4 > 0) {\nif (VAR4 < VAR14)\nVAR14 = VAR4;\nVAR16 = FUN8(VAR10);\nif (!VAR16) {\nVAR17 = -VAR34;\ngoto VAR33;\n}\nVAR17 = FUN9(VAR10);\nif (VAR17)\ngoto VAR35;\nVAR36:\nFUN10(VAR10, VAR14, &VAR11, &VAR12);\nVAR16->VAR37 = VAR11 + VAR12;\nVAR17 = FUN11(VAR10);\nif (VAR17) {\nif (VAR17 == -VAR38 && VAR14 > VAR9->VAR20.VAR21) {\nVAR14 >>= 1;\nVAR14 &= VAR18;\nif (VAR14 == 0)\nVAR14 = VAR9->VAR20.VAR21;\ngoto VAR36;\n}\ngoto VAR39;\n}\nVAR15 = VAR14;\nFUN12(VAR10, (VAR4 > VAR24)? VAR24: VAR4,\n&VAR15, &VAR11, &VAR12);\nVAR16->VAR37 = VAR11 + VAR12;\nVAR13 = VAR40 + VAR12 + VAR41 + VAR42 +\nVAR43 + FUN13(VAR10);\nif (FUN14(VAR10))\nVAR13 += VAR11 ? VAR11 : 1;\nVAR17 = FUN15(VAR9, VAR13,\nVAR44/VAR9->VAR20.VAR21);\nif (VAR17)\ngoto VAR45;\nVAR17 = FUN16(VAR5, VAR3, VAR15, VAR2);\nFUN17(VAR9);\nif (VAR17)\ngoto VAR45;\nVAR4 -= VAR15;\nVAR3 += VAR15;\nFUN18(VAR10);\nFUN19(VAR10);\nFUN20(VAR10);\n}\ngoto VAR33;\nVAR45:\nFUN18(VAR10);\nVAR39:\nFUN19(VAR10);\nVAR35:\nFUN20(VAR10);\nVAR33:\nFUN21(&VAR10->VAR31);\nVAR32:\nFUN22(&VAR10->VAR31);\nreturn VAR17;\n}\n",
      "code_before_change_normalized": "static long FUN1(struct VAR1 *VAR1, int VAR2, loff_t VAR3,\nloff_t VAR4)\n{\nstruct VAR5 *VAR5 = VAR1->VAR6.VAR7->VAR8;\nstruct gfs2_sbd *VAR9 = FUN2(VAR5);\nstruct gfs2_inode *VAR10 = FUN3(VAR5);\nunsigned int VAR11 = 0, VAR12 = 0, VAR13;\nloff_t VAR14, VAR15;\nstruct gfs2_alloc *VAR16;\nint VAR17;\nloff_t VAR18 = ~((VAR19)VAR9->VAR20.VAR21 - 1);\nloff_t VAR22 = (VAR3 + VAR4 - 1) >> VAR9->VAR20.VAR23;\nVAR22 = (VAR22 + 1) << VAR9->VAR20.VAR23;\nif (VAR2 & ~VAR24)\nreturn -VAR25;\nVAR3 &= VAR18;\nVAR4 = VAR22 - VAR3;\nVAR14 = VAR9->VAR26 * VAR9->VAR20.VAR21 / 2;\nif (!VAR14)\nVAR14 = VAR27;\nVAR14 &= VAR18;\nif (VAR14 == 0)\nVAR14 = VAR9->VAR20.VAR21;\nFUN4(VAR10->VAR28, VAR29, 0, &VAR10->VAR30);\nVAR17 = FUN5(&VAR10->VAR30);\nif (FUN6(VAR17))\ngoto VAR31;\nif (!FUN7(VAR10, VAR3, VAR4))\ngoto VAR32;\nwhile (VAR4 > 0) {\nif (VAR4 < VAR14)\nVAR14 = VAR4;\nVAR16 = FUN8(VAR10);\nif (!VAR16) {\nVAR17 = -VAR33;\ngoto VAR32;\n}\nVAR17 = FUN9(VAR10);\nif (VAR17)\ngoto VAR34;\nVAR35:\nFUN10(VAR10, VAR14, &VAR11, &VAR12);\nVAR16->VAR36 = VAR11 + VAR12;\nVAR17 = FUN11(VAR10);\nif (VAR17) {\nif (VAR17 == -VAR37 && VAR14 > VAR9->VAR20.VAR21) {\nVAR14 >>= 1;\nVAR14 &= VAR18;\nif (VAR14 == 0)\nVAR14 = VAR9->VAR20.VAR21;\ngoto VAR35;\n}\ngoto VAR38;\n}\nVAR15 = VAR14;\nFUN12(VAR10, VAR4, &VAR15, &VAR11, &VAR12);\nVAR16->VAR36 = VAR11 + VAR12;\nVAR13 = VAR39 + VAR12 + VAR40 + VAR41 +\nVAR42 + FUN13(VAR10);\nif (FUN14(VAR10))\nVAR13 += VAR11 ? VAR11 : 1;\nVAR17 = FUN15(VAR9, VAR13,\nVAR43/VAR9->VAR20.VAR21);\nif (VAR17)\ngoto VAR44;\nVAR17 = FUN16(VAR5, VAR3, VAR15, VAR2);\nFUN17(VAR9);\nif (VAR17)\ngoto VAR44;\nVAR4 -= VAR15;\nVAR3 += VAR15;\nFUN18(VAR10);\nFUN19(VAR10);\nFUN20(VAR10);\n}\ngoto VAR32;\nVAR44:\nFUN18(VAR10);\nVAR38:\nFUN19(VAR10);\nVAR34:\nFUN20(VAR10);\nVAR32:\nFUN21(&VAR10->VAR30);\nVAR31:\nFUN22(&VAR10->VAR30);\nreturn VAR17;\n}\n",
      "code_after_change_raw": "static long gfs2_fallocate(struct file *file, int mode, loff_t offset,\nloff_t len)\n{\nstruct inode *inode = file->f_path.dentry->d_inode;\nstruct gfs2_sbd *sdp = GFS2_SB(inode);\nstruct gfs2_inode *ip = GFS2_I(inode);\nunsigned int data_blocks = 0, ind_blocks = 0, rblocks;\nloff_t bytes, max_bytes;\nstruct gfs2_alloc *al;\nint error;\nloff_t bsize_mask = ~((loff_t)sdp->sd_sb.sb_bsize - 1);\nloff_t next = (offset + len - 1) >> sdp->sd_sb.sb_bsize_shift;\nloff_t max_chunk_size = UINT_MAX & bsize_mask;\nnext = (next + 1) << sdp->sd_sb.sb_bsize_shift;\nif (mode & ~FALLOC_FL_KEEP_SIZE)\nreturn -EOPNOTSUPP;\noffset &= bsize_mask;\nlen = next - offset;\nbytes = sdp->sd_max_rg_data * sdp->sd_sb.sb_bsize / 2;\nif (!bytes)\nbytes = UINT_MAX;\nbytes &= bsize_mask;\nif (bytes == 0)\nbytes = sdp->sd_sb.sb_bsize;\ngfs2_holder_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &ip->i_gh);\nerror = gfs2_glock_nq(&ip->i_gh);\nif (unlikely(error))\ngoto out_uninit;\nif (!gfs2_write_alloc_required(ip, offset, len))\ngoto out_unlock;\nwhile (len > 0) {\nif (len < bytes)\nbytes = len;\nal = gfs2_alloc_get(ip);\nif (!al) {\nerror = -ENOMEM;\ngoto out_unlock;\n}\nerror = gfs2_quota_lock_check(ip);\nif (error)\ngoto out_alloc_put;\nretry:\ngfs2_write_calc_reserv(ip, bytes, &data_blocks, &ind_blocks);\nal->al_requested = data_blocks + ind_blocks;\nerror = gfs2_inplace_reserve(ip);\nif (error) {\nif (error == -ENOSPC && bytes > sdp->sd_sb.sb_bsize) {\nbytes >>= 1;\nbytes &= bsize_mask;\nif (bytes == 0)\nbytes = sdp->sd_sb.sb_bsize;\ngoto retry;\n}\ngoto out_qunlock;\n}\nmax_bytes = bytes;\ncalc_max_reserv(ip, (len > max_chunk_size)? max_chunk_size: len,\n&max_bytes, &data_blocks, &ind_blocks);\nal->al_requested = data_blocks + ind_blocks;\nrblocks = RES_DINODE + ind_blocks + RES_STATFS + RES_QUOTA +\nRES_RG_HDR + gfs2_rg_blocks(ip);\nif (gfs2_is_jdata(ip))\nrblocks += data_blocks ? data_blocks : 1;\nerror = gfs2_trans_begin(sdp, rblocks,\nPAGE_CACHE_SIZE/sdp->sd_sb.sb_bsize);\nif (error)\ngoto out_trans_fail;\nerror = fallocate_chunk(inode, offset, max_bytes, mode);\ngfs2_trans_end(sdp);\nif (error)\ngoto out_trans_fail;\nlen -= max_bytes;\noffset += max_bytes;\ngfs2_inplace_release(ip);\ngfs2_quota_unlock(ip);\ngfs2_alloc_put(ip);\n}\ngoto out_unlock;\nout_trans_fail:\ngfs2_inplace_release(ip);\nout_qunlock:\ngfs2_quota_unlock(ip);\nout_alloc_put:\ngfs2_alloc_put(ip);\nout_unlock:\ngfs2_glock_dq(&ip->i_gh);\nout_uninit:\ngfs2_holder_uninit(&ip->i_gh);\nreturn error;\n}\n",
      "code_before_change_raw": "static long gfs2_fallocate(struct file *file, int mode, loff_t offset,\nloff_t len)\n{\nstruct inode *inode = file->f_path.dentry->d_inode;\nstruct gfs2_sbd *sdp = GFS2_SB(inode);\nstruct gfs2_inode *ip = GFS2_I(inode);\nunsigned int data_blocks = 0, ind_blocks = 0, rblocks;\nloff_t bytes, max_bytes;\nstruct gfs2_alloc *al;\nint error;\nloff_t bsize_mask = ~((loff_t)sdp->sd_sb.sb_bsize - 1);\nloff_t next = (offset + len - 1) >> sdp->sd_sb.sb_bsize_shift;\nnext = (next + 1) << sdp->sd_sb.sb_bsize_shift;\nif (mode & ~FALLOC_FL_KEEP_SIZE)\nreturn -EOPNOTSUPP;\noffset &= bsize_mask;\nlen = next - offset;\nbytes = sdp->sd_max_rg_data * sdp->sd_sb.sb_bsize / 2;\nif (!bytes)\nbytes = UINT_MAX;\nbytes &= bsize_mask;\nif (bytes == 0)\nbytes = sdp->sd_sb.sb_bsize;\ngfs2_holder_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &ip->i_gh);\nerror = gfs2_glock_nq(&ip->i_gh);\nif (unlikely(error))\ngoto out_uninit;\nif (!gfs2_write_alloc_required(ip, offset, len))\ngoto out_unlock;\nwhile (len > 0) {\nif (len < bytes)\nbytes = len;\nal = gfs2_alloc_get(ip);\nif (!al) {\nerror = -ENOMEM;\ngoto out_unlock;\n}\nerror = gfs2_quota_lock_check(ip);\nif (error)\ngoto out_alloc_put;\nretry:\ngfs2_write_calc_reserv(ip, bytes, &data_blocks, &ind_blocks);\nal->al_requested = data_blocks + ind_blocks;\nerror = gfs2_inplace_reserve(ip);\nif (error) {\nif (error == -ENOSPC && bytes > sdp->sd_sb.sb_bsize) {\nbytes >>= 1;\nbytes &= bsize_mask;\nif (bytes == 0)\nbytes = sdp->sd_sb.sb_bsize;\ngoto retry;\n}\ngoto out_qunlock;\n}\nmax_bytes = bytes;\ncalc_max_reserv(ip, len, &max_bytes, &data_blocks, &ind_blocks);\nal->al_requested = data_blocks + ind_blocks;\nrblocks = RES_DINODE + ind_blocks + RES_STATFS + RES_QUOTA +\nRES_RG_HDR + gfs2_rg_blocks(ip);\nif (gfs2_is_jdata(ip))\nrblocks += data_blocks ? data_blocks : 1;\nerror = gfs2_trans_begin(sdp, rblocks,\nPAGE_CACHE_SIZE/sdp->sd_sb.sb_bsize);\nif (error)\ngoto out_trans_fail;\nerror = fallocate_chunk(inode, offset, max_bytes, mode);\ngfs2_trans_end(sdp);\nif (error)\ngoto out_trans_fail;\nlen -= max_bytes;\noffset += max_bytes;\ngfs2_inplace_release(ip);\ngfs2_quota_unlock(ip);\ngfs2_alloc_put(ip);\n}\ngoto out_unlock;\nout_trans_fail:\ngfs2_inplace_release(ip);\nout_qunlock:\ngfs2_quota_unlock(ip);\nout_alloc_put:\ngfs2_alloc_put(ip);\nout_unlock:\ngfs2_glock_dq(&ip->i_gh);\nout_uninit:\ngfs2_holder_uninit(&ip->i_gh);\nreturn error;\n}\n"
    }
  ],
  "CVE-2011-5327": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper comparison logic in checking the value of a variable against a constant, leading to an off-by-one error.",
        "trigger_condition": "When the variable value is allowed to be equal to a specific constant, it can result in memory corruption or unexpected behavior.",
        "specific_code_behavior_causing_vulnerability": "The code snippet compares a variable value with a constant using '>' instead of '>=' which allows the variable to reach the constant value, causing an off-by-one error and potential memory corruption."
      },
      "solution": "To mitigate the vulnerability, it is necessary to adjust the comparison logic to use '>=' instead of '>' when checking the variable value against the constant. This modification ensures that the variable is not allowed to be equal to the constant, preventing the off-by-one error and associated memory corruption. In this case, the solution involves updating the comparison condition to 'if (variable >= constant)' to address the vulnerability.",
      "GPT_analysis": "The modification in the code snippet is necessary to fix a vulnerability related to an off-by-one error in the tcm_loop_make_naa_tpg() function. The vulnerability occurs when checking the value of \"tpgt\" against the constant TL_TPGS_PER_HBA. \n\nIn the original code snippet, the comparison \"if (tpgt > TL_TPGS_PER_HBA)\" is used to check if the value of \"tpgt\" exceeds TL_TPGS_PER_HBA. However, this condition is incorrect because it does not account for the case where \"tpgt\" is equal to TL_TPGS_PER_HBA. This can lead to memory corruption or other unexpected behavior if the index \"tpgt\" is allowed to reach the value of TL_TPGS_PER_HBA.\n\nBy modifying the comparison to \"if (tpgt >= TL_TPGS_PER_HBA)\", the code ensures that \"tpgt\" is not allowed to be equal to TL_TPGS_PER_HBA, thus preventing the off-by-one error and potential memory corruption. This modification ensures that the code behaves correctly and avoids the vulnerability described in CVE-2011-5327.",
      "GPT_purpose": "This function is used to create an emulated TCM target port for a specified WWN within a TCM loop HBA.",
      "GPT_function": "\n1. Extracts the target portal group tag (tpgt) from the provided name.\n2. Checks if the extracted tpgt exceeds a predefined limit.\n3. Registers the tl_tpg as an emulated SAS TCM Target Endpoint and returns an error if registration fails.",
      "CVE_id": "CVE-2011-5327",
      "code_before_change": "struct se_portal_group *tcm_loop_make_naa_tpg(\n\tstruct se_wwn *wwn,\n\tstruct config_group *group,\n\tconst char *name)\n{\n\tstruct tcm_loop_hba *tl_hba = container_of(wwn,\n\t\t\tstruct tcm_loop_hba, tl_hba_wwn);\n\tstruct tcm_loop_tpg *tl_tpg;\n\tchar *tpgt_str, *end_ptr;\n\tint ret;\n\tunsigned short int tpgt;\n\n\ttpgt_str = strstr(name, \"tpgt_\");\n\tif (!tpgt_str) {\n\t\tprintk(KERN_ERR \"Unable to locate \\\"tpgt_#\\\" directory\"\n\t\t\t\t\" group\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttpgt_str += 5; /* Skip ahead of \"tpgt_\" */\n\ttpgt = (unsigned short int) simple_strtoul(tpgt_str, &end_ptr, 0);\n\n\tif (tpgt > TL_TPGS_PER_HBA) {\n\t\tprintk(KERN_ERR \"Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:\"\n\t\t\t\t\" %u\\n\", tpgt, TL_TPGS_PER_HBA);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttl_tpg = &tl_hba->tl_hba_tpgs[tpgt];\n\ttl_tpg->tl_hba = tl_hba;\n\ttl_tpg->tl_tpgt = tpgt;\n\t/*\n\t * Register the tl_tpg as a emulated SAS TCM Target Endpoint\n\t */\n\tret = core_tpg_register(&tcm_loop_fabric_configfs->tf_ops,\n\t\t\twwn, &tl_tpg->tl_se_tpg, tl_tpg,\n\t\t\tTRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tprintk(KERN_INFO \"TCM_Loop_ConfigFS: Allocated Emulated %s\"\n\t\t\" Target Port %s,t,0x%04x\\n\", tcm_loop_dump_proto_id(tl_hba),\n\t\tconfig_item_name(&wwn->wwn_group.cg_item), tpgt);\n\n\treturn &tl_tpg->tl_se_tpg;\n}",
      "code_after_change": "struct se_portal_group *tcm_loop_make_naa_tpg(\n\tstruct se_wwn *wwn,\n\tstruct config_group *group,\n\tconst char *name)\n{\n\tstruct tcm_loop_hba *tl_hba = container_of(wwn,\n\t\t\tstruct tcm_loop_hba, tl_hba_wwn);\n\tstruct tcm_loop_tpg *tl_tpg;\n\tchar *tpgt_str, *end_ptr;\n\tint ret;\n\tunsigned short int tpgt;\n\n\ttpgt_str = strstr(name, \"tpgt_\");\n\tif (!tpgt_str) {\n\t\tprintk(KERN_ERR \"Unable to locate \\\"tpgt_#\\\" directory\"\n\t\t\t\t\" group\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttpgt_str += 5; /* Skip ahead of \"tpgt_\" */\n\ttpgt = (unsigned short int) simple_strtoul(tpgt_str, &end_ptr, 0);\n\n\tif (tpgt >= TL_TPGS_PER_HBA) {\n\t\tprintk(KERN_ERR \"Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:\"\n\t\t\t\t\" %u\\n\", tpgt, TL_TPGS_PER_HBA);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttl_tpg = &tl_hba->tl_hba_tpgs[tpgt];\n\ttl_tpg->tl_hba = tl_hba;\n\ttl_tpg->tl_tpgt = tpgt;\n\t/*\n\t * Register the tl_tpg as a emulated SAS TCM Target Endpoint\n\t */\n\tret = core_tpg_register(&tcm_loop_fabric_configfs->tf_ops,\n\t\t\twwn, &tl_tpg->tl_se_tpg, tl_tpg,\n\t\t\tTRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tprintk(KERN_INFO \"TCM_Loop_ConfigFS: Allocated Emulated %s\"\n\t\t\" Target Port %s,t,0x%04x\\n\", tcm_loop_dump_proto_id(tl_hba),\n\t\tconfig_item_name(&wwn->wwn_group.cg_item), tpgt);\n\n\treturn &tl_tpg->tl_se_tpg;\n}",
      "modified_lines": {
        "added": [
          "\tif (tpgt >= TL_TPGS_PER_HBA) {"
        ],
        "deleted": [
          "\tif (tpgt > TL_TPGS_PER_HBA) {"
        ]
      },
      "preconditions_for_vulnerability": "Improper comparison logic in checking the value of a variable against a constant, leading to an off-by-one error.",
      "trigger_condition": "When the variable value is allowed to be equal to a specific constant, it can result in memory corruption or unexpected behavior.",
      "specific_code_behavior_causing_vulnerability": "The code snippet compares a variable value with a constant using '>' instead of '>=' which allows the variable to reach the constant value, causing an off-by-one error and potential memory corruption.",
      "id": 8,
      "code_after_change_normalized": "struct se_portal_group *FUN1(\nstruct se_wwn *VAR1,\nstruct config_group *VAR2,\nconst char *VAR3)\n{\nstruct tcm_loop_hba *VAR4 = FUN2(VAR1,\nstruct VAR5, VAR6);\nstruct tcm_loop_tpg *VAR7;\nchar *VAR8, *VAR9;\nint VAR10;\nunsigned short int VAR11;\nVAR8 = FUN3(VAR3, \"STR\");\nif (!VAR8) {\nFUN4(VAR12 \"STR\"\n\"STR\");\nreturn FUN5(-VAR13);\n}\nVAR8 += 5; \nVAR11 = (unsigned short int) FUN6(VAR8, &VAR9, 0);\nif (VAR11 >= VAR14) {\nFUN4(VAR12 \"STR\"\n\"STR\", VAR11, VAR14);\nreturn FUN5(-VAR13);\n}\nVAR7 = &VAR4->VAR15[VAR11];\nVAR7->VAR4 = VAR4;\nVAR7->VAR16 = VAR11;\nVAR10 = FUN7(&VAR17->VAR18,\nVAR1, &VAR7->VAR19, VAR7,\nVAR20);\nif (VAR10 < 0)\nreturn FUN5(-VAR21);\nFUN4(VAR22 \"STR\"\n\"STR\", FUN8(VAR4),\nFUN9(&VAR1->VAR23.VAR24), VAR11);\nreturn &VAR7->VAR19;\n}\n",
      "code_before_change_normalized": "struct se_portal_group *FUN1(\nstruct se_wwn *VAR1,\nstruct config_group *VAR2,\nconst char *VAR3)\n{\nstruct tcm_loop_hba *VAR4 = FUN2(VAR1,\nstruct VAR5, VAR6);\nstruct tcm_loop_tpg *VAR7;\nchar *VAR8, *VAR9;\nint VAR10;\nunsigned short int VAR11;\nVAR8 = FUN3(VAR3, \"STR\");\nif (!VAR8) {\nFUN4(VAR12 \"STR\"\n\"STR\");\nreturn FUN5(-VAR13);\n}\nVAR8 += 5; \nVAR11 = (unsigned short int) FUN6(VAR8, &VAR9, 0);\nif (VAR11 > VAR14) {\nFUN4(VAR12 \"STR\"\n\"STR\", VAR11, VAR14);\nreturn FUN5(-VAR13);\n}\nVAR7 = &VAR4->VAR15[VAR11];\nVAR7->VAR4 = VAR4;\nVAR7->VAR16 = VAR11;\nVAR10 = FUN7(&VAR17->VAR18,\nVAR1, &VAR7->VAR19, VAR7,\nVAR20);\nif (VAR10 < 0)\nreturn FUN5(-VAR21);\nFUN4(VAR22 \"STR\"\n\"STR\", FUN8(VAR4),\nFUN9(&VAR1->VAR23.VAR24), VAR11);\nreturn &VAR7->VAR19;\n}\n",
      "code_after_change_raw": "struct se_portal_group *tcm_loop_make_naa_tpg(\nstruct se_wwn *wwn,\nstruct config_group *group,\nconst char *name)\n{\nstruct tcm_loop_hba *tl_hba = container_of(wwn,\nstruct tcm_loop_hba, tl_hba_wwn);\nstruct tcm_loop_tpg *tl_tpg;\nchar *tpgt_str, *end_ptr;\nint ret;\nunsigned short int tpgt;\ntpgt_str = strstr(name, \"tpgt_\");\nif (!tpgt_str) {\nprintk(KERN_ERR \"Unable to locate \\\"tpgt_#\\\" directory\"\n\" group\\n\");\nreturn ERR_PTR(-EINVAL);\n}\ntpgt_str += 5; \ntpgt = (unsigned short int) simple_strtoul(tpgt_str, &end_ptr, 0);\nif (tpgt >= TL_TPGS_PER_HBA) {\nprintk(KERN_ERR \"Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:\"\n\" %u\\n\", tpgt, TL_TPGS_PER_HBA);\nreturn ERR_PTR(-EINVAL);\n}\ntl_tpg = &tl_hba->tl_hba_tpgs[tpgt];\ntl_tpg->tl_hba = tl_hba;\ntl_tpg->tl_tpgt = tpgt;\nret = core_tpg_register(&tcm_loop_fabric_configfs->tf_ops,\nwwn, &tl_tpg->tl_se_tpg, tl_tpg,\nTRANSPORT_TPG_TYPE_NORMAL);\nif (ret < 0)\nreturn ERR_PTR(-ENOMEM);\nprintk(KERN_INFO \"TCM_Loop_ConfigFS: Allocated Emulated %s\"\n\" Target Port %s,t,0x%04x\\n\", tcm_loop_dump_proto_id(tl_hba),\nconfig_item_name(&wwn->wwn_group.cg_item), tpgt);\nreturn &tl_tpg->tl_se_tpg;\n}\n",
      "code_before_change_raw": "struct se_portal_group *tcm_loop_make_naa_tpg(\nstruct se_wwn *wwn,\nstruct config_group *group,\nconst char *name)\n{\nstruct tcm_loop_hba *tl_hba = container_of(wwn,\nstruct tcm_loop_hba, tl_hba_wwn);\nstruct tcm_loop_tpg *tl_tpg;\nchar *tpgt_str, *end_ptr;\nint ret;\nunsigned short int tpgt;\ntpgt_str = strstr(name, \"tpgt_\");\nif (!tpgt_str) {\nprintk(KERN_ERR \"Unable to locate \\\"tpgt_#\\\" directory\"\n\" group\\n\");\nreturn ERR_PTR(-EINVAL);\n}\ntpgt_str += 5; \ntpgt = (unsigned short int) simple_strtoul(tpgt_str, &end_ptr, 0);\nif (tpgt > TL_TPGS_PER_HBA) {\nprintk(KERN_ERR \"Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:\"\n\" %u\\n\", tpgt, TL_TPGS_PER_HBA);\nreturn ERR_PTR(-EINVAL);\n}\ntl_tpg = &tl_hba->tl_hba_tpgs[tpgt];\ntl_tpg->tl_hba = tl_hba;\ntl_tpg->tl_tpgt = tpgt;\nret = core_tpg_register(&tcm_loop_fabric_configfs->tf_ops,\nwwn, &tl_tpg->tl_se_tpg, tl_tpg,\nTRANSPORT_TPG_TYPE_NORMAL);\nif (ret < 0)\nreturn ERR_PTR(-ENOMEM);\nprintk(KERN_INFO \"TCM_Loop_ConfigFS: Allocated Emulated %s\"\n\" Target Port %s,t,0x%04x\\n\", tcm_loop_dump_proto_id(tl_hba),\nconfig_item_name(&wwn->wwn_group.cg_item), tpgt);\nreturn &tl_tpg->tl_se_tpg;\n}\n"
    }
  ],
  "CVE-2012-2119": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper management of the 'offset' variable during data copying operations within the 'zerocopy_sg_from_iovec' function.",
        "trigger_condition": "Running the code in certain configurations where a long descriptor with a long vector length is encountered, leading to a buffer overflow vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code fails to properly update the 'offset' variable when copying data from the 'from' iovec to the 'skb' buffer, potentially allowing for a buffer overflow if a long descriptor with a long vector length is encountered."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the 'offset' variable is correctly managed and updated during data copying operations within the 'zerocopy_sg_from_iovec' function. Specifically, the 'offset' variable should be incremented appropriately after each data copy operation to prevent buffer overflow issues. The solution involves adding the line 'offset += size;' within the 'else' block of the 'if (copy > size)' condition to ensure proper handling of the 'offset' variable.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2012-2119, which is a buffer overflow issue in the macvtap device driver in the Linux kernel. The vulnerability occurs when running in certain configurations and allows privileged KVM guest users to cause a denial of service (crash) via a long descriptor with a long vector length.\n\nThe specific change made in the code snippet is to ensure that the 'offset' variable is properly updated within the 'while' loop in the 'zerocopy_sg_from_iovec' function. By adding the line 'offset += size;' within the 'else' block of the 'if (copy > size)' condition, the code ensures that the 'offset' is correctly incremented when copying data from the 'from' iovec to the 'skb' buffer. This prevents potential buffer overflow issues that could be exploited to trigger the vulnerability.\n\nIn summary, the modification ensures that the 'offset' variable is managed correctly during data copying operations, thereby addressing the buffer overflow vulnerability and enhancing the security of the code.",
      "GPT_purpose": "Copy data from an iovec array to a socket buffer with potential buffer overflow vulnerability.",
      "GPT_function": "\n1. Copy data from an iovec to an sk_buff with zero-copy optimization.\n2. Handle cases where the data to be copied exceeds the skb head length.\n3. Manage page allocation and data copying for cases where the data length is longer than the skb head length.",
      "CVE_id": "CVE-2012-2119",
      "code_before_change": "static int zerocopy_sg_from_iovec(struct sk_buff *skb, const struct iovec *from,\n\t\t\t\t  int offset, size_t count)\n{\n\tint len = iov_length(from, count) - offset;\n\tint copy = skb_headlen(skb);\n\tint size, offset1 = 0;\n\tint i = 0;\n\n\t/* Skip over from offset */\n\twhile (count && (offset >= from->iov_len)) {\n\t\toffset -= from->iov_len;\n\t\t++from;\n\t\t--count;\n\t}\n\n\t/* copy up to skb headlen */\n\twhile (count && (copy > 0)) {\n\t\tsize = min_t(unsigned int, copy, from->iov_len - offset);\n\t\tif (copy_from_user(skb->data + offset1, from->iov_base + offset,\n\t\t\t\t   size))\n\t\t\treturn -EFAULT;\n\t\tif (copy > size) {\n\t\t\t++from;\n\t\t\t--count;\n\t\t}\n\t\tcopy -= size;\n\t\toffset1 += size;\n\t\toffset = 0;\n\t}\n\n\tif (len == offset1)\n\t\treturn 0;\n\n\twhile (count--) {\n\t\tstruct page *page[MAX_SKB_FRAGS];\n\t\tint num_pages;\n\t\tunsigned long base;\n\n\t\tlen = from->iov_len - offset1;\n\t\tif (!len) {\n\t\t\toffset1 = 0;\n\t\t\t++from;\n\t\t\tcontinue;\n\t\t}\n\t\tbase = (unsigned long)from->iov_base + offset1;\n\t\tsize = ((base & ~PAGE_MASK) + len + ~PAGE_MASK) >> PAGE_SHIFT;\n\t\tnum_pages = get_user_pages_fast(base, size, 0, &page[i]);\n\t\tif ((num_pages != size) ||\n\t\t    (num_pages > MAX_SKB_FRAGS - skb_shinfo(skb)->nr_frags))\n\t\t\t/* put_page is in skb free */\n\t\t\treturn -EFAULT;\n\t\tskb->data_len += len;\n\t\tskb->len += len;\n\t\tskb->truesize += len;\n\t\tatomic_add(len, &skb->sk->sk_wmem_alloc);\n\t\twhile (len) {\n\t\t\tint off = base & ~PAGE_MASK;\n\t\t\tint size = min_t(int, len, PAGE_SIZE - off);\n\t\t\t__skb_fill_page_desc(skb, i, page[i], off, size);\n\t\t\tskb_shinfo(skb)->nr_frags++;\n\t\t\t/* increase sk_wmem_alloc */\n\t\t\tbase += size;\n\t\t\tlen -= size;\n\t\t\ti++;\n\t\t}\n\t\toffset1 = 0;\n\t\t++from;\n\t}\n\treturn 0;\n}",
      "code_after_change": "static int zerocopy_sg_from_iovec(struct sk_buff *skb, const struct iovec *from,\n\t\t\t\t  int offset, size_t count)\n{\n\tint len = iov_length(from, count) - offset;\n\tint copy = skb_headlen(skb);\n\tint size, offset1 = 0;\n\tint i = 0;\n\n\t/* Skip over from offset */\n\twhile (count && (offset >= from->iov_len)) {\n\t\toffset -= from->iov_len;\n\t\t++from;\n\t\t--count;\n\t}\n\n\t/* copy up to skb headlen */\n\twhile (count && (copy > 0)) {\n\t\tsize = min_t(unsigned int, copy, from->iov_len - offset);\n\t\tif (copy_from_user(skb->data + offset1, from->iov_base + offset,\n\t\t\t\t   size))\n\t\t\treturn -EFAULT;\n\t\tif (copy > size) {\n\t\t\t++from;\n\t\t\t--count;\n\t\t\toffset = 0;\n\t\t} else\n\t\t\toffset += size;\n\t\tcopy -= size;\n\t\toffset1 += size;\n\t}\n\n\tif (len == offset1)\n\t\treturn 0;\n\n\twhile (count--) {\n\t\tstruct page *page[MAX_SKB_FRAGS];\n\t\tint num_pages;\n\t\tunsigned long base;\n\n\t\tlen = from->iov_len - offset;\n\t\tif (!len) {\n\t\t\toffset = 0;\n\t\t\t++from;\n\t\t\tcontinue;\n\t\t}\n\t\tbase = (unsigned long)from->iov_base + offset;\n\t\tsize = ((base & ~PAGE_MASK) + len + ~PAGE_MASK) >> PAGE_SHIFT;\n\t\tnum_pages = get_user_pages_fast(base, size, 0, &page[i]);\n\t\tif ((num_pages != size) ||\n\t\t    (num_pages > MAX_SKB_FRAGS - skb_shinfo(skb)->nr_frags))\n\t\t\t/* put_page is in skb free */\n\t\t\treturn -EFAULT;\n\t\tskb->data_len += len;\n\t\tskb->len += len;\n\t\tskb->truesize += len;\n\t\tatomic_add(len, &skb->sk->sk_wmem_alloc);\n\t\twhile (len) {\n\t\t\tint off = base & ~PAGE_MASK;\n\t\t\tint size = min_t(int, len, PAGE_SIZE - off);\n\t\t\t__skb_fill_page_desc(skb, i, page[i], off, size);\n\t\t\tskb_shinfo(skb)->nr_frags++;\n\t\t\t/* increase sk_wmem_alloc */\n\t\t\tbase += size;\n\t\t\tlen -= size;\n\t\t\ti++;\n\t\t}\n\t\toffset = 0;\n\t\t++from;\n\t}\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\t\toffset = 0;",
          "\t\t} else",
          "\t\t\toffset += size;",
          "\t\tlen = from->iov_len - offset;",
          "\t\t\toffset = 0;",
          "\t\tbase = (unsigned long)from->iov_base + offset;",
          "\t\toffset = 0;"
        ],
        "deleted": [
          "\t\t}",
          "\t\toffset = 0;",
          "\t\tlen = from->iov_len - offset1;",
          "\t\t\toffset1 = 0;",
          "\t\tbase = (unsigned long)from->iov_base + offset1;",
          "\t\toffset1 = 0;"
        ]
      },
      "preconditions_for_vulnerability": "Improper management of the 'offset' variable during data copying operations within the 'zerocopy_sg_from_iovec' function.",
      "trigger_condition": "Running the code in certain configurations where a long descriptor with a long vector length is encountered, leading to a buffer overflow vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code fails to properly update the 'offset' variable when copying data from the 'from' iovec to the 'skb' buffer, potentially allowing for a buffer overflow if a long descriptor with a long vector length is encountered.",
      "id": 9,
      "code_after_change_normalized": "static int FUN1(struct sk_buff *VAR1, const struct iovec *VAR2,\nint VAR3, size_t VAR4)\n{\nint VAR5 = FUN2(VAR2, VAR4) - VAR3;\nint VAR6 = FUN3(VAR1);\nint VAR7, VAR8 = 0;\nint VAR9 = 0;\nwhile (VAR4 && (VAR3 >= VAR2->VAR10)) {\nVAR3 -= VAR2->VAR10;\n++VAR2;\n--VAR4;\n}\nwhile (VAR4 && (VAR6 > 0)) {\nVAR7 = FUN4(unsigned int, VAR6, VAR2->VAR10 - VAR3);\nif (FUN5(VAR1->VAR11 + VAR8, VAR2->VAR12 + VAR3,\nVAR7))\nreturn -VAR13;\nif (VAR6 > VAR7) {\n++VAR2;\n--VAR4;\nVAR3 = 0;\n} else\nVAR3 += VAR7;\nVAR6 -= VAR7;\nVAR8 += VAR7;\n}\nif (VAR5 == VAR8)\nreturn 0;\nwhile (VAR4--) {\nstruct VAR14 *VAR14[VAR15];\nint VAR16;\nunsigned long VAR17;\nVAR5 = VAR2->VAR10 - VAR3;\nif (!VAR5) {\nVAR3 = 0;\n++VAR2;\ncontinue;\n}\nVAR17 = (unsigned long)VAR2->VAR12 + VAR3;\nVAR7 = ((VAR17 & ~VAR18) + VAR5 + ~VAR18) >> VAR19;\nVAR16 = FUN6(VAR17, VAR7, 0, &VAR14[VAR9]);\nif ((VAR16 != VAR7) ||\n(VAR16 > VAR15 - FUN7(VAR1)->VAR20))\nreturn -VAR13;\nVAR1->VAR21 += VAR5;\nVAR1->VAR5 += VAR5;\nVAR1->VAR22 += VAR5;\nFUN8(VAR5, &VAR1->VAR23->VAR24);\nwhile (VAR5) {\nint VAR25 = VAR17 & ~VAR18;\nint VAR7 = FUN4(int, VAR5, VAR26 - VAR25);\nFUN9(VAR1, VAR9, VAR14[VAR9], VAR25, VAR7);\nFUN7(VAR1)->VAR20++;\nVAR17 += VAR7;\nVAR5 -= VAR7;\nVAR9++;\n}\nVAR3 = 0;\n++VAR2;\n}\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct sk_buff *VAR1, const struct iovec *VAR2,\nint VAR3, size_t VAR4)\n{\nint VAR5 = FUN2(VAR2, VAR4) - VAR3;\nint VAR6 = FUN3(VAR1);\nint VAR7, VAR8 = 0;\nint VAR9 = 0;\nwhile (VAR4 && (VAR3 >= VAR2->VAR10)) {\nVAR3 -= VAR2->VAR10;\n++VAR2;\n--VAR4;\n}\nwhile (VAR4 && (VAR6 > 0)) {\nVAR7 = FUN4(unsigned int, VAR6, VAR2->VAR10 - VAR3);\nif (FUN5(VAR1->VAR11 + VAR8, VAR2->VAR12 + VAR3,\nVAR7))\nreturn -VAR13;\nif (VAR6 > VAR7) {\n++VAR2;\n--VAR4;\n}\nVAR6 -= VAR7;\nVAR8 += VAR7;\nVAR3 = 0;\n}\nif (VAR5 == VAR8)\nreturn 0;\nwhile (VAR4--) {\nstruct VAR14 *VAR14[VAR15];\nint VAR16;\nunsigned long VAR17;\nVAR5 = VAR2->VAR10 - VAR8;\nif (!VAR5) {\nVAR8 = 0;\n++VAR2;\ncontinue;\n}\nVAR17 = (unsigned long)VAR2->VAR12 + VAR8;\nVAR7 = ((VAR17 & ~VAR18) + VAR5 + ~VAR18) >> VAR19;\nVAR16 = FUN6(VAR17, VAR7, 0, &VAR14[VAR9]);\nif ((VAR16 != VAR7) ||\n(VAR16 > VAR15 - FUN7(VAR1)->VAR20))\nreturn -VAR13;\nVAR1->VAR21 += VAR5;\nVAR1->VAR5 += VAR5;\nVAR1->VAR22 += VAR5;\nFUN8(VAR5, &VAR1->VAR23->VAR24);\nwhile (VAR5) {\nint VAR25 = VAR17 & ~VAR18;\nint VAR7 = FUN4(int, VAR5, VAR26 - VAR25);\nFUN9(VAR1, VAR9, VAR14[VAR9], VAR25, VAR7);\nFUN7(VAR1)->VAR20++;\nVAR17 += VAR7;\nVAR5 -= VAR7;\nVAR9++;\n}\nVAR8 = 0;\n++VAR2;\n}\nreturn 0;\n}\n",
      "code_after_change_raw": "static int zerocopy_sg_from_iovec(struct sk_buff *skb, const struct iovec *from,\nint offset, size_t count)\n{\nint len = iov_length(from, count) - offset;\nint copy = skb_headlen(skb);\nint size, offset1 = 0;\nint i = 0;\nwhile (count && (offset >= from->iov_len)) {\noffset -= from->iov_len;\n++from;\n--count;\n}\nwhile (count && (copy > 0)) {\nsize = min_t(unsigned int, copy, from->iov_len - offset);\nif (copy_from_user(skb->data + offset1, from->iov_base + offset,\nsize))\nreturn -EFAULT;\nif (copy > size) {\n++from;\n--count;\noffset = 0;\n} else\noffset += size;\ncopy -= size;\noffset1 += size;\n}\nif (len == offset1)\nreturn 0;\nwhile (count--) {\nstruct page *page[MAX_SKB_FRAGS];\nint num_pages;\nunsigned long base;\nlen = from->iov_len - offset;\nif (!len) {\noffset = 0;\n++from;\ncontinue;\n}\nbase = (unsigned long)from->iov_base + offset;\nsize = ((base & ~PAGE_MASK) + len + ~PAGE_MASK) >> PAGE_SHIFT;\nnum_pages = get_user_pages_fast(base, size, 0, &page[i]);\nif ((num_pages != size) ||\n(num_pages > MAX_SKB_FRAGS - skb_shinfo(skb)->nr_frags))\nreturn -EFAULT;\nskb->data_len += len;\nskb->len += len;\nskb->truesize += len;\natomic_add(len, &skb->sk->sk_wmem_alloc);\nwhile (len) {\nint off = base & ~PAGE_MASK;\nint size = min_t(int, len, PAGE_SIZE - off);\n__skb_fill_page_desc(skb, i, page[i], off, size);\nskb_shinfo(skb)->nr_frags++;\nbase += size;\nlen -= size;\ni++;\n}\noffset = 0;\n++from;\n}\nreturn 0;\n}\n",
      "code_before_change_raw": "static int zerocopy_sg_from_iovec(struct sk_buff *skb, const struct iovec *from,\nint offset, size_t count)\n{\nint len = iov_length(from, count) - offset;\nint copy = skb_headlen(skb);\nint size, offset1 = 0;\nint i = 0;\nwhile (count && (offset >= from->iov_len)) {\noffset -= from->iov_len;\n++from;\n--count;\n}\nwhile (count && (copy > 0)) {\nsize = min_t(unsigned int, copy, from->iov_len - offset);\nif (copy_from_user(skb->data + offset1, from->iov_base + offset,\nsize))\nreturn -EFAULT;\nif (copy > size) {\n++from;\n--count;\n}\ncopy -= size;\noffset1 += size;\noffset = 0;\n}\nif (len == offset1)\nreturn 0;\nwhile (count--) {\nstruct page *page[MAX_SKB_FRAGS];\nint num_pages;\nunsigned long base;\nlen = from->iov_len - offset1;\nif (!len) {\noffset1 = 0;\n++from;\ncontinue;\n}\nbase = (unsigned long)from->iov_base + offset1;\nsize = ((base & ~PAGE_MASK) + len + ~PAGE_MASK) >> PAGE_SHIFT;\nnum_pages = get_user_pages_fast(base, size, 0, &page[i]);\nif ((num_pages != size) ||\n(num_pages > MAX_SKB_FRAGS - skb_shinfo(skb)->nr_frags))\nreturn -EFAULT;\nskb->data_len += len;\nskb->len += len;\nskb->truesize += len;\natomic_add(len, &skb->sk->sk_wmem_alloc);\nwhile (len) {\nint off = base & ~PAGE_MASK;\nint size = min_t(int, len, PAGE_SIZE - off);\n__skb_fill_page_desc(skb, i, page[i], off, size);\nskb_shinfo(skb)->nr_frags++;\nbase += size;\nlen -= size;\ni++;\n}\noffset1 = 0;\n++from;\n}\nreturn 0;\n}\n"
    }
  ],
  "CVE-2012-2137": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for mapping between GSI and MSI entries in the setup_routing_entry function.",
        "trigger_condition": "The setup_routing_entry function allows mapping between GSI and MSI entries without proper validation, leading to a buffer overflow vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not check for the type of the incoming entry (ue) being KVM_IRQ_ROUTING_MSI before allowing mapping, which can result in a buffer overflow and potential code execution due to incorrect handling of MSI entries."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check in the setup_routing_entry function to prevent mapping between GSI and MSI entries. By including a condition to check if the type of the incoming entry is KVM_IRQ_ROUTING_MSI, the code ensures that only valid mappings are allowed, thus preventing the buffer overflow vulnerability. This solution enhances the security of the code by restricting the mapping between GSI and MSI entries and reducing the risk of exploitation.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2012-2137, which involves a buffer overflow in the KVM subsystem in the Linux kernel. The vulnerability allows local users to cause a denial of service (crash) and potentially execute arbitrary code by exploiting vectors related to Message Signaled Interrupts (MSI), irq routing entries, and an incorrect check in the setup_routing_entry function before invoking the kvm_set_irq function.\n\nThe modification adds an additional condition in the if statement inside the hlist_for_each_entry loop to check if the type of the incoming entry (ue) is KVM_IRQ_ROUTING_MSI. This check ensures that the function does not allow mapping between GSI and MSI entries, preventing a potential buffer overflow and exploitation of the vulnerability.\n\nBy including this additional check, the code is made more secure and prevents the exploitation of the vulnerability by restricting the mapping between GSI and MSI entries, thus mitigating the risk of a buffer overflow and potential code execution.",
      "GPT_purpose": "Set up routing entries for IRQs in the KVM subsystem, checking for duplicate mappings and handling different types of IRQ routing entries.",
      "GPT_function": "\n1. Check for mapping between GSI and irqchip to prevent multiple mappings.\n2. Set up routing entry based on the type of irqchip or MSI.\n3. Add the routing entry to the routing table if conditions are met.",
      "CVE_id": "CVE-2012-2137",
      "code_before_change": "static int setup_routing_entry(struct kvm_irq_routing_table *rt,\n\t\t\t       struct kvm_kernel_irq_routing_entry *e,\n\t\t\t       const struct kvm_irq_routing_entry *ue)\n{\n\tint r = -EINVAL;\n\tint delta;\n\tunsigned max_pin;\n\tstruct kvm_kernel_irq_routing_entry *ei;\n\tstruct hlist_node *n;\n\n\t/*\n\t * Do not allow GSI to be mapped to the same irqchip more than once.\n\t * Allow only one to one mapping between GSI and MSI.\n\t */\n\thlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\n\t\tif (ei->type == KVM_IRQ_ROUTING_MSI ||\n\t\t    ue->u.irqchip.irqchip == ei->irqchip.irqchip)\n\t\t\treturn r;\n\n\te->gsi = ue->gsi;\n\te->type = ue->type;\n\tswitch (ue->type) {\n\tcase KVM_IRQ_ROUTING_IRQCHIP:\n\t\tdelta = 0;\n\t\tswitch (ue->u.irqchip.irqchip) {\n\t\tcase KVM_IRQCHIP_PIC_MASTER:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_PIC_SLAVE:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tdelta = 8;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_IOAPIC:\n\t\t\tmax_pin = KVM_IOAPIC_NUM_PINS;\n\t\t\te->set = kvm_set_ioapic_irq;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto out;\n\t\t}\n\t\te->irqchip.irqchip = ue->u.irqchip.irqchip;\n\t\te->irqchip.pin = ue->u.irqchip.pin + delta;\n\t\tif (e->irqchip.pin >= max_pin)\n\t\t\tgoto out;\n\t\trt->chip[ue->u.irqchip.irqchip][e->irqchip.pin] = ue->gsi;\n\t\tbreak;\n\tcase KVM_IRQ_ROUTING_MSI:\n\t\te->set = kvm_set_msi;\n\t\te->msi.address_lo = ue->u.msi.address_lo;\n\t\te->msi.address_hi = ue->u.msi.address_hi;\n\t\te->msi.data = ue->u.msi.data;\n\t\tbreak;\n\tdefault:\n\t\tgoto out;\n\t}\n\n\thlist_add_head(&e->link, &rt->map[e->gsi]);\n\tr = 0;\nout:\n\treturn r;\n}",
      "code_after_change": "static int setup_routing_entry(struct kvm_irq_routing_table *rt,\n\t\t\t       struct kvm_kernel_irq_routing_entry *e,\n\t\t\t       const struct kvm_irq_routing_entry *ue)\n{\n\tint r = -EINVAL;\n\tint delta;\n\tunsigned max_pin;\n\tstruct kvm_kernel_irq_routing_entry *ei;\n\tstruct hlist_node *n;\n\n\t/*\n\t * Do not allow GSI to be mapped to the same irqchip more than once.\n\t * Allow only one to one mapping between GSI and MSI.\n\t */\n\thlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\n\t\tif (ei->type == KVM_IRQ_ROUTING_MSI ||\n\t\t    ue->type == KVM_IRQ_ROUTING_MSI ||\n\t\t    ue->u.irqchip.irqchip == ei->irqchip.irqchip)\n\t\t\treturn r;\n\n\te->gsi = ue->gsi;\n\te->type = ue->type;\n\tswitch (ue->type) {\n\tcase KVM_IRQ_ROUTING_IRQCHIP:\n\t\tdelta = 0;\n\t\tswitch (ue->u.irqchip.irqchip) {\n\t\tcase KVM_IRQCHIP_PIC_MASTER:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_PIC_SLAVE:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tdelta = 8;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_IOAPIC:\n\t\t\tmax_pin = KVM_IOAPIC_NUM_PINS;\n\t\t\te->set = kvm_set_ioapic_irq;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto out;\n\t\t}\n\t\te->irqchip.irqchip = ue->u.irqchip.irqchip;\n\t\te->irqchip.pin = ue->u.irqchip.pin + delta;\n\t\tif (e->irqchip.pin >= max_pin)\n\t\t\tgoto out;\n\t\trt->chip[ue->u.irqchip.irqchip][e->irqchip.pin] = ue->gsi;\n\t\tbreak;\n\tcase KVM_IRQ_ROUTING_MSI:\n\t\te->set = kvm_set_msi;\n\t\te->msi.address_lo = ue->u.msi.address_lo;\n\t\te->msi.address_hi = ue->u.msi.address_hi;\n\t\te->msi.data = ue->u.msi.data;\n\t\tbreak;\n\tdefault:\n\t\tgoto out;\n\t}\n\n\thlist_add_head(&e->link, &rt->map[e->gsi]);\n\tr = 0;\nout:\n\treturn r;\n}",
      "modified_lines": {
        "added": [
          "\t\t    ue->type == KVM_IRQ_ROUTING_MSI ||"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper validation for mapping between GSI and MSI entries in the setup_routing_entry function.",
      "trigger_condition": "The setup_routing_entry function allows mapping between GSI and MSI entries without proper validation, leading to a buffer overflow vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not check for the type of the incoming entry (ue) being KVM_IRQ_ROUTING_MSI before allowing mapping, which can result in a buffer overflow and potential code execution due to incorrect handling of MSI entries.",
      "id": 10,
      "code_after_change_normalized": "static int FUN1(struct kvm_irq_routing_table *VAR1,\nstruct kvm_kernel_irq_routing_entry *VAR2,\nconst struct kvm_irq_routing_entry *VAR3)\n{\nint VAR4 = -VAR5;\nint VAR6;\nunsigned VAR7;\nstruct kvm_kernel_irq_routing_entry *VAR8;\nstruct hlist_node *VAR9;\nFUN2(VAR8, VAR9, &VAR1->VAR10[VAR3->VAR11], VAR12)\nif (VAR8->VAR13 == VAR14 ||\nVAR3->VAR13 == VAR14 ||\nVAR3->VAR15.VAR16.VAR16 == VAR8->VAR16.VAR16)\nreturn VAR4;\nVAR2->VAR11 = VAR3->VAR11;\nVAR2->VAR13 = VAR3->VAR13;\nswitch (VAR3->VAR13) {\ncase VAR17:\nVAR6 = 0;\nswitch (VAR3->VAR15.VAR16.VAR16) {\ncase VAR18:\nVAR2->VAR19 = VAR20;\nVAR7 = 16;\nbreak;\ncase VAR21:\nVAR2->VAR19 = VAR20;\nVAR7 = 16;\nVAR6 = 8;\nbreak;\ncase VAR22:\nVAR7 = VAR23;\nVAR2->VAR19 = VAR24;\nbreak;\ndefault:\ngoto VAR25;\n}\nVAR2->VAR16.VAR16 = VAR3->VAR15.VAR16.VAR16;\nVAR2->VAR16.VAR26 = VAR3->VAR15.VAR16.VAR26 + VAR6;\nif (VAR2->VAR16.VAR26 >= VAR7)\ngoto VAR25;\nVAR1->VAR27[VAR3->VAR15.VAR16.VAR16][VAR2->VAR16.VAR26] = VAR3->VAR11;\nbreak;\ncase VAR14:\nVAR2->VAR19 = VAR28;\nVAR2->VAR29.VAR30 = VAR3->VAR15.VAR29.VAR30;\nVAR2->VAR29.VAR31 = VAR3->VAR15.VAR29.VAR31;\nVAR2->VAR29.VAR32 = VAR3->VAR15.VAR29.VAR32;\nbreak;\ndefault:\ngoto VAR25;\n}\nFUN3(&VAR2->VAR12, &VAR1->VAR10[VAR2->VAR11]);\nVAR4 = 0;\nVAR25:\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct kvm_irq_routing_table *VAR1,\nstruct kvm_kernel_irq_routing_entry *VAR2,\nconst struct kvm_irq_routing_entry *VAR3)\n{\nint VAR4 = -VAR5;\nint VAR6;\nunsigned VAR7;\nstruct kvm_kernel_irq_routing_entry *VAR8;\nstruct hlist_node *VAR9;\nFUN2(VAR8, VAR9, &VAR1->VAR10[VAR3->VAR11], VAR12)\nif (VAR8->VAR13 == VAR14 ||\nVAR3->VAR15.VAR16.VAR16 == VAR8->VAR16.VAR16)\nreturn VAR4;\nVAR2->VAR11 = VAR3->VAR11;\nVAR2->VAR13 = VAR3->VAR13;\nswitch (VAR3->VAR13) {\ncase VAR17:\nVAR6 = 0;\nswitch (VAR3->VAR15.VAR16.VAR16) {\ncase VAR18:\nVAR2->VAR19 = VAR20;\nVAR7 = 16;\nbreak;\ncase VAR21:\nVAR2->VAR19 = VAR20;\nVAR7 = 16;\nVAR6 = 8;\nbreak;\ncase VAR22:\nVAR7 = VAR23;\nVAR2->VAR19 = VAR24;\nbreak;\ndefault:\ngoto VAR25;\n}\nVAR2->VAR16.VAR16 = VAR3->VAR15.VAR16.VAR16;\nVAR2->VAR16.VAR26 = VAR3->VAR15.VAR16.VAR26 + VAR6;\nif (VAR2->VAR16.VAR26 >= VAR7)\ngoto VAR25;\nVAR1->VAR27[VAR3->VAR15.VAR16.VAR16][VAR2->VAR16.VAR26] = VAR3->VAR11;\nbreak;\ncase VAR14:\nVAR2->VAR19 = VAR28;\nVAR2->VAR29.VAR30 = VAR3->VAR15.VAR29.VAR30;\nVAR2->VAR29.VAR31 = VAR3->VAR15.VAR29.VAR31;\nVAR2->VAR29.VAR32 = VAR3->VAR15.VAR29.VAR32;\nbreak;\ndefault:\ngoto VAR25;\n}\nFUN3(&VAR2->VAR12, &VAR1->VAR10[VAR2->VAR11]);\nVAR4 = 0;\nVAR25:\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int setup_routing_entry(struct kvm_irq_routing_table *rt,\nstruct kvm_kernel_irq_routing_entry *e,\nconst struct kvm_irq_routing_entry *ue)\n{\nint r = -EINVAL;\nint delta;\nunsigned max_pin;\nstruct kvm_kernel_irq_routing_entry *ei;\nstruct hlist_node *n;\nhlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\nif (ei->type == KVM_IRQ_ROUTING_MSI ||\nue->type == KVM_IRQ_ROUTING_MSI ||\nue->u.irqchip.irqchip == ei->irqchip.irqchip)\nreturn r;\ne->gsi = ue->gsi;\ne->type = ue->type;\nswitch (ue->type) {\ncase KVM_IRQ_ROUTING_IRQCHIP:\ndelta = 0;\nswitch (ue->u.irqchip.irqchip) {\ncase KVM_IRQCHIP_PIC_MASTER:\ne->set = kvm_set_pic_irq;\nmax_pin = 16;\nbreak;\ncase KVM_IRQCHIP_PIC_SLAVE:\ne->set = kvm_set_pic_irq;\nmax_pin = 16;\ndelta = 8;\nbreak;\ncase KVM_IRQCHIP_IOAPIC:\nmax_pin = KVM_IOAPIC_NUM_PINS;\ne->set = kvm_set_ioapic_irq;\nbreak;\ndefault:\ngoto out;\n}\ne->irqchip.irqchip = ue->u.irqchip.irqchip;\ne->irqchip.pin = ue->u.irqchip.pin + delta;\nif (e->irqchip.pin >= max_pin)\ngoto out;\nrt->chip[ue->u.irqchip.irqchip][e->irqchip.pin] = ue->gsi;\nbreak;\ncase KVM_IRQ_ROUTING_MSI:\ne->set = kvm_set_msi;\ne->msi.address_lo = ue->u.msi.address_lo;\ne->msi.address_hi = ue->u.msi.address_hi;\ne->msi.data = ue->u.msi.data;\nbreak;\ndefault:\ngoto out;\n}\nhlist_add_head(&e->link, &rt->map[e->gsi]);\nr = 0;\nout:\nreturn r;\n}\n",
      "code_before_change_raw": "static int setup_routing_entry(struct kvm_irq_routing_table *rt,\nstruct kvm_kernel_irq_routing_entry *e,\nconst struct kvm_irq_routing_entry *ue)\n{\nint r = -EINVAL;\nint delta;\nunsigned max_pin;\nstruct kvm_kernel_irq_routing_entry *ei;\nstruct hlist_node *n;\nhlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\nif (ei->type == KVM_IRQ_ROUTING_MSI ||\nue->u.irqchip.irqchip == ei->irqchip.irqchip)\nreturn r;\ne->gsi = ue->gsi;\ne->type = ue->type;\nswitch (ue->type) {\ncase KVM_IRQ_ROUTING_IRQCHIP:\ndelta = 0;\nswitch (ue->u.irqchip.irqchip) {\ncase KVM_IRQCHIP_PIC_MASTER:\ne->set = kvm_set_pic_irq;\nmax_pin = 16;\nbreak;\ncase KVM_IRQCHIP_PIC_SLAVE:\ne->set = kvm_set_pic_irq;\nmax_pin = 16;\ndelta = 8;\nbreak;\ncase KVM_IRQCHIP_IOAPIC:\nmax_pin = KVM_IOAPIC_NUM_PINS;\ne->set = kvm_set_ioapic_irq;\nbreak;\ndefault:\ngoto out;\n}\ne->irqchip.irqchip = ue->u.irqchip.irqchip;\ne->irqchip.pin = ue->u.irqchip.pin + delta;\nif (e->irqchip.pin >= max_pin)\ngoto out;\nrt->chip[ue->u.irqchip.irqchip][e->irqchip.pin] = ue->gsi;\nbreak;\ncase KVM_IRQ_ROUTING_MSI:\ne->set = kvm_set_msi;\ne->msi.address_lo = ue->u.msi.address_lo;\ne->msi.address_hi = ue->u.msi.address_hi;\ne->msi.data = ue->u.msi.data;\nbreak;\ndefault:\ngoto out;\n}\nhlist_add_head(&e->link, &rt->map[e->gsi]);\nr = 0;\nout:\nreturn r;\n}\n"
    }
  ],
  "CVE-2012-2745": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of session keyring assignment during child process creation.",
        "trigger_condition": "A crafted application utilizing the fork system call triggers the vulnerability by causing the copy_creds function to provide an invalid replacement session keyring to the child process.",
        "specific_code_behavior_causing_vulnerability": "The code fails to properly set the replacement session keyring for the child process, leading to a denial of service (panic) due to the use of an invalid session keyring."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the replacement session keyring for the child process is set to NULL at the beginning of the copy_creds function. This prevents the provision of an invalid session keyring and helps avoid the denial of service condition caused by the incorrect session keyring assignment.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2012-2745 identified in the original code snippet. The vulnerability arises from the copy_creds function providing an invalid replacement session keyring to a child process, which can lead to a denial of service (panic) when a crafted application utilizing the fork system call is executed.\n\nBy adding the line `p->replacement_session_keyring = NULL;` at the beginning of the function, the code ensures that the replacement session keyring for the child process is set to NULL, thereby preventing the invalid replacement session keyring issue that could lead to a denial of service.\n\nThis modification helps to mitigate the vulnerability by properly handling the session keyring assignment, ensuring that a valid session keyring is used for the child process, thus preventing the potential panic caused by the incorrect replacement session keyring.",
      "GPT_purpose": "Copy credentials and prepare new credentials for a process, potentially creating a new user namespace and handling keyrings for new threads.",
      "GPT_function": "\n1. Copy credentials for a new process or thread.\n2. Handle cases where a new user namespace is created.\n3. Manage thread keyrings and sharing of keyrings between threads in a process.",
      "CVE_id": "CVE-2012-2745",
      "code_before_change": "int copy_creds(struct task_struct *p, unsigned long clone_flags)\n{\n#ifdef CONFIG_KEYS\n\tstruct thread_group_cred *tgcred;\n#endif\n\tstruct cred *new;\n\tint ret;\n\n\tif (\n#ifdef CONFIG_KEYS\n\t\t!p->cred->thread_keyring &&\n#endif\n\t\tclone_flags & CLONE_THREAD\n\t    ) {\n\t\tp->real_cred = get_cred(p->cred);\n\t\tget_cred(p->cred);\n\t\talter_cred_subscribers(p->cred, 2);\n\t\tkdebug(\"share_creds(%p{%d,%d})\",\n\t\t       p->cred, atomic_read(&p->cred->usage),\n\t\t       read_cred_subscribers(p->cred));\n\t\tatomic_inc(&p->cred->user->processes);\n\t\treturn 0;\n\t}\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tif (clone_flags & CLONE_NEWUSER) {\n\t\tret = create_user_ns(new);\n\t\tif (ret < 0)\n\t\t\tgoto error_put;\n\t}\n\n\t/* cache user_ns in cred.  Doesn't need a refcount because it will\n\t * stay pinned by cred->user\n\t */\n\tnew->user_ns = new->user->user_ns;\n\n#ifdef CONFIG_KEYS\n\t/* new threads get their own thread keyrings if their parent already\n\t * had one */\n\tif (new->thread_keyring) {\n\t\tkey_put(new->thread_keyring);\n\t\tnew->thread_keyring = NULL;\n\t\tif (clone_flags & CLONE_THREAD)\n\t\t\tinstall_thread_keyring_to_cred(new);\n\t}\n\n\t/* we share the process and session keyrings between all the threads in\n\t * a process - this is slightly icky as we violate COW credentials a\n\t * bit */\n\tif (!(clone_flags & CLONE_THREAD)) {\n\t\ttgcred = kmalloc(sizeof(*tgcred), GFP_KERNEL);\n\t\tif (!tgcred) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto error_put;\n\t\t}\n\t\tatomic_set(&tgcred->usage, 1);\n\t\tspin_lock_init(&tgcred->lock);\n\t\ttgcred->process_keyring = NULL;\n\t\ttgcred->session_keyring = key_get(new->tgcred->session_keyring);\n\n\t\trelease_tgcred(new);\n\t\tnew->tgcred = tgcred;\n\t}\n#endif\n\n\tatomic_inc(&new->user->processes);\n\tp->cred = p->real_cred = get_cred(new);\n\talter_cred_subscribers(new, 2);\n\tvalidate_creds(new);\n\treturn 0;\n\nerror_put:\n\tput_cred(new);\n\treturn ret;\n}",
      "code_after_change": "int copy_creds(struct task_struct *p, unsigned long clone_flags)\n{\n#ifdef CONFIG_KEYS\n\tstruct thread_group_cred *tgcred;\n#endif\n\tstruct cred *new;\n\tint ret;\n\n\tp->replacement_session_keyring = NULL;\n\n\tif (\n#ifdef CONFIG_KEYS\n\t\t!p->cred->thread_keyring &&\n#endif\n\t\tclone_flags & CLONE_THREAD\n\t    ) {\n\t\tp->real_cred = get_cred(p->cred);\n\t\tget_cred(p->cred);\n\t\talter_cred_subscribers(p->cred, 2);\n\t\tkdebug(\"share_creds(%p{%d,%d})\",\n\t\t       p->cred, atomic_read(&p->cred->usage),\n\t\t       read_cred_subscribers(p->cred));\n\t\tatomic_inc(&p->cred->user->processes);\n\t\treturn 0;\n\t}\n\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tif (clone_flags & CLONE_NEWUSER) {\n\t\tret = create_user_ns(new);\n\t\tif (ret < 0)\n\t\t\tgoto error_put;\n\t}\n\n\t/* cache user_ns in cred.  Doesn't need a refcount because it will\n\t * stay pinned by cred->user\n\t */\n\tnew->user_ns = new->user->user_ns;\n\n#ifdef CONFIG_KEYS\n\t/* new threads get their own thread keyrings if their parent already\n\t * had one */\n\tif (new->thread_keyring) {\n\t\tkey_put(new->thread_keyring);\n\t\tnew->thread_keyring = NULL;\n\t\tif (clone_flags & CLONE_THREAD)\n\t\t\tinstall_thread_keyring_to_cred(new);\n\t}\n\n\t/* we share the process and session keyrings between all the threads in\n\t * a process - this is slightly icky as we violate COW credentials a\n\t * bit */\n\tif (!(clone_flags & CLONE_THREAD)) {\n\t\ttgcred = kmalloc(sizeof(*tgcred), GFP_KERNEL);\n\t\tif (!tgcred) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto error_put;\n\t\t}\n\t\tatomic_set(&tgcred->usage, 1);\n\t\tspin_lock_init(&tgcred->lock);\n\t\ttgcred->process_keyring = NULL;\n\t\ttgcred->session_keyring = key_get(new->tgcred->session_keyring);\n\n\t\trelease_tgcred(new);\n\t\tnew->tgcred = tgcred;\n\t}\n#endif\n\n\tatomic_inc(&new->user->processes);\n\tp->cred = p->real_cred = get_cred(new);\n\talter_cred_subscribers(new, 2);\n\tvalidate_creds(new);\n\treturn 0;\n\nerror_put:\n\tput_cred(new);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "",
          "\tp->replacement_session_keyring = NULL;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Improper handling of session keyring assignment during child process creation.",
      "trigger_condition": "A crafted application utilizing the fork system call triggers the vulnerability by causing the copy_creds function to provide an invalid replacement session keyring to the child process.",
      "specific_code_behavior_causing_vulnerability": "The code fails to properly set the replacement session keyring for the child process, leading to a denial of service (panic) due to the use of an invalid session keyring.",
      "id": 11,
      "code_after_change_normalized": "int FUN1(struct task_struct *VAR1, unsigned long VAR2)\n{\n#ifdef VAR3\nstruct thread_group_cred *VAR4;\n#VAR5\nstruct cred *new;\nint VAR6;\nVAR1->VAR7 = NULL;\nif (\n#ifdef VAR3\n!VAR1->VAR8->VAR9 &&\n#VAR5\nVAR2 & VAR10\n) {\nVAR1->VAR11 = FUN2(VAR1->VAR8);\nFUN2(VAR1->VAR8);\nFUN3(VAR1->VAR8, 2);\nFUN4(\"STR\",\nVAR1->VAR8, FUN5(&VAR1->VAR8->VAR12),\nFUN6(VAR1->VAR8));\nFUN7(&VAR1->VAR8->VAR13->VAR14);\nreturn 0;\n}\nnew = FUN8();\nif (!new)\nreturn -VAR15;\nif (VAR2 & VAR16) {\nVAR6 = FUN9(new);\nif (VAR6 < 0)\ngoto VAR17;\n}\nnew->VAR18 = new->VAR13->VAR18;\n#ifdef VAR3\nif (new->VAR9) {\nFUN10(new->VAR9);\nnew->VAR9 = NULL;\nif (VAR2 & VAR10)\nFUN11(new);\n}\nif (!(VAR2 & VAR10)) {\nVAR4 = FUN12(sizeof(*VAR4), VAR19);\nif (!VAR4) {\nVAR6 = -VAR15;\ngoto VAR17;\n}\nFUN13(&VAR4->VAR12, 1);\nFUN14(&VAR4->VAR20);\nVAR4->VAR21 = NULL;\nVAR4->VAR22 = FUN15(new->VAR4->VAR22);\nFUN16(new);\nnew->VAR4 = VAR4;\n}\n#VAR5\nFUN7(&new->VAR13->VAR14);\nVAR1->VAR8 = VAR1->VAR11 = FUN2(new);\nFUN3(new, 2);\nFUN17(new);\nreturn 0;\nVAR17:\nFUN18(new);\nreturn VAR6;\n}\n",
      "code_before_change_normalized": "int FUN1(struct task_struct *VAR1, unsigned long VAR2)\n{\n#ifdef VAR3\nstruct thread_group_cred *VAR4;\n#VAR5\nstruct cred *new;\nint VAR6;\nif (\n#ifdef VAR3\n!VAR1->VAR7->VAR8 &&\n#VAR5\nVAR2 & VAR9\n) {\nVAR1->VAR10 = FUN2(VAR1->VAR7);\nFUN2(VAR1->VAR7);\nFUN3(VAR1->VAR7, 2);\nFUN4(\"STR\",\nVAR1->VAR7, FUN5(&VAR1->VAR7->VAR11),\nFUN6(VAR1->VAR7));\nFUN7(&VAR1->VAR7->VAR12->VAR13);\nreturn 0;\n}\nnew = FUN8();\nif (!new)\nreturn -VAR14;\nif (VAR2 & VAR15) {\nVAR6 = FUN9(new);\nif (VAR6 < 0)\ngoto VAR16;\n}\nnew->VAR17 = new->VAR12->VAR17;\n#ifdef VAR3\nif (new->VAR8) {\nFUN10(new->VAR8);\nnew->VAR8 = NULL;\nif (VAR2 & VAR9)\nFUN11(new);\n}\nif (!(VAR2 & VAR9)) {\nVAR4 = FUN12(sizeof(*VAR4), VAR18);\nif (!VAR4) {\nVAR6 = -VAR14;\ngoto VAR16;\n}\nFUN13(&VAR4->VAR11, 1);\nFUN14(&VAR4->VAR19);\nVAR4->VAR20 = NULL;\nVAR4->VAR21 = FUN15(new->VAR4->VAR21);\nFUN16(new);\nnew->VAR4 = VAR4;\n}\n#VAR5\nFUN7(&new->VAR12->VAR13);\nVAR1->VAR7 = VAR1->VAR10 = FUN2(new);\nFUN3(new, 2);\nFUN17(new);\nreturn 0;\nVAR16:\nFUN18(new);\nreturn VAR6;\n}\n",
      "code_after_change_raw": "int copy_creds(struct task_struct *p, unsigned long clone_flags)\n{\n#ifdef CONFIG_KEYS\nstruct thread_group_cred *tgcred;\n#endif\nstruct cred *new;\nint ret;\np->replacement_session_keyring = NULL;\nif (\n#ifdef CONFIG_KEYS\n!p->cred->thread_keyring &&\n#endif\nclone_flags & CLONE_THREAD\n) {\np->real_cred = get_cred(p->cred);\nget_cred(p->cred);\nalter_cred_subscribers(p->cred, 2);\nkdebug(\"share_creds(%p{%d,%d})\",\np->cred, atomic_read(&p->cred->usage),\nread_cred_subscribers(p->cred));\natomic_inc(&p->cred->user->processes);\nreturn 0;\n}\nnew = prepare_creds();\nif (!new)\nreturn -ENOMEM;\nif (clone_flags & CLONE_NEWUSER) {\nret = create_user_ns(new);\nif (ret < 0)\ngoto error_put;\n}\nnew->user_ns = new->user->user_ns;\n#ifdef CONFIG_KEYS\nif (new->thread_keyring) {\nkey_put(new->thread_keyring);\nnew->thread_keyring = NULL;\nif (clone_flags & CLONE_THREAD)\ninstall_thread_keyring_to_cred(new);\n}\nif (!(clone_flags & CLONE_THREAD)) {\ntgcred = kmalloc(sizeof(*tgcred), GFP_KERNEL);\nif (!tgcred) {\nret = -ENOMEM;\ngoto error_put;\n}\natomic_set(&tgcred->usage, 1);\nspin_lock_init(&tgcred->lock);\ntgcred->process_keyring = NULL;\ntgcred->session_keyring = key_get(new->tgcred->session_keyring);\nrelease_tgcred(new);\nnew->tgcred = tgcred;\n}\n#endif\natomic_inc(&new->user->processes);\np->cred = p->real_cred = get_cred(new);\nalter_cred_subscribers(new, 2);\nvalidate_creds(new);\nreturn 0;\nerror_put:\nput_cred(new);\nreturn ret;\n}\n",
      "code_before_change_raw": "int copy_creds(struct task_struct *p, unsigned long clone_flags)\n{\n#ifdef CONFIG_KEYS\nstruct thread_group_cred *tgcred;\n#endif\nstruct cred *new;\nint ret;\nif (\n#ifdef CONFIG_KEYS\n!p->cred->thread_keyring &&\n#endif\nclone_flags & CLONE_THREAD\n) {\np->real_cred = get_cred(p->cred);\nget_cred(p->cred);\nalter_cred_subscribers(p->cred, 2);\nkdebug(\"share_creds(%p{%d,%d})\",\np->cred, atomic_read(&p->cred->usage),\nread_cred_subscribers(p->cred));\natomic_inc(&p->cred->user->processes);\nreturn 0;\n}\nnew = prepare_creds();\nif (!new)\nreturn -ENOMEM;\nif (clone_flags & CLONE_NEWUSER) {\nret = create_user_ns(new);\nif (ret < 0)\ngoto error_put;\n}\nnew->user_ns = new->user->user_ns;\n#ifdef CONFIG_KEYS\nif (new->thread_keyring) {\nkey_put(new->thread_keyring);\nnew->thread_keyring = NULL;\nif (clone_flags & CLONE_THREAD)\ninstall_thread_keyring_to_cred(new);\n}\nif (!(clone_flags & CLONE_THREAD)) {\ntgcred = kmalloc(sizeof(*tgcred), GFP_KERNEL);\nif (!tgcred) {\nret = -ENOMEM;\ngoto error_put;\n}\natomic_set(&tgcred->usage, 1);\nspin_lock_init(&tgcred->lock);\ntgcred->process_keyring = NULL;\ntgcred->session_keyring = key_get(new->tgcred->session_keyring);\nrelease_tgcred(new);\nnew->tgcred = tgcred;\n}\n#endif\natomic_inc(&new->user->processes);\np->cred = p->real_cred = get_cred(new);\nalter_cred_subscribers(new, 2);\nvalidate_creds(new);\nreturn 0;\nerror_put:\nput_cred(new);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2012-3364": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of boundary checks on length fields read from incoming data, allowing for potential stack-based buffer overflows.",
        "trigger_condition": "Crafted length fields in incoming frames cause the code to read data beyond the bounds of the stack buffers, leading to a denial of service (crash) and potential arbitrary code execution.",
        "specific_code_behavior_causing_vulnerability": "The code directly reads length fields from incoming data without verifying or limiting their values, enabling attackers to manipulate the length fields to overflow the stack buffers."
      },
      "solution": "To mitigate the vulnerability, it is necessary to limit the size of the data being read into the stack buffers by using boundary checks. In this case, the solution involves using the min_t macro to restrict the length fields to safe maximum values (20 for rats_res_len and 50 for attrib_res_len). This ensures that the code does not read more data than the stack buffers can safely hold, preventing buffer overflows and enhancing the security of the code.",
      "GPT_analysis": "The modification made in the code snippet is necessary to mitigate the vulnerability CVE-2012-3364, which involves stack-based buffer overflows in the Near Field Communication Controller Interface (NCI) in the Linux kernel. \n\nBy using the `min_t` macro to limit the size of the data being read into the buffer (`rats_res_len` and `attrib_res_len`), we ensure that the length fields are within safe bounds and prevent potential buffer overflows. \n\nIn the original code, the length fields were directly read from the incoming data without any boundary checks, making the code vulnerable to crafted length fields that could lead to buffer overflows. By using `min_t` to limit the length to a safe maximum value (20 for `rats_res_len` and 50 for `attrib_res_len`), we prevent the possibility of overflowing the stack buffers and reduce the risk of a denial of service or arbitrary code execution. \n\nTherefore, the modification is necessary to enhance the security of the code and prevent exploitation of the vulnerability.",
      "GPT_purpose": "Extract activation parameters for ISO-DEP communication from a Near Field Communication Controller Interface (NCI) notification structure.",
      "GPT_function": "\n1. Extracts activation parameters for NFC-A passive poll mode.\n2. Extracts activation parameters for NFC-B passive poll mode.\n3. Handles unsupported activation_rf_tech_and_mode by returning an error.",
      "CVE_id": "CVE-2012-3364",
      "code_before_change": "static int nci_extract_activation_params_iso_dep(struct nci_dev *ndev,\n\t\t\tstruct nci_rf_intf_activated_ntf *ntf, __u8 *data)\n{\n\tstruct activation_params_nfca_poll_iso_dep *nfca_poll;\n\tstruct activation_params_nfcb_poll_iso_dep *nfcb_poll;\n\n\tswitch (ntf->activation_rf_tech_and_mode) {\n\tcase NCI_NFC_A_PASSIVE_POLL_MODE:\n\t\tnfca_poll = &ntf->activation_params.nfca_poll_iso_dep;\n\t\tnfca_poll->rats_res_len = *data++;\n\t\tpr_debug(\"rats_res_len %d\\n\", nfca_poll->rats_res_len);\n\t\tif (nfca_poll->rats_res_len > 0) {\n\t\t\tmemcpy(nfca_poll->rats_res,\n\t\t\t       data, nfca_poll->rats_res_len);\n\t\t}\n\t\tbreak;\n\n\tcase NCI_NFC_B_PASSIVE_POLL_MODE:\n\t\tnfcb_poll = &ntf->activation_params.nfcb_poll_iso_dep;\n\t\tnfcb_poll->attrib_res_len = *data++;\n\t\tpr_debug(\"attrib_res_len %d\\n\", nfcb_poll->attrib_res_len);\n\t\tif (nfcb_poll->attrib_res_len > 0) {\n\t\t\tmemcpy(nfcb_poll->attrib_res,\n\t\t\t       data, nfcb_poll->attrib_res_len);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tpr_err(\"unsupported activation_rf_tech_and_mode 0x%x\\n\",\n\t\t       ntf->activation_rf_tech_and_mode);\n\t\treturn NCI_STATUS_RF_PROTOCOL_ERROR;\n\t}\n\n\treturn NCI_STATUS_OK;\n}",
      "code_after_change": "static int nci_extract_activation_params_iso_dep(struct nci_dev *ndev,\n\t\t\tstruct nci_rf_intf_activated_ntf *ntf, __u8 *data)\n{\n\tstruct activation_params_nfca_poll_iso_dep *nfca_poll;\n\tstruct activation_params_nfcb_poll_iso_dep *nfcb_poll;\n\n\tswitch (ntf->activation_rf_tech_and_mode) {\n\tcase NCI_NFC_A_PASSIVE_POLL_MODE:\n\t\tnfca_poll = &ntf->activation_params.nfca_poll_iso_dep;\n\t\tnfca_poll->rats_res_len = min_t(__u8, *data++, 20);\n\t\tpr_debug(\"rats_res_len %d\\n\", nfca_poll->rats_res_len);\n\t\tif (nfca_poll->rats_res_len > 0) {\n\t\t\tmemcpy(nfca_poll->rats_res,\n\t\t\t       data, nfca_poll->rats_res_len);\n\t\t}\n\t\tbreak;\n\n\tcase NCI_NFC_B_PASSIVE_POLL_MODE:\n\t\tnfcb_poll = &ntf->activation_params.nfcb_poll_iso_dep;\n\t\tnfcb_poll->attrib_res_len = min_t(__u8, *data++, 50);\n\t\tpr_debug(\"attrib_res_len %d\\n\", nfcb_poll->attrib_res_len);\n\t\tif (nfcb_poll->attrib_res_len > 0) {\n\t\t\tmemcpy(nfcb_poll->attrib_res,\n\t\t\t       data, nfcb_poll->attrib_res_len);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tpr_err(\"unsupported activation_rf_tech_and_mode 0x%x\\n\",\n\t\t       ntf->activation_rf_tech_and_mode);\n\t\treturn NCI_STATUS_RF_PROTOCOL_ERROR;\n\t}\n\n\treturn NCI_STATUS_OK;\n}",
      "modified_lines": {
        "added": [
          "\t\tnfca_poll->rats_res_len = min_t(__u8, *data++, 20);",
          "\t\tnfcb_poll->attrib_res_len = min_t(__u8, *data++, 50);"
        ],
        "deleted": [
          "\t\tnfca_poll->rats_res_len = *data++;",
          "\t\tnfcb_poll->attrib_res_len = *data++;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of boundary checks on length fields read from incoming data, allowing for potential stack-based buffer overflows.",
      "trigger_condition": "Crafted length fields in incoming frames cause the code to read data beyond the bounds of the stack buffers, leading to a denial of service (crash) and potential arbitrary code execution.",
      "specific_code_behavior_causing_vulnerability": "The code directly reads length fields from incoming data without verifying or limiting their values, enabling attackers to manipulate the length fields to overflow the stack buffers.",
      "id": 12,
      "code_after_change_normalized": "static int FUN1(struct nci_dev *VAR1,\nstruct nci_rf_intf_activated_ntf *VAR2, __u8 *VAR3)\n{\nstruct activation_params_nfca_poll_iso_dep *VAR4;\nstruct activation_params_nfcb_poll_iso_dep *VAR5;\nswitch (VAR2->VAR6) {\ncase VAR7:\nVAR4 = &VAR2->VAR8.VAR9;\nVAR4->VAR10 = FUN2(VAR11, *VAR3++, 20);\nFUN3(\"STR\", VAR4->VAR10);\nif (VAR4->VAR10 > 0) {\nFUN4(VAR4->VAR12,\nVAR3, VAR4->VAR10);\n}\nbreak;\ncase VAR13:\nVAR5 = &VAR2->VAR8.VAR14;\nVAR5->VAR15 = FUN2(VAR11, *VAR3++, 50);\nFUN3(\"STR\", VAR5->VAR15);\nif (VAR5->VAR15 > 0) {\nFUN4(VAR5->VAR16,\nVAR3, VAR5->VAR15);\n}\nbreak;\ndefault:\nFUN5(\"STR\",\nVAR2->VAR6);\nreturn VAR17;\n}\nreturn VAR18;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct nci_dev *VAR1,\nstruct nci_rf_intf_activated_ntf *VAR2, __u8 *VAR3)\n{\nstruct activation_params_nfca_poll_iso_dep *VAR4;\nstruct activation_params_nfcb_poll_iso_dep *VAR5;\nswitch (VAR2->VAR6) {\ncase VAR7:\nVAR4 = &VAR2->VAR8.VAR9;\nVAR4->VAR10 = *VAR3++;\nFUN2(\"STR\", VAR4->VAR10);\nif (VAR4->VAR10 > 0) {\nFUN3(VAR4->VAR11,\nVAR3, VAR4->VAR10);\n}\nbreak;\ncase VAR12:\nVAR5 = &VAR2->VAR8.VAR13;\nVAR5->VAR14 = *VAR3++;\nFUN2(\"STR\", VAR5->VAR14);\nif (VAR5->VAR14 > 0) {\nFUN3(VAR5->VAR15,\nVAR3, VAR5->VAR14);\n}\nbreak;\ndefault:\nFUN4(\"STR\",\nVAR2->VAR6);\nreturn VAR16;\n}\nreturn VAR17;\n}\n",
      "code_after_change_raw": "static int nci_extract_activation_params_iso_dep(struct nci_dev *ndev,\nstruct nci_rf_intf_activated_ntf *ntf, __u8 *data)\n{\nstruct activation_params_nfca_poll_iso_dep *nfca_poll;\nstruct activation_params_nfcb_poll_iso_dep *nfcb_poll;\nswitch (ntf->activation_rf_tech_and_mode) {\ncase NCI_NFC_A_PASSIVE_POLL_MODE:\nnfca_poll = &ntf->activation_params.nfca_poll_iso_dep;\nnfca_poll->rats_res_len = min_t(__u8, *data++, 20);\npr_debug(\"rats_res_len %d\\n\", nfca_poll->rats_res_len);\nif (nfca_poll->rats_res_len > 0) {\nmemcpy(nfca_poll->rats_res,\ndata, nfca_poll->rats_res_len);\n}\nbreak;\ncase NCI_NFC_B_PASSIVE_POLL_MODE:\nnfcb_poll = &ntf->activation_params.nfcb_poll_iso_dep;\nnfcb_poll->attrib_res_len = min_t(__u8, *data++, 50);\npr_debug(\"attrib_res_len %d\\n\", nfcb_poll->attrib_res_len);\nif (nfcb_poll->attrib_res_len > 0) {\nmemcpy(nfcb_poll->attrib_res,\ndata, nfcb_poll->attrib_res_len);\n}\nbreak;\ndefault:\npr_err(\"unsupported activation_rf_tech_and_mode 0x%x\\n\",\nntf->activation_rf_tech_and_mode);\nreturn NCI_STATUS_RF_PROTOCOL_ERROR;\n}\nreturn NCI_STATUS_OK;\n}\n",
      "code_before_change_raw": "static int nci_extract_activation_params_iso_dep(struct nci_dev *ndev,\nstruct nci_rf_intf_activated_ntf *ntf, __u8 *data)\n{\nstruct activation_params_nfca_poll_iso_dep *nfca_poll;\nstruct activation_params_nfcb_poll_iso_dep *nfcb_poll;\nswitch (ntf->activation_rf_tech_and_mode) {\ncase NCI_NFC_A_PASSIVE_POLL_MODE:\nnfca_poll = &ntf->activation_params.nfca_poll_iso_dep;\nnfca_poll->rats_res_len = *data++;\npr_debug(\"rats_res_len %d\\n\", nfca_poll->rats_res_len);\nif (nfca_poll->rats_res_len > 0) {\nmemcpy(nfca_poll->rats_res,\ndata, nfca_poll->rats_res_len);\n}\nbreak;\ncase NCI_NFC_B_PASSIVE_POLL_MODE:\nnfcb_poll = &ntf->activation_params.nfcb_poll_iso_dep;\nnfcb_poll->attrib_res_len = *data++;\npr_debug(\"attrib_res_len %d\\n\", nfcb_poll->attrib_res_len);\nif (nfcb_poll->attrib_res_len > 0) {\nmemcpy(nfcb_poll->attrib_res,\ndata, nfcb_poll->attrib_res_len);\n}\nbreak;\ndefault:\npr_err(\"unsupported activation_rf_tech_and_mode 0x%x\\n\",\nntf->activation_rf_tech_and_mode);\nreturn NCI_STATUS_RF_PROTOCOL_ERROR;\n}\nreturn NCI_STATUS_OK;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper bounds checking for length fields in incoming frames, allowing for potential buffer overflows.",
        "trigger_condition": "Crafted length fields in incoming frames trigger buffer overflows, leading to denial of service and potential arbitrary code execution.",
        "specific_code_behavior_causing_vulnerability": "The code reads length fields directly from incoming data without proper bounds checking, potentially allowing for buffer overflows if the length values are manipulated in a malicious way."
      },
      "solution": "To mitigate the vulnerability, it is necessary to enforce bounds checking on the length fields read from incoming data. Specifically, the modification involves using the min_t macro to limit the value of the length field to a maximum size defined by NFC_NFCID1_MAXSIZE. This ensures that the length field is within a safe range and helps prevent buffer overflows. By adding this bounds checking, the code becomes more secure and less susceptible to attacks exploiting buffer overflows in the NCI interface.",
      "GPT_analysis": "The modification made to the code snippet is necessary to address the vulnerability CVE-2012-3364, which involves stack-based buffer overflows in the Near Field Communication Controller Interface (NCI) in the Linux kernel. \n\nIn the original code snippet, there are potential vulnerabilities due to unchecked buffer sizes when reading data from incoming frames. Specifically, the `nfcid1_len` and `sel_res_len` fields are read directly from the incoming data without proper bounds checking, which can lead to buffer overflows and potential security issues.\n\nThe modification addresses this vulnerability by using the `min_t` macro to limit the value of `nfcid1_len` to a maximum size defined by `NFC_NFCID1_MAXSIZE`. This ensures that the length field is within a safe range and helps prevent buffer overflows.\n\nBy making this modification, the code becomes more secure and less susceptible to attacks that exploit buffer overflows in the NCI interface. It helps to mitigate the risk of denial of service (crashes) and potential execution of arbitrary code through crafted length fields in incoming frames.",
      "GPT_purpose": "Extracting RF parameters for NFC-A passive polling from incoming data in an NCI device.",
      "GPT_function": "\n1. Extracts the sens_res and nfcid1_len values from the data.\n2. Copies nfcid1 data from the data buffer.\n3. Handles the sel_res_len and sel_res values from the data buffer.",
      "CVE_id": "CVE-2012-3364",
      "code_before_change": "static __u8 *nci_extract_rf_params_nfca_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfca_poll *nfca_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfca_poll->sens_res = __le16_to_cpu(*((__u16 *)data));\n\tdata += 2;\n\n\tnfca_poll->nfcid1_len = *data++;\n\n\tpr_debug(\"sens_res 0x%x, nfcid1_len %d\\n\",\n\t\t nfca_poll->sens_res, nfca_poll->nfcid1_len);\n\n\tmemcpy(nfca_poll->nfcid1, data, nfca_poll->nfcid1_len);\n\tdata += nfca_poll->nfcid1_len;\n\n\tnfca_poll->sel_res_len = *data++;\n\n\tif (nfca_poll->sel_res_len != 0)\n\t\tnfca_poll->sel_res = *data++;\n\n\tpr_debug(\"sel_res_len %d, sel_res 0x%x\\n\",\n\t\t nfca_poll->sel_res_len,\n\t\t nfca_poll->sel_res);\n\n\treturn data;\n}",
      "code_after_change": "static __u8 *nci_extract_rf_params_nfca_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfca_poll *nfca_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfca_poll->sens_res = __le16_to_cpu(*((__u16 *)data));\n\tdata += 2;\n\n\tnfca_poll->nfcid1_len = min_t(__u8, *data++, NFC_NFCID1_MAXSIZE);\n\n\tpr_debug(\"sens_res 0x%x, nfcid1_len %d\\n\",\n\t\t nfca_poll->sens_res, nfca_poll->nfcid1_len);\n\n\tmemcpy(nfca_poll->nfcid1, data, nfca_poll->nfcid1_len);\n\tdata += nfca_poll->nfcid1_len;\n\n\tnfca_poll->sel_res_len = *data++;\n\n\tif (nfca_poll->sel_res_len != 0)\n\t\tnfca_poll->sel_res = *data++;\n\n\tpr_debug(\"sel_res_len %d, sel_res 0x%x\\n\",\n\t\t nfca_poll->sel_res_len,\n\t\t nfca_poll->sel_res);\n\n\treturn data;\n}",
      "modified_lines": {
        "added": [
          "\tnfca_poll->nfcid1_len = min_t(__u8, *data++, NFC_NFCID1_MAXSIZE);"
        ],
        "deleted": [
          "\tnfca_poll->nfcid1_len = *data++;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper bounds checking for length fields in incoming frames, allowing for potential buffer overflows.",
      "trigger_condition": "Crafted length fields in incoming frames trigger buffer overflows, leading to denial of service and potential arbitrary code execution.",
      "specific_code_behavior_causing_vulnerability": "The code reads length fields directly from incoming data without proper bounds checking, potentially allowing for buffer overflows if the length values are manipulated in a malicious way.",
      "id": 13,
      "code_after_change_normalized": "static __u8 *FUN1(struct nci_dev *VAR1,\nstruct rf_tech_specific_params_nfca_poll *VAR2,\n__u8 *VAR3)\n{\nVAR2->VAR4 = FUN2(*((VAR5 *)VAR3));\nVAR3 += 2;\nVAR2->VAR6 = FUN3(VAR7, *VAR3++, VAR8);\nFUN4(\"STR\",\nVAR2->VAR4, VAR2->VAR6);\nFUN5(VAR2->VAR9, VAR3, VAR2->VAR6);\nVAR3 += VAR2->VAR6;\nVAR2->VAR10 = *VAR3++;\nif (VAR2->VAR10 != 0)\nVAR2->VAR11 = *VAR3++;\nFUN4(\"STR\",\nVAR2->VAR10,\nVAR2->VAR11);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static __u8 *FUN1(struct nci_dev *VAR1,\nstruct rf_tech_specific_params_nfca_poll *VAR2,\n__u8 *VAR3)\n{\nVAR2->VAR4 = FUN2(*((VAR5 *)VAR3));\nVAR3 += 2;\nVAR2->VAR6 = *VAR3++;\nFUN3(\"STR\",\nVAR2->VAR4, VAR2->VAR6);\nFUN4(VAR2->VAR7, VAR3, VAR2->VAR6);\nVAR3 += VAR2->VAR6;\nVAR2->VAR8 = *VAR3++;\nif (VAR2->VAR8 != 0)\nVAR2->VAR9 = *VAR3++;\nFUN3(\"STR\",\nVAR2->VAR8,\nVAR2->VAR9);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static __u8 *nci_extract_rf_params_nfca_passive_poll(struct nci_dev *ndev,\nstruct rf_tech_specific_params_nfca_poll *nfca_poll,\n__u8 *data)\n{\nnfca_poll->sens_res = __le16_to_cpu(*((__u16 *)data));\ndata += 2;\nnfca_poll->nfcid1_len = min_t(__u8, *data++, NFC_NFCID1_MAXSIZE);\npr_debug(\"sens_res 0x%x, nfcid1_len %d\\n\",\nnfca_poll->sens_res, nfca_poll->nfcid1_len);\nmemcpy(nfca_poll->nfcid1, data, nfca_poll->nfcid1_len);\ndata += nfca_poll->nfcid1_len;\nnfca_poll->sel_res_len = *data++;\nif (nfca_poll->sel_res_len != 0)\nnfca_poll->sel_res = *data++;\npr_debug(\"sel_res_len %d, sel_res 0x%x\\n\",\nnfca_poll->sel_res_len,\nnfca_poll->sel_res);\nreturn data;\n}\n",
      "code_before_change_raw": "static __u8 *nci_extract_rf_params_nfca_passive_poll(struct nci_dev *ndev,\nstruct rf_tech_specific_params_nfca_poll *nfca_poll,\n__u8 *data)\n{\nnfca_poll->sens_res = __le16_to_cpu(*((__u16 *)data));\ndata += 2;\nnfca_poll->nfcid1_len = *data++;\npr_debug(\"sens_res 0x%x, nfcid1_len %d\\n\",\nnfca_poll->sens_res, nfca_poll->nfcid1_len);\nmemcpy(nfca_poll->nfcid1, data, nfca_poll->nfcid1_len);\ndata += nfca_poll->nfcid1_len;\nnfca_poll->sel_res_len = *data++;\nif (nfca_poll->sel_res_len != 0)\nnfca_poll->sel_res = *data++;\npr_debug(\"sel_res_len %d, sel_res 0x%x\\n\",\nnfca_poll->sel_res_len,\nnfca_poll->sel_res);\nreturn data;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation and bounding of user-controlled input data.",
        "trigger_condition": "Receiving incoming frames with crafted length fields that exceed the bounds of the buffer, leading to a stack-based buffer overflow vulnerability.",
        "specific_code_behavior_causing_vulnerability": "Directly assigning the length field a value from user-controlled data without proper validation, allowing an attacker to manipulate the length field to trigger a buffer overflow."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation and bounding of user-controlled input data. In this case, the solution involves using the min_t macro to limit the length value to a predefined maximum size, preventing buffer overflows by restricting the length field within safe bounds.",
      "GPT_analysis": "The modification is necessary to prevent a stack-based buffer overflow vulnerability (CVE-2012-3364) in the code snippet. By using the `min_t` macro to limit the value of `nfcb_poll->sensb_res_len` to `NFC_SENSB_RES_MAXSIZE`, the code ensures that the length field is properly bounded and cannot be manipulated by an attacker to cause a buffer overflow.\n\nIn the original code snippet, the length field `nfcb_poll->sensb_res_len` is directly assigned the value of `*data++`, which could potentially be manipulated by an attacker to provide a crafted length value that exceeds the bounds of the `sensb_res` buffer. This could lead to a buffer overflow vulnerability, allowing an attacker to crash the system or potentially execute arbitrary code.\n\nBy using the `min_t` macro to limit the length value to `NFC_SENSB_RES_MAXSIZE`, the modified code ensures that the length field is within safe bounds, thereby mitigating the risk of a buffer overflow vulnerability.",
      "GPT_purpose": "Extracts RF parameters for NFC-B passive polling from the provided data.",
      "GPT_function": "\n1. Extracts RF parameters for NFC-B passive polling.\n2. Reads the length of sensb_res from the data.\n3. Copies sensb_res data from the data buffer using memcpy.",
      "CVE_id": "CVE-2012-3364",
      "code_before_change": "static __u8 *nci_extract_rf_params_nfcb_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfcb_poll *nfcb_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfcb_poll->sensb_res_len = *data++;\n\n\tpr_debug(\"sensb_res_len %d\\n\", nfcb_poll->sensb_res_len);\n\n\tmemcpy(nfcb_poll->sensb_res, data, nfcb_poll->sensb_res_len);\n\tdata += nfcb_poll->sensb_res_len;\n\n\treturn data;\n}",
      "code_after_change": "static __u8 *nci_extract_rf_params_nfcb_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfcb_poll *nfcb_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfcb_poll->sensb_res_len = min_t(__u8, *data++, NFC_SENSB_RES_MAXSIZE);\n\n\tpr_debug(\"sensb_res_len %d\\n\", nfcb_poll->sensb_res_len);\n\n\tmemcpy(nfcb_poll->sensb_res, data, nfcb_poll->sensb_res_len);\n\tdata += nfcb_poll->sensb_res_len;\n\n\treturn data;\n}",
      "modified_lines": {
        "added": [
          "\tnfcb_poll->sensb_res_len = min_t(__u8, *data++, NFC_SENSB_RES_MAXSIZE);"
        ],
        "deleted": [
          "\tnfcb_poll->sensb_res_len = *data++;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation and bounding of user-controlled input data.",
      "trigger_condition": "Receiving incoming frames with crafted length fields that exceed the bounds of the buffer, leading to a stack-based buffer overflow vulnerability.",
      "specific_code_behavior_causing_vulnerability": "Directly assigning the length field a value from user-controlled data without proper validation, allowing an attacker to manipulate the length field to trigger a buffer overflow.",
      "id": 14,
      "code_after_change_normalized": "static __u8 *FUN1(struct nci_dev *VAR1,\nstruct rf_tech_specific_params_nfcb_poll *VAR2,\n__u8 *VAR3)\n{\nVAR2->VAR4 = FUN2(VAR5, *VAR3++, VAR6);\nFUN3(\"STR\", VAR2->VAR4);\nFUN4(VAR2->VAR7, VAR3, VAR2->VAR4);\nVAR3 += VAR2->VAR4;\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static __u8 *FUN1(struct nci_dev *VAR1,\nstruct rf_tech_specific_params_nfcb_poll *VAR2,\n__u8 *VAR3)\n{\nVAR2->VAR4 = *VAR3++;\nFUN2(\"STR\", VAR2->VAR4);\nFUN3(VAR2->VAR5, VAR3, VAR2->VAR4);\nVAR3 += VAR2->VAR4;\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static __u8 *nci_extract_rf_params_nfcb_passive_poll(struct nci_dev *ndev,\nstruct rf_tech_specific_params_nfcb_poll *nfcb_poll,\n__u8 *data)\n{\nnfcb_poll->sensb_res_len = min_t(__u8, *data++, NFC_SENSB_RES_MAXSIZE);\npr_debug(\"sensb_res_len %d\\n\", nfcb_poll->sensb_res_len);\nmemcpy(nfcb_poll->sensb_res, data, nfcb_poll->sensb_res_len);\ndata += nfcb_poll->sensb_res_len;\nreturn data;\n}\n",
      "code_before_change_raw": "static __u8 *nci_extract_rf_params_nfcb_passive_poll(struct nci_dev *ndev,\nstruct rf_tech_specific_params_nfcb_poll *nfcb_poll,\n__u8 *data)\n{\nnfcb_poll->sensb_res_len = *data++;\npr_debug(\"sensb_res_len %d\\n\", nfcb_poll->sensb_res_len);\nmemcpy(nfcb_poll->sensb_res, data, nfcb_poll->sensb_res_len);\ndata += nfcb_poll->sensb_res_len;\nreturn data;\n}\n"
    }
  ],
  "CVE-2012-6704": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for negative values of sk_sndbuf and sk_rcvbuf in the sock_setsockopt function.",
        "trigger_condition": "A local user with CAP_NET_ADMIN capability crafts a setsockopt system call with the SO_SNDBUF or SO_RCVBUF option using negative values.",
        "specific_code_behavior_causing_vulnerability": "The code in the sock_setsockopt function does not properly handle negative values of sk_sndbuf and sk_rcvbuf, leading to memory corruption and system crash vulnerabilities when a setsockopt system call with negative values is made."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add proper checks and handling for negative values of sk_sndbuf and sk_rcvbuf in the sock_setsockopt function. By ensuring that negative values are handled correctly, the code can prevent memory corruption and system crashes caused by malicious input. In this case, the solution involves adding checks to validate and handle negative values of sk_sndbuf and sk_rcvbuf before proceeding with further processing in the sock_setsockopt function.",
      "GPT_analysis": "The modification is necessary to address the vulnerability described in CVE-2012-6704. The vulnerability arises from mishandling negative values of sk_sndbuf and sk_rcvbuf in the sock_setsockopt function, which can lead to a denial of service (memory corruption and system crash) or other unspecified impacts when a crafted setsockopt system call with the SO_SNDBUF or SO_RCVBUF option is made by a local user leveraging the CAP_NET_ADMIN capability.\n\nTo fix this vulnerability, the modification ensures that negative values of sk_sndbuf and sk_rcvbuf are properly handled in the sock_getsockopt function. By checking for negative values and handling them appropriately, the vulnerability can be mitigated, preventing potential memory corruption and system crashes that could be caused by malicious input.\n\nTherefore, the modification is necessary to enhance the security and stability of the system by addressing the vulnerability and preventing potential exploitation by attackers.",
      "GPT_purpose": "Retrieve socket options for a given socket.",
      "GPT_function": "\n1. Retrieve socket options using getsockopt.\n2. Handle various socket options such as SO_DEBUG, SO_DONTROUTE, SO_BROADCAST, etc.\n3. Copy the retrieved option value to user space.\n4. Handle specific cases like SO_PEERCRED, SO_PEERNAME, SO_MARK, etc.\n5. Check for negative values of sk_sndbuf and sk_rcvbuf.",
      "CVE_id": "CVE-2012-6704",
      "code_before_change": "int sock_getsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\n\tunion {\n\t\tint val;\n\t\tstruct linger ling;\n\t\tstruct timeval tm;\n\t} v;\n\n\tint lv = sizeof(int);\n\tint len;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\tmemset(&v, 0, sizeof(v));\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tv.val = sock_flag(sk, SOCK_DBG);\n\t\tbreak;\n\n\tcase SO_DONTROUTE:\n\t\tv.val = sock_flag(sk, SOCK_LOCALROUTE);\n\t\tbreak;\n\n\tcase SO_BROADCAST:\n\t\tv.val = !!sock_flag(sk, SOCK_BROADCAST);\n\t\tbreak;\n\n\tcase SO_SNDBUF:\n\t\tv.val = sk->sk_sndbuf;\n\t\tbreak;\n\n\tcase SO_RCVBUF:\n\t\tv.val = sk->sk_rcvbuf;\n\t\tbreak;\n\n\tcase SO_REUSEADDR:\n\t\tv.val = sk->sk_reuse;\n\t\tbreak;\n\n\tcase SO_KEEPALIVE:\n\t\tv.val = !!sock_flag(sk, SOCK_KEEPOPEN);\n\t\tbreak;\n\n\tcase SO_TYPE:\n\t\tv.val = sk->sk_type;\n\t\tbreak;\n\n\tcase SO_PROTOCOL:\n\t\tv.val = sk->sk_protocol;\n\t\tbreak;\n\n\tcase SO_DOMAIN:\n\t\tv.val = sk->sk_family;\n\t\tbreak;\n\n\tcase SO_ERROR:\n\t\tv.val = -sock_error(sk);\n\t\tif (v.val == 0)\n\t\t\tv.val = xchg(&sk->sk_err_soft, 0);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tv.val = !!sock_flag(sk, SOCK_URGINLINE);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tv.val = sk->sk_no_check;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tv.val = sk->sk_priority;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tlv\t\t= sizeof(v.ling);\n\t\tv.ling.l_onoff\t= !!sock_flag(sk, SOCK_LINGER);\n\t\tv.ling.l_linger\t= sk->sk_lingertime / HZ;\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"getsockopt\");\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMP) &&\n\t\t\t\t!sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_TIMESTAMPNS:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tv.val = 0;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_TX_HARDWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_TX_SOFTWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_RX_HARDWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_RX_SOFTWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_RX_SOFTWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_SOFTWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_SOFTWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_SYS_HARDWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_RAW_HARDWARE;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tlv = sizeof(struct timeval);\n\t\tif (sk->sk_rcvtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_rcvtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_rcvtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tlv = sizeof(struct timeval);\n\t\tif (sk->sk_sndtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_sndtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_sndtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tv.val = sk->sk_rcvlowat;\n\t\tbreak;\n\n\tcase SO_SNDLOWAT:\n\t\tv.val = 1;\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tv.val = test_bit(SOCK_PASSCRED, &sock->flags) ? 1 : 0;\n\t\tbreak;\n\n\tcase SO_PEERCRED:\n\t{\n\t\tstruct ucred peercred;\n\t\tif (len > sizeof(peercred))\n\t\t\tlen = sizeof(peercred);\n\t\tcred_to_ucred(sk->sk_peer_pid, sk->sk_peer_cred, &peercred);\n\t\tif (copy_to_user(optval, &peercred, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\t}\n\n\tcase SO_PEERNAME:\n\t{\n\t\tchar address[128];\n\n\t\tif (sock->ops->getname(sock, (struct sockaddr *)address, &lv, 2))\n\t\t\treturn -ENOTCONN;\n\t\tif (lv < len)\n\t\t\treturn -EINVAL;\n\t\tif (copy_to_user(optval, address, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\t}\n\n\t/* Dubious BSD thing... Probably nobody even uses it, but\n\t * the UNIX standard wants it for whatever reason... -DaveM\n\t */\n\tcase SO_ACCEPTCONN:\n\t\tv.val = sk->sk_state == TCP_LISTEN;\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tv.val = test_bit(SOCK_PASSSEC, &sock->flags) ? 1 : 0;\n\t\tbreak;\n\n\tcase SO_PEERSEC:\n\t\treturn security_socket_getpeersec_stream(sock, optval, optlen, len);\n\n\tcase SO_MARK:\n\t\tv.val = sk->sk_mark;\n\t\tbreak;\n\n\tcase SO_RXQ_OVFL:\n\t\tv.val = !!sock_flag(sk, SOCK_RXQ_OVFL);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tv.val = !!sock_flag(sk, SOCK_WIFI_STATUS);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (!sock->ops->set_peek_off)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tv.val = sk->sk_peek_off;\n\t\tbreak;\n\tcase SO_NOFCS:\n\t\tv.val = !!sock_flag(sk, SOCK_NOFCS);\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\tif (len > lv)\n\t\tlen = lv;\n\tif (copy_to_user(optval, &v, len))\n\t\treturn -EFAULT;\nlenout:\n\tif (put_user(len, optlen))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
      "code_after_change": "int sock_getsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\n\tunion {\n\t\tint val;\n\t\tstruct linger ling;\n\t\tstruct timeval tm;\n\t} v;\n\n\tint lv = sizeof(int);\n\tint len;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\tmemset(&v, 0, sizeof(v));\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tv.val = sock_flag(sk, SOCK_DBG);\n\t\tbreak;\n\n\tcase SO_DONTROUTE:\n\t\tv.val = sock_flag(sk, SOCK_LOCALROUTE);\n\t\tbreak;\n\n\tcase SO_BROADCAST:\n\t\tv.val = !!sock_flag(sk, SOCK_BROADCAST);\n\t\tbreak;\n\n\tcase SO_SNDBUF:\n\t\tv.val = sk->sk_sndbuf;\n\t\tbreak;\n\n\tcase SO_RCVBUF:\n\t\tv.val = sk->sk_rcvbuf;\n\t\tbreak;\n\n\tcase SO_REUSEADDR:\n\t\tv.val = sk->sk_reuse;\n\t\tbreak;\n\n\tcase SO_KEEPALIVE:\n\t\tv.val = !!sock_flag(sk, SOCK_KEEPOPEN);\n\t\tbreak;\n\n\tcase SO_TYPE:\n\t\tv.val = sk->sk_type;\n\t\tbreak;\n\n\tcase SO_PROTOCOL:\n\t\tv.val = sk->sk_protocol;\n\t\tbreak;\n\n\tcase SO_DOMAIN:\n\t\tv.val = sk->sk_family;\n\t\tbreak;\n\n\tcase SO_ERROR:\n\t\tv.val = -sock_error(sk);\n\t\tif (v.val == 0)\n\t\t\tv.val = xchg(&sk->sk_err_soft, 0);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tv.val = !!sock_flag(sk, SOCK_URGINLINE);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tv.val = sk->sk_no_check;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tv.val = sk->sk_priority;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tlv\t\t= sizeof(v.ling);\n\t\tv.ling.l_onoff\t= !!sock_flag(sk, SOCK_LINGER);\n\t\tv.ling.l_linger\t= sk->sk_lingertime / HZ;\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"getsockopt\");\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMP) &&\n\t\t\t\t!sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_TIMESTAMPNS:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tv.val = 0;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_TX_HARDWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_TX_SOFTWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_RX_HARDWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_RX_SOFTWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_RX_SOFTWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_SOFTWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_SOFTWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_SYS_HARDWARE;\n\t\tif (sock_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE))\n\t\t\tv.val |= SOF_TIMESTAMPING_RAW_HARDWARE;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tlv = sizeof(struct timeval);\n\t\tif (sk->sk_rcvtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_rcvtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_rcvtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tlv = sizeof(struct timeval);\n\t\tif (sk->sk_sndtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_sndtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_sndtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tv.val = sk->sk_rcvlowat;\n\t\tbreak;\n\n\tcase SO_SNDLOWAT:\n\t\tv.val = 1;\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tv.val = !!test_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_PEERCRED:\n\t{\n\t\tstruct ucred peercred;\n\t\tif (len > sizeof(peercred))\n\t\t\tlen = sizeof(peercred);\n\t\tcred_to_ucred(sk->sk_peer_pid, sk->sk_peer_cred, &peercred);\n\t\tif (copy_to_user(optval, &peercred, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\t}\n\n\tcase SO_PEERNAME:\n\t{\n\t\tchar address[128];\n\n\t\tif (sock->ops->getname(sock, (struct sockaddr *)address, &lv, 2))\n\t\t\treturn -ENOTCONN;\n\t\tif (lv < len)\n\t\t\treturn -EINVAL;\n\t\tif (copy_to_user(optval, address, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\t}\n\n\t/* Dubious BSD thing... Probably nobody even uses it, but\n\t * the UNIX standard wants it for whatever reason... -DaveM\n\t */\n\tcase SO_ACCEPTCONN:\n\t\tv.val = sk->sk_state == TCP_LISTEN;\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tv.val = !!test_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\n\tcase SO_PEERSEC:\n\t\treturn security_socket_getpeersec_stream(sock, optval, optlen, len);\n\n\tcase SO_MARK:\n\t\tv.val = sk->sk_mark;\n\t\tbreak;\n\n\tcase SO_RXQ_OVFL:\n\t\tv.val = !!sock_flag(sk, SOCK_RXQ_OVFL);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tv.val = !!sock_flag(sk, SOCK_WIFI_STATUS);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (!sock->ops->set_peek_off)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tv.val = sk->sk_peek_off;\n\t\tbreak;\n\tcase SO_NOFCS:\n\t\tv.val = !!sock_flag(sk, SOCK_NOFCS);\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\tif (len > lv)\n\t\tlen = lv;\n\tif (copy_to_user(optval, &v, len))\n\t\treturn -EFAULT;\nlenout:\n\tif (put_user(len, optlen))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\tv.val = !!test_bit(SOCK_PASSCRED, &sock->flags);",
          "\t\tv.val = !!test_bit(SOCK_PASSSEC, &sock->flags);"
        ],
        "deleted": [
          "\t\tv.val = test_bit(SOCK_PASSCRED, &sock->flags) ? 1 : 0;",
          "\t\tv.val = test_bit(SOCK_PASSSEC, &sock->flags) ? 1 : 0;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for negative values of sk_sndbuf and sk_rcvbuf in the sock_setsockopt function.",
      "trigger_condition": "A local user with CAP_NET_ADMIN capability crafts a setsockopt system call with the SO_SNDBUF or SO_RCVBUF option using negative values.",
      "specific_code_behavior_causing_vulnerability": "The code in the sock_setsockopt function does not properly handle negative values of sk_sndbuf and sk_rcvbuf, leading to memory corruption and system crash vulnerabilities when a setsockopt system call with negative values is made.",
      "id": 15,
      "code_after_change_normalized": "int FUN1(struct socket *VAR1, int VAR2, int VAR3,\nchar __user *VAR4, int __user *VAR5)\n{\nstruct VAR1 *VAR6 = VAR1->VAR6;\nunion {\nint VAR7;\nstruct linger VAR8;\nstruct timeval VAR9;\n} VAR10;\nint VAR11 = sizeof(int);\nint VAR12;\nif (FUN2(VAR12, VAR5))\nreturn -VAR13;\nif (VAR12 < 0)\nreturn -VAR14;\nFUN3(&VAR10, 0, sizeof(VAR10));\nswitch (VAR3) {\ncase VAR15:\nVAR10.VAR7 = FUN4(VAR6, VAR16);\nbreak;\ncase VAR17:\nVAR10.VAR7 = FUN4(VAR6, VAR18);\nbreak;\ncase VAR19:\nVAR10.VAR7 = !!FUN4(VAR6, VAR20);\nbreak;\ncase VAR21:\nVAR10.VAR7 = VAR6->VAR22;\nbreak;\ncase VAR23:\nVAR10.VAR7 = VAR6->VAR24;\nbreak;\ncase VAR25:\nVAR10.VAR7 = VAR6->VAR26;\nbreak;\ncase VAR27:\nVAR10.VAR7 = !!FUN4(VAR6, VAR28);\nbreak;\ncase VAR29:\nVAR10.VAR7 = VAR6->VAR30;\nbreak;\ncase VAR31:\nVAR10.VAR7 = VAR6->VAR32;\nbreak;\ncase VAR33:\nVAR10.VAR7 = VAR6->VAR34;\nbreak;\ncase VAR35:\nVAR10.VAR7 = -FUN5(VAR6);\nif (VAR10.VAR7 == 0)\nVAR10.VAR7 = FUN6(&VAR6->VAR36, 0);\nbreak;\ncase VAR37:\nVAR10.VAR7 = !!FUN4(VAR6, VAR38);\nbreak;\ncase VAR39:\nVAR10.VAR7 = VAR6->VAR40;\nbreak;\ncase VAR41:\nVAR10.VAR7 = VAR6->VAR42;\nbreak;\ncase VAR43:\nVAR11\t\t= sizeof(VAR10.VAR8);\nVAR10.VAR8.VAR44\t= !!FUN4(VAR6, VAR45);\nVAR10.VAR8.VAR46\t= VAR6->VAR47 / VAR48;\nbreak;\ncase VAR49:\nFUN7(\"STR\");\nbreak;\ncase VAR50:\nVAR10.VAR7 = FUN4(VAR6, VAR51) &&\n!FUN4(VAR6, VAR52);\nbreak;\ncase VAR53:\nVAR10.VAR7 = FUN4(VAR6, VAR52);\nbreak;\ncase VAR54:\nVAR10.VAR7 = 0;\nif (FUN4(VAR6, VAR55))\nVAR10.VAR7 |= VAR56;\nif (FUN4(VAR6, VAR57))\nVAR10.VAR7 |= VAR58;\nif (FUN4(VAR6, VAR59))\nVAR10.VAR7 |= VAR60;\nif (FUN4(VAR6, VAR61))\nVAR10.VAR7 |= VAR62;\nif (FUN4(VAR6, VAR63))\nVAR10.VAR7 |= VAR64;\nif (FUN4(VAR6, VAR65))\nVAR10.VAR7 |= VAR66;\nif (FUN4(VAR6, VAR67))\nVAR10.VAR7 |= VAR68;\nbreak;\ncase VAR69:\nVAR11 = sizeof(struct VAR70);\nif (VAR6->VAR71 == VAR72) {\nVAR10.VAR9.VAR73 = 0;\nVAR10.VAR9.VAR74 = 0;\n} else {\nVAR10.VAR9.VAR73 = VAR6->VAR71 / VAR48;\nVAR10.VAR9.VAR74 = ((VAR6->VAR71 % VAR48) * 1000000) / VAR48;\n}\nbreak;\ncase VAR75:\nVAR11 = sizeof(struct VAR70);\nif (VAR6->VAR76 == VAR72) {\nVAR10.VAR9.VAR73 = 0;\nVAR10.VAR9.VAR74 = 0;\n} else {\nVAR10.VAR9.VAR73 = VAR6->VAR76 / VAR48;\nVAR10.VAR9.VAR74 = ((VAR6->VAR76 % VAR48) * 1000000) / VAR48;\n}\nbreak;\ncase VAR77:\nVAR10.VAR7 = VAR6->VAR78;\nbreak;\ncase VAR79:\nVAR10.VAR7 = 1;\nbreak;\ncase VAR80:\nVAR10.VAR7 = !!FUN8(VAR81, &VAR1->VAR82);\nbreak;\ncase VAR83:\n{\nstruct ucred VAR84;\nif (VAR12 > sizeof(VAR84))\nVAR12 = sizeof(VAR84);\nFUN9(VAR6->VAR85, VAR6->VAR86, &VAR84);\nif (FUN10(VAR4, &VAR84, VAR12))\nreturn -VAR13;\ngoto VAR87;\n}\ncase VAR88:\n{\nchar VAR89[128];\nif (VAR1->VAR90->FUN11(VAR1, (struct VAR91 *)VAR89, &VAR11, 2))\nreturn -VAR92;\nif (VAR11 < VAR12)\nreturn -VAR14;\nif (FUN10(VAR4, VAR89, VAR12))\nreturn -VAR13;\ngoto VAR87;\n}\ncase VAR93:\nVAR10.VAR7 = VAR6->VAR94 == VAR95;\nbreak;\ncase VAR96:\nVAR10.VAR7 = !!FUN8(VAR97, &VAR1->VAR82);\nbreak;\ncase VAR98:\nreturn FUN12(VAR1, VAR4, VAR5, VAR12);\ncase VAR99:\nVAR10.VAR7 = VAR6->VAR100;\nbreak;\ncase VAR101:\nVAR10.VAR7 = !!FUN4(VAR6, VAR102);\nbreak;\ncase VAR103:\nVAR10.VAR7 = !!FUN4(VAR6, VAR104);\nbreak;\ncase VAR105:\nif (!VAR1->VAR90->VAR106)\nreturn -VAR107;\nVAR10.VAR7 = VAR6->VAR108;\nbreak;\ncase VAR109:\nVAR10.VAR7 = !!FUN4(VAR6, VAR110);\nbreak;\ndefault:\nreturn -VAR111;\n}\nif (VAR12 > VAR11)\nVAR12 = VAR11;\nif (FUN10(VAR4, &VAR10, VAR12))\nreturn -VAR13;\nVAR87:\nif (FUN13(VAR12, VAR5))\nreturn -VAR13;\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(struct socket *VAR1, int VAR2, int VAR3,\nchar __user *VAR4, int __user *VAR5)\n{\nstruct VAR1 *VAR6 = VAR1->VAR6;\nunion {\nint VAR7;\nstruct linger VAR8;\nstruct timeval VAR9;\n} VAR10;\nint VAR11 = sizeof(int);\nint VAR12;\nif (FUN2(VAR12, VAR5))\nreturn -VAR13;\nif (VAR12 < 0)\nreturn -VAR14;\nFUN3(&VAR10, 0, sizeof(VAR10));\nswitch (VAR3) {\ncase VAR15:\nVAR10.VAR7 = FUN4(VAR6, VAR16);\nbreak;\ncase VAR17:\nVAR10.VAR7 = FUN4(VAR6, VAR18);\nbreak;\ncase VAR19:\nVAR10.VAR7 = !!FUN4(VAR6, VAR20);\nbreak;\ncase VAR21:\nVAR10.VAR7 = VAR6->VAR22;\nbreak;\ncase VAR23:\nVAR10.VAR7 = VAR6->VAR24;\nbreak;\ncase VAR25:\nVAR10.VAR7 = VAR6->VAR26;\nbreak;\ncase VAR27:\nVAR10.VAR7 = !!FUN4(VAR6, VAR28);\nbreak;\ncase VAR29:\nVAR10.VAR7 = VAR6->VAR30;\nbreak;\ncase VAR31:\nVAR10.VAR7 = VAR6->VAR32;\nbreak;\ncase VAR33:\nVAR10.VAR7 = VAR6->VAR34;\nbreak;\ncase VAR35:\nVAR10.VAR7 = -FUN5(VAR6);\nif (VAR10.VAR7 == 0)\nVAR10.VAR7 = FUN6(&VAR6->VAR36, 0);\nbreak;\ncase VAR37:\nVAR10.VAR7 = !!FUN4(VAR6, VAR38);\nbreak;\ncase VAR39:\nVAR10.VAR7 = VAR6->VAR40;\nbreak;\ncase VAR41:\nVAR10.VAR7 = VAR6->VAR42;\nbreak;\ncase VAR43:\nVAR11\t\t= sizeof(VAR10.VAR8);\nVAR10.VAR8.VAR44\t= !!FUN4(VAR6, VAR45);\nVAR10.VAR8.VAR46\t= VAR6->VAR47 / VAR48;\nbreak;\ncase VAR49:\nFUN7(\"STR\");\nbreak;\ncase VAR50:\nVAR10.VAR7 = FUN4(VAR6, VAR51) &&\n!FUN4(VAR6, VAR52);\nbreak;\ncase VAR53:\nVAR10.VAR7 = FUN4(VAR6, VAR52);\nbreak;\ncase VAR54:\nVAR10.VAR7 = 0;\nif (FUN4(VAR6, VAR55))\nVAR10.VAR7 |= VAR56;\nif (FUN4(VAR6, VAR57))\nVAR10.VAR7 |= VAR58;\nif (FUN4(VAR6, VAR59))\nVAR10.VAR7 |= VAR60;\nif (FUN4(VAR6, VAR61))\nVAR10.VAR7 |= VAR62;\nif (FUN4(VAR6, VAR63))\nVAR10.VAR7 |= VAR64;\nif (FUN4(VAR6, VAR65))\nVAR10.VAR7 |= VAR66;\nif (FUN4(VAR6, VAR67))\nVAR10.VAR7 |= VAR68;\nbreak;\ncase VAR69:\nVAR11 = sizeof(struct VAR70);\nif (VAR6->VAR71 == VAR72) {\nVAR10.VAR9.VAR73 = 0;\nVAR10.VAR9.VAR74 = 0;\n} else {\nVAR10.VAR9.VAR73 = VAR6->VAR71 / VAR48;\nVAR10.VAR9.VAR74 = ((VAR6->VAR71 % VAR48) * 1000000) / VAR48;\n}\nbreak;\ncase VAR75:\nVAR11 = sizeof(struct VAR70);\nif (VAR6->VAR76 == VAR72) {\nVAR10.VAR9.VAR73 = 0;\nVAR10.VAR9.VAR74 = 0;\n} else {\nVAR10.VAR9.VAR73 = VAR6->VAR76 / VAR48;\nVAR10.VAR9.VAR74 = ((VAR6->VAR76 % VAR48) * 1000000) / VAR48;\n}\nbreak;\ncase VAR77:\nVAR10.VAR7 = VAR6->VAR78;\nbreak;\ncase VAR79:\nVAR10.VAR7 = 1;\nbreak;\ncase VAR80:\nVAR10.VAR7 = FUN8(VAR81, &VAR1->VAR82) ? 1 : 0;\nbreak;\ncase VAR83:\n{\nstruct ucred VAR84;\nif (VAR12 > sizeof(VAR84))\nVAR12 = sizeof(VAR84);\nFUN9(VAR6->VAR85, VAR6->VAR86, &VAR84);\nif (FUN10(VAR4, &VAR84, VAR12))\nreturn -VAR13;\ngoto VAR87;\n}\ncase VAR88:\n{\nchar VAR89[128];\nif (VAR1->VAR90->FUN11(VAR1, (struct VAR91 *)VAR89, &VAR11, 2))\nreturn -VAR92;\nif (VAR11 < VAR12)\nreturn -VAR14;\nif (FUN10(VAR4, VAR89, VAR12))\nreturn -VAR13;\ngoto VAR87;\n}\ncase VAR93:\nVAR10.VAR7 = VAR6->VAR94 == VAR95;\nbreak;\ncase VAR96:\nVAR10.VAR7 = FUN8(VAR97, &VAR1->VAR82) ? 1 : 0;\nbreak;\ncase VAR98:\nreturn FUN12(VAR1, VAR4, VAR5, VAR12);\ncase VAR99:\nVAR10.VAR7 = VAR6->VAR100;\nbreak;\ncase VAR101:\nVAR10.VAR7 = !!FUN4(VAR6, VAR102);\nbreak;\ncase VAR103:\nVAR10.VAR7 = !!FUN4(VAR6, VAR104);\nbreak;\ncase VAR105:\nif (!VAR1->VAR90->VAR106)\nreturn -VAR107;\nVAR10.VAR7 = VAR6->VAR108;\nbreak;\ncase VAR109:\nVAR10.VAR7 = !!FUN4(VAR6, VAR110);\nbreak;\ndefault:\nreturn -VAR111;\n}\nif (VAR12 > VAR11)\nVAR12 = VAR11;\nif (FUN10(VAR4, &VAR10, VAR12))\nreturn -VAR13;\nVAR87:\nif (FUN13(VAR12, VAR5))\nreturn -VAR13;\nreturn 0;\n}\n",
      "code_after_change_raw": "int sock_getsockopt(struct socket *sock, int level, int optname,\nchar __user *optval, int __user *optlen)\n{\nstruct sock *sk = sock->sk;\nunion {\nint val;\nstruct linger ling;\nstruct timeval tm;\n} v;\nint lv = sizeof(int);\nint len;\nif (get_user(len, optlen))\nreturn -EFAULT;\nif (len < 0)\nreturn -EINVAL;\nmemset(&v, 0, sizeof(v));\nswitch (optname) {\ncase SO_DEBUG:\nv.val = sock_flag(sk, SOCK_DBG);\nbreak;\ncase SO_DONTROUTE:\nv.val = sock_flag(sk, SOCK_LOCALROUTE);\nbreak;\ncase SO_BROADCAST:\nv.val = !!sock_flag(sk, SOCK_BROADCAST);\nbreak;\ncase SO_SNDBUF:\nv.val = sk->sk_sndbuf;\nbreak;\ncase SO_RCVBUF:\nv.val = sk->sk_rcvbuf;\nbreak;\ncase SO_REUSEADDR:\nv.val = sk->sk_reuse;\nbreak;\ncase SO_KEEPALIVE:\nv.val = !!sock_flag(sk, SOCK_KEEPOPEN);\nbreak;\ncase SO_TYPE:\nv.val = sk->sk_type;\nbreak;\ncase SO_PROTOCOL:\nv.val = sk->sk_protocol;\nbreak;\ncase SO_DOMAIN:\nv.val = sk->sk_family;\nbreak;\ncase SO_ERROR:\nv.val = -sock_error(sk);\nif (v.val == 0)\nv.val = xchg(&sk->sk_err_soft, 0);\nbreak;\ncase SO_OOBINLINE:\nv.val = !!sock_flag(sk, SOCK_URGINLINE);\nbreak;\ncase SO_NO_CHECK:\nv.val = sk->sk_no_check;\nbreak;\ncase SO_PRIORITY:\nv.val = sk->sk_priority;\nbreak;\ncase SO_LINGER:\nlv\t\t= sizeof(v.ling);\nv.ling.l_onoff\t= !!sock_flag(sk, SOCK_LINGER);\nv.ling.l_linger\t= sk->sk_lingertime / HZ;\nbreak;\ncase SO_BSDCOMPAT:\nsock_warn_obsolete_bsdism(\"getsockopt\");\nbreak;\ncase SO_TIMESTAMP:\nv.val = sock_flag(sk, SOCK_RCVTSTAMP) &&\n!sock_flag(sk, SOCK_RCVTSTAMPNS);\nbreak;\ncase SO_TIMESTAMPNS:\nv.val = sock_flag(sk, SOCK_RCVTSTAMPNS);\nbreak;\ncase SO_TIMESTAMPING:\nv.val = 0;\nif (sock_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE))\nv.val |= SOF_TIMESTAMPING_TX_HARDWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE))\nv.val |= SOF_TIMESTAMPING_TX_SOFTWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE))\nv.val |= SOF_TIMESTAMPING_RX_HARDWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_RX_SOFTWARE))\nv.val |= SOF_TIMESTAMPING_RX_SOFTWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_SOFTWARE))\nv.val |= SOF_TIMESTAMPING_SOFTWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE))\nv.val |= SOF_TIMESTAMPING_SYS_HARDWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE))\nv.val |= SOF_TIMESTAMPING_RAW_HARDWARE;\nbreak;\ncase SO_RCVTIMEO:\nlv = sizeof(struct timeval);\nif (sk->sk_rcvtimeo == MAX_SCHEDULE_TIMEOUT) {\nv.tm.tv_sec = 0;\nv.tm.tv_usec = 0;\n} else {\nv.tm.tv_sec = sk->sk_rcvtimeo / HZ;\nv.tm.tv_usec = ((sk->sk_rcvtimeo % HZ) * 1000000) / HZ;\n}\nbreak;\ncase SO_SNDTIMEO:\nlv = sizeof(struct timeval);\nif (sk->sk_sndtimeo == MAX_SCHEDULE_TIMEOUT) {\nv.tm.tv_sec = 0;\nv.tm.tv_usec = 0;\n} else {\nv.tm.tv_sec = sk->sk_sndtimeo / HZ;\nv.tm.tv_usec = ((sk->sk_sndtimeo % HZ) * 1000000) / HZ;\n}\nbreak;\ncase SO_RCVLOWAT:\nv.val = sk->sk_rcvlowat;\nbreak;\ncase SO_SNDLOWAT:\nv.val = 1;\nbreak;\ncase SO_PASSCRED:\nv.val = !!test_bit(SOCK_PASSCRED, &sock->flags);\nbreak;\ncase SO_PEERCRED:\n{\nstruct ucred peercred;\nif (len > sizeof(peercred))\nlen = sizeof(peercred);\ncred_to_ucred(sk->sk_peer_pid, sk->sk_peer_cred, &peercred);\nif (copy_to_user(optval, &peercred, len))\nreturn -EFAULT;\ngoto lenout;\n}\ncase SO_PEERNAME:\n{\nchar address[128];\nif (sock->ops->getname(sock, (struct sockaddr *)address, &lv, 2))\nreturn -ENOTCONN;\nif (lv < len)\nreturn -EINVAL;\nif (copy_to_user(optval, address, len))\nreturn -EFAULT;\ngoto lenout;\n}\ncase SO_ACCEPTCONN:\nv.val = sk->sk_state == TCP_LISTEN;\nbreak;\ncase SO_PASSSEC:\nv.val = !!test_bit(SOCK_PASSSEC, &sock->flags);\nbreak;\ncase SO_PEERSEC:\nreturn security_socket_getpeersec_stream(sock, optval, optlen, len);\ncase SO_MARK:\nv.val = sk->sk_mark;\nbreak;\ncase SO_RXQ_OVFL:\nv.val = !!sock_flag(sk, SOCK_RXQ_OVFL);\nbreak;\ncase SO_WIFI_STATUS:\nv.val = !!sock_flag(sk, SOCK_WIFI_STATUS);\nbreak;\ncase SO_PEEK_OFF:\nif (!sock->ops->set_peek_off)\nreturn -EOPNOTSUPP;\nv.val = sk->sk_peek_off;\nbreak;\ncase SO_NOFCS:\nv.val = !!sock_flag(sk, SOCK_NOFCS);\nbreak;\ndefault:\nreturn -ENOPROTOOPT;\n}\nif (len > lv)\nlen = lv;\nif (copy_to_user(optval, &v, len))\nreturn -EFAULT;\nlenout:\nif (put_user(len, optlen))\nreturn -EFAULT;\nreturn 0;\n}\n",
      "code_before_change_raw": "int sock_getsockopt(struct socket *sock, int level, int optname,\nchar __user *optval, int __user *optlen)\n{\nstruct sock *sk = sock->sk;\nunion {\nint val;\nstruct linger ling;\nstruct timeval tm;\n} v;\nint lv = sizeof(int);\nint len;\nif (get_user(len, optlen))\nreturn -EFAULT;\nif (len < 0)\nreturn -EINVAL;\nmemset(&v, 0, sizeof(v));\nswitch (optname) {\ncase SO_DEBUG:\nv.val = sock_flag(sk, SOCK_DBG);\nbreak;\ncase SO_DONTROUTE:\nv.val = sock_flag(sk, SOCK_LOCALROUTE);\nbreak;\ncase SO_BROADCAST:\nv.val = !!sock_flag(sk, SOCK_BROADCAST);\nbreak;\ncase SO_SNDBUF:\nv.val = sk->sk_sndbuf;\nbreak;\ncase SO_RCVBUF:\nv.val = sk->sk_rcvbuf;\nbreak;\ncase SO_REUSEADDR:\nv.val = sk->sk_reuse;\nbreak;\ncase SO_KEEPALIVE:\nv.val = !!sock_flag(sk, SOCK_KEEPOPEN);\nbreak;\ncase SO_TYPE:\nv.val = sk->sk_type;\nbreak;\ncase SO_PROTOCOL:\nv.val = sk->sk_protocol;\nbreak;\ncase SO_DOMAIN:\nv.val = sk->sk_family;\nbreak;\ncase SO_ERROR:\nv.val = -sock_error(sk);\nif (v.val == 0)\nv.val = xchg(&sk->sk_err_soft, 0);\nbreak;\ncase SO_OOBINLINE:\nv.val = !!sock_flag(sk, SOCK_URGINLINE);\nbreak;\ncase SO_NO_CHECK:\nv.val = sk->sk_no_check;\nbreak;\ncase SO_PRIORITY:\nv.val = sk->sk_priority;\nbreak;\ncase SO_LINGER:\nlv\t\t= sizeof(v.ling);\nv.ling.l_onoff\t= !!sock_flag(sk, SOCK_LINGER);\nv.ling.l_linger\t= sk->sk_lingertime / HZ;\nbreak;\ncase SO_BSDCOMPAT:\nsock_warn_obsolete_bsdism(\"getsockopt\");\nbreak;\ncase SO_TIMESTAMP:\nv.val = sock_flag(sk, SOCK_RCVTSTAMP) &&\n!sock_flag(sk, SOCK_RCVTSTAMPNS);\nbreak;\ncase SO_TIMESTAMPNS:\nv.val = sock_flag(sk, SOCK_RCVTSTAMPNS);\nbreak;\ncase SO_TIMESTAMPING:\nv.val = 0;\nif (sock_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE))\nv.val |= SOF_TIMESTAMPING_TX_HARDWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE))\nv.val |= SOF_TIMESTAMPING_TX_SOFTWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE))\nv.val |= SOF_TIMESTAMPING_RX_HARDWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_RX_SOFTWARE))\nv.val |= SOF_TIMESTAMPING_RX_SOFTWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_SOFTWARE))\nv.val |= SOF_TIMESTAMPING_SOFTWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE))\nv.val |= SOF_TIMESTAMPING_SYS_HARDWARE;\nif (sock_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE))\nv.val |= SOF_TIMESTAMPING_RAW_HARDWARE;\nbreak;\ncase SO_RCVTIMEO:\nlv = sizeof(struct timeval);\nif (sk->sk_rcvtimeo == MAX_SCHEDULE_TIMEOUT) {\nv.tm.tv_sec = 0;\nv.tm.tv_usec = 0;\n} else {\nv.tm.tv_sec = sk->sk_rcvtimeo / HZ;\nv.tm.tv_usec = ((sk->sk_rcvtimeo % HZ) * 1000000) / HZ;\n}\nbreak;\ncase SO_SNDTIMEO:\nlv = sizeof(struct timeval);\nif (sk->sk_sndtimeo == MAX_SCHEDULE_TIMEOUT) {\nv.tm.tv_sec = 0;\nv.tm.tv_usec = 0;\n} else {\nv.tm.tv_sec = sk->sk_sndtimeo / HZ;\nv.tm.tv_usec = ((sk->sk_sndtimeo % HZ) * 1000000) / HZ;\n}\nbreak;\ncase SO_RCVLOWAT:\nv.val = sk->sk_rcvlowat;\nbreak;\ncase SO_SNDLOWAT:\nv.val = 1;\nbreak;\ncase SO_PASSCRED:\nv.val = test_bit(SOCK_PASSCRED, &sock->flags) ? 1 : 0;\nbreak;\ncase SO_PEERCRED:\n{\nstruct ucred peercred;\nif (len > sizeof(peercred))\nlen = sizeof(peercred);\ncred_to_ucred(sk->sk_peer_pid, sk->sk_peer_cred, &peercred);\nif (copy_to_user(optval, &peercred, len))\nreturn -EFAULT;\ngoto lenout;\n}\ncase SO_PEERNAME:\n{\nchar address[128];\nif (sock->ops->getname(sock, (struct sockaddr *)address, &lv, 2))\nreturn -ENOTCONN;\nif (lv < len)\nreturn -EINVAL;\nif (copy_to_user(optval, address, len))\nreturn -EFAULT;\ngoto lenout;\n}\ncase SO_ACCEPTCONN:\nv.val = sk->sk_state == TCP_LISTEN;\nbreak;\ncase SO_PASSSEC:\nv.val = test_bit(SOCK_PASSSEC, &sock->flags) ? 1 : 0;\nbreak;\ncase SO_PEERSEC:\nreturn security_socket_getpeersec_stream(sock, optval, optlen, len);\ncase SO_MARK:\nv.val = sk->sk_mark;\nbreak;\ncase SO_RXQ_OVFL:\nv.val = !!sock_flag(sk, SOCK_RXQ_OVFL);\nbreak;\ncase SO_WIFI_STATUS:\nv.val = !!sock_flag(sk, SOCK_WIFI_STATUS);\nbreak;\ncase SO_PEEK_OFF:\nif (!sock->ops->set_peek_off)\nreturn -EOPNOTSUPP;\nv.val = sk->sk_peek_off;\nbreak;\ncase SO_NOFCS:\nv.val = !!sock_flag(sk, SOCK_NOFCS);\nbreak;\ndefault:\nreturn -ENOPROTOOPT;\n}\nif (len > lv)\nlen = lv;\nif (copy_to_user(optval, &v, len))\nreturn -EFAULT;\nlenout:\nif (put_user(len, optlen))\nreturn -EFAULT;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2012-6712": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for return value assignment in a specific function call.",
        "trigger_condition": "The code assigns a fixed value to a variable instead of capturing the return value of a function, leading to potential memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The vulnerable code snippet assigns a fixed value of 0 to a variable instead of capturing the return value of a function call. This behavior can result in memory corruption due to a buffer overflow vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the return value of the function call is properly captured and assigned to the variable. In this case, the solution involves modifying the code to assign the return value of the function call to the variable instead of using a fixed value. By doing so, the code handles the function return value correctly, reducing the risk of memory corruption.",
      "GPT_analysis": "The modification is necessary to fix a buffer overflow vulnerability in the code snippet. By changing the line `ret = 0;` to `ret = iwl_sta_ucode_activate(priv, sta_id);`, we ensure that the `ret` variable is assigned the return value of the `iwl_sta_ucode_activate` function. This change helps prevent potential memory corruption that could occur due to the buffer overflow vulnerability described in CVE-2012-6712.\n\nBy updating the code in this way, we address the vulnerability by correctly handling the return value of the `iwl_sta_ucode_activate` function, which is a safer and more secure approach compared to assigning a fixed value of 0 to the `ret` variable.",
      "GPT_purpose": "Process the response for adding a station in an Intel wireless driver and handle different status cases.",
      "GPT_function": "\n1. Process the response for adding a station.\n2. Check for errors in the response packet.\n3. Handle different status cases for adding a station.\n4. Activate the station in the microcode.\n5. Log error messages for different failure cases.\n6. Log debug information about the station and its address.",
      "CVE_id": "CVE-2012-6712",
      "code_before_change": "static int iwl_process_add_sta_resp(struct iwl_priv *priv,\n\t\t\t\t    struct iwl_addsta_cmd *addsta,\n\t\t\t\t    struct iwl_rx_packet *pkt)\n{\n\tu8 sta_id = addsta->sta.sta_id;\n\tunsigned long flags;\n\tint ret = -EIO;\n\n\tif (pkt->hdr.flags & IWL_CMD_FAILED_MSK) {\n\t\tIWL_ERR(priv, \"Bad return from REPLY_ADD_STA (0x%08X)\\n\",\n\t\t\tpkt->hdr.flags);\n\t\treturn ret;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"Processing response for adding station %u\\n\",\n\t\t       sta_id);\n\n\tspin_lock_irqsave(&priv->shrd->sta_lock, flags);\n\n\tswitch (pkt->u.add_sta.status) {\n\tcase ADD_STA_SUCCESS_MSK:\n\t\tIWL_DEBUG_INFO(priv, \"REPLY_ADD_STA PASSED\\n\");\n\t\tiwl_sta_ucode_activate(priv, sta_id);\n\t\tret = 0;\n\t\tbreak;\n\tcase ADD_STA_NO_ROOM_IN_TABLE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no room in table.\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tcase ADD_STA_NO_BLOCK_ACK_RESOURCE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no block ack \"\n\t\t\t\"resource.\\n\", sta_id);\n\t\tbreak;\n\tcase ADD_STA_MODIFY_NON_EXIST_STA:\n\t\tIWL_ERR(priv, \"Attempting to modify non-existing station %d\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tdefault:\n\t\tIWL_DEBUG_ASSOC(priv, \"Received REPLY_ADD_STA:(0x%08X)\\n\",\n\t\t\t\tpkt->u.add_sta.status);\n\t\tbreak;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"%s station id %u addr %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ?  \"Modified\" : \"Added\",\n\t\t       sta_id, priv->stations[sta_id].sta.sta.addr);\n\n\t/*\n\t * XXX: The MAC address in the command buffer is often changed from\n\t * the original sent to the device. That is, the MAC address\n\t * written to the command buffer often is not the same MAC address\n\t * read from the command buffer when the command returns. This\n\t * issue has not yet been resolved and this debugging is left to\n\t * observe the problem.\n\t */\n\tIWL_DEBUG_INFO(priv, \"%s station according to cmd buffer %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ? \"Modified\" : \"Added\",\n\t\t       addsta->sta.addr);\n\tspin_unlock_irqrestore(&priv->shrd->sta_lock, flags);\n\n\treturn ret;\n}",
      "code_after_change": "static int iwl_process_add_sta_resp(struct iwl_priv *priv,\n\t\t\t\t    struct iwl_addsta_cmd *addsta,\n\t\t\t\t    struct iwl_rx_packet *pkt)\n{\n\tu8 sta_id = addsta->sta.sta_id;\n\tunsigned long flags;\n\tint ret = -EIO;\n\n\tif (pkt->hdr.flags & IWL_CMD_FAILED_MSK) {\n\t\tIWL_ERR(priv, \"Bad return from REPLY_ADD_STA (0x%08X)\\n\",\n\t\t\tpkt->hdr.flags);\n\t\treturn ret;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"Processing response for adding station %u\\n\",\n\t\t       sta_id);\n\n\tspin_lock_irqsave(&priv->shrd->sta_lock, flags);\n\n\tswitch (pkt->u.add_sta.status) {\n\tcase ADD_STA_SUCCESS_MSK:\n\t\tIWL_DEBUG_INFO(priv, \"REPLY_ADD_STA PASSED\\n\");\n\t\tret = iwl_sta_ucode_activate(priv, sta_id);\n\t\tbreak;\n\tcase ADD_STA_NO_ROOM_IN_TABLE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no room in table.\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tcase ADD_STA_NO_BLOCK_ACK_RESOURCE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no block ack \"\n\t\t\t\"resource.\\n\", sta_id);\n\t\tbreak;\n\tcase ADD_STA_MODIFY_NON_EXIST_STA:\n\t\tIWL_ERR(priv, \"Attempting to modify non-existing station %d\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tdefault:\n\t\tIWL_DEBUG_ASSOC(priv, \"Received REPLY_ADD_STA:(0x%08X)\\n\",\n\t\t\t\tpkt->u.add_sta.status);\n\t\tbreak;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"%s station id %u addr %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ?  \"Modified\" : \"Added\",\n\t\t       sta_id, priv->stations[sta_id].sta.sta.addr);\n\n\t/*\n\t * XXX: The MAC address in the command buffer is often changed from\n\t * the original sent to the device. That is, the MAC address\n\t * written to the command buffer often is not the same MAC address\n\t * read from the command buffer when the command returns. This\n\t * issue has not yet been resolved and this debugging is left to\n\t * observe the problem.\n\t */\n\tIWL_DEBUG_INFO(priv, \"%s station according to cmd buffer %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ? \"Modified\" : \"Added\",\n\t\t       addsta->sta.addr);\n\tspin_unlock_irqrestore(&priv->shrd->sta_lock, flags);\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\t\tret = iwl_sta_ucode_activate(priv, sta_id);"
        ],
        "deleted": [
          "\t\tiwl_sta_ucode_activate(priv, sta_id);",
          "\t\tret = 0;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for return value assignment in a specific function call.",
      "trigger_condition": "The code assigns a fixed value to a variable instead of capturing the return value of a function, leading to potential memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The vulnerable code snippet assigns a fixed value of 0 to a variable instead of capturing the return value of a function call. This behavior can result in memory corruption due to a buffer overflow vulnerability.",
      "id": 16,
      "code_after_change_normalized": "static int FUN1(struct iwl_priv *VAR1,\nstruct iwl_addsta_cmd *VAR2,\nstruct iwl_rx_packet *VAR3)\n{\nu8 VAR4 = VAR2->VAR5.VAR4;\nunsigned long VAR6;\nint VAR7 = -VAR8;\nif (VAR3->VAR9.VAR6 & VAR10) {\nFUN2(VAR1, \"STR\",\nVAR3->VAR9.VAR6);\nreturn VAR7;\n}\nFUN3(VAR1, \"STR\",\nVAR4);\nFUN4(&VAR1->VAR11->VAR12, VAR6);\nswitch (VAR3->VAR13.VAR14.VAR15) {\ncase VAR16:\nFUN3(VAR1, \"STR\");\nVAR7 = FUN5(VAR1, VAR4);\nbreak;\ncase VAR17:\nFUN2(VAR1, \"STR\",\nVAR4);\nbreak;\ncase VAR18:\nFUN2(VAR1, \"STR\"\n\"STR\", VAR4);\nbreak;\ncase VAR19:\nFUN2(VAR1, \"STR\",\nVAR4);\nbreak;\ndefault:\nFUN6(VAR1, \"STR\",\nVAR3->VAR13.VAR14.VAR15);\nbreak;\n}\nFUN3(VAR1, \"STR\",\nVAR1->VAR20[VAR4].VAR5.VAR21 ==\nVAR22 ?  \"STR\" : \"STR\",\nVAR4, VAR1->VAR20[VAR4].VAR5.VAR5.VAR23);\nFUN3(VAR1, \"STR\",\nVAR1->VAR20[VAR4].VAR5.VAR21 ==\nVAR22 ? \"STR\" : \"STR\",\nVAR2->VAR5.VAR23);\nFUN7(&VAR1->VAR11->VAR12, VAR6);\nreturn VAR7;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct iwl_priv *VAR1,\nstruct iwl_addsta_cmd *VAR2,\nstruct iwl_rx_packet *VAR3)\n{\nu8 VAR4 = VAR2->VAR5.VAR4;\nunsigned long VAR6;\nint VAR7 = -VAR8;\nif (VAR3->VAR9.VAR6 & VAR10) {\nFUN2(VAR1, \"STR\",\nVAR3->VAR9.VAR6);\nreturn VAR7;\n}\nFUN3(VAR1, \"STR\",\nVAR4);\nFUN4(&VAR1->VAR11->VAR12, VAR6);\nswitch (VAR3->VAR13.VAR14.VAR15) {\ncase VAR16:\nFUN3(VAR1, \"STR\");\nFUN5(VAR1, VAR4);\nVAR7 = 0;\nbreak;\ncase VAR17:\nFUN2(VAR1, \"STR\",\nVAR4);\nbreak;\ncase VAR18:\nFUN2(VAR1, \"STR\"\n\"STR\", VAR4);\nbreak;\ncase VAR19:\nFUN2(VAR1, \"STR\",\nVAR4);\nbreak;\ndefault:\nFUN6(VAR1, \"STR\",\nVAR3->VAR13.VAR14.VAR15);\nbreak;\n}\nFUN3(VAR1, \"STR\",\nVAR1->VAR20[VAR4].VAR5.VAR21 ==\nVAR22 ?  \"STR\" : \"STR\",\nVAR4, VAR1->VAR20[VAR4].VAR5.VAR5.VAR23);\nFUN3(VAR1, \"STR\",\nVAR1->VAR20[VAR4].VAR5.VAR21 ==\nVAR22 ? \"STR\" : \"STR\",\nVAR2->VAR5.VAR23);\nFUN7(&VAR1->VAR11->VAR12, VAR6);\nreturn VAR7;\n}\n",
      "code_after_change_raw": "static int iwl_process_add_sta_resp(struct iwl_priv *priv,\nstruct iwl_addsta_cmd *addsta,\nstruct iwl_rx_packet *pkt)\n{\nu8 sta_id = addsta->sta.sta_id;\nunsigned long flags;\nint ret = -EIO;\nif (pkt->hdr.flags & IWL_CMD_FAILED_MSK) {\nIWL_ERR(priv, \"Bad return from REPLY_ADD_STA (0x%08X)\\n\",\npkt->hdr.flags);\nreturn ret;\n}\nIWL_DEBUG_INFO(priv, \"Processing response for adding station %u\\n\",\nsta_id);\nspin_lock_irqsave(&priv->shrd->sta_lock, flags);\nswitch (pkt->u.add_sta.status) {\ncase ADD_STA_SUCCESS_MSK:\nIWL_DEBUG_INFO(priv, \"REPLY_ADD_STA PASSED\\n\");\nret = iwl_sta_ucode_activate(priv, sta_id);\nbreak;\ncase ADD_STA_NO_ROOM_IN_TABLE:\nIWL_ERR(priv, \"Adding station %d failed, no room in table.\\n\",\nsta_id);\nbreak;\ncase ADD_STA_NO_BLOCK_ACK_RESOURCE:\nIWL_ERR(priv, \"Adding station %d failed, no block ack \"\n\"resource.\\n\", sta_id);\nbreak;\ncase ADD_STA_MODIFY_NON_EXIST_STA:\nIWL_ERR(priv, \"Attempting to modify non-existing station %d\\n\",\nsta_id);\nbreak;\ndefault:\nIWL_DEBUG_ASSOC(priv, \"Received REPLY_ADD_STA:(0x%08X)\\n\",\npkt->u.add_sta.status);\nbreak;\n}\nIWL_DEBUG_INFO(priv, \"%s station id %u addr %pM\\n\",\npriv->stations[sta_id].sta.mode ==\nSTA_CONTROL_MODIFY_MSK ?  \"Modified\" : \"Added\",\nsta_id, priv->stations[sta_id].sta.sta.addr);\nIWL_DEBUG_INFO(priv, \"%s station according to cmd buffer %pM\\n\",\npriv->stations[sta_id].sta.mode ==\nSTA_CONTROL_MODIFY_MSK ? \"Modified\" : \"Added\",\naddsta->sta.addr);\nspin_unlock_irqrestore(&priv->shrd->sta_lock, flags);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int iwl_process_add_sta_resp(struct iwl_priv *priv,\nstruct iwl_addsta_cmd *addsta,\nstruct iwl_rx_packet *pkt)\n{\nu8 sta_id = addsta->sta.sta_id;\nunsigned long flags;\nint ret = -EIO;\nif (pkt->hdr.flags & IWL_CMD_FAILED_MSK) {\nIWL_ERR(priv, \"Bad return from REPLY_ADD_STA (0x%08X)\\n\",\npkt->hdr.flags);\nreturn ret;\n}\nIWL_DEBUG_INFO(priv, \"Processing response for adding station %u\\n\",\nsta_id);\nspin_lock_irqsave(&priv->shrd->sta_lock, flags);\nswitch (pkt->u.add_sta.status) {\ncase ADD_STA_SUCCESS_MSK:\nIWL_DEBUG_INFO(priv, \"REPLY_ADD_STA PASSED\\n\");\niwl_sta_ucode_activate(priv, sta_id);\nret = 0;\nbreak;\ncase ADD_STA_NO_ROOM_IN_TABLE:\nIWL_ERR(priv, \"Adding station %d failed, no room in table.\\n\",\nsta_id);\nbreak;\ncase ADD_STA_NO_BLOCK_ACK_RESOURCE:\nIWL_ERR(priv, \"Adding station %d failed, no block ack \"\n\"resource.\\n\", sta_id);\nbreak;\ncase ADD_STA_MODIFY_NON_EXIST_STA:\nIWL_ERR(priv, \"Attempting to modify non-existing station %d\\n\",\nsta_id);\nbreak;\ndefault:\nIWL_DEBUG_ASSOC(priv, \"Received REPLY_ADD_STA:(0x%08X)\\n\",\npkt->u.add_sta.status);\nbreak;\n}\nIWL_DEBUG_INFO(priv, \"%s station id %u addr %pM\\n\",\npriv->stations[sta_id].sta.mode ==\nSTA_CONTROL_MODIFY_MSK ?  \"Modified\" : \"Added\",\nsta_id, priv->stations[sta_id].sta.sta.addr);\nIWL_DEBUG_INFO(priv, \"%s station according to cmd buffer %pM\\n\",\npriv->stations[sta_id].sta.mode ==\nSTA_CONTROL_MODIFY_MSK ? \"Modified\" : \"Added\",\naddsta->sta.addr);\nspin_unlock_irqrestore(&priv->shrd->sta_lock, flags);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2013-0231": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Inadequate rate limiting of kernel log messages in response to a specific event, allowing guest OS users with PCI device access to flood the logs and cause a denial of service.",
        "trigger_condition": "Guest OS users with PCI device access generate a large number of kernel log messages, overwhelming the system and leading to a denial of service condition.",
        "specific_code_behavior_causing_vulnerability": "The code uses printk to log messages without rate limiting, making it susceptible to abuse by allowing excessive log messages to be generated by unauthorized users, leading to a denial of service.",
        "solution": "To mitigate the vulnerability, the code has been modified to use pr_warn_ratelimited instead of printk for logging messages related to enabling MSI. This change introduces rate limiting to control the number of log messages generated, preventing unauthorized users from flooding the logs and causing a denial of service. Additionally, the error message format has been updated for clarity and consistency."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-0231, which allows guest OS users with PCI device access to cause a denial of service by generating a large number of kernel log messages. \n\nThe vulnerability is mitigated by replacing the printk statement with pr_warn_ratelimited, which limits the rate at which log messages are printed. This change prevents the excessive logging that could lead to a denial of service condition. \n\nAdditionally, the error message format has been updated for consistency and clarity. The modification ensures that error messages are logged appropriately without exposing the system to potential abuse by malicious users.",
      "GPT_purpose": "Enable MSI (Message Signaled Interrupts) for a PCI device in a Xen environment.",
      "GPT_function": "\n1. Enable MSI for a PCI device.\n2. Log debug messages if verbose mode is enabled.\n3. Handle errors during MSI enablement.\n4. Set the value needed by the guest as the IDT vector.\n5. Acknowledge interrupts if device data is available.",
      "CVE_id": "CVE-2013-0231",
      "code_before_change": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\n\t\t\t struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint otherend = pdev->xdev->otherend_id;\n\tint status;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\n\n\tstatus = pci_enable_msi(dev);\n\n\tif (status) {\n\t\tprintk(KERN_ERR \"error enable msi for guest %x status %x\\n\",\n\t\t\totherend, status);\n\t\top->value = 0;\n\t\treturn XEN_PCI_ERR_op_failed;\n\t}\n\n\t/* The value the guest needs is actually the IDT vector, not the\n\t * the local domain's IRQ number. */\n\n\top->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\n\t\t\top->value);\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn 0;\n}",
      "code_after_change": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\n\t\t\t struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint status;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\n\n\tstatus = pci_enable_msi(dev);\n\n\tif (status) {\n\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI for guest %u: err %d\\n\",\n\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,\n\t\t\t\t    status);\n\t\top->value = 0;\n\t\treturn XEN_PCI_ERR_op_failed;\n\t}\n\n\t/* The value the guest needs is actually the IDT vector, not the\n\t * the local domain's IRQ number. */\n\n\top->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\n\t\t\top->value);\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI for guest %u: err %d\\n\",",
          "\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,",
          "\t\t\t\t    status);"
        ],
        "deleted": [
          "\tint otherend = pdev->xdev->otherend_id;",
          "\t\tprintk(KERN_ERR \"error enable msi for guest %x status %x\\n\",",
          "\t\t\totherend, status);"
        ]
      },
      "preconditions_for_vulnerability": "Inadequate rate limiting of kernel log messages in response to a specific event, allowing guest OS users with PCI device access to flood the logs and cause a denial of service.",
      "trigger_condition": "Guest OS users with PCI device access generate a large number of kernel log messages, overwhelming the system and leading to a denial of service condition.",
      "specific_code_behavior_causing_vulnerability": "The code uses printk to log messages without rate limiting, making it susceptible to abuse by allowing excessive log messages to be generated by unauthorized users, leading to a denial of service.",
      "solution": "To mitigate the vulnerability, the code has been modified to use pr_warn_ratelimited instead of printk for logging messages related to enabling MSI. This change introduces rate limiting to control the number of log messages generated, preventing unauthorized users from flooding the logs and causing a denial of service. Additionally, the error message format has been updated for clarity and consistency.",
      "id": 17,
      "code_after_change_normalized": "int FUN1(struct xen_pcibk_device *VAR1,\nstruct pci_dev *VAR2, struct xen_pci_op *VAR3)\n{\nstruct xen_pcibk_dev_data *VAR4;\nint VAR5;\nif (FUN2(VAR6))\nFUN3(KERN_DEBUG VAR7 \"STR\", FUN4(VAR2));\nVAR5 = FUN5(VAR2);\nif (VAR5) {\nFUN6(VAR7 \"STR\",\nFUN4(VAR2), VAR1->VAR8->VAR9,\nVAR5);\nVAR3->VAR10 = 0;\nreturn VAR11;\n}\nVAR3->VAR10 = VAR2->VAR12 ? FUN7(VAR2->VAR12) : 0;\nif (FUN2(VAR6))\nFUN3(KERN_DEBUG VAR7 \"STR\", FUN4(VAR2),\nVAR3->VAR10);\nVAR4 = FUN8(VAR2);\nif (VAR4)\nVAR4->VAR13 = 0;\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(struct xen_pcibk_device *VAR1,\nstruct pci_dev *VAR2, struct xen_pci_op *VAR3)\n{\nstruct xen_pcibk_dev_data *VAR4;\nint VAR5 = VAR1->VAR6->VAR7;\nint VAR8;\nif (FUN2(VAR9))\nFUN3(KERN_DEBUG VAR10 \"STR\", FUN4(VAR2));\nVAR8 = FUN5(VAR2);\nif (VAR8) {\nFUN3(VAR11 \"STR\",\nVAR5, VAR8);\nVAR3->VAR12 = 0;\nreturn VAR13;\n}\nVAR3->VAR12 = VAR2->VAR14 ? FUN6(VAR2->VAR14) : 0;\nif (FUN2(VAR9))\nFUN3(KERN_DEBUG VAR10 \"STR\", FUN4(VAR2),\nVAR3->VAR12);\nVAR4 = FUN7(VAR2);\nif (VAR4)\nVAR4->VAR15 = 0;\nreturn 0;\n}\n",
      "code_after_change_raw": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\nstruct pci_dev *dev, struct xen_pci_op *op)\n{\nstruct xen_pcibk_dev_data *dev_data;\nint status;\nif (unlikely(verbose_request))\nprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\nstatus = pci_enable_msi(dev);\nif (status) {\npr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI for guest %u: err %d\\n\",\npci_name(dev), pdev->xdev->otherend_id,\nstatus);\nop->value = 0;\nreturn XEN_PCI_ERR_op_failed;\n}\nop->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\nif (unlikely(verbose_request))\nprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\nop->value);\ndev_data = pci_get_drvdata(dev);\nif (dev_data)\ndev_data->ack_intr = 0;\nreturn 0;\n}\n",
      "code_before_change_raw": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\nstruct pci_dev *dev, struct xen_pci_op *op)\n{\nstruct xen_pcibk_dev_data *dev_data;\nint otherend = pdev->xdev->otherend_id;\nint status;\nif (unlikely(verbose_request))\nprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\nstatus = pci_enable_msi(dev);\nif (status) {\nprintk(KERN_ERR \"error enable msi for guest %x status %x\\n\",\notherend, status);\nop->value = 0;\nreturn XEN_PCI_ERR_op_failed;\n}\nop->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\nif (unlikely(verbose_request))\nprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\nop->value);\ndev_data = pci_get_drvdata(dev);\nif (dev_data)\ndev_data->ack_intr = 0;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2013-0309": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper support for PROT_NONE memory regions when transparent huge pages are used.",
        "trigger_condition": "Local users execute a crafted application that interacts with memory regions marked as PROT_NONE.",
        "specific_code_behavior_causing_vulnerability": "The code snippet only checks for the _PAGE_PRESENT flag to determine page presence, which is insufficient when transparent huge pages are used. This can lead to a denial of service (system crash) due to improper handling of PROT_NONE memory regions."
      },
      "solution": "To mitigate the vulnerability, it is necessary to modify the code to include checks for _PAGE_PROTNONE and _PAGE_PSE flags in addition to _PAGE_PRESENT. This ensures proper support for PROT_NONE memory regions and transparent huge pages. The modified code snippet accurately determines page presence in scenarios involving transparent huge pages, preventing the denial of service vulnerability.",
      "GPT_analysis": "The modification to the code snippet is necessary to address the vulnerability CVE-2013-0309 related to transparent huge pages not properly supporting PROT_NONE memory regions. \n\nThe original code snippet only checks for the _PAGE_PRESENT flag when determining if a page is present. However, in the presence of transparent huge pages, the _PAGE_PRESENT flag may not accurately reflect the presence of a page due to the use of huge pages. \n\nThe modified code snippet adds the _PAGE_PROTNONE flag and _PAGE_PSE flag to the check. The _PAGE_PROTNONE flag is necessary to properly support PROT_NONE memory regions, and the _PAGE_PSE flag is needed because split_huge_page may temporarily clear the present bit while keeping the _PAGE_PSE flag set. \n\nBy including these additional flags in the check, the modified code snippet ensures that it accurately determines the presence of a page in scenarios involving transparent huge pages, thereby addressing the vulnerability and preventing a denial of service caused by a system crash.",
      "GPT_purpose": "Check if the page middle directory (pmd) is present by examining its flags.",
      "GPT_function": "\n1. Checks if the page middle directory (pmd) is present.\n2. Returns true if the page middle directory is present, false otherwise.",
      "CVE_id": "CVE-2013-0309",
      "code_before_change": "static inline int pmd_present(pmd_t pmd)\n{\n\treturn pmd_flags(pmd) & _PAGE_PRESENT;\n}",
      "code_after_change": "static inline int pmd_present(pmd_t pmd)\n{\n\t/*\n\t * Checking for _PAGE_PSE is needed too because\n\t * split_huge_page will temporarily clear the present bit (but\n\t * the _PAGE_PSE flag will remain set at all times while the\n\t * _PAGE_PRESENT bit is clear).\n\t */\n\treturn pmd_flags(pmd) & (_PAGE_PRESENT | _PAGE_PROTNONE | _PAGE_PSE);\n}",
      "modified_lines": {
        "added": [
          "\t/*",
          "\t * Checking for _PAGE_PSE is needed too because",
          "\t * split_huge_page will temporarily clear the present bit (but",
          "\t * the _PAGE_PSE flag will remain set at all times while the",
          "\t * _PAGE_PRESENT bit is clear).",
          "\t */",
          "\treturn pmd_flags(pmd) & (_PAGE_PRESENT | _PAGE_PROTNONE | _PAGE_PSE);"
        ],
        "deleted": [
          "\treturn pmd_flags(pmd) & _PAGE_PRESENT;"
        ]
      },
      "preconditions_for_vulnerability": "Improper support for PROT_NONE memory regions when transparent huge pages are used.",
      "trigger_condition": "Local users execute a crafted application that interacts with memory regions marked as PROT_NONE.",
      "specific_code_behavior_causing_vulnerability": "The code snippet only checks for the _PAGE_PRESENT flag to determine page presence, which is insufficient when transparent huge pages are used. This can lead to a denial of service (system crash) due to improper handling of PROT_NONE memory regions.",
      "id": 18,
      "code_after_change_normalized": "static inline int FUN1(pmd_t VAR1)\n{\nreturn FUN2(VAR1) & (VAR2 | VAR3 | VAR4);\n}\n",
      "code_before_change_normalized": "static inline int FUN1(pmd_t VAR1)\n{\nreturn FUN2(VAR1) & VAR2;\n}\n",
      "code_after_change_raw": "static inline int pmd_present(pmd_t pmd)\n{\nreturn pmd_flags(pmd) & (_PAGE_PRESENT | _PAGE_PROTNONE | _PAGE_PSE);\n}\n",
      "code_before_change_raw": "static inline int pmd_present(pmd_t pmd)\n{\nreturn pmd_flags(pmd) & _PAGE_PRESENT;\n}\n"
    }
  ],
  "CVE-2013-0310": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for the incoming interface in the CIPSO_V4_TAG_LOCAL case.",
        "trigger_condition": "An attacker sets the IPOPT_CIPSO IP_OPTIONS using a system call, causing the code to process the CIPSO_V4_TAG_LOCAL tag without verifying the incoming interface, potentially leading to unauthorized access or system instability.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the incoming interface is the loopback device before processing the CIPSO_V4_TAG_LOCAL tag, allowing the tag to be handled without proper validation, which can result in security vulnerabilities and system crashes."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the incoming interface is the loopback device before processing the CIPSO_V4_TAG_LOCAL tag. Additionally, a check should be included to reject the tag if the socket buffer is NULL, indicating an invalid state. These checks enhance security by preventing unauthorized use of the CIPSO_V4_TAG_LOCAL tag and improving system stability.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2013-0310, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impacts via an IPOPT_CIPSO IP_OPTIONS setsockopt system call.\n\nThe vulnerability arises from the lack of validation for the incoming interface in the CIPSO_V4_TAG_LOCAL case. By allowing the tag to be processed without checking if the incoming interface is the loopback device, the code is exposed to potential issues when handling network packets.\n\nThe modification adds a check to ensure that the incoming interface is the loopback device before processing the CIPSO_V4_TAG_LOCAL tag. Additionally, it includes a check to reject the tag if the skb (socket buffer) is NULL, indicating an invalid state. These checks help prevent unauthorized or malicious use of the CIPSO_V4_TAG_LOCAL tag, thereby enhancing the security and stability of the system.",
      "GPT_purpose": "Validate CIPSO options in an IPv4 packet header.",
      "GPT_function": "\n1. Validate CIPSO options in an IPv4 packet.\n2. Check the length of the CIPSO options.\n3. Search for the CIPSO Domain of Interpretation (DOI).\n4. Verify and process different types of CIPSO tags.\n5. Handle non-standard CIPSO tags for local connections.\n6. Return an error offset in case of validation failure.",
      "CVE_id": "CVE-2013-0310",
      "code_before_change": "int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)\n{\n\tunsigned char *opt = *option;\n\tunsigned char *tag;\n\tunsigned char opt_iter;\n\tunsigned char err_offset = 0;\n\tu8 opt_len;\n\tu8 tag_len;\n\tstruct cipso_v4_doi *doi_def = NULL;\n\tu32 tag_iter;\n\n\t/* caller already checks for length values that are too large */\n\topt_len = opt[1];\n\tif (opt_len < 8) {\n\t\terr_offset = 1;\n\t\tgoto validate_return;\n\t}\n\n\trcu_read_lock();\n\tdoi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));\n\tif (doi_def == NULL) {\n\t\terr_offset = 2;\n\t\tgoto validate_return_locked;\n\t}\n\n\topt_iter = CIPSO_V4_HDR_LEN;\n\ttag = opt + opt_iter;\n\twhile (opt_iter < opt_len) {\n\t\tfor (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];)\n\t\t\tif (doi_def->tags[tag_iter] == CIPSO_V4_TAG_INVALID ||\n\t\t\t    ++tag_iter == CIPSO_V4_TAG_MAXCNT) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\ttag_len = tag[1];\n\t\tif (tag_len > (opt_len - opt_iter)) {\n\t\t\terr_offset = opt_iter + 1;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\tswitch (tag[0]) {\n\t\tcase CIPSO_V4_TAG_RBITMAP:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RBM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\t/* We are already going to do all the verification\n\t\t\t * necessary at the socket layer so from our point of\n\t\t\t * view it is safe to turn these checks off (and less\n\t\t\t * work), however, the CIPSO draft says we should do\n\t\t\t * all the CIPSO validations here but it doesn't\n\t\t\t * really specify _exactly_ what we need to validate\n\t\t\t * ... so, just make it a sysctl tunable. */\n\t\t\tif (cipso_v4_rbm_strictvalid) {\n\t\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t\tif (tag_len > CIPSO_V4_TAG_RBM_BLEN &&\n\t\t\t\t    cipso_v4_map_cat_rbm_valid(doi_def,\n\t\t\t\t\t\t\t    &tag[4],\n\t\t\t\t\t\t\t    tag_len - 4) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_ENUM:\n\t\t\tif (tag_len < CIPSO_V4_TAG_ENUM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_ENUM_BLEN &&\n\t\t\t    cipso_v4_map_cat_enum_valid(doi_def,\n\t\t\t\t\t\t\t&tag[4],\n\t\t\t\t\t\t\ttag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_RANGE:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RNG_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_RNG_BLEN &&\n\t\t\t    cipso_v4_map_cat_rng_valid(doi_def,\n\t\t\t\t\t\t       &tag[4],\n\t\t\t\t\t\t       tag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_LOCAL:\n\t\t\t/* This is a non-standard tag that we only allow for\n\t\t\t * local connections, so if the incoming interface is\n\t\t\t * not the loopback device drop the packet. */\n\t\t\tif (!(skb->dev->flags & IFF_LOOPBACK)) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len != CIPSO_V4_TAG_LOC_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terr_offset = opt_iter;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\ttag += tag_len;\n\t\topt_iter += tag_len;\n\t}\n\nvalidate_return_locked:\n\trcu_read_unlock();\nvalidate_return:\n\t*option = opt + err_offset;\n\treturn err_offset;\n}",
      "code_after_change": "int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)\n{\n\tunsigned char *opt = *option;\n\tunsigned char *tag;\n\tunsigned char opt_iter;\n\tunsigned char err_offset = 0;\n\tu8 opt_len;\n\tu8 tag_len;\n\tstruct cipso_v4_doi *doi_def = NULL;\n\tu32 tag_iter;\n\n\t/* caller already checks for length values that are too large */\n\topt_len = opt[1];\n\tif (opt_len < 8) {\n\t\terr_offset = 1;\n\t\tgoto validate_return;\n\t}\n\n\trcu_read_lock();\n\tdoi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));\n\tif (doi_def == NULL) {\n\t\terr_offset = 2;\n\t\tgoto validate_return_locked;\n\t}\n\n\topt_iter = CIPSO_V4_HDR_LEN;\n\ttag = opt + opt_iter;\n\twhile (opt_iter < opt_len) {\n\t\tfor (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];)\n\t\t\tif (doi_def->tags[tag_iter] == CIPSO_V4_TAG_INVALID ||\n\t\t\t    ++tag_iter == CIPSO_V4_TAG_MAXCNT) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\ttag_len = tag[1];\n\t\tif (tag_len > (opt_len - opt_iter)) {\n\t\t\terr_offset = opt_iter + 1;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\tswitch (tag[0]) {\n\t\tcase CIPSO_V4_TAG_RBITMAP:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RBM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\t/* We are already going to do all the verification\n\t\t\t * necessary at the socket layer so from our point of\n\t\t\t * view it is safe to turn these checks off (and less\n\t\t\t * work), however, the CIPSO draft says we should do\n\t\t\t * all the CIPSO validations here but it doesn't\n\t\t\t * really specify _exactly_ what we need to validate\n\t\t\t * ... so, just make it a sysctl tunable. */\n\t\t\tif (cipso_v4_rbm_strictvalid) {\n\t\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t\tif (tag_len > CIPSO_V4_TAG_RBM_BLEN &&\n\t\t\t\t    cipso_v4_map_cat_rbm_valid(doi_def,\n\t\t\t\t\t\t\t    &tag[4],\n\t\t\t\t\t\t\t    tag_len - 4) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_ENUM:\n\t\t\tif (tag_len < CIPSO_V4_TAG_ENUM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_ENUM_BLEN &&\n\t\t\t    cipso_v4_map_cat_enum_valid(doi_def,\n\t\t\t\t\t\t\t&tag[4],\n\t\t\t\t\t\t\ttag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_RANGE:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RNG_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_RNG_BLEN &&\n\t\t\t    cipso_v4_map_cat_rng_valid(doi_def,\n\t\t\t\t\t\t       &tag[4],\n\t\t\t\t\t\t       tag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_LOCAL:\n\t\t\t/* This is a non-standard tag that we only allow for\n\t\t\t * local connections, so if the incoming interface is\n\t\t\t * not the loopback device drop the packet. Further,\n\t\t\t * there is no legitimate reason for setting this from\n\t\t\t * userspace so reject it if skb is NULL. */\n\t\t\tif (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len != CIPSO_V4_TAG_LOC_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terr_offset = opt_iter;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\ttag += tag_len;\n\t\topt_iter += tag_len;\n\t}\n\nvalidate_return_locked:\n\trcu_read_unlock();\nvalidate_return:\n\t*option = opt + err_offset;\n\treturn err_offset;\n}",
      "modified_lines": {
        "added": [
          "\t\t\t * not the loopback device drop the packet. Further,",
          "\t\t\t * there is no legitimate reason for setting this from",
          "\t\t\t * userspace so reject it if skb is NULL. */",
          "\t\t\tif (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {"
        ],
        "deleted": [
          "\t\t\t * not the loopback device drop the packet. */",
          "\t\t\tif (!(skb->dev->flags & IFF_LOOPBACK)) {"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for the incoming interface in the CIPSO_V4_TAG_LOCAL case.",
      "trigger_condition": "An attacker sets the IPOPT_CIPSO IP_OPTIONS using a system call, causing the code to process the CIPSO_V4_TAG_LOCAL tag without verifying the incoming interface, potentially leading to unauthorized access or system instability.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the incoming interface is the loopback device before processing the CIPSO_V4_TAG_LOCAL tag, allowing the tag to be handled without proper validation, which can result in security vulnerabilities and system crashes.",
      "id": 19,
      "code_after_change_normalized": "int FUN1(const struct sk_buff *VAR1, unsigned char **VAR2)\n{\nunsigned char *VAR3 = *VAR2;\nunsigned char *VAR4;\nunsigned char VAR5;\nunsigned char VAR6 = 0;\nu8 VAR7;\nu8 VAR8;\nstruct cipso_v4_doi *VAR9 = NULL;\nu32 VAR10;\nVAR7 = VAR3[1];\nif (VAR7 < 8) {\nVAR6 = 1;\ngoto VAR11;\n}\nFUN2();\nVAR9 = FUN3(FUN4(&VAR3[2]));\nif (VAR9 == NULL) {\nVAR6 = 2;\ngoto VAR12;\n}\nVAR5 = VAR13;\nVAR4 = VAR3 + VAR5;\nwhile (VAR5 < VAR7) {\nfor (VAR10 = 0; VAR9->VAR14[VAR10] != VAR4[0];)\nif (VAR9->VAR14[VAR10] == VAR15 ||\n++VAR10 == VAR16) {\nVAR6 = VAR5;\ngoto VAR12;\n}\nVAR8 = VAR4[1];\nif (VAR8 > (VAR7 - VAR5)) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nswitch (VAR4[0]) {\ncase VAR17:\nif (VAR8 < VAR18) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nif (VAR19) {\nif (FUN5(VAR9,\nVAR4[3]) < 0) {\nVAR6 = VAR5 + 3;\ngoto VAR12;\n}\nif (VAR8 > VAR18 &&\nFUN6(VAR9,\n&VAR4[4],\nVAR8 - 4) < 0) {\nVAR6 = VAR5 + 4;\ngoto VAR12;\n}\n}\nbreak;\ncase VAR20:\nif (VAR8 < VAR21) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nif (FUN5(VAR9,\nVAR4[3]) < 0) {\nVAR6 = VAR5 + 3;\ngoto VAR12;\n}\nif (VAR8 > VAR21 &&\nFUN7(VAR9,\n&VAR4[4],\nVAR8 - 4) < 0) {\nVAR6 = VAR5 + 4;\ngoto VAR12;\n}\nbreak;\ncase VAR22:\nif (VAR8 < VAR23) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nif (FUN5(VAR9,\nVAR4[3]) < 0) {\nVAR6 = VAR5 + 3;\ngoto VAR12;\n}\nif (VAR8 > VAR23 &&\nFUN8(VAR9,\n&VAR4[4],\nVAR8 - 4) < 0) {\nVAR6 = VAR5 + 4;\ngoto VAR12;\n}\nbreak;\ncase VAR24:\nif (VAR1 == NULL || !(VAR1->VAR25->VAR26 & VAR27)) {\nVAR6 = VAR5;\ngoto VAR12;\n}\nif (VAR8 != VAR28) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nbreak;\ndefault:\nVAR6 = VAR5;\ngoto VAR12;\n}\nVAR4 += VAR8;\nVAR5 += VAR8;\n}\nVAR12:\nFUN9();\nVAR11:\n*VAR2 = VAR3 + VAR6;\nreturn VAR6;\n}\n",
      "code_before_change_normalized": "int FUN1(const struct sk_buff *VAR1, unsigned char **VAR2)\n{\nunsigned char *VAR3 = *VAR2;\nunsigned char *VAR4;\nunsigned char VAR5;\nunsigned char VAR6 = 0;\nu8 VAR7;\nu8 VAR8;\nstruct cipso_v4_doi *VAR9 = NULL;\nu32 VAR10;\nVAR7 = VAR3[1];\nif (VAR7 < 8) {\nVAR6 = 1;\ngoto VAR11;\n}\nFUN2();\nVAR9 = FUN3(FUN4(&VAR3[2]));\nif (VAR9 == NULL) {\nVAR6 = 2;\ngoto VAR12;\n}\nVAR5 = VAR13;\nVAR4 = VAR3 + VAR5;\nwhile (VAR5 < VAR7) {\nfor (VAR10 = 0; VAR9->VAR14[VAR10] != VAR4[0];)\nif (VAR9->VAR14[VAR10] == VAR15 ||\n++VAR10 == VAR16) {\nVAR6 = VAR5;\ngoto VAR12;\n}\nVAR8 = VAR4[1];\nif (VAR8 > (VAR7 - VAR5)) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nswitch (VAR4[0]) {\ncase VAR17:\nif (VAR8 < VAR18) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nif (VAR19) {\nif (FUN5(VAR9,\nVAR4[3]) < 0) {\nVAR6 = VAR5 + 3;\ngoto VAR12;\n}\nif (VAR8 > VAR18 &&\nFUN6(VAR9,\n&VAR4[4],\nVAR8 - 4) < 0) {\nVAR6 = VAR5 + 4;\ngoto VAR12;\n}\n}\nbreak;\ncase VAR20:\nif (VAR8 < VAR21) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nif (FUN5(VAR9,\nVAR4[3]) < 0) {\nVAR6 = VAR5 + 3;\ngoto VAR12;\n}\nif (VAR8 > VAR21 &&\nFUN7(VAR9,\n&VAR4[4],\nVAR8 - 4) < 0) {\nVAR6 = VAR5 + 4;\ngoto VAR12;\n}\nbreak;\ncase VAR22:\nif (VAR8 < VAR23) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nif (FUN5(VAR9,\nVAR4[3]) < 0) {\nVAR6 = VAR5 + 3;\ngoto VAR12;\n}\nif (VAR8 > VAR23 &&\nFUN8(VAR9,\n&VAR4[4],\nVAR8 - 4) < 0) {\nVAR6 = VAR5 + 4;\ngoto VAR12;\n}\nbreak;\ncase VAR24:\nif (!(VAR1->VAR25->VAR26 & VAR27)) {\nVAR6 = VAR5;\ngoto VAR12;\n}\nif (VAR8 != VAR28) {\nVAR6 = VAR5 + 1;\ngoto VAR12;\n}\nbreak;\ndefault:\nVAR6 = VAR5;\ngoto VAR12;\n}\nVAR4 += VAR8;\nVAR5 += VAR8;\n}\nVAR12:\nFUN9();\nVAR11:\n*VAR2 = VAR3 + VAR6;\nreturn VAR6;\n}\n",
      "code_after_change_raw": "int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)\n{\nunsigned char *opt = *option;\nunsigned char *tag;\nunsigned char opt_iter;\nunsigned char err_offset = 0;\nu8 opt_len;\nu8 tag_len;\nstruct cipso_v4_doi *doi_def = NULL;\nu32 tag_iter;\nopt_len = opt[1];\nif (opt_len < 8) {\nerr_offset = 1;\ngoto validate_return;\n}\nrcu_read_lock();\ndoi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));\nif (doi_def == NULL) {\nerr_offset = 2;\ngoto validate_return_locked;\n}\nopt_iter = CIPSO_V4_HDR_LEN;\ntag = opt + opt_iter;\nwhile (opt_iter < opt_len) {\nfor (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];)\nif (doi_def->tags[tag_iter] == CIPSO_V4_TAG_INVALID ||\n++tag_iter == CIPSO_V4_TAG_MAXCNT) {\nerr_offset = opt_iter;\ngoto validate_return_locked;\n}\ntag_len = tag[1];\nif (tag_len > (opt_len - opt_iter)) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nswitch (tag[0]) {\ncase CIPSO_V4_TAG_RBITMAP:\nif (tag_len < CIPSO_V4_TAG_RBM_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nif (cipso_v4_rbm_strictvalid) {\nif (cipso_v4_map_lvl_valid(doi_def,\ntag[3]) < 0) {\nerr_offset = opt_iter + 3;\ngoto validate_return_locked;\n}\nif (tag_len > CIPSO_V4_TAG_RBM_BLEN &&\ncipso_v4_map_cat_rbm_valid(doi_def,\n&tag[4],\ntag_len - 4) < 0) {\nerr_offset = opt_iter + 4;\ngoto validate_return_locked;\n}\n}\nbreak;\ncase CIPSO_V4_TAG_ENUM:\nif (tag_len < CIPSO_V4_TAG_ENUM_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nif (cipso_v4_map_lvl_valid(doi_def,\ntag[3]) < 0) {\nerr_offset = opt_iter + 3;\ngoto validate_return_locked;\n}\nif (tag_len > CIPSO_V4_TAG_ENUM_BLEN &&\ncipso_v4_map_cat_enum_valid(doi_def,\n&tag[4],\ntag_len - 4) < 0) {\nerr_offset = opt_iter + 4;\ngoto validate_return_locked;\n}\nbreak;\ncase CIPSO_V4_TAG_RANGE:\nif (tag_len < CIPSO_V4_TAG_RNG_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nif (cipso_v4_map_lvl_valid(doi_def,\ntag[3]) < 0) {\nerr_offset = opt_iter + 3;\ngoto validate_return_locked;\n}\nif (tag_len > CIPSO_V4_TAG_RNG_BLEN &&\ncipso_v4_map_cat_rng_valid(doi_def,\n&tag[4],\ntag_len - 4) < 0) {\nerr_offset = opt_iter + 4;\ngoto validate_return_locked;\n}\nbreak;\ncase CIPSO_V4_TAG_LOCAL:\nif (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {\nerr_offset = opt_iter;\ngoto validate_return_locked;\n}\nif (tag_len != CIPSO_V4_TAG_LOC_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nbreak;\ndefault:\nerr_offset = opt_iter;\ngoto validate_return_locked;\n}\ntag += tag_len;\nopt_iter += tag_len;\n}\nvalidate_return_locked:\nrcu_read_unlock();\nvalidate_return:\n*option = opt + err_offset;\nreturn err_offset;\n}\n",
      "code_before_change_raw": "int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)\n{\nunsigned char *opt = *option;\nunsigned char *tag;\nunsigned char opt_iter;\nunsigned char err_offset = 0;\nu8 opt_len;\nu8 tag_len;\nstruct cipso_v4_doi *doi_def = NULL;\nu32 tag_iter;\nopt_len = opt[1];\nif (opt_len < 8) {\nerr_offset = 1;\ngoto validate_return;\n}\nrcu_read_lock();\ndoi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));\nif (doi_def == NULL) {\nerr_offset = 2;\ngoto validate_return_locked;\n}\nopt_iter = CIPSO_V4_HDR_LEN;\ntag = opt + opt_iter;\nwhile (opt_iter < opt_len) {\nfor (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];)\nif (doi_def->tags[tag_iter] == CIPSO_V4_TAG_INVALID ||\n++tag_iter == CIPSO_V4_TAG_MAXCNT) {\nerr_offset = opt_iter;\ngoto validate_return_locked;\n}\ntag_len = tag[1];\nif (tag_len > (opt_len - opt_iter)) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nswitch (tag[0]) {\ncase CIPSO_V4_TAG_RBITMAP:\nif (tag_len < CIPSO_V4_TAG_RBM_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nif (cipso_v4_rbm_strictvalid) {\nif (cipso_v4_map_lvl_valid(doi_def,\ntag[3]) < 0) {\nerr_offset = opt_iter + 3;\ngoto validate_return_locked;\n}\nif (tag_len > CIPSO_V4_TAG_RBM_BLEN &&\ncipso_v4_map_cat_rbm_valid(doi_def,\n&tag[4],\ntag_len - 4) < 0) {\nerr_offset = opt_iter + 4;\ngoto validate_return_locked;\n}\n}\nbreak;\ncase CIPSO_V4_TAG_ENUM:\nif (tag_len < CIPSO_V4_TAG_ENUM_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nif (cipso_v4_map_lvl_valid(doi_def,\ntag[3]) < 0) {\nerr_offset = opt_iter + 3;\ngoto validate_return_locked;\n}\nif (tag_len > CIPSO_V4_TAG_ENUM_BLEN &&\ncipso_v4_map_cat_enum_valid(doi_def,\n&tag[4],\ntag_len - 4) < 0) {\nerr_offset = opt_iter + 4;\ngoto validate_return_locked;\n}\nbreak;\ncase CIPSO_V4_TAG_RANGE:\nif (tag_len < CIPSO_V4_TAG_RNG_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nif (cipso_v4_map_lvl_valid(doi_def,\ntag[3]) < 0) {\nerr_offset = opt_iter + 3;\ngoto validate_return_locked;\n}\nif (tag_len > CIPSO_V4_TAG_RNG_BLEN &&\ncipso_v4_map_cat_rng_valid(doi_def,\n&tag[4],\ntag_len - 4) < 0) {\nerr_offset = opt_iter + 4;\ngoto validate_return_locked;\n}\nbreak;\ncase CIPSO_V4_TAG_LOCAL:\nif (!(skb->dev->flags & IFF_LOOPBACK)) {\nerr_offset = opt_iter;\ngoto validate_return_locked;\n}\nif (tag_len != CIPSO_V4_TAG_LOC_BLEN) {\nerr_offset = opt_iter + 1;\ngoto validate_return_locked;\n}\nbreak;\ndefault:\nerr_offset = opt_iter;\ngoto validate_return_locked;\n}\ntag += tag_len;\nopt_iter += tag_len;\n}\nvalidate_return_locked:\nrcu_read_unlock();\nvalidate_return:\n*option = opt + err_offset;\nreturn err_offset;\n}\n"
    }
  ],
  "CVE-2013-1772": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of syslog header prefix in the kmsg_writev function.",
        "trigger_condition": "A local user with /dev/kmsg write access triggers a call_console_drivers function call, leading to a denial of service due to a buffer overflow and system crash.",
        "specific_code_behavior_causing_vulnerability": "The original code does not properly remove the syslog header prefix from the log message, allowing for potential buffer overflow and system crash when processing the log message.",
        "solution": "The vulnerability can be mitigated by extracting and skipping the syslog header prefix <[0-9]*> before processing the log message. This ensures that the log message is handled correctly and prevents buffer overflows that could lead to a system crash. The modified code snippet now correctly handles the syslog header prefix and mitigates the risk of exploitation by malicious users."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-1772, which involves a buffer overflow and system crash caused by improper handling of a syslog header prefix in the kmsg_writev function. \n\nThe original code snippet did not properly remove the syslog header prefix, which could lead to a denial of service when a local user with /dev/kmsg write access triggers a call_console_drivers function call.\n\nThe modified code snippet addresses this vulnerability by extracting and skipping the syslog prefix <[0-9]*> before processing the log message. This ensures that the log message is handled correctly and prevents buffer overflows that could lead to a system crash.\n\nBy making these changes, the code now properly handles the syslog header prefix and mitigates the risk of the vulnerability being exploited by malicious users.",
      "GPT_purpose": "Write a log message to the kernel message log buffer by copying data from user space into a single string.",
      "GPT_function": "\n1. Write data from multiple vectors into a single string.\n2. Copy the single string to the kernel log using printk.\n3. Free allocated memory before returning.",
      "CVE_id": "CVE-2013-1772",
      "code_before_change": "static ssize_t kmsg_writev(struct kiocb *iocb, const struct iovec *iv,\n\t\t\t   unsigned long count, loff_t pos)\n{\n\tchar *line, *p;\n\tint i;\n\tssize_t ret = -EFAULT;\n\tsize_t len = iov_length(iv, count);\n\n\tline = kmalloc(len + 1, GFP_KERNEL);\n\tif (line == NULL)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * copy all vectors into a single string, to ensure we do\n\t * not interleave our log line with other printk calls\n\t */\n\tp = line;\n\tfor (i = 0; i < count; i++) {\n\t\tif (copy_from_user(p, iv[i].iov_base, iv[i].iov_len))\n\t\t\tgoto out;\n\t\tp += iv[i].iov_len;\n\t}\n\tp[0] = '\\0';\n\n\tret = printk(\"%s\", line);\n\t/* printk can add a prefix */\n\tif (ret > len)\n\t\tret = len;\nout:\n\tkfree(line);\n\treturn ret;\n}",
      "code_after_change": "static ssize_t kmsg_writev(struct kiocb *iocb, const struct iovec *iv,\n\t\t\t   unsigned long count, loff_t pos)\n{\n\tchar *buf, *line;\n\tint i;\n\tint level = default_message_loglevel;\n\tint facility = 1;\t/* LOG_USER */\n\tsize_t len = iov_length(iv, count);\n\tssize_t ret = len;\n\n\tif (len > 1024)\n\t\treturn -EINVAL;\n\tbuf = kmalloc(len+1, GFP_KERNEL);\n\tif (buf == NULL)\n\t\treturn -ENOMEM;\n\n\tline = buf;\n\tfor (i = 0; i < count; i++) {\n\t\tif (copy_from_user(line, iv[i].iov_base, iv[i].iov_len))\n\t\t\tgoto out;\n\t\tline += iv[i].iov_len;\n\t}\n\n\t/*\n\t * Extract and skip the syslog prefix <[0-9]*>. Coming from userspace\n\t * the decimal value represents 32bit, the lower 3 bit are the log\n\t * level, the rest are the log facility.\n\t *\n\t * If no prefix or no userspace facility is specified, we\n\t * enforce LOG_USER, to be able to reliably distinguish\n\t * kernel-generated messages from userspace-injected ones.\n\t */\n\tline = buf;\n\tif (line[0] == '<') {\n\t\tchar *endp = NULL;\n\n\t\ti = simple_strtoul(line+1, &endp, 10);\n\t\tif (endp && endp[0] == '>') {\n\t\t\tlevel = i & 7;\n\t\t\tif (i >> 3)\n\t\t\t\tfacility = i >> 3;\n\t\t\tendp++;\n\t\t\tlen -= endp - line;\n\t\t\tline = endp;\n\t\t}\n\t}\n\tline[len] = '\\0';\n\n\tprintk_emit(facility, level, NULL, 0, \"%s\", line);\nout:\n\tkfree(buf);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tchar *buf, *line;",
          "\tint level = default_message_loglevel;",
          "\tint facility = 1;\t/* LOG_USER */",
          "\tssize_t ret = len;",
          "\tif (len > 1024)",
          "\t\treturn -EINVAL;",
          "\tbuf = kmalloc(len+1, GFP_KERNEL);",
          "\tif (buf == NULL)",
          "\tline = buf;",
          "\tfor (i = 0; i < count; i++) {",
          "\t\tif (copy_from_user(line, iv[i].iov_base, iv[i].iov_len))",
          "\t\t\tgoto out;",
          "\t\tline += iv[i].iov_len;",
          "\t}",
          "",
          "\t * Extract and skip the syslog prefix <[0-9]*>. Coming from userspace",
          "\t * the decimal value represents 32bit, the lower 3 bit are the log",
          "\t * level, the rest are the log facility.",
          "\t *",
          "\t * If no prefix or no userspace facility is specified, we",
          "\t * enforce LOG_USER, to be able to reliably distinguish",
          "\t * kernel-generated messages from userspace-injected ones.",
          "\tline = buf;",
          "\tif (line[0] == '<') {",
          "\t\tchar *endp = NULL;",
          "",
          "\t\ti = simple_strtoul(line+1, &endp, 10);",
          "\t\tif (endp && endp[0] == '>') {",
          "\t\t\tlevel = i & 7;",
          "\t\t\tif (i >> 3)",
          "\t\t\t\tfacility = i >> 3;",
          "\t\t\tendp++;",
          "\t\t\tlen -= endp - line;",
          "\t\t\tline = endp;",
          "\t\t}",
          "\tline[len] = '\\0';",
          "\tprintk_emit(facility, level, NULL, 0, \"%s\", line);",
          "\tkfree(buf);"
        ],
        "deleted": [
          "\tchar *line, *p;",
          "\tssize_t ret = -EFAULT;",
          "\tline = kmalloc(len + 1, GFP_KERNEL);",
          "\tif (line == NULL)",
          "\t * copy all vectors into a single string, to ensure we do",
          "\t * not interleave our log line with other printk calls",
          "\tp = line;",
          "\tfor (i = 0; i < count; i++) {",
          "\t\tif (copy_from_user(p, iv[i].iov_base, iv[i].iov_len))",
          "\t\t\tgoto out;",
          "\t\tp += iv[i].iov_len;",
          "\tp[0] = '\\0';",
          "\tret = printk(\"%s\", line);",
          "\t/* printk can add a prefix */",
          "\tif (ret > len)",
          "\t\tret = len;",
          "\tkfree(line);"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of syslog header prefix in the kmsg_writev function.",
      "trigger_condition": "A local user with /dev/kmsg write access triggers a call_console_drivers function call, leading to a denial of service due to a buffer overflow and system crash.",
      "specific_code_behavior_causing_vulnerability": "The original code does not properly remove the syslog header prefix from the log message, allowing for potential buffer overflow and system crash when processing the log message.",
      "solution": "The vulnerability can be mitigated by extracting and skipping the syslog header prefix <[0-9]*> before processing the log message. This ensures that the log message is handled correctly and prevents buffer overflows that could lead to a system crash. The modified code snippet now correctly handles the syslog header prefix and mitigates the risk of exploitation by malicious users.",
      "id": 20,
      "code_after_change_normalized": "static ssize_t FUN1(struct kiocb *VAR1, const struct iovec *VAR2,\nunsigned long VAR3, loff_t VAR4)\n{\nchar *VAR5, *VAR6;\nint VAR7;\nint VAR8 = VAR9;\nint VAR10 = 1;\t\nsize_t VAR11 = FUN2(VAR2, VAR3);\nssize_t VAR12 = VAR11;\nif (VAR11 > 1024)\nreturn -VAR13;\nVAR5 = FUN3(VAR11+1, VAR14);\nif (VAR5 == NULL)\nreturn -VAR15;\nVAR6 = VAR5;\nfor (VAR7 = 0; VAR7 < VAR3; VAR7++) {\nif (FUN4(VAR6, VAR2[VAR7].VAR16, VAR2[VAR7].VAR17))\ngoto VAR18;\nVAR6 += VAR2[VAR7].VAR17;\n}\nVAR6 = VAR5;\nif (VAR6[0] == ) {\nchar *VAR19 = NULL;\nVAR7 = FUN5(VAR6+1, &VAR19, 10);\nif (VAR19 && VAR19[0] == ) {\nVAR8 = VAR7 & 7;\nif (VAR7 >> 3)\nVAR10 = VAR7 >> 3;\nVAR19++;\nVAR11 -= VAR19 - VAR6;\nVAR6 = VAR19;\n}\n}\nVAR6[VAR11] = ;\nFUN6(VAR10, VAR8, NULL, 0, \"STR\", VAR6);\nVAR18:\nFUN7(VAR5);\nreturn VAR12;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct kiocb *VAR1, const struct iovec *VAR2,\nunsigned long VAR3, loff_t VAR4)\n{\nchar *VAR5, *VAR6;\nint VAR7;\nssize_t VAR8 = -VAR9;\nsize_t VAR10 = FUN2(VAR2, VAR3);\nVAR5 = FUN3(VAR10 + 1, VAR11);\nif (VAR5 == NULL)\nreturn -VAR12;\nVAR6 = VAR5;\nfor (VAR7 = 0; VAR7 < VAR3; VAR7++) {\nif (FUN4(VAR6, VAR2[VAR7].VAR13, VAR2[VAR7].VAR14))\ngoto VAR15;\nVAR6 += VAR2[VAR7].VAR14;\n}\nVAR6[0] = ;\nVAR8 = FUN5(\"STR\", VAR5);\nif (VAR8 > VAR10)\nVAR8 = VAR10;\nVAR15:\nFUN6(VAR5);\nreturn VAR8;\n}\n",
      "code_after_change_raw": "static ssize_t kmsg_writev(struct kiocb *iocb, const struct iovec *iv,\nunsigned long count, loff_t pos)\n{\nchar *buf, *line;\nint i;\nint level = default_message_loglevel;\nint facility = 1;\t\nsize_t len = iov_length(iv, count);\nssize_t ret = len;\nif (len > 1024)\nreturn -EINVAL;\nbuf = kmalloc(len+1, GFP_KERNEL);\nif (buf == NULL)\nreturn -ENOMEM;\nline = buf;\nfor (i = 0; i < count; i++) {\nif (copy_from_user(line, iv[i].iov_base, iv[i].iov_len))\ngoto out;\nline += iv[i].iov_len;\n}\nline = buf;\nif (line[0] == '<') {\nchar *endp = NULL;\ni = simple_strtoul(line+1, &endp, 10);\nif (endp && endp[0] == '>') {\nlevel = i & 7;\nif (i >> 3)\nfacility = i >> 3;\nendp++;\nlen -= endp - line;\nline = endp;\n}\n}\nline[len] = '\\0';\nprintk_emit(facility, level, NULL, 0, \"%s\", line);\nout:\nkfree(buf);\nreturn ret;\n}\n",
      "code_before_change_raw": "static ssize_t kmsg_writev(struct kiocb *iocb, const struct iovec *iv,\nunsigned long count, loff_t pos)\n{\nchar *line, *p;\nint i;\nssize_t ret = -EFAULT;\nsize_t len = iov_length(iv, count);\nline = kmalloc(len + 1, GFP_KERNEL);\nif (line == NULL)\nreturn -ENOMEM;\np = line;\nfor (i = 0; i < count; i++) {\nif (copy_from_user(p, iv[i].iov_base, iv[i].iov_len))\ngoto out;\np += iv[i].iov_len;\n}\np[0] = '\\0';\nret = printk(\"%s\", line);\nif (ret > len)\nret = len;\nout:\nkfree(line);\nreturn ret;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper removal of a prefix string from a syslog header in the code.",
        "trigger_condition": "Local users with /dev/kmsg write access can exploit the vulnerability by triggering a call_console_drivers function call.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly remove a prefix string from a syslog header, leading to a buffer overflow and system crash vulnerability. This vulnerability can be exploited by local users with specific write access, causing a denial of service by triggering a function call.",
        "solution": "To mitigate the vulnerability, the code needs to be modified to ensure proper handling of the syslog header prefix. This involves updating the syslog functions to correctly remove the prefix string and prevent buffer overflow. Additionally, access controls should be enforced to restrict write access to /dev/kmsg and prevent unauthorized users from triggering the vulnerable function call."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-1772 in the original code snippet. The vulnerability arises from the log_prefix function in kernel/printk.c not properly removing a prefix string from a syslog header. This vulnerability allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.\n\nThe modification includes changes such as renaming variables, updating the error handling logic, and revising the handling of syslog actions. These changes help to improve the overall security and robustness of the code by addressing the vulnerability and ensuring that the syslog functions operate correctly and securely.\n\nBy making these modifications, the code is updated to prevent the exploitation of the vulnerability and enhance the resilience of the syslog functionality within the kernel.",
      "GPT_purpose": "Perform various actions related to syslog management, such as reading, clearing, and controlling logging behavior.",
      "GPT_function": "\n1. Open or close a log file.\n2. Read from the log buffer.\n3. Read or clear the last kernel messages.\n4. Clear the ring buffer.\n5. Disable or enable logging to the console.\n6. Set the level of messages printed to the console.\n7. Get the number of characters in the log buffer.\n8. Get the size of the log buffer.",
      "CVE_id": "CVE-2013-1772",
      "code_before_change": "int do_syslog(int type, char __user *buf, int len, bool from_file)\n{\n\tunsigned i, j, limit, count;\n\tint do_clear = 0;\n\tchar c;\n\tint error;\n\n\terror = check_syslog_permissions(type, from_file);\n\tif (error)\n\t\tgoto out;\n\n\terror = security_syslog(type);\n\tif (error)\n\t\treturn error;\n\n\tswitch (type) {\n\tcase SYSLOG_ACTION_CLOSE:\t/* Close log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_OPEN:\t/* Open log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_READ:\t/* Read from log */\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\terror = wait_event_interruptible(log_wait,\n\t\t\t\t\t\t\t(log_start - log_end));\n\t\tif (error)\n\t\t\tgoto out;\n\t\ti = 0;\n\t\traw_spin_lock_irq(&logbuf_lock);\n\t\twhile (!error && (log_start != log_end) && i < len) {\n\t\t\tc = LOG_BUF(log_start);\n\t\t\tlog_start++;\n\t\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\t\terror = __put_user(c,buf);\n\t\t\tbuf++;\n\t\t\ti++;\n\t\t\tcond_resched();\n\t\t\traw_spin_lock_irq(&logbuf_lock);\n\t\t}\n\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\tif (!error)\n\t\t\terror = i;\n\t\tbreak;\n\t/* Read/clear last kernel messages */\n\tcase SYSLOG_ACTION_READ_CLEAR:\n\t\tdo_clear = 1;\n\t\t/* FALL THRU */\n\t/* Read last kernel messages */\n\tcase SYSLOG_ACTION_READ_ALL:\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tcount = len;\n\t\tif (count > log_buf_len)\n\t\t\tcount = log_buf_len;\n\t\traw_spin_lock_irq(&logbuf_lock);\n\t\tif (count > logged_chars)\n\t\t\tcount = logged_chars;\n\t\tif (do_clear)\n\t\t\tlogged_chars = 0;\n\t\tlimit = log_end;\n\t\t/*\n\t\t * __put_user() could sleep, and while we sleep\n\t\t * printk() could overwrite the messages\n\t\t * we try to copy to user space. Therefore\n\t\t * the messages are copied in reverse. <manfreds>\n\t\t */\n\t\tfor (i = 0; i < count && !error; i++) {\n\t\t\tj = limit-1-i;\n\t\t\tif (j + log_buf_len < log_end)\n\t\t\t\tbreak;\n\t\t\tc = LOG_BUF(j);\n\t\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\t\terror = __put_user(c,&buf[count-1-i]);\n\t\t\tcond_resched();\n\t\t\traw_spin_lock_irq(&logbuf_lock);\n\t\t}\n\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\tif (error)\n\t\t\tbreak;\n\t\terror = i;\n\t\tif (i != count) {\n\t\t\tint offset = count-error;\n\t\t\t/* buffer overflow during copy, correct user buffer. */\n\t\t\tfor (i = 0; i < error; i++) {\n\t\t\t\tif (__get_user(c,&buf[i+offset]) ||\n\t\t\t\t    __put_user(c,&buf[i])) {\n\t\t\t\t\terror = -EFAULT;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcond_resched();\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t/* Clear ring buffer */\n\tcase SYSLOG_ACTION_CLEAR:\n\t\tlogged_chars = 0;\n\t\tbreak;\n\t/* Disable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_OFF:\n\t\tif (saved_console_loglevel == -1)\n\t\t\tsaved_console_loglevel = console_loglevel;\n\t\tconsole_loglevel = minimum_console_loglevel;\n\t\tbreak;\n\t/* Enable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_ON:\n\t\tif (saved_console_loglevel != -1) {\n\t\t\tconsole_loglevel = saved_console_loglevel;\n\t\t\tsaved_console_loglevel = -1;\n\t\t}\n\t\tbreak;\n\t/* Set level of messages printed to console */\n\tcase SYSLOG_ACTION_CONSOLE_LEVEL:\n\t\terror = -EINVAL;\n\t\tif (len < 1 || len > 8)\n\t\t\tgoto out;\n\t\tif (len < minimum_console_loglevel)\n\t\t\tlen = minimum_console_loglevel;\n\t\tconsole_loglevel = len;\n\t\t/* Implicitly re-enable logging to console */\n\t\tsaved_console_loglevel = -1;\n\t\terror = 0;\n\t\tbreak;\n\t/* Number of chars in the log buffer */\n\tcase SYSLOG_ACTION_SIZE_UNREAD:\n\t\terror = log_end - log_start;\n\t\tbreak;\n\t/* Size of the log buffer */\n\tcase SYSLOG_ACTION_SIZE_BUFFER:\n\t\terror = log_buf_len;\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tbreak;\n\t}\nout:\n\treturn error;\n}",
      "code_after_change": "int do_syslog(int type, char __user *buf, int len, bool from_file)\n{\n\tbool clear = false;\n\tstatic int saved_console_loglevel = -1;\n\tint error;\n\n\terror = check_syslog_permissions(type, from_file);\n\tif (error)\n\t\tgoto out;\n\n\terror = security_syslog(type);\n\tif (error)\n\t\treturn error;\n\n\tswitch (type) {\n\tcase SYSLOG_ACTION_CLOSE:\t/* Close log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_OPEN:\t/* Open log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_READ:\t/* Read from log */\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\terror = wait_event_interruptible(log_wait,\n\t\t\t\t\t\t syslog_seq != log_next_seq);\n\t\tif (error)\n\t\t\tgoto out;\n\t\terror = syslog_print(buf, len);\n\t\tbreak;\n\t/* Read/clear last kernel messages */\n\tcase SYSLOG_ACTION_READ_CLEAR:\n\t\tclear = true;\n\t\t/* FALL THRU */\n\t/* Read last kernel messages */\n\tcase SYSLOG_ACTION_READ_ALL:\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\terror = syslog_print_all(buf, len, clear);\n\t\tbreak;\n\t/* Clear ring buffer */\n\tcase SYSLOG_ACTION_CLEAR:\n\t\tsyslog_print_all(NULL, 0, true);\n\t/* Disable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_OFF:\n\t\tif (saved_console_loglevel == -1)\n\t\t\tsaved_console_loglevel = console_loglevel;\n\t\tconsole_loglevel = minimum_console_loglevel;\n\t\tbreak;\n\t/* Enable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_ON:\n\t\tif (saved_console_loglevel != -1) {\n\t\t\tconsole_loglevel = saved_console_loglevel;\n\t\t\tsaved_console_loglevel = -1;\n\t\t}\n\t\tbreak;\n\t/* Set level of messages printed to console */\n\tcase SYSLOG_ACTION_CONSOLE_LEVEL:\n\t\terror = -EINVAL;\n\t\tif (len < 1 || len > 8)\n\t\t\tgoto out;\n\t\tif (len < minimum_console_loglevel)\n\t\t\tlen = minimum_console_loglevel;\n\t\tconsole_loglevel = len;\n\t\t/* Implicitly re-enable logging to console */\n\t\tsaved_console_loglevel = -1;\n\t\terror = 0;\n\t\tbreak;\n\t/* Number of chars in the log buffer */\n\tcase SYSLOG_ACTION_SIZE_UNREAD:\n\t\traw_spin_lock_irq(&logbuf_lock);\n\t\tif (syslog_seq < log_first_seq) {\n\t\t\t/* messages are gone, move to first one */\n\t\t\tsyslog_seq = log_first_seq;\n\t\t\tsyslog_idx = log_first_idx;\n\t\t}\n\t\tif (from_file) {\n\t\t\t/*\n\t\t\t * Short-cut for poll(/\"proc/kmsg\") which simply checks\n\t\t\t * for pending data, not the size; return the count of\n\t\t\t * records, not the length.\n\t\t\t */\n\t\t\terror = log_next_idx - syslog_idx;\n\t\t} else {\n\t\t\tu64 seq;\n\t\t\tu32 idx;\n\n\t\t\terror = 0;\n\t\t\tseq = syslog_seq;\n\t\t\tidx = syslog_idx;\n\t\t\twhile (seq < log_next_seq) {\n\t\t\t\terror += syslog_print_line(idx, NULL, 0);\n\t\t\t\tidx = log_next(idx);\n\t\t\t\tseq++;\n\t\t\t}\n\t\t}\n\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\tbreak;\n\t/* Size of the log buffer */\n\tcase SYSLOG_ACTION_SIZE_BUFFER:\n\t\terror = log_buf_len;\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tbreak;\n\t}\nout:\n\treturn error;\n}",
      "modified_lines": {
        "added": [
          "\tbool clear = false;",
          "\tstatic int saved_console_loglevel = -1;",
          "\t\t\t\t\t\t syslog_seq != log_next_seq);",
          "\t\terror = syslog_print(buf, len);",
          "\t\tclear = true;",
          "\t\terror = syslog_print_all(buf, len, clear);",
          "\t\tsyslog_print_all(NULL, 0, true);",
          "\t\traw_spin_lock_irq(&logbuf_lock);",
          "\t\tif (syslog_seq < log_first_seq) {",
          "\t\t\t/* messages are gone, move to first one */",
          "\t\t\tsyslog_seq = log_first_seq;",
          "\t\t\tsyslog_idx = log_first_idx;",
          "\t\t}",
          "\t\tif (from_file) {",
          "\t\t\t/*",
          "\t\t\t * Short-cut for poll(/\"proc/kmsg\") which simply checks",
          "\t\t\t * for pending data, not the size; return the count of",
          "\t\t\t * records, not the length.",
          "\t\t\t */",
          "\t\t\terror = log_next_idx - syslog_idx;",
          "\t\t} else {",
          "\t\t\tu64 seq;",
          "\t\t\tu32 idx;",
          "",
          "\t\t\terror = 0;",
          "\t\t\tseq = syslog_seq;",
          "\t\t\tidx = syslog_idx;",
          "\t\t\twhile (seq < log_next_seq) {",
          "\t\t\t\terror += syslog_print_line(idx, NULL, 0);",
          "\t\t\t\tidx = log_next(idx);",
          "\t\t\t\tseq++;",
          "\t\t\t}",
          "\t\t}",
          "\t\traw_spin_unlock_irq(&logbuf_lock);"
        ],
        "deleted": [
          "\tunsigned i, j, limit, count;",
          "\tint do_clear = 0;",
          "\tchar c;",
          "\t\t\t\t\t\t\t(log_start - log_end));",
          "\t\ti = 0;",
          "\t\traw_spin_lock_irq(&logbuf_lock);",
          "\t\twhile (!error && (log_start != log_end) && i < len) {",
          "\t\t\tc = LOG_BUF(log_start);",
          "\t\t\tlog_start++;",
          "\t\t\traw_spin_unlock_irq(&logbuf_lock);",
          "\t\t\terror = __put_user(c,buf);",
          "\t\t\tbuf++;",
          "\t\t\ti++;",
          "\t\t\tcond_resched();",
          "\t\t\traw_spin_lock_irq(&logbuf_lock);",
          "\t\t}",
          "\t\traw_spin_unlock_irq(&logbuf_lock);",
          "\t\tif (!error)",
          "\t\t\terror = i;",
          "\t\tdo_clear = 1;",
          "\t\tcount = len;",
          "\t\tif (count > log_buf_len)",
          "\t\t\tcount = log_buf_len;",
          "\t\traw_spin_lock_irq(&logbuf_lock);",
          "\t\tif (count > logged_chars)",
          "\t\t\tcount = logged_chars;",
          "\t\tif (do_clear)",
          "\t\t\tlogged_chars = 0;",
          "\t\tlimit = log_end;",
          "\t\t/*",
          "\t\t * __put_user() could sleep, and while we sleep",
          "\t\t * printk() could overwrite the messages",
          "\t\t * we try to copy to user space. Therefore",
          "\t\t * the messages are copied in reverse. <manfreds>",
          "\t\t */",
          "\t\tfor (i = 0; i < count && !error; i++) {",
          "\t\t\tj = limit-1-i;",
          "\t\t\tif (j + log_buf_len < log_end)",
          "\t\t\t\tbreak;",
          "\t\t\tc = LOG_BUF(j);",
          "\t\t\traw_spin_unlock_irq(&logbuf_lock);",
          "\t\t\terror = __put_user(c,&buf[count-1-i]);",
          "\t\t\tcond_resched();",
          "\t\t\traw_spin_lock_irq(&logbuf_lock);",
          "\t\t}",
          "\t\traw_spin_unlock_irq(&logbuf_lock);",
          "\t\tif (error)",
          "\t\t\tbreak;",
          "\t\terror = i;",
          "\t\tif (i != count) {",
          "\t\t\tint offset = count-error;",
          "\t\t\t/* buffer overflow during copy, correct user buffer. */",
          "\t\t\tfor (i = 0; i < error; i++) {",
          "\t\t\t\tif (__get_user(c,&buf[i+offset]) ||",
          "\t\t\t\t    __put_user(c,&buf[i])) {",
          "\t\t\t\t\terror = -EFAULT;",
          "\t\t\t\t\tbreak;",
          "\t\t\t\t}",
          "\t\t\t\tcond_resched();",
          "\t\t\t}",
          "\t\t}",
          "\t\tlogged_chars = 0;",
          "\t\tbreak;",
          "\t\terror = log_end - log_start;"
        ]
      },
      "preconditions_for_vulnerability": "Improper removal of a prefix string from a syslog header in the code.",
      "trigger_condition": "Local users with /dev/kmsg write access can exploit the vulnerability by triggering a call_console_drivers function call.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly remove a prefix string from a syslog header, leading to a buffer overflow and system crash vulnerability. This vulnerability can be exploited by local users with specific write access, causing a denial of service by triggering a function call.",
      "solution": "To mitigate the vulnerability, the code needs to be modified to ensure proper handling of the syslog header prefix. This involves updating the syslog functions to correctly remove the prefix string and prevent buffer overflow. Additionally, access controls should be enforced to restrict write access to /dev/kmsg and prevent unauthorized users from triggering the vulnerable function call.",
      "id": 21,
      "code_after_change_normalized": "int FUN1(int VAR1, char __user *VAR2, int VAR3, bool VAR4)\n{\nbool VAR5 = false;\nstatic int VAR6 = -1;\nint VAR7;\nVAR7 = FUN2(VAR1, VAR4);\nif (VAR7)\ngoto VAR8;\nVAR7 = FUN3(VAR1);\nif (VAR7)\nreturn VAR7;\nswitch (VAR1) {\ncase VAR9:\t\nbreak;\ncase VAR10:\t\nbreak;\ncase VAR11:\t\nVAR7 = -VAR12;\nif (!VAR2 || VAR3 < 0)\ngoto VAR8;\nVAR7 = 0;\nif (!VAR3)\ngoto VAR8;\nif (!FUN4(VAR13, VAR2, VAR3)) {\nVAR7 = -VAR14;\ngoto VAR8;\n}\nVAR7 = FUN5(VAR15,\nVAR16 != VAR17);\nif (VAR7)\ngoto VAR8;\nVAR7 = FUN6(VAR2, VAR3);\nbreak;\ncase VAR18:\nVAR5 = true;\ncase VAR19:\nVAR7 = -VAR12;\nif (!VAR2 || VAR3 < 0)\ngoto VAR8;\nVAR7 = 0;\nif (!VAR3)\ngoto VAR8;\nif (!FUN4(VAR13, VAR2, VAR3)) {\nVAR7 = -VAR14;\ngoto VAR8;\n}\nVAR7 = FUN7(VAR2, VAR3, VAR5);\nbreak;\ncase VAR20:\nFUN7(NULL, 0, true);\ncase VAR21:\nif (VAR6 == -1)\nVAR6 = VAR22;\nVAR22 = VAR23;\nbreak;\ncase VAR24:\nif (VAR6 != -1) {\nVAR22 = VAR6;\nVAR6 = -1;\n}\nbreak;\ncase VAR25:\nVAR7 = -VAR12;\nif (VAR3 < 1 || VAR3 > 8)\ngoto VAR8;\nif (VAR3 < VAR23)\nVAR3 = VAR23;\nVAR22 = VAR3;\nVAR6 = -1;\nVAR7 = 0;\nbreak;\ncase VAR26:\nFUN8(&VAR27);\nif (VAR16 < VAR28) {\nVAR16 = VAR28;\nVAR29 = VAR30;\n}\nif (VAR4) {\nVAR7 = VAR31 - VAR29;\n} else {\nu64 VAR32;\nu32 VAR33;\nVAR7 = 0;\nVAR32 = VAR16;\nVAR33 = VAR29;\nwhile (VAR32 < VAR17) {\nVAR7 += FUN9(VAR33, NULL, 0);\nVAR33 = FUN10(VAR33);\nVAR32++;\n}\n}\nFUN11(&VAR27);\nbreak;\ncase VAR34:\nVAR7 = VAR35;\nbreak;\ndefault:\nVAR7 = -VAR12;\nbreak;\n}\nVAR8:\nreturn VAR7;\n}\n",
      "code_before_change_normalized": "int FUN1(int VAR1, char __user *VAR2, int VAR3, bool VAR4)\n{\nunsigned VAR5, VAR6, VAR7, VAR8;\nint VAR9 = 0;\nchar VAR10;\nint VAR11;\nVAR11 = FUN2(VAR1, VAR4);\nif (VAR11)\ngoto VAR12;\nVAR11 = FUN3(VAR1);\nif (VAR11)\nreturn VAR11;\nswitch (VAR1) {\ncase VAR13:\t\nbreak;\ncase VAR14:\t\nbreak;\ncase VAR15:\t\nVAR11 = -VAR16;\nif (!VAR2 || VAR3 < 0)\ngoto VAR12;\nVAR11 = 0;\nif (!VAR3)\ngoto VAR12;\nif (!FUN4(VAR17, VAR2, VAR3)) {\nVAR11 = -VAR18;\ngoto VAR12;\n}\nVAR11 = FUN5(VAR19,\n(VAR20 - VAR21));\nif (VAR11)\ngoto VAR12;\nVAR5 = 0;\nFUN6(&VAR22);\nwhile (!VAR11 && (VAR20 != VAR21) && VAR5 < VAR3) {\nVAR10 = FUN7(VAR20);\nVAR20++;\nFUN8(&VAR22);\nVAR11 = FUN9(VAR10,VAR2);\nVAR2++;\nVAR5++;\nFUN10();\nFUN6(&VAR22);\n}\nFUN8(&VAR22);\nif (!VAR11)\nVAR11 = VAR5;\nbreak;\ncase VAR23:\nVAR9 = 1;\ncase VAR24:\nVAR11 = -VAR16;\nif (!VAR2 || VAR3 < 0)\ngoto VAR12;\nVAR11 = 0;\nif (!VAR3)\ngoto VAR12;\nif (!FUN4(VAR17, VAR2, VAR3)) {\nVAR11 = -VAR18;\ngoto VAR12;\n}\nVAR8 = VAR3;\nif (VAR8 > VAR25)\nVAR8 = VAR25;\nFUN6(&VAR22);\nif (VAR8 > VAR26)\nVAR8 = VAR26;\nif (VAR9)\nVAR26 = 0;\nVAR7 = VAR21;\nfor (VAR5 = 0; VAR5 < VAR8 && !VAR11; VAR5++) {\nVAR6 = VAR7-1-VAR5;\nif (VAR6 + VAR25 < VAR21)\nbreak;\nVAR10 = FUN7(VAR6);\nFUN8(&VAR22);\nVAR11 = FUN9(VAR10,&VAR2[VAR8-1-VAR5]);\nFUN10();\nFUN6(&VAR22);\n}\nFUN8(&VAR22);\nif (VAR11)\nbreak;\nVAR11 = VAR5;\nif (VAR5 != VAR8) {\nint VAR27 = VAR8-VAR11;\nfor (VAR5 = 0; VAR5 < VAR11; VAR5++) {\nif (FUN11(VAR10,&VAR2[VAR5+VAR27]) ||\nFUN9(VAR10,&VAR2[VAR5])) {\nVAR11 = -VAR18;\nbreak;\n}\nFUN10();\n}\n}\nbreak;\ncase VAR28:\nVAR26 = 0;\nbreak;\ncase VAR29:\nif (VAR30 == -1)\nVAR30 = VAR31;\nVAR31 = VAR32;\nbreak;\ncase VAR33:\nif (VAR30 != -1) {\nVAR31 = VAR30;\nVAR30 = -1;\n}\nbreak;\ncase VAR34:\nVAR11 = -VAR16;\nif (VAR3 < 1 || VAR3 > 8)\ngoto VAR12;\nif (VAR3 < VAR32)\nVAR3 = VAR32;\nVAR31 = VAR3;\nVAR30 = -1;\nVAR11 = 0;\nbreak;\ncase VAR35:\nVAR11 = VAR21 - VAR20;\nbreak;\ncase VAR36:\nVAR11 = VAR25;\nbreak;\ndefault:\nVAR11 = -VAR16;\nbreak;\n}\nVAR12:\nreturn VAR11;\n}\n",
      "code_after_change_raw": "int do_syslog(int type, char __user *buf, int len, bool from_file)\n{\nbool clear = false;\nstatic int saved_console_loglevel = -1;\nint error;\nerror = check_syslog_permissions(type, from_file);\nif (error)\ngoto out;\nerror = security_syslog(type);\nif (error)\nreturn error;\nswitch (type) {\ncase SYSLOG_ACTION_CLOSE:\t\nbreak;\ncase SYSLOG_ACTION_OPEN:\t\nbreak;\ncase SYSLOG_ACTION_READ:\t\nerror = -EINVAL;\nif (!buf || len < 0)\ngoto out;\nerror = 0;\nif (!len)\ngoto out;\nif (!access_ok(VERIFY_WRITE, buf, len)) {\nerror = -EFAULT;\ngoto out;\n}\nerror = wait_event_interruptible(log_wait,\nsyslog_seq != log_next_seq);\nif (error)\ngoto out;\nerror = syslog_print(buf, len);\nbreak;\ncase SYSLOG_ACTION_READ_CLEAR:\nclear = true;\ncase SYSLOG_ACTION_READ_ALL:\nerror = -EINVAL;\nif (!buf || len < 0)\ngoto out;\nerror = 0;\nif (!len)\ngoto out;\nif (!access_ok(VERIFY_WRITE, buf, len)) {\nerror = -EFAULT;\ngoto out;\n}\nerror = syslog_print_all(buf, len, clear);\nbreak;\ncase SYSLOG_ACTION_CLEAR:\nsyslog_print_all(NULL, 0, true);\ncase SYSLOG_ACTION_CONSOLE_OFF:\nif (saved_console_loglevel == -1)\nsaved_console_loglevel = console_loglevel;\nconsole_loglevel = minimum_console_loglevel;\nbreak;\ncase SYSLOG_ACTION_CONSOLE_ON:\nif (saved_console_loglevel != -1) {\nconsole_loglevel = saved_console_loglevel;\nsaved_console_loglevel = -1;\n}\nbreak;\ncase SYSLOG_ACTION_CONSOLE_LEVEL:\nerror = -EINVAL;\nif (len < 1 || len > 8)\ngoto out;\nif (len < minimum_console_loglevel)\nlen = minimum_console_loglevel;\nconsole_loglevel = len;\nsaved_console_loglevel = -1;\nerror = 0;\nbreak;\ncase SYSLOG_ACTION_SIZE_UNREAD:\nraw_spin_lock_irq(&logbuf_lock);\nif (syslog_seq < log_first_seq) {\nsyslog_seq = log_first_seq;\nsyslog_idx = log_first_idx;\n}\nif (from_file) {\nerror = log_next_idx - syslog_idx;\n} else {\nu64 seq;\nu32 idx;\nerror = 0;\nseq = syslog_seq;\nidx = syslog_idx;\nwhile (seq < log_next_seq) {\nerror += syslog_print_line(idx, NULL, 0);\nidx = log_next(idx);\nseq++;\n}\n}\nraw_spin_unlock_irq(&logbuf_lock);\nbreak;\ncase SYSLOG_ACTION_SIZE_BUFFER:\nerror = log_buf_len;\nbreak;\ndefault:\nerror = -EINVAL;\nbreak;\n}\nout:\nreturn error;\n}\n",
      "code_before_change_raw": "int do_syslog(int type, char __user *buf, int len, bool from_file)\n{\nunsigned i, j, limit, count;\nint do_clear = 0;\nchar c;\nint error;\nerror = check_syslog_permissions(type, from_file);\nif (error)\ngoto out;\nerror = security_syslog(type);\nif (error)\nreturn error;\nswitch (type) {\ncase SYSLOG_ACTION_CLOSE:\t\nbreak;\ncase SYSLOG_ACTION_OPEN:\t\nbreak;\ncase SYSLOG_ACTION_READ:\t\nerror = -EINVAL;\nif (!buf || len < 0)\ngoto out;\nerror = 0;\nif (!len)\ngoto out;\nif (!access_ok(VERIFY_WRITE, buf, len)) {\nerror = -EFAULT;\ngoto out;\n}\nerror = wait_event_interruptible(log_wait,\n(log_start - log_end));\nif (error)\ngoto out;\ni = 0;\nraw_spin_lock_irq(&logbuf_lock);\nwhile (!error && (log_start != log_end) && i < len) {\nc = LOG_BUF(log_start);\nlog_start++;\nraw_spin_unlock_irq(&logbuf_lock);\nerror = __put_user(c,buf);\nbuf++;\ni++;\ncond_resched();\nraw_spin_lock_irq(&logbuf_lock);\n}\nraw_spin_unlock_irq(&logbuf_lock);\nif (!error)\nerror = i;\nbreak;\ncase SYSLOG_ACTION_READ_CLEAR:\ndo_clear = 1;\ncase SYSLOG_ACTION_READ_ALL:\nerror = -EINVAL;\nif (!buf || len < 0)\ngoto out;\nerror = 0;\nif (!len)\ngoto out;\nif (!access_ok(VERIFY_WRITE, buf, len)) {\nerror = -EFAULT;\ngoto out;\n}\ncount = len;\nif (count > log_buf_len)\ncount = log_buf_len;\nraw_spin_lock_irq(&logbuf_lock);\nif (count > logged_chars)\ncount = logged_chars;\nif (do_clear)\nlogged_chars = 0;\nlimit = log_end;\nfor (i = 0; i < count && !error; i++) {\nj = limit-1-i;\nif (j + log_buf_len < log_end)\nbreak;\nc = LOG_BUF(j);\nraw_spin_unlock_irq(&logbuf_lock);\nerror = __put_user(c,&buf[count-1-i]);\ncond_resched();\nraw_spin_lock_irq(&logbuf_lock);\n}\nraw_spin_unlock_irq(&logbuf_lock);\nif (error)\nbreak;\nerror = i;\nif (i != count) {\nint offset = count-error;\nfor (i = 0; i < error; i++) {\nif (__get_user(c,&buf[i+offset]) ||\n__put_user(c,&buf[i])) {\nerror = -EFAULT;\nbreak;\n}\ncond_resched();\n}\n}\nbreak;\ncase SYSLOG_ACTION_CLEAR:\nlogged_chars = 0;\nbreak;\ncase SYSLOG_ACTION_CONSOLE_OFF:\nif (saved_console_loglevel == -1)\nsaved_console_loglevel = console_loglevel;\nconsole_loglevel = minimum_console_loglevel;\nbreak;\ncase SYSLOG_ACTION_CONSOLE_ON:\nif (saved_console_loglevel != -1) {\nconsole_loglevel = saved_console_loglevel;\nsaved_console_loglevel = -1;\n}\nbreak;\ncase SYSLOG_ACTION_CONSOLE_LEVEL:\nerror = -EINVAL;\nif (len < 1 || len > 8)\ngoto out;\nif (len < minimum_console_loglevel)\nlen = minimum_console_loglevel;\nconsole_loglevel = len;\nsaved_console_loglevel = -1;\nerror = 0;\nbreak;\ncase SYSLOG_ACTION_SIZE_UNREAD:\nerror = log_end - log_start;\nbreak;\ncase SYSLOG_ACTION_SIZE_BUFFER:\nerror = log_buf_len;\nbreak;\ndefault:\nerror = -EINVAL;\nbreak;\n}\nout:\nreturn error;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of syslog header prefix string in the log_prefix function.",
        "trigger_condition": "Local users with /dev/kmsg write access can exploit the vulnerability by triggering a call_console_drivers function call.",
        "specific_code_behavior_causing_vulnerability": "The code in the printk function does not properly remove the prefix string from a syslog header, leading to a buffer overflow and system crash when a call_console_drivers function call is triggered.",
        "solution": "To mitigate the vulnerability, the code should be modified to use the vprintk_emit function instead of vprintk. This change ensures proper handling of the syslog header prefix string, preventing buffer overflow and system crash when a call_console_drivers function call is triggered."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-1772 by changing the call to the vprintk function to vprintk_emit function. This change ensures that the log_prefix function in kernel/printk.c properly handles the syslog header prefix string, preventing a buffer overflow and system crash that could be triggered by a local user with /dev/kmsg write access. By using vprintk_emit with appropriate parameters, the vulnerability is mitigated, and the system is protected from the potential denial of service attack described in the vulnerability report.",
      "GPT_purpose": "Print a formatted message to the kernel log.",
      "GPT_function": "\n1. Define the printk function with variable arguments.\n2. Check for a specific configuration option related to kernel debugging.\n3. Call the vprintk function with the provided format string and arguments.",
      "CVE_id": "CVE-2013-1772",
      "code_before_change": "asmlinkage int printk(const char *fmt, ...)\n{\n\tva_list args;\n\tint r;\n\n#ifdef CONFIG_KGDB_KDB\n\tif (unlikely(kdb_trap_printk)) {\n\t\tva_start(args, fmt);\n\t\tr = vkdb_printf(fmt, args);\n\t\tva_end(args);\n\t\treturn r;\n\t}\n#endif\n\tva_start(args, fmt);\n\tr = vprintk(fmt, args);\n\tva_end(args);\n\n\treturn r;\n}",
      "code_after_change": "asmlinkage int printk(const char *fmt, ...)\n{\n\tva_list args;\n\tint r;\n\n#ifdef CONFIG_KGDB_KDB\n\tif (unlikely(kdb_trap_printk)) {\n\t\tva_start(args, fmt);\n\t\tr = vkdb_printf(fmt, args);\n\t\tva_end(args);\n\t\treturn r;\n\t}\n#endif\n\tva_start(args, fmt);\n\tr = vprintk_emit(0, -1, NULL, 0, fmt, args);\n\tva_end(args);\n\n\treturn r;\n}",
      "modified_lines": {
        "added": [
          "\tr = vprintk_emit(0, -1, NULL, 0, fmt, args);"
        ],
        "deleted": [
          "\tr = vprintk(fmt, args);"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of syslog header prefix string in the log_prefix function.",
      "trigger_condition": "Local users with /dev/kmsg write access can exploit the vulnerability by triggering a call_console_drivers function call.",
      "specific_code_behavior_causing_vulnerability": "The code in the printk function does not properly remove the prefix string from a syslog header, leading to a buffer overflow and system crash when a call_console_drivers function call is triggered.",
      "solution": "To mitigate the vulnerability, the code should be modified to use the vprintk_emit function instead of vprintk. This change ensures proper handling of the syslog header prefix string, preventing buffer overflow and system crash when a call_console_drivers function call is triggered.",
      "id": 22,
      "code_after_change_normalized": "asmlinkage int FUN1(const char *VAR1, ...)\n{\nva_list VAR2;\nint VAR3;\n#ifdef VAR4\nif (FUN2(VAR5)) {\nFUN3(VAR2, VAR1);\nVAR3 = FUN4(VAR1, VAR2);\nFUN5(VAR2);\nreturn VAR3;\n}\n#VAR6\nFUN3(VAR2, VAR1);\nVAR3 = FUN6(0, -1, NULL, 0, VAR1, VAR2);\nFUN5(VAR2);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "asmlinkage int FUN1(const char *VAR1, ...)\n{\nva_list VAR2;\nint VAR3;\n#ifdef VAR4\nif (FUN2(VAR5)) {\nFUN3(VAR2, VAR1);\nVAR3 = FUN4(VAR1, VAR2);\nFUN5(VAR2);\nreturn VAR3;\n}\n#VAR6\nFUN3(VAR2, VAR1);\nVAR3 = FUN6(VAR1, VAR2);\nFUN5(VAR2);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "asmlinkage int printk(const char *fmt, ...)\n{\nva_list args;\nint r;\n#ifdef CONFIG_KGDB_KDB\nif (unlikely(kdb_trap_printk)) {\nva_start(args, fmt);\nr = vkdb_printf(fmt, args);\nva_end(args);\nreturn r;\n}\n#endif\nva_start(args, fmt);\nr = vprintk_emit(0, -1, NULL, 0, fmt, args);\nva_end(args);\nreturn r;\n}\n",
      "code_before_change_raw": "asmlinkage int printk(const char *fmt, ...)\n{\nva_list args;\nint r;\n#ifdef CONFIG_KGDB_KDB\nif (unlikely(kdb_trap_printk)) {\nva_start(args, fmt);\nr = vkdb_printf(fmt, args);\nva_end(args);\nreturn r;\n}\n#endif\nva_start(args, fmt);\nr = vprintk(fmt, args);\nva_end(args);\nreturn r;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of syslog header prefix string in the log buffer.",
        "trigger_condition": "Local user leverages /dev/kmsg write access and triggers a call_console_drivers function call, leading to a buffer overflow and system crash.",
        "specific_code_behavior_causing_vulnerability": "The original code does not properly remove a prefix string from the syslog header, allowing for a buffer overflow and system crash when specific conditions are met."
      },
      "solution": "To mitigate the vulnerability, it is necessary to update the code to handle the syslog header prefix string correctly. This involves modifying the logic for determining the start and end points of the log buffer to prevent buffer overflows and system crashes. By making these changes, the code ensures proper handling of the syslog header and reduces the risk of exploitation.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2013-1772, which involves a buffer overflow and system crash caused by improper handling of a prefix string in the syslog header. \n\nThe original code snippet does not properly handle the syslog header prefix string, which can lead to a denial of service when a local user leverages /dev/kmsg write access and triggers a call_console_drivers function call.\n\nThe modified code snippet addresses this vulnerability by introducing changes that ensure proper handling of the syslog header and prevent buffer overflow and system crashes. Specifically, the modification includes updating the logic for determining the start and end points of the log buffer to prevent potential buffer overflows and crashes.\n\nBy making these changes, the code is more secure and less susceptible to exploitation, thereby mitigating the vulnerability described in CVE-2013-1772.",
      "GPT_purpose": "Dump kernel messages for debugging purposes.",
      "GPT_function": "\n1. kmsg_dump function that dumps kernel messages based on a specified reason.\n2. Acquires log buffer information and splits it into two parts for dumping.\n3. Iterates through a list of dumpers and calls their dump function with the message parts.",
      "CVE_id": "CVE-2013-1772",
      "code_before_change": "void kmsg_dump(enum kmsg_dump_reason reason)\n{\n\tunsigned long end;\n\tunsigned chars;\n\tstruct kmsg_dumper *dumper;\n\tconst char *s1, *s2;\n\tunsigned long l1, l2;\n\tunsigned long flags;\n\n\tif ((reason > KMSG_DUMP_OOPS) && !always_kmsg_dump)\n\t\treturn;\n\n\t/* Theoretically, the log could move on after we do this, but\n\t   there's not a lot we can do about that. The new messages\n\t   will overwrite the start of what we dump. */\n\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\tend = log_end & LOG_BUF_MASK;\n\tchars = logged_chars;\n\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\n\tif (chars > end) {\n\t\ts1 = log_buf + log_buf_len - chars + end;\n\t\tl1 = chars - end;\n\n\t\ts2 = log_buf;\n\t\tl2 = end;\n\t} else {\n\t\ts1 = \"\";\n\t\tl1 = 0;\n\n\t\ts2 = log_buf + end - chars;\n\t\tl2 = chars;\n\t}\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(dumper, &dump_list, list)\n\t\tdumper->dump(dumper, reason, s1, l1, s2, l2);\n\trcu_read_unlock();\n}",
      "code_after_change": "void kmsg_dump(enum kmsg_dump_reason reason)\n{\n\tu64 idx;\n\tstruct kmsg_dumper *dumper;\n\tconst char *s1, *s2;\n\tunsigned long l1, l2;\n\tunsigned long flags;\n\n\tif ((reason > KMSG_DUMP_OOPS) && !always_kmsg_dump)\n\t\treturn;\n\n\t/* Theoretically, the log could move on after we do this, but\n\t   there's not a lot we can do about that. The new messages\n\t   will overwrite the start of what we dump. */\n\n\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\tif (syslog_seq < log_first_seq)\n\t\tidx = syslog_idx;\n\telse\n\t\tidx = log_first_idx;\n\n\tif (idx > log_next_idx) {\n\t\ts1 = log_buf;\n\t\tl1 = log_next_idx;\n\n\t\ts2 = log_buf + idx;\n\t\tl2 = log_buf_len - idx;\n\t} else {\n\t\ts1 = \"\";\n\t\tl1 = 0;\n\n\t\ts2 = log_buf + idx;\n\t\tl2 = log_next_idx - idx;\n\t}\n\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(dumper, &dump_list, list)\n\t\tdumper->dump(dumper, reason, s1, l1, s2, l2);\n\trcu_read_unlock();\n}",
      "modified_lines": {
        "added": [
          "\tu64 idx;",
          "",
          "\tif (syslog_seq < log_first_seq)",
          "\t\tidx = syslog_idx;",
          "\telse",
          "\t\tidx = log_first_idx;",
          "\tif (idx > log_next_idx) {",
          "\t\ts1 = log_buf;",
          "\t\tl1 = log_next_idx;",
          "\t\ts2 = log_buf + idx;",
          "\t\tl2 = log_buf_len - idx;",
          "\t\ts2 = log_buf + idx;",
          "\t\tl2 = log_next_idx - idx;",
          "\traw_spin_unlock_irqrestore(&logbuf_lock, flags);"
        ],
        "deleted": [
          "\tunsigned long end;",
          "\tunsigned chars;",
          "\tend = log_end & LOG_BUF_MASK;",
          "\tchars = logged_chars;",
          "\traw_spin_unlock_irqrestore(&logbuf_lock, flags);",
          "\tif (chars > end) {",
          "\t\ts1 = log_buf + log_buf_len - chars + end;",
          "\t\tl1 = chars - end;",
          "\t\ts2 = log_buf;",
          "\t\tl2 = end;",
          "\t\ts2 = log_buf + end - chars;",
          "\t\tl2 = chars;"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of syslog header prefix string in the log buffer.",
      "trigger_condition": "Local user leverages /dev/kmsg write access and triggers a call_console_drivers function call, leading to a buffer overflow and system crash.",
      "specific_code_behavior_causing_vulnerability": "The original code does not properly remove a prefix string from the syslog header, allowing for a buffer overflow and system crash when specific conditions are met.",
      "id": 23,
      "code_after_change_normalized": "void FUN1(enum kmsg_dump_reason VAR1)\n{\nu64 VAR2;\nstruct kmsg_dumper *VAR3;\nconst char *VAR4, *VAR5;\nunsigned long VAR6, VAR7;\nunsigned long VAR8;\nif ((VAR1 > VAR9) && !VAR10)\nreturn;\nFUN2(&VAR11, VAR8);\nif (VAR12 < VAR13)\nVAR2 = VAR14;\nelse\nVAR2 = VAR15;\nif (VAR2 > VAR16) {\nVAR4 = VAR17;\nVAR6 = VAR16;\nVAR5 = VAR17 + VAR2;\nVAR7 = VAR18 - VAR2;\n} else {\nVAR4 = \"STR\";\nVAR6 = 0;\nVAR5 = VAR17 + VAR2;\nVAR7 = VAR16 - VAR2;\n}\nFUN3(&VAR11, VAR8);\nFUN4();\nFUN5(VAR3, &VAR19, VAR20)\nVAR3->FUN6(VAR3, VAR1, VAR4, VAR6, VAR5, VAR7);\nFUN7();\n}\n",
      "code_before_change_normalized": "void FUN1(enum kmsg_dump_reason VAR1)\n{\nunsigned long VAR2;\nunsigned VAR3;\nstruct kmsg_dumper *VAR4;\nconst char *VAR5, *VAR6;\nunsigned long VAR7, VAR8;\nunsigned long VAR9;\nif ((VAR1 > VAR10) && !VAR11)\nreturn;\nFUN2(&VAR12, VAR9);\nVAR2 = VAR13 & VAR14;\nVAR3 = VAR15;\nFUN3(&VAR12, VAR9);\nif (VAR3 > VAR2) {\nVAR5 = VAR16 + VAR17 - VAR3 + VAR2;\nVAR7 = VAR3 - VAR2;\nVAR6 = VAR16;\nVAR8 = VAR2;\n} else {\nVAR5 = \"STR\";\nVAR7 = 0;\nVAR6 = VAR16 + VAR2 - VAR3;\nVAR8 = VAR3;\n}\nFUN4();\nFUN5(VAR4, &VAR18, VAR19)\nVAR4->FUN6(VAR4, VAR1, VAR5, VAR7, VAR6, VAR8);\nFUN7();\n}\n",
      "code_after_change_raw": "void kmsg_dump(enum kmsg_dump_reason reason)\n{\nu64 idx;\nstruct kmsg_dumper *dumper;\nconst char *s1, *s2;\nunsigned long l1, l2;\nunsigned long flags;\nif ((reason > KMSG_DUMP_OOPS) && !always_kmsg_dump)\nreturn;\nraw_spin_lock_irqsave(&logbuf_lock, flags);\nif (syslog_seq < log_first_seq)\nidx = syslog_idx;\nelse\nidx = log_first_idx;\nif (idx > log_next_idx) {\ns1 = log_buf;\nl1 = log_next_idx;\ns2 = log_buf + idx;\nl2 = log_buf_len - idx;\n} else {\ns1 = \"\";\nl1 = 0;\ns2 = log_buf + idx;\nl2 = log_next_idx - idx;\n}\nraw_spin_unlock_irqrestore(&logbuf_lock, flags);\nrcu_read_lock();\nlist_for_each_entry_rcu(dumper, &dump_list, list)\ndumper->dump(dumper, reason, s1, l1, s2, l2);\nrcu_read_unlock();\n}\n",
      "code_before_change_raw": "void kmsg_dump(enum kmsg_dump_reason reason)\n{\nunsigned long end;\nunsigned chars;\nstruct kmsg_dumper *dumper;\nconst char *s1, *s2;\nunsigned long l1, l2;\nunsigned long flags;\nif ((reason > KMSG_DUMP_OOPS) && !always_kmsg_dump)\nreturn;\nraw_spin_lock_irqsave(&logbuf_lock, flags);\nend = log_end & LOG_BUF_MASK;\nchars = logged_chars;\nraw_spin_unlock_irqrestore(&logbuf_lock, flags);\nif (chars > end) {\ns1 = log_buf + log_buf_len - chars + end;\nl1 = chars - end;\ns2 = log_buf;\nl2 = end;\n} else {\ns1 = \"\";\nl1 = 0;\ns2 = log_buf + end - chars;\nl2 = chars;\n}\nrcu_read_lock();\nlist_for_each_entry_rcu(dumper, &dump_list, list)\ndumper->dump(dumper, reason, s1, l1, s2, l2);\nrcu_read_unlock();\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of a prefix string in the syslog header, allowing a denial of service vulnerability.",
        "trigger_condition": "Local users with /dev/kmsg write access can exploit the vulnerability by triggering a call_console_drivers function call.",
        "specific_code_behavior_causing_vulnerability": "The code in the log_prefix function does not properly remove a prefix string from a syslog header, leading to a buffer overflow and system crash when triggered by specific user actions."
      },
      "solution": "To address the vulnerability, it is necessary to ensure that the prefix string is correctly removed from the syslog header to prevent buffer overflow and system crash. The solution involves updating the code to handle the prefix string removal securely, mitigating the risk of exploitation by local users with /dev/kmsg write access. In this case, the solution includes modifying the code to properly remove the prefix string from the syslog header, thereby preventing the buffer overflow and system crash vulnerability.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-1772, which involves a buffer overflow and system crash caused by improper handling of a prefix string in the syslog header. By updating the code to properly remove the prefix string from the syslog header, the vulnerability can be mitigated, preventing potential exploitation by local users with /dev/kmsg write access. This modification ensures that the log buffer is handled correctly and avoids triggering the vulnerable call_console_drivers function call, thus enhancing the security and stability of the system.",
      "GPT_purpose": "Registering and enabling console drivers in the Linux kernel.",
      "GPT_function": "\n1. Registering a new console driver.\n2. Checking for existing console drivers and handling boot consoles.\n3. Setting up the preferred console and enabling the new console driver.\n4. Matching console settings from the command line.\n5. Adding the new console to the list of console drivers.\n6. Handling log buffer printing and notifications.\n7. Unregistering boot consoles if necessary.",
      "CVE_id": "CVE-2013-1772",
      "code_before_change": "void register_console(struct console *newcon)\n{\n\tint i;\n\tunsigned long flags;\n\tstruct console *bcon = NULL;\n\n\t/*\n\t * before we register a new CON_BOOT console, make sure we don't\n\t * already have a valid console\n\t */\n\tif (console_drivers && newcon->flags & CON_BOOT) {\n\t\t/* find the last or real console */\n\t\tfor_each_console(bcon) {\n\t\t\tif (!(bcon->flags & CON_BOOT)) {\n\t\t\t\tprintk(KERN_INFO \"Too late to register bootconsole %s%d\\n\",\n\t\t\t\t\tnewcon->name, newcon->index);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (console_drivers && console_drivers->flags & CON_BOOT)\n\t\tbcon = console_drivers;\n\n\tif (preferred_console < 0 || bcon || !console_drivers)\n\t\tpreferred_console = selected_console;\n\n\tif (newcon->early_setup)\n\t\tnewcon->early_setup();\n\n\t/*\n\t *\tSee if we want to use this console driver. If we\n\t *\tdidn't select a console we take the first one\n\t *\tthat registers here.\n\t */\n\tif (preferred_console < 0) {\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = 0;\n\t\tif (newcon->setup == NULL ||\n\t\t    newcon->setup(newcon, NULL) == 0) {\n\t\t\tnewcon->flags |= CON_ENABLED;\n\t\t\tif (newcon->device) {\n\t\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\t\tpreferred_console = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t *\tSee if this console matches one we selected on\n\t *\tthe command line.\n\t */\n\tfor (i = 0; i < MAX_CMDLINECONSOLES && console_cmdline[i].name[0];\n\t\t\ti++) {\n\t\tif (strcmp(console_cmdline[i].name, newcon->name) != 0)\n\t\t\tcontinue;\n\t\tif (newcon->index >= 0 &&\n\t\t    newcon->index != console_cmdline[i].index)\n\t\t\tcontinue;\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = console_cmdline[i].index;\n#ifdef CONFIG_A11Y_BRAILLE_CONSOLE\n\t\tif (console_cmdline[i].brl_options) {\n\t\t\tnewcon->flags |= CON_BRL;\n\t\t\tbraille_register_console(newcon,\n\t\t\t\t\tconsole_cmdline[i].index,\n\t\t\t\t\tconsole_cmdline[i].options,\n\t\t\t\t\tconsole_cmdline[i].brl_options);\n\t\t\treturn;\n\t\t}\n#endif\n\t\tif (newcon->setup &&\n\t\t    newcon->setup(newcon, console_cmdline[i].options) != 0)\n\t\t\tbreak;\n\t\tnewcon->flags |= CON_ENABLED;\n\t\tnewcon->index = console_cmdline[i].index;\n\t\tif (i == selected_console) {\n\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\tpreferred_console = selected_console;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (!(newcon->flags & CON_ENABLED))\n\t\treturn;\n\n\t/*\n\t * If we have a bootconsole, and are switching to a real console,\n\t * don't print everything out again, since when the boot console, and\n\t * the real console are the same physical device, it's annoying to\n\t * see the beginning boot messages twice\n\t */\n\tif (bcon && ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV))\n\t\tnewcon->flags &= ~CON_PRINTBUFFER;\n\n\t/*\n\t *\tPut this console in the list - keep the\n\t *\tpreferred driver at the head of the list.\n\t */\n\tconsole_lock();\n\tif ((newcon->flags & CON_CONSDEV) || console_drivers == NULL) {\n\t\tnewcon->next = console_drivers;\n\t\tconsole_drivers = newcon;\n\t\tif (newcon->next)\n\t\t\tnewcon->next->flags &= ~CON_CONSDEV;\n\t} else {\n\t\tnewcon->next = console_drivers->next;\n\t\tconsole_drivers->next = newcon;\n\t}\n\tif (newcon->flags & CON_PRINTBUFFER) {\n\t\t/*\n\t\t * console_unlock(); will print out the buffered messages\n\t\t * for us.\n\t\t */\n\t\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\t\tcon_start = log_start;\n\t\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\t\t/*\n\t\t * We're about to replay the log buffer.  Only do this to the\n\t\t * just-registered console to avoid excessive message spam to\n\t\t * the already-registered consoles.\n\t\t */\n\t\texclusive_console = newcon;\n\t}\n\tconsole_unlock();\n\tconsole_sysfs_notify();\n\n\t/*\n\t * By unregistering the bootconsoles after we enable the real console\n\t * we get the \"console xxx enabled\" message on all the consoles -\n\t * boot consoles, real consoles, etc - this is to ensure that end\n\t * users know there might be something in the kernel's log buffer that\n\t * went to the bootconsole (that they do not see on the real console)\n\t */\n\tif (bcon &&\n\t    ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV) &&\n\t    !keep_bootcon) {\n\t\t/* we need to iterate through twice, to make sure we print\n\t\t * everything out, before we unregister the console(s)\n\t\t */\n\t\tprintk(KERN_INFO \"console [%s%d] enabled, bootconsole disabled\\n\",\n\t\t\tnewcon->name, newcon->index);\n\t\tfor_each_console(bcon)\n\t\t\tif (bcon->flags & CON_BOOT)\n\t\t\t\tunregister_console(bcon);\n\t} else {\n\t\tprintk(KERN_INFO \"%sconsole [%s%d] enabled\\n\",\n\t\t\t(newcon->flags & CON_BOOT) ? \"boot\" : \"\" ,\n\t\t\tnewcon->name, newcon->index);\n\t}\n}",
      "code_after_change": "void register_console(struct console *newcon)\n{\n\tint i;\n\tunsigned long flags;\n\tstruct console *bcon = NULL;\n\n\t/*\n\t * before we register a new CON_BOOT console, make sure we don't\n\t * already have a valid console\n\t */\n\tif (console_drivers && newcon->flags & CON_BOOT) {\n\t\t/* find the last or real console */\n\t\tfor_each_console(bcon) {\n\t\t\tif (!(bcon->flags & CON_BOOT)) {\n\t\t\t\tprintk(KERN_INFO \"Too late to register bootconsole %s%d\\n\",\n\t\t\t\t\tnewcon->name, newcon->index);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (console_drivers && console_drivers->flags & CON_BOOT)\n\t\tbcon = console_drivers;\n\n\tif (preferred_console < 0 || bcon || !console_drivers)\n\t\tpreferred_console = selected_console;\n\n\tif (newcon->early_setup)\n\t\tnewcon->early_setup();\n\n\t/*\n\t *\tSee if we want to use this console driver. If we\n\t *\tdidn't select a console we take the first one\n\t *\tthat registers here.\n\t */\n\tif (preferred_console < 0) {\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = 0;\n\t\tif (newcon->setup == NULL ||\n\t\t    newcon->setup(newcon, NULL) == 0) {\n\t\t\tnewcon->flags |= CON_ENABLED;\n\t\t\tif (newcon->device) {\n\t\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\t\tpreferred_console = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t *\tSee if this console matches one we selected on\n\t *\tthe command line.\n\t */\n\tfor (i = 0; i < MAX_CMDLINECONSOLES && console_cmdline[i].name[0];\n\t\t\ti++) {\n\t\tif (strcmp(console_cmdline[i].name, newcon->name) != 0)\n\t\t\tcontinue;\n\t\tif (newcon->index >= 0 &&\n\t\t    newcon->index != console_cmdline[i].index)\n\t\t\tcontinue;\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = console_cmdline[i].index;\n#ifdef CONFIG_A11Y_BRAILLE_CONSOLE\n\t\tif (console_cmdline[i].brl_options) {\n\t\t\tnewcon->flags |= CON_BRL;\n\t\t\tbraille_register_console(newcon,\n\t\t\t\t\tconsole_cmdline[i].index,\n\t\t\t\t\tconsole_cmdline[i].options,\n\t\t\t\t\tconsole_cmdline[i].brl_options);\n\t\t\treturn;\n\t\t}\n#endif\n\t\tif (newcon->setup &&\n\t\t    newcon->setup(newcon, console_cmdline[i].options) != 0)\n\t\t\tbreak;\n\t\tnewcon->flags |= CON_ENABLED;\n\t\tnewcon->index = console_cmdline[i].index;\n\t\tif (i == selected_console) {\n\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\tpreferred_console = selected_console;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (!(newcon->flags & CON_ENABLED))\n\t\treturn;\n\n\t/*\n\t * If we have a bootconsole, and are switching to a real console,\n\t * don't print everything out again, since when the boot console, and\n\t * the real console are the same physical device, it's annoying to\n\t * see the beginning boot messages twice\n\t */\n\tif (bcon && ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV))\n\t\tnewcon->flags &= ~CON_PRINTBUFFER;\n\n\t/*\n\t *\tPut this console in the list - keep the\n\t *\tpreferred driver at the head of the list.\n\t */\n\tconsole_lock();\n\tif ((newcon->flags & CON_CONSDEV) || console_drivers == NULL) {\n\t\tnewcon->next = console_drivers;\n\t\tconsole_drivers = newcon;\n\t\tif (newcon->next)\n\t\t\tnewcon->next->flags &= ~CON_CONSDEV;\n\t} else {\n\t\tnewcon->next = console_drivers->next;\n\t\tconsole_drivers->next = newcon;\n\t}\n\tif (newcon->flags & CON_PRINTBUFFER) {\n\t\t/*\n\t\t * console_unlock(); will print out the buffered messages\n\t\t * for us.\n\t\t */\n\t\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\t\tconsole_seq = syslog_seq;\n\t\tconsole_idx = syslog_idx;\n\t\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\t\t/*\n\t\t * We're about to replay the log buffer.  Only do this to the\n\t\t * just-registered console to avoid excessive message spam to\n\t\t * the already-registered consoles.\n\t\t */\n\t\texclusive_console = newcon;\n\t}\n\tconsole_unlock();\n\tconsole_sysfs_notify();\n\n\t/*\n\t * By unregistering the bootconsoles after we enable the real console\n\t * we get the \"console xxx enabled\" message on all the consoles -\n\t * boot consoles, real consoles, etc - this is to ensure that end\n\t * users know there might be something in the kernel's log buffer that\n\t * went to the bootconsole (that they do not see on the real console)\n\t */\n\tif (bcon &&\n\t    ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV) &&\n\t    !keep_bootcon) {\n\t\t/* we need to iterate through twice, to make sure we print\n\t\t * everything out, before we unregister the console(s)\n\t\t */\n\t\tprintk(KERN_INFO \"console [%s%d] enabled, bootconsole disabled\\n\",\n\t\t\tnewcon->name, newcon->index);\n\t\tfor_each_console(bcon)\n\t\t\tif (bcon->flags & CON_BOOT)\n\t\t\t\tunregister_console(bcon);\n\t} else {\n\t\tprintk(KERN_INFO \"%sconsole [%s%d] enabled\\n\",\n\t\t\t(newcon->flags & CON_BOOT) ? \"boot\" : \"\" ,\n\t\t\tnewcon->name, newcon->index);\n\t}\n}",
      "modified_lines": {
        "added": [
          "\t\tconsole_seq = syslog_seq;",
          "\t\tconsole_idx = syslog_idx;"
        ],
        "deleted": [
          "\t\tcon_start = log_start;"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of a prefix string in the syslog header, allowing a denial of service vulnerability.",
      "trigger_condition": "Local users with /dev/kmsg write access can exploit the vulnerability by triggering a call_console_drivers function call.",
      "specific_code_behavior_causing_vulnerability": "The code in the log_prefix function does not properly remove a prefix string from a syslog header, leading to a buffer overflow and system crash when triggered by specific user actions.",
      "id": 24,
      "code_after_change_normalized": "void FUN1(struct console *VAR1)\n{\nint VAR2;\nunsigned long VAR3;\nstruct console *VAR4 = NULL;\nif (VAR5 && VAR1->VAR3 & VAR6) {\nFUN2(VAR4) {\nif (!(VAR4->VAR3 & VAR6)) {\nFUN3(VAR7 \"STR\",\nVAR1->VAR8, VAR1->VAR9);\nreturn;\n}\n}\n}\nif (VAR5 && VAR5->VAR3 & VAR6)\nVAR4 = VAR5;\nif (VAR10 < 0 || VAR4 || !VAR5)\nVAR10 = VAR11;\nif (VAR1->VAR12)\nVAR1->FUN4();\nif (VAR10 < 0) {\nif (VAR1->VAR9 < 0)\nVAR1->VAR9 = 0;\nif (VAR1->VAR13 == NULL ||\nVAR1->FUN5(VAR1, NULL) == 0) {\nVAR1->VAR3 |= VAR14;\nif (VAR1->VAR15) {\nVAR1->VAR3 |= VAR16;\nVAR10 = 0;\n}\n}\n}\nfor (VAR2 = 0; VAR2 < VAR17 && VAR18[VAR2].VAR8[0];\nVAR2++) {\nif (FUN6(VAR18[VAR2].VAR8, VAR1->VAR8) != 0)\ncontinue;\nif (VAR1->VAR9 >= 0 &&\nVAR1->VAR9 != VAR18[VAR2].VAR9)\ncontinue;\nif (VAR1->VAR9 < 0)\nVAR1->VAR9 = VAR18[VAR2].VAR9;\n#ifdef VAR19\nif (VAR18[VAR2].VAR20) {\nVAR1->VAR3 |= VAR21;\nFUN7(VAR1,\nVAR18[VAR2].VAR9,\nVAR18[VAR2].VAR22,\nVAR18[VAR2].VAR20);\nreturn;\n}\n#VAR23\nif (VAR1->VAR13 &&\nVAR1->FUN5(VAR1, VAR18[VAR2].VAR22) != 0)\nbreak;\nVAR1->VAR3 |= VAR14;\nVAR1->VAR9 = VAR18[VAR2].VAR9;\nif (VAR2 == VAR11) {\nVAR1->VAR3 |= VAR16;\nVAR10 = VAR11;\n}\nbreak;\n}\nif (!(VAR1->VAR3 & VAR14))\nreturn;\nif (VAR4 && ((VAR1->VAR3 & (VAR16 | VAR6)) == VAR16))\nVAR1->VAR3 &= ~VAR24;\nFUN8();\nif ((VAR1->VAR3 & VAR16) || VAR5 == NULL) {\nVAR1->VAR25 = VAR5;\nVAR5 = VAR1;\nif (VAR1->VAR25)\nVAR1->VAR25->VAR3 &= ~VAR16;\n} else {\nVAR1->VAR25 = VAR5->VAR25;\nVAR5->VAR25 = VAR1;\n}\nif (VAR1->VAR3 & VAR24) {\nFUN9(&VAR26, VAR3);\nVAR27 = VAR28;\nVAR29 = VAR30;\nFUN10(&VAR26, VAR3);\nVAR31 = VAR1;\n}\nFUN11();\nFUN12();\nif (VAR4 &&\n((VAR1->VAR3 & (VAR16 | VAR6)) == VAR16) &&\n!VAR32) {\nFUN3(VAR7 \"STR\",\nVAR1->VAR8, VAR1->VAR9);\nFUN2(VAR4)\nif (VAR4->VAR3 & VAR6)\nFUN13(VAR4);\n} else {\nFUN3(VAR7 \"STR\",\n(VAR1->VAR3 & VAR6) ? \"STR\" : \"STR\" ,\nVAR1->VAR8, VAR1->VAR9);\n}\n}\n",
      "code_before_change_normalized": "void FUN1(struct console *VAR1)\n{\nint VAR2;\nunsigned long VAR3;\nstruct console *VAR4 = NULL;\nif (VAR5 && VAR1->VAR3 & VAR6) {\nFUN2(VAR4) {\nif (!(VAR4->VAR3 & VAR6)) {\nFUN3(VAR7 \"STR\",\nVAR1->VAR8, VAR1->VAR9);\nreturn;\n}\n}\n}\nif (VAR5 && VAR5->VAR3 & VAR6)\nVAR4 = VAR5;\nif (VAR10 < 0 || VAR4 || !VAR5)\nVAR10 = VAR11;\nif (VAR1->VAR12)\nVAR1->FUN4();\nif (VAR10 < 0) {\nif (VAR1->VAR9 < 0)\nVAR1->VAR9 = 0;\nif (VAR1->VAR13 == NULL ||\nVAR1->FUN5(VAR1, NULL) == 0) {\nVAR1->VAR3 |= VAR14;\nif (VAR1->VAR15) {\nVAR1->VAR3 |= VAR16;\nVAR10 = 0;\n}\n}\n}\nfor (VAR2 = 0; VAR2 < VAR17 && VAR18[VAR2].VAR8[0];\nVAR2++) {\nif (FUN6(VAR18[VAR2].VAR8, VAR1->VAR8) != 0)\ncontinue;\nif (VAR1->VAR9 >= 0 &&\nVAR1->VAR9 != VAR18[VAR2].VAR9)\ncontinue;\nif (VAR1->VAR9 < 0)\nVAR1->VAR9 = VAR18[VAR2].VAR9;\n#ifdef VAR19\nif (VAR18[VAR2].VAR20) {\nVAR1->VAR3 |= VAR21;\nFUN7(VAR1,\nVAR18[VAR2].VAR9,\nVAR18[VAR2].VAR22,\nVAR18[VAR2].VAR20);\nreturn;\n}\n#VAR23\nif (VAR1->VAR13 &&\nVAR1->FUN5(VAR1, VAR18[VAR2].VAR22) != 0)\nbreak;\nVAR1->VAR3 |= VAR14;\nVAR1->VAR9 = VAR18[VAR2].VAR9;\nif (VAR2 == VAR11) {\nVAR1->VAR3 |= VAR16;\nVAR10 = VAR11;\n}\nbreak;\n}\nif (!(VAR1->VAR3 & VAR14))\nreturn;\nif (VAR4 && ((VAR1->VAR3 & (VAR16 | VAR6)) == VAR16))\nVAR1->VAR3 &= ~VAR24;\nFUN8();\nif ((VAR1->VAR3 & VAR16) || VAR5 == NULL) {\nVAR1->VAR25 = VAR5;\nVAR5 = VAR1;\nif (VAR1->VAR25)\nVAR1->VAR25->VAR3 &= ~VAR16;\n} else {\nVAR1->VAR25 = VAR5->VAR25;\nVAR5->VAR25 = VAR1;\n}\nif (VAR1->VAR3 & VAR24) {\nFUN9(&VAR26, VAR3);\nVAR27 = VAR28;\nFUN10(&VAR26, VAR3);\nVAR29 = VAR1;\n}\nFUN11();\nFUN12();\nif (VAR4 &&\n((VAR1->VAR3 & (VAR16 | VAR6)) == VAR16) &&\n!VAR30) {\nFUN3(VAR7 \"STR\",\nVAR1->VAR8, VAR1->VAR9);\nFUN2(VAR4)\nif (VAR4->VAR3 & VAR6)\nFUN13(VAR4);\n} else {\nFUN3(VAR7 \"STR\",\n(VAR1->VAR3 & VAR6) ? \"STR\" : \"STR\" ,\nVAR1->VAR8, VAR1->VAR9);\n}\n}\n",
      "code_after_change_raw": "void register_console(struct console *newcon)\n{\nint i;\nunsigned long flags;\nstruct console *bcon = NULL;\nif (console_drivers && newcon->flags & CON_BOOT) {\nfor_each_console(bcon) {\nif (!(bcon->flags & CON_BOOT)) {\nprintk(KERN_INFO \"Too late to register bootconsole %s%d\\n\",\nnewcon->name, newcon->index);\nreturn;\n}\n}\n}\nif (console_drivers && console_drivers->flags & CON_BOOT)\nbcon = console_drivers;\nif (preferred_console < 0 || bcon || !console_drivers)\npreferred_console = selected_console;\nif (newcon->early_setup)\nnewcon->early_setup();\nif (preferred_console < 0) {\nif (newcon->index < 0)\nnewcon->index = 0;\nif (newcon->setup == NULL ||\nnewcon->setup(newcon, NULL) == 0) {\nnewcon->flags |= CON_ENABLED;\nif (newcon->device) {\nnewcon->flags |= CON_CONSDEV;\npreferred_console = 0;\n}\n}\n}\nfor (i = 0; i < MAX_CMDLINECONSOLES && console_cmdline[i].name[0];\ni++) {\nif (strcmp(console_cmdline[i].name, newcon->name) != 0)\ncontinue;\nif (newcon->index >= 0 &&\nnewcon->index != console_cmdline[i].index)\ncontinue;\nif (newcon->index < 0)\nnewcon->index = console_cmdline[i].index;\n#ifdef CONFIG_A11Y_BRAILLE_CONSOLE\nif (console_cmdline[i].brl_options) {\nnewcon->flags |= CON_BRL;\nbraille_register_console(newcon,\nconsole_cmdline[i].index,\nconsole_cmdline[i].options,\nconsole_cmdline[i].brl_options);\nreturn;\n}\n#endif\nif (newcon->setup &&\nnewcon->setup(newcon, console_cmdline[i].options) != 0)\nbreak;\nnewcon->flags |= CON_ENABLED;\nnewcon->index = console_cmdline[i].index;\nif (i == selected_console) {\nnewcon->flags |= CON_CONSDEV;\npreferred_console = selected_console;\n}\nbreak;\n}\nif (!(newcon->flags & CON_ENABLED))\nreturn;\nif (bcon && ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV))\nnewcon->flags &= ~CON_PRINTBUFFER;\nconsole_lock();\nif ((newcon->flags & CON_CONSDEV) || console_drivers == NULL) {\nnewcon->next = console_drivers;\nconsole_drivers = newcon;\nif (newcon->next)\nnewcon->next->flags &= ~CON_CONSDEV;\n} else {\nnewcon->next = console_drivers->next;\nconsole_drivers->next = newcon;\n}\nif (newcon->flags & CON_PRINTBUFFER) {\nraw_spin_lock_irqsave(&logbuf_lock, flags);\nconsole_seq = syslog_seq;\nconsole_idx = syslog_idx;\nraw_spin_unlock_irqrestore(&logbuf_lock, flags);\nexclusive_console = newcon;\n}\nconsole_unlock();\nconsole_sysfs_notify();\nif (bcon &&\n((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV) &&\n!keep_bootcon) {\nprintk(KERN_INFO \"console [%s%d] enabled, bootconsole disabled\\n\",\nnewcon->name, newcon->index);\nfor_each_console(bcon)\nif (bcon->flags & CON_BOOT)\nunregister_console(bcon);\n} else {\nprintk(KERN_INFO \"%sconsole [%s%d] enabled\\n\",\n(newcon->flags & CON_BOOT) ? \"boot\" : \"\" ,\nnewcon->name, newcon->index);\n}\n}\n",
      "code_before_change_raw": "void register_console(struct console *newcon)\n{\nint i;\nunsigned long flags;\nstruct console *bcon = NULL;\nif (console_drivers && newcon->flags & CON_BOOT) {\nfor_each_console(bcon) {\nif (!(bcon->flags & CON_BOOT)) {\nprintk(KERN_INFO \"Too late to register bootconsole %s%d\\n\",\nnewcon->name, newcon->index);\nreturn;\n}\n}\n}\nif (console_drivers && console_drivers->flags & CON_BOOT)\nbcon = console_drivers;\nif (preferred_console < 0 || bcon || !console_drivers)\npreferred_console = selected_console;\nif (newcon->early_setup)\nnewcon->early_setup();\nif (preferred_console < 0) {\nif (newcon->index < 0)\nnewcon->index = 0;\nif (newcon->setup == NULL ||\nnewcon->setup(newcon, NULL) == 0) {\nnewcon->flags |= CON_ENABLED;\nif (newcon->device) {\nnewcon->flags |= CON_CONSDEV;\npreferred_console = 0;\n}\n}\n}\nfor (i = 0; i < MAX_CMDLINECONSOLES && console_cmdline[i].name[0];\ni++) {\nif (strcmp(console_cmdline[i].name, newcon->name) != 0)\ncontinue;\nif (newcon->index >= 0 &&\nnewcon->index != console_cmdline[i].index)\ncontinue;\nif (newcon->index < 0)\nnewcon->index = console_cmdline[i].index;\n#ifdef CONFIG_A11Y_BRAILLE_CONSOLE\nif (console_cmdline[i].brl_options) {\nnewcon->flags |= CON_BRL;\nbraille_register_console(newcon,\nconsole_cmdline[i].index,\nconsole_cmdline[i].options,\nconsole_cmdline[i].brl_options);\nreturn;\n}\n#endif\nif (newcon->setup &&\nnewcon->setup(newcon, console_cmdline[i].options) != 0)\nbreak;\nnewcon->flags |= CON_ENABLED;\nnewcon->index = console_cmdline[i].index;\nif (i == selected_console) {\nnewcon->flags |= CON_CONSDEV;\npreferred_console = selected_console;\n}\nbreak;\n}\nif (!(newcon->flags & CON_ENABLED))\nreturn;\nif (bcon && ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV))\nnewcon->flags &= ~CON_PRINTBUFFER;\nconsole_lock();\nif ((newcon->flags & CON_CONSDEV) || console_drivers == NULL) {\nnewcon->next = console_drivers;\nconsole_drivers = newcon;\nif (newcon->next)\nnewcon->next->flags &= ~CON_CONSDEV;\n} else {\nnewcon->next = console_drivers->next;\nconsole_drivers->next = newcon;\n}\nif (newcon->flags & CON_PRINTBUFFER) {\nraw_spin_lock_irqsave(&logbuf_lock, flags);\ncon_start = log_start;\nraw_spin_unlock_irqrestore(&logbuf_lock, flags);\nexclusive_console = newcon;\n}\nconsole_unlock();\nconsole_sysfs_notify();\nif (bcon &&\n((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV) &&\n!keep_bootcon) {\nprintk(KERN_INFO \"console [%s%d] enabled, bootconsole disabled\\n\",\nnewcon->name, newcon->index);\nfor_each_console(bcon)\nif (bcon->flags & CON_BOOT)\nunregister_console(bcon);\n} else {\nprintk(KERN_INFO \"%sconsole [%s%d] enabled\\n\",\n(newcon->flags & CON_BOOT) ? \"boot\" : \"\" ,\nnewcon->name, newcon->index);\n}\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of prefix string in syslog header, leading to a buffer overflow and system crash.",
        "trigger_condition": "Local users with /dev/kmsg write access trigger a call_console_drivers function call, exploiting the vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly remove a prefix string from a syslog header, allowing local users to cause a denial of service by triggering a buffer overflow and system crash."
      },
      "solution": "To mitigate the vulnerability, it is necessary to update the code to correctly handle the prefix string in the syslog header. In this case, changing the assignment from printk_cpu to logbuf_cpu helps prevent the buffer overflow and system crash. This modification ensures that the prefix string is handled properly, reducing the risk of exploitation by local users with write access to /dev/kmsg.",
      "GPT_analysis": "The modification you provided is necessary to address the vulnerability CVE-2013-1772 in the code snippet. The vulnerability is related to the log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 not properly removing a prefix string from a syslog header. This vulnerability allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.\n\nTo fix this vulnerability, the log_prefix function needs to be modified to prevent the buffer overflow and system crash. In the code snippet you provided, the modification changes the assignment of printk_cpu to logbuf_cpu. By changing printk_cpu to logbuf_cpu, the code is updated to address the vulnerability and prevent the potential denial of service attack.\n\nTherefore, the modification you provided is necessary to mitigate the vulnerability and ensure the proper functioning and security of the code.",
      "GPT_purpose": "Attempt to lock the console for printk output and release the lock if console cannot be used to avoid buffer flushing.",
      "GPT_function": "\n1. Attempt to acquire a lock for printk on a specific CPU.\n2. Check if the console lock can be acquired; if not, release the console semaphore.\n3. Reset printk_cpu to UINT_MAX if wake condition is met.\n4. Release the logbuf_lock and return the result of the lock acquisition attempt.",
      "CVE_id": "CVE-2013-1772",
      "code_before_change": "static int console_trylock_for_printk(unsigned int cpu)\n\t__releases(&logbuf_lock)\n{\n\tint retval = 0, wake = 0;\n\n\tif (console_trylock()) {\n\t\tretval = 1;\n\n\t\t/*\n\t\t * If we can't use the console, we need to release\n\t\t * the console semaphore by hand to avoid flushing\n\t\t * the buffer. We need to hold the console semaphore\n\t\t * in order to do this test safely.\n\t\t */\n\t\tif (!can_use_console(cpu)) {\n\t\t\tconsole_locked = 0;\n\t\t\twake = 1;\n\t\t\tretval = 0;\n\t\t}\n\t}\n\tprintk_cpu = UINT_MAX;\n\tif (wake)\n\t\tup(&console_sem);\n\traw_spin_unlock(&logbuf_lock);\n\treturn retval;\n}",
      "code_after_change": "static int console_trylock_for_printk(unsigned int cpu)\n\t__releases(&logbuf_lock)\n{\n\tint retval = 0, wake = 0;\n\n\tif (console_trylock()) {\n\t\tretval = 1;\n\n\t\t/*\n\t\t * If we can't use the console, we need to release\n\t\t * the console semaphore by hand to avoid flushing\n\t\t * the buffer. We need to hold the console semaphore\n\t\t * in order to do this test safely.\n\t\t */\n\t\tif (!can_use_console(cpu)) {\n\t\t\tconsole_locked = 0;\n\t\t\twake = 1;\n\t\t\tretval = 0;\n\t\t}\n\t}\n\tlogbuf_cpu = UINT_MAX;\n\tif (wake)\n\t\tup(&console_sem);\n\traw_spin_unlock(&logbuf_lock);\n\treturn retval;\n}",
      "modified_lines": {
        "added": [
          "\tlogbuf_cpu = UINT_MAX;"
        ],
        "deleted": [
          "\tprintk_cpu = UINT_MAX;"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of prefix string in syslog header, leading to a buffer overflow and system crash.",
      "trigger_condition": "Local users with /dev/kmsg write access trigger a call_console_drivers function call, exploiting the vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly remove a prefix string from a syslog header, allowing local users to cause a denial of service by triggering a buffer overflow and system crash.",
      "id": 25,
      "code_after_change_normalized": "static int FUN1(unsigned int VAR1)\nFUN2(&VAR2)\n{\nint VAR3 = 0, VAR4 = 0;\nif (FUN3()) {\nVAR3 = 1;\nif (!FUN4(VAR1)) {\nVAR5 = 0;\nVAR4 = 1;\nVAR3 = 0;\n}\n}\nVAR6 = VAR7;\nif (VAR4)\nFUN5(&VAR8);\nFUN6(&VAR2);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static int FUN1(unsigned int VAR1)\nFUN2(&VAR2)\n{\nint VAR3 = 0, VAR4 = 0;\nif (FUN3()) {\nVAR3 = 1;\nif (!FUN4(VAR1)) {\nVAR5 = 0;\nVAR4 = 1;\nVAR3 = 0;\n}\n}\nVAR6 = VAR7;\nif (VAR4)\nFUN5(&VAR8);\nFUN6(&VAR2);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static int console_trylock_for_printk(unsigned int cpu)\n__releases(&logbuf_lock)\n{\nint retval = 0, wake = 0;\nif (console_trylock()) {\nretval = 1;\nif (!can_use_console(cpu)) {\nconsole_locked = 0;\nwake = 1;\nretval = 0;\n}\n}\nlogbuf_cpu = UINT_MAX;\nif (wake)\nup(&console_sem);\nraw_spin_unlock(&logbuf_lock);\nreturn retval;\n}\n",
      "code_before_change_raw": "static int console_trylock_for_printk(unsigned int cpu)\n__releases(&logbuf_lock)\n{\nint retval = 0, wake = 0;\nif (console_trylock()) {\nretval = 1;\nif (!can_use_console(cpu)) {\nconsole_locked = 0;\nwake = 1;\nretval = 0;\n}\n}\nprintk_cpu = UINT_MAX;\nif (wake)\nup(&console_sem);\nraw_spin_unlock(&logbuf_lock);\nreturn retval;\n}\n"
    }
  ],
  "CVE-2013-1773": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of UTF-8 to UTF-16 conversion during a VFAT write operation on a filesystem with the utf8 mount option.",
        "trigger_condition": "A VFAT write operation occurs on a filesystem with the utf8 mount option, leading to a buffer overflow due to inadequate validation and sizing of the converted UTF-16 data.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly limit the number of characters converted during the UTF-8 to UTF-16 conversion, potentially allowing the conversion to exceed the allocated buffer size and leading to a buffer overflow vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to limit the number of characters converted during the UTF-8 to UTF-16 conversion by specifying the maximum key and value sizes divided by 2. Additionally, the endianness of the UTF-16 encoding should be specified to ensure proper conversion and prevent buffer overflows. These changes enhance the security and robustness of the conversion process, reducing the risk of buffer overflow vulnerabilities and potential exploitation.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2013-1773 related to a buffer overflow in the VFAT filesystem implementation. The vulnerability arises from improper handling of UTF-8 to UTF-16 conversion during a VFAT write operation on a filesystem with the utf8 mount option.\n\nTo mitigate this vulnerability, the modification adds the following changes to the code snippet:\n1. The addition of the `UTF16_HOST_ENDIAN` parameter in the `utf8s_to_utf16s` function calls for key and value conversion. This parameter specifies the endianness of the UTF-16 encoding, ensuring proper conversion and preventing potential buffer overflows.\n2. Limiting the number of characters converted during the UTF-8 to UTF-16 conversion by specifying the maximum key and value sizes (`HV_KVP_EXCHANGE_MAX_KEY_SIZE` and `HV_KVP_EXCHANGE_MAX_VALUE_SIZE`) divided by 2. This helps prevent buffer overflow by ensuring that the converted data fits within the allocated buffer size.\n\nBy making these modifications, the code snippet enhances the security and robustness of the UTF-8 to UTF-16 conversion process, reducing the risk of buffer overflow vulnerabilities and potential exploitation.",
      "GPT_purpose": "Responding to a host with key-value pair data and handling transaction completion in a Key-Value Pair (KVP) communication protocol.",
      "GPT_function": "\n1. Responding to a host with key-value data and error status.\n2. Handling the completion of a transaction and copying global state.\n3. Encoding key and value data into UTF-16 format for Windows host compatibility.\n4. Setting status flags and sending the response packet to the host via VMBus.",
      "CVE_id": "CVE-2013-1773",
      "code_before_change": "static void\nkvp_respond_to_host(char *key, char *value, int error)\n{\n\tstruct hv_kvp_msg  *kvp_msg;\n\tstruct hv_kvp_msg_enumerate  *kvp_data;\n\tchar\t*key_name;\n\tstruct icmsg_hdr *icmsghdrp;\n\tint\tkeylen, valuelen;\n\tu32\tbuf_len;\n\tstruct vmbus_channel *channel;\n\tu64\treq_id;\n\n\t/*\n\t * If a transaction is not active; log and return.\n\t */\n\n\tif (!kvp_transaction.active) {\n\t\t/*\n\t\t * This is a spurious call!\n\t\t */\n\t\tpr_warn(\"KVP: Transaction not active\\n\");\n\t\treturn;\n\t}\n\t/*\n\t * Copy the global state for completing the transaction. Note that\n\t * only one transaction can be active at a time.\n\t */\n\n\tbuf_len = kvp_transaction.recv_len;\n\tchannel = kvp_transaction.recv_channel;\n\treq_id = kvp_transaction.recv_req_id;\n\n\tkvp_transaction.active = false;\n\n\tif (channel->onchannel_callback == NULL)\n\t\t/*\n\t\t * We have raced with util driver being unloaded;\n\t\t * silently return.\n\t\t */\n\t\treturn;\n\n\ticmsghdrp = (struct icmsg_hdr *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr)];\n\tkvp_msg = (struct hv_kvp_msg *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr) +\n\t\t\tsizeof(struct icmsg_hdr)];\n\tkvp_data = &kvp_msg->kvp_data;\n\tkey_name = key;\n\n\t/*\n\t * If the error parameter is set, terminate the host's enumeration.\n\t */\n\tif (error) {\n\t\t/*\n\t\t * We don't support this index or the we have timedout;\n\t\t * terminate the host-side iteration by returning an error.\n\t\t */\n\t\ticmsghdrp->status = HV_E_FAIL;\n\t\tgoto response_done;\n\t}\n\n\t/*\n\t * The windows host expects the key/value pair to be encoded\n\t * in utf16.\n\t */\n\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name),\n\t\t\t\t(wchar_t *)kvp_data->data.key);\n\tkvp_data->data.key_size = 2*(keylen + 1); /* utf16 encoding */\n\tvaluelen = utf8s_to_utf16s(value, strlen(value),\n\t\t\t\t(wchar_t *)kvp_data->data.value);\n\tkvp_data->data.value_size = 2*(valuelen + 1); /* utf16 encoding */\n\n\tkvp_data->data.value_type = REG_SZ; /* all our values are strings */\n\ticmsghdrp->status = HV_S_OK;\n\nresponse_done:\n\ticmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;\n\n\tvmbus_sendpacket(channel, recv_buffer, buf_len, req_id,\n\t\t\t\tVM_PKT_DATA_INBAND, 0);\n\n}",
      "code_after_change": "static void\nkvp_respond_to_host(char *key, char *value, int error)\n{\n\tstruct hv_kvp_msg  *kvp_msg;\n\tstruct hv_kvp_msg_enumerate  *kvp_data;\n\tchar\t*key_name;\n\tstruct icmsg_hdr *icmsghdrp;\n\tint\tkeylen, valuelen;\n\tu32\tbuf_len;\n\tstruct vmbus_channel *channel;\n\tu64\treq_id;\n\n\t/*\n\t * If a transaction is not active; log and return.\n\t */\n\n\tif (!kvp_transaction.active) {\n\t\t/*\n\t\t * This is a spurious call!\n\t\t */\n\t\tpr_warn(\"KVP: Transaction not active\\n\");\n\t\treturn;\n\t}\n\t/*\n\t * Copy the global state for completing the transaction. Note that\n\t * only one transaction can be active at a time.\n\t */\n\n\tbuf_len = kvp_transaction.recv_len;\n\tchannel = kvp_transaction.recv_channel;\n\treq_id = kvp_transaction.recv_req_id;\n\n\tkvp_transaction.active = false;\n\n\tif (channel->onchannel_callback == NULL)\n\t\t/*\n\t\t * We have raced with util driver being unloaded;\n\t\t * silently return.\n\t\t */\n\t\treturn;\n\n\ticmsghdrp = (struct icmsg_hdr *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr)];\n\tkvp_msg = (struct hv_kvp_msg *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr) +\n\t\t\tsizeof(struct icmsg_hdr)];\n\tkvp_data = &kvp_msg->kvp_data;\n\tkey_name = key;\n\n\t/*\n\t * If the error parameter is set, terminate the host's enumeration.\n\t */\n\tif (error) {\n\t\t/*\n\t\t * We don't support this index or the we have timedout;\n\t\t * terminate the host-side iteration by returning an error.\n\t\t */\n\t\ticmsghdrp->status = HV_E_FAIL;\n\t\tgoto response_done;\n\t}\n\n\t/*\n\t * The windows host expects the key/value pair to be encoded\n\t * in utf16.\n\t */\n\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN,\n\t\t\t\t(wchar_t *) kvp_data->data.key,\n\t\t\t\tHV_KVP_EXCHANGE_MAX_KEY_SIZE / 2);\n\tkvp_data->data.key_size = 2*(keylen + 1); /* utf16 encoding */\n\tvaluelen = utf8s_to_utf16s(value, strlen(value), UTF16_HOST_ENDIAN,\n\t\t\t\t(wchar_t *) kvp_data->data.value,\n\t\t\t\tHV_KVP_EXCHANGE_MAX_VALUE_SIZE / 2);\n\tkvp_data->data.value_size = 2*(valuelen + 1); /* utf16 encoding */\n\n\tkvp_data->data.value_type = REG_SZ; /* all our values are strings */\n\ticmsghdrp->status = HV_S_OK;\n\nresponse_done:\n\ticmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;\n\n\tvmbus_sendpacket(channel, recv_buffer, buf_len, req_id,\n\t\t\t\tVM_PKT_DATA_INBAND, 0);\n\n}",
      "modified_lines": {
        "added": [
          "\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN,",
          "\t\t\t\t(wchar_t *) kvp_data->data.key,",
          "\t\t\t\tHV_KVP_EXCHANGE_MAX_KEY_SIZE / 2);",
          "\tvaluelen = utf8s_to_utf16s(value, strlen(value), UTF16_HOST_ENDIAN,",
          "\t\t\t\t(wchar_t *) kvp_data->data.value,",
          "\t\t\t\tHV_KVP_EXCHANGE_MAX_VALUE_SIZE / 2);"
        ],
        "deleted": [
          "\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name),",
          "\t\t\t\t(wchar_t *)kvp_data->data.key);",
          "\tvaluelen = utf8s_to_utf16s(value, strlen(value),",
          "\t\t\t\t(wchar_t *)kvp_data->data.value);"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of UTF-8 to UTF-16 conversion during a VFAT write operation on a filesystem with the utf8 mount option.",
      "trigger_condition": "A VFAT write operation occurs on a filesystem with the utf8 mount option, leading to a buffer overflow due to inadequate validation and sizing of the converted UTF-16 data.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly limit the number of characters converted during the UTF-8 to UTF-16 conversion, potentially allowing the conversion to exceed the allocated buffer size and leading to a buffer overflow vulnerability.",
      "id": 26,
      "code_after_change_normalized": "static void\nFUN1(char *VAR1, char *VAR2, int VAR3)\n{\nstruct hv_kvp_msg  *VAR4;\nstruct hv_kvp_msg_enumerate  *VAR5;\nchar\t*VAR6;\nstruct icmsg_hdr *VAR7;\nint\tVAR8, VAR9;\nu32\tVAR10;\nstruct vmbus_channel *VAR11;\nu64\tVAR12;\nif (!VAR13.VAR14) {\nFUN2(\"STR\");\nreturn;\n}\nVAR10 = VAR13.VAR15;\nVAR11 = VAR13.VAR16;\nVAR12 = VAR13.VAR17;\nVAR13.VAR14 = false;\nif (VAR11->VAR18 == NULL)\nreturn;\nVAR7 = (struct VAR19 *)\n&VAR20[sizeof(struct VAR21)];\nVAR4 = (struct VAR22 *)\n&VAR20[sizeof(struct VAR21) +\nsizeof(struct VAR19)];\nVAR5 = &VAR4->VAR5;\nVAR6 = VAR1;\nif (VAR3) {\nVAR7->VAR23 = VAR24;\ngoto VAR25;\n}\nVAR8 = FUN3(VAR6, FUN4(VAR6), VAR26,\n(wchar_t *) VAR5->VAR27.VAR1,\nVAR28 / 2);\nVAR5->VAR27.VAR29 = 2*(VAR8 + 1); \nVAR9 = FUN3(VAR2, FUN4(VAR2), VAR26,\n(wchar_t *) VAR5->VAR27.VAR2,\nVAR30 / 2);\nVAR5->VAR27.VAR31 = 2*(VAR9 + 1); \nVAR5->VAR27.VAR32 = VAR33; \nVAR7->VAR23 = VAR34;\nVAR25:\nVAR7->VAR35 = VAR36 | VAR37;\nFUN5(VAR11, VAR20, VAR10, VAR12,\nVAR38, 0);\n}\n",
      "code_before_change_normalized": "static void\nFUN1(char *VAR1, char *VAR2, int VAR3)\n{\nstruct hv_kvp_msg  *VAR4;\nstruct hv_kvp_msg_enumerate  *VAR5;\nchar\t*VAR6;\nstruct icmsg_hdr *VAR7;\nint\tVAR8, VAR9;\nu32\tVAR10;\nstruct vmbus_channel *VAR11;\nu64\tVAR12;\nif (!VAR13.VAR14) {\nFUN2(\"STR\");\nreturn;\n}\nVAR10 = VAR13.VAR15;\nVAR11 = VAR13.VAR16;\nVAR12 = VAR13.VAR17;\nVAR13.VAR14 = false;\nif (VAR11->VAR18 == NULL)\nreturn;\nVAR7 = (struct VAR19 *)\n&VAR20[sizeof(struct VAR21)];\nVAR4 = (struct VAR22 *)\n&VAR20[sizeof(struct VAR21) +\nsizeof(struct VAR19)];\nVAR5 = &VAR4->VAR5;\nVAR6 = VAR1;\nif (VAR3) {\nVAR7->VAR23 = VAR24;\ngoto VAR25;\n}\nVAR8 = FUN3(VAR6, FUN4(VAR6),\n(wchar_t *)VAR5->VAR26.VAR1);\nVAR5->VAR26.VAR27 = 2*(VAR8 + 1); \nVAR9 = FUN3(VAR2, FUN4(VAR2),\n(wchar_t *)VAR5->VAR26.VAR2);\nVAR5->VAR26.VAR28 = 2*(VAR9 + 1); \nVAR5->VAR26.VAR29 = VAR30; \nVAR7->VAR23 = VAR31;\nVAR25:\nVAR7->VAR32 = VAR33 | VAR34;\nFUN5(VAR11, VAR20, VAR10, VAR12,\nVAR35, 0);\n}\n",
      "code_after_change_raw": "static void\nkvp_respond_to_host(char *key, char *value, int error)\n{\nstruct hv_kvp_msg  *kvp_msg;\nstruct hv_kvp_msg_enumerate  *kvp_data;\nchar\t*key_name;\nstruct icmsg_hdr *icmsghdrp;\nint\tkeylen, valuelen;\nu32\tbuf_len;\nstruct vmbus_channel *channel;\nu64\treq_id;\nif (!kvp_transaction.active) {\npr_warn(\"KVP: Transaction not active\\n\");\nreturn;\n}\nbuf_len = kvp_transaction.recv_len;\nchannel = kvp_transaction.recv_channel;\nreq_id = kvp_transaction.recv_req_id;\nkvp_transaction.active = false;\nif (channel->onchannel_callback == NULL)\nreturn;\nicmsghdrp = (struct icmsg_hdr *)\n&recv_buffer[sizeof(struct vmbuspipe_hdr)];\nkvp_msg = (struct hv_kvp_msg *)\n&recv_buffer[sizeof(struct vmbuspipe_hdr) +\nsizeof(struct icmsg_hdr)];\nkvp_data = &kvp_msg->kvp_data;\nkey_name = key;\nif (error) {\nicmsghdrp->status = HV_E_FAIL;\ngoto response_done;\n}\nkeylen = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN,\n(wchar_t *) kvp_data->data.key,\nHV_KVP_EXCHANGE_MAX_KEY_SIZE / 2);\nkvp_data->data.key_size = 2*(keylen + 1); \nvaluelen = utf8s_to_utf16s(value, strlen(value), UTF16_HOST_ENDIAN,\n(wchar_t *) kvp_data->data.value,\nHV_KVP_EXCHANGE_MAX_VALUE_SIZE / 2);\nkvp_data->data.value_size = 2*(valuelen + 1); \nkvp_data->data.value_type = REG_SZ; \nicmsghdrp->status = HV_S_OK;\nresponse_done:\nicmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;\nvmbus_sendpacket(channel, recv_buffer, buf_len, req_id,\nVM_PKT_DATA_INBAND, 0);\n}\n",
      "code_before_change_raw": "static void\nkvp_respond_to_host(char *key, char *value, int error)\n{\nstruct hv_kvp_msg  *kvp_msg;\nstruct hv_kvp_msg_enumerate  *kvp_data;\nchar\t*key_name;\nstruct icmsg_hdr *icmsghdrp;\nint\tkeylen, valuelen;\nu32\tbuf_len;\nstruct vmbus_channel *channel;\nu64\treq_id;\nif (!kvp_transaction.active) {\npr_warn(\"KVP: Transaction not active\\n\");\nreturn;\n}\nbuf_len = kvp_transaction.recv_len;\nchannel = kvp_transaction.recv_channel;\nreq_id = kvp_transaction.recv_req_id;\nkvp_transaction.active = false;\nif (channel->onchannel_callback == NULL)\nreturn;\nicmsghdrp = (struct icmsg_hdr *)\n&recv_buffer[sizeof(struct vmbuspipe_hdr)];\nkvp_msg = (struct hv_kvp_msg *)\n&recv_buffer[sizeof(struct vmbuspipe_hdr) +\nsizeof(struct icmsg_hdr)];\nkvp_data = &kvp_msg->kvp_data;\nkey_name = key;\nif (error) {\nicmsghdrp->status = HV_E_FAIL;\ngoto response_done;\n}\nkeylen = utf8s_to_utf16s(key_name, strlen(key_name),\n(wchar_t *)kvp_data->data.key);\nkvp_data->data.key_size = 2*(keylen + 1); \nvaluelen = utf8s_to_utf16s(value, strlen(value),\n(wchar_t *)kvp_data->data.value);\nkvp_data->data.value_size = 2*(valuelen + 1); \nkvp_data->data.value_type = REG_SZ; \nicmsghdrp->status = HV_S_OK;\nresponse_done:\nicmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;\nvmbus_sendpacket(channel, recv_buffer, buf_len, req_id,\nVM_PKT_DATA_INBAND, 0);\n}\n"
    }
  ],
  "CVE-2013-1860": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper buffer overflow protection in the read operation of the wdm device driver.",
        "trigger_condition": "A physically proximate attacker sends crafted data to the wdm device driver, causing a heap-based buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not check for potential buffer overflow conditions before performing the read operation, allowing an attacker to send malicious data that overflows the buffer and leads to a denial of service or potential code execution."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check for a new flag 'WDM_OVERFLOW' before proceeding with the read operation. If the 'WDM_OVERFLOW' flag is set, indicating a potential buffer overflow, the code should clear the flag and return an error code to prevent the buffer overflow from occurring. This solution helps prevent the exploitation of the vulnerability by handling potential buffer overflow scenarios in a controlled manner.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-1860, which involves a heap-based buffer overflow in the wdm_in_callback function in the Linux kernel. The vulnerability allows physically proximate attackers to cause a denial of service (system crash) or potentially execute arbitrary code via a crafted cdc-wdm USB device.\n\nTo mitigate this vulnerability, the code modification includes adding a check for a new flag `WDM_OVERFLOW` before proceeding with the read operation. If the `WDM_OVERFLOW` flag is set, indicating a potential buffer overflow, the code clears the flag and returns an error code `-ENOBUFS` to prevent the buffer overflow from occurring.\n\nBy adding this check and handling the potential buffer overflow scenario, the modified code helps prevent the exploitation of the vulnerability and enhances the security of the system when interacting with cdc-wdm USB devices.",
      "GPT_purpose": "Read data from a USB device using the wdm_read function.",
      "GPT_function": "\n1. Read data from a USB device using the wdm_read function.\n2. Handle various error conditions during the read operation.\n3. Copy data to user space and update internal buffers accordingly.\n4. Manage locks and flags to ensure proper synchronization.",
      "CVE_id": "CVE-2013-1860",
      "code_before_change": "static ssize_t wdm_read\n(struct file *file, char __user *buffer, size_t count, loff_t *ppos)\n{\n\tint rv, cntr;\n\tint i = 0;\n\tstruct wdm_device *desc = file->private_data;\n\n\n\trv = mutex_lock_interruptible(&desc->rlock); /*concurrent reads */\n\tif (rv < 0)\n\t\treturn -ERESTARTSYS;\n\n\tcntr = ACCESS_ONCE(desc->length);\n\tif (cntr == 0) {\n\t\tdesc->read = 0;\nretry:\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\ti++;\n\t\tif (file->f_flags & O_NONBLOCK) {\n\t\t\tif (!test_bit(WDM_READ, &desc->flags)) {\n\t\t\t\trv = cntr ? cntr : -EAGAIN;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\trv = 0;\n\t\t} else {\n\t\t\trv = wait_event_interruptible(desc->wait,\n\t\t\t\ttest_bit(WDM_READ, &desc->flags));\n\t\t}\n\n\t\t/* may have happened while we slept */\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tif (test_bit(WDM_RESETTING, &desc->flags)) {\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\tusb_mark_last_busy(interface_to_usbdev(desc->intf));\n\t\tif (rv < 0) {\n\t\t\trv = -ERESTARTSYS;\n\t\t\tgoto err;\n\t\t}\n\n\t\tspin_lock_irq(&desc->iuspin);\n\n\t\tif (desc->rerr) { /* read completed, error happened */\n\t\t\tdesc->rerr = 0;\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\t/*\n\t\t * recheck whether we've lost the race\n\t\t * against the completion handler\n\t\t */\n\t\tif (!test_bit(WDM_READ, &desc->flags)) { /* lost race */\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (!desc->reslength) { /* zero length read */\n\t\t\tdev_dbg(&desc->intf->dev, \"%s: zero length - clearing WDM_READ\\n\", __func__);\n\t\t\tclear_bit(WDM_READ, &desc->flags);\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\t\tcntr = desc->length;\n\t\tspin_unlock_irq(&desc->iuspin);\n\t}\n\n\tif (cntr > count)\n\t\tcntr = count;\n\trv = copy_to_user(buffer, desc->ubuf, cntr);\n\tif (rv > 0) {\n\t\trv = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tspin_lock_irq(&desc->iuspin);\n\n\tfor (i = 0; i < desc->length - cntr; i++)\n\t\tdesc->ubuf[i] = desc->ubuf[i + cntr];\n\n\tdesc->length -= cntr;\n\t/* in case we had outstanding data */\n\tif (!desc->length)\n\t\tclear_bit(WDM_READ, &desc->flags);\n\n\tspin_unlock_irq(&desc->iuspin);\n\n\trv = cntr;\n\nerr:\n\tmutex_unlock(&desc->rlock);\n\treturn rv;\n}",
      "code_after_change": "static ssize_t wdm_read\n(struct file *file, char __user *buffer, size_t count, loff_t *ppos)\n{\n\tint rv, cntr;\n\tint i = 0;\n\tstruct wdm_device *desc = file->private_data;\n\n\n\trv = mutex_lock_interruptible(&desc->rlock); /*concurrent reads */\n\tif (rv < 0)\n\t\treturn -ERESTARTSYS;\n\n\tcntr = ACCESS_ONCE(desc->length);\n\tif (cntr == 0) {\n\t\tdesc->read = 0;\nretry:\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tif (test_bit(WDM_OVERFLOW, &desc->flags)) {\n\t\t\tclear_bit(WDM_OVERFLOW, &desc->flags);\n\t\t\trv = -ENOBUFS;\n\t\t\tgoto err;\n\t\t}\n\t\ti++;\n\t\tif (file->f_flags & O_NONBLOCK) {\n\t\t\tif (!test_bit(WDM_READ, &desc->flags)) {\n\t\t\t\trv = cntr ? cntr : -EAGAIN;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\trv = 0;\n\t\t} else {\n\t\t\trv = wait_event_interruptible(desc->wait,\n\t\t\t\ttest_bit(WDM_READ, &desc->flags));\n\t\t}\n\n\t\t/* may have happened while we slept */\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tif (test_bit(WDM_RESETTING, &desc->flags)) {\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\tusb_mark_last_busy(interface_to_usbdev(desc->intf));\n\t\tif (rv < 0) {\n\t\t\trv = -ERESTARTSYS;\n\t\t\tgoto err;\n\t\t}\n\n\t\tspin_lock_irq(&desc->iuspin);\n\n\t\tif (desc->rerr) { /* read completed, error happened */\n\t\t\tdesc->rerr = 0;\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\t/*\n\t\t * recheck whether we've lost the race\n\t\t * against the completion handler\n\t\t */\n\t\tif (!test_bit(WDM_READ, &desc->flags)) { /* lost race */\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\n\t\tif (!desc->reslength) { /* zero length read */\n\t\t\tdev_dbg(&desc->intf->dev, \"%s: zero length - clearing WDM_READ\\n\", __func__);\n\t\t\tclear_bit(WDM_READ, &desc->flags);\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\t\tcntr = desc->length;\n\t\tspin_unlock_irq(&desc->iuspin);\n\t}\n\n\tif (cntr > count)\n\t\tcntr = count;\n\trv = copy_to_user(buffer, desc->ubuf, cntr);\n\tif (rv > 0) {\n\t\trv = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tspin_lock_irq(&desc->iuspin);\n\n\tfor (i = 0; i < desc->length - cntr; i++)\n\t\tdesc->ubuf[i] = desc->ubuf[i + cntr];\n\n\tdesc->length -= cntr;\n\t/* in case we had outstanding data */\n\tif (!desc->length)\n\t\tclear_bit(WDM_READ, &desc->flags);\n\n\tspin_unlock_irq(&desc->iuspin);\n\n\trv = cntr;\n\nerr:\n\tmutex_unlock(&desc->rlock);\n\treturn rv;\n}",
      "modified_lines": {
        "added": [
          "\t\t\tgoto err;",
          "\t\t}",
          "\t\tif (test_bit(WDM_OVERFLOW, &desc->flags)) {",
          "\t\t\tclear_bit(WDM_OVERFLOW, &desc->flags);",
          "\t\t\trv = -ENOBUFS;",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper buffer overflow protection in the read operation of the wdm device driver.",
      "trigger_condition": "A physically proximate attacker sends crafted data to the wdm device driver, causing a heap-based buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not check for potential buffer overflow conditions before performing the read operation, allowing an attacker to send malicious data that overflows the buffer and leads to a denial of service or potential code execution.",
      "id": 27,
      "code_after_change_normalized": "static ssize_t VAR1\n(struct VAR2 *VAR2, char __user *VAR3, size_t VAR4, loff_t *VAR5)\n{\nint VAR6, VAR7;\nint VAR8 = 0;\nstruct wdm_device *VAR9 = VAR2->VAR10;\nVAR6 = FUN1(&VAR9->VAR11); \nif (VAR6 < 0)\nreturn -VAR12;\nVAR7 = FUN2(VAR9->VAR13);\nif (VAR7 == 0) {\nVAR9->VAR14 = 0;\nVAR15:\nif (FUN3(VAR16, &VAR9->VAR17)) {\nVAR6 = -VAR18;\ngoto VAR19;\n}\nif (FUN3(VAR20, &VAR9->VAR17)) {\nFUN4(VAR20, &VAR9->VAR17);\nVAR6 = -VAR21;\ngoto VAR19;\n}\nVAR8++;\nif (VAR2->VAR22 & VAR23) {\nif (!FUN3(VAR24, &VAR9->VAR17)) {\nVAR6 = VAR7 ? VAR7 : -VAR25;\ngoto VAR19;\n}\nVAR6 = 0;\n} else {\nVAR6 = FUN5(VAR9->VAR26,\nFUN3(VAR24, &VAR9->VAR17));\n}\nif (FUN3(VAR16, &VAR9->VAR17)) {\nVAR6 = -VAR18;\ngoto VAR19;\n}\nif (FUN3(VAR27, &VAR9->VAR17)) {\nVAR6 = -VAR28;\ngoto VAR19;\n}\nFUN6(FUN7(VAR9->VAR29));\nif (VAR6 < 0) {\nVAR6 = -VAR12;\ngoto VAR19;\n}\nFUN8(&VAR9->VAR30);\nif (VAR9->VAR31) { \nVAR9->VAR31 = 0;\nFUN9(&VAR9->VAR30);\nVAR6 = -VAR28;\ngoto VAR19;\n}\nif (!FUN3(VAR24, &VAR9->VAR17)) { \nFUN9(&VAR9->VAR30);\ngoto VAR15;\n}\nif (!VAR9->VAR32) { \nFUN10(&VAR9->VAR29->VAR33, \"STR\", VAR34);\nFUN4(VAR24, &VAR9->VAR17);\nFUN9(&VAR9->VAR30);\ngoto VAR15;\n}\nVAR7 = VAR9->VAR13;\nFUN9(&VAR9->VAR30);\n}\nif (VAR7 > VAR4)\nVAR7 = VAR4;\nVAR6 = FUN11(VAR3, VAR9->VAR35, VAR7);\nif (VAR6 > 0) {\nVAR6 = -VAR36;\ngoto VAR19;\n}\nFUN8(&VAR9->VAR30);\nfor (VAR8 = 0; VAR8 < VAR9->VAR13 - VAR7; VAR8++)\nVAR9->VAR35[VAR8] = VAR9->VAR35[VAR8 + VAR7];\nVAR9->VAR13 -= VAR7;\nif (!VAR9->VAR13)\nFUN4(VAR24, &VAR9->VAR17);\nFUN9(&VAR9->VAR30);\nVAR6 = VAR7;\nVAR19:\nFUN12(&VAR9->VAR11);\nreturn VAR6;\n}\n",
      "code_before_change_normalized": "static ssize_t VAR1\n(struct VAR2 *VAR2, char __user *VAR3, size_t VAR4, loff_t *VAR5)\n{\nint VAR6, VAR7;\nint VAR8 = 0;\nstruct wdm_device *VAR9 = VAR2->VAR10;\nVAR6 = FUN1(&VAR9->VAR11); \nif (VAR6 < 0)\nreturn -VAR12;\nVAR7 = FUN2(VAR9->VAR13);\nif (VAR7 == 0) {\nVAR9->VAR14 = 0;\nVAR15:\nif (FUN3(VAR16, &VAR9->VAR17)) {\nVAR6 = -VAR18;\ngoto VAR19;\n}\nVAR8++;\nif (VAR2->VAR20 & VAR21) {\nif (!FUN3(VAR22, &VAR9->VAR17)) {\nVAR6 = VAR7 ? VAR7 : -VAR23;\ngoto VAR19;\n}\nVAR6 = 0;\n} else {\nVAR6 = FUN4(VAR9->VAR24,\nFUN3(VAR22, &VAR9->VAR17));\n}\nif (FUN3(VAR16, &VAR9->VAR17)) {\nVAR6 = -VAR18;\ngoto VAR19;\n}\nif (FUN3(VAR25, &VAR9->VAR17)) {\nVAR6 = -VAR26;\ngoto VAR19;\n}\nFUN5(FUN6(VAR9->VAR27));\nif (VAR6 < 0) {\nVAR6 = -VAR12;\ngoto VAR19;\n}\nFUN7(&VAR9->VAR28);\nif (VAR9->VAR29) { \nVAR9->VAR29 = 0;\nFUN8(&VAR9->VAR28);\nVAR6 = -VAR26;\ngoto VAR19;\n}\nif (!FUN3(VAR22, &VAR9->VAR17)) { \nFUN8(&VAR9->VAR28);\ngoto VAR15;\n}\nif (!VAR9->VAR30) { \nFUN9(&VAR9->VAR27->VAR31, \"STR\", VAR32);\nFUN10(VAR22, &VAR9->VAR17);\nFUN8(&VAR9->VAR28);\ngoto VAR15;\n}\nVAR7 = VAR9->VAR13;\nFUN8(&VAR9->VAR28);\n}\nif (VAR7 > VAR4)\nVAR7 = VAR4;\nVAR6 = FUN11(VAR3, VAR9->VAR33, VAR7);\nif (VAR6 > 0) {\nVAR6 = -VAR34;\ngoto VAR19;\n}\nFUN7(&VAR9->VAR28);\nfor (VAR8 = 0; VAR8 < VAR9->VAR13 - VAR7; VAR8++)\nVAR9->VAR33[VAR8] = VAR9->VAR33[VAR8 + VAR7];\nVAR9->VAR13 -= VAR7;\nif (!VAR9->VAR13)\nFUN10(VAR22, &VAR9->VAR17);\nFUN8(&VAR9->VAR28);\nVAR6 = VAR7;\nVAR19:\nFUN12(&VAR9->VAR11);\nreturn VAR6;\n}\n",
      "code_after_change_raw": "static ssize_t wdm_read\n(struct file *file, char __user *buffer, size_t count, loff_t *ppos)\n{\nint rv, cntr;\nint i = 0;\nstruct wdm_device *desc = file->private_data;\nrv = mutex_lock_interruptible(&desc->rlock); \nif (rv < 0)\nreturn -ERESTARTSYS;\ncntr = ACCESS_ONCE(desc->length);\nif (cntr == 0) {\ndesc->read = 0;\nretry:\nif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\nrv = -ENODEV;\ngoto err;\n}\nif (test_bit(WDM_OVERFLOW, &desc->flags)) {\nclear_bit(WDM_OVERFLOW, &desc->flags);\nrv = -ENOBUFS;\ngoto err;\n}\ni++;\nif (file->f_flags & O_NONBLOCK) {\nif (!test_bit(WDM_READ, &desc->flags)) {\nrv = cntr ? cntr : -EAGAIN;\ngoto err;\n}\nrv = 0;\n} else {\nrv = wait_event_interruptible(desc->wait,\ntest_bit(WDM_READ, &desc->flags));\n}\nif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\nrv = -ENODEV;\ngoto err;\n}\nif (test_bit(WDM_RESETTING, &desc->flags)) {\nrv = -EIO;\ngoto err;\n}\nusb_mark_last_busy(interface_to_usbdev(desc->intf));\nif (rv < 0) {\nrv = -ERESTARTSYS;\ngoto err;\n}\nspin_lock_irq(&desc->iuspin);\nif (desc->rerr) { \ndesc->rerr = 0;\nspin_unlock_irq(&desc->iuspin);\nrv = -EIO;\ngoto err;\n}\nif (!test_bit(WDM_READ, &desc->flags)) { \nspin_unlock_irq(&desc->iuspin);\ngoto retry;\n}\nif (!desc->reslength) { \ndev_dbg(&desc->intf->dev, \"%s: zero length - clearing WDM_READ\\n\", __func__);\nclear_bit(WDM_READ, &desc->flags);\nspin_unlock_irq(&desc->iuspin);\ngoto retry;\n}\ncntr = desc->length;\nspin_unlock_irq(&desc->iuspin);\n}\nif (cntr > count)\ncntr = count;\nrv = copy_to_user(buffer, desc->ubuf, cntr);\nif (rv > 0) {\nrv = -EFAULT;\ngoto err;\n}\nspin_lock_irq(&desc->iuspin);\nfor (i = 0; i < desc->length - cntr; i++)\ndesc->ubuf[i] = desc->ubuf[i + cntr];\ndesc->length -= cntr;\nif (!desc->length)\nclear_bit(WDM_READ, &desc->flags);\nspin_unlock_irq(&desc->iuspin);\nrv = cntr;\nerr:\nmutex_unlock(&desc->rlock);\nreturn rv;\n}\n",
      "code_before_change_raw": "static ssize_t wdm_read\n(struct file *file, char __user *buffer, size_t count, loff_t *ppos)\n{\nint rv, cntr;\nint i = 0;\nstruct wdm_device *desc = file->private_data;\nrv = mutex_lock_interruptible(&desc->rlock); \nif (rv < 0)\nreturn -ERESTARTSYS;\ncntr = ACCESS_ONCE(desc->length);\nif (cntr == 0) {\ndesc->read = 0;\nretry:\nif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\nrv = -ENODEV;\ngoto err;\n}\ni++;\nif (file->f_flags & O_NONBLOCK) {\nif (!test_bit(WDM_READ, &desc->flags)) {\nrv = cntr ? cntr : -EAGAIN;\ngoto err;\n}\nrv = 0;\n} else {\nrv = wait_event_interruptible(desc->wait,\ntest_bit(WDM_READ, &desc->flags));\n}\nif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\nrv = -ENODEV;\ngoto err;\n}\nif (test_bit(WDM_RESETTING, &desc->flags)) {\nrv = -EIO;\ngoto err;\n}\nusb_mark_last_busy(interface_to_usbdev(desc->intf));\nif (rv < 0) {\nrv = -ERESTARTSYS;\ngoto err;\n}\nspin_lock_irq(&desc->iuspin);\nif (desc->rerr) { \ndesc->rerr = 0;\nspin_unlock_irq(&desc->iuspin);\nrv = -EIO;\ngoto err;\n}\nif (!test_bit(WDM_READ, &desc->flags)) { \nspin_unlock_irq(&desc->iuspin);\ngoto retry;\n}\nif (!desc->reslength) { \ndev_dbg(&desc->intf->dev, \"%s: zero length - clearing WDM_READ\\n\", __func__);\nclear_bit(WDM_READ, &desc->flags);\nspin_unlock_irq(&desc->iuspin);\ngoto retry;\n}\ncntr = desc->length;\nspin_unlock_irq(&desc->iuspin);\n}\nif (cntr > count)\ncntr = count;\nrv = copy_to_user(buffer, desc->ubuf, cntr);\nif (rv > 0) {\nrv = -EFAULT;\ngoto err;\n}\nspin_lock_irq(&desc->iuspin);\nfor (i = 0; i < desc->length - cntr; i++)\ndesc->ubuf[i] = desc->ubuf[i + cntr];\ndesc->length -= cntr;\nif (!desc->length)\nclear_bit(WDM_READ, &desc->flags);\nspin_unlock_irq(&desc->iuspin);\nrv = cntr;\nerr:\nmutex_unlock(&desc->rlock);\nreturn rv;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation and handling of data length received from a USB device in the wdm_in_callback function.",
        "trigger_condition": "Receiving data with a length that, when appended to the buffer, would exceed the maximum buffer size, leading to a heap-based buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code directly appends the received data to the buffer without checking if the addition would cause a buffer overflow, potentially allowing an attacker to craft data that triggers the overflow.",
        "solution": "To mitigate the vulnerability, it is necessary to introduce a length check before appending the received data to the buffer. If the addition of the data would exceed the maximum buffer size, set a flag to indicate a potential overflow instead of appending the data. This ensures that the buffer size is not exceeded and prevents the heap-based buffer overflow."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2013-1860, which is a heap-based buffer overflow in the wdm_in_callback function. The vulnerability allows physically proximate attackers to cause a denial of service (system crash) or possibly execute arbitrary code via a crafted cdc-wdm USB device.\n\nThe key changes made in the modified code snippet are related to handling the length of the data received in the USB device's urb (USB Request Block). By introducing the 'length' variable to store the actual length of the data received, the code now checks if appending this data to the existing buffer would cause an overflow.\n\nThe following modifications were made to address the vulnerability:\n1. Added 'int length = urb->actual_length;' to store the actual length of the received data.\n2. Introduced a check to ensure that appending the received data to the buffer would not exceed the maximum buffer size 'wMaxCommand'. If the buffer would overflow, a flag 'WDM_OVERFLOW' is set to indicate the potential issue.\n3. Only if the buffer is not already in an overflow state, the received data is appended to the buffer using 'memmove', and the buffer length is updated accordingly.\n\nBy implementing these changes, the code now properly handles the received data length and prevents a buffer overflow scenario, thereby mitigating the vulnerability and enhancing the security of the system.",
      "GPT_purpose": "Handle the completion of a USB Request Block (URB) for a WDM (Windows Driver Model) device and process the received data.",
      "GPT_function": "\n1. Handle the completion callback for a USB Request Block (URB).\n2. Check the status of the URB and handle different error cases.\n3. Copy data from the URB buffer to the device buffer.\n4. Update flags and wake up waiting processes.\n5. Unlock the spin lock after processing the URB.",
      "CVE_id": "CVE-2013-1860",
      "code_before_change": "static void wdm_in_callback(struct urb *urb)\n{\n\tstruct wdm_device *desc = urb->context;\n\tint status = urb->status;\n\n\tspin_lock(&desc->iuspin);\n\tclear_bit(WDM_RESPONDING, &desc->flags);\n\n\tif (status) {\n\t\tswitch (status) {\n\t\tcase -ENOENT:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ENOENT\");\n\t\t\tgoto skip_error;\n\t\tcase -ECONNRESET:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ECONNRESET\");\n\t\t\tgoto skip_error;\n\t\tcase -ESHUTDOWN:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ESHUTDOWN\");\n\t\t\tgoto skip_error;\n\t\tcase -EPIPE:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -EPIPE\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"Unexpected error %d\\n\", status);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tdesc->rerr = status;\n\tdesc->reslength = urb->actual_length;\n\tmemmove(desc->ubuf + desc->length, desc->inbuf, desc->reslength);\n\tdesc->length += desc->reslength;\nskip_error:\n\twake_up(&desc->wait);\n\n\tset_bit(WDM_READ, &desc->flags);\n\tspin_unlock(&desc->iuspin);\n}",
      "code_after_change": "static void wdm_in_callback(struct urb *urb)\n{\n\tstruct wdm_device *desc = urb->context;\n\tint status = urb->status;\n\tint length = urb->actual_length;\n\n\tspin_lock(&desc->iuspin);\n\tclear_bit(WDM_RESPONDING, &desc->flags);\n\n\tif (status) {\n\t\tswitch (status) {\n\t\tcase -ENOENT:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ENOENT\");\n\t\t\tgoto skip_error;\n\t\tcase -ECONNRESET:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ECONNRESET\");\n\t\t\tgoto skip_error;\n\t\tcase -ESHUTDOWN:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ESHUTDOWN\");\n\t\t\tgoto skip_error;\n\t\tcase -EPIPE:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -EPIPE\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"Unexpected error %d\\n\", status);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tdesc->rerr = status;\n\tif (length + desc->length > desc->wMaxCommand) {\n\t\t/* The buffer would overflow */\n\t\tset_bit(WDM_OVERFLOW, &desc->flags);\n\t} else {\n\t\t/* we may already be in overflow */\n\t\tif (!test_bit(WDM_OVERFLOW, &desc->flags)) {\n\t\t\tmemmove(desc->ubuf + desc->length, desc->inbuf, length);\n\t\t\tdesc->length += length;\n\t\t\tdesc->reslength = length;\n\t\t}\n\t}\nskip_error:\n\twake_up(&desc->wait);\n\n\tset_bit(WDM_READ, &desc->flags);\n\tspin_unlock(&desc->iuspin);\n}",
      "modified_lines": {
        "added": [
          "\tint length = urb->actual_length;",
          "\tif (length + desc->length > desc->wMaxCommand) {",
          "\t\t/* The buffer would overflow */",
          "\t\tset_bit(WDM_OVERFLOW, &desc->flags);",
          "\t} else {",
          "\t\t/* we may already be in overflow */",
          "\t\tif (!test_bit(WDM_OVERFLOW, &desc->flags)) {",
          "\t\t\tmemmove(desc->ubuf + desc->length, desc->inbuf, length);",
          "\t\t\tdesc->length += length;",
          "\t\t\tdesc->reslength = length;",
          "\t\t}",
          "\t}"
        ],
        "deleted": [
          "\tdesc->reslength = urb->actual_length;",
          "\tmemmove(desc->ubuf + desc->length, desc->inbuf, desc->reslength);",
          "\tdesc->length += desc->reslength;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation and handling of data length received from a USB device in the wdm_in_callback function.",
      "trigger_condition": "Receiving data with a length that, when appended to the buffer, would exceed the maximum buffer size, leading to a heap-based buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code directly appends the received data to the buffer without checking if the addition would cause a buffer overflow, potentially allowing an attacker to craft data that triggers the overflow.",
      "solution": "To mitigate the vulnerability, it is necessary to introduce a length check before appending the received data to the buffer. If the addition of the data would exceed the maximum buffer size, set a flag to indicate a potential overflow instead of appending the data. This ensures that the buffer size is not exceeded and prevents the heap-based buffer overflow.",
      "id": 28,
      "code_after_change_normalized": "static void FUN1(struct VAR1 *VAR1)\n{\nstruct wdm_device *VAR2 = VAR1->VAR3;\nint VAR4 = VAR1->VAR4;\nint VAR5 = VAR1->VAR6;\nFUN2(&VAR2->VAR7);\nFUN3(VAR8, &VAR2->VAR9);\nif (VAR4) {\nswitch (VAR4) {\ncase -VAR10:\nFUN4(&VAR2->VAR11->VAR12,\n\"STR\");\ngoto VAR13;\ncase -VAR14:\nFUN4(&VAR2->VAR11->VAR12,\n\"STR\");\ngoto VAR13;\ncase -VAR15:\nFUN4(&VAR2->VAR11->VAR12,\n\"STR\");\ngoto VAR13;\ncase -VAR16:\nFUN5(&VAR2->VAR11->VAR12,\n\"STR\");\nbreak;\ndefault:\nFUN5(&VAR2->VAR11->VAR12,\n\"STR\", VAR4);\nbreak;\n}\n}\nVAR2->VAR17 = VAR4;\nif (VAR5 + VAR2->VAR5 > VAR2->VAR18) {\nFUN6(VAR19, &VAR2->VAR9);\n} else {\nif (!FUN7(VAR19, &VAR2->VAR9)) {\nFUN8(VAR2->VAR20 + VAR2->VAR5, VAR2->VAR21, VAR5);\nVAR2->VAR5 += VAR5;\nVAR2->VAR22 = VAR5;\n}\n}\nVAR13:\nFUN9(&VAR2->VAR23);\nFUN6(VAR24, &VAR2->VAR9);\nFUN10(&VAR2->VAR7);\n}\n",
      "code_before_change_normalized": "static void FUN1(struct VAR1 *VAR1)\n{\nstruct wdm_device *VAR2 = VAR1->VAR3;\nint VAR4 = VAR1->VAR4;\nFUN2(&VAR2->VAR5);\nFUN3(VAR6, &VAR2->VAR7);\nif (VAR4) {\nswitch (VAR4) {\ncase -VAR8:\nFUN4(&VAR2->VAR9->VAR10,\n\"STR\");\ngoto VAR11;\ncase -VAR12:\nFUN4(&VAR2->VAR9->VAR10,\n\"STR\");\ngoto VAR11;\ncase -VAR13:\nFUN4(&VAR2->VAR9->VAR10,\n\"STR\");\ngoto VAR11;\ncase -VAR14:\nFUN5(&VAR2->VAR9->VAR10,\n\"STR\");\nbreak;\ndefault:\nFUN5(&VAR2->VAR9->VAR10,\n\"STR\", VAR4);\nbreak;\n}\n}\nVAR2->VAR15 = VAR4;\nVAR2->VAR16 = VAR1->VAR17;\nFUN6(VAR2->VAR18 + VAR2->VAR19, VAR2->VAR20, VAR2->VAR16);\nVAR2->VAR19 += VAR2->VAR16;\nVAR11:\nFUN7(&VAR2->VAR21);\nFUN8(VAR22, &VAR2->VAR7);\nFUN9(&VAR2->VAR5);\n}\n",
      "code_after_change_raw": "static void wdm_in_callback(struct urb *urb)\n{\nstruct wdm_device *desc = urb->context;\nint status = urb->status;\nint length = urb->actual_length;\nspin_lock(&desc->iuspin);\nclear_bit(WDM_RESPONDING, &desc->flags);\nif (status) {\nswitch (status) {\ncase -ENOENT:\ndev_dbg(&desc->intf->dev,\n\"nonzero urb status received: -ENOENT\");\ngoto skip_error;\ncase -ECONNRESET:\ndev_dbg(&desc->intf->dev,\n\"nonzero urb status received: -ECONNRESET\");\ngoto skip_error;\ncase -ESHUTDOWN:\ndev_dbg(&desc->intf->dev,\n\"nonzero urb status received: -ESHUTDOWN\");\ngoto skip_error;\ncase -EPIPE:\ndev_err(&desc->intf->dev,\n\"nonzero urb status received: -EPIPE\\n\");\nbreak;\ndefault:\ndev_err(&desc->intf->dev,\n\"Unexpected error %d\\n\", status);\nbreak;\n}\n}\ndesc->rerr = status;\nif (length + desc->length > desc->wMaxCommand) {\nset_bit(WDM_OVERFLOW, &desc->flags);\n} else {\nif (!test_bit(WDM_OVERFLOW, &desc->flags)) {\nmemmove(desc->ubuf + desc->length, desc->inbuf, length);\ndesc->length += length;\ndesc->reslength = length;\n}\n}\nskip_error:\nwake_up(&desc->wait);\nset_bit(WDM_READ, &desc->flags);\nspin_unlock(&desc->iuspin);\n}\n",
      "code_before_change_raw": "static void wdm_in_callback(struct urb *urb)\n{\nstruct wdm_device *desc = urb->context;\nint status = urb->status;\nspin_lock(&desc->iuspin);\nclear_bit(WDM_RESPONDING, &desc->flags);\nif (status) {\nswitch (status) {\ncase -ENOENT:\ndev_dbg(&desc->intf->dev,\n\"nonzero urb status received: -ENOENT\");\ngoto skip_error;\ncase -ECONNRESET:\ndev_dbg(&desc->intf->dev,\n\"nonzero urb status received: -ECONNRESET\");\ngoto skip_error;\ncase -ESHUTDOWN:\ndev_dbg(&desc->intf->dev,\n\"nonzero urb status received: -ESHUTDOWN\");\ngoto skip_error;\ncase -EPIPE:\ndev_err(&desc->intf->dev,\n\"nonzero urb status received: -EPIPE\\n\");\nbreak;\ndefault:\ndev_err(&desc->intf->dev,\n\"Unexpected error %d\\n\", status);\nbreak;\n}\n}\ndesc->rerr = status;\ndesc->reslength = urb->actual_length;\nmemmove(desc->ubuf + desc->length, desc->inbuf, desc->reslength);\ndesc->length += desc->reslength;\nskip_error:\nwake_up(&desc->wait);\nset_bit(WDM_READ, &desc->flags);\nspin_unlock(&desc->iuspin);\n}\n"
    }
  ],
  "CVE-2013-1929": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper length validation for data copied into a buffer, allowing for potential buffer overflow.",
        "trigger_condition": "Crafted firmware specifies a long string in the Vital Product Data (VPD) data structure, causing the buffer overflow during data processing.",
        "specific_code_behavior_causing_vulnerability": "The code copies data into the 'tp->fw_ver' buffer without properly checking the length, potentially exceeding the buffer size and leading to a heap-based buffer overflow."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the length of the data being copied into the 'tp->fw_ver' buffer is properly checked and limited to the size of the buffer. This can be achieved by using functions like 'snprintf' with a specified maximum length to prevent buffer overflow. By limiting the copied data length to fit within the buffer size, the code prevents the risk of overwriting adjacent memory locations and enhances system security.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the identified vulnerability CVE-2013-1929, which is a heap-based buffer overflow in the `tg3_read_vpd` function. The vulnerability allows physically proximate attackers to cause a denial of service (system crash) or potentially execute arbitrary code by providing crafted firmware that specifies a long string in the Vital Product Data (VPD) data structure.\n\nThe modification specifically addresses the buffer overflow issue by ensuring that the length of the data being copied into the `tp->fw_ver` buffer is properly checked and limited to the size of the buffer. This is achieved by using the `snprintf` function with a specified maximum length to prevent buffer overflow.\n\nBy limiting the length of the copied data to fit within the buffer size, the modified code prevents the possibility of overwriting adjacent memory locations and mitigates the risk of a buffer overflow exploit, thus enhancing the security and stability of the system.",
      "GPT_purpose": "Read and process Vital Product Data (VPD) information for a Broadcom network adapter.",
      "GPT_function": "\n1. Read Vital Product Data (VPD) information from a Broadcom network device.\n2. Process the VPD data to extract specific information such as firmware version and board part number.\n3. Handle cases where certain VPD information is not found or matches predefined values.\n4. Assign board part numbers based on the Broadcom device's ASIC revision and device type.\n5. Handle cases where no matching board part number is found by assigning a default value.",
      "CVE_id": "CVE-2013-1929",
      "code_before_change": "static void tg3_read_vpd(struct tg3 *tp)\n{\n\tu8 *vpd_data;\n\tunsigned int block_end, rosize, len;\n\tu32 vpdlen;\n\tint j, i = 0;\n\n\tvpd_data = (u8 *)tg3_vpd_readblock(tp, &vpdlen);\n\tif (!vpd_data)\n\t\tgoto out_no_vpd;\n\n\ti = pci_vpd_find_tag(vpd_data, 0, vpdlen, PCI_VPD_LRDT_RO_DATA);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\trosize = pci_vpd_lrdt_size(&vpd_data[i]);\n\tblock_end = i + PCI_VPD_LRDT_TAG_SIZE + rosize;\n\ti += PCI_VPD_LRDT_TAG_SIZE;\n\n\tif (block_end > vpdlen)\n\t\tgoto out_not_found;\n\n\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_MFR_ID);\n\tif (j > 0) {\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end || len != 4 ||\n\t\t    memcmp(&vpd_data[j], \"1028\", 4))\n\t\t\tgoto partno;\n\n\t\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t\t      PCI_VPD_RO_KEYWORD_VENDOR0);\n\t\tif (j < 0)\n\t\t\tgoto partno;\n\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end)\n\t\t\tgoto partno;\n\n\t\tmemcpy(tp->fw_ver, &vpd_data[j], len);\n\t\tstrncat(tp->fw_ver, \" bc \", vpdlen - len - 1);\n\t}\n\npartno:\n\ti = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_PARTNO);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\tlen = pci_vpd_info_field_size(&vpd_data[i]);\n\n\ti += PCI_VPD_INFO_FLD_HDR_SIZE;\n\tif (len > TG3_BPN_SIZE ||\n\t    (len + i) > vpdlen)\n\t\tgoto out_not_found;\n\n\tmemcpy(tp->board_part_number, &vpd_data[i], len);\n\nout_not_found:\n\tkfree(vpd_data);\n\tif (tp->board_part_number[0])\n\t\treturn;\n\nout_no_vpd:\n\tif (tg3_asic_rev(tp) == ASIC_REV_5717) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717 ||\n\t\t    tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717_C)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5717\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5718)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5718\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57780) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57780)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57780\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57760)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57760\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57790)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57790\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57788)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57788\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57765) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57761)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57761\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57765)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57765\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57781)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57781\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57785)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57785\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57791)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57791\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57795)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57795\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57766) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57762)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57762\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57766)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57766\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57782)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57782\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57786)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57786\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_5906) {\n\t\tstrcpy(tp->board_part_number, \"BCM95906\");\n\t} else {\nnomatch:\n\t\tstrcpy(tp->board_part_number, \"none\");\n\t}\n}",
      "code_after_change": "static void tg3_read_vpd(struct tg3 *tp)\n{\n\tu8 *vpd_data;\n\tunsigned int block_end, rosize, len;\n\tu32 vpdlen;\n\tint j, i = 0;\n\n\tvpd_data = (u8 *)tg3_vpd_readblock(tp, &vpdlen);\n\tif (!vpd_data)\n\t\tgoto out_no_vpd;\n\n\ti = pci_vpd_find_tag(vpd_data, 0, vpdlen, PCI_VPD_LRDT_RO_DATA);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\trosize = pci_vpd_lrdt_size(&vpd_data[i]);\n\tblock_end = i + PCI_VPD_LRDT_TAG_SIZE + rosize;\n\ti += PCI_VPD_LRDT_TAG_SIZE;\n\n\tif (block_end > vpdlen)\n\t\tgoto out_not_found;\n\n\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_MFR_ID);\n\tif (j > 0) {\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end || len != 4 ||\n\t\t    memcmp(&vpd_data[j], \"1028\", 4))\n\t\t\tgoto partno;\n\n\t\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t\t      PCI_VPD_RO_KEYWORD_VENDOR0);\n\t\tif (j < 0)\n\t\t\tgoto partno;\n\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end)\n\t\t\tgoto partno;\n\n\t\tif (len >= sizeof(tp->fw_ver))\n\t\t\tlen = sizeof(tp->fw_ver) - 1;\n\t\tmemset(tp->fw_ver, 0, sizeof(tp->fw_ver));\n\t\tsnprintf(tp->fw_ver, sizeof(tp->fw_ver), \"%.*s bc \", len,\n\t\t\t &vpd_data[j]);\n\t}\n\npartno:\n\ti = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_PARTNO);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\tlen = pci_vpd_info_field_size(&vpd_data[i]);\n\n\ti += PCI_VPD_INFO_FLD_HDR_SIZE;\n\tif (len > TG3_BPN_SIZE ||\n\t    (len + i) > vpdlen)\n\t\tgoto out_not_found;\n\n\tmemcpy(tp->board_part_number, &vpd_data[i], len);\n\nout_not_found:\n\tkfree(vpd_data);\n\tif (tp->board_part_number[0])\n\t\treturn;\n\nout_no_vpd:\n\tif (tg3_asic_rev(tp) == ASIC_REV_5717) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717 ||\n\t\t    tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717_C)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5717\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5718)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5718\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57780) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57780)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57780\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57760)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57760\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57790)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57790\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57788)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57788\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57765) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57761)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57761\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57765)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57765\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57781)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57781\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57785)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57785\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57791)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57791\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57795)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57795\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57766) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57762)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57762\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57766)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57766\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57782)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57782\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57786)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57786\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_5906) {\n\t\tstrcpy(tp->board_part_number, \"BCM95906\");\n\t} else {\nnomatch:\n\t\tstrcpy(tp->board_part_number, \"none\");\n\t}\n}",
      "modified_lines": {
        "added": [
          "\t\tif (len >= sizeof(tp->fw_ver))",
          "\t\t\tlen = sizeof(tp->fw_ver) - 1;",
          "\t\tmemset(tp->fw_ver, 0, sizeof(tp->fw_ver));",
          "\t\tsnprintf(tp->fw_ver, sizeof(tp->fw_ver), \"%.*s bc \", len,",
          "\t\t\t &vpd_data[j]);"
        ],
        "deleted": [
          "\t\tmemcpy(tp->fw_ver, &vpd_data[j], len);",
          "\t\tstrncat(tp->fw_ver, \" bc \", vpdlen - len - 1);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper length validation for data copied into a buffer, allowing for potential buffer overflow.",
      "trigger_condition": "Crafted firmware specifies a long string in the Vital Product Data (VPD) data structure, causing the buffer overflow during data processing.",
      "specific_code_behavior_causing_vulnerability": "The code copies data into the 'tp->fw_ver' buffer without properly checking the length, potentially exceeding the buffer size and leading to a heap-based buffer overflow.",
      "id": 29,
      "code_after_change_normalized": "static void FUN1(struct tg3 *VAR1)\n{\nu8 *VAR2;\nunsigned int VAR3, VAR4, VAR5;\nu32 VAR6;\nint VAR7, VAR8 = 0;\nVAR2 = (VAR9 *)FUN2(VAR1, &VAR6);\nif (!VAR2)\ngoto VAR10;\nVAR8 = FUN3(VAR2, 0, VAR6, VAR11);\nif (VAR8 < 0)\ngoto VAR12;\nVAR4 = FUN4(&VAR2[VAR8]);\nVAR3 = VAR8 + VAR13 + VAR4;\nVAR8 += VAR13;\nif (VAR3 > VAR6)\ngoto VAR12;\nVAR7 = FUN5(VAR2, VAR8, VAR4,\nVAR14);\nif (VAR7 > 0) {\nVAR5 = FUN6(&VAR2[VAR7]);\nVAR7 += VAR15;\nif (VAR7 + VAR5 > VAR3 || VAR5 != 4 ||\nFUN7(&VAR2[VAR7], \"STR\", 4))\ngoto VAR16;\nVAR7 = FUN5(VAR2, VAR8, VAR4,\nVAR17);\nif (VAR7 < 0)\ngoto VAR16;\nVAR5 = FUN6(&VAR2[VAR7]);\nVAR7 += VAR15;\nif (VAR7 + VAR5 > VAR3)\ngoto VAR16;\nif (VAR5 >= sizeof(VAR1->VAR18))\nVAR5 = sizeof(VAR1->VAR18) - 1;\nFUN8(VAR1->VAR18, 0, sizeof(VAR1->VAR18));\nFUN9(VAR1->VAR18, sizeof(VAR1->VAR18), \"STR\", VAR5,\n&VAR2[VAR7]);\n}\nVAR16:\nVAR8 = FUN5(VAR2, VAR8, VAR4,\nVAR19);\nif (VAR8 < 0)\ngoto VAR12;\nVAR5 = FUN6(&VAR2[VAR8]);\nVAR8 += VAR15;\nif (VAR5 > VAR20 ||\n(VAR5 + VAR8) > VAR6)\ngoto VAR12;\nFUN10(VAR1->VAR21, &VAR2[VAR8], VAR5);\nVAR12:\nFUN11(VAR2);\nif (VAR1->VAR21[0])\nreturn;\nVAR10:\nif (FUN12(VAR1) == VAR22) {\nif (VAR1->VAR23->VAR24 == VAR25 ||\nVAR1->VAR23->VAR24 == VAR26)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR27)\nFUN13(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN12(VAR1) == VAR29) {\nif (VAR1->VAR23->VAR24 == VAR30)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR31)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR32)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR33)\nFUN13(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN12(VAR1) == VAR34) {\nif (VAR1->VAR23->VAR24 == VAR35)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR36)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR37)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR38)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR39)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR40)\nFUN13(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN12(VAR1) == VAR41) {\nif (VAR1->VAR23->VAR24 == VAR42)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR43)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR44)\nFUN13(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR45)\nFUN13(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN12(VAR1) == VAR46) {\nFUN13(VAR1->VAR21, \"STR\");\n} else {\nVAR28:\nFUN13(VAR1->VAR21, \"STR\");\n}\n}\n",
      "code_before_change_normalized": "static void FUN1(struct tg3 *VAR1)\n{\nu8 *VAR2;\nunsigned int VAR3, VAR4, VAR5;\nu32 VAR6;\nint VAR7, VAR8 = 0;\nVAR2 = (VAR9 *)FUN2(VAR1, &VAR6);\nif (!VAR2)\ngoto VAR10;\nVAR8 = FUN3(VAR2, 0, VAR6, VAR11);\nif (VAR8 < 0)\ngoto VAR12;\nVAR4 = FUN4(&VAR2[VAR8]);\nVAR3 = VAR8 + VAR13 + VAR4;\nVAR8 += VAR13;\nif (VAR3 > VAR6)\ngoto VAR12;\nVAR7 = FUN5(VAR2, VAR8, VAR4,\nVAR14);\nif (VAR7 > 0) {\nVAR5 = FUN6(&VAR2[VAR7]);\nVAR7 += VAR15;\nif (VAR7 + VAR5 > VAR3 || VAR5 != 4 ||\nFUN7(&VAR2[VAR7], \"STR\", 4))\ngoto VAR16;\nVAR7 = FUN5(VAR2, VAR8, VAR4,\nVAR17);\nif (VAR7 < 0)\ngoto VAR16;\nVAR5 = FUN6(&VAR2[VAR7]);\nVAR7 += VAR15;\nif (VAR7 + VAR5 > VAR3)\ngoto VAR16;\nFUN8(VAR1->VAR18, &VAR2[VAR7], VAR5);\nFUN9(VAR1->VAR18, \"STR\", VAR6 - VAR5 - 1);\n}\nVAR16:\nVAR8 = FUN5(VAR2, VAR8, VAR4,\nVAR19);\nif (VAR8 < 0)\ngoto VAR12;\nVAR5 = FUN6(&VAR2[VAR8]);\nVAR8 += VAR15;\nif (VAR5 > VAR20 ||\n(VAR5 + VAR8) > VAR6)\ngoto VAR12;\nFUN8(VAR1->VAR21, &VAR2[VAR8], VAR5);\nVAR12:\nFUN10(VAR2);\nif (VAR1->VAR21[0])\nreturn;\nVAR10:\nif (FUN11(VAR1) == VAR22) {\nif (VAR1->VAR23->VAR24 == VAR25 ||\nVAR1->VAR23->VAR24 == VAR26)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR27)\nFUN12(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN11(VAR1) == VAR29) {\nif (VAR1->VAR23->VAR24 == VAR30)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR31)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR32)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR33)\nFUN12(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN11(VAR1) == VAR34) {\nif (VAR1->VAR23->VAR24 == VAR35)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR36)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR37)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR38)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR39)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR40)\nFUN12(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN11(VAR1) == VAR41) {\nif (VAR1->VAR23->VAR24 == VAR42)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR43)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR44)\nFUN12(VAR1->VAR21, \"STR\");\nelse if (VAR1->VAR23->VAR24 == VAR45)\nFUN12(VAR1->VAR21, \"STR\");\nelse\ngoto VAR28;\n} else if (FUN11(VAR1) == VAR46) {\nFUN12(VAR1->VAR21, \"STR\");\n} else {\nVAR28:\nFUN12(VAR1->VAR21, \"STR\");\n}\n}\n",
      "code_after_change_raw": "static void tg3_read_vpd(struct tg3 *tp)\n{\nu8 *vpd_data;\nunsigned int block_end, rosize, len;\nu32 vpdlen;\nint j, i = 0;\nvpd_data = (u8 *)tg3_vpd_readblock(tp, &vpdlen);\nif (!vpd_data)\ngoto out_no_vpd;\ni = pci_vpd_find_tag(vpd_data, 0, vpdlen, PCI_VPD_LRDT_RO_DATA);\nif (i < 0)\ngoto out_not_found;\nrosize = pci_vpd_lrdt_size(&vpd_data[i]);\nblock_end = i + PCI_VPD_LRDT_TAG_SIZE + rosize;\ni += PCI_VPD_LRDT_TAG_SIZE;\nif (block_end > vpdlen)\ngoto out_not_found;\nj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\nPCI_VPD_RO_KEYWORD_MFR_ID);\nif (j > 0) {\nlen = pci_vpd_info_field_size(&vpd_data[j]);\nj += PCI_VPD_INFO_FLD_HDR_SIZE;\nif (j + len > block_end || len != 4 ||\nmemcmp(&vpd_data[j], \"1028\", 4))\ngoto partno;\nj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\nPCI_VPD_RO_KEYWORD_VENDOR0);\nif (j < 0)\ngoto partno;\nlen = pci_vpd_info_field_size(&vpd_data[j]);\nj += PCI_VPD_INFO_FLD_HDR_SIZE;\nif (j + len > block_end)\ngoto partno;\nif (len >= sizeof(tp->fw_ver))\nlen = sizeof(tp->fw_ver) - 1;\nmemset(tp->fw_ver, 0, sizeof(tp->fw_ver));\nsnprintf(tp->fw_ver, sizeof(tp->fw_ver), \"%.*s bc \", len,\n&vpd_data[j]);\n}\npartno:\ni = pci_vpd_find_info_keyword(vpd_data, i, rosize,\nPCI_VPD_RO_KEYWORD_PARTNO);\nif (i < 0)\ngoto out_not_found;\nlen = pci_vpd_info_field_size(&vpd_data[i]);\ni += PCI_VPD_INFO_FLD_HDR_SIZE;\nif (len > TG3_BPN_SIZE ||\n(len + i) > vpdlen)\ngoto out_not_found;\nmemcpy(tp->board_part_number, &vpd_data[i], len);\nout_not_found:\nkfree(vpd_data);\nif (tp->board_part_number[0])\nreturn;\nout_no_vpd:\nif (tg3_asic_rev(tp) == ASIC_REV_5717) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717 ||\ntp->pdev->device == TG3PCI_DEVICE_TIGON3_5717_C)\nstrcpy(tp->board_part_number, \"BCM5717\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5718)\nstrcpy(tp->board_part_number, \"BCM5718\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_57780) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57780)\nstrcpy(tp->board_part_number, \"BCM57780\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57760)\nstrcpy(tp->board_part_number, \"BCM57760\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57790)\nstrcpy(tp->board_part_number, \"BCM57790\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57788)\nstrcpy(tp->board_part_number, \"BCM57788\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_57765) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57761)\nstrcpy(tp->board_part_number, \"BCM57761\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57765)\nstrcpy(tp->board_part_number, \"BCM57765\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57781)\nstrcpy(tp->board_part_number, \"BCM57781\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57785)\nstrcpy(tp->board_part_number, \"BCM57785\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57791)\nstrcpy(tp->board_part_number, \"BCM57791\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57795)\nstrcpy(tp->board_part_number, \"BCM57795\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_57766) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57762)\nstrcpy(tp->board_part_number, \"BCM57762\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57766)\nstrcpy(tp->board_part_number, \"BCM57766\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57782)\nstrcpy(tp->board_part_number, \"BCM57782\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57786)\nstrcpy(tp->board_part_number, \"BCM57786\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_5906) {\nstrcpy(tp->board_part_number, \"BCM95906\");\n} else {\nnomatch:\nstrcpy(tp->board_part_number, \"none\");\n}\n}\n",
      "code_before_change_raw": "static void tg3_read_vpd(struct tg3 *tp)\n{\nu8 *vpd_data;\nunsigned int block_end, rosize, len;\nu32 vpdlen;\nint j, i = 0;\nvpd_data = (u8 *)tg3_vpd_readblock(tp, &vpdlen);\nif (!vpd_data)\ngoto out_no_vpd;\ni = pci_vpd_find_tag(vpd_data, 0, vpdlen, PCI_VPD_LRDT_RO_DATA);\nif (i < 0)\ngoto out_not_found;\nrosize = pci_vpd_lrdt_size(&vpd_data[i]);\nblock_end = i + PCI_VPD_LRDT_TAG_SIZE + rosize;\ni += PCI_VPD_LRDT_TAG_SIZE;\nif (block_end > vpdlen)\ngoto out_not_found;\nj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\nPCI_VPD_RO_KEYWORD_MFR_ID);\nif (j > 0) {\nlen = pci_vpd_info_field_size(&vpd_data[j]);\nj += PCI_VPD_INFO_FLD_HDR_SIZE;\nif (j + len > block_end || len != 4 ||\nmemcmp(&vpd_data[j], \"1028\", 4))\ngoto partno;\nj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\nPCI_VPD_RO_KEYWORD_VENDOR0);\nif (j < 0)\ngoto partno;\nlen = pci_vpd_info_field_size(&vpd_data[j]);\nj += PCI_VPD_INFO_FLD_HDR_SIZE;\nif (j + len > block_end)\ngoto partno;\nmemcpy(tp->fw_ver, &vpd_data[j], len);\nstrncat(tp->fw_ver, \" bc \", vpdlen - len - 1);\n}\npartno:\ni = pci_vpd_find_info_keyword(vpd_data, i, rosize,\nPCI_VPD_RO_KEYWORD_PARTNO);\nif (i < 0)\ngoto out_not_found;\nlen = pci_vpd_info_field_size(&vpd_data[i]);\ni += PCI_VPD_INFO_FLD_HDR_SIZE;\nif (len > TG3_BPN_SIZE ||\n(len + i) > vpdlen)\ngoto out_not_found;\nmemcpy(tp->board_part_number, &vpd_data[i], len);\nout_not_found:\nkfree(vpd_data);\nif (tp->board_part_number[0])\nreturn;\nout_no_vpd:\nif (tg3_asic_rev(tp) == ASIC_REV_5717) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717 ||\ntp->pdev->device == TG3PCI_DEVICE_TIGON3_5717_C)\nstrcpy(tp->board_part_number, \"BCM5717\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5718)\nstrcpy(tp->board_part_number, \"BCM5718\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_57780) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57780)\nstrcpy(tp->board_part_number, \"BCM57780\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57760)\nstrcpy(tp->board_part_number, \"BCM57760\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57790)\nstrcpy(tp->board_part_number, \"BCM57790\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57788)\nstrcpy(tp->board_part_number, \"BCM57788\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_57765) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57761)\nstrcpy(tp->board_part_number, \"BCM57761\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57765)\nstrcpy(tp->board_part_number, \"BCM57765\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57781)\nstrcpy(tp->board_part_number, \"BCM57781\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57785)\nstrcpy(tp->board_part_number, \"BCM57785\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57791)\nstrcpy(tp->board_part_number, \"BCM57791\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57795)\nstrcpy(tp->board_part_number, \"BCM57795\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_57766) {\nif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57762)\nstrcpy(tp->board_part_number, \"BCM57762\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57766)\nstrcpy(tp->board_part_number, \"BCM57766\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57782)\nstrcpy(tp->board_part_number, \"BCM57782\");\nelse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57786)\nstrcpy(tp->board_part_number, \"BCM57786\");\nelse\ngoto nomatch;\n} else if (tg3_asic_rev(tp) == ASIC_REV_5906) {\nstrcpy(tp->board_part_number, \"BCM95906\");\n} else {\nnomatch:\nstrcpy(tp->board_part_number, \"none\");\n}\n}\n"
    }
  ],
  "CVE-2013-2234": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of initialization for certain structure members in key_notify_sa_flush function.",
        "trigger_condition": "Local users read a broadcast message from the notify interface of an IPSec key_socket, leading to sensitive information disclosure from kernel heap memory.",
        "specific_code_behavior_causing_vulnerability": "The code does not initialize the 'sadb_msg_reserved' member of the 'sadb_msg' structure, leaving it with uninitialized memory that can be read by local users, potentially leaking sensitive information.",
        "solution": "To mitigate the vulnerability, it is necessary to initialize the 'sadb_msg_reserved' member of the 'sadb_msg' structure to prevent sensitive information disclosure. By setting 'sadb_msg_reserved' to 0, the structure is properly initialized, ensuring that no uninitialized memory is accessible to local users."
      },
      "GPT_analysis": "The modification is necessary to fix the vulnerability described in CVE-2013-2234. By adding the line `hdr->sadb_msg_reserved = 0;`, you are initializing the `sadb_msg_reserved` member of the `sadb_msg` structure. This member was not initialized in the original code snippet, which could allow local users to obtain sensitive information from kernel heap memory by reading a broadcast message from the notify interface of an IPSec key_socket.\n\nInitializing the `sadb_msg_reserved` member ensures that the structure is properly initialized, preventing potential security vulnerabilities related to uninitialized memory access. By setting it to 0, you are ensuring that no sensitive information is leaked from uninitialized memory locations, thus addressing the vulnerability.",
      "GPT_purpose": "Notify the IPSec key_socket of a SA flush event.",
      "GPT_function": "\n1. Allocate an skb buffer for a sadb_msg structure.\n2. Populate the sadb_msg structure with specific values.\n3. Broadcast the skb buffer using pfkey_broadcast function.",
      "CVE_id": "CVE-2013-2234",
      "code_before_change": "static int key_notify_sa_flush(const struct km_event *c)\n{\n\tstruct sk_buff *skb;\n\tstruct sadb_msg *hdr;\n\n\tskb = alloc_skb(sizeof(struct sadb_msg) + 16, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOBUFS;\n\thdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));\n\thdr->sadb_msg_satype = pfkey_proto2satype(c->data.proto);\n\thdr->sadb_msg_type = SADB_FLUSH;\n\thdr->sadb_msg_seq = c->seq;\n\thdr->sadb_msg_pid = c->portid;\n\thdr->sadb_msg_version = PF_KEY_V2;\n\thdr->sadb_msg_errno = (uint8_t) 0;\n\thdr->sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));\n\n\tpfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c->net);\n\n\treturn 0;\n}",
      "code_after_change": "static int key_notify_sa_flush(const struct km_event *c)\n{\n\tstruct sk_buff *skb;\n\tstruct sadb_msg *hdr;\n\n\tskb = alloc_skb(sizeof(struct sadb_msg) + 16, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOBUFS;\n\thdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));\n\thdr->sadb_msg_satype = pfkey_proto2satype(c->data.proto);\n\thdr->sadb_msg_type = SADB_FLUSH;\n\thdr->sadb_msg_seq = c->seq;\n\thdr->sadb_msg_pid = c->portid;\n\thdr->sadb_msg_version = PF_KEY_V2;\n\thdr->sadb_msg_errno = (uint8_t) 0;\n\thdr->sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));\n\thdr->sadb_msg_reserved = 0;\n\n\tpfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c->net);\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\thdr->sadb_msg_reserved = 0;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of initialization for certain structure members in key_notify_sa_flush function.",
      "trigger_condition": "Local users read a broadcast message from the notify interface of an IPSec key_socket, leading to sensitive information disclosure from kernel heap memory.",
      "specific_code_behavior_causing_vulnerability": "The code does not initialize the 'sadb_msg_reserved' member of the 'sadb_msg' structure, leaving it with uninitialized memory that can be read by local users, potentially leaking sensitive information.",
      "solution": "To mitigate the vulnerability, it is necessary to initialize the 'sadb_msg_reserved' member of the 'sadb_msg' structure to prevent sensitive information disclosure. By setting 'sadb_msg_reserved' to 0, the structure is properly initialized, ensuring that no uninitialized memory is accessible to local users.",
      "id": 30,
      "code_after_change_normalized": "static int FUN1(const struct km_event *VAR1)\n{\nstruct sk_buff *VAR2;\nstruct sadb_msg *VAR3;\nVAR2 = FUN2(sizeof(struct VAR4) + 16, VAR5);\nif (!VAR2)\nreturn -VAR6;\nVAR3 = (struct VAR4 *) FUN3(VAR2, sizeof(struct VAR4));\nVAR3->VAR7 = FUN4(VAR1->VAR8.VAR9);\nVAR3->VAR10 = VAR11;\nVAR3->VAR12 = VAR1->VAR13;\nVAR3->VAR14 = VAR1->VAR15;\nVAR3->VAR16 = VAR17;\nVAR3->VAR18 = (VAR19) 0;\nVAR3->VAR20 = (sizeof(struct VAR4) / sizeof(VAR21));\nVAR3->VAR22 = 0;\nFUN5(VAR2, VAR5, VAR23, NULL, VAR1->VAR24);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(const struct km_event *VAR1)\n{\nstruct sk_buff *VAR2;\nstruct sadb_msg *VAR3;\nVAR2 = FUN2(sizeof(struct VAR4) + 16, VAR5);\nif (!VAR2)\nreturn -VAR6;\nVAR3 = (struct VAR4 *) FUN3(VAR2, sizeof(struct VAR4));\nVAR3->VAR7 = FUN4(VAR1->VAR8.VAR9);\nVAR3->VAR10 = VAR11;\nVAR3->VAR12 = VAR1->VAR13;\nVAR3->VAR14 = VAR1->VAR15;\nVAR3->VAR16 = VAR17;\nVAR3->VAR18 = (VAR19) 0;\nVAR3->VAR20 = (sizeof(struct VAR4) / sizeof(VAR21));\nFUN5(VAR2, VAR5, VAR22, NULL, VAR1->VAR23);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int key_notify_sa_flush(const struct km_event *c)\n{\nstruct sk_buff *skb;\nstruct sadb_msg *hdr;\nskb = alloc_skb(sizeof(struct sadb_msg) + 16, GFP_ATOMIC);\nif (!skb)\nreturn -ENOBUFS;\nhdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));\nhdr->sadb_msg_satype = pfkey_proto2satype(c->data.proto);\nhdr->sadb_msg_type = SADB_FLUSH;\nhdr->sadb_msg_seq = c->seq;\nhdr->sadb_msg_pid = c->portid;\nhdr->sadb_msg_version = PF_KEY_V2;\nhdr->sadb_msg_errno = (uint8_t) 0;\nhdr->sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));\nhdr->sadb_msg_reserved = 0;\npfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c->net);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int key_notify_sa_flush(const struct km_event *c)\n{\nstruct sk_buff *skb;\nstruct sadb_msg *hdr;\nskb = alloc_skb(sizeof(struct sadb_msg) + 16, GFP_ATOMIC);\nif (!skb)\nreturn -ENOBUFS;\nhdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));\nhdr->sadb_msg_satype = pfkey_proto2satype(c->data.proto);\nhdr->sadb_msg_type = SADB_FLUSH;\nhdr->sadb_msg_seq = c->seq;\nhdr->sadb_msg_pid = c->portid;\nhdr->sadb_msg_version = PF_KEY_V2;\nhdr->sadb_msg_errno = (uint8_t) 0;\nhdr->sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));\npfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c->net);\nreturn 0;\n}\n"
    }
  ],
  "CVE-2013-2850": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for the length of the key input in the iscsi_decode_text_input function.",
        "trigger_condition": "An attacker provides a long key input that is not properly handled during the construction of an error-response packet, leading to a heap-based buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not check the length of the key input before processing it, resulting in insufficient memory allocation and potential buffer overflow when constructing the error-response packet."
      },
      "solution": "To mitigate the vulnerability, it is necessary to validate the length of the key input before processing it to prevent buffer overflow. By adding a check to ensure that the key length does not exceed a predefined maximum length, the code can allocate memory appropriately and avoid the heap-based buffer overflow issue. In this case, the solution involves adding a check for the key length and returning an error if it exceeds the maximum allowed length.",
      "GPT_analysis": "The modification is necessary to address the identified vulnerability CVE-2013-2850, which is a heap-based buffer overflow in the `iscsi_add_notunderstood_response` function. This vulnerability allows remote attackers to cause a denial of service or potentially execute arbitrary code by providing a long key that is not properly handled during the construction of an error-response packet.\n\nTo fix this vulnerability, you should ensure that the key length is properly validated and that sufficient memory is allocated to accommodate the key without causing a buffer overflow. This can be achieved by checking the length of the key before processing it and allocating memory accordingly.\n\nBy adding the following modification, you can prevent the buffer overflow issue:\n```\nif (strlen(key) > MAX_KEY_LENGTH) {\n    pr_err(\"Key length exceeds maximum allowed length.\\n\");\n    kfree(tmpbuf);\n    return -1;\n}\n```\n\nThis modification checks if the length of the key exceeds a predefined maximum length (`MAX_KEY_LENGTH`) and returns an error if it does, preventing the buffer overflow vulnerability.",
      "GPT_purpose": "Decode and process text input for iSCSI parameters, checking for specific keys and values and handling them accordingly, with a vulnerability that can lead to a heap-based buffer overflow.",
      "GPT_function": "\n1. Decode text input for iSCSI connection parameters.\n2. Extract key-value pairs from the input text.\n3. Check for authentication key during the security phase.\n4. Check and handle iSCSI parameters based on the phase and sender.\n5. Handle proposer and acceptor states for iSCSI parameters.\n6. Free allocated memory before returning.",
      "CVE_id": "CVE-2013-2850",
      "code_before_change": "int iscsi_decode_text_input(\n\tu8 phase,\n\tu8 sender,\n\tchar *textbuf,\n\tu32 length,\n\tstruct iscsi_conn *conn)\n{\n\tstruct iscsi_param_list *param_list = conn->param_list;\n\tchar *tmpbuf, *start = NULL, *end = NULL;\n\n\ttmpbuf = kzalloc(length + 1, GFP_KERNEL);\n\tif (!tmpbuf) {\n\t\tpr_err(\"Unable to allocate memory for tmpbuf.\\n\");\n\t\treturn -1;\n\t}\n\n\tmemcpy(tmpbuf, textbuf, length);\n\ttmpbuf[length] = '\\0';\n\tstart = tmpbuf;\n\tend = (start + length);\n\n\twhile (start < end) {\n\t\tchar *key, *value;\n\t\tstruct iscsi_param *param;\n\n\t\tif (iscsi_extract_key_value(start, &key, &value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tpr_debug(\"Got key: %s=%s\\n\", key, value);\n\n\t\tif (phase & PHASE_SECURITY) {\n\t\t\tif (iscsi_check_for_auth_key(key) > 0) {\n\t\t\t\tchar *tmpptr = key + strlen(key);\n\t\t\t\t*tmpptr = '=';\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tparam = iscsi_check_key(key, phase, sender, param_list);\n\t\tif (!param) {\n\t\t\tif (iscsi_add_notunderstood_response(key,\n\t\t\t\t\tvalue, param_list) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tstart += strlen(key) + strlen(value) + 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (iscsi_check_value(param, value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tstart += strlen(key) + strlen(value) + 2;\n\n\t\tif (IS_PSTATE_PROPOSER(param)) {\n\t\t\tif (iscsi_check_proposer_state(param, value) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_RESPONSE_GOT(param);\n\t\t} else {\n\t\t\tif (iscsi_check_acceptor_state(param, value, conn) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_ACCEPTOR(param);\n\t\t}\n\t}\n\n\tkfree(tmpbuf);\n\treturn 0;\n}",
      "code_after_change": "int iscsi_decode_text_input(\n\tu8 phase,\n\tu8 sender,\n\tchar *textbuf,\n\tu32 length,\n\tstruct iscsi_conn *conn)\n{\n\tstruct iscsi_param_list *param_list = conn->param_list;\n\tchar *tmpbuf, *start = NULL, *end = NULL;\n\n\ttmpbuf = kzalloc(length + 1, GFP_KERNEL);\n\tif (!tmpbuf) {\n\t\tpr_err(\"Unable to allocate memory for tmpbuf.\\n\");\n\t\treturn -1;\n\t}\n\n\tmemcpy(tmpbuf, textbuf, length);\n\ttmpbuf[length] = '\\0';\n\tstart = tmpbuf;\n\tend = (start + length);\n\n\twhile (start < end) {\n\t\tchar *key, *value;\n\t\tstruct iscsi_param *param;\n\n\t\tif (iscsi_extract_key_value(start, &key, &value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tpr_debug(\"Got key: %s=%s\\n\", key, value);\n\n\t\tif (phase & PHASE_SECURITY) {\n\t\t\tif (iscsi_check_for_auth_key(key) > 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tparam = iscsi_check_key(key, phase, sender, param_list);\n\t\tif (!param) {\n\t\t\tif (iscsi_add_notunderstood_response(key,\n\t\t\t\t\tvalue, param_list) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tstart += strlen(key) + strlen(value) + 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (iscsi_check_value(param, value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tstart += strlen(key) + strlen(value) + 2;\n\n\t\tif (IS_PSTATE_PROPOSER(param)) {\n\t\t\tif (iscsi_check_proposer_state(param, value) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_RESPONSE_GOT(param);\n\t\t} else {\n\t\t\tif (iscsi_check_acceptor_state(param, value, conn) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_ACCEPTOR(param);\n\t\t}\n\t}\n\n\tkfree(tmpbuf);\n\treturn 0;\n}",
      "modified_lines": {
        "added": [],
        "deleted": [
          "\t\t\t\tchar *tmpptr = key + strlen(key);",
          "\t\t\t\t*tmpptr = '=';"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for the length of the key input in the iscsi_decode_text_input function.",
      "trigger_condition": "An attacker provides a long key input that is not properly handled during the construction of an error-response packet, leading to a heap-based buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not check the length of the key input before processing it, resulting in insufficient memory allocation and potential buffer overflow when constructing the error-response packet.",
      "id": 31,
      "code_after_change_normalized": "int FUN1(\nu8 VAR1,\nu8 VAR2,\nchar *VAR3,\nu32 VAR4,\nstruct iscsi_conn *VAR5)\n{\nstruct iscsi_param_list *VAR6 = VAR5->VAR6;\nchar *VAR7, *VAR8 = NULL, *VAR9 = NULL;\nVAR7 = FUN2(VAR4 + 1, VAR10);\nif (!VAR7) {\nFUN3(\"STR\");\nreturn -1;\n}\nFUN4(VAR7, VAR3, VAR4);\nVAR7[VAR4] = ;\nVAR8 = VAR7;\nVAR9 = (VAR8 + VAR4);\nwhile (VAR8 < VAR9) {\nchar *VAR11, *VAR12;\nstruct iscsi_param *VAR13;\nif (FUN5(VAR8, &VAR11, &VAR12) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nFUN7(\"STR\", VAR11, VAR12);\nif (VAR1 & VAR14) {\nif (FUN8(VAR11) > 0) {\nFUN6(VAR7);\nreturn 1;\n}\n}\nVAR13 = FUN9(VAR11, VAR1, VAR2, VAR6);\nif (!VAR13) {\nif (FUN10(VAR11,\nVAR12, VAR6) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nVAR8 += FUN11(VAR11) + FUN11(VAR12) + 2;\ncontinue;\n}\nif (FUN12(VAR13, VAR12) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nVAR8 += FUN11(VAR11) + FUN11(VAR12) + 2;\nif (FUN13(VAR13)) {\nif (FUN14(VAR13, VAR12) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nFUN15(VAR13);\n} else {\nif (FUN16(VAR13, VAR12, VAR5) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nFUN17(VAR13);\n}\n}\nFUN6(VAR7);\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(\nu8 VAR1,\nu8 VAR2,\nchar *VAR3,\nu32 VAR4,\nstruct iscsi_conn *VAR5)\n{\nstruct iscsi_param_list *VAR6 = VAR5->VAR6;\nchar *VAR7, *VAR8 = NULL, *VAR9 = NULL;\nVAR7 = FUN2(VAR4 + 1, VAR10);\nif (!VAR7) {\nFUN3(\"STR\");\nreturn -1;\n}\nFUN4(VAR7, VAR3, VAR4);\nVAR7[VAR4] = ;\nVAR8 = VAR7;\nVAR9 = (VAR8 + VAR4);\nwhile (VAR8 < VAR9) {\nchar *VAR11, *VAR12;\nstruct iscsi_param *VAR13;\nif (FUN5(VAR8, &VAR11, &VAR12) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nFUN7(\"STR\", VAR11, VAR12);\nif (VAR1 & VAR14) {\nif (FUN8(VAR11) > 0) {\nchar *VAR15 = VAR11 + FUN9(VAR11);\n*VAR15 = ;\nFUN6(VAR7);\nreturn 1;\n}\n}\nVAR13 = FUN10(VAR11, VAR1, VAR2, VAR6);\nif (!VAR13) {\nif (FUN11(VAR11,\nVAR12, VAR6) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nVAR8 += FUN9(VAR11) + FUN9(VAR12) + 2;\ncontinue;\n}\nif (FUN12(VAR13, VAR12) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nVAR8 += FUN9(VAR11) + FUN9(VAR12) + 2;\nif (FUN13(VAR13)) {\nif (FUN14(VAR13, VAR12) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nFUN15(VAR13);\n} else {\nif (FUN16(VAR13, VAR12, VAR5) < 0) {\nFUN6(VAR7);\nreturn -1;\n}\nFUN17(VAR13);\n}\n}\nFUN6(VAR7);\nreturn 0;\n}\n",
      "code_after_change_raw": "int iscsi_decode_text_input(\nu8 phase,\nu8 sender,\nchar *textbuf,\nu32 length,\nstruct iscsi_conn *conn)\n{\nstruct iscsi_param_list *param_list = conn->param_list;\nchar *tmpbuf, *start = NULL, *end = NULL;\ntmpbuf = kzalloc(length + 1, GFP_KERNEL);\nif (!tmpbuf) {\npr_err(\"Unable to allocate memory for tmpbuf.\\n\");\nreturn -1;\n}\nmemcpy(tmpbuf, textbuf, length);\ntmpbuf[length] = '\\0';\nstart = tmpbuf;\nend = (start + length);\nwhile (start < end) {\nchar *key, *value;\nstruct iscsi_param *param;\nif (iscsi_extract_key_value(start, &key, &value) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\npr_debug(\"Got key: %s=%s\\n\", key, value);\nif (phase & PHASE_SECURITY) {\nif (iscsi_check_for_auth_key(key) > 0) {\nkfree(tmpbuf);\nreturn 1;\n}\n}\nparam = iscsi_check_key(key, phase, sender, param_list);\nif (!param) {\nif (iscsi_add_notunderstood_response(key,\nvalue, param_list) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nstart += strlen(key) + strlen(value) + 2;\ncontinue;\n}\nif (iscsi_check_value(param, value) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nstart += strlen(key) + strlen(value) + 2;\nif (IS_PSTATE_PROPOSER(param)) {\nif (iscsi_check_proposer_state(param, value) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nSET_PSTATE_RESPONSE_GOT(param);\n} else {\nif (iscsi_check_acceptor_state(param, value, conn) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nSET_PSTATE_ACCEPTOR(param);\n}\n}\nkfree(tmpbuf);\nreturn 0;\n}\n",
      "code_before_change_raw": "int iscsi_decode_text_input(\nu8 phase,\nu8 sender,\nchar *textbuf,\nu32 length,\nstruct iscsi_conn *conn)\n{\nstruct iscsi_param_list *param_list = conn->param_list;\nchar *tmpbuf, *start = NULL, *end = NULL;\ntmpbuf = kzalloc(length + 1, GFP_KERNEL);\nif (!tmpbuf) {\npr_err(\"Unable to allocate memory for tmpbuf.\\n\");\nreturn -1;\n}\nmemcpy(tmpbuf, textbuf, length);\ntmpbuf[length] = '\\0';\nstart = tmpbuf;\nend = (start + length);\nwhile (start < end) {\nchar *key, *value;\nstruct iscsi_param *param;\nif (iscsi_extract_key_value(start, &key, &value) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\npr_debug(\"Got key: %s=%s\\n\", key, value);\nif (phase & PHASE_SECURITY) {\nif (iscsi_check_for_auth_key(key) > 0) {\nchar *tmpptr = key + strlen(key);\n*tmpptr = '=';\nkfree(tmpbuf);\nreturn 1;\n}\n}\nparam = iscsi_check_key(key, phase, sender, param_list);\nif (!param) {\nif (iscsi_add_notunderstood_response(key,\nvalue, param_list) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nstart += strlen(key) + strlen(value) + 2;\ncontinue;\n}\nif (iscsi_check_value(param, value) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nstart += strlen(key) + strlen(value) + 2;\nif (IS_PSTATE_PROPOSER(param)) {\nif (iscsi_check_proposer_state(param, value) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nSET_PSTATE_RESPONSE_GOT(param);\n} else {\nif (iscsi_check_acceptor_state(param, value, conn) < 0) {\nkfree(tmpbuf);\nreturn -1;\n}\nSET_PSTATE_ACCEPTOR(param);\n}\n}\nkfree(tmpbuf);\nreturn 0;\n}\n"
    }
  ],
  "CVE-2013-2890": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for expected report characteristics of the HID device.",
        "trigger_condition": "A physically proximate attacker sends a crafted device input that does not conform to the expected report characteristics.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the expected report characteristics of the HID device, allowing a crafted input to trigger a denial of service via a heap-based out-of-bounds write."
      },
      "solution": "To mitigate the vulnerability, it is necessary to validate the expected report characteristics of the HID device before proceeding with further operations. This validation step ensures that the input conforms to the expected format and prevents a denial of service through a heap-based out-of-bounds write. In this case, the solution involves adding a line to validate the expected report characteristics of the HID device before continuing with the initialization process.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-2890, which involves a heap-based out-of-bounds write that can be triggered by a crafted device when CONFIG_HID_SONY is enabled in the Linux kernel. \n\nThe fix involves adding the following line to validate the expected report characteristics:\n```c\nif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 7))\n    return -ENODEV;\n```\n\nBy adding this validation step, the code ensures that the HID device's output report characteristics are within expected bounds, thus preventing the vulnerability from being exploited by a physically proximate attacker to cause a denial of service through a heap-based out-of-bounds write.\n\nTherefore, the modification is necessary to enhance the security of the code and prevent the identified vulnerability from being exploited.",
      "GPT_purpose": "Initialize a Sony Buzz controller device with LED support.",
      "GPT_function": "\n1. Initialize the buzz controller for a HID device.\n2. Allocate memory for LED devices and set their properties.\n3. Register LED devices with the HID device.\n4. Handle errors related to LED device allocation and registration.\n5. Free memory allocated for LED devices and the buzz controller in case of errors.",
      "CVE_id": "CVE-2013-2890",
      "code_before_change": "static int buzz_init(struct hid_device *hdev)\n{\n\tstruct sony_sc *drv_data;\n\tstruct buzz_extra *buzz;\n\tint n, ret = 0;\n\tstruct led_classdev *led;\n\tsize_t name_sz;\n\tchar *name;\n\n\tdrv_data = hid_get_drvdata(hdev);\n\tBUG_ON(!(drv_data->quirks & BUZZ_CONTROLLER));\n\n\tbuzz = kzalloc(sizeof(*buzz), GFP_KERNEL);\n\tif (!buzz) {\n\t\thid_err(hdev, \"Insufficient memory, cannot allocate driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->extra = buzz;\n\n\t/* Clear LEDs as we have no way of reading their initial state. This is\n\t * only relevant if the driver is loaded after somebody actively set the\n\t * LEDs to on */\n\tbuzz_set_leds(hdev, 0x00);\n\n\tname_sz = strlen(dev_name(&hdev->dev)) + strlen(\"::buzz#\") + 1;\n\n\tfor (n = 0; n < 4; n++) {\n\t\tled = kzalloc(sizeof(struct led_classdev) + name_sz, GFP_KERNEL);\n\t\tif (!led) {\n\t\t\thid_err(hdev, \"Couldn't allocate memory for LED %d\\n\", n);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz, \"%s::buzz%d\", dev_name(&hdev->dev), n + 1);\n\t\tled->name = name;\n\t\tled->brightness = 0;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = buzz_led_get_brightness;\n\t\tled->brightness_set = buzz_led_set_brightness;\n\n\t\tif (led_classdev_register(&hdev->dev, led)) {\n\t\t\thid_err(hdev, \"Failed to register LED %d\\n\", n);\n\t\t\tkfree(led);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tbuzz->leds[n] = led;\n\t}\n\n\treturn ret;\n\nerror_leds:\n\tfor (n = 0; n < 4; n++) {\n\t\tled = buzz->leds[n];\n\t\tbuzz->leds[n] = NULL;\n\t\tif (!led)\n\t\t\tcontinue;\n\t\tled_classdev_unregister(led);\n\t\tkfree(led);\n\t}\n\n\tkfree(drv_data->extra);\n\tdrv_data->extra = NULL;\n\treturn ret;\n}",
      "code_after_change": "static int buzz_init(struct hid_device *hdev)\n{\n\tstruct sony_sc *drv_data;\n\tstruct buzz_extra *buzz;\n\tint n, ret = 0;\n\tstruct led_classdev *led;\n\tsize_t name_sz;\n\tchar *name;\n\n\tdrv_data = hid_get_drvdata(hdev);\n\tBUG_ON(!(drv_data->quirks & BUZZ_CONTROLLER));\n\n\t/* Validate expected report characteristics. */\n\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -ENODEV;\n\n\tbuzz = kzalloc(sizeof(*buzz), GFP_KERNEL);\n\tif (!buzz) {\n\t\thid_err(hdev, \"Insufficient memory, cannot allocate driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->extra = buzz;\n\n\t/* Clear LEDs as we have no way of reading their initial state. This is\n\t * only relevant if the driver is loaded after somebody actively set the\n\t * LEDs to on */\n\tbuzz_set_leds(hdev, 0x00);\n\n\tname_sz = strlen(dev_name(&hdev->dev)) + strlen(\"::buzz#\") + 1;\n\n\tfor (n = 0; n < 4; n++) {\n\t\tled = kzalloc(sizeof(struct led_classdev) + name_sz, GFP_KERNEL);\n\t\tif (!led) {\n\t\t\thid_err(hdev, \"Couldn't allocate memory for LED %d\\n\", n);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz, \"%s::buzz%d\", dev_name(&hdev->dev), n + 1);\n\t\tled->name = name;\n\t\tled->brightness = 0;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = buzz_led_get_brightness;\n\t\tled->brightness_set = buzz_led_set_brightness;\n\n\t\tif (led_classdev_register(&hdev->dev, led)) {\n\t\t\thid_err(hdev, \"Failed to register LED %d\\n\", n);\n\t\t\tkfree(led);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tbuzz->leds[n] = led;\n\t}\n\n\treturn ret;\n\nerror_leds:\n\tfor (n = 0; n < 4; n++) {\n\t\tled = buzz->leds[n];\n\t\tbuzz->leds[n] = NULL;\n\t\tif (!led)\n\t\t\tcontinue;\n\t\tled_classdev_unregister(led);\n\t\tkfree(led);\n\t}\n\n\tkfree(drv_data->extra);\n\tdrv_data->extra = NULL;\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "",
          "\t/* Validate expected report characteristics. */",
          "\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 7))",
          "\t\treturn -ENODEV;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation for expected report characteristics of the HID device.",
      "trigger_condition": "A physically proximate attacker sends a crafted device input that does not conform to the expected report characteristics.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the expected report characteristics of the HID device, allowing a crafted input to trigger a denial of service via a heap-based out-of-bounds write.",
      "id": 32,
      "code_after_change_normalized": "static int FUN1(struct hid_device *VAR1)\n{\nstruct sony_sc *VAR2;\nstruct buzz_extra *VAR3;\nint VAR4, VAR5 = 0;\nstruct led_classdev *VAR6;\nsize_t VAR7;\nchar *VAR8;\nVAR2 = FUN2(VAR1);\nFUN3(!(VAR2->VAR9 & VAR10));\nif (!FUN4(VAR1, VAR11, 0, 0, 7))\nreturn -VAR12;\nVAR3 = FUN5(sizeof(*VAR3), VAR13);\nif (!VAR3) {\nFUN6(VAR1, \"STR\");\nreturn -VAR14;\n}\nVAR2->VAR15 = VAR3;\nFUN7(VAR1, VAR16);\nVAR7 = FUN8(FUN9(&VAR1->VAR17)) + FUN8(\"STR\") + 1;\nfor (VAR4 = 0; VAR4 < 4; VAR4++) {\nVAR6 = FUN5(sizeof(struct VAR18) + VAR7, VAR13);\nif (!VAR6) {\nFUN6(VAR1, \"STR\", VAR4);\ngoto VAR19;\n}\nVAR8 = (void *)(&VAR6[1]);\nFUN10(VAR8, VAR7, \"STR\", FUN9(&VAR1->VAR17), VAR4 + 1);\nVAR6->VAR8 = VAR8;\nVAR6->VAR20 = 0;\nVAR6->VAR21 = 1;\nVAR6->VAR22 = VAR23;\nVAR6->VAR24 = VAR25;\nif (FUN11(&VAR1->VAR17, VAR6)) {\nFUN6(VAR1, \"STR\", VAR4);\nFUN12(VAR6);\ngoto VAR19;\n}\nVAR3->VAR26[VAR4] = VAR6;\n}\nreturn VAR5;\nVAR19:\nfor (VAR4 = 0; VAR4 < 4; VAR4++) {\nVAR6 = VAR3->VAR26[VAR4];\nVAR3->VAR26[VAR4] = NULL;\nif (!VAR6)\ncontinue;\nFUN13(VAR6);\nFUN12(VAR6);\n}\nFUN12(VAR2->VAR15);\nVAR2->VAR15 = NULL;\nreturn VAR5;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct hid_device *VAR1)\n{\nstruct sony_sc *VAR2;\nstruct buzz_extra *VAR3;\nint VAR4, VAR5 = 0;\nstruct led_classdev *VAR6;\nsize_t VAR7;\nchar *VAR8;\nVAR2 = FUN2(VAR1);\nFUN3(!(VAR2->VAR9 & VAR10));\nVAR3 = FUN4(sizeof(*VAR3), VAR11);\nif (!VAR3) {\nFUN5(VAR1, \"STR\");\nreturn -VAR12;\n}\nVAR2->VAR13 = VAR3;\nFUN6(VAR1, VAR14);\nVAR7 = FUN7(FUN8(&VAR1->VAR15)) + FUN7(\"STR\") + 1;\nfor (VAR4 = 0; VAR4 < 4; VAR4++) {\nVAR6 = FUN4(sizeof(struct VAR16) + VAR7, VAR11);\nif (!VAR6) {\nFUN5(VAR1, \"STR\", VAR4);\ngoto VAR17;\n}\nVAR8 = (void *)(&VAR6[1]);\nFUN9(VAR8, VAR7, \"STR\", FUN8(&VAR1->VAR15), VAR4 + 1);\nVAR6->VAR8 = VAR8;\nVAR6->VAR18 = 0;\nVAR6->VAR19 = 1;\nVAR6->VAR20 = VAR21;\nVAR6->VAR22 = VAR23;\nif (FUN10(&VAR1->VAR15, VAR6)) {\nFUN5(VAR1, \"STR\", VAR4);\nFUN11(VAR6);\ngoto VAR17;\n}\nVAR3->VAR24[VAR4] = VAR6;\n}\nreturn VAR5;\nVAR17:\nfor (VAR4 = 0; VAR4 < 4; VAR4++) {\nVAR6 = VAR3->VAR24[VAR4];\nVAR3->VAR24[VAR4] = NULL;\nif (!VAR6)\ncontinue;\nFUN12(VAR6);\nFUN11(VAR6);\n}\nFUN11(VAR2->VAR13);\nVAR2->VAR13 = NULL;\nreturn VAR5;\n}\n",
      "code_after_change_raw": "static int buzz_init(struct hid_device *hdev)\n{\nstruct sony_sc *drv_data;\nstruct buzz_extra *buzz;\nint n, ret = 0;\nstruct led_classdev *led;\nsize_t name_sz;\nchar *name;\ndrv_data = hid_get_drvdata(hdev);\nBUG_ON(!(drv_data->quirks & BUZZ_CONTROLLER));\nif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 7))\nreturn -ENODEV;\nbuzz = kzalloc(sizeof(*buzz), GFP_KERNEL);\nif (!buzz) {\nhid_err(hdev, \"Insufficient memory, cannot allocate driver data\\n\");\nreturn -ENOMEM;\n}\ndrv_data->extra = buzz;\nbuzz_set_leds(hdev, 0x00);\nname_sz = strlen(dev_name(&hdev->dev)) + strlen(\"::buzz#\") + 1;\nfor (n = 0; n < 4; n++) {\nled = kzalloc(sizeof(struct led_classdev) + name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hdev, \"Couldn't allocate memory for LED %d\\n\", n);\ngoto error_leds;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"%s::buzz%d\", dev_name(&hdev->dev), n + 1);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = buzz_led_get_brightness;\nled->brightness_set = buzz_led_set_brightness;\nif (led_classdev_register(&hdev->dev, led)) {\nhid_err(hdev, \"Failed to register LED %d\\n\", n);\nkfree(led);\ngoto error_leds;\n}\nbuzz->leds[n] = led;\n}\nreturn ret;\nerror_leds:\nfor (n = 0; n < 4; n++) {\nled = buzz->leds[n];\nbuzz->leds[n] = NULL;\nif (!led)\ncontinue;\nled_classdev_unregister(led);\nkfree(led);\n}\nkfree(drv_data->extra);\ndrv_data->extra = NULL;\nreturn ret;\n}\n",
      "code_before_change_raw": "static int buzz_init(struct hid_device *hdev)\n{\nstruct sony_sc *drv_data;\nstruct buzz_extra *buzz;\nint n, ret = 0;\nstruct led_classdev *led;\nsize_t name_sz;\nchar *name;\ndrv_data = hid_get_drvdata(hdev);\nBUG_ON(!(drv_data->quirks & BUZZ_CONTROLLER));\nbuzz = kzalloc(sizeof(*buzz), GFP_KERNEL);\nif (!buzz) {\nhid_err(hdev, \"Insufficient memory, cannot allocate driver data\\n\");\nreturn -ENOMEM;\n}\ndrv_data->extra = buzz;\nbuzz_set_leds(hdev, 0x00);\nname_sz = strlen(dev_name(&hdev->dev)) + strlen(\"::buzz#\") + 1;\nfor (n = 0; n < 4; n++) {\nled = kzalloc(sizeof(struct led_classdev) + name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hdev, \"Couldn't allocate memory for LED %d\\n\", n);\ngoto error_leds;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"%s::buzz%d\", dev_name(&hdev->dev), n + 1);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = buzz_led_get_brightness;\nled->brightness_set = buzz_led_set_brightness;\nif (led_classdev_register(&hdev->dev, led)) {\nhid_err(hdev, \"Failed to register LED %d\\n\", n);\nkfree(led);\ngoto error_leds;\n}\nbuzz->leds[n] = led;\n}\nreturn ret;\nerror_leds:\nfor (n = 0; n < 4; n++) {\nled = buzz->leds[n];\nbuzz->leds[n] = NULL;\nif (!led)\ncontinue;\nled_classdev_unregister(led);\nkfree(led);\n}\nkfree(drv_data->extra);\ndrv_data->extra = NULL;\nreturn ret;\n}\n"
    }
  ],
  "CVE-2013-2891": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation on HID device values, specifically the output report size.",
        "trigger_condition": "A crafted device triggers a heap-based out-of-bounds write by providing malicious values for the output report size.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the output report size of the HID device, allowing a crafted device to provide values that lead to a heap-based out-of-bounds write vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add validation on the HID device values, specifically checking the output report size to ensure it falls within expected ranges. This validation step prevents malicious values from triggering a heap-based out-of-bounds write. In this case, the solution involves adding a validation check for the output report size to ensure it is within the expected range of 0 to 16 bytes.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-2891, which involves a denial of service (heap-based out-of-bounds write) caused by a crafted device in the Linux kernel's Human Interface Device (HID) subsystem when CONFIG_HID_STEELSERIES is enabled.\n\nThe added line `if (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 16))` is crucial because it performs validation on the HID device values to ensure they are within expected ranges. In this case, it checks if the output report size is within the expected range of 0 to 16 bytes. If the validation fails, it returns an error code `-ENODEV`, preventing the vulnerable code from proceeding and potentially causing a denial of service due to the out-of-bounds write vulnerability.\n\nBy adding this validation step, the code becomes more secure by ensuring that only valid and expected values are processed, thereby mitigating the vulnerability and enhancing the overall security of the system.",
      "GPT_purpose": "The function steelseries_srws1_probe is used to probe and initialize a SteelSeries SRW-S1 device, including setting up LED subsystem for controlling LEDs on the device.",
      "GPT_function": "\n1. Probe the steelseries_srws1 device.\n2. Parse the HID device.\n3. Start the hardware.\n4. Register the LED subsystem.\n5. Set up LEDs for the device.\n6. Register LED for setting all LEDs simultaneously.\n7. Register individual LEDs.\n8. Handle errors and clean up resources appropriately.",
      "CVE_id": "CVE-2013-2891",
      "code_before_change": "static int steelseries_srws1_probe(struct hid_device *hdev,\n\t\tconst struct hid_device_id *id)\n{\n\tint ret, i;\n\tstruct led_classdev *led;\n\tsize_t name_sz;\n\tchar *name;\n\n\tstruct steelseries_srws1_data *drv_data = kzalloc(sizeof(*drv_data), GFP_KERNEL);\n\n\tif (drv_data == NULL) {\n\t\thid_err(hdev, \"can't alloc SRW-S1 memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\thid_set_drvdata(hdev, drv_data);\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"parse failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"hw start failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\t/* register led subsystem */\n\tdrv_data->led_state = 0;\n\tfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++)\n\t\tdrv_data->led[i] = NULL;\n\n\tsteelseries_srws1_set_leds(hdev, 0);\n\n\tname_sz = strlen(hdev->uniq) + 16;\n\n\t/* 'ALL', for setting all LEDs simultaneously */\n\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\tif (!led) {\n\t\thid_err(hdev, \"can't allocate memory for LED ALL\\n\");\n\t\tgoto err_led;\n\t}\n\n\tname = (void *)(&led[1]);\n\tsnprintf(name, name_sz, \"SRWS1::%s::RPMALL\", hdev->uniq);\n\tled->name = name;\n\tled->brightness = 0;\n\tled->max_brightness = 1;\n\tled->brightness_get = steelseries_srws1_led_all_get_brightness;\n\tled->brightness_set = steelseries_srws1_led_all_set_brightness;\n\n\tdrv_data->led[SRWS1_NUMBER_LEDS] = led;\n\tret = led_classdev_register(&hdev->dev, led);\n\tif (ret)\n\t\tgoto err_led;\n\n\t/* Each individual LED */\n\tfor (i = 0; i < SRWS1_NUMBER_LEDS; i++) {\n\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\tif (!led) {\n\t\t\thid_err(hdev, \"can't allocate memory for LED %d\\n\", i);\n\t\t\tgoto err_led;\n\t\t}\n\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz, \"SRWS1::%s::RPM%d\", hdev->uniq, i+1);\n\t\tled->name = name;\n\t\tled->brightness = 0;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = steelseries_srws1_led_get_brightness;\n\t\tled->brightness_set = steelseries_srws1_led_set_brightness;\n\n\t\tdrv_data->led[i] = led;\n\t\tret = led_classdev_register(&hdev->dev, led);\n\n\t\tif (ret) {\n\t\t\thid_err(hdev, \"failed to register LED %d. Aborting.\\n\", i);\nerr_led:\n\t\t\t/* Deregister all LEDs (if any) */\n\t\t\tfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++) {\n\t\t\t\tled = drv_data->led[i];\n\t\t\t\tdrv_data->led[i] = NULL;\n\t\t\t\tif (!led)\n\t\t\t\t\tcontinue;\n\t\t\t\tled_classdev_unregister(led);\n\t\t\t\tkfree(led);\n\t\t\t}\n\t\t\tgoto out;\t/* but let the driver continue without LEDs */\n\t\t}\n\t}\nout:\n\treturn 0;\nerr_free:\n\tkfree(drv_data);\n\treturn ret;\n}",
      "code_after_change": "static int steelseries_srws1_probe(struct hid_device *hdev,\n\t\tconst struct hid_device_id *id)\n{\n\tint ret, i;\n\tstruct led_classdev *led;\n\tsize_t name_sz;\n\tchar *name;\n\n\tstruct steelseries_srws1_data *drv_data = kzalloc(sizeof(*drv_data), GFP_KERNEL);\n\n\tif (drv_data == NULL) {\n\t\thid_err(hdev, \"can't alloc SRW-S1 memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\thid_set_drvdata(hdev, drv_data);\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"parse failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 16)) {\n\t\tret = -ENODEV;\n\t\tgoto err_free;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"hw start failed\\n\");\n\t\tgoto err_free;\n\t}\n\n\t/* register led subsystem */\n\tdrv_data->led_state = 0;\n\tfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++)\n\t\tdrv_data->led[i] = NULL;\n\n\tsteelseries_srws1_set_leds(hdev, 0);\n\n\tname_sz = strlen(hdev->uniq) + 16;\n\n\t/* 'ALL', for setting all LEDs simultaneously */\n\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\tif (!led) {\n\t\thid_err(hdev, \"can't allocate memory for LED ALL\\n\");\n\t\tgoto err_led;\n\t}\n\n\tname = (void *)(&led[1]);\n\tsnprintf(name, name_sz, \"SRWS1::%s::RPMALL\", hdev->uniq);\n\tled->name = name;\n\tled->brightness = 0;\n\tled->max_brightness = 1;\n\tled->brightness_get = steelseries_srws1_led_all_get_brightness;\n\tled->brightness_set = steelseries_srws1_led_all_set_brightness;\n\n\tdrv_data->led[SRWS1_NUMBER_LEDS] = led;\n\tret = led_classdev_register(&hdev->dev, led);\n\tif (ret)\n\t\tgoto err_led;\n\n\t/* Each individual LED */\n\tfor (i = 0; i < SRWS1_NUMBER_LEDS; i++) {\n\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\tif (!led) {\n\t\t\thid_err(hdev, \"can't allocate memory for LED %d\\n\", i);\n\t\t\tgoto err_led;\n\t\t}\n\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz, \"SRWS1::%s::RPM%d\", hdev->uniq, i+1);\n\t\tled->name = name;\n\t\tled->brightness = 0;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = steelseries_srws1_led_get_brightness;\n\t\tled->brightness_set = steelseries_srws1_led_set_brightness;\n\n\t\tdrv_data->led[i] = led;\n\t\tret = led_classdev_register(&hdev->dev, led);\n\n\t\tif (ret) {\n\t\t\thid_err(hdev, \"failed to register LED %d. Aborting.\\n\", i);\nerr_led:\n\t\t\t/* Deregister all LEDs (if any) */\n\t\t\tfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++) {\n\t\t\t\tled = drv_data->led[i];\n\t\t\t\tdrv_data->led[i] = NULL;\n\t\t\t\tif (!led)\n\t\t\t\t\tcontinue;\n\t\t\t\tled_classdev_unregister(led);\n\t\t\t\tkfree(led);\n\t\t\t}\n\t\t\tgoto out;\t/* but let the driver continue without LEDs */\n\t\t}\n\t}\nout:\n\treturn 0;\nerr_free:\n\tkfree(drv_data);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\t\tgoto err_free;",
          "\t}",
          "",
          "\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 16)) {",
          "\t\tret = -ENODEV;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation on HID device values, specifically the output report size.",
      "trigger_condition": "A crafted device triggers a heap-based out-of-bounds write by providing malicious values for the output report size.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the output report size of the HID device, allowing a crafted device to provide values that lead to a heap-based out-of-bounds write vulnerability.",
      "id": 33,
      "code_after_change_normalized": "static int FUN1(struct hid_device *VAR1,\nconst struct hid_device_id *VAR2)\n{\nint VAR3, VAR4;\nstruct led_classdev *VAR5;\nsize_t VAR6;\nchar *VAR7;\nstruct steelseries_srws1_data *VAR8 = FUN2(sizeof(*VAR8), VAR9);\nif (VAR8 == NULL) {\nFUN3(VAR1, \"STR\");\nreturn -VAR10;\n}\nFUN4(VAR1, VAR8);\nVAR3 = FUN5(VAR1);\nif (VAR3) {\nFUN3(VAR1, \"STR\");\ngoto VAR11;\n}\nif (!FUN6(VAR1, VAR12, 0, 0, 16)) {\nVAR3 = -VAR13;\ngoto VAR11;\n}\nVAR3 = FUN7(VAR1, VAR14);\nif (VAR3) {\nFUN3(VAR1, \"STR\");\ngoto VAR11;\n}\nVAR8->VAR15 = 0;\nfor (VAR4 = 0; VAR4 < VAR16 + 1; VAR4++)\nVAR8->VAR5[VAR4] = NULL;\nFUN8(VAR1, 0);\nVAR6 = FUN9(VAR1->VAR17) + 16;\nVAR5 = FUN2(sizeof(struct VAR18)+VAR6, VAR9);\nif (!VAR5) {\nFUN3(VAR1, \"STR\");\ngoto VAR19;\n}\nVAR7 = (void *)(&VAR5[1]);\nFUN10(VAR7, VAR6, \"STR\", VAR1->VAR17);\nVAR5->VAR7 = VAR7;\nVAR5->VAR20 = 0;\nVAR5->VAR21 = 1;\nVAR5->VAR22 = VAR23;\nVAR5->VAR24 = VAR25;\nVAR8->VAR5[VAR16] = VAR5;\nVAR3 = FUN11(&VAR1->VAR26, VAR5);\nif (VAR3)\ngoto VAR19;\nfor (VAR4 = 0; VAR4 < VAR16; VAR4++) {\nVAR5 = FUN2(sizeof(struct VAR18)+VAR6, VAR9);\nif (!VAR5) {\nFUN3(VAR1, \"STR\", VAR4);\ngoto VAR19;\n}\nVAR7 = (void *)(&VAR5[1]);\nFUN10(VAR7, VAR6, \"STR\", VAR1->VAR17, VAR4+1);\nVAR5->VAR7 = VAR7;\nVAR5->VAR20 = 0;\nVAR5->VAR21 = 1;\nVAR5->VAR22 = VAR27;\nVAR5->VAR24 = VAR28;\nVAR8->VAR5[VAR4] = VAR5;\nVAR3 = FUN11(&VAR1->VAR26, VAR5);\nif (VAR3) {\nFUN3(VAR1, \"STR\", VAR4);\nVAR19:\nfor (VAR4 = 0; VAR4 < VAR16 + 1; VAR4++) {\nVAR5 = VAR8->VAR5[VAR4];\nVAR8->VAR5[VAR4] = NULL;\nif (!VAR5)\ncontinue;\nFUN12(VAR5);\nFUN13(VAR5);\n}\ngoto VAR29;\t\n}\n}\nVAR29:\nreturn 0;\nVAR11:\nFUN13(VAR8);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct hid_device *VAR1,\nconst struct hid_device_id *VAR2)\n{\nint VAR3, VAR4;\nstruct led_classdev *VAR5;\nsize_t VAR6;\nchar *VAR7;\nstruct steelseries_srws1_data *VAR8 = FUN2(sizeof(*VAR8), VAR9);\nif (VAR8 == NULL) {\nFUN3(VAR1, \"STR\");\nreturn -VAR10;\n}\nFUN4(VAR1, VAR8);\nVAR3 = FUN5(VAR1);\nif (VAR3) {\nFUN3(VAR1, \"STR\");\ngoto VAR11;\n}\nVAR3 = FUN6(VAR1, VAR12);\nif (VAR3) {\nFUN3(VAR1, \"STR\");\ngoto VAR11;\n}\nVAR8->VAR13 = 0;\nfor (VAR4 = 0; VAR4 < VAR14 + 1; VAR4++)\nVAR8->VAR5[VAR4] = NULL;\nFUN7(VAR1, 0);\nVAR6 = FUN8(VAR1->VAR15) + 16;\nVAR5 = FUN2(sizeof(struct VAR16)+VAR6, VAR9);\nif (!VAR5) {\nFUN3(VAR1, \"STR\");\ngoto VAR17;\n}\nVAR7 = (void *)(&VAR5[1]);\nFUN9(VAR7, VAR6, \"STR\", VAR1->VAR15);\nVAR5->VAR7 = VAR7;\nVAR5->VAR18 = 0;\nVAR5->VAR19 = 1;\nVAR5->VAR20 = VAR21;\nVAR5->VAR22 = VAR23;\nVAR8->VAR5[VAR14] = VAR5;\nVAR3 = FUN10(&VAR1->VAR24, VAR5);\nif (VAR3)\ngoto VAR17;\nfor (VAR4 = 0; VAR4 < VAR14; VAR4++) {\nVAR5 = FUN2(sizeof(struct VAR16)+VAR6, VAR9);\nif (!VAR5) {\nFUN3(VAR1, \"STR\", VAR4);\ngoto VAR17;\n}\nVAR7 = (void *)(&VAR5[1]);\nFUN9(VAR7, VAR6, \"STR\", VAR1->VAR15, VAR4+1);\nVAR5->VAR7 = VAR7;\nVAR5->VAR18 = 0;\nVAR5->VAR19 = 1;\nVAR5->VAR20 = VAR25;\nVAR5->VAR22 = VAR26;\nVAR8->VAR5[VAR4] = VAR5;\nVAR3 = FUN10(&VAR1->VAR24, VAR5);\nif (VAR3) {\nFUN3(VAR1, \"STR\", VAR4);\nVAR17:\nfor (VAR4 = 0; VAR4 < VAR14 + 1; VAR4++) {\nVAR5 = VAR8->VAR5[VAR4];\nVAR8->VAR5[VAR4] = NULL;\nif (!VAR5)\ncontinue;\nFUN11(VAR5);\nFUN12(VAR5);\n}\ngoto VAR27;\t\n}\n}\nVAR27:\nreturn 0;\nVAR11:\nFUN12(VAR8);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static int steelseries_srws1_probe(struct hid_device *hdev,\nconst struct hid_device_id *id)\n{\nint ret, i;\nstruct led_classdev *led;\nsize_t name_sz;\nchar *name;\nstruct steelseries_srws1_data *drv_data = kzalloc(sizeof(*drv_data), GFP_KERNEL);\nif (drv_data == NULL) {\nhid_err(hdev, \"can't alloc SRW-S1 memory\\n\");\nreturn -ENOMEM;\n}\nhid_set_drvdata(hdev, drv_data);\nret = hid_parse(hdev);\nif (ret) {\nhid_err(hdev, \"parse failed\\n\");\ngoto err_free;\n}\nif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 16)) {\nret = -ENODEV;\ngoto err_free;\n}\nret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\nif (ret) {\nhid_err(hdev, \"hw start failed\\n\");\ngoto err_free;\n}\ndrv_data->led_state = 0;\nfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++)\ndrv_data->led[i] = NULL;\nsteelseries_srws1_set_leds(hdev, 0);\nname_sz = strlen(hdev->uniq) + 16;\nled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hdev, \"can't allocate memory for LED ALL\\n\");\ngoto err_led;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"SRWS1::%s::RPMALL\", hdev->uniq);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = steelseries_srws1_led_all_get_brightness;\nled->brightness_set = steelseries_srws1_led_all_set_brightness;\ndrv_data->led[SRWS1_NUMBER_LEDS] = led;\nret = led_classdev_register(&hdev->dev, led);\nif (ret)\ngoto err_led;\nfor (i = 0; i < SRWS1_NUMBER_LEDS; i++) {\nled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hdev, \"can't allocate memory for LED %d\\n\", i);\ngoto err_led;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"SRWS1::%s::RPM%d\", hdev->uniq, i+1);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = steelseries_srws1_led_get_brightness;\nled->brightness_set = steelseries_srws1_led_set_brightness;\ndrv_data->led[i] = led;\nret = led_classdev_register(&hdev->dev, led);\nif (ret) {\nhid_err(hdev, \"failed to register LED %d. Aborting.\\n\", i);\nerr_led:\nfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++) {\nled = drv_data->led[i];\ndrv_data->led[i] = NULL;\nif (!led)\ncontinue;\nled_classdev_unregister(led);\nkfree(led);\n}\ngoto out;\t\n}\n}\nout:\nreturn 0;\nerr_free:\nkfree(drv_data);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int steelseries_srws1_probe(struct hid_device *hdev,\nconst struct hid_device_id *id)\n{\nint ret, i;\nstruct led_classdev *led;\nsize_t name_sz;\nchar *name;\nstruct steelseries_srws1_data *drv_data = kzalloc(sizeof(*drv_data), GFP_KERNEL);\nif (drv_data == NULL) {\nhid_err(hdev, \"can't alloc SRW-S1 memory\\n\");\nreturn -ENOMEM;\n}\nhid_set_drvdata(hdev, drv_data);\nret = hid_parse(hdev);\nif (ret) {\nhid_err(hdev, \"parse failed\\n\");\ngoto err_free;\n}\nret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\nif (ret) {\nhid_err(hdev, \"hw start failed\\n\");\ngoto err_free;\n}\ndrv_data->led_state = 0;\nfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++)\ndrv_data->led[i] = NULL;\nsteelseries_srws1_set_leds(hdev, 0);\nname_sz = strlen(hdev->uniq) + 16;\nled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hdev, \"can't allocate memory for LED ALL\\n\");\ngoto err_led;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"SRWS1::%s::RPMALL\", hdev->uniq);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = steelseries_srws1_led_all_get_brightness;\nled->brightness_set = steelseries_srws1_led_all_set_brightness;\ndrv_data->led[SRWS1_NUMBER_LEDS] = led;\nret = led_classdev_register(&hdev->dev, led);\nif (ret)\ngoto err_led;\nfor (i = 0; i < SRWS1_NUMBER_LEDS; i++) {\nled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hdev, \"can't allocate memory for LED %d\\n\", i);\ngoto err_led;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"SRWS1::%s::RPM%d\", hdev->uniq, i+1);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = steelseries_srws1_led_get_brightness;\nled->brightness_set = steelseries_srws1_led_set_brightness;\ndrv_data->led[i] = led;\nret = led_classdev_register(&hdev->dev, led);\nif (ret) {\nhid_err(hdev, \"failed to register LED %d. Aborting.\\n\", i);\nerr_led:\nfor (i = 0; i < SRWS1_NUMBER_LEDS + 1; i++) {\nled = drv_data->led[i];\ndrv_data->led[i] = NULL;\nif (!led)\ncontinue;\nled_classdev_unregister(led);\nkfree(led);\n}\ngoto out;\t\n}\n}\nout:\nreturn 0;\nerr_free:\nkfree(drv_data);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2013-2893": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "The code lacks proper validation of the HID report structure before accessing its fields.",
        "trigger_condition": "When a physically proximate attacker interacts with a crafted device, it can lead to a denial of service due to a heap-based out-of-bounds write vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the HID report structure before directly accessing its fields, allowing for potential out-of-bounds write operations if the report structure is not as expected."
      },
      "solution": "To mitigate the vulnerability, the code should include a validation step to check the HID report structure for correctness before accessing its fields. This validation ensures that the report is properly formatted and contains the expected values, reducing the risk of a heap-based out-of-bounds write vulnerability. In this case, the solution involves adding a call to the hid_validate_values function to validate the HID report structure before proceeding with further operations.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-2893 in the code snippet. The vulnerability allows physically proximate attackers to cause a denial of service (heap-based out-of-bounds write) by exploiting certain configurations in the HID subsystem of the Linux kernel.\n\nThe modification introduces a call to the `hid_validate_values` function to check that the report is valid before proceeding with the initialization. This helps prevent the out-of-bounds write vulnerability by ensuring that the report structure is properly validated and contains the expected values before accessing its fields.\n\nBy performing this validation step, the code becomes more robust and secure against potential attacks that exploit the vulnerability. It helps to mitigate the risk of unauthorized access and manipulation of memory beyond the allocated boundaries, thereby enhancing the overall security of the system.",
      "GPT_purpose": "Initialize force feedback for Logitech RumblePad/Rumblepad 2 devices.",
      "GPT_function": "\n1. Initialize a Logitech force feedback device.\n2. Check for the presence of an output report and its contents.\n3. Allocate memory for the device and set up force feedback effects.",
      "CVE_id": "CVE-2013-2893",
      "code_before_change": "int lg2ff_init(struct hid_device *hid)\n{\n\tstruct lg2ff_device *lg2ff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct list_head *report_list =\n\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct input_dev *dev = hidinput->input;\n\tint error;\n\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"no output report found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treport = list_entry(report_list->next, struct hid_report, list);\n\n\tif (report->maxfield < 1) {\n\t\thid_err(hid, \"output report is empty\\n\");\n\t\treturn -ENODEV;\n\t}\n\tif (report->field[0]->report_count < 7) {\n\t\thid_err(hid, \"not enough values in the field\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\n\tif (!lg2ff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, lg2ff, play_effect);\n\tif (error) {\n\t\tkfree(lg2ff);\n\t\treturn error;\n\t}\n\n\tlg2ff->report = report;\n\treport->field[0]->value[0] = 0xf3;\n\treport->field[0]->value[1] = 0x00;\n\treport->field[0]->value[2] = 0x00;\n\treport->field[0]->value[3] = 0x00;\n\treport->field[0]->value[4] = 0x00;\n\treport->field[0]->value[5] = 0x00;\n\treport->field[0]->value[6] = 0x00;\n\n\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force feedback for Logitech RumblePad/Rumblepad 2 by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\n\n\treturn 0;\n}",
      "code_after_change": "int lg2ff_init(struct hid_device *hid)\n{\n\tstruct lg2ff_device *lg2ff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tint error;\n\n\t/* Check that the report looks ok */\n\treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);\n\tif (!report)\n\t\treturn -ENODEV;\n\n\tlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\n\tif (!lg2ff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, lg2ff, play_effect);\n\tif (error) {\n\t\tkfree(lg2ff);\n\t\treturn error;\n\t}\n\n\tlg2ff->report = report;\n\treport->field[0]->value[0] = 0xf3;\n\treport->field[0]->value[1] = 0x00;\n\treport->field[0]->value[2] = 0x00;\n\treport->field[0]->value[3] = 0x00;\n\treport->field[0]->value[4] = 0x00;\n\treport->field[0]->value[5] = 0x00;\n\treport->field[0]->value[6] = 0x00;\n\n\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force feedback for Logitech RumblePad/Rumblepad 2 by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t/* Check that the report looks ok */",
          "\treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);",
          "\tif (!report)"
        ],
        "deleted": [
          "\tstruct list_head *report_list =",
          "\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;",
          "\tif (list_empty(report_list)) {",
          "\t\thid_err(hid, \"no output report found\\n\");",
          "\t}",
          "",
          "\treport = list_entry(report_list->next, struct hid_report, list);",
          "",
          "\tif (report->maxfield < 1) {",
          "\t\thid_err(hid, \"output report is empty\\n\");",
          "\t\treturn -ENODEV;",
          "\t}",
          "\tif (report->field[0]->report_count < 7) {",
          "\t\thid_err(hid, \"not enough values in the field\\n\");",
          "\t\treturn -ENODEV;",
          "\t}"
        ]
      },
      "preconditions_for_vulnerability": "The code lacks proper validation of the HID report structure before accessing its fields.",
      "trigger_condition": "When a physically proximate attacker interacts with a crafted device, it can lead to a denial of service due to a heap-based out-of-bounds write vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the HID report structure before directly accessing its fields, allowing for potential out-of-bounds write operations if the report structure is not as expected.",
      "id": 34,
      "code_after_change_normalized": "int FUN1(struct hid_device *VAR1)\n{\nstruct lg2ff_device *VAR2;\nstruct hid_report *VAR3;\nstruct hid_input *VAR4 = FUN2(VAR1->VAR5.VAR6,\nstruct VAR7, VAR8);\nstruct input_dev *VAR9 = VAR4->VAR10;\nint VAR11;\nVAR3 = FUN3(VAR1, VAR12, 0, 0, 7);\nif (!VAR3)\nreturn -VAR13;\nVAR2 = FUN4(sizeof(struct VAR14), VAR15);\nif (!VAR2)\nreturn -VAR16;\nFUN5(VAR17, VAR9->VAR18);\nVAR11 = FUN6(VAR9, VAR2, VAR19);\nif (VAR11) {\nFUN7(VAR2);\nreturn VAR11;\n}\nVAR2->VAR3 = VAR3;\nVAR3->VAR20[0]->VAR21[0] = VAR22;\nVAR3->VAR20[0]->VAR21[1] = VAR22;\nVAR3->VAR20[0]->VAR21[2] = VAR22;\nVAR3->VAR20[0]->VAR21[3] = VAR22;\nVAR3->VAR20[0]->VAR21[4] = VAR22;\nVAR3->VAR20[0]->VAR21[5] = VAR22;\nVAR3->VAR20[0]->VAR21[6] = VAR22;\nFUN8(VAR1, VAR3, VAR23);\nFUN9(VAR1, \"STR\");\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(struct hid_device *VAR1)\n{\nstruct lg2ff_device *VAR2;\nstruct hid_report *VAR3;\nstruct hid_input *VAR4 = FUN2(VAR1->VAR5.VAR6,\nstruct VAR7, VAR8);\nstruct list_head *VAR9 =\n&VAR1->VAR10[VAR11].VAR9;\nstruct input_dev *VAR12 = VAR4->VAR13;\nint VAR14;\nif (FUN3(VAR9)) {\nFUN4(VAR1, \"STR\");\nreturn -VAR15;\n}\nVAR3 = FUN2(VAR9->VAR6, struct VAR16, VAR8);\nif (VAR3->VAR17 < 1) {\nFUN4(VAR1, \"STR\");\nreturn -VAR15;\n}\nif (VAR3->VAR18[0]->VAR19 < 7) {\nFUN4(VAR1, \"STR\");\nreturn -VAR15;\n}\nVAR2 = FUN5(sizeof(struct VAR20), VAR21);\nif (!VAR2)\nreturn -VAR22;\nFUN6(VAR23, VAR12->VAR24);\nVAR14 = FUN7(VAR12, VAR2, VAR25);\nif (VAR14) {\nFUN8(VAR2);\nreturn VAR14;\n}\nVAR2->VAR3 = VAR3;\nVAR3->VAR18[0]->VAR26[0] = VAR27;\nVAR3->VAR18[0]->VAR26[1] = VAR27;\nVAR3->VAR18[0]->VAR26[2] = VAR27;\nVAR3->VAR18[0]->VAR26[3] = VAR27;\nVAR3->VAR18[0]->VAR26[4] = VAR27;\nVAR3->VAR18[0]->VAR26[5] = VAR27;\nVAR3->VAR18[0]->VAR26[6] = VAR27;\nFUN9(VAR1, VAR3, VAR28);\nFUN10(VAR1, \"STR\");\nreturn 0;\n}\n",
      "code_after_change_raw": "int lg2ff_init(struct hid_device *hid)\n{\nstruct lg2ff_device *lg2ff;\nstruct hid_report *report;\nstruct hid_input *hidinput = list_entry(hid->inputs.next,\nstruct hid_input, list);\nstruct input_dev *dev = hidinput->input;\nint error;\nreport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);\nif (!report)\nreturn -ENODEV;\nlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\nif (!lg2ff)\nreturn -ENOMEM;\nset_bit(FF_RUMBLE, dev->ffbit);\nerror = input_ff_create_memless(dev, lg2ff, play_effect);\nif (error) {\nkfree(lg2ff);\nreturn error;\n}\nlg2ff->report = report;\nreport->field[0]->value[0] = 0xf3;\nreport->field[0]->value[1] = 0x00;\nreport->field[0]->value[2] = 0x00;\nreport->field[0]->value[3] = 0x00;\nreport->field[0]->value[4] = 0x00;\nreport->field[0]->value[5] = 0x00;\nreport->field[0]->value[6] = 0x00;\nhid_hw_request(hid, report, HID_REQ_SET_REPORT);\nhid_info(hid, \"Force feedback for Logitech RumblePad/Rumblepad 2 by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\nreturn 0;\n}\n",
      "code_before_change_raw": "int lg2ff_init(struct hid_device *hid)\n{\nstruct lg2ff_device *lg2ff;\nstruct hid_report *report;\nstruct hid_input *hidinput = list_entry(hid->inputs.next,\nstruct hid_input, list);\nstruct list_head *report_list =\n&hid->report_enum[HID_OUTPUT_REPORT].report_list;\nstruct input_dev *dev = hidinput->input;\nint error;\nif (list_empty(report_list)) {\nhid_err(hid, \"no output report found\\n\");\nreturn -ENODEV;\n}\nreport = list_entry(report_list->next, struct hid_report, list);\nif (report->maxfield < 1) {\nhid_err(hid, \"output report is empty\\n\");\nreturn -ENODEV;\n}\nif (report->field[0]->report_count < 7) {\nhid_err(hid, \"not enough values in the field\\n\");\nreturn -ENODEV;\n}\nlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\nif (!lg2ff)\nreturn -ENOMEM;\nset_bit(FF_RUMBLE, dev->ffbit);\nerror = input_ff_create_memless(dev, lg2ff, play_effect);\nif (error) {\nkfree(lg2ff);\nreturn error;\n}\nlg2ff->report = report;\nreport->field[0]->value[0] = 0xf3;\nreport->field[0]->value[1] = 0x00;\nreport->field[0]->value[2] = 0x00;\nreport->field[0]->value[3] = 0x00;\nreport->field[0]->value[4] = 0x00;\nreport->field[0]->value[5] = 0x00;\nreport->field[0]->value[6] = 0x00;\nhid_hw_request(hid, report, HID_REQ_SET_REPORT);\nhid_info(hid, \"Force feedback for Logitech RumblePad/Rumblepad 2 by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for HID output report values, allowing for potential out-of-bounds write vulnerabilities.",
        "trigger_condition": "Crafted device input with malicious HID output report values triggers a heap-based out-of-bounds write vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the HID output report values before processing them, leading to potential out-of-bounds memory writes if the values are manipulated by a malicious device."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a validation step to check the HID output report values for correctness and ensure they are within expected bounds before proceeding with further operations. This validation step helps prevent potential out-of-bounds memory writes and enhances the security of the code.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-2893 in the code snippet. The vulnerability involves a heap-based out-of-bounds write that can be triggered by a crafted device when certain HID subsystem configurations are enabled. \n\nThe modification introduces a call to the `hid_validate_values` function to check the validity of the HID output report before proceeding with further operations. This validation step helps prevent the vulnerability from being exploited by ensuring that the HID report is within expected bounds and does not contain malicious data that could lead to a denial of service.\n\nBy adding the `hid_validate_values` check, the code snippet becomes more secure and less susceptible to the heap-based out-of-bounds write vulnerability described in the CVE-2013-2893.",
      "GPT_purpose": "Initialize a Logitech force feedback device and set up various properties and capabilities, including checking for compatibility, switching to native mode, setting force feedback effects, creating a sysfs interface, and registering LED subsystem for specific devices.",
      "GPT_function": "\n1. Initialize a Logitech force feedback device.\n2. Check for compatibility with supported devices.\n3. Set force feedback capabilities and autocentering.\n4. Initialize device properties and create a sysfs interface.\n5. Register LED subsystem for specific devices.",
      "CVE_id": "CVE-2013-2893",
      "code_before_change": "int lg4ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct input_dev *dev = hidinput->input;\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tstruct lg4ff_device_entry *entry;\n\tstruct lg_drv_data *drv_data;\n\tstruct usb_device_descriptor *udesc;\n\tint error, i, j;\n\t__u16 bcdDevice, rev_maj, rev_min;\n\n\t/* Find the report to use */\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"No output report found\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Check that the report looks ok */\n\treport = list_entry(report_list->next, struct hid_report, list);\n\tif (!report) {\n\t\thid_err(hid, \"NULL output report\\n\");\n\t\treturn -1;\n\t}\n\n\tfield = report->field[0];\n\tif (!field) {\n\t\thid_err(hid, \"NULL field\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Check what wheel has been connected */\n\tfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\n\t\tif (hid->product == lg4ff_devices[i].product_id) {\n\t\t\tdbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == ARRAY_SIZE(lg4ff_devices)) {\n\t\thid_err(hid, \"Device is not supported by lg4ff driver. If you think it should be, consider reporting a bug to\"\n\t\t\t     \"LKML, Simon Wood <simon@mungewell.org> or Michal Maly <madcatxster@gmail.com>\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Attempt to switch wheel to native mode when applicable */\n\tudesc = &(hid_to_usb_dev(hid)->descriptor);\n\tif (!udesc) {\n\t\thid_err(hid, \"NULL USB device descriptor\\n\");\n\t\treturn -1;\n\t}\n\tbcdDevice = le16_to_cpu(udesc->bcdDevice);\n\trev_maj = bcdDevice >> 8;\n\trev_min = bcdDevice & 0xff;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_WHEEL) {\n\t\tdbg_hid(\"Generic wheel detected, can it do native?\\n\");\n\t\tdbg_hid(\"USB revision: %2x.%02x\\n\", rev_maj, rev_min);\n\n\t\tfor (j = 0; j < ARRAY_SIZE(lg4ff_revs); j++) {\n\t\t\tif (lg4ff_revs[j].rev_maj == rev_maj && lg4ff_revs[j].rev_min == rev_min) {\n\t\t\t\thid_lg4ff_switch_native(hid, lg4ff_revs[j].command);\n\t\t\t\thid_info(hid, \"Switched to native mode\\n\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\n\t\tset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lg4ff_play);\n\n\tif (error)\n\t\treturn error;\n\n\t/* Check if autocentering is available and\n\t * set the centering force to zero by default */\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\n\t\tif (rev_maj == FFEX_REV_MAJ && rev_min == FFEX_REV_MIN)\t/* Formula Force EX expects different autocentering command */\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_ffex;\n\t\telse\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_default;\n\n\t\tdev->ff->set_autocenter(dev, 0);\n\t}\n\n\t/* Get private driver data */\n\tdrv_data = hid_get_drvdata(hid);\n\tif (!drv_data) {\n\t\thid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Initialize device properties */\n\tentry = kzalloc(sizeof(struct lg4ff_device_entry), GFP_KERNEL);\n\tif (!entry) {\n\t\thid_err(hid, \"Cannot add device, insufficient memory to allocate device properties.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->device_props = entry;\n\n\tentry->product_id = lg4ff_devices[i].product_id;\n\tentry->min_range = lg4ff_devices[i].min_range;\n\tentry->max_range = lg4ff_devices[i].max_range;\n\tentry->set_range = lg4ff_devices[i].set_range;\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&hid->dev, &dev_attr_range);\n\tif (error)\n\t\treturn error;\n\tdbg_hid(\"sysfs interface created\\n\");\n\n\t/* Set the maximum range to start with */\n\tentry->range = entry->max_range;\n\tif (entry->set_range != NULL)\n\t\tentry->set_range(hid, entry->range);\n\n#ifdef CONFIG_LEDS_CLASS\n\t/* register led subsystem - G27 only */\n\tentry->led_state = 0;\n\tfor (j = 0; j < 5; j++)\n\t\tentry->led[j] = NULL;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL) {\n\t\tstruct led_classdev *led;\n\t\tsize_t name_sz;\n\t\tchar *name;\n\n\t\tlg4ff_set_leds(hid, 0);\n\n\t\tname_sz = strlen(dev_name(&hid->dev)) + 8;\n\n\t\tfor (j = 0; j < 5; j++) {\n\t\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\t\tif (!led) {\n\t\t\t\thid_err(hid, \"can't allocate memory for LED %d\\n\", j);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tname = (void *)(&led[1]);\n\t\t\tsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\n\t\t\tled->name = name;\n\t\t\tled->brightness = 0;\n\t\t\tled->max_brightness = 1;\n\t\t\tled->brightness_get = lg4ff_led_get_brightness;\n\t\t\tled->brightness_set = lg4ff_led_set_brightness;\n\n\t\t\tentry->led[j] = led;\n\t\t\terror = led_classdev_register(&hid->dev, led);\n\n\t\t\tif (error) {\n\t\t\t\thid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr:\n\t\t\t\t/* Deregister LEDs (if any) */\n\t\t\t\tfor (j = 0; j < 5; j++) {\n\t\t\t\t\tled = entry->led[j];\n\t\t\t\t\tentry->led[j] = NULL;\n\t\t\t\t\tif (!led)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tled_classdev_unregister(led);\n\t\t\t\t\tkfree(led);\n\t\t\t\t}\n\t\t\t\tgoto out;\t/* Let the driver continue without LEDs */\n\t\t\t}\n\t\t}\n\t}\nout:\n#endif\n\thid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\n\treturn 0;\n}",
      "code_after_change": "int lg4ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tstruct lg4ff_device_entry *entry;\n\tstruct lg_drv_data *drv_data;\n\tstruct usb_device_descriptor *udesc;\n\tint error, i, j;\n\t__u16 bcdDevice, rev_maj, rev_min;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -1;\n\n\t/* Check what wheel has been connected */\n\tfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\n\t\tif (hid->product == lg4ff_devices[i].product_id) {\n\t\t\tdbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == ARRAY_SIZE(lg4ff_devices)) {\n\t\thid_err(hid, \"Device is not supported by lg4ff driver. If you think it should be, consider reporting a bug to\"\n\t\t\t     \"LKML, Simon Wood <simon@mungewell.org> or Michal Maly <madcatxster@gmail.com>\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Attempt to switch wheel to native mode when applicable */\n\tudesc = &(hid_to_usb_dev(hid)->descriptor);\n\tif (!udesc) {\n\t\thid_err(hid, \"NULL USB device descriptor\\n\");\n\t\treturn -1;\n\t}\n\tbcdDevice = le16_to_cpu(udesc->bcdDevice);\n\trev_maj = bcdDevice >> 8;\n\trev_min = bcdDevice & 0xff;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_WHEEL) {\n\t\tdbg_hid(\"Generic wheel detected, can it do native?\\n\");\n\t\tdbg_hid(\"USB revision: %2x.%02x\\n\", rev_maj, rev_min);\n\n\t\tfor (j = 0; j < ARRAY_SIZE(lg4ff_revs); j++) {\n\t\t\tif (lg4ff_revs[j].rev_maj == rev_maj && lg4ff_revs[j].rev_min == rev_min) {\n\t\t\t\thid_lg4ff_switch_native(hid, lg4ff_revs[j].command);\n\t\t\t\thid_info(hid, \"Switched to native mode\\n\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\n\t\tset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lg4ff_play);\n\n\tif (error)\n\t\treturn error;\n\n\t/* Check if autocentering is available and\n\t * set the centering force to zero by default */\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\n\t\tif (rev_maj == FFEX_REV_MAJ && rev_min == FFEX_REV_MIN)\t/* Formula Force EX expects different autocentering command */\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_ffex;\n\t\telse\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_default;\n\n\t\tdev->ff->set_autocenter(dev, 0);\n\t}\n\n\t/* Get private driver data */\n\tdrv_data = hid_get_drvdata(hid);\n\tif (!drv_data) {\n\t\thid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Initialize device properties */\n\tentry = kzalloc(sizeof(struct lg4ff_device_entry), GFP_KERNEL);\n\tif (!entry) {\n\t\thid_err(hid, \"Cannot add device, insufficient memory to allocate device properties.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->device_props = entry;\n\n\tentry->product_id = lg4ff_devices[i].product_id;\n\tentry->min_range = lg4ff_devices[i].min_range;\n\tentry->max_range = lg4ff_devices[i].max_range;\n\tentry->set_range = lg4ff_devices[i].set_range;\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&hid->dev, &dev_attr_range);\n\tif (error)\n\t\treturn error;\n\tdbg_hid(\"sysfs interface created\\n\");\n\n\t/* Set the maximum range to start with */\n\tentry->range = entry->max_range;\n\tif (entry->set_range != NULL)\n\t\tentry->set_range(hid, entry->range);\n\n#ifdef CONFIG_LEDS_CLASS\n\t/* register led subsystem - G27 only */\n\tentry->led_state = 0;\n\tfor (j = 0; j < 5; j++)\n\t\tentry->led[j] = NULL;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL) {\n\t\tstruct led_classdev *led;\n\t\tsize_t name_sz;\n\t\tchar *name;\n\n\t\tlg4ff_set_leds(hid, 0);\n\n\t\tname_sz = strlen(dev_name(&hid->dev)) + 8;\n\n\t\tfor (j = 0; j < 5; j++) {\n\t\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\t\tif (!led) {\n\t\t\t\thid_err(hid, \"can't allocate memory for LED %d\\n\", j);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tname = (void *)(&led[1]);\n\t\t\tsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\n\t\t\tled->name = name;\n\t\t\tled->brightness = 0;\n\t\t\tled->max_brightness = 1;\n\t\t\tled->brightness_get = lg4ff_led_get_brightness;\n\t\t\tled->brightness_set = lg4ff_led_set_brightness;\n\n\t\t\tentry->led[j] = led;\n\t\t\terror = led_classdev_register(&hid->dev, led);\n\n\t\t\tif (error) {\n\t\t\t\thid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr:\n\t\t\t\t/* Deregister LEDs (if any) */\n\t\t\t\tfor (j = 0; j < 5; j++) {\n\t\t\t\t\tled = entry->led[j];\n\t\t\t\t\tentry->led[j] = NULL;\n\t\t\t\t\tif (!led)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tled_classdev_unregister(led);\n\t\t\t\t\tkfree(led);\n\t\t\t\t}\n\t\t\t\tgoto out;\t/* Let the driver continue without LEDs */\n\t\t\t}\n\t\t}\n\t}\nout:\n#endif\n\thid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t/* Check that the report looks ok */",
          "\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))"
        ],
        "deleted": [
          "\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;",
          "\tstruct hid_report *report;",
          "\tstruct hid_field *field;",
          "\t/* Find the report to use */",
          "\tif (list_empty(report_list)) {",
          "\t\thid_err(hid, \"No output report found\\n\");",
          "\t}",
          "",
          "\t/* Check that the report looks ok */",
          "\treport = list_entry(report_list->next, struct hid_report, list);",
          "\tif (!report) {",
          "\t\thid_err(hid, \"NULL output report\\n\");",
          "\t\treturn -1;",
          "\t}",
          "",
          "\tfield = report->field[0];",
          "\tif (!field) {",
          "\t\thid_err(hid, \"NULL field\\n\");",
          "\t\treturn -1;",
          "\t}"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation for HID output report values, allowing for potential out-of-bounds write vulnerabilities.",
      "trigger_condition": "Crafted device input with malicious HID output report values triggers a heap-based out-of-bounds write vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the HID output report values before processing them, leading to potential out-of-bounds memory writes if the values are manipulated by a malicious device.",
      "id": 35,
      "code_after_change_normalized": "int FUN1(struct hid_device *VAR1)\n{\nstruct VAR5 *VAR2 = FUN2(VAR1->VAR3.VAR4, struct VAR5, VAR6);\nstruct input_dev *VAR7 = VAR2->VAR8;\nstruct lg4ff_device_entry *VAR9;\nstruct lg_drv_data *VAR10;\nstruct usb_device_descriptor *VAR11;\nint VAR12, VAR13, VAR14;\n__u16 VAR15, VAR16, VAR17;\nif (!FUN3(VAR1, VAR18, 0, 0, 7))\nreturn -1;\nfor (VAR13 = 0; VAR13 < FUN4(VAR19); VAR13++) {\nif (VAR1->VAR20 == VAR19[VAR13].VAR21) {\nFUN5(\"STR\", VAR19[VAR13].VAR21);\nbreak;\n}\n}\nif (VAR13 == FUN4(VAR19)) {\nFUN6(VAR1, \"STR\"\n\"STR\");\nreturn -1;\n}\nVAR11 = &(FUN7(VAR1)->VAR22);\nif (!VAR11) {\nFUN6(VAR1, \"STR\");\nreturn -1;\n}\nVAR15 = FUN8(VAR11->VAR15);\nVAR16 = VAR15 >> 8;\nVAR17 = VAR15 & VAR23;\nif (VAR19[VAR13].VAR21 == VAR24) {\nFUN5(\"STR\");\nFUN5(\"STR\", VAR16, VAR17);\nfor (VAR14 = 0; VAR14 < FUN4(VAR25); VAR14++) {\nif (VAR25[VAR14].VAR16 == VAR16 && VAR25[VAR14].VAR17 == VAR17) {\nFUN9(VAR1, VAR25[VAR14].VAR26);\nFUN10(VAR1, \"STR\");\n}\n}\n}\nfor (VAR14 = 0; VAR19[VAR13].VAR27[VAR14] >= 0; VAR14++)\nFUN11(VAR19[VAR13].VAR27[VAR14], VAR7->VAR28);\nVAR12 = FUN12(VAR7, NULL, VAR29);\nif (VAR12)\nreturn VAR12;\nif (FUN13(VAR30, VAR7->VAR28)) {\nif (VAR16 == VAR31 && VAR17 == VAR32)\t\nVAR7->VAR33->VAR34 = VAR35;\nelse\nVAR7->VAR33->VAR34 = VAR36;\nVAR7->VAR33->FUN14(VAR7, 0);\n}\nVAR10 = FUN15(VAR1);\nif (!VAR10) {\nFUN6(VAR1, \"STR\");\nreturn -1;\n}\nVAR9 = FUN16(sizeof(struct VAR37), VAR38);\nif (!VAR9) {\nFUN6(VAR1, \"STR\");\nreturn -VAR39;\n}\nVAR10->VAR40 = VAR9;\nVAR9->VAR21 = VAR19[VAR13].VAR21;\nVAR9->VAR41 = VAR19[VAR13].VAR41;\nVAR9->VAR42 = VAR19[VAR13].VAR42;\nVAR9->VAR43 = VAR19[VAR13].VAR43;\nVAR12 = FUN17(&VAR1->VAR7, &VAR44);\nif (VAR12)\nreturn VAR12;\nFUN5(\"STR\");\nVAR9->VAR45 = VAR9->VAR42;\nif (VAR9->VAR43 != NULL)\nVAR9->FUN18(VAR1, VAR9->VAR45);\n#ifdef VAR46\nVAR9->VAR47 = 0;\nfor (VAR14 = 0; VAR14 < 5; VAR14++)\nVAR9->VAR48[VAR14] = NULL;\nif (VAR19[VAR13].VAR21 == VAR49) {\nstruct led_classdev *VAR48;\nsize_t VAR50;\nchar *VAR51;\nFUN19(VAR1, 0);\nVAR50 = FUN20(FUN21(&VAR1->VAR7)) + 8;\nfor (VAR14 = 0; VAR14 < 5; VAR14++) {\nVAR48 = FUN16(sizeof(struct VAR52)+VAR50, VAR38);\nif (!VAR48) {\nFUN6(VAR1, \"STR\", VAR14);\ngoto VAR53;\n}\nVAR51 = (void *)(&VAR48[1]);\nFUN22(VAR51, VAR50, \"STR\", FUN21(&VAR1->VAR7), VAR14+1);\nVAR48->VAR51 = VAR51;\nVAR48->VAR54 = 0;\nVAR48->VAR55 = 1;\nVAR48->VAR56 = VAR57;\nVAR48->VAR58 = VAR59;\nVAR9->VAR48[VAR14] = VAR48;\nVAR12 = FUN23(&VAR1->VAR7, VAR48);\nif (VAR12) {\nFUN6(VAR1, \"STR\", VAR14);\nVAR53:\nfor (VAR14 = 0; VAR14 < 5; VAR14++) {\nVAR48 = VAR9->VAR48[VAR14];\nVAR9->VAR48[VAR14] = NULL;\nif (!VAR48)\ncontinue;\nFUN24(VAR48);\nFUN25(VAR48);\n}\ngoto VAR60;\t\n}\n}\n}\nVAR60:\n#VAR61\nFUN10(VAR1, \"STR\");\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(struct hid_device *VAR1)\n{\nstruct VAR5 *VAR2 = FUN2(VAR1->VAR3.VAR4, struct VAR5, VAR6);\nstruct list_head *VAR7 = &VAR1->VAR8[VAR9].VAR7;\nstruct input_dev *VAR10 = VAR2->VAR11;\nstruct hid_report *VAR12;\nstruct hid_field *VAR13;\nstruct lg4ff_device_entry *VAR14;\nstruct lg_drv_data *VAR15;\nstruct usb_device_descriptor *VAR16;\nint VAR17, VAR18, VAR19;\n__u16 VAR20, VAR21, VAR22;\nif (FUN3(VAR7)) {\nFUN4(VAR1, \"STR\");\nreturn -1;\n}\nVAR12 = FUN2(VAR7->VAR4, struct VAR23, VAR6);\nif (!VAR12) {\nFUN4(VAR1, \"STR\");\nreturn -1;\n}\nVAR13 = VAR12->VAR13[0];\nif (!VAR13) {\nFUN4(VAR1, \"STR\");\nreturn -1;\n}\nfor (VAR18 = 0; VAR18 < FUN5(VAR24); VAR18++) {\nif (VAR1->VAR25 == VAR24[VAR18].VAR26) {\nFUN6(\"STR\", VAR24[VAR18].VAR26);\nbreak;\n}\n}\nif (VAR18 == FUN5(VAR24)) {\nFUN4(VAR1, \"STR\"\n\"STR\");\nreturn -1;\n}\nVAR16 = &(FUN7(VAR1)->VAR27);\nif (!VAR16) {\nFUN4(VAR1, \"STR\");\nreturn -1;\n}\nVAR20 = FUN8(VAR16->VAR20);\nVAR21 = VAR20 >> 8;\nVAR22 = VAR20 & VAR28;\nif (VAR24[VAR18].VAR26 == VAR29) {\nFUN6(\"STR\");\nFUN6(\"STR\", VAR21, VAR22);\nfor (VAR19 = 0; VAR19 < FUN5(VAR30); VAR19++) {\nif (VAR30[VAR19].VAR21 == VAR21 && VAR30[VAR19].VAR22 == VAR22) {\nFUN9(VAR1, VAR30[VAR19].VAR31);\nFUN10(VAR1, \"STR\");\n}\n}\n}\nfor (VAR19 = 0; VAR24[VAR18].VAR32[VAR19] >= 0; VAR19++)\nFUN11(VAR24[VAR18].VAR32[VAR19], VAR10->VAR33);\nVAR17 = FUN12(VAR10, NULL, VAR34);\nif (VAR17)\nreturn VAR17;\nif (FUN13(VAR35, VAR10->VAR33)) {\nif (VAR21 == VAR36 && VAR22 == VAR37)\t\nVAR10->VAR38->VAR39 = VAR40;\nelse\nVAR10->VAR38->VAR39 = VAR41;\nVAR10->VAR38->FUN14(VAR10, 0);\n}\nVAR15 = FUN15(VAR1);\nif (!VAR15) {\nFUN4(VAR1, \"STR\");\nreturn -1;\n}\nVAR14 = FUN16(sizeof(struct VAR42), VAR43);\nif (!VAR14) {\nFUN4(VAR1, \"STR\");\nreturn -VAR44;\n}\nVAR15->VAR45 = VAR14;\nVAR14->VAR26 = VAR24[VAR18].VAR26;\nVAR14->VAR46 = VAR24[VAR18].VAR46;\nVAR14->VAR47 = VAR24[VAR18].VAR47;\nVAR14->VAR48 = VAR24[VAR18].VAR48;\nVAR17 = FUN17(&VAR1->VAR10, &VAR49);\nif (VAR17)\nreturn VAR17;\nFUN6(\"STR\");\nVAR14->VAR50 = VAR14->VAR47;\nif (VAR14->VAR48 != NULL)\nVAR14->FUN18(VAR1, VAR14->VAR50);\n#ifdef VAR51\nVAR14->VAR52 = 0;\nfor (VAR19 = 0; VAR19 < 5; VAR19++)\nVAR14->VAR53[VAR19] = NULL;\nif (VAR24[VAR18].VAR26 == VAR54) {\nstruct led_classdev *VAR53;\nsize_t VAR55;\nchar *VAR56;\nFUN19(VAR1, 0);\nVAR55 = FUN20(FUN21(&VAR1->VAR10)) + 8;\nfor (VAR19 = 0; VAR19 < 5; VAR19++) {\nVAR53 = FUN16(sizeof(struct VAR57)+VAR55, VAR43);\nif (!VAR53) {\nFUN4(VAR1, \"STR\", VAR19);\ngoto VAR58;\n}\nVAR56 = (void *)(&VAR53[1]);\nFUN22(VAR56, VAR55, \"STR\", FUN21(&VAR1->VAR10), VAR19+1);\nVAR53->VAR56 = VAR56;\nVAR53->VAR59 = 0;\nVAR53->VAR60 = 1;\nVAR53->VAR61 = VAR62;\nVAR53->VAR63 = VAR64;\nVAR14->VAR53[VAR19] = VAR53;\nVAR17 = FUN23(&VAR1->VAR10, VAR53);\nif (VAR17) {\nFUN4(VAR1, \"STR\", VAR19);\nVAR58:\nfor (VAR19 = 0; VAR19 < 5; VAR19++) {\nVAR53 = VAR14->VAR53[VAR19];\nVAR14->VAR53[VAR19] = NULL;\nif (!VAR53)\ncontinue;\nFUN24(VAR53);\nFUN25(VAR53);\n}\ngoto VAR65;\t\n}\n}\n}\nVAR65:\n#VAR66\nFUN10(VAR1, \"STR\");\nreturn 0;\n}\n",
      "code_after_change_raw": "int lg4ff_init(struct hid_device *hid)\n{\nstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\nstruct input_dev *dev = hidinput->input;\nstruct lg4ff_device_entry *entry;\nstruct lg_drv_data *drv_data;\nstruct usb_device_descriptor *udesc;\nint error, i, j;\n__u16 bcdDevice, rev_maj, rev_min;\nif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\nreturn -1;\nfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\nif (hid->product == lg4ff_devices[i].product_id) {\ndbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\nbreak;\n}\n}\nif (i == ARRAY_SIZE(lg4ff_devices)) {\nhid_err(hid, \"Device is not supported by lg4ff driver. If you think it should be, consider reporting a bug to\"\n\"LKML, Simon Wood <simon@mungewell.org> or Michal Maly <madcatxster@gmail.com>\\n\");\nreturn -1;\n}\nudesc = &(hid_to_usb_dev(hid)->descriptor);\nif (!udesc) {\nhid_err(hid, \"NULL USB device descriptor\\n\");\nreturn -1;\n}\nbcdDevice = le16_to_cpu(udesc->bcdDevice);\nrev_maj = bcdDevice >> 8;\nrev_min = bcdDevice & 0xff;\nif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_WHEEL) {\ndbg_hid(\"Generic wheel detected, can it do native?\\n\");\ndbg_hid(\"USB revision: %2x.%02x\\n\", rev_maj, rev_min);\nfor (j = 0; j < ARRAY_SIZE(lg4ff_revs); j++) {\nif (lg4ff_revs[j].rev_maj == rev_maj && lg4ff_revs[j].rev_min == rev_min) {\nhid_lg4ff_switch_native(hid, lg4ff_revs[j].command);\nhid_info(hid, \"Switched to native mode\\n\");\n}\n}\n}\nfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\nset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\nerror = input_ff_create_memless(dev, NULL, hid_lg4ff_play);\nif (error)\nreturn error;\nif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\nif (rev_maj == FFEX_REV_MAJ && rev_min == FFEX_REV_MIN)\t\ndev->ff->set_autocenter = hid_lg4ff_set_autocenter_ffex;\nelse\ndev->ff->set_autocenter = hid_lg4ff_set_autocenter_default;\ndev->ff->set_autocenter(dev, 0);\n}\ndrv_data = hid_get_drvdata(hid);\nif (!drv_data) {\nhid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\nreturn -1;\n}\nentry = kzalloc(sizeof(struct lg4ff_device_entry), GFP_KERNEL);\nif (!entry) {\nhid_err(hid, \"Cannot add device, insufficient memory to allocate device properties.\\n\");\nreturn -ENOMEM;\n}\ndrv_data->device_props = entry;\nentry->product_id = lg4ff_devices[i].product_id;\nentry->min_range = lg4ff_devices[i].min_range;\nentry->max_range = lg4ff_devices[i].max_range;\nentry->set_range = lg4ff_devices[i].set_range;\nerror = device_create_file(&hid->dev, &dev_attr_range);\nif (error)\nreturn error;\ndbg_hid(\"sysfs interface created\\n\");\nentry->range = entry->max_range;\nif (entry->set_range != NULL)\nentry->set_range(hid, entry->range);\n#ifdef CONFIG_LEDS_CLASS\nentry->led_state = 0;\nfor (j = 0; j < 5; j++)\nentry->led[j] = NULL;\nif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL) {\nstruct led_classdev *led;\nsize_t name_sz;\nchar *name;\nlg4ff_set_leds(hid, 0);\nname_sz = strlen(dev_name(&hid->dev)) + 8;\nfor (j = 0; j < 5; j++) {\nled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hid, \"can't allocate memory for LED %d\\n\", j);\ngoto err;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = lg4ff_led_get_brightness;\nled->brightness_set = lg4ff_led_set_brightness;\nentry->led[j] = led;\nerror = led_classdev_register(&hid->dev, led);\nif (error) {\nhid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr:\nfor (j = 0; j < 5; j++) {\nled = entry->led[j];\nentry->led[j] = NULL;\nif (!led)\ncontinue;\nled_classdev_unregister(led);\nkfree(led);\n}\ngoto out;\t\n}\n}\n}\nout:\n#endif\nhid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\nreturn 0;\n}\n",
      "code_before_change_raw": "int lg4ff_init(struct hid_device *hid)\n{\nstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\nstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\nstruct input_dev *dev = hidinput->input;\nstruct hid_report *report;\nstruct hid_field *field;\nstruct lg4ff_device_entry *entry;\nstruct lg_drv_data *drv_data;\nstruct usb_device_descriptor *udesc;\nint error, i, j;\n__u16 bcdDevice, rev_maj, rev_min;\nif (list_empty(report_list)) {\nhid_err(hid, \"No output report found\\n\");\nreturn -1;\n}\nreport = list_entry(report_list->next, struct hid_report, list);\nif (!report) {\nhid_err(hid, \"NULL output report\\n\");\nreturn -1;\n}\nfield = report->field[0];\nif (!field) {\nhid_err(hid, \"NULL field\\n\");\nreturn -1;\n}\nfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\nif (hid->product == lg4ff_devices[i].product_id) {\ndbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\nbreak;\n}\n}\nif (i == ARRAY_SIZE(lg4ff_devices)) {\nhid_err(hid, \"Device is not supported by lg4ff driver. If you think it should be, consider reporting a bug to\"\n\"LKML, Simon Wood <simon@mungewell.org> or Michal Maly <madcatxster@gmail.com>\\n\");\nreturn -1;\n}\nudesc = &(hid_to_usb_dev(hid)->descriptor);\nif (!udesc) {\nhid_err(hid, \"NULL USB device descriptor\\n\");\nreturn -1;\n}\nbcdDevice = le16_to_cpu(udesc->bcdDevice);\nrev_maj = bcdDevice >> 8;\nrev_min = bcdDevice & 0xff;\nif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_WHEEL) {\ndbg_hid(\"Generic wheel detected, can it do native?\\n\");\ndbg_hid(\"USB revision: %2x.%02x\\n\", rev_maj, rev_min);\nfor (j = 0; j < ARRAY_SIZE(lg4ff_revs); j++) {\nif (lg4ff_revs[j].rev_maj == rev_maj && lg4ff_revs[j].rev_min == rev_min) {\nhid_lg4ff_switch_native(hid, lg4ff_revs[j].command);\nhid_info(hid, \"Switched to native mode\\n\");\n}\n}\n}\nfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\nset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\nerror = input_ff_create_memless(dev, NULL, hid_lg4ff_play);\nif (error)\nreturn error;\nif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\nif (rev_maj == FFEX_REV_MAJ && rev_min == FFEX_REV_MIN)\t\ndev->ff->set_autocenter = hid_lg4ff_set_autocenter_ffex;\nelse\ndev->ff->set_autocenter = hid_lg4ff_set_autocenter_default;\ndev->ff->set_autocenter(dev, 0);\n}\ndrv_data = hid_get_drvdata(hid);\nif (!drv_data) {\nhid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\nreturn -1;\n}\nentry = kzalloc(sizeof(struct lg4ff_device_entry), GFP_KERNEL);\nif (!entry) {\nhid_err(hid, \"Cannot add device, insufficient memory to allocate device properties.\\n\");\nreturn -ENOMEM;\n}\ndrv_data->device_props = entry;\nentry->product_id = lg4ff_devices[i].product_id;\nentry->min_range = lg4ff_devices[i].min_range;\nentry->max_range = lg4ff_devices[i].max_range;\nentry->set_range = lg4ff_devices[i].set_range;\nerror = device_create_file(&hid->dev, &dev_attr_range);\nif (error)\nreturn error;\ndbg_hid(\"sysfs interface created\\n\");\nentry->range = entry->max_range;\nif (entry->set_range != NULL)\nentry->set_range(hid, entry->range);\n#ifdef CONFIG_LEDS_CLASS\nentry->led_state = 0;\nfor (j = 0; j < 5; j++)\nentry->led[j] = NULL;\nif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL) {\nstruct led_classdev *led;\nsize_t name_sz;\nchar *name;\nlg4ff_set_leds(hid, 0);\nname_sz = strlen(dev_name(&hid->dev)) + 8;\nfor (j = 0; j < 5; j++) {\nled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\nif (!led) {\nhid_err(hid, \"can't allocate memory for LED %d\\n\", j);\ngoto err;\n}\nname = (void *)(&led[1]);\nsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\nled->name = name;\nled->brightness = 0;\nled->max_brightness = 1;\nled->brightness_get = lg4ff_led_get_brightness;\nled->brightness_set = lg4ff_led_set_brightness;\nentry->led[j] = led;\nerror = led_classdev_register(&hid->dev, led);\nif (error) {\nhid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr:\nfor (j = 0; j < 5; j++) {\nled = entry->led[j];\nentry->led[j] = NULL;\nif (!led)\ncontinue;\nled_classdev_unregister(led);\nkfree(led);\n}\ngoto out;\t\n}\n}\n}\nout:\n#endif\nhid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\nreturn 0;\n}\n"
    }
  ],
  "CVE-2013-2894": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for required reports during device initialization.",
        "trigger_condition": "When a crafted device is initialized without proper validation of required reports, a physically proximate attacker can exploit the vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code initializes the device without validating the required reports, allowing a crafted device to trigger a heap-based out-of-bounds write vulnerability."
      },
      "solution": "To address the vulnerability, it is necessary to validate the required reports before proceeding with the device initialization process. This validation step ensures that the device meets the expected criteria and helps prevent the crafted device from triggering the heap-based out-of-bounds write vulnerability. In this case, the solution involves adding code to validate the required reports using the hid_validate_values function before continuing with the device initialization.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-2894, which involves a heap-based out-of-bounds write issue in the HID subsystem of the Linux kernel. By adding the code snippet that validates the required reports before proceeding with the initialization of the device, the modification helps prevent the vulnerability from being exploited by physically proximate attackers to cause a denial of service.\n\nSpecifically, the added code snippet checks for the required reports using the `hid_validate_values` function to ensure that the device meets the expected criteria before continuing with the initialization process. This validation step helps to mitigate the risk of the crafted device triggering the vulnerability and causing a heap-based out-of-bounds write, thus improving the security of the code and preventing potential attacks.",
      "GPT_purpose": "Initialize and configure a Lenovo ThinkPad keyboard device with LED controls and default values.",
      "GPT_function": "\n1. Probe the touchpad keyboard device.\n2. Allocate memory for driver data and set default values.\n3. Allocate memory for LED data and register LED devices.\n4. Set touchpad keyboard features.\n5. Handle error cases by freeing allocated memory.",
      "CVE_id": "CVE-2013-2894",
      "code_before_change": "static int tpkbd_probe_tp(struct hid_device *hdev)\n{\n\tstruct device *dev = &hdev->dev;\n\tstruct tpkbd_data_pointer *data_pointer;\n\tsize_t name_sz = strlen(dev_name(dev)) + 16;\n\tchar *name_mute, *name_micmute;\n\tint ret;\n\n\tif (sysfs_create_group(&hdev->dev.kobj,\n\t\t\t\t&tpkbd_attr_group_pointer)) {\n\t\thid_warn(hdev, \"Could not create sysfs group\\n\");\n\t}\n\n\tdata_pointer = kzalloc(sizeof(struct tpkbd_data_pointer), GFP_KERNEL);\n\tif (data_pointer == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t// set same default values as windows driver\n\tdata_pointer->sensitivity = 0xa0;\n\tdata_pointer->press_speed = 0x38;\n\n\tname_mute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_mute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tsnprintf(name_mute, name_sz, \"%s:amber:mute\", dev_name(dev));\n\n\tname_micmute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_micmute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err2;\n\t}\n\tsnprintf(name_micmute, name_sz, \"%s:amber:micmute\", dev_name(dev));\n\n\thid_set_drvdata(hdev, data_pointer);\n\n\tdata_pointer->led_mute.name = name_mute;\n\tdata_pointer->led_mute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_mute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_mute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_mute);\n\n\tdata_pointer->led_micmute.name = name_micmute;\n\tdata_pointer->led_micmute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_micmute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_micmute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_micmute);\n\n\ttpkbd_features_set(hdev);\n\n\treturn 0;\n\nerr2:\n\tkfree(name_mute);\nerr:\n\tkfree(data_pointer);\n\treturn ret;\n}",
      "code_after_change": "static int tpkbd_probe_tp(struct hid_device *hdev)\n{\n\tstruct device *dev = &hdev->dev;\n\tstruct tpkbd_data_pointer *data_pointer;\n\tsize_t name_sz = strlen(dev_name(dev)) + 16;\n\tchar *name_mute, *name_micmute;\n\tint i, ret;\n\n\t/* Validate required reports. */\n\tfor (i = 0; i < 4; i++) {\n\t\tif (!hid_validate_values(hdev, HID_FEATURE_REPORT, 4, i, 1))\n\t\t\treturn -ENODEV;\n\t}\n\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 3, 0, 2))\n\t\treturn -ENODEV;\n\n\tif (sysfs_create_group(&hdev->dev.kobj,\n\t\t\t\t&tpkbd_attr_group_pointer)) {\n\t\thid_warn(hdev, \"Could not create sysfs group\\n\");\n\t}\n\n\tdata_pointer = kzalloc(sizeof(struct tpkbd_data_pointer), GFP_KERNEL);\n\tif (data_pointer == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t// set same default values as windows driver\n\tdata_pointer->sensitivity = 0xa0;\n\tdata_pointer->press_speed = 0x38;\n\n\tname_mute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_mute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tsnprintf(name_mute, name_sz, \"%s:amber:mute\", dev_name(dev));\n\n\tname_micmute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_micmute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err2;\n\t}\n\tsnprintf(name_micmute, name_sz, \"%s:amber:micmute\", dev_name(dev));\n\n\thid_set_drvdata(hdev, data_pointer);\n\n\tdata_pointer->led_mute.name = name_mute;\n\tdata_pointer->led_mute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_mute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_mute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_mute);\n\n\tdata_pointer->led_micmute.name = name_micmute;\n\tdata_pointer->led_micmute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_micmute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_micmute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_micmute);\n\n\ttpkbd_features_set(hdev);\n\n\treturn 0;\n\nerr2:\n\tkfree(name_mute);\nerr:\n\tkfree(data_pointer);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tint i, ret;",
          "",
          "\t/* Validate required reports. */",
          "\tfor (i = 0; i < 4; i++) {",
          "\t\tif (!hid_validate_values(hdev, HID_FEATURE_REPORT, 4, i, 1))",
          "\t\t\treturn -ENODEV;",
          "\t}",
          "\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 3, 0, 2))",
          "\t\treturn -ENODEV;"
        ],
        "deleted": [
          "\tint ret;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation for required reports during device initialization.",
      "trigger_condition": "When a crafted device is initialized without proper validation of required reports, a physically proximate attacker can exploit the vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code initializes the device without validating the required reports, allowing a crafted device to trigger a heap-based out-of-bounds write vulnerability.",
      "id": 36,
      "code_after_change_normalized": "static int FUN1(struct hid_device *VAR1)\n{\nstruct device *VAR2 = &VAR1->VAR2;\nstruct tpkbd_data_pointer *VAR3;\nsize_t VAR4 = FUN2(FUN3(VAR2)) + 16;\nchar *VAR5, *VAR6;\nint VAR7, VAR8;\nfor (VAR7 = 0; VAR7 < 4; VAR7++) {\nif (!FUN4(VAR1, VAR9, 4, VAR7, 1))\nreturn -VAR10;\n}\nif (!FUN4(VAR1, VAR11, 3, 0, 2))\nreturn -VAR10;\nif (FUN5(&VAR1->VAR2.VAR12,\n&VAR13)) {\nFUN6(VAR1, \"STR\");\n}\nVAR3 = FUN7(sizeof(struct VAR14), VAR15);\nif (VAR3 == NULL) {\nFUN8(VAR1, \"STR\");\nreturn -VAR16;\n}\nVAR3->VAR17 = VAR18;\nVAR3->VAR19 = VAR18;\nVAR5 = FUN7(VAR4, VAR15);\nif (VAR5 == NULL) {\nFUN8(VAR1, \"STR\");\nVAR8 = -VAR16;\ngoto VAR20;\n}\nFUN9(VAR5, VAR4, \"STR\", FUN3(VAR2));\nVAR6 = FUN7(VAR4, VAR15);\nif (VAR6 == NULL) {\nFUN8(VAR1, \"STR\");\nVAR8 = -VAR16;\ngoto VAR21;\n}\nFUN9(VAR6, VAR4, \"STR\", FUN3(VAR2));\nFUN10(VAR1, VAR3);\nVAR3->VAR22.VAR23 = VAR5;\nVAR3->VAR22.VAR24 = VAR25;\nVAR3->VAR22.VAR26 = VAR27;\nVAR3->VAR22.VAR2 = VAR2;\nFUN11(VAR2, &VAR3->VAR22);\nVAR3->VAR28.VAR23 = VAR6;\nVAR3->VAR28.VAR24 = VAR25;\nVAR3->VAR28.VAR26 = VAR27;\nVAR3->VAR28.VAR2 = VAR2;\nFUN11(VAR2, &VAR3->VAR28);\nFUN12(VAR1);\nreturn 0;\nVAR21:\nFUN13(VAR5);\nVAR20:\nFUN13(VAR3);\nreturn VAR8;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct hid_device *VAR1)\n{\nstruct device *VAR2 = &VAR1->VAR2;\nstruct tpkbd_data_pointer *VAR3;\nsize_t VAR4 = FUN2(FUN3(VAR2)) + 16;\nchar *VAR5, *VAR6;\nint VAR7;\nif (FUN4(&VAR1->VAR2.VAR8,\n&VAR9)) {\nFUN5(VAR1, \"STR\");\n}\nVAR3 = FUN6(sizeof(struct VAR10), VAR11);\nif (VAR3 == NULL) {\nFUN7(VAR1, \"STR\");\nreturn -VAR12;\n}\nVAR3->VAR13 = VAR14;\nVAR3->VAR15 = VAR14;\nVAR5 = FUN6(VAR4, VAR11);\nif (VAR5 == NULL) {\nFUN7(VAR1, \"STR\");\nVAR7 = -VAR12;\ngoto VAR16;\n}\nFUN8(VAR5, VAR4, \"STR\", FUN3(VAR2));\nVAR6 = FUN6(VAR4, VAR11);\nif (VAR6 == NULL) {\nFUN7(VAR1, \"STR\");\nVAR7 = -VAR12;\ngoto VAR17;\n}\nFUN8(VAR6, VAR4, \"STR\", FUN3(VAR2));\nFUN9(VAR1, VAR3);\nVAR3->VAR18.VAR19 = VAR5;\nVAR3->VAR18.VAR20 = VAR21;\nVAR3->VAR18.VAR22 = VAR23;\nVAR3->VAR18.VAR2 = VAR2;\nFUN10(VAR2, &VAR3->VAR18);\nVAR3->VAR24.VAR19 = VAR6;\nVAR3->VAR24.VAR20 = VAR21;\nVAR3->VAR24.VAR22 = VAR23;\nVAR3->VAR24.VAR2 = VAR2;\nFUN10(VAR2, &VAR3->VAR24);\nFUN11(VAR1);\nreturn 0;\nVAR17:\nFUN12(VAR5);\nVAR16:\nFUN12(VAR3);\nreturn VAR7;\n}\n",
      "code_after_change_raw": "static int tpkbd_probe_tp(struct hid_device *hdev)\n{\nstruct device *dev = &hdev->dev;\nstruct tpkbd_data_pointer *data_pointer;\nsize_t name_sz = strlen(dev_name(dev)) + 16;\nchar *name_mute, *name_micmute;\nint i, ret;\nfor (i = 0; i < 4; i++) {\nif (!hid_validate_values(hdev, HID_FEATURE_REPORT, 4, i, 1))\nreturn -ENODEV;\n}\nif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 3, 0, 2))\nreturn -ENODEV;\nif (sysfs_create_group(&hdev->dev.kobj,\n&tpkbd_attr_group_pointer)) {\nhid_warn(hdev, \"Could not create sysfs group\\n\");\n}\ndata_pointer = kzalloc(sizeof(struct tpkbd_data_pointer), GFP_KERNEL);\nif (data_pointer == NULL) {\nhid_err(hdev, \"Could not allocate memory for driver data\\n\");\nreturn -ENOMEM;\n}\ndata_pointer->sensitivity = 0xa0;\ndata_pointer->press_speed = 0x38;\nname_mute = kzalloc(name_sz, GFP_KERNEL);\nif (name_mute == NULL) {\nhid_err(hdev, \"Could not allocate memory for led data\\n\");\nret = -ENOMEM;\ngoto err;\n}\nsnprintf(name_mute, name_sz, \"%s:amber:mute\", dev_name(dev));\nname_micmute = kzalloc(name_sz, GFP_KERNEL);\nif (name_micmute == NULL) {\nhid_err(hdev, \"Could not allocate memory for led data\\n\");\nret = -ENOMEM;\ngoto err2;\n}\nsnprintf(name_micmute, name_sz, \"%s:amber:micmute\", dev_name(dev));\nhid_set_drvdata(hdev, data_pointer);\ndata_pointer->led_mute.name = name_mute;\ndata_pointer->led_mute.brightness_get = tpkbd_led_brightness_get;\ndata_pointer->led_mute.brightness_set = tpkbd_led_brightness_set;\ndata_pointer->led_mute.dev = dev;\nled_classdev_register(dev, &data_pointer->led_mute);\ndata_pointer->led_micmute.name = name_micmute;\ndata_pointer->led_micmute.brightness_get = tpkbd_led_brightness_get;\ndata_pointer->led_micmute.brightness_set = tpkbd_led_brightness_set;\ndata_pointer->led_micmute.dev = dev;\nled_classdev_register(dev, &data_pointer->led_micmute);\ntpkbd_features_set(hdev);\nreturn 0;\nerr2:\nkfree(name_mute);\nerr:\nkfree(data_pointer);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int tpkbd_probe_tp(struct hid_device *hdev)\n{\nstruct device *dev = &hdev->dev;\nstruct tpkbd_data_pointer *data_pointer;\nsize_t name_sz = strlen(dev_name(dev)) + 16;\nchar *name_mute, *name_micmute;\nint ret;\nif (sysfs_create_group(&hdev->dev.kobj,\n&tpkbd_attr_group_pointer)) {\nhid_warn(hdev, \"Could not create sysfs group\\n\");\n}\ndata_pointer = kzalloc(sizeof(struct tpkbd_data_pointer), GFP_KERNEL);\nif (data_pointer == NULL) {\nhid_err(hdev, \"Could not allocate memory for driver data\\n\");\nreturn -ENOMEM;\n}\ndata_pointer->sensitivity = 0xa0;\ndata_pointer->press_speed = 0x38;\nname_mute = kzalloc(name_sz, GFP_KERNEL);\nif (name_mute == NULL) {\nhid_err(hdev, \"Could not allocate memory for led data\\n\");\nret = -ENOMEM;\ngoto err;\n}\nsnprintf(name_mute, name_sz, \"%s:amber:mute\", dev_name(dev));\nname_micmute = kzalloc(name_sz, GFP_KERNEL);\nif (name_micmute == NULL) {\nhid_err(hdev, \"Could not allocate memory for led data\\n\");\nret = -ENOMEM;\ngoto err2;\n}\nsnprintf(name_micmute, name_sz, \"%s:amber:micmute\", dev_name(dev));\nhid_set_drvdata(hdev, data_pointer);\ndata_pointer->led_mute.name = name_mute;\ndata_pointer->led_mute.brightness_get = tpkbd_led_brightness_get;\ndata_pointer->led_mute.brightness_set = tpkbd_led_brightness_set;\ndata_pointer->led_mute.dev = dev;\nled_classdev_register(dev, &data_pointer->led_mute);\ndata_pointer->led_micmute.name = name_micmute;\ndata_pointer->led_micmute.brightness_get = tpkbd_led_brightness_get;\ndata_pointer->led_micmute.brightness_set = tpkbd_led_brightness_set;\ndata_pointer->led_micmute.dev = dev;\nled_classdev_register(dev, &data_pointer->led_micmute);\ntpkbd_features_set(hdev);\nreturn 0;\nerr2:\nkfree(name_mute);\nerr:\nkfree(data_pointer);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2013-2895": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for HID output report values after parsing the HID descriptors.",
        "trigger_condition": "A crafted device with malicious values in the HID output report is connected, leading to potential NULL pointer dereference and OOPS.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the HID output report values after parsing the descriptors, allowing potentially malicious values to be processed without verification. This can result in a vulnerability where sensitive kernel memory can be accessed or a denial of service can be triggered."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a validation step for the HID output report values after parsing the descriptors. This validation ensures that the values are within the expected range and format, reducing the risk of exploitation by malicious devices. In this case, the solution involves adding a call to hid_validate_values after the hid_parse function to verify the integrity of the HID output report values.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-2895 in the code snippet. The vulnerability allows physically proximate attackers to cause a denial of service (NULL pointer dereference and OOPS) or obtain sensitive information from kernel memory via a crafted device. \n\nThe modification includes adding a call to `hid_validate_values` after the `hid_parse` function to validate the values received. This validation step helps prevent potential issues related to the HID output report, ensuring that the values are within the expected range and format. By performing this validation, the code can mitigate the risk of the vulnerability being exploited by malicious devices.\n\nIn summary, the addition of `hid_validate_values` helps to enhance the security of the code by validating the HID output report values, thereby reducing the risk of potential security vulnerabilities being exploited.",
      "GPT_purpose": "The logi_dj_probe function is responsible for initializing and setting up a Logitech Unifying Receiver device in the Linux kernel HID subsystem.",
      "GPT_function": "\n1. Probe the Logitech Unifying Receiver device.\n2. Allocate memory for the receiver device structure.\n3. Parse HID descriptors and create HID nodes for interface 2.\n4. Start the USB device and connect to upper interfaces.\n5. Switch to DJ mode for the receiver.\n6. Enable polling on the IN endpoint.\n7. Start HID device I/O.\n8. Query paired devices for the Logitech Unifying Receiver.",
      "CVE_id": "CVE-2013-2895",
      "code_before_change": "static int logi_dj_probe(struct hid_device *hdev,\n\t\t\t const struct hid_device_id *id)\n{\n\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n\tstruct dj_receiver_dev *djrcv_dev;\n\tint retval;\n\n\tif (is_dj_device((struct dj_device *)hdev->driver_data))\n\t\treturn -ENODEV;\n\n\tdbg_hid(\"%s called for ifnum %d\\n\", __func__,\n\t\tintf->cur_altsetting->desc.bInterfaceNumber);\n\n\t/* Ignore interfaces 0 and 1, they will not carry any data, dont create\n\t * any hid_device for them */\n\tif (intf->cur_altsetting->desc.bInterfaceNumber !=\n\t    LOGITECH_DJ_INTERFACE_NUMBER) {\n\t\tdbg_hid(\"%s: ignoring ifnum %d\\n\", __func__,\n\t\t\tintf->cur_altsetting->desc.bInterfaceNumber);\n\t\treturn -ENODEV;\n\t}\n\n\t/* Treat interface 2 */\n\n\tdjrcv_dev = kzalloc(sizeof(struct dj_receiver_dev), GFP_KERNEL);\n\tif (!djrcv_dev) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:failed allocating dj_receiver_dev\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\tdjrcv_dev->hdev = hdev;\n\tINIT_WORK(&djrcv_dev->work, delayedwork_callback);\n\tspin_lock_init(&djrcv_dev->lock);\n\tif (kfifo_alloc(&djrcv_dev->notif_fifo,\n\t\t\tDJ_MAX_NUMBER_NOTIFICATIONS * sizeof(struct dj_report),\n\t\t\tGFP_KERNEL)) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:failed allocating notif_fifo\\n\", __func__);\n\t\tkfree(djrcv_dev);\n\t\treturn -ENOMEM;\n\t}\n\thid_set_drvdata(hdev, djrcv_dev);\n\n\t/* Call  to usbhid to fetch the HID descriptors of interface 2 and\n\t * subsequently call to the hid/hid-core to parse the fetched\n\t * descriptors, this will in turn create the hidraw and hiddev nodes\n\t * for interface 2 of the receiver */\n\tretval = hid_parse(hdev);\n\tif (retval) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:parse of interface 2 failed\\n\", __func__);\n\t\tgoto hid_parse_fail;\n\t}\n\n\t/* Starts the usb device and connects to upper interfaces hiddev and\n\t * hidraw */\n\tretval = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (retval) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:hid_hw_start returned error\\n\", __func__);\n\t\tgoto hid_hw_start_fail;\n\t}\n\n\tretval = logi_dj_recv_switch_to_dj_mode(djrcv_dev, 0);\n\tif (retval < 0) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:logi_dj_recv_switch_to_dj_mode returned error:%d\\n\",\n\t\t\t__func__, retval);\n\t\tgoto switch_to_dj_mode_fail;\n\t}\n\n\t/* This is enabling the polling urb on the IN endpoint */\n\tretval = hid_hw_open(hdev);\n\tif (retval < 0) {\n\t\tdev_err(&hdev->dev, \"%s:hid_hw_open returned error:%d\\n\",\n\t\t\t__func__, retval);\n\t\tgoto llopen_failed;\n\t}\n\n\t/* Allow incoming packets to arrive: */\n\thid_device_io_start(hdev);\n\n\tretval = logi_dj_recv_query_paired_devices(djrcv_dev);\n\tif (retval < 0) {\n\t\tdev_err(&hdev->dev, \"%s:logi_dj_recv_query_paired_devices \"\n\t\t\t\"error:%d\\n\", __func__, retval);\n\t\tgoto logi_dj_recv_query_paired_devices_failed;\n\t}\n\n\treturn retval;\n\nlogi_dj_recv_query_paired_devices_failed:\n\thid_hw_close(hdev);\n\nllopen_failed:\nswitch_to_dj_mode_fail:\n\thid_hw_stop(hdev);\n\nhid_hw_start_fail:\nhid_parse_fail:\n\tkfifo_free(&djrcv_dev->notif_fifo);\n\tkfree(djrcv_dev);\n\thid_set_drvdata(hdev, NULL);\n\treturn retval;\n\n}",
      "code_after_change": "static int logi_dj_probe(struct hid_device *hdev,\n\t\t\t const struct hid_device_id *id)\n{\n\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n\tstruct dj_receiver_dev *djrcv_dev;\n\tint retval;\n\n\tif (is_dj_device((struct dj_device *)hdev->driver_data))\n\t\treturn -ENODEV;\n\n\tdbg_hid(\"%s called for ifnum %d\\n\", __func__,\n\t\tintf->cur_altsetting->desc.bInterfaceNumber);\n\n\t/* Ignore interfaces 0 and 1, they will not carry any data, dont create\n\t * any hid_device for them */\n\tif (intf->cur_altsetting->desc.bInterfaceNumber !=\n\t    LOGITECH_DJ_INTERFACE_NUMBER) {\n\t\tdbg_hid(\"%s: ignoring ifnum %d\\n\", __func__,\n\t\t\tintf->cur_altsetting->desc.bInterfaceNumber);\n\t\treturn -ENODEV;\n\t}\n\n\t/* Treat interface 2 */\n\n\tdjrcv_dev = kzalloc(sizeof(struct dj_receiver_dev), GFP_KERNEL);\n\tif (!djrcv_dev) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:failed allocating dj_receiver_dev\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\tdjrcv_dev->hdev = hdev;\n\tINIT_WORK(&djrcv_dev->work, delayedwork_callback);\n\tspin_lock_init(&djrcv_dev->lock);\n\tif (kfifo_alloc(&djrcv_dev->notif_fifo,\n\t\t\tDJ_MAX_NUMBER_NOTIFICATIONS * sizeof(struct dj_report),\n\t\t\tGFP_KERNEL)) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:failed allocating notif_fifo\\n\", __func__);\n\t\tkfree(djrcv_dev);\n\t\treturn -ENOMEM;\n\t}\n\thid_set_drvdata(hdev, djrcv_dev);\n\n\t/* Call  to usbhid to fetch the HID descriptors of interface 2 and\n\t * subsequently call to the hid/hid-core to parse the fetched\n\t * descriptors, this will in turn create the hidraw and hiddev nodes\n\t * for interface 2 of the receiver */\n\tretval = hid_parse(hdev);\n\tif (retval) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:parse of interface 2 failed\\n\", __func__);\n\t\tgoto hid_parse_fail;\n\t}\n\n\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, REPORT_ID_DJ_SHORT,\n\t\t\t\t 0, DJREPORT_SHORT_LENGTH - 1)) {\n\t\tretval = -ENODEV;\n\t\tgoto hid_parse_fail;\n\t}\n\n\t/* Starts the usb device and connects to upper interfaces hiddev and\n\t * hidraw */\n\tretval = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (retval) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:hid_hw_start returned error\\n\", __func__);\n\t\tgoto hid_hw_start_fail;\n\t}\n\n\tretval = logi_dj_recv_switch_to_dj_mode(djrcv_dev, 0);\n\tif (retval < 0) {\n\t\tdev_err(&hdev->dev,\n\t\t\t\"%s:logi_dj_recv_switch_to_dj_mode returned error:%d\\n\",\n\t\t\t__func__, retval);\n\t\tgoto switch_to_dj_mode_fail;\n\t}\n\n\t/* This is enabling the polling urb on the IN endpoint */\n\tretval = hid_hw_open(hdev);\n\tif (retval < 0) {\n\t\tdev_err(&hdev->dev, \"%s:hid_hw_open returned error:%d\\n\",\n\t\t\t__func__, retval);\n\t\tgoto llopen_failed;\n\t}\n\n\t/* Allow incoming packets to arrive: */\n\thid_device_io_start(hdev);\n\n\tretval = logi_dj_recv_query_paired_devices(djrcv_dev);\n\tif (retval < 0) {\n\t\tdev_err(&hdev->dev, \"%s:logi_dj_recv_query_paired_devices \"\n\t\t\t\"error:%d\\n\", __func__, retval);\n\t\tgoto logi_dj_recv_query_paired_devices_failed;\n\t}\n\n\treturn retval;\n\nlogi_dj_recv_query_paired_devices_failed:\n\thid_hw_close(hdev);\n\nllopen_failed:\nswitch_to_dj_mode_fail:\n\thid_hw_stop(hdev);\n\nhid_hw_start_fail:\nhid_parse_fail:\n\tkfifo_free(&djrcv_dev->notif_fifo);\n\tkfree(djrcv_dev);\n\thid_set_drvdata(hdev, NULL);\n\treturn retval;\n\n}",
      "modified_lines": {
        "added": [
          "\t\tgoto hid_parse_fail;",
          "\t}",
          "",
          "\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, REPORT_ID_DJ_SHORT,",
          "\t\t\t\t 0, DJREPORT_SHORT_LENGTH - 1)) {",
          "\t\tretval = -ENODEV;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation for HID output report values after parsing the HID descriptors.",
      "trigger_condition": "A crafted device with malicious values in the HID output report is connected, leading to potential NULL pointer dereference and OOPS.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the HID output report values after parsing the descriptors, allowing potentially malicious values to be processed without verification. This can result in a vulnerability where sensitive kernel memory can be accessed or a denial of service can be triggered.",
      "id": 37,
      "code_after_change_normalized": "static int FUN1(struct hid_device *VAR1,\nconst struct hid_device_id *VAR2)\n{\nstruct usb_interface *VAR3 = FUN2(VAR1->VAR4.VAR5);\nstruct dj_receiver_dev *VAR6;\nint VAR7;\nif (FUN3((struct VAR8 *)VAR1->VAR9))\nreturn -VAR10;\nFUN4(\"STR\", VAR11,\nVAR3->VAR12->VAR13.VAR14);\nif (VAR3->VAR12->VAR13.VAR14 !=\nVAR15) {\nFUN4(\"STR\", VAR11,\nVAR3->VAR12->VAR13.VAR14);\nreturn -VAR10;\n}\nVAR6 = FUN5(sizeof(struct VAR16), VAR17);\nif (!VAR6) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\nreturn -VAR18;\n}\nVAR6->VAR1 = VAR1;\nFUN7(&VAR6->VAR19, VAR20);\nFUN8(&VAR6->VAR21);\nif (FUN9(&VAR6->VAR22,\nVAR23 * sizeof(struct VAR24),\nVAR17)) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\nFUN10(VAR6);\nreturn -VAR18;\n}\nFUN11(VAR1, VAR6);\nVAR7 = FUN12(VAR1);\nif (VAR7) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\ngoto VAR25;\n}\nif (!FUN13(VAR1, VAR26, VAR27,\n0, VAR28 - 1)) {\nVAR7 = -VAR10;\ngoto VAR25;\n}\nVAR7 = FUN14(VAR1, VAR29);\nif (VAR7) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\ngoto VAR30;\n}\nVAR7 = FUN15(VAR6, 0);\nif (VAR7 < 0) {\nFUN6(&VAR1->VAR4,\n\"STR\",\nVAR11, VAR7);\ngoto VAR31;\n}\nVAR7 = FUN16(VAR1);\nif (VAR7 < 0) {\nFUN6(&VAR1->VAR4, \"STR\",\nVAR11, VAR7);\ngoto VAR32;\n}\nFUN17(VAR1);\nVAR7 = FUN18(VAR6);\nif (VAR7 < 0) {\nFUN6(&VAR1->VAR4, \"STR\"\n\"STR\", VAR11, VAR7);\ngoto VAR33;\n}\nreturn VAR7;\nVAR33:\nFUN19(VAR1);\nVAR32:\nVAR31:\nFUN20(VAR1);\nVAR30:\nVAR25:\nFUN21(&VAR6->VAR22);\nFUN10(VAR6);\nFUN11(VAR1, NULL);\nreturn VAR7;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct hid_device *VAR1,\nconst struct hid_device_id *VAR2)\n{\nstruct usb_interface *VAR3 = FUN2(VAR1->VAR4.VAR5);\nstruct dj_receiver_dev *VAR6;\nint VAR7;\nif (FUN3((struct VAR8 *)VAR1->VAR9))\nreturn -VAR10;\nFUN4(\"STR\", VAR11,\nVAR3->VAR12->VAR13.VAR14);\nif (VAR3->VAR12->VAR13.VAR14 !=\nVAR15) {\nFUN4(\"STR\", VAR11,\nVAR3->VAR12->VAR13.VAR14);\nreturn -VAR10;\n}\nVAR6 = FUN5(sizeof(struct VAR16), VAR17);\nif (!VAR6) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\nreturn -VAR18;\n}\nVAR6->VAR1 = VAR1;\nFUN7(&VAR6->VAR19, VAR20);\nFUN8(&VAR6->VAR21);\nif (FUN9(&VAR6->VAR22,\nVAR23 * sizeof(struct VAR24),\nVAR17)) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\nFUN10(VAR6);\nreturn -VAR18;\n}\nFUN11(VAR1, VAR6);\nVAR7 = FUN12(VAR1);\nif (VAR7) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\ngoto VAR25;\n}\nVAR7 = FUN13(VAR1, VAR26);\nif (VAR7) {\nFUN6(&VAR1->VAR4,\n\"STR\", VAR11);\ngoto VAR27;\n}\nVAR7 = FUN14(VAR6, 0);\nif (VAR7 < 0) {\nFUN6(&VAR1->VAR4,\n\"STR\",\nVAR11, VAR7);\ngoto VAR28;\n}\nVAR7 = FUN15(VAR1);\nif (VAR7 < 0) {\nFUN6(&VAR1->VAR4, \"STR\",\nVAR11, VAR7);\ngoto VAR29;\n}\nFUN16(VAR1);\nVAR7 = FUN17(VAR6);\nif (VAR7 < 0) {\nFUN6(&VAR1->VAR4, \"STR\"\n\"STR\", VAR11, VAR7);\ngoto VAR30;\n}\nreturn VAR7;\nVAR30:\nFUN18(VAR1);\nVAR29:\nVAR28:\nFUN19(VAR1);\nVAR27:\nVAR25:\nFUN20(&VAR6->VAR22);\nFUN10(VAR6);\nFUN11(VAR1, NULL);\nreturn VAR7;\n}\n",
      "code_after_change_raw": "static int logi_dj_probe(struct hid_device *hdev,\nconst struct hid_device_id *id)\n{\nstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\nstruct dj_receiver_dev *djrcv_dev;\nint retval;\nif (is_dj_device((struct dj_device *)hdev->driver_data))\nreturn -ENODEV;\ndbg_hid(\"%s called for ifnum %d\\n\", __func__,\nintf->cur_altsetting->desc.bInterfaceNumber);\nif (intf->cur_altsetting->desc.bInterfaceNumber !=\nLOGITECH_DJ_INTERFACE_NUMBER) {\ndbg_hid(\"%s: ignoring ifnum %d\\n\", __func__,\nintf->cur_altsetting->desc.bInterfaceNumber);\nreturn -ENODEV;\n}\ndjrcv_dev = kzalloc(sizeof(struct dj_receiver_dev), GFP_KERNEL);\nif (!djrcv_dev) {\ndev_err(&hdev->dev,\n\"%s:failed allocating dj_receiver_dev\\n\", __func__);\nreturn -ENOMEM;\n}\ndjrcv_dev->hdev = hdev;\nINIT_WORK(&djrcv_dev->work, delayedwork_callback);\nspin_lock_init(&djrcv_dev->lock);\nif (kfifo_alloc(&djrcv_dev->notif_fifo,\nDJ_MAX_NUMBER_NOTIFICATIONS * sizeof(struct dj_report),\nGFP_KERNEL)) {\ndev_err(&hdev->dev,\n\"%s:failed allocating notif_fifo\\n\", __func__);\nkfree(djrcv_dev);\nreturn -ENOMEM;\n}\nhid_set_drvdata(hdev, djrcv_dev);\nretval = hid_parse(hdev);\nif (retval) {\ndev_err(&hdev->dev,\n\"%s:parse of interface 2 failed\\n\", __func__);\ngoto hid_parse_fail;\n}\nif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, REPORT_ID_DJ_SHORT,\n0, DJREPORT_SHORT_LENGTH - 1)) {\nretval = -ENODEV;\ngoto hid_parse_fail;\n}\nretval = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\nif (retval) {\ndev_err(&hdev->dev,\n\"%s:hid_hw_start returned error\\n\", __func__);\ngoto hid_hw_start_fail;\n}\nretval = logi_dj_recv_switch_to_dj_mode(djrcv_dev, 0);\nif (retval < 0) {\ndev_err(&hdev->dev,\n\"%s:logi_dj_recv_switch_to_dj_mode returned error:%d\\n\",\n__func__, retval);\ngoto switch_to_dj_mode_fail;\n}\nretval = hid_hw_open(hdev);\nif (retval < 0) {\ndev_err(&hdev->dev, \"%s:hid_hw_open returned error:%d\\n\",\n__func__, retval);\ngoto llopen_failed;\n}\nhid_device_io_start(hdev);\nretval = logi_dj_recv_query_paired_devices(djrcv_dev);\nif (retval < 0) {\ndev_err(&hdev->dev, \"%s:logi_dj_recv_query_paired_devices \"\n\"error:%d\\n\", __func__, retval);\ngoto logi_dj_recv_query_paired_devices_failed;\n}\nreturn retval;\nlogi_dj_recv_query_paired_devices_failed:\nhid_hw_close(hdev);\nllopen_failed:\nswitch_to_dj_mode_fail:\nhid_hw_stop(hdev);\nhid_hw_start_fail:\nhid_parse_fail:\nkfifo_free(&djrcv_dev->notif_fifo);\nkfree(djrcv_dev);\nhid_set_drvdata(hdev, NULL);\nreturn retval;\n}\n",
      "code_before_change_raw": "static int logi_dj_probe(struct hid_device *hdev,\nconst struct hid_device_id *id)\n{\nstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\nstruct dj_receiver_dev *djrcv_dev;\nint retval;\nif (is_dj_device((struct dj_device *)hdev->driver_data))\nreturn -ENODEV;\ndbg_hid(\"%s called for ifnum %d\\n\", __func__,\nintf->cur_altsetting->desc.bInterfaceNumber);\nif (intf->cur_altsetting->desc.bInterfaceNumber !=\nLOGITECH_DJ_INTERFACE_NUMBER) {\ndbg_hid(\"%s: ignoring ifnum %d\\n\", __func__,\nintf->cur_altsetting->desc.bInterfaceNumber);\nreturn -ENODEV;\n}\ndjrcv_dev = kzalloc(sizeof(struct dj_receiver_dev), GFP_KERNEL);\nif (!djrcv_dev) {\ndev_err(&hdev->dev,\n\"%s:failed allocating dj_receiver_dev\\n\", __func__);\nreturn -ENOMEM;\n}\ndjrcv_dev->hdev = hdev;\nINIT_WORK(&djrcv_dev->work, delayedwork_callback);\nspin_lock_init(&djrcv_dev->lock);\nif (kfifo_alloc(&djrcv_dev->notif_fifo,\nDJ_MAX_NUMBER_NOTIFICATIONS * sizeof(struct dj_report),\nGFP_KERNEL)) {\ndev_err(&hdev->dev,\n\"%s:failed allocating notif_fifo\\n\", __func__);\nkfree(djrcv_dev);\nreturn -ENOMEM;\n}\nhid_set_drvdata(hdev, djrcv_dev);\nretval = hid_parse(hdev);\nif (retval) {\ndev_err(&hdev->dev,\n\"%s:parse of interface 2 failed\\n\", __func__);\ngoto hid_parse_fail;\n}\nretval = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\nif (retval) {\ndev_err(&hdev->dev,\n\"%s:hid_hw_start returned error\\n\", __func__);\ngoto hid_hw_start_fail;\n}\nretval = logi_dj_recv_switch_to_dj_mode(djrcv_dev, 0);\nif (retval < 0) {\ndev_err(&hdev->dev,\n\"%s:logi_dj_recv_switch_to_dj_mode returned error:%d\\n\",\n__func__, retval);\ngoto switch_to_dj_mode_fail;\n}\nretval = hid_hw_open(hdev);\nif (retval < 0) {\ndev_err(&hdev->dev, \"%s:hid_hw_open returned error:%d\\n\",\n__func__, retval);\ngoto llopen_failed;\n}\nhid_device_io_start(hdev);\nretval = logi_dj_recv_query_paired_devices(djrcv_dev);\nif (retval < 0) {\ndev_err(&hdev->dev, \"%s:logi_dj_recv_query_paired_devices \"\n\"error:%d\\n\", __func__, retval);\ngoto logi_dj_recv_query_paired_devices_failed;\n}\nreturn retval;\nlogi_dj_recv_query_paired_devices_failed:\nhid_hw_close(hdev);\nllopen_failed:\nswitch_to_dj_mode_fail:\nhid_hw_stop(hdev);\nhid_hw_start_fail:\nhid_parse_fail:\nkfifo_free(&djrcv_dev->notif_fifo);\nkfree(djrcv_dev);\nhid_set_drvdata(hdev, NULL);\nreturn retval;\n}\n"
    }
  ],
  "CVE-2013-2899": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for the 'report' pointer, leading to a NULL pointer dereference vulnerability.",
        "trigger_condition": "When the 'report' pointer is NULL and the code attempts to access 'report->maxfield'.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the 'report' pointer is valid before accessing 'report->maxfield', which can result in a NULL pointer dereference and OOPS vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to validate the 'report' pointer before accessing 'report->maxfield'. By adding a condition to check if 'report' is not NULL and ensuring 'report->maxfield' is valid, the code can prevent the vulnerability from being exploited. In this case, the solution involves adding a condition 'if (!report || report->maxfield != 1)' to ensure the 'report' pointer is valid before proceeding.",
      "GPT_analysis": "The modification is necessary to prevent a NULL pointer dereference and OOPS (kernel panic) vulnerability in the code. The vulnerability occurs when the `report` pointer is NULL, and the code attempts to access `report->maxfield` without checking if `report` is valid. By adding the condition `if (!report || report->maxfield != 1)`, the code ensures that `report` is not NULL and that it has a valid `maxfield` value before proceeding. This helps to prevent the vulnerability from being exploited by attackers, thereby enhancing the security and stability of the system.",
      "GPT_purpose": "This function handles the setting of operation modes for a picolcd device, adjusting timeout values and sending HID reports accordingly.",
      "GPT_function": "\n1. Handles the store operation for the picolcd operation mode.\n2. Checks the input buffer for specific commands (\"lcd\" or \"bootloader\").\n3. Sets the timeout value for the operation mode.\n4. Performs HID request to set the report.",
      "CVE_id": "CVE-2013-2899",
      "code_before_change": "static ssize_t picolcd_operation_mode_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct picolcd_data *data = dev_get_drvdata(dev);\n\tstruct hid_report *report = NULL;\n\tsize_t cnt = count;\n\tint timeout = data->opmode_delay;\n\tunsigned long flags;\n\n\tif (cnt >= 3 && strncmp(\"lcd\", buf, 3) == 0) {\n\t\tif (data->status & PICOLCD_BOOTLOADER)\n\t\t\treport = picolcd_out_report(REPORT_EXIT_FLASHER, data->hdev);\n\t\tbuf += 3;\n\t\tcnt -= 3;\n\t} else if (cnt >= 10 && strncmp(\"bootloader\", buf, 10) == 0) {\n\t\tif (!(data->status & PICOLCD_BOOTLOADER))\n\t\t\treport = picolcd_out_report(REPORT_EXIT_KEYBOARD, data->hdev);\n\t\tbuf += 10;\n\t\tcnt -= 10;\n\t}\n\tif (!report)\n\t\treturn -EINVAL;\n\n\twhile (cnt > 0 && (buf[cnt-1] == '\\n' || buf[cnt-1] == '\\r'))\n\t\tcnt--;\n\tif (cnt != 0)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&data->lock, flags);\n\thid_set_field(report->field[0], 0, timeout & 0xff);\n\thid_set_field(report->field[0], 1, (timeout >> 8) & 0xff);\n\thid_hw_request(data->hdev, report, HID_REQ_SET_REPORT);\n\tspin_unlock_irqrestore(&data->lock, flags);\n\treturn count;\n}",
      "code_after_change": "static ssize_t picolcd_operation_mode_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct picolcd_data *data = dev_get_drvdata(dev);\n\tstruct hid_report *report = NULL;\n\tsize_t cnt = count;\n\tint timeout = data->opmode_delay;\n\tunsigned long flags;\n\n\tif (cnt >= 3 && strncmp(\"lcd\", buf, 3) == 0) {\n\t\tif (data->status & PICOLCD_BOOTLOADER)\n\t\t\treport = picolcd_out_report(REPORT_EXIT_FLASHER, data->hdev);\n\t\tbuf += 3;\n\t\tcnt -= 3;\n\t} else if (cnt >= 10 && strncmp(\"bootloader\", buf, 10) == 0) {\n\t\tif (!(data->status & PICOLCD_BOOTLOADER))\n\t\t\treport = picolcd_out_report(REPORT_EXIT_KEYBOARD, data->hdev);\n\t\tbuf += 10;\n\t\tcnt -= 10;\n\t}\n\tif (!report || report->maxfield != 1)\n\t\treturn -EINVAL;\n\n\twhile (cnt > 0 && (buf[cnt-1] == '\\n' || buf[cnt-1] == '\\r'))\n\t\tcnt--;\n\tif (cnt != 0)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&data->lock, flags);\n\thid_set_field(report->field[0], 0, timeout & 0xff);\n\thid_set_field(report->field[0], 1, (timeout >> 8) & 0xff);\n\thid_hw_request(data->hdev, report, HID_REQ_SET_REPORT);\n\tspin_unlock_irqrestore(&data->lock, flags);\n\treturn count;\n}",
      "modified_lines": {
        "added": [
          "\tif (!report || report->maxfield != 1)"
        ],
        "deleted": [
          "\tif (!report)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation for the 'report' pointer, leading to a NULL pointer dereference vulnerability.",
      "trigger_condition": "When the 'report' pointer is NULL and the code attempts to access 'report->maxfield'.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the 'report' pointer is valid before accessing 'report->maxfield', which can result in a NULL pointer dereference and OOPS vulnerability.",
      "id": 38,
      "code_after_change_normalized": "static ssize_t FUN1(struct device *VAR1,\nstruct device_attribute *VAR2, const char *VAR3, size_t VAR4)\n{\nstruct picolcd_data *VAR5 = FUN2(VAR1);\nstruct hid_report *VAR6 = NULL;\nsize_t VAR7 = VAR4;\nint VAR8 = VAR5->VAR9;\nunsigned long VAR10;\nif (VAR7 >= 3 && FUN3(\"STR\", VAR3, 3) == 0) {\nif (VAR5->VAR11 & VAR12)\nVAR6 = FUN4(VAR13, VAR5->VAR14);\nVAR3 += 3;\nVAR7 -= 3;\n} else if (VAR7 >= 10 && FUN3(\"STR\", VAR3, 10) == 0) {\nif (!(VAR5->VAR11 & VAR12))\nVAR6 = FUN4(VAR15, VAR5->VAR14);\nVAR3 += 10;\nVAR7 -= 10;\n}\nif (!VAR6 || VAR6->VAR16 != 1)\nreturn -VAR17;\nwhile (VAR7 > 0 && (VAR3[VAR7-1] ==  || VAR3[VAR7-1] == ))\nVAR7--;\nif (VAR7 != 0)\nreturn -VAR17;\nFUN5(&VAR5->VAR18, VAR10);\nFUN6(VAR6->VAR19[0], 0, VAR8 & VAR20);\nFUN6(VAR6->VAR19[0], 1, (VAR8 >> 8) & VAR20);\nFUN7(VAR5->VAR14, VAR6, VAR21);\nFUN8(&VAR5->VAR18, VAR10);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct device *VAR1,\nstruct device_attribute *VAR2, const char *VAR3, size_t VAR4)\n{\nstruct picolcd_data *VAR5 = FUN2(VAR1);\nstruct hid_report *VAR6 = NULL;\nsize_t VAR7 = VAR4;\nint VAR8 = VAR5->VAR9;\nunsigned long VAR10;\nif (VAR7 >= 3 && FUN3(\"STR\", VAR3, 3) == 0) {\nif (VAR5->VAR11 & VAR12)\nVAR6 = FUN4(VAR13, VAR5->VAR14);\nVAR3 += 3;\nVAR7 -= 3;\n} else if (VAR7 >= 10 && FUN3(\"STR\", VAR3, 10) == 0) {\nif (!(VAR5->VAR11 & VAR12))\nVAR6 = FUN4(VAR15, VAR5->VAR14);\nVAR3 += 10;\nVAR7 -= 10;\n}\nif (!VAR6)\nreturn -VAR16;\nwhile (VAR7 > 0 && (VAR3[VAR7-1] ==  || VAR3[VAR7-1] == ))\nVAR7--;\nif (VAR7 != 0)\nreturn -VAR16;\nFUN5(&VAR5->VAR17, VAR10);\nFUN6(VAR6->VAR18[0], 0, VAR8 & VAR19);\nFUN6(VAR6->VAR18[0], 1, (VAR8 >> 8) & VAR19);\nFUN7(VAR5->VAR14, VAR6, VAR20);\nFUN8(&VAR5->VAR17, VAR10);\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static ssize_t picolcd_operation_mode_store(struct device *dev,\nstruct device_attribute *attr, const char *buf, size_t count)\n{\nstruct picolcd_data *data = dev_get_drvdata(dev);\nstruct hid_report *report = NULL;\nsize_t cnt = count;\nint timeout = data->opmode_delay;\nunsigned long flags;\nif (cnt >= 3 && strncmp(\"lcd\", buf, 3) == 0) {\nif (data->status & PICOLCD_BOOTLOADER)\nreport = picolcd_out_report(REPORT_EXIT_FLASHER, data->hdev);\nbuf += 3;\ncnt -= 3;\n} else if (cnt >= 10 && strncmp(\"bootloader\", buf, 10) == 0) {\nif (!(data->status & PICOLCD_BOOTLOADER))\nreport = picolcd_out_report(REPORT_EXIT_KEYBOARD, data->hdev);\nbuf += 10;\ncnt -= 10;\n}\nif (!report || report->maxfield != 1)\nreturn -EINVAL;\nwhile (cnt > 0 && (buf[cnt-1] == '\\n' || buf[cnt-1] == '\\r'))\ncnt--;\nif (cnt != 0)\nreturn -EINVAL;\nspin_lock_irqsave(&data->lock, flags);\nhid_set_field(report->field[0], 0, timeout & 0xff);\nhid_set_field(report->field[0], 1, (timeout >> 8) & 0xff);\nhid_hw_request(data->hdev, report, HID_REQ_SET_REPORT);\nspin_unlock_irqrestore(&data->lock, flags);\nreturn count;\n}\n",
      "code_before_change_raw": "static ssize_t picolcd_operation_mode_store(struct device *dev,\nstruct device_attribute *attr, const char *buf, size_t count)\n{\nstruct picolcd_data *data = dev_get_drvdata(dev);\nstruct hid_report *report = NULL;\nsize_t cnt = count;\nint timeout = data->opmode_delay;\nunsigned long flags;\nif (cnt >= 3 && strncmp(\"lcd\", buf, 3) == 0) {\nif (data->status & PICOLCD_BOOTLOADER)\nreport = picolcd_out_report(REPORT_EXIT_FLASHER, data->hdev);\nbuf += 3;\ncnt -= 3;\n} else if (cnt >= 10 && strncmp(\"bootloader\", buf, 10) == 0) {\nif (!(data->status & PICOLCD_BOOTLOADER))\nreport = picolcd_out_report(REPORT_EXIT_KEYBOARD, data->hdev);\nbuf += 10;\ncnt -= 10;\n}\nif (!report)\nreturn -EINVAL;\nwhile (cnt > 0 && (buf[cnt-1] == '\\n' || buf[cnt-1] == '\\r'))\ncnt--;\nif (cnt != 0)\nreturn -EINVAL;\nspin_lock_irqsave(&data->lock, flags);\nhid_set_field(report->field[0], 0, timeout & 0xff);\nhid_set_field(report->field[0], 1, (timeout >> 8) & 0xff);\nhid_hw_request(data->hdev, report, HID_REQ_SET_REPORT);\nspin_unlock_irqrestore(&data->lock, flags);\nreturn count;\n}\n"
    }
  ],
  "CVE-2013-4312": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for file descriptor reference counts associated with UNIX sockets.",
        "trigger_condition": "Local users sending each file descriptor over a UNIX socket before closing it, bypassing file-descriptor limits and causing a denial of service due to memory consumption.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly decrement the reference count of file descriptors when the inflight count reaches zero, leading to a denial of service vulnerability.",
        "solution": "To mitigate the vulnerability, it is necessary to ensure that the reference count of file descriptors associated with UNIX sockets is correctly decremented. This involves adding a line to decrement the reference count of file descriptors when the inflight count reaches zero, ensuring that resources are properly released and preventing the denial of service vulnerability caused by memory consumption."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-4312 by properly updating the reference count of the file descriptors associated with UNIX sockets. \n\nIn the original code snippet, the reference count of the file descriptors is not properly decremented when the inflight count reaches zero. This can lead to a denial of service due to memory consumption if file descriptors are sent over a UNIX socket before closing them.\n\nBy adding the line `fp->f_cred->user->unix_inflight--;` in the modified code, the reference count of the file descriptors is correctly decremented, ensuring that the resources associated with the file descriptors are properly released. This helps prevent the denial of service vulnerability caused by bypassing file-descriptor limits and excessive memory consumption.",
      "GPT_purpose": "Decrease the in-flight count of a UNIX socket and remove it from the list if the count reaches zero, contributing to garbage collection in the UNIX socket subsystem.",
      "GPT_function": "\n1. Retrieves the socket associated with a file.\n2. Decrements the inflight count and removes the socket from a list if the count reaches zero.\n3. Decrements the total inflight count.",
      "CVE_id": "CVE-2013-4312",
      "code_before_change": "void unix_notinflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tspin_lock(&unix_gc_lock);\n\t\tBUG_ON(list_empty(&u->link));\n\n\t\tif (atomic_long_dec_and_test(&u->inflight))\n\t\t\tlist_del_init(&u->link);\n\t\tunix_tot_inflight--;\n\t\tspin_unlock(&unix_gc_lock);\n\t}\n}",
      "code_after_change": "void unix_notinflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tspin_lock(&unix_gc_lock);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tBUG_ON(list_empty(&u->link));\n\n\t\tif (atomic_long_dec_and_test(&u->inflight))\n\t\t\tlist_del_init(&u->link);\n\t\tunix_tot_inflight--;\n\t}\n\tfp->f_cred->user->unix_inflight--;\n\tspin_unlock(&unix_gc_lock);\n}",
      "modified_lines": {
        "added": [
          "\tspin_lock(&unix_gc_lock);",
          "",
          "\tfp->f_cred->user->unix_inflight--;",
          "\tspin_unlock(&unix_gc_lock);"
        ],
        "deleted": [
          "\t\tspin_lock(&unix_gc_lock);",
          "\t\tspin_unlock(&unix_gc_lock);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for file descriptor reference counts associated with UNIX sockets.",
      "trigger_condition": "Local users sending each file descriptor over a UNIX socket before closing it, bypassing file-descriptor limits and causing a denial of service due to memory consumption.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly decrement the reference count of file descriptors when the inflight count reaches zero, leading to a denial of service vulnerability.",
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the reference count of file descriptors associated with UNIX sockets is correctly decremented. This involves adding a line to decrement the reference count of file descriptors when the inflight count reaches zero, ensuring that resources are properly released and preventing the denial of service vulnerability caused by memory consumption.",
      "id": 39,
      "code_after_change_normalized": "void FUN1(struct file *VAR1)\n{\nstruct sock *VAR2 = FUN2(VAR1);\nFUN3(&VAR3);\nif (VAR2) {\nstruct unix_sock *VAR4 = FUN4(VAR2);\nFUN5(FUN6(&VAR4->VAR5));\nif (FUN7(&VAR4->VAR6))\nFUN8(&VAR4->VAR5);\nVAR7--;\n}\nVAR1->VAR8->VAR9->VAR10--;\nFUN9(&VAR3);\n}\n",
      "code_before_change_normalized": "void FUN1(struct file *VAR1)\n{\nstruct sock *VAR2 = FUN2(VAR1);\nif (VAR2) {\nstruct unix_sock *VAR3 = FUN3(VAR2);\nFUN4(&VAR4);\nFUN5(FUN6(&VAR3->VAR5));\nif (FUN7(&VAR3->VAR6))\nFUN8(&VAR3->VAR5);\nVAR7--;\nFUN9(&VAR4);\n}\n}\n",
      "code_after_change_raw": "void unix_notinflight(struct file *fp)\n{\nstruct sock *s = unix_get_socket(fp);\nspin_lock(&unix_gc_lock);\nif (s) {\nstruct unix_sock *u = unix_sk(s);\nBUG_ON(list_empty(&u->link));\nif (atomic_long_dec_and_test(&u->inflight))\nlist_del_init(&u->link);\nunix_tot_inflight--;\n}\nfp->f_cred->user->unix_inflight--;\nspin_unlock(&unix_gc_lock);\n}\n",
      "code_before_change_raw": "void unix_notinflight(struct file *fp)\n{\nstruct sock *s = unix_get_socket(fp);\nif (s) {\nstruct unix_sock *u = unix_sk(s);\nspin_lock(&unix_gc_lock);\nBUG_ON(list_empty(&u->link));\nif (atomic_long_dec_and_test(&u->inflight))\nlist_del_init(&u->link);\nunix_tot_inflight--;\nspin_unlock(&unix_gc_lock);\n}\n}\n"
    }
  ],
  "CVE-2013-4387": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for UDP Fragmentation Offload (UFO) processing of small packets after queueing a large packet.",
        "trigger_condition": "Receiving network traffic that triggers a large response packet without proper UFO processing for subsequent small packets.",
        "specific_code_behavior_causing_vulnerability": "The code does not check for the need for UFO processing of small packets after queueing a large packet, leading to a denial of service (memory corruption and system crash) vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check for the need for UDP Fragmentation Offload (UFO) processing of small packets after queueing a large packet. This check ensures that the code handles UFO processing correctly and prevents the denial of service vulnerability. In this case, the solution involves adding a conditional check for UFO processing of small packets and handling it appropriately to prevent memory corruption and system crash.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-4387 in the code snippet. The vulnerability allows remote attackers to cause a denial of service (memory corruption and system crash) or possibly have other unspecified impacts via network traffic that triggers a large response packet.\n\nThe modification specifically addresses the issue by checking for the need for UDP Fragmentation Offload (UFO) processing of small packets after the UFO queueing of a large packet. By adding the check for UFO processing and handling it appropriately, the code can prevent the vulnerability from being exploited and mitigate the potential impact of the attack.\n\nIn summary, the modification is necessary to fix the vulnerability and ensure the code handles UFO processing correctly, thereby enhancing the security and stability of the system.",
      "GPT_purpose": "Append data to an IPv6 packet for transmission.",
      "GPT_function": "\n1. Append data to an IPv6 packet.\n2. Handle corking for IPv6 packets.\n3. Check for UDP TX timestamp enablement.\n4. Handle fragmentation of IPv6 packets.\n5. Allocate new socket buffers for packet data.\n6. Fill in control structures for packet transmission.\n7. Determine where to start putting bytes in the packet.\n8. Put the packet on the pending queue.\n9. Handle errors and statistics updates.",
      "CVE_id": "CVE-2013-4387",
      "code_before_change": "int ip6_append_data(struct sock *sk, int getfrag(void *from, char *to,\n\tint offset, int len, int odd, struct sk_buff *skb),\n\tvoid *from, int length, int transhdrlen,\n\tint hlimit, int tclass, struct ipv6_txoptions *opt, struct flowi6 *fl6,\n\tstruct rt6_info *rt, unsigned int flags, int dontfrag)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct inet_cork *cork;\n\tstruct sk_buff *skb, *skb_prev = NULL;\n\tunsigned int maxfraglen, fragheaderlen, mtu;\n\tint exthdrlen;\n\tint dst_exthdrlen;\n\tint hh_len;\n\tint copy;\n\tint err;\n\tint offset = 0;\n\t__u8 tx_flags = 0;\n\n\tif (flags&MSG_PROBE)\n\t\treturn 0;\n\tcork = &inet->cork.base;\n\tif (skb_queue_empty(&sk->sk_write_queue)) {\n\t\t/*\n\t\t * setup for corking\n\t\t */\n\t\tif (opt) {\n\t\t\tif (WARN_ON(np->cork.opt))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tnp->cork.opt = kzalloc(opt->tot_len, sk->sk_allocation);\n\t\t\tif (unlikely(np->cork.opt == NULL))\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->tot_len = opt->tot_len;\n\t\t\tnp->cork.opt->opt_flen = opt->opt_flen;\n\t\t\tnp->cork.opt->opt_nflen = opt->opt_nflen;\n\n\t\t\tnp->cork.opt->dst0opt = ip6_opt_dup(opt->dst0opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst0opt && !np->cork.opt->dst0opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->dst1opt = ip6_opt_dup(opt->dst1opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst1opt && !np->cork.opt->dst1opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->hopopt = ip6_opt_dup(opt->hopopt,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (opt->hopopt && !np->cork.opt->hopopt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->srcrt = ip6_rthdr_dup(opt->srcrt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->srcrt && !np->cork.opt->srcrt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\t/* need source address above miyazawa*/\n\t\t}\n\t\tdst_hold(&rt->dst);\n\t\tcork->dst = &rt->dst;\n\t\tinet->cork.fl.u.ip6 = *fl6;\n\t\tnp->cork.hop_limit = hlimit;\n\t\tnp->cork.tclass = tclass;\n\t\tif (rt->dst.flags & DST_XFRM_TUNNEL)\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(&rt->dst);\n\t\telse\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(rt->dst.path);\n\t\tif (np->frag_size < mtu) {\n\t\t\tif (np->frag_size)\n\t\t\t\tmtu = np->frag_size;\n\t\t}\n\t\tcork->fragsize = mtu;\n\t\tif (dst_allfrag(rt->dst.path))\n\t\t\tcork->flags |= IPCORK_ALLFRAG;\n\t\tcork->length = 0;\n\t\texthdrlen = (opt ? opt->opt_flen : 0);\n\t\tlength += exthdrlen;\n\t\ttranshdrlen += exthdrlen;\n\t\tdst_exthdrlen = rt->dst.header_len - rt->rt6i_nfheader_len;\n\t} else {\n\t\trt = (struct rt6_info *)cork->dst;\n\t\tfl6 = &inet->cork.fl.u.ip6;\n\t\topt = np->cork.opt;\n\t\ttranshdrlen = 0;\n\t\texthdrlen = 0;\n\t\tdst_exthdrlen = 0;\n\t\tmtu = cork->fragsize;\n\t}\n\n\thh_len = LL_RESERVED_SPACE(rt->dst.dev);\n\n\tfragheaderlen = sizeof(struct ipv6hdr) + rt->rt6i_nfheader_len +\n\t\t\t(opt ? opt->opt_nflen : 0);\n\tmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen - sizeof(struct frag_hdr);\n\n\tif (mtu <= sizeof(struct ipv6hdr) + IPV6_MAXPLEN) {\n\t\tif (cork->length + length > sizeof(struct ipv6hdr) + IPV6_MAXPLEN - fragheaderlen) {\n\t\t\tipv6_local_error(sk, EMSGSIZE, fl6, mtu-exthdrlen);\n\t\t\treturn -EMSGSIZE;\n\t\t}\n\t}\n\n\t/* For UDP, check if TX timestamp is enabled */\n\tif (sk->sk_type == SOCK_DGRAM)\n\t\tsock_tx_timestamp(sk, &tx_flags);\n\n\t/*\n\t * Let's try using as much space as possible.\n\t * Use MTU if total length of the message fits into the MTU.\n\t * Otherwise, we need to reserve fragment header and\n\t * fragment alignment (= 8-15 octects, in total).\n\t *\n\t * Note that we may need to \"move\" the data from the tail of\n\t * of the buffer to the new fragment when we split\n\t * the message.\n\t *\n\t * FIXME: It may be fragmented into multiple chunks\n\t *        at once if non-fragmentable extension headers\n\t *        are too large.\n\t * --yoshfuji\n\t */\n\n\tcork->length += length;\n\tif (length > mtu) {\n\t\tint proto = sk->sk_protocol;\n\t\tif (dontfrag && (proto == IPPROTO_UDP || proto == IPPROTO_RAW)){\n\t\t\tipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);\n\t\t\treturn -EMSGSIZE;\n\t\t}\n\n\t\tif (proto == IPPROTO_UDP &&\n\t\t    (rt->dst.dev->features & NETIF_F_UFO)) {\n\n\t\t\terr = ip6_ufo_append_data(sk, getfrag, from, length,\n\t\t\t\t\t\t  hh_len, fragheaderlen,\n\t\t\t\t\t\t  transhdrlen, mtu, flags, rt);\n\t\t\tif (err)\n\t\t\t\tgoto error;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL)\n\t\tgoto alloc_new_skb;\n\n\twhile (length > 0) {\n\t\t/* Check if the remaining data fits into current packet. */\n\t\tcopy = (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - skb->len;\n\t\tif (copy < length)\n\t\t\tcopy = maxfraglen - skb->len;\n\n\t\tif (copy <= 0) {\n\t\t\tchar *data;\n\t\t\tunsigned int datalen;\n\t\t\tunsigned int fraglen;\n\t\t\tunsigned int fraggap;\n\t\t\tunsigned int alloclen;\nalloc_new_skb:\n\t\t\t/* There's no room in the current skb */\n\t\t\tif (skb)\n\t\t\t\tfraggap = skb->len - maxfraglen;\n\t\t\telse\n\t\t\t\tfraggap = 0;\n\t\t\t/* update mtu and maxfraglen if necessary */\n\t\t\tif (skb == NULL || skb_prev == NULL)\n\t\t\t\tip6_append_data_mtu(&mtu, &maxfraglen,\n\t\t\t\t\t\t    fragheaderlen, skb, rt,\n\t\t\t\t\t\t    np->pmtudisc ==\n\t\t\t\t\t\t    IPV6_PMTUDISC_PROBE);\n\n\t\t\tskb_prev = skb;\n\n\t\t\t/*\n\t\t\t * If remaining data exceeds the mtu,\n\t\t\t * we know we need more fragment(s).\n\t\t\t */\n\t\t\tdatalen = length + fraggap;\n\n\t\t\tif (datalen > (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - fragheaderlen)\n\t\t\t\tdatalen = maxfraglen - fragheaderlen - rt->dst.trailer_len;\n\t\t\tif ((flags & MSG_MORE) &&\n\t\t\t    !(rt->dst.dev->features&NETIF_F_SG))\n\t\t\t\talloclen = mtu;\n\t\t\telse\n\t\t\t\talloclen = datalen + fragheaderlen;\n\n\t\t\talloclen += dst_exthdrlen;\n\n\t\t\tif (datalen != length + fraggap) {\n\t\t\t\t/*\n\t\t\t\t * this is not the last fragment, the trailer\n\t\t\t\t * space is regarded as data space.\n\t\t\t\t */\n\t\t\t\tdatalen += rt->dst.trailer_len;\n\t\t\t}\n\n\t\t\talloclen += rt->dst.trailer_len;\n\t\t\tfraglen = datalen + fragheaderlen;\n\n\t\t\t/*\n\t\t\t * We just reserve space for fragment header.\n\t\t\t * Note: this may be overallocation if the message\n\t\t\t * (without MSG_MORE) fits into the MTU.\n\t\t\t */\n\t\t\talloclen += sizeof(struct frag_hdr);\n\n\t\t\tif (transhdrlen) {\n\t\t\t\tskb = sock_alloc_send_skb(sk,\n\t\t\t\t\t\talloclen + hh_len,\n\t\t\t\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\t\t} else {\n\t\t\t\tskb = NULL;\n\t\t\t\tif (atomic_read(&sk->sk_wmem_alloc) <=\n\t\t\t\t    2 * sk->sk_sndbuf)\n\t\t\t\t\tskb = sock_wmalloc(sk,\n\t\t\t\t\t\t\t   alloclen + hh_len, 1,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\t\tif (unlikely(skb == NULL))\n\t\t\t\t\terr = -ENOBUFS;\n\t\t\t\telse {\n\t\t\t\t\t/* Only the initial fragment\n\t\t\t\t\t * is time stamped.\n\t\t\t\t\t */\n\t\t\t\t\ttx_flags = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (skb == NULL)\n\t\t\t\tgoto error;\n\t\t\t/*\n\t\t\t *\tFill in the control structures\n\t\t\t */\n\t\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t\tskb->csum = 0;\n\t\t\t/* reserve for fragmentation and ipsec header */\n\t\t\tskb_reserve(skb, hh_len + sizeof(struct frag_hdr) +\n\t\t\t\t    dst_exthdrlen);\n\n\t\t\tif (sk->sk_type == SOCK_DGRAM)\n\t\t\t\tskb_shinfo(skb)->tx_flags = tx_flags;\n\n\t\t\t/*\n\t\t\t *\tFind where to start putting bytes\n\t\t\t */\n\t\t\tdata = skb_put(skb, fraglen);\n\t\t\tskb_set_network_header(skb, exthdrlen);\n\t\t\tdata += fragheaderlen;\n\t\t\tskb->transport_header = (skb->network_header +\n\t\t\t\t\t\t fragheaderlen);\n\t\t\tif (fraggap) {\n\t\t\t\tskb->csum = skb_copy_and_csum_bits(\n\t\t\t\t\tskb_prev, maxfraglen,\n\t\t\t\t\tdata + transhdrlen, fraggap, 0);\n\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,\n\t\t\t\t\t\t\t  skb->csum);\n\t\t\t\tdata += fraggap;\n\t\t\t\tpskb_trim_unique(skb_prev, maxfraglen);\n\t\t\t}\n\t\t\tcopy = datalen - transhdrlen - fraggap;\n\n\t\t\tif (copy < 0) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t} else if (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t}\n\n\t\t\toffset += copy;\n\t\t\tlength -= datalen - fraggap;\n\t\t\ttranshdrlen = 0;\n\t\t\texthdrlen = 0;\n\t\t\tdst_exthdrlen = 0;\n\n\t\t\t/*\n\t\t\t * Put the packet on the pending queue\n\t\t\t */\n\t\t\t__skb_queue_tail(&sk->sk_write_queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (copy > length)\n\t\t\tcopy = length;\n\n\t\tif (!(rt->dst.dev->features&NETIF_F_SG)) {\n\t\t\tunsigned int off;\n\n\t\t\toff = skb->len;\n\t\t\tif (getfrag(from, skb_put(skb, copy),\n\t\t\t\t\t\toffset, copy, off, skb) < 0) {\n\t\t\t\t__skb_trim(skb, off);\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else {\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\terr = -ENOMEM;\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto error;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tif (i == MAX_SKB_FRAGS)\n\t\t\t\t\tgoto error;\n\n\t\t\t\t__skb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t     pfrag->offset, 0);\n\t\t\t\tskb_shinfo(skb)->nr_frags = ++i;\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\t\t\tif (getfrag(from,\n\t\t\t\t    page_address(pfrag->page) + pfrag->offset,\n\t\t\t\t    offset, copy, skb->len, skb) < 0)\n\t\t\t\tgoto error_efault;\n\n\t\t\tpfrag->offset += copy;\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\tskb->len += copy;\n\t\t\tskb->data_len += copy;\n\t\t\tskb->truesize += copy;\n\t\t\tatomic_add(copy, &sk->sk_wmem_alloc);\n\t\t}\n\t\toffset += copy;\n\t\tlength -= copy;\n\t}\n\n\treturn 0;\n\nerror_efault:\n\terr = -EFAULT;\nerror:\n\tcork->length -= length;\n\tIP6_INC_STATS(sock_net(sk), rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);\n\treturn err;\n}",
      "code_after_change": "int ip6_append_data(struct sock *sk, int getfrag(void *from, char *to,\n\tint offset, int len, int odd, struct sk_buff *skb),\n\tvoid *from, int length, int transhdrlen,\n\tint hlimit, int tclass, struct ipv6_txoptions *opt, struct flowi6 *fl6,\n\tstruct rt6_info *rt, unsigned int flags, int dontfrag)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct inet_cork *cork;\n\tstruct sk_buff *skb, *skb_prev = NULL;\n\tunsigned int maxfraglen, fragheaderlen, mtu;\n\tint exthdrlen;\n\tint dst_exthdrlen;\n\tint hh_len;\n\tint copy;\n\tint err;\n\tint offset = 0;\n\t__u8 tx_flags = 0;\n\n\tif (flags&MSG_PROBE)\n\t\treturn 0;\n\tcork = &inet->cork.base;\n\tif (skb_queue_empty(&sk->sk_write_queue)) {\n\t\t/*\n\t\t * setup for corking\n\t\t */\n\t\tif (opt) {\n\t\t\tif (WARN_ON(np->cork.opt))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tnp->cork.opt = kzalloc(opt->tot_len, sk->sk_allocation);\n\t\t\tif (unlikely(np->cork.opt == NULL))\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->tot_len = opt->tot_len;\n\t\t\tnp->cork.opt->opt_flen = opt->opt_flen;\n\t\t\tnp->cork.opt->opt_nflen = opt->opt_nflen;\n\n\t\t\tnp->cork.opt->dst0opt = ip6_opt_dup(opt->dst0opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst0opt && !np->cork.opt->dst0opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->dst1opt = ip6_opt_dup(opt->dst1opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst1opt && !np->cork.opt->dst1opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->hopopt = ip6_opt_dup(opt->hopopt,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (opt->hopopt && !np->cork.opt->hopopt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->srcrt = ip6_rthdr_dup(opt->srcrt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->srcrt && !np->cork.opt->srcrt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\t/* need source address above miyazawa*/\n\t\t}\n\t\tdst_hold(&rt->dst);\n\t\tcork->dst = &rt->dst;\n\t\tinet->cork.fl.u.ip6 = *fl6;\n\t\tnp->cork.hop_limit = hlimit;\n\t\tnp->cork.tclass = tclass;\n\t\tif (rt->dst.flags & DST_XFRM_TUNNEL)\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(&rt->dst);\n\t\telse\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(rt->dst.path);\n\t\tif (np->frag_size < mtu) {\n\t\t\tif (np->frag_size)\n\t\t\t\tmtu = np->frag_size;\n\t\t}\n\t\tcork->fragsize = mtu;\n\t\tif (dst_allfrag(rt->dst.path))\n\t\t\tcork->flags |= IPCORK_ALLFRAG;\n\t\tcork->length = 0;\n\t\texthdrlen = (opt ? opt->opt_flen : 0);\n\t\tlength += exthdrlen;\n\t\ttranshdrlen += exthdrlen;\n\t\tdst_exthdrlen = rt->dst.header_len - rt->rt6i_nfheader_len;\n\t} else {\n\t\trt = (struct rt6_info *)cork->dst;\n\t\tfl6 = &inet->cork.fl.u.ip6;\n\t\topt = np->cork.opt;\n\t\ttranshdrlen = 0;\n\t\texthdrlen = 0;\n\t\tdst_exthdrlen = 0;\n\t\tmtu = cork->fragsize;\n\t}\n\n\thh_len = LL_RESERVED_SPACE(rt->dst.dev);\n\n\tfragheaderlen = sizeof(struct ipv6hdr) + rt->rt6i_nfheader_len +\n\t\t\t(opt ? opt->opt_nflen : 0);\n\tmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen - sizeof(struct frag_hdr);\n\n\tif (mtu <= sizeof(struct ipv6hdr) + IPV6_MAXPLEN) {\n\t\tif (cork->length + length > sizeof(struct ipv6hdr) + IPV6_MAXPLEN - fragheaderlen) {\n\t\t\tipv6_local_error(sk, EMSGSIZE, fl6, mtu-exthdrlen);\n\t\t\treturn -EMSGSIZE;\n\t\t}\n\t}\n\n\t/* For UDP, check if TX timestamp is enabled */\n\tif (sk->sk_type == SOCK_DGRAM)\n\t\tsock_tx_timestamp(sk, &tx_flags);\n\n\t/*\n\t * Let's try using as much space as possible.\n\t * Use MTU if total length of the message fits into the MTU.\n\t * Otherwise, we need to reserve fragment header and\n\t * fragment alignment (= 8-15 octects, in total).\n\t *\n\t * Note that we may need to \"move\" the data from the tail of\n\t * of the buffer to the new fragment when we split\n\t * the message.\n\t *\n\t * FIXME: It may be fragmented into multiple chunks\n\t *        at once if non-fragmentable extension headers\n\t *        are too large.\n\t * --yoshfuji\n\t */\n\n\tif ((length > mtu) && dontfrag && (sk->sk_protocol == IPPROTO_UDP ||\n\t\t\t\t\t   sk->sk_protocol == IPPROTO_RAW)) {\n\t\tipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);\n\t\treturn -EMSGSIZE;\n\t}\n\n\tskb = skb_peek_tail(&sk->sk_write_queue);\n\tcork->length += length;\n\tif (((length > mtu) ||\n\t     (skb && skb_is_gso(skb))) &&\n\t    (sk->sk_protocol == IPPROTO_UDP) &&\n\t    (rt->dst.dev->features & NETIF_F_UFO)) {\n\t\terr = ip6_ufo_append_data(sk, getfrag, from, length,\n\t\t\t\t\t  hh_len, fragheaderlen,\n\t\t\t\t\t  transhdrlen, mtu, flags, rt);\n\t\tif (err)\n\t\t\tgoto error;\n\t\treturn 0;\n\t}\n\n\tif (!skb)\n\t\tgoto alloc_new_skb;\n\n\twhile (length > 0) {\n\t\t/* Check if the remaining data fits into current packet. */\n\t\tcopy = (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - skb->len;\n\t\tif (copy < length)\n\t\t\tcopy = maxfraglen - skb->len;\n\n\t\tif (copy <= 0) {\n\t\t\tchar *data;\n\t\t\tunsigned int datalen;\n\t\t\tunsigned int fraglen;\n\t\t\tunsigned int fraggap;\n\t\t\tunsigned int alloclen;\nalloc_new_skb:\n\t\t\t/* There's no room in the current skb */\n\t\t\tif (skb)\n\t\t\t\tfraggap = skb->len - maxfraglen;\n\t\t\telse\n\t\t\t\tfraggap = 0;\n\t\t\t/* update mtu and maxfraglen if necessary */\n\t\t\tif (skb == NULL || skb_prev == NULL)\n\t\t\t\tip6_append_data_mtu(&mtu, &maxfraglen,\n\t\t\t\t\t\t    fragheaderlen, skb, rt,\n\t\t\t\t\t\t    np->pmtudisc ==\n\t\t\t\t\t\t    IPV6_PMTUDISC_PROBE);\n\n\t\t\tskb_prev = skb;\n\n\t\t\t/*\n\t\t\t * If remaining data exceeds the mtu,\n\t\t\t * we know we need more fragment(s).\n\t\t\t */\n\t\t\tdatalen = length + fraggap;\n\n\t\t\tif (datalen > (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - fragheaderlen)\n\t\t\t\tdatalen = maxfraglen - fragheaderlen - rt->dst.trailer_len;\n\t\t\tif ((flags & MSG_MORE) &&\n\t\t\t    !(rt->dst.dev->features&NETIF_F_SG))\n\t\t\t\talloclen = mtu;\n\t\t\telse\n\t\t\t\talloclen = datalen + fragheaderlen;\n\n\t\t\talloclen += dst_exthdrlen;\n\n\t\t\tif (datalen != length + fraggap) {\n\t\t\t\t/*\n\t\t\t\t * this is not the last fragment, the trailer\n\t\t\t\t * space is regarded as data space.\n\t\t\t\t */\n\t\t\t\tdatalen += rt->dst.trailer_len;\n\t\t\t}\n\n\t\t\talloclen += rt->dst.trailer_len;\n\t\t\tfraglen = datalen + fragheaderlen;\n\n\t\t\t/*\n\t\t\t * We just reserve space for fragment header.\n\t\t\t * Note: this may be overallocation if the message\n\t\t\t * (without MSG_MORE) fits into the MTU.\n\t\t\t */\n\t\t\talloclen += sizeof(struct frag_hdr);\n\n\t\t\tif (transhdrlen) {\n\t\t\t\tskb = sock_alloc_send_skb(sk,\n\t\t\t\t\t\talloclen + hh_len,\n\t\t\t\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\t\t} else {\n\t\t\t\tskb = NULL;\n\t\t\t\tif (atomic_read(&sk->sk_wmem_alloc) <=\n\t\t\t\t    2 * sk->sk_sndbuf)\n\t\t\t\t\tskb = sock_wmalloc(sk,\n\t\t\t\t\t\t\t   alloclen + hh_len, 1,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\t\tif (unlikely(skb == NULL))\n\t\t\t\t\terr = -ENOBUFS;\n\t\t\t\telse {\n\t\t\t\t\t/* Only the initial fragment\n\t\t\t\t\t * is time stamped.\n\t\t\t\t\t */\n\t\t\t\t\ttx_flags = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (skb == NULL)\n\t\t\t\tgoto error;\n\t\t\t/*\n\t\t\t *\tFill in the control structures\n\t\t\t */\n\t\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t\tskb->csum = 0;\n\t\t\t/* reserve for fragmentation and ipsec header */\n\t\t\tskb_reserve(skb, hh_len + sizeof(struct frag_hdr) +\n\t\t\t\t    dst_exthdrlen);\n\n\t\t\tif (sk->sk_type == SOCK_DGRAM)\n\t\t\t\tskb_shinfo(skb)->tx_flags = tx_flags;\n\n\t\t\t/*\n\t\t\t *\tFind where to start putting bytes\n\t\t\t */\n\t\t\tdata = skb_put(skb, fraglen);\n\t\t\tskb_set_network_header(skb, exthdrlen);\n\t\t\tdata += fragheaderlen;\n\t\t\tskb->transport_header = (skb->network_header +\n\t\t\t\t\t\t fragheaderlen);\n\t\t\tif (fraggap) {\n\t\t\t\tskb->csum = skb_copy_and_csum_bits(\n\t\t\t\t\tskb_prev, maxfraglen,\n\t\t\t\t\tdata + transhdrlen, fraggap, 0);\n\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,\n\t\t\t\t\t\t\t  skb->csum);\n\t\t\t\tdata += fraggap;\n\t\t\t\tpskb_trim_unique(skb_prev, maxfraglen);\n\t\t\t}\n\t\t\tcopy = datalen - transhdrlen - fraggap;\n\n\t\t\tif (copy < 0) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t} else if (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t}\n\n\t\t\toffset += copy;\n\t\t\tlength -= datalen - fraggap;\n\t\t\ttranshdrlen = 0;\n\t\t\texthdrlen = 0;\n\t\t\tdst_exthdrlen = 0;\n\n\t\t\t/*\n\t\t\t * Put the packet on the pending queue\n\t\t\t */\n\t\t\t__skb_queue_tail(&sk->sk_write_queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (copy > length)\n\t\t\tcopy = length;\n\n\t\tif (!(rt->dst.dev->features&NETIF_F_SG)) {\n\t\t\tunsigned int off;\n\n\t\t\toff = skb->len;\n\t\t\tif (getfrag(from, skb_put(skb, copy),\n\t\t\t\t\t\toffset, copy, off, skb) < 0) {\n\t\t\t\t__skb_trim(skb, off);\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else {\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\terr = -ENOMEM;\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto error;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tif (i == MAX_SKB_FRAGS)\n\t\t\t\t\tgoto error;\n\n\t\t\t\t__skb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t     pfrag->offset, 0);\n\t\t\t\tskb_shinfo(skb)->nr_frags = ++i;\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\t\t\tif (getfrag(from,\n\t\t\t\t    page_address(pfrag->page) + pfrag->offset,\n\t\t\t\t    offset, copy, skb->len, skb) < 0)\n\t\t\t\tgoto error_efault;\n\n\t\t\tpfrag->offset += copy;\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\tskb->len += copy;\n\t\t\tskb->data_len += copy;\n\t\t\tskb->truesize += copy;\n\t\t\tatomic_add(copy, &sk->sk_wmem_alloc);\n\t\t}\n\t\toffset += copy;\n\t\tlength -= copy;\n\t}\n\n\treturn 0;\n\nerror_efault:\n\terr = -EFAULT;\nerror:\n\tcork->length -= length;\n\tIP6_INC_STATS(sock_net(sk), rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\tif ((length > mtu) && dontfrag && (sk->sk_protocol == IPPROTO_UDP ||",
          "\t\t\t\t\t   sk->sk_protocol == IPPROTO_RAW)) {",
          "\t\tipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);",
          "\t\treturn -EMSGSIZE;",
          "\t}",
          "",
          "\tskb = skb_peek_tail(&sk->sk_write_queue);",
          "\tif (((length > mtu) ||",
          "\t     (skb && skb_is_gso(skb))) &&",
          "\t    (sk->sk_protocol == IPPROTO_UDP) &&",
          "\t    (rt->dst.dev->features & NETIF_F_UFO)) {",
          "\t\terr = ip6_ufo_append_data(sk, getfrag, from, length,",
          "\t\t\t\t\t  hh_len, fragheaderlen,",
          "\t\t\t\t\t  transhdrlen, mtu, flags, rt);",
          "\t\tif (err)",
          "\t\t\tgoto error;",
          "\t\treturn 0;",
          "\t}",
          "",
          "\tif (!skb)"
        ],
        "deleted": [
          "\tif (length > mtu) {",
          "\t\tint proto = sk->sk_protocol;",
          "\t\tif (dontfrag && (proto == IPPROTO_UDP || proto == IPPROTO_RAW)){",
          "\t\t\tipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);",
          "\t\t\treturn -EMSGSIZE;",
          "\t\t}",
          "",
          "\t\tif (proto == IPPROTO_UDP &&",
          "\t\t    (rt->dst.dev->features & NETIF_F_UFO)) {",
          "",
          "\t\t\terr = ip6_ufo_append_data(sk, getfrag, from, length,",
          "\t\t\t\t\t\t  hh_len, fragheaderlen,",
          "\t\t\t\t\t\t  transhdrlen, mtu, flags, rt);",
          "\t\t\tif (err)",
          "\t\t\t\tgoto error;",
          "\t\t\treturn 0;",
          "\t\t}",
          "\t}",
          "",
          "\tif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for UDP Fragmentation Offload (UFO) processing of small packets after queueing a large packet.",
      "trigger_condition": "Receiving network traffic that triggers a large response packet without proper UFO processing for subsequent small packets.",
      "specific_code_behavior_causing_vulnerability": "The code does not check for the need for UFO processing of small packets after queueing a large packet, leading to a denial of service (memory corruption and system crash) vulnerability.",
      "id": 40,
      "code_after_change_normalized": "int FUN1(struct sock *VAR1, int FUN2(void *VAR2, char *VAR3,\nint VAR4, int VAR5, int VAR6, struct sk_buff *VAR7),\nvoid *VAR2, int VAR8, int VAR9,\nint VAR10, int VAR11, struct ipv6_txoptions *VAR12, struct flowi6 *VAR13,\nstruct rt6_info *VAR14, unsigned int VAR15, int VAR16)\n{\nstruct inet_sock *VAR17 = FUN3(VAR1);\nstruct ipv6_pinfo *VAR18 = FUN4(VAR1);\nstruct inet_cork *VAR19;\nstruct sk_buff *VAR7, *VAR20 = NULL;\nunsigned int VAR21, VAR22, VAR23;\nint VAR24;\nint VAR25;\nint VAR26;\nint VAR27;\nint VAR28;\nint VAR4 = 0;\n__u8 VAR29 = 0;\nif (VAR15&VAR30)\nreturn 0;\nVAR19 = &VAR17->VAR19.VAR31;\nif (FUN5(&VAR1->VAR32)) {\nif (VAR12) {\nif (FUN6(VAR18->VAR19.VAR12))\nreturn -VAR33;\nVAR18->VAR19.VAR12 = FUN7(VAR12->VAR34, VAR1->VAR35);\nif (FUN8(VAR18->VAR19.VAR12 == NULL))\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR34 = VAR12->VAR34;\nVAR18->VAR19.VAR12->VAR37 = VAR12->VAR37;\nVAR18->VAR19.VAR12->VAR38 = VAR12->VAR38;\nVAR18->VAR19.VAR12->VAR39 = FUN9(VAR12->VAR39,\nVAR1->VAR35);\nif (VAR12->VAR39 && !VAR18->VAR19.VAR12->VAR39)\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR40 = FUN9(VAR12->VAR40,\nVAR1->VAR35);\nif (VAR12->VAR40 && !VAR18->VAR19.VAR12->VAR40)\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR41 = FUN9(VAR12->VAR41,\nVAR1->VAR35);\nif (VAR12->VAR41 && !VAR18->VAR19.VAR12->VAR41)\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR42 = FUN10(VAR12->VAR42,\nVAR1->VAR35);\nif (VAR12->VAR42 && !VAR18->VAR19.VAR12->VAR42)\nreturn -VAR36;\n}\nFUN11(&VAR14->VAR43);\nVAR19->VAR43 = &VAR14->VAR43;\nVAR17->VAR19.VAR44.VAR45.VAR46 = *VAR13;\nVAR18->VAR19.VAR47 = VAR10;\nVAR18->VAR19.VAR11 = VAR11;\nif (VAR14->VAR43.VAR15 & VAR48)\nVAR23 = VAR18->VAR49 == VAR50 ?\nVAR14->VAR43.VAR51->VAR23 : FUN12(&VAR14->VAR43);\nelse\nVAR23 = VAR18->VAR49 == VAR50 ?\nVAR14->VAR43.VAR51->VAR23 : FUN12(VAR14->VAR43.VAR52);\nif (VAR18->VAR53 < VAR23) {\nif (VAR18->VAR53)\nVAR23 = VAR18->VAR53;\n}\nVAR19->VAR54 = VAR23;\nif (FUN13(VAR14->VAR43.VAR52))\nVAR19->VAR15 |= VAR55;\nVAR19->VAR8 = 0;\nVAR24 = (VAR12 ? VAR12->VAR37 : 0);\nVAR8 += VAR24;\nVAR9 += VAR24;\nVAR25 = VAR14->VAR43.VAR56 - VAR14->VAR57;\n} else {\nVAR14 = (struct VAR58 *)VAR19->VAR43;\nVAR13 = &VAR17->VAR19.VAR44.VAR45.VAR46;\nVAR12 = VAR18->VAR19.VAR12;\nVAR9 = 0;\nVAR24 = 0;\nVAR25 = 0;\nVAR23 = VAR19->VAR54;\n}\nVAR26 = FUN14(VAR14->VAR43.VAR51);\nVAR22 = sizeof(struct VAR59) + VAR14->VAR57 +\n(VAR12 ? VAR12->VAR38 : 0);\nVAR21 = ((VAR23 - VAR22) & ~7) + VAR22 - sizeof(struct VAR60);\nif (VAR23 <= sizeof(struct VAR59) + VAR61) {\nif (VAR19->VAR8 + VAR8 > sizeof(struct VAR59) + VAR61 - VAR22) {\nFUN15(VAR1, VAR62, VAR13, VAR23-VAR24);\nreturn -VAR62;\n}\n}\nif (VAR1->VAR63 == VAR64)\nFUN16(VAR1, &VAR29);\nif ((VAR8 > VAR23) && VAR16 && (VAR1->VAR65 == VAR66 ||\nVAR1->VAR65 == VAR67)) {\nFUN17(VAR1, VAR13, VAR23-VAR24);\nreturn -VAR62;\n}\nVAR7 = FUN18(&VAR1->VAR32);\nVAR19->VAR8 += VAR8;\nif (((VAR8 > VAR23) ||\n(VAR7 && FUN19(VAR7))) &&\n(VAR1->VAR65 == VAR66) &&\n(VAR14->VAR43.VAR51->VAR68 & VAR69)) {\nVAR28 = FUN20(VAR1, VAR70, VAR2, VAR8,\nVAR26, VAR22,\nVAR9, VAR23, VAR15, VAR14);\nif (VAR28)\ngoto VAR71;\nreturn 0;\n}\nif (!VAR7)\ngoto VAR72;\nwhile (VAR8 > 0) {\nVAR27 = (VAR19->VAR8 <= VAR23 && !(VAR19->VAR15 & VAR55) ? VAR23 : VAR21) - VAR7->VAR5;\nif (VAR27 < VAR8)\nVAR27 = VAR21 - VAR7->VAR5;\nif (VAR27 <= 0) {\nchar *VAR73;\nunsigned int VAR74;\nunsigned int VAR75;\nunsigned int VAR76;\nunsigned int VAR77;\nVAR72:\nif (VAR7)\nVAR76 = VAR7->VAR5 - VAR21;\nelse\nVAR76 = 0;\nif (VAR7 == NULL || VAR20 == NULL)\nFUN21(&VAR23, &VAR21,\nVAR22, VAR7, VAR14,\nVAR18->VAR49 ==\nVAR50);\nVAR20 = VAR7;\nVAR74 = VAR8 + VAR76;\nif (VAR74 > (VAR19->VAR8 <= VAR23 && !(VAR19->VAR15 & VAR55) ? VAR23 : VAR21) - VAR22)\nVAR74 = VAR21 - VAR22 - VAR14->VAR43.VAR78;\nif ((VAR15 & VAR79) &&\n!(VAR14->VAR43.VAR51->VAR68&VAR80))\nVAR77 = VAR23;\nelse\nVAR77 = VAR74 + VAR22;\nVAR77 += VAR25;\nif (VAR74 != VAR8 + VAR76) {\nVAR74 += VAR14->VAR43.VAR78;\n}\nVAR77 += VAR14->VAR43.VAR78;\nVAR75 = VAR74 + VAR22;\nVAR77 += sizeof(struct VAR60);\nif (VAR9) {\nVAR7 = FUN22(VAR1,\nVAR77 + VAR26,\n(VAR15 & VAR81), &VAR28);\n} else {\nVAR7 = NULL;\nif (FUN23(&VAR1->VAR82) <=\n2 * VAR1->VAR83)\nVAR7 = FUN24(VAR1,\nVAR77 + VAR26, 1,\nVAR1->VAR35);\nif (FUN8(VAR7 == NULL))\nVAR28 = -VAR36;\nelse {\nVAR29 = 0;\n}\n}\nif (VAR7 == NULL)\ngoto VAR71;\nVAR7->VAR84 = FUN25(VAR85);\nVAR7->VAR86 = VAR87;\nVAR7->VAR88 = 0;\nFUN26(VAR7, VAR26 + sizeof(struct VAR60) +\nVAR25);\nif (VAR1->VAR63 == VAR64)\nFUN27(VAR7)->VAR29 = VAR29;\nVAR73 = FUN28(VAR7, VAR75);\nFUN29(VAR7, VAR24);\nVAR73 += VAR22;\nVAR7->VAR89 = (VAR7->VAR90 +\nVAR22);\nif (VAR76) {\nVAR7->VAR88 = FUN30(\nVAR20, VAR21,\nVAR73 + VAR9, VAR76, 0);\nVAR20->VAR88 = FUN31(VAR20->VAR88,\nVAR7->VAR88);\nVAR73 += VAR76;\nFUN32(VAR20, VAR21);\n}\nVAR27 = VAR74 - VAR9 - VAR76;\nif (VAR27 < 0) {\nVAR28 = -VAR33;\nFUN33(VAR7);\ngoto VAR71;\n} else if (VAR27 > 0 && FUN2(VAR2, VAR73 + VAR9, VAR4, VAR27, VAR76, VAR7) < 0) {\nVAR28 = -VAR91;\nFUN33(VAR7);\ngoto VAR71;\n}\nVAR4 += VAR27;\nVAR8 -= VAR74 - VAR76;\nVAR9 = 0;\nVAR24 = 0;\nVAR25 = 0;\nFUN34(&VAR1->VAR32, VAR7);\ncontinue;\n}\nif (VAR27 > VAR8)\nVAR27 = VAR8;\nif (!(VAR14->VAR43.VAR51->VAR68&VAR80)) {\nunsigned int VAR92;\nVAR92 = VAR7->VAR5;\nif (FUN2(VAR2, FUN28(VAR7, VAR27),\nVAR4, VAR27, VAR92, VAR7) < 0) {\nFUN35(VAR7, VAR92);\nVAR28 = -VAR91;\ngoto VAR71;\n}\n} else {\nint VAR93 = FUN27(VAR7)->VAR94;\nstruct page_frag *VAR95 = FUN36(VAR1);\nVAR28 = -VAR96;\nif (!FUN37(VAR1, VAR95))\ngoto VAR71;\nif (!FUN38(VAR7, VAR93, VAR95->VAR97,\nVAR95->VAR4)) {\nVAR28 = -VAR62;\nif (VAR93 == VAR98)\ngoto VAR71;\nFUN39(VAR7, VAR93, VAR95->VAR97,\nVAR95->VAR4, 0);\nFUN27(VAR7)->VAR94 = ++VAR93;\nFUN40(VAR95->VAR97);\n}\nVAR27 = FUN41(int, VAR27, VAR95->VAR99 - VAR95->VAR4);\nif (FUN2(VAR2,\nFUN42(VAR95->VAR97) + VAR95->VAR4,\nVAR4, VAR27, VAR7->VAR5, VAR7) < 0)\ngoto VAR100;\nVAR95->VAR4 += VAR27;\nFUN43(&FUN27(VAR7)->VAR101[VAR93 - 1], VAR27);\nVAR7->VAR5 += VAR27;\nVAR7->VAR102 += VAR27;\nVAR7->VAR103 += VAR27;\nFUN44(VAR27, &VAR1->VAR82);\n}\nVAR4 += VAR27;\nVAR8 -= VAR27;\n}\nreturn 0;\nVAR100:\nVAR28 = -VAR91;\nVAR71:\nVAR19->VAR8 -= VAR8;\nFUN45(FUN46(VAR1), VAR14->VAR104, VAR105);\nreturn VAR28;\n}\n",
      "code_before_change_normalized": "int FUN1(struct sock *VAR1, int FUN2(void *VAR2, char *VAR3,\nint VAR4, int VAR5, int VAR6, struct sk_buff *VAR7),\nvoid *VAR2, int VAR8, int VAR9,\nint VAR10, int VAR11, struct ipv6_txoptions *VAR12, struct flowi6 *VAR13,\nstruct rt6_info *VAR14, unsigned int VAR15, int VAR16)\n{\nstruct inet_sock *VAR17 = FUN3(VAR1);\nstruct ipv6_pinfo *VAR18 = FUN4(VAR1);\nstruct inet_cork *VAR19;\nstruct sk_buff *VAR7, *VAR20 = NULL;\nunsigned int VAR21, VAR22, VAR23;\nint VAR24;\nint VAR25;\nint VAR26;\nint VAR27;\nint VAR28;\nint VAR4 = 0;\n__u8 VAR29 = 0;\nif (VAR15&VAR30)\nreturn 0;\nVAR19 = &VAR17->VAR19.VAR31;\nif (FUN5(&VAR1->VAR32)) {\nif (VAR12) {\nif (FUN6(VAR18->VAR19.VAR12))\nreturn -VAR33;\nVAR18->VAR19.VAR12 = FUN7(VAR12->VAR34, VAR1->VAR35);\nif (FUN8(VAR18->VAR19.VAR12 == NULL))\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR34 = VAR12->VAR34;\nVAR18->VAR19.VAR12->VAR37 = VAR12->VAR37;\nVAR18->VAR19.VAR12->VAR38 = VAR12->VAR38;\nVAR18->VAR19.VAR12->VAR39 = FUN9(VAR12->VAR39,\nVAR1->VAR35);\nif (VAR12->VAR39 && !VAR18->VAR19.VAR12->VAR39)\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR40 = FUN9(VAR12->VAR40,\nVAR1->VAR35);\nif (VAR12->VAR40 && !VAR18->VAR19.VAR12->VAR40)\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR41 = FUN9(VAR12->VAR41,\nVAR1->VAR35);\nif (VAR12->VAR41 && !VAR18->VAR19.VAR12->VAR41)\nreturn -VAR36;\nVAR18->VAR19.VAR12->VAR42 = FUN10(VAR12->VAR42,\nVAR1->VAR35);\nif (VAR12->VAR42 && !VAR18->VAR19.VAR12->VAR42)\nreturn -VAR36;\n}\nFUN11(&VAR14->VAR43);\nVAR19->VAR43 = &VAR14->VAR43;\nVAR17->VAR19.VAR44.VAR45.VAR46 = *VAR13;\nVAR18->VAR19.VAR47 = VAR10;\nVAR18->VAR19.VAR11 = VAR11;\nif (VAR14->VAR43.VAR15 & VAR48)\nVAR23 = VAR18->VAR49 == VAR50 ?\nVAR14->VAR43.VAR51->VAR23 : FUN12(&VAR14->VAR43);\nelse\nVAR23 = VAR18->VAR49 == VAR50 ?\nVAR14->VAR43.VAR51->VAR23 : FUN12(VAR14->VAR43.VAR52);\nif (VAR18->VAR53 < VAR23) {\nif (VAR18->VAR53)\nVAR23 = VAR18->VAR53;\n}\nVAR19->VAR54 = VAR23;\nif (FUN13(VAR14->VAR43.VAR52))\nVAR19->VAR15 |= VAR55;\nVAR19->VAR8 = 0;\nVAR24 = (VAR12 ? VAR12->VAR37 : 0);\nVAR8 += VAR24;\nVAR9 += VAR24;\nVAR25 = VAR14->VAR43.VAR56 - VAR14->VAR57;\n} else {\nVAR14 = (struct VAR58 *)VAR19->VAR43;\nVAR13 = &VAR17->VAR19.VAR44.VAR45.VAR46;\nVAR12 = VAR18->VAR19.VAR12;\nVAR9 = 0;\nVAR24 = 0;\nVAR25 = 0;\nVAR23 = VAR19->VAR54;\n}\nVAR26 = FUN14(VAR14->VAR43.VAR51);\nVAR22 = sizeof(struct VAR59) + VAR14->VAR57 +\n(VAR12 ? VAR12->VAR38 : 0);\nVAR21 = ((VAR23 - VAR22) & ~7) + VAR22 - sizeof(struct VAR60);\nif (VAR23 <= sizeof(struct VAR59) + VAR61) {\nif (VAR19->VAR8 + VAR8 > sizeof(struct VAR59) + VAR61 - VAR22) {\nFUN15(VAR1, VAR62, VAR13, VAR23-VAR24);\nreturn -VAR62;\n}\n}\nif (VAR1->VAR63 == VAR64)\nFUN16(VAR1, &VAR29);\nVAR19->VAR8 += VAR8;\nif (VAR8 > VAR23) {\nint VAR65 = VAR1->VAR66;\nif (VAR16 && (VAR65 == VAR67 || VAR65 == VAR68)){\nFUN17(VAR1, VAR13, VAR23-VAR24);\nreturn -VAR62;\n}\nif (VAR65 == VAR67 &&\n(VAR14->VAR43.VAR51->VAR69 & VAR70)) {\nVAR28 = FUN18(VAR1, VAR71, VAR2, VAR8,\nVAR26, VAR22,\nVAR9, VAR23, VAR15, VAR14);\nif (VAR28)\ngoto VAR72;\nreturn 0;\n}\n}\nif ((VAR7 = FUN19(&VAR1->VAR32)) == NULL)\ngoto VAR73;\nwhile (VAR8 > 0) {\nVAR27 = (VAR19->VAR8 <= VAR23 && !(VAR19->VAR15 & VAR55) ? VAR23 : VAR21) - VAR7->VAR5;\nif (VAR27 < VAR8)\nVAR27 = VAR21 - VAR7->VAR5;\nif (VAR27 <= 0) {\nchar *VAR74;\nunsigned int VAR75;\nunsigned int VAR76;\nunsigned int VAR77;\nunsigned int VAR78;\nVAR73:\nif (VAR7)\nVAR77 = VAR7->VAR5 - VAR21;\nelse\nVAR77 = 0;\nif (VAR7 == NULL || VAR20 == NULL)\nFUN20(&VAR23, &VAR21,\nVAR22, VAR7, VAR14,\nVAR18->VAR49 ==\nVAR50);\nVAR20 = VAR7;\nVAR75 = VAR8 + VAR77;\nif (VAR75 > (VAR19->VAR8 <= VAR23 && !(VAR19->VAR15 & VAR55) ? VAR23 : VAR21) - VAR22)\nVAR75 = VAR21 - VAR22 - VAR14->VAR43.VAR79;\nif ((VAR15 & VAR80) &&\n!(VAR14->VAR43.VAR51->VAR69&VAR81))\nVAR78 = VAR23;\nelse\nVAR78 = VAR75 + VAR22;\nVAR78 += VAR25;\nif (VAR75 != VAR8 + VAR77) {\nVAR75 += VAR14->VAR43.VAR79;\n}\nVAR78 += VAR14->VAR43.VAR79;\nVAR76 = VAR75 + VAR22;\nVAR78 += sizeof(struct VAR60);\nif (VAR9) {\nVAR7 = FUN21(VAR1,\nVAR78 + VAR26,\n(VAR15 & VAR82), &VAR28);\n} else {\nVAR7 = NULL;\nif (FUN22(&VAR1->VAR83) <=\n2 * VAR1->VAR84)\nVAR7 = FUN23(VAR1,\nVAR78 + VAR26, 1,\nVAR1->VAR35);\nif (FUN8(VAR7 == NULL))\nVAR28 = -VAR36;\nelse {\nVAR29 = 0;\n}\n}\nif (VAR7 == NULL)\ngoto VAR72;\nVAR7->VAR85 = FUN24(VAR86);\nVAR7->VAR87 = VAR88;\nVAR7->VAR89 = 0;\nFUN25(VAR7, VAR26 + sizeof(struct VAR60) +\nVAR25);\nif (VAR1->VAR63 == VAR64)\nFUN26(VAR7)->VAR29 = VAR29;\nVAR74 = FUN27(VAR7, VAR76);\nFUN28(VAR7, VAR24);\nVAR74 += VAR22;\nVAR7->VAR90 = (VAR7->VAR91 +\nVAR22);\nif (VAR77) {\nVAR7->VAR89 = FUN29(\nVAR20, VAR21,\nVAR74 + VAR9, VAR77, 0);\nVAR20->VAR89 = FUN30(VAR20->VAR89,\nVAR7->VAR89);\nVAR74 += VAR77;\nFUN31(VAR20, VAR21);\n}\nVAR27 = VAR75 - VAR9 - VAR77;\nif (VAR27 < 0) {\nVAR28 = -VAR33;\nFUN32(VAR7);\ngoto VAR72;\n} else if (VAR27 > 0 && FUN2(VAR2, VAR74 + VAR9, VAR4, VAR27, VAR77, VAR7) < 0) {\nVAR28 = -VAR92;\nFUN32(VAR7);\ngoto VAR72;\n}\nVAR4 += VAR27;\nVAR8 -= VAR75 - VAR77;\nVAR9 = 0;\nVAR24 = 0;\nVAR25 = 0;\nFUN33(&VAR1->VAR32, VAR7);\ncontinue;\n}\nif (VAR27 > VAR8)\nVAR27 = VAR8;\nif (!(VAR14->VAR43.VAR51->VAR69&VAR81)) {\nunsigned int VAR93;\nVAR93 = VAR7->VAR5;\nif (FUN2(VAR2, FUN27(VAR7, VAR27),\nVAR4, VAR27, VAR93, VAR7) < 0) {\nFUN34(VAR7, VAR93);\nVAR28 = -VAR92;\ngoto VAR72;\n}\n} else {\nint VAR94 = FUN26(VAR7)->VAR95;\nstruct page_frag *VAR96 = FUN35(VAR1);\nVAR28 = -VAR97;\nif (!FUN36(VAR1, VAR96))\ngoto VAR72;\nif (!FUN37(VAR7, VAR94, VAR96->VAR98,\nVAR96->VAR4)) {\nVAR28 = -VAR62;\nif (VAR94 == VAR99)\ngoto VAR72;\nFUN38(VAR7, VAR94, VAR96->VAR98,\nVAR96->VAR4, 0);\nFUN26(VAR7)->VAR95 = ++VAR94;\nFUN39(VAR96->VAR98);\n}\nVAR27 = FUN40(int, VAR27, VAR96->VAR100 - VAR96->VAR4);\nif (FUN2(VAR2,\nFUN41(VAR96->VAR98) + VAR96->VAR4,\nVAR4, VAR27, VAR7->VAR5, VAR7) < 0)\ngoto VAR101;\nVAR96->VAR4 += VAR27;\nFUN42(&FUN26(VAR7)->VAR102[VAR94 - 1], VAR27);\nVAR7->VAR5 += VAR27;\nVAR7->VAR103 += VAR27;\nVAR7->VAR104 += VAR27;\nFUN43(VAR27, &VAR1->VAR83);\n}\nVAR4 += VAR27;\nVAR8 -= VAR27;\n}\nreturn 0;\nVAR101:\nVAR28 = -VAR92;\nVAR72:\nVAR19->VAR8 -= VAR8;\nFUN44(FUN45(VAR1), VAR14->VAR105, VAR106);\nreturn VAR28;\n}\n",
      "code_after_change_raw": "int ip6_append_data(struct sock *sk, int getfrag(void *from, char *to,\nint offset, int len, int odd, struct sk_buff *skb),\nvoid *from, int length, int transhdrlen,\nint hlimit, int tclass, struct ipv6_txoptions *opt, struct flowi6 *fl6,\nstruct rt6_info *rt, unsigned int flags, int dontfrag)\n{\nstruct inet_sock *inet = inet_sk(sk);\nstruct ipv6_pinfo *np = inet6_sk(sk);\nstruct inet_cork *cork;\nstruct sk_buff *skb, *skb_prev = NULL;\nunsigned int maxfraglen, fragheaderlen, mtu;\nint exthdrlen;\nint dst_exthdrlen;\nint hh_len;\nint copy;\nint err;\nint offset = 0;\n__u8 tx_flags = 0;\nif (flags&MSG_PROBE)\nreturn 0;\ncork = &inet->cork.base;\nif (skb_queue_empty(&sk->sk_write_queue)) {\nif (opt) {\nif (WARN_ON(np->cork.opt))\nreturn -EINVAL;\nnp->cork.opt = kzalloc(opt->tot_len, sk->sk_allocation);\nif (unlikely(np->cork.opt == NULL))\nreturn -ENOBUFS;\nnp->cork.opt->tot_len = opt->tot_len;\nnp->cork.opt->opt_flen = opt->opt_flen;\nnp->cork.opt->opt_nflen = opt->opt_nflen;\nnp->cork.opt->dst0opt = ip6_opt_dup(opt->dst0opt,\nsk->sk_allocation);\nif (opt->dst0opt && !np->cork.opt->dst0opt)\nreturn -ENOBUFS;\nnp->cork.opt->dst1opt = ip6_opt_dup(opt->dst1opt,\nsk->sk_allocation);\nif (opt->dst1opt && !np->cork.opt->dst1opt)\nreturn -ENOBUFS;\nnp->cork.opt->hopopt = ip6_opt_dup(opt->hopopt,\nsk->sk_allocation);\nif (opt->hopopt && !np->cork.opt->hopopt)\nreturn -ENOBUFS;\nnp->cork.opt->srcrt = ip6_rthdr_dup(opt->srcrt,\nsk->sk_allocation);\nif (opt->srcrt && !np->cork.opt->srcrt)\nreturn -ENOBUFS;\n}\ndst_hold(&rt->dst);\ncork->dst = &rt->dst;\ninet->cork.fl.u.ip6 = *fl6;\nnp->cork.hop_limit = hlimit;\nnp->cork.tclass = tclass;\nif (rt->dst.flags & DST_XFRM_TUNNEL)\nmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\nrt->dst.dev->mtu : dst_mtu(&rt->dst);\nelse\nmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\nrt->dst.dev->mtu : dst_mtu(rt->dst.path);\nif (np->frag_size < mtu) {\nif (np->frag_size)\nmtu = np->frag_size;\n}\ncork->fragsize = mtu;\nif (dst_allfrag(rt->dst.path))\ncork->flags |= IPCORK_ALLFRAG;\ncork->length = 0;\nexthdrlen = (opt ? opt->opt_flen : 0);\nlength += exthdrlen;\ntranshdrlen += exthdrlen;\ndst_exthdrlen = rt->dst.header_len - rt->rt6i_nfheader_len;\n} else {\nrt = (struct rt6_info *)cork->dst;\nfl6 = &inet->cork.fl.u.ip6;\nopt = np->cork.opt;\ntranshdrlen = 0;\nexthdrlen = 0;\ndst_exthdrlen = 0;\nmtu = cork->fragsize;\n}\nhh_len = LL_RESERVED_SPACE(rt->dst.dev);\nfragheaderlen = sizeof(struct ipv6hdr) + rt->rt6i_nfheader_len +\n(opt ? opt->opt_nflen : 0);\nmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen - sizeof(struct frag_hdr);\nif (mtu <= sizeof(struct ipv6hdr) + IPV6_MAXPLEN) {\nif (cork->length + length > sizeof(struct ipv6hdr) + IPV6_MAXPLEN - fragheaderlen) {\nipv6_local_error(sk, EMSGSIZE, fl6, mtu-exthdrlen);\nreturn -EMSGSIZE;\n}\n}\nif (sk->sk_type == SOCK_DGRAM)\nsock_tx_timestamp(sk, &tx_flags);\nif ((length > mtu) && dontfrag && (sk->sk_protocol == IPPROTO_UDP ||\nsk->sk_protocol == IPPROTO_RAW)) {\nipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);\nreturn -EMSGSIZE;\n}\nskb = skb_peek_tail(&sk->sk_write_queue);\ncork->length += length;\nif (((length > mtu) ||\n(skb && skb_is_gso(skb))) &&\n(sk->sk_protocol == IPPROTO_UDP) &&\n(rt->dst.dev->features & NETIF_F_UFO)) {\nerr = ip6_ufo_append_data(sk, getfrag, from, length,\nhh_len, fragheaderlen,\ntranshdrlen, mtu, flags, rt);\nif (err)\ngoto error;\nreturn 0;\n}\nif (!skb)\ngoto alloc_new_skb;\nwhile (length > 0) {\ncopy = (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - skb->len;\nif (copy < length)\ncopy = maxfraglen - skb->len;\nif (copy <= 0) {\nchar *data;\nunsigned int datalen;\nunsigned int fraglen;\nunsigned int fraggap;\nunsigned int alloclen;\nalloc_new_skb:\nif (skb)\nfraggap = skb->len - maxfraglen;\nelse\nfraggap = 0;\nif (skb == NULL || skb_prev == NULL)\nip6_append_data_mtu(&mtu, &maxfraglen,\nfragheaderlen, skb, rt,\nnp->pmtudisc ==\nIPV6_PMTUDISC_PROBE);\nskb_prev = skb;\ndatalen = length + fraggap;\nif (datalen > (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - fragheaderlen)\ndatalen = maxfraglen - fragheaderlen - rt->dst.trailer_len;\nif ((flags & MSG_MORE) &&\n!(rt->dst.dev->features&NETIF_F_SG))\nalloclen = mtu;\nelse\nalloclen = datalen + fragheaderlen;\nalloclen += dst_exthdrlen;\nif (datalen != length + fraggap) {\ndatalen += rt->dst.trailer_len;\n}\nalloclen += rt->dst.trailer_len;\nfraglen = datalen + fragheaderlen;\nalloclen += sizeof(struct frag_hdr);\nif (transhdrlen) {\nskb = sock_alloc_send_skb(sk,\nalloclen + hh_len,\n(flags & MSG_DONTWAIT), &err);\n} else {\nskb = NULL;\nif (atomic_read(&sk->sk_wmem_alloc) <=\n2 * sk->sk_sndbuf)\nskb = sock_wmalloc(sk,\nalloclen + hh_len, 1,\nsk->sk_allocation);\nif (unlikely(skb == NULL))\nerr = -ENOBUFS;\nelse {\ntx_flags = 0;\n}\n}\nif (skb == NULL)\ngoto error;\nskb->protocol = htons(ETH_P_IPV6);\nskb->ip_summed = CHECKSUM_NONE;\nskb->csum = 0;\nskb_reserve(skb, hh_len + sizeof(struct frag_hdr) +\ndst_exthdrlen);\nif (sk->sk_type == SOCK_DGRAM)\nskb_shinfo(skb)->tx_flags = tx_flags;\ndata = skb_put(skb, fraglen);\nskb_set_network_header(skb, exthdrlen);\ndata += fragheaderlen;\nskb->transport_header = (skb->network_header +\nfragheaderlen);\nif (fraggap) {\nskb->csum = skb_copy_and_csum_bits(\nskb_prev, maxfraglen,\ndata + transhdrlen, fraggap, 0);\nskb_prev->csum = csum_sub(skb_prev->csum,\nskb->csum);\ndata += fraggap;\npskb_trim_unique(skb_prev, maxfraglen);\n}\ncopy = datalen - transhdrlen - fraggap;\nif (copy < 0) {\nerr = -EINVAL;\nkfree_skb(skb);\ngoto error;\n} else if (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\nerr = -EFAULT;\nkfree_skb(skb);\ngoto error;\n}\noffset += copy;\nlength -= datalen - fraggap;\ntranshdrlen = 0;\nexthdrlen = 0;\ndst_exthdrlen = 0;\n__skb_queue_tail(&sk->sk_write_queue, skb);\ncontinue;\n}\nif (copy > length)\ncopy = length;\nif (!(rt->dst.dev->features&NETIF_F_SG)) {\nunsigned int off;\noff = skb->len;\nif (getfrag(from, skb_put(skb, copy),\noffset, copy, off, skb) < 0) {\n__skb_trim(skb, off);\nerr = -EFAULT;\ngoto error;\n}\n} else {\nint i = skb_shinfo(skb)->nr_frags;\nstruct page_frag *pfrag = sk_page_frag(sk);\nerr = -ENOMEM;\nif (!sk_page_frag_refill(sk, pfrag))\ngoto error;\nif (!skb_can_coalesce(skb, i, pfrag->page,\npfrag->offset)) {\nerr = -EMSGSIZE;\nif (i == MAX_SKB_FRAGS)\ngoto error;\n__skb_fill_page_desc(skb, i, pfrag->page,\npfrag->offset, 0);\nskb_shinfo(skb)->nr_frags = ++i;\nget_page(pfrag->page);\n}\ncopy = min_t(int, copy, pfrag->size - pfrag->offset);\nif (getfrag(from,\npage_address(pfrag->page) + pfrag->offset,\noffset, copy, skb->len, skb) < 0)\ngoto error_efault;\npfrag->offset += copy;\nskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\nskb->len += copy;\nskb->data_len += copy;\nskb->truesize += copy;\natomic_add(copy, &sk->sk_wmem_alloc);\n}\noffset += copy;\nlength -= copy;\n}\nreturn 0;\nerror_efault:\nerr = -EFAULT;\nerror:\ncork->length -= length;\nIP6_INC_STATS(sock_net(sk), rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);\nreturn err;\n}\n",
      "code_before_change_raw": "int ip6_append_data(struct sock *sk, int getfrag(void *from, char *to,\nint offset, int len, int odd, struct sk_buff *skb),\nvoid *from, int length, int transhdrlen,\nint hlimit, int tclass, struct ipv6_txoptions *opt, struct flowi6 *fl6,\nstruct rt6_info *rt, unsigned int flags, int dontfrag)\n{\nstruct inet_sock *inet = inet_sk(sk);\nstruct ipv6_pinfo *np = inet6_sk(sk);\nstruct inet_cork *cork;\nstruct sk_buff *skb, *skb_prev = NULL;\nunsigned int maxfraglen, fragheaderlen, mtu;\nint exthdrlen;\nint dst_exthdrlen;\nint hh_len;\nint copy;\nint err;\nint offset = 0;\n__u8 tx_flags = 0;\nif (flags&MSG_PROBE)\nreturn 0;\ncork = &inet->cork.base;\nif (skb_queue_empty(&sk->sk_write_queue)) {\nif (opt) {\nif (WARN_ON(np->cork.opt))\nreturn -EINVAL;\nnp->cork.opt = kzalloc(opt->tot_len, sk->sk_allocation);\nif (unlikely(np->cork.opt == NULL))\nreturn -ENOBUFS;\nnp->cork.opt->tot_len = opt->tot_len;\nnp->cork.opt->opt_flen = opt->opt_flen;\nnp->cork.opt->opt_nflen = opt->opt_nflen;\nnp->cork.opt->dst0opt = ip6_opt_dup(opt->dst0opt,\nsk->sk_allocation);\nif (opt->dst0opt && !np->cork.opt->dst0opt)\nreturn -ENOBUFS;\nnp->cork.opt->dst1opt = ip6_opt_dup(opt->dst1opt,\nsk->sk_allocation);\nif (opt->dst1opt && !np->cork.opt->dst1opt)\nreturn -ENOBUFS;\nnp->cork.opt->hopopt = ip6_opt_dup(opt->hopopt,\nsk->sk_allocation);\nif (opt->hopopt && !np->cork.opt->hopopt)\nreturn -ENOBUFS;\nnp->cork.opt->srcrt = ip6_rthdr_dup(opt->srcrt,\nsk->sk_allocation);\nif (opt->srcrt && !np->cork.opt->srcrt)\nreturn -ENOBUFS;\n}\ndst_hold(&rt->dst);\ncork->dst = &rt->dst;\ninet->cork.fl.u.ip6 = *fl6;\nnp->cork.hop_limit = hlimit;\nnp->cork.tclass = tclass;\nif (rt->dst.flags & DST_XFRM_TUNNEL)\nmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\nrt->dst.dev->mtu : dst_mtu(&rt->dst);\nelse\nmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\nrt->dst.dev->mtu : dst_mtu(rt->dst.path);\nif (np->frag_size < mtu) {\nif (np->frag_size)\nmtu = np->frag_size;\n}\ncork->fragsize = mtu;\nif (dst_allfrag(rt->dst.path))\ncork->flags |= IPCORK_ALLFRAG;\ncork->length = 0;\nexthdrlen = (opt ? opt->opt_flen : 0);\nlength += exthdrlen;\ntranshdrlen += exthdrlen;\ndst_exthdrlen = rt->dst.header_len - rt->rt6i_nfheader_len;\n} else {\nrt = (struct rt6_info *)cork->dst;\nfl6 = &inet->cork.fl.u.ip6;\nopt = np->cork.opt;\ntranshdrlen = 0;\nexthdrlen = 0;\ndst_exthdrlen = 0;\nmtu = cork->fragsize;\n}\nhh_len = LL_RESERVED_SPACE(rt->dst.dev);\nfragheaderlen = sizeof(struct ipv6hdr) + rt->rt6i_nfheader_len +\n(opt ? opt->opt_nflen : 0);\nmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen - sizeof(struct frag_hdr);\nif (mtu <= sizeof(struct ipv6hdr) + IPV6_MAXPLEN) {\nif (cork->length + length > sizeof(struct ipv6hdr) + IPV6_MAXPLEN - fragheaderlen) {\nipv6_local_error(sk, EMSGSIZE, fl6, mtu-exthdrlen);\nreturn -EMSGSIZE;\n}\n}\nif (sk->sk_type == SOCK_DGRAM)\nsock_tx_timestamp(sk, &tx_flags);\ncork->length += length;\nif (length > mtu) {\nint proto = sk->sk_protocol;\nif (dontfrag && (proto == IPPROTO_UDP || proto == IPPROTO_RAW)){\nipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);\nreturn -EMSGSIZE;\n}\nif (proto == IPPROTO_UDP &&\n(rt->dst.dev->features & NETIF_F_UFO)) {\nerr = ip6_ufo_append_data(sk, getfrag, from, length,\nhh_len, fragheaderlen,\ntranshdrlen, mtu, flags, rt);\nif (err)\ngoto error;\nreturn 0;\n}\n}\nif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL)\ngoto alloc_new_skb;\nwhile (length > 0) {\ncopy = (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - skb->len;\nif (copy < length)\ncopy = maxfraglen - skb->len;\nif (copy <= 0) {\nchar *data;\nunsigned int datalen;\nunsigned int fraglen;\nunsigned int fraggap;\nunsigned int alloclen;\nalloc_new_skb:\nif (skb)\nfraggap = skb->len - maxfraglen;\nelse\nfraggap = 0;\nif (skb == NULL || skb_prev == NULL)\nip6_append_data_mtu(&mtu, &maxfraglen,\nfragheaderlen, skb, rt,\nnp->pmtudisc ==\nIPV6_PMTUDISC_PROBE);\nskb_prev = skb;\ndatalen = length + fraggap;\nif (datalen > (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - fragheaderlen)\ndatalen = maxfraglen - fragheaderlen - rt->dst.trailer_len;\nif ((flags & MSG_MORE) &&\n!(rt->dst.dev->features&NETIF_F_SG))\nalloclen = mtu;\nelse\nalloclen = datalen + fragheaderlen;\nalloclen += dst_exthdrlen;\nif (datalen != length + fraggap) {\ndatalen += rt->dst.trailer_len;\n}\nalloclen += rt->dst.trailer_len;\nfraglen = datalen + fragheaderlen;\nalloclen += sizeof(struct frag_hdr);\nif (transhdrlen) {\nskb = sock_alloc_send_skb(sk,\nalloclen + hh_len,\n(flags & MSG_DONTWAIT), &err);\n} else {\nskb = NULL;\nif (atomic_read(&sk->sk_wmem_alloc) <=\n2 * sk->sk_sndbuf)\nskb = sock_wmalloc(sk,\nalloclen + hh_len, 1,\nsk->sk_allocation);\nif (unlikely(skb == NULL))\nerr = -ENOBUFS;\nelse {\ntx_flags = 0;\n}\n}\nif (skb == NULL)\ngoto error;\nskb->protocol = htons(ETH_P_IPV6);\nskb->ip_summed = CHECKSUM_NONE;\nskb->csum = 0;\nskb_reserve(skb, hh_len + sizeof(struct frag_hdr) +\ndst_exthdrlen);\nif (sk->sk_type == SOCK_DGRAM)\nskb_shinfo(skb)->tx_flags = tx_flags;\ndata = skb_put(skb, fraglen);\nskb_set_network_header(skb, exthdrlen);\ndata += fragheaderlen;\nskb->transport_header = (skb->network_header +\nfragheaderlen);\nif (fraggap) {\nskb->csum = skb_copy_and_csum_bits(\nskb_prev, maxfraglen,\ndata + transhdrlen, fraggap, 0);\nskb_prev->csum = csum_sub(skb_prev->csum,\nskb->csum);\ndata += fraggap;\npskb_trim_unique(skb_prev, maxfraglen);\n}\ncopy = datalen - transhdrlen - fraggap;\nif (copy < 0) {\nerr = -EINVAL;\nkfree_skb(skb);\ngoto error;\n} else if (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\nerr = -EFAULT;\nkfree_skb(skb);\ngoto error;\n}\noffset += copy;\nlength -= datalen - fraggap;\ntranshdrlen = 0;\nexthdrlen = 0;\ndst_exthdrlen = 0;\n__skb_queue_tail(&sk->sk_write_queue, skb);\ncontinue;\n}\nif (copy > length)\ncopy = length;\nif (!(rt->dst.dev->features&NETIF_F_SG)) {\nunsigned int off;\noff = skb->len;\nif (getfrag(from, skb_put(skb, copy),\noffset, copy, off, skb) < 0) {\n__skb_trim(skb, off);\nerr = -EFAULT;\ngoto error;\n}\n} else {\nint i = skb_shinfo(skb)->nr_frags;\nstruct page_frag *pfrag = sk_page_frag(sk);\nerr = -ENOMEM;\nif (!sk_page_frag_refill(sk, pfrag))\ngoto error;\nif (!skb_can_coalesce(skb, i, pfrag->page,\npfrag->offset)) {\nerr = -EMSGSIZE;\nif (i == MAX_SKB_FRAGS)\ngoto error;\n__skb_fill_page_desc(skb, i, pfrag->page,\npfrag->offset, 0);\nskb_shinfo(skb)->nr_frags = ++i;\nget_page(pfrag->page);\n}\ncopy = min_t(int, copy, pfrag->size - pfrag->offset);\nif (getfrag(from,\npage_address(pfrag->page) + pfrag->offset,\noffset, copy, skb->len, skb) < 0)\ngoto error_efault;\npfrag->offset += copy;\nskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\nskb->len += copy;\nskb->data_len += copy;\nskb->truesize += copy;\natomic_add(copy, &sk->sk_wmem_alloc);\n}\noffset += copy;\nlength -= copy;\n}\nreturn 0;\nerror_efault:\nerr = -EFAULT;\nerror:\ncork->length -= length;\nIP6_INC_STATS(sock_net(sk), rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);\nreturn err;\n}\n"
    }
  ],
  "CVE-2013-4512": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of size validation for user-provided input buffer during a write operation, allowing potential buffer overflow.",
        "trigger_condition": "A local user with root privileges performs a write operation with a buffer size larger than the destination buffer size, leading to a buffer overflow vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code copies user-provided data to a fixed-size buffer without validating the size of the input data, potentially causing a buffer overflow if the input size exceeds the buffer size."
      },
      "solution": "To mitigate the vulnerability, it is necessary to validate the size of the user-provided input buffer before copying data to the destination buffer. By limiting the amount of data copied to the destination buffer based on the minimum of the input size and the destination buffer size, the code prevents buffer overflow vulnerabilities. In this case, the solution involves adding size validation by calculating the minimum of the input size and the destination buffer size and using this size as the limit for copying data.",
      "GPT_analysis": "The modification made to the code snippet is necessary to prevent a buffer overflow vulnerability. In the original code, the `copy_from_user` function copies `count` bytes from the user-provided buffer to the `buf` array without checking if `count` exceeds the size of `buf`. This can lead to a buffer overflow if `count` is larger than the size of `buf`, potentially causing a denial of service or other unspecified impacts.\n\nBy adding the line `size = min(count, sizeof(buf));` and using `size` as the limit for the `copy_from_user` function, the modified code ensures that only a safe amount of data is copied to `buf`, preventing a buffer overflow vulnerability. This way, the code is more secure and less susceptible to exploitation by malicious users.",
      "GPT_purpose": "Write the exit code value to a specific kernel file for the User-Mode Linux (UML) kernel.",
      "GPT_function": "\n1. Writes data to the exitcode file in the Linux kernel.\n2. Copies data from user space to kernel space.\n3. Converts the copied data to an integer and assigns it to uml_exitcode.",
      "CVE_id": "CVE-2013-4512",
      "code_before_change": "static ssize_t exitcode_proc_write(struct file *file,\n\t\tconst char __user *buffer, size_t count, loff_t *pos)\n{\n\tchar *end, buf[sizeof(\"nnnnn\\0\")];\n\tint tmp;\n\n\tif (copy_from_user(buf, buffer, count))\n\t\treturn -EFAULT;\n\n\ttmp = simple_strtol(buf, &end, 0);\n\tif ((*end != '\\0') && !isspace(*end))\n\t\treturn -EINVAL;\n\n\tuml_exitcode = tmp;\n\treturn count;\n}",
      "code_after_change": "static ssize_t exitcode_proc_write(struct file *file,\n\t\tconst char __user *buffer, size_t count, loff_t *pos)\n{\n\tchar *end, buf[sizeof(\"nnnnn\\0\")];\n\tsize_t size;\n\tint tmp;\n\n\tsize = min(count, sizeof(buf));\n\tif (copy_from_user(buf, buffer, size))\n\t\treturn -EFAULT;\n\n\ttmp = simple_strtol(buf, &end, 0);\n\tif ((*end != '\\0') && !isspace(*end))\n\t\treturn -EINVAL;\n\n\tuml_exitcode = tmp;\n\treturn count;\n}",
      "modified_lines": {
        "added": [
          "\tsize_t size;",
          "\tsize = min(count, sizeof(buf));",
          "\tif (copy_from_user(buf, buffer, size))"
        ],
        "deleted": [
          "\tif (copy_from_user(buf, buffer, count))"
        ]
      },
      "preconditions_for_vulnerability": "Lack of size validation for user-provided input buffer during a write operation, allowing potential buffer overflow.",
      "trigger_condition": "A local user with root privileges performs a write operation with a buffer size larger than the destination buffer size, leading to a buffer overflow vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code copies user-provided data to a fixed-size buffer without validating the size of the input data, potentially causing a buffer overflow if the input size exceeds the buffer size.",
      "id": 41,
      "code_after_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1,\nconst char __user *VAR2, size_t VAR3, loff_t *VAR4)\n{\nchar *VAR5, VAR6[sizeof(\"STR\")];\nsize_t VAR7;\nint VAR8;\nVAR7 = FUN2(VAR3, sizeof(VAR6));\nif (FUN3(VAR6, VAR2, VAR7))\nreturn -VAR9;\nVAR8 = FUN4(VAR6, &VAR5, 0);\nif ((*VAR5 != ) && !FUN5(*VAR5))\nreturn -VAR10;\nVAR11 = VAR8;\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1,\nconst char __user *VAR2, size_t VAR3, loff_t *VAR4)\n{\nchar *VAR5, VAR6[sizeof(\"STR\")];\nint VAR7;\nif (FUN2(VAR6, VAR2, VAR3))\nreturn -VAR8;\nVAR7 = FUN3(VAR6, &VAR5, 0);\nif ((*VAR5 != ) && !FUN4(*VAR5))\nreturn -VAR9;\nVAR10 = VAR7;\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static ssize_t exitcode_proc_write(struct file *file,\nconst char __user *buffer, size_t count, loff_t *pos)\n{\nchar *end, buf[sizeof(\"nnnnn\\0\")];\nsize_t size;\nint tmp;\nsize = min(count, sizeof(buf));\nif (copy_from_user(buf, buffer, size))\nreturn -EFAULT;\ntmp = simple_strtol(buf, &end, 0);\nif ((*end != '\\0') && !isspace(*end))\nreturn -EINVAL;\numl_exitcode = tmp;\nreturn count;\n}\n",
      "code_before_change_raw": "static ssize_t exitcode_proc_write(struct file *file,\nconst char __user *buffer, size_t count, loff_t *pos)\n{\nchar *end, buf[sizeof(\"nnnnn\\0\")];\nint tmp;\nif (copy_from_user(buf, buffer, count))\nreturn -EFAULT;\ntmp = simple_strtol(buf, &end, 0);\nif ((*end != '\\0') && !isspace(*end))\nreturn -EINVAL;\numl_exitcode = tmp;\nreturn count;\n}\n"
    }
  ],
  "CVE-2013-4513": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of bounds checking on the input data size during a write operation.",
        "trigger_condition": "A local user sends a crafted write operation with a data size that exceeds the available buffer space, leading to a buffer overflow vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not verify that the size of the data being written does not exceed the available buffer space, allowing a potential buffer overflow if the input data size is not properly checked."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a bounds checking condition to ensure that the size of the data being written does not exceed the available buffer space. By checking the input data size against the buffer capacity before writing, the code can prevent buffer overflow vulnerabilities. In this case, the solution involves adding a check to verify that the data size does not exceed the available buffer space before proceeding with the write operation.",
      "GPT_analysis": "The modification in the code snippet is necessary to prevent a buffer overflow vulnerability in the oz_cdev_write function. The vulnerability arises from the potential for a crafted write operation to cause a buffer overflow, leading to a denial of service or other unspecified impacts.\n\nThe added check `if (count > sizeof(ei->data) - sizeof(*elt) - sizeof(*app_hdr))` ensures that the `count` parameter does not exceed the available space in the `ei->data` buffer. By checking the size of the data being written against the available buffer size, the modification helps prevent buffer overflow by rejecting writes that would exceed the buffer's capacity.\n\nBy adding this check, the code ensures that only valid and safe write operations are allowed, reducing the risk of exploitation through buffer overflow attacks.",
      "GPT_purpose": "Write data to a character device associated with a specific oz_pd structure in the Linux kernel.",
      "GPT_function": "\n1. Write data to a character device file.\n2. Allocate memory for an element info structure.\n3. Copy data from user space to kernel space.\n4. Update sequence number and queue element information.\n5. Free allocated memory for element info structure.",
      "CVE_id": "CVE-2013-4513",
      "code_before_change": "static ssize_t oz_cdev_write(struct file *filp, const char __user *buf,\n\t\tsize_t count, loff_t *fpos)\n{\n\tstruct oz_pd *pd;\n\tstruct oz_elt_buf *eb;\n\tstruct oz_elt_info *ei;\n\tstruct oz_elt *elt;\n\tstruct oz_app_hdr *app_hdr;\n\tstruct oz_serial_ctx *ctx;\n\n\tspin_lock_bh(&g_cdev.lock);\n\tpd = g_cdev.active_pd;\n\tif (pd)\n\t\toz_pd_get(pd);\n\tspin_unlock_bh(&g_cdev.lock);\n\tif (pd == NULL)\n\t\treturn -ENXIO;\n\tif (!(pd->state & OZ_PD_S_CONNECTED))\n\t\treturn -EAGAIN;\n\teb = &pd->elt_buff;\n\tei = oz_elt_info_alloc(eb);\n\tif (ei == NULL) {\n\t\tcount = 0;\n\t\tgoto out;\n\t}\n\telt = (struct oz_elt *)ei->data;\n\tapp_hdr = (struct oz_app_hdr *)(elt+1);\n\telt->length = sizeof(struct oz_app_hdr) + count;\n\telt->type = OZ_ELT_APP_DATA;\n\tei->app_id = OZ_APPID_SERIAL;\n\tei->length = elt->length + sizeof(struct oz_elt);\n\tapp_hdr->app_id = OZ_APPID_SERIAL;\n\tif (copy_from_user(app_hdr+1, buf, count))\n\t\tgoto out;\n\tspin_lock_bh(&pd->app_lock[OZ_APPID_USB-1]);\n\tctx = (struct oz_serial_ctx *)pd->app_ctx[OZ_APPID_SERIAL-1];\n\tif (ctx) {\n\t\tapp_hdr->elt_seq_num = ctx->tx_seq_num++;\n\t\tif (ctx->tx_seq_num == 0)\n\t\t\tctx->tx_seq_num = 1;\n\t\tspin_lock(&eb->lock);\n\t\tif (oz_queue_elt_info(eb, 0, 0, ei) == 0)\n\t\t\tei = NULL;\n\t\tspin_unlock(&eb->lock);\n\t}\n\tspin_unlock_bh(&pd->app_lock[OZ_APPID_USB-1]);\nout:\n\tif (ei) {\n\t\tcount = 0;\n\t\tspin_lock_bh(&eb->lock);\n\t\toz_elt_info_free(eb, ei);\n\t\tspin_unlock_bh(&eb->lock);\n\t}\n\toz_pd_put(pd);\n\treturn count;\n}",
      "code_after_change": "static ssize_t oz_cdev_write(struct file *filp, const char __user *buf,\n\t\tsize_t count, loff_t *fpos)\n{\n\tstruct oz_pd *pd;\n\tstruct oz_elt_buf *eb;\n\tstruct oz_elt_info *ei;\n\tstruct oz_elt *elt;\n\tstruct oz_app_hdr *app_hdr;\n\tstruct oz_serial_ctx *ctx;\n\n\tif (count > sizeof(ei->data) - sizeof(*elt) - sizeof(*app_hdr))\n\t\treturn -EINVAL;\n\n\tspin_lock_bh(&g_cdev.lock);\n\tpd = g_cdev.active_pd;\n\tif (pd)\n\t\toz_pd_get(pd);\n\tspin_unlock_bh(&g_cdev.lock);\n\tif (pd == NULL)\n\t\treturn -ENXIO;\n\tif (!(pd->state & OZ_PD_S_CONNECTED))\n\t\treturn -EAGAIN;\n\teb = &pd->elt_buff;\n\tei = oz_elt_info_alloc(eb);\n\tif (ei == NULL) {\n\t\tcount = 0;\n\t\tgoto out;\n\t}\n\telt = (struct oz_elt *)ei->data;\n\tapp_hdr = (struct oz_app_hdr *)(elt+1);\n\telt->length = sizeof(struct oz_app_hdr) + count;\n\telt->type = OZ_ELT_APP_DATA;\n\tei->app_id = OZ_APPID_SERIAL;\n\tei->length = elt->length + sizeof(struct oz_elt);\n\tapp_hdr->app_id = OZ_APPID_SERIAL;\n\tif (copy_from_user(app_hdr+1, buf, count))\n\t\tgoto out;\n\tspin_lock_bh(&pd->app_lock[OZ_APPID_USB-1]);\n\tctx = (struct oz_serial_ctx *)pd->app_ctx[OZ_APPID_SERIAL-1];\n\tif (ctx) {\n\t\tapp_hdr->elt_seq_num = ctx->tx_seq_num++;\n\t\tif (ctx->tx_seq_num == 0)\n\t\t\tctx->tx_seq_num = 1;\n\t\tspin_lock(&eb->lock);\n\t\tif (oz_queue_elt_info(eb, 0, 0, ei) == 0)\n\t\t\tei = NULL;\n\t\tspin_unlock(&eb->lock);\n\t}\n\tspin_unlock_bh(&pd->app_lock[OZ_APPID_USB-1]);\nout:\n\tif (ei) {\n\t\tcount = 0;\n\t\tspin_lock_bh(&eb->lock);\n\t\toz_elt_info_free(eb, ei);\n\t\tspin_unlock_bh(&eb->lock);\n\t}\n\toz_pd_put(pd);\n\treturn count;\n}",
      "modified_lines": {
        "added": [
          "",
          "\tif (count > sizeof(ei->data) - sizeof(*elt) - sizeof(*app_hdr))",
          "\t\treturn -EINVAL;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of bounds checking on the input data size during a write operation.",
      "trigger_condition": "A local user sends a crafted write operation with a data size that exceeds the available buffer space, leading to a buffer overflow vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not verify that the size of the data being written does not exceed the available buffer space, allowing a potential buffer overflow if the input data size is not properly checked.",
      "id": 42,
      "code_after_change_normalized": "static ssize_t FUN1(struct file *VAR1, const char __user *VAR2,\nsize_t VAR3, loff_t *VAR4)\n{\nstruct oz_pd *VAR5;\nstruct oz_elt_buf *VAR6;\nstruct oz_elt_info *VAR7;\nstruct oz_elt *VAR8;\nstruct oz_app_hdr *VAR9;\nstruct oz_serial_ctx *VAR10;\nif (VAR3 > sizeof(VAR7->VAR11) - sizeof(*VAR8) - sizeof(*VAR9))\nreturn -VAR12;\nFUN2(&VAR13.VAR14);\nVAR5 = VAR13.VAR15;\nif (VAR5)\nFUN3(VAR5);\nFUN4(&VAR13.VAR14);\nif (VAR5 == NULL)\nreturn -VAR16;\nif (!(VAR5->VAR17 & VAR18))\nreturn -VAR19;\nVAR6 = &VAR5->VAR20;\nVAR7 = FUN5(VAR6);\nif (VAR7 == NULL) {\nVAR3 = 0;\ngoto VAR21;\n}\nVAR8 = (struct VAR22 *)VAR7->VAR11;\nVAR9 = (struct VAR23 *)(VAR8+1);\nVAR8->VAR24 = sizeof(struct VAR23) + VAR3;\nVAR8->VAR25 = VAR26;\nVAR7->VAR27 = VAR28;\nVAR7->VAR24 = VAR8->VAR24 + sizeof(struct VAR22);\nVAR9->VAR27 = VAR28;\nif (FUN6(VAR9+1, VAR2, VAR3))\ngoto VAR21;\nFUN2(&VAR5->VAR29[VAR30-1]);\nVAR10 = (struct VAR31 *)VAR5->VAR32[VAR28-1];\nif (VAR10) {\nVAR9->VAR33 = VAR10->VAR34++;\nif (VAR10->VAR34 == 0)\nVAR10->VAR34 = 1;\nFUN7(&VAR6->VAR14);\nif (FUN8(VAR6, 0, 0, VAR7) == 0)\nVAR7 = NULL;\nFUN9(&VAR6->VAR14);\n}\nFUN4(&VAR5->VAR29[VAR30-1]);\nVAR21:\nif (VAR7) {\nVAR3 = 0;\nFUN2(&VAR6->VAR14);\nFUN10(VAR6, VAR7);\nFUN4(&VAR6->VAR14);\n}\nFUN11(VAR5);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct file *VAR1, const char __user *VAR2,\nsize_t VAR3, loff_t *VAR4)\n{\nstruct oz_pd *VAR5;\nstruct oz_elt_buf *VAR6;\nstruct oz_elt_info *VAR7;\nstruct oz_elt *VAR8;\nstruct oz_app_hdr *VAR9;\nstruct oz_serial_ctx *VAR10;\nFUN2(&VAR11.VAR12);\nVAR5 = VAR11.VAR13;\nif (VAR5)\nFUN3(VAR5);\nFUN4(&VAR11.VAR12);\nif (VAR5 == NULL)\nreturn -VAR14;\nif (!(VAR5->VAR15 & VAR16))\nreturn -VAR17;\nVAR6 = &VAR5->VAR18;\nVAR7 = FUN5(VAR6);\nif (VAR7 == NULL) {\nVAR3 = 0;\ngoto VAR19;\n}\nVAR8 = (struct VAR20 *)VAR7->VAR21;\nVAR9 = (struct VAR22 *)(VAR8+1);\nVAR8->VAR23 = sizeof(struct VAR22) + VAR3;\nVAR8->VAR24 = VAR25;\nVAR7->VAR26 = VAR27;\nVAR7->VAR23 = VAR8->VAR23 + sizeof(struct VAR20);\nVAR9->VAR26 = VAR27;\nif (FUN6(VAR9+1, VAR2, VAR3))\ngoto VAR19;\nFUN2(&VAR5->VAR28[VAR29-1]);\nVAR10 = (struct VAR30 *)VAR5->VAR31[VAR27-1];\nif (VAR10) {\nVAR9->VAR32 = VAR10->VAR33++;\nif (VAR10->VAR33 == 0)\nVAR10->VAR33 = 1;\nFUN7(&VAR6->VAR12);\nif (FUN8(VAR6, 0, 0, VAR7) == 0)\nVAR7 = NULL;\nFUN9(&VAR6->VAR12);\n}\nFUN4(&VAR5->VAR28[VAR29-1]);\nVAR19:\nif (VAR7) {\nVAR3 = 0;\nFUN2(&VAR6->VAR12);\nFUN10(VAR6, VAR7);\nFUN4(&VAR6->VAR12);\n}\nFUN11(VAR5);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static ssize_t oz_cdev_write(struct file *filp, const char __user *buf,\nsize_t count, loff_t *fpos)\n{\nstruct oz_pd *pd;\nstruct oz_elt_buf *eb;\nstruct oz_elt_info *ei;\nstruct oz_elt *elt;\nstruct oz_app_hdr *app_hdr;\nstruct oz_serial_ctx *ctx;\nif (count > sizeof(ei->data) - sizeof(*elt) - sizeof(*app_hdr))\nreturn -EINVAL;\nspin_lock_bh(&g_cdev.lock);\npd = g_cdev.active_pd;\nif (pd)\noz_pd_get(pd);\nspin_unlock_bh(&g_cdev.lock);\nif (pd == NULL)\nreturn -ENXIO;\nif (!(pd->state & OZ_PD_S_CONNECTED))\nreturn -EAGAIN;\neb = &pd->elt_buff;\nei = oz_elt_info_alloc(eb);\nif (ei == NULL) {\ncount = 0;\ngoto out;\n}\nelt = (struct oz_elt *)ei->data;\napp_hdr = (struct oz_app_hdr *)(elt+1);\nelt->length = sizeof(struct oz_app_hdr) + count;\nelt->type = OZ_ELT_APP_DATA;\nei->app_id = OZ_APPID_SERIAL;\nei->length = elt->length + sizeof(struct oz_elt);\napp_hdr->app_id = OZ_APPID_SERIAL;\nif (copy_from_user(app_hdr+1, buf, count))\ngoto out;\nspin_lock_bh(&pd->app_lock[OZ_APPID_USB-1]);\nctx = (struct oz_serial_ctx *)pd->app_ctx[OZ_APPID_SERIAL-1];\nif (ctx) {\napp_hdr->elt_seq_num = ctx->tx_seq_num++;\nif (ctx->tx_seq_num == 0)\nctx->tx_seq_num = 1;\nspin_lock(&eb->lock);\nif (oz_queue_elt_info(eb, 0, 0, ei) == 0)\nei = NULL;\nspin_unlock(&eb->lock);\n}\nspin_unlock_bh(&pd->app_lock[OZ_APPID_USB-1]);\nout:\nif (ei) {\ncount = 0;\nspin_lock_bh(&eb->lock);\noz_elt_info_free(eb, ei);\nspin_unlock_bh(&eb->lock);\n}\noz_pd_put(pd);\nreturn count;\n}\n",
      "code_before_change_raw": "static ssize_t oz_cdev_write(struct file *filp, const char __user *buf,\nsize_t count, loff_t *fpos)\n{\nstruct oz_pd *pd;\nstruct oz_elt_buf *eb;\nstruct oz_elt_info *ei;\nstruct oz_elt *elt;\nstruct oz_app_hdr *app_hdr;\nstruct oz_serial_ctx *ctx;\nspin_lock_bh(&g_cdev.lock);\npd = g_cdev.active_pd;\nif (pd)\noz_pd_get(pd);\nspin_unlock_bh(&g_cdev.lock);\nif (pd == NULL)\nreturn -ENXIO;\nif (!(pd->state & OZ_PD_S_CONNECTED))\nreturn -EAGAIN;\neb = &pd->elt_buff;\nei = oz_elt_info_alloc(eb);\nif (ei == NULL) {\ncount = 0;\ngoto out;\n}\nelt = (struct oz_elt *)ei->data;\napp_hdr = (struct oz_app_hdr *)(elt+1);\nelt->length = sizeof(struct oz_app_hdr) + count;\nelt->type = OZ_ELT_APP_DATA;\nei->app_id = OZ_APPID_SERIAL;\nei->length = elt->length + sizeof(struct oz_elt);\napp_hdr->app_id = OZ_APPID_SERIAL;\nif (copy_from_user(app_hdr+1, buf, count))\ngoto out;\nspin_lock_bh(&pd->app_lock[OZ_APPID_USB-1]);\nctx = (struct oz_serial_ctx *)pd->app_ctx[OZ_APPID_SERIAL-1];\nif (ctx) {\napp_hdr->elt_seq_num = ctx->tx_seq_num++;\nif (ctx->tx_seq_num == 0)\nctx->tx_seq_num = 1;\nspin_lock(&eb->lock);\nif (oz_queue_elt_info(eb, 0, 0, ei) == 0)\nei = NULL;\nspin_unlock(&eb->lock);\n}\nspin_unlock_bh(&pd->app_lock[OZ_APPID_USB-1]);\nout:\nif (ei) {\ncount = 0;\nspin_lock_bh(&eb->lock);\noz_elt_info_free(eb, ei);\nspin_unlock_bh(&eb->lock);\n}\noz_pd_put(pd);\nreturn count;\n}\n"
    }
  ],
  "CVE-2013-4514": [],
  "CVE-2013-4588": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper input validation and boundary checking on the 'cmd' and 'len' parameters in the do_ip_vs_set_ctl function.",
        "trigger_condition": "An attacker with CAP_NET_ADMIN capability provides malicious input values for 'cmd' and 'len', leading to buffer overflows in the stack-based 'arg' buffer.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the 'cmd' parameter to ensure it falls within the expected range of valid commands, and it does not check the 'len' parameter to ensure it is within a safe range. This lack of input validation allows an attacker to provide values that exceed buffer boundaries, leading to stack-based buffer overflows."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add input validation checks for the 'cmd' and 'len' parameters in the do_ip_vs_set_ctl function. Specifically, validate that 'cmd' falls within the range of valid commands (from IP_VS_BASE_CTL to IP_VS_SO_SET_MAX) and that 'len' is within a safe range (greater than or equal to 0 and less than or equal to MAX_ARG_LEN). By enforcing these checks, the code can prevent buffer overflows and unauthorized privilege escalation that could be achieved through malicious input values.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-4588, which involves multiple stack-based buffer overflows in the `do_ip_vs_set_ctl` function in the Linux kernel's `ip_vs_ctl.c` file. By adding the following lines of code:\n\n```c\nif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_SET_MAX)\n    return -EINVAL;\nif (len < 0 || len >  MAX_ARG_LEN)\n    return -EINVAL;\n```\n\nwe are performing additional checks on the `cmd` and `len` parameters to ensure that they fall within expected ranges. These checks help prevent potential buffer overflows that could be exploited by a local user with the `CAP_NET_ADMIN` capability, as described in the vulnerability.\n\nBy validating the `cmd` parameter against the range of valid commands and ensuring that the `len` parameter is within a safe range, we can mitigate the risk of buffer overflows and unauthorized privilege escalation that could be achieved through the vulnerable code.",
      "GPT_purpose": "Handling various IP Virtual Server (IPVS) control operations including adding, editing, deleting services and destinations, setting timeouts, starting/stopping daemons, and flushing services.",
      "GPT_function": "\n1. do_ip_vs_set_ctl\n2. ip_vs_flush\n3. ip_vs_set_timeout\n4. start_sync_thread\n5. stop_sync_thread\n6. ip_vs_zero_all\n7. ip_vs_zero_service\n8. ip_vs_add_service\n9. ip_vs_edit_service\n10. ip_vs_del_service\n11. ip_vs_add_dest\n12. ip_vs_edit_dest\n13. ip_vs_del_dest",
      "CVE_id": "CVE-2013-4588",
      "code_before_change": "static int\ndo_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\tunsigned char arg[MAX_ARG_LEN];\n\tstruct ip_vs_service_user *usvc_compat;\n\tstruct ip_vs_service_user_kern usvc;\n\tstruct ip_vs_service *svc;\n\tstruct ip_vs_dest_user *udest_compat;\n\tstruct ip_vs_dest_user_kern udest;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (len != set_arglen[SET_CMDID(cmd)]) {\n\t\tpr_err(\"set_ctl: len %u != %u\\n\",\n\t\t       len, set_arglen[SET_CMDID(cmd)]);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(arg, user, len) != 0)\n\t\treturn -EFAULT;\n\n\t/* increase the module use count */\n\tip_vs_use_count_inc();\n\n\tif (mutex_lock_interruptible(&__ip_vs_mutex)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto out_dec;\n\t}\n\n\tif (cmd == IP_VS_SO_SET_FLUSH) {\n\t\t/* Flush the virtual service */\n\t\tret = ip_vs_flush();\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_TIMEOUT) {\n\t\t/* Set timeout values for (tcp tcpfin udp) */\n\t\tret = ip_vs_set_timeout((struct ip_vs_timeout_user *)arg);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STARTDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = start_sync_thread(dm->state, dm->mcast_ifn, dm->syncid);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STOPDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = stop_sync_thread(dm->state);\n\t\tgoto out_unlock;\n\t}\n\n\tusvc_compat = (struct ip_vs_service_user *)arg;\n\tudest_compat = (struct ip_vs_dest_user *)(usvc_compat + 1);\n\n\t/* We only use the new structs internally, so copy userspace compat\n\t * structs to extended internal versions */\n\tip_vs_copy_usvc_compat(&usvc, usvc_compat);\n\tip_vs_copy_udest_compat(&udest, udest_compat);\n\n\tif (cmd == IP_VS_SO_SET_ZERO) {\n\t\t/* if no service address is set, zero counters in all */\n\t\tif (!usvc.fwmark && !usvc.addr.ip && !usvc.port) {\n\t\t\tret = ip_vs_zero_all();\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\t/* Check for valid protocol: TCP or UDP, even for fwmark!=0 */\n\tif (usvc.protocol != IPPROTO_TCP && usvc.protocol != IPPROTO_UDP) {\n\t\tpr_err(\"set_ctl: invalid protocol: %d %pI4:%d %s\\n\",\n\t\t       usvc.protocol, &usvc.addr.ip,\n\t\t       ntohs(usvc.port), usvc.sched_name);\n\t\tret = -EFAULT;\n\t\tgoto out_unlock;\n\t}\n\n\t/* Lookup the exact service by <protocol, addr, port> or fwmark */\n\tif (usvc.fwmark == 0)\n\t\tsvc = __ip_vs_service_get(usvc.af, usvc.protocol,\n\t\t\t\t\t  &usvc.addr, usvc.port);\n\telse\n\t\tsvc = __ip_vs_svc_fwm_get(usvc.af, usvc.fwmark);\n\n\tif (cmd != IP_VS_SO_SET_ADD\n\t    && (svc == NULL || svc->protocol != usvc.protocol)) {\n\t\tret = -ESRCH;\n\t\tgoto out_unlock;\n\t}\n\n\tswitch (cmd) {\n\tcase IP_VS_SO_SET_ADD:\n\t\tif (svc != NULL)\n\t\t\tret = -EEXIST;\n\t\telse\n\t\t\tret = ip_vs_add_service(&usvc, &svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDIT:\n\t\tret = ip_vs_edit_service(svc, &usvc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DEL:\n\t\tret = ip_vs_del_service(svc);\n\t\tif (!ret)\n\t\t\tgoto out_unlock;\n\t\tbreak;\n\tcase IP_VS_SO_SET_ZERO:\n\t\tret = ip_vs_zero_service(svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_ADDDEST:\n\t\tret = ip_vs_add_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDITDEST:\n\t\tret = ip_vs_edit_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DELDEST:\n\t\tret = ip_vs_del_dest(svc, &udest);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n\tif (svc)\n\t\tip_vs_service_put(svc);\n\n  out_unlock:\n\tmutex_unlock(&__ip_vs_mutex);\n  out_dec:\n\t/* decrease the module use count */\n\tip_vs_use_count_dec();\n\n\treturn ret;\n}",
      "code_after_change": "static int\ndo_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\tunsigned char arg[MAX_ARG_LEN];\n\tstruct ip_vs_service_user *usvc_compat;\n\tstruct ip_vs_service_user_kern usvc;\n\tstruct ip_vs_service *svc;\n\tstruct ip_vs_dest_user *udest_compat;\n\tstruct ip_vs_dest_user_kern udest;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_SET_MAX)\n\t\treturn -EINVAL;\n\tif (len < 0 || len >  MAX_ARG_LEN)\n\t\treturn -EINVAL;\n\tif (len != set_arglen[SET_CMDID(cmd)]) {\n\t\tpr_err(\"set_ctl: len %u != %u\\n\",\n\t\t       len, set_arglen[SET_CMDID(cmd)]);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(arg, user, len) != 0)\n\t\treturn -EFAULT;\n\n\t/* increase the module use count */\n\tip_vs_use_count_inc();\n\n\tif (mutex_lock_interruptible(&__ip_vs_mutex)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto out_dec;\n\t}\n\n\tif (cmd == IP_VS_SO_SET_FLUSH) {\n\t\t/* Flush the virtual service */\n\t\tret = ip_vs_flush();\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_TIMEOUT) {\n\t\t/* Set timeout values for (tcp tcpfin udp) */\n\t\tret = ip_vs_set_timeout((struct ip_vs_timeout_user *)arg);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STARTDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = start_sync_thread(dm->state, dm->mcast_ifn, dm->syncid);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STOPDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = stop_sync_thread(dm->state);\n\t\tgoto out_unlock;\n\t}\n\n\tusvc_compat = (struct ip_vs_service_user *)arg;\n\tudest_compat = (struct ip_vs_dest_user *)(usvc_compat + 1);\n\n\t/* We only use the new structs internally, so copy userspace compat\n\t * structs to extended internal versions */\n\tip_vs_copy_usvc_compat(&usvc, usvc_compat);\n\tip_vs_copy_udest_compat(&udest, udest_compat);\n\n\tif (cmd == IP_VS_SO_SET_ZERO) {\n\t\t/* if no service address is set, zero counters in all */\n\t\tif (!usvc.fwmark && !usvc.addr.ip && !usvc.port) {\n\t\t\tret = ip_vs_zero_all();\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\t/* Check for valid protocol: TCP or UDP, even for fwmark!=0 */\n\tif (usvc.protocol != IPPROTO_TCP && usvc.protocol != IPPROTO_UDP) {\n\t\tpr_err(\"set_ctl: invalid protocol: %d %pI4:%d %s\\n\",\n\t\t       usvc.protocol, &usvc.addr.ip,\n\t\t       ntohs(usvc.port), usvc.sched_name);\n\t\tret = -EFAULT;\n\t\tgoto out_unlock;\n\t}\n\n\t/* Lookup the exact service by <protocol, addr, port> or fwmark */\n\tif (usvc.fwmark == 0)\n\t\tsvc = __ip_vs_service_get(usvc.af, usvc.protocol,\n\t\t\t\t\t  &usvc.addr, usvc.port);\n\telse\n\t\tsvc = __ip_vs_svc_fwm_get(usvc.af, usvc.fwmark);\n\n\tif (cmd != IP_VS_SO_SET_ADD\n\t    && (svc == NULL || svc->protocol != usvc.protocol)) {\n\t\tret = -ESRCH;\n\t\tgoto out_unlock;\n\t}\n\n\tswitch (cmd) {\n\tcase IP_VS_SO_SET_ADD:\n\t\tif (svc != NULL)\n\t\t\tret = -EEXIST;\n\t\telse\n\t\t\tret = ip_vs_add_service(&usvc, &svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDIT:\n\t\tret = ip_vs_edit_service(svc, &usvc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DEL:\n\t\tret = ip_vs_del_service(svc);\n\t\tif (!ret)\n\t\t\tgoto out_unlock;\n\t\tbreak;\n\tcase IP_VS_SO_SET_ZERO:\n\t\tret = ip_vs_zero_service(svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_ADDDEST:\n\t\tret = ip_vs_add_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDITDEST:\n\t\tret = ip_vs_edit_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DELDEST:\n\t\tret = ip_vs_del_dest(svc, &udest);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n\tif (svc)\n\t\tip_vs_service_put(svc);\n\n  out_unlock:\n\tmutex_unlock(&__ip_vs_mutex);\n  out_dec:\n\t/* decrease the module use count */\n\tip_vs_use_count_dec();\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_SET_MAX)",
          "\t\treturn -EINVAL;",
          "\tif (len < 0 || len >  MAX_ARG_LEN)",
          "\t\treturn -EINVAL;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper input validation and boundary checking on the 'cmd' and 'len' parameters in the do_ip_vs_set_ctl function.",
      "trigger_condition": "An attacker with CAP_NET_ADMIN capability provides malicious input values for 'cmd' and 'len', leading to buffer overflows in the stack-based 'arg' buffer.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the 'cmd' parameter to ensure it falls within the expected range of valid commands, and it does not check the 'len' parameter to ensure it is within a safe range. This lack of input validation allows an attacker to provide values that exceed buffer boundaries, leading to stack-based buffer overflows.",
      "id": 43,
      "code_after_change_normalized": "static int\nFUN1(struct sock *VAR1, int VAR2, void __user *VAR3, unsigned int VAR4)\n{\nint VAR5;\nunsigned char VAR6[VAR7];\nstruct ip_vs_service_user *VAR8;\nstruct ip_vs_service_user_kern VAR9;\nstruct ip_vs_service *VAR10;\nstruct ip_vs_dest_user *VAR11;\nstruct ip_vs_dest_user_kern VAR12;\nif (!FUN2(VAR13))\nreturn -VAR14;\nif (VAR2 < VAR15 || VAR2 > VAR16)\nreturn -VAR17;\nif (VAR4 < 0 || VAR4 >  VAR7)\nreturn -VAR17;\nif (VAR4 != VAR18[FUN3(VAR2)]) {\nFUN4(\"STR\",\nVAR4, VAR18[FUN3(VAR2)]);\nreturn -VAR17;\n}\nif (FUN5(VAR6, VAR3, VAR4) != 0)\nreturn -VAR19;\nFUN6();\nif (FUN7(&VAR20)) {\nVAR5 = -VAR21;\ngoto VAR22;\n}\nif (VAR2 == VAR23) {\nVAR5 = FUN8();\ngoto VAR24;\n} else if (VAR2 == VAR25) {\nVAR5 = FUN9((struct VAR26 *)VAR6);\ngoto VAR24;\n} else if (VAR2 == VAR27) {\nstruct VAR29 *VAR28 = (struct VAR29 *)VAR6;\nVAR5 = FUN10(VAR28->VAR30, VAR28->VAR31, VAR28->VAR32);\ngoto VAR24;\n} else if (VAR2 == VAR33) {\nstruct VAR29 *VAR28 = (struct VAR29 *)VAR6;\nVAR5 = FUN11(VAR28->VAR30);\ngoto VAR24;\n}\nVAR8 = (struct VAR34 *)VAR6;\nVAR11 = (struct VAR35 *)(VAR8 + 1);\nFUN12(&VAR9, VAR8);\nFUN13(&VAR12, VAR11);\nif (VAR2 == VAR36) {\nif (!VAR9.VAR37 && !VAR9.VAR38.VAR39 && !VAR9.VAR40) {\nVAR5 = FUN14();\ngoto VAR24;\n}\n}\nif (VAR9.VAR41 != VAR42 && VAR9.VAR41 != VAR43) {\nFUN4(\"STR\",\nVAR9.VAR41, &VAR9.VAR38.VAR39,\nFUN15(VAR9.VAR40), VAR9.VAR44);\nVAR5 = -VAR19;\ngoto VAR24;\n}\nif (VAR9.VAR37 == 0)\nVAR10 = FUN16(VAR9.VAR45, VAR9.VAR41,\n&VAR9.VAR38, VAR9.VAR40);\nelse\nVAR10 = FUN17(VAR9.VAR45, VAR9.VAR37);\nif (VAR2 != VAR46\n&& (VAR10 == NULL || VAR10->VAR41 != VAR9.VAR41)) {\nVAR5 = -VAR47;\ngoto VAR24;\n}\nswitch (VAR2) {\ncase VAR46:\nif (VAR10 != NULL)\nVAR5 = -VAR48;\nelse\nVAR5 = FUN18(&VAR9, &VAR10);\nbreak;\ncase VAR49:\nVAR5 = FUN19(VAR10, &VAR9);\nbreak;\ncase VAR50:\nVAR5 = FUN20(VAR10);\nif (!VAR5)\ngoto VAR24;\nbreak;\ncase VAR36:\nVAR5 = FUN21(VAR10);\nbreak;\ncase VAR51:\nVAR5 = FUN22(VAR10, &VAR12);\nbreak;\ncase VAR52:\nVAR5 = FUN23(VAR10, &VAR12);\nbreak;\ncase VAR53:\nVAR5 = FUN24(VAR10, &VAR12);\nbreak;\ndefault:\nVAR5 = -VAR17;\n}\nif (VAR10)\nFUN25(VAR10);\nVAR24:\nFUN26(&VAR20);\nVAR22:\nFUN27();\nreturn VAR5;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(struct sock *VAR1, int VAR2, void __user *VAR3, unsigned int VAR4)\n{\nint VAR5;\nunsigned char VAR6[VAR7];\nstruct ip_vs_service_user *VAR8;\nstruct ip_vs_service_user_kern VAR9;\nstruct ip_vs_service *VAR10;\nstruct ip_vs_dest_user *VAR11;\nstruct ip_vs_dest_user_kern VAR12;\nif (!FUN2(VAR13))\nreturn -VAR14;\nif (VAR4 != VAR15[FUN3(VAR2)]) {\nFUN4(\"STR\",\nVAR4, VAR15[FUN3(VAR2)]);\nreturn -VAR16;\n}\nif (FUN5(VAR6, VAR3, VAR4) != 0)\nreturn -VAR17;\nFUN6();\nif (FUN7(&VAR18)) {\nVAR5 = -VAR19;\ngoto VAR20;\n}\nif (VAR2 == VAR21) {\nVAR5 = FUN8();\ngoto VAR22;\n} else if (VAR2 == VAR23) {\nVAR5 = FUN9((struct VAR24 *)VAR6);\ngoto VAR22;\n} else if (VAR2 == VAR25) {\nstruct VAR27 *VAR26 = (struct VAR27 *)VAR6;\nVAR5 = FUN10(VAR26->VAR28, VAR26->VAR29, VAR26->VAR30);\ngoto VAR22;\n} else if (VAR2 == VAR31) {\nstruct VAR27 *VAR26 = (struct VAR27 *)VAR6;\nVAR5 = FUN11(VAR26->VAR28);\ngoto VAR22;\n}\nVAR8 = (struct VAR32 *)VAR6;\nVAR11 = (struct VAR33 *)(VAR8 + 1);\nFUN12(&VAR9, VAR8);\nFUN13(&VAR12, VAR11);\nif (VAR2 == VAR34) {\nif (!VAR9.VAR35 && !VAR9.VAR36.VAR37 && !VAR9.VAR38) {\nVAR5 = FUN14();\ngoto VAR22;\n}\n}\nif (VAR9.VAR39 != VAR40 && VAR9.VAR39 != VAR41) {\nFUN4(\"STR\",\nVAR9.VAR39, &VAR9.VAR36.VAR37,\nFUN15(VAR9.VAR38), VAR9.VAR42);\nVAR5 = -VAR17;\ngoto VAR22;\n}\nif (VAR9.VAR35 == 0)\nVAR10 = FUN16(VAR9.VAR43, VAR9.VAR39,\n&VAR9.VAR36, VAR9.VAR38);\nelse\nVAR10 = FUN17(VAR9.VAR43, VAR9.VAR35);\nif (VAR2 != VAR44\n&& (VAR10 == NULL || VAR10->VAR39 != VAR9.VAR39)) {\nVAR5 = -VAR45;\ngoto VAR22;\n}\nswitch (VAR2) {\ncase VAR44:\nif (VAR10 != NULL)\nVAR5 = -VAR46;\nelse\nVAR5 = FUN18(&VAR9, &VAR10);\nbreak;\ncase VAR47:\nVAR5 = FUN19(VAR10, &VAR9);\nbreak;\ncase VAR48:\nVAR5 = FUN20(VAR10);\nif (!VAR5)\ngoto VAR22;\nbreak;\ncase VAR34:\nVAR5 = FUN21(VAR10);\nbreak;\ncase VAR49:\nVAR5 = FUN22(VAR10, &VAR12);\nbreak;\ncase VAR50:\nVAR5 = FUN23(VAR10, &VAR12);\nbreak;\ncase VAR51:\nVAR5 = FUN24(VAR10, &VAR12);\nbreak;\ndefault:\nVAR5 = -VAR16;\n}\nif (VAR10)\nFUN25(VAR10);\nVAR22:\nFUN26(&VAR18);\nVAR20:\nFUN27();\nreturn VAR5;\n}\n",
      "code_after_change_raw": "static int\ndo_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\nint ret;\nunsigned char arg[MAX_ARG_LEN];\nstruct ip_vs_service_user *usvc_compat;\nstruct ip_vs_service_user_kern usvc;\nstruct ip_vs_service *svc;\nstruct ip_vs_dest_user *udest_compat;\nstruct ip_vs_dest_user_kern udest;\nif (!capable(CAP_NET_ADMIN))\nreturn -EPERM;\nif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_SET_MAX)\nreturn -EINVAL;\nif (len < 0 || len >  MAX_ARG_LEN)\nreturn -EINVAL;\nif (len != set_arglen[SET_CMDID(cmd)]) {\npr_err(\"set_ctl: len %u != %u\\n\",\nlen, set_arglen[SET_CMDID(cmd)]);\nreturn -EINVAL;\n}\nif (copy_from_user(arg, user, len) != 0)\nreturn -EFAULT;\nip_vs_use_count_inc();\nif (mutex_lock_interruptible(&__ip_vs_mutex)) {\nret = -ERESTARTSYS;\ngoto out_dec;\n}\nif (cmd == IP_VS_SO_SET_FLUSH) {\nret = ip_vs_flush();\ngoto out_unlock;\n} else if (cmd == IP_VS_SO_SET_TIMEOUT) {\nret = ip_vs_set_timeout((struct ip_vs_timeout_user *)arg);\ngoto out_unlock;\n} else if (cmd == IP_VS_SO_SET_STARTDAEMON) {\nstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\nret = start_sync_thread(dm->state, dm->mcast_ifn, dm->syncid);\ngoto out_unlock;\n} else if (cmd == IP_VS_SO_SET_STOPDAEMON) {\nstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\nret = stop_sync_thread(dm->state);\ngoto out_unlock;\n}\nusvc_compat = (struct ip_vs_service_user *)arg;\nudest_compat = (struct ip_vs_dest_user *)(usvc_compat + 1);\nip_vs_copy_usvc_compat(&usvc, usvc_compat);\nip_vs_copy_udest_compat(&udest, udest_compat);\nif (cmd == IP_VS_SO_SET_ZERO) {\nif (!usvc.fwmark && !usvc.addr.ip && !usvc.port) {\nret = ip_vs_zero_all();\ngoto out_unlock;\n}\n}\nif (usvc.protocol != IPPROTO_TCP && usvc.protocol != IPPROTO_UDP) {\npr_err(\"set_ctl: invalid protocol: %d %pI4:%d %s\\n\",\nusvc.protocol, &usvc.addr.ip,\nntohs(usvc.port), usvc.sched_name);\nret = -EFAULT;\ngoto out_unlock;\n}\nif (usvc.fwmark == 0)\nsvc = __ip_vs_service_get(usvc.af, usvc.protocol,\n&usvc.addr, usvc.port);\nelse\nsvc = __ip_vs_svc_fwm_get(usvc.af, usvc.fwmark);\nif (cmd != IP_VS_SO_SET_ADD\n&& (svc == NULL || svc->protocol != usvc.protocol)) {\nret = -ESRCH;\ngoto out_unlock;\n}\nswitch (cmd) {\ncase IP_VS_SO_SET_ADD:\nif (svc != NULL)\nret = -EEXIST;\nelse\nret = ip_vs_add_service(&usvc, &svc);\nbreak;\ncase IP_VS_SO_SET_EDIT:\nret = ip_vs_edit_service(svc, &usvc);\nbreak;\ncase IP_VS_SO_SET_DEL:\nret = ip_vs_del_service(svc);\nif (!ret)\ngoto out_unlock;\nbreak;\ncase IP_VS_SO_SET_ZERO:\nret = ip_vs_zero_service(svc);\nbreak;\ncase IP_VS_SO_SET_ADDDEST:\nret = ip_vs_add_dest(svc, &udest);\nbreak;\ncase IP_VS_SO_SET_EDITDEST:\nret = ip_vs_edit_dest(svc, &udest);\nbreak;\ncase IP_VS_SO_SET_DELDEST:\nret = ip_vs_del_dest(svc, &udest);\nbreak;\ndefault:\nret = -EINVAL;\n}\nif (svc)\nip_vs_service_put(svc);\nout_unlock:\nmutex_unlock(&__ip_vs_mutex);\nout_dec:\nip_vs_use_count_dec();\nreturn ret;\n}\n",
      "code_before_change_raw": "static int\ndo_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\nint ret;\nunsigned char arg[MAX_ARG_LEN];\nstruct ip_vs_service_user *usvc_compat;\nstruct ip_vs_service_user_kern usvc;\nstruct ip_vs_service *svc;\nstruct ip_vs_dest_user *udest_compat;\nstruct ip_vs_dest_user_kern udest;\nif (!capable(CAP_NET_ADMIN))\nreturn -EPERM;\nif (len != set_arglen[SET_CMDID(cmd)]) {\npr_err(\"set_ctl: len %u != %u\\n\",\nlen, set_arglen[SET_CMDID(cmd)]);\nreturn -EINVAL;\n}\nif (copy_from_user(arg, user, len) != 0)\nreturn -EFAULT;\nip_vs_use_count_inc();\nif (mutex_lock_interruptible(&__ip_vs_mutex)) {\nret = -ERESTARTSYS;\ngoto out_dec;\n}\nif (cmd == IP_VS_SO_SET_FLUSH) {\nret = ip_vs_flush();\ngoto out_unlock;\n} else if (cmd == IP_VS_SO_SET_TIMEOUT) {\nret = ip_vs_set_timeout((struct ip_vs_timeout_user *)arg);\ngoto out_unlock;\n} else if (cmd == IP_VS_SO_SET_STARTDAEMON) {\nstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\nret = start_sync_thread(dm->state, dm->mcast_ifn, dm->syncid);\ngoto out_unlock;\n} else if (cmd == IP_VS_SO_SET_STOPDAEMON) {\nstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\nret = stop_sync_thread(dm->state);\ngoto out_unlock;\n}\nusvc_compat = (struct ip_vs_service_user *)arg;\nudest_compat = (struct ip_vs_dest_user *)(usvc_compat + 1);\nip_vs_copy_usvc_compat(&usvc, usvc_compat);\nip_vs_copy_udest_compat(&udest, udest_compat);\nif (cmd == IP_VS_SO_SET_ZERO) {\nif (!usvc.fwmark && !usvc.addr.ip && !usvc.port) {\nret = ip_vs_zero_all();\ngoto out_unlock;\n}\n}\nif (usvc.protocol != IPPROTO_TCP && usvc.protocol != IPPROTO_UDP) {\npr_err(\"set_ctl: invalid protocol: %d %pI4:%d %s\\n\",\nusvc.protocol, &usvc.addr.ip,\nntohs(usvc.port), usvc.sched_name);\nret = -EFAULT;\ngoto out_unlock;\n}\nif (usvc.fwmark == 0)\nsvc = __ip_vs_service_get(usvc.af, usvc.protocol,\n&usvc.addr, usvc.port);\nelse\nsvc = __ip_vs_svc_fwm_get(usvc.af, usvc.fwmark);\nif (cmd != IP_VS_SO_SET_ADD\n&& (svc == NULL || svc->protocol != usvc.protocol)) {\nret = -ESRCH;\ngoto out_unlock;\n}\nswitch (cmd) {\ncase IP_VS_SO_SET_ADD:\nif (svc != NULL)\nret = -EEXIST;\nelse\nret = ip_vs_add_service(&usvc, &svc);\nbreak;\ncase IP_VS_SO_SET_EDIT:\nret = ip_vs_edit_service(svc, &usvc);\nbreak;\ncase IP_VS_SO_SET_DEL:\nret = ip_vs_del_service(svc);\nif (!ret)\ngoto out_unlock;\nbreak;\ncase IP_VS_SO_SET_ZERO:\nret = ip_vs_zero_service(svc);\nbreak;\ncase IP_VS_SO_SET_ADDDEST:\nret = ip_vs_add_dest(svc, &udest);\nbreak;\ncase IP_VS_SO_SET_EDITDEST:\nret = ip_vs_edit_dest(svc, &udest);\nbreak;\ncase IP_VS_SO_SET_DELDEST:\nret = ip_vs_del_dest(svc, &udest);\nbreak;\ndefault:\nret = -EINVAL;\n}\nif (svc)\nip_vs_service_put(svc);\nout_unlock:\nmutex_unlock(&__ip_vs_mutex);\nout_dec:\nip_vs_use_count_dec();\nreturn ret;\n}\n"
    }
  ],
  "CVE-2013-4591": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for buffer size before copying data from an array to a buffer.",
        "trigger_condition": "A local user triggers a getxattr system call for a specific extended attribute of a pathname on an NFSv4 filesystem, leading to a buffer overflow due to copying data without checking if it exceeds the buffer size.",
        "specific_code_behavior_causing_vulnerability": "The code copies data from an array to a buffer without verifying if the length of the data to be copied exceeds the size of the buffer, potentially causing a buffer overflow vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to verify that the length of the data to be copied from the array to the buffer does not exceed the size of the buffer. If the data length is greater than the buffer size, the code should handle this scenario appropriately by setting the return value to -ERANGE and freeing allocated resources to prevent a buffer overflow. This ensures that the code behaves correctly even when the data to be copied exceeds the buffer size, improving security and stability.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-4591, which involves a buffer overflow in the `__nfs4_get_acl_uncached` function. The vulnerability allows local users to cause a denial of service (memory corruption and system crash) or possibly have unspecified other impacts via a `getxattr` system call for the `system.nfs4_acl` extended attribute of a pathname on an NFSv4 filesystem.\n\nThe modification ensures that before copying data from the `pages` array to the `buf` buffer, it checks if the length of the data to be copied (`res.acl_len`) exceeds the size of the `buf` buffer (`buflen`). If the length of the data to be copied is greater than the size of the buffer, it sets the return value to `-ERANGE` and frees allocated resources to prevent a buffer overflow.\n\nBy adding the check for buffer size before copying data, the modification helps prevent the buffer overflow vulnerability and ensures that the function behaves correctly even when the data to be copied exceeds the buffer size, thus improving the security and stability of the code.",
      "GPT_purpose": "Retrieve NFSv4 ACL data for a given inode, handling multiple pages of ACL data if necessary.",
      "GPT_function": "\n1. Allocate memory for pages to store ACL data.\n2. Prepare arguments and structures for an NFS call to retrieve ACL data.\n3. Handle the retrieval and processing of ACL data, including potential buffer overflow vulnerability.",
      "CVE_id": "CVE-2013-4591",
      "code_before_change": "static ssize_t __nfs4_get_acl_uncached(struct inode *inode, void *buf, size_t buflen)\n{\n\tstruct page *pages[NFS4ACL_MAXPAGES] = {NULL, };\n\tstruct nfs_getaclargs args = {\n\t\t.fh = NFS_FH(inode),\n\t\t.acl_pages = pages,\n\t\t.acl_len = buflen,\n\t};\n\tstruct nfs_getaclres res = {\n\t\t.acl_len = buflen,\n\t};\n\tstruct rpc_message msg = {\n\t\t.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_GETACL],\n\t\t.rpc_argp = &args,\n\t\t.rpc_resp = &res,\n\t};\n\tunsigned int npages = DIV_ROUND_UP(buflen, PAGE_SIZE);\n\tint ret = -ENOMEM, i;\n\n\t/* As long as we're doing a round trip to the server anyway,\n\t * let's be prepared for a page of acl data. */\n\tif (npages == 0)\n\t\tnpages = 1;\n\tif (npages > ARRAY_SIZE(pages))\n\t\treturn -ERANGE;\n\n\tfor (i = 0; i < npages; i++) {\n\t\tpages[i] = alloc_page(GFP_KERNEL);\n\t\tif (!pages[i])\n\t\t\tgoto out_free;\n\t}\n\n\t/* for decoding across pages */\n\tres.acl_scratch = alloc_page(GFP_KERNEL);\n\tif (!res.acl_scratch)\n\t\tgoto out_free;\n\n\targs.acl_len = npages * PAGE_SIZE;\n\targs.acl_pgbase = 0;\n\n\tdprintk(\"%s  buf %p buflen %zu npages %d args.acl_len %zu\\n\",\n\t\t__func__, buf, buflen, npages, args.acl_len);\n\tret = nfs4_call_sync(NFS_SERVER(inode)->client, NFS_SERVER(inode),\n\t\t\t     &msg, &args.seq_args, &res.seq_res, 0);\n\tif (ret)\n\t\tgoto out_free;\n\n\t/* Handle the case where the passed-in buffer is too short */\n\tif (res.acl_flags & NFS4_ACL_TRUNC) {\n\t\t/* Did the user only issue a request for the acl length? */\n\t\tif (buf == NULL)\n\t\t\tgoto out_ok;\n\t\tret = -ERANGE;\n\t\tgoto out_free;\n\t}\n\tnfs4_write_cached_acl(inode, pages, res.acl_data_offset, res.acl_len);\n\tif (buf)\n\t\t_copy_from_pages(buf, pages, res.acl_data_offset, res.acl_len);\nout_ok:\n\tret = res.acl_len;\nout_free:\n\tfor (i = 0; i < npages; i++)\n\t\tif (pages[i])\n\t\t\t__free_page(pages[i]);\n\tif (res.acl_scratch)\n\t\t__free_page(res.acl_scratch);\n\treturn ret;\n}",
      "code_after_change": "static ssize_t __nfs4_get_acl_uncached(struct inode *inode, void *buf, size_t buflen)\n{\n\tstruct page *pages[NFS4ACL_MAXPAGES] = {NULL, };\n\tstruct nfs_getaclargs args = {\n\t\t.fh = NFS_FH(inode),\n\t\t.acl_pages = pages,\n\t\t.acl_len = buflen,\n\t};\n\tstruct nfs_getaclres res = {\n\t\t.acl_len = buflen,\n\t};\n\tstruct rpc_message msg = {\n\t\t.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_GETACL],\n\t\t.rpc_argp = &args,\n\t\t.rpc_resp = &res,\n\t};\n\tunsigned int npages = DIV_ROUND_UP(buflen, PAGE_SIZE);\n\tint ret = -ENOMEM, i;\n\n\t/* As long as we're doing a round trip to the server anyway,\n\t * let's be prepared for a page of acl data. */\n\tif (npages == 0)\n\t\tnpages = 1;\n\tif (npages > ARRAY_SIZE(pages))\n\t\treturn -ERANGE;\n\n\tfor (i = 0; i < npages; i++) {\n\t\tpages[i] = alloc_page(GFP_KERNEL);\n\t\tif (!pages[i])\n\t\t\tgoto out_free;\n\t}\n\n\t/* for decoding across pages */\n\tres.acl_scratch = alloc_page(GFP_KERNEL);\n\tif (!res.acl_scratch)\n\t\tgoto out_free;\n\n\targs.acl_len = npages * PAGE_SIZE;\n\targs.acl_pgbase = 0;\n\n\tdprintk(\"%s  buf %p buflen %zu npages %d args.acl_len %zu\\n\",\n\t\t__func__, buf, buflen, npages, args.acl_len);\n\tret = nfs4_call_sync(NFS_SERVER(inode)->client, NFS_SERVER(inode),\n\t\t\t     &msg, &args.seq_args, &res.seq_res, 0);\n\tif (ret)\n\t\tgoto out_free;\n\n\t/* Handle the case where the passed-in buffer is too short */\n\tif (res.acl_flags & NFS4_ACL_TRUNC) {\n\t\t/* Did the user only issue a request for the acl length? */\n\t\tif (buf == NULL)\n\t\t\tgoto out_ok;\n\t\tret = -ERANGE;\n\t\tgoto out_free;\n\t}\n\tnfs4_write_cached_acl(inode, pages, res.acl_data_offset, res.acl_len);\n\tif (buf) {\n\t\tif (res.acl_len > buflen) {\n\t\t\tret = -ERANGE;\n\t\t\tgoto out_free;\n\t\t}\n\t\t_copy_from_pages(buf, pages, res.acl_data_offset, res.acl_len);\n\t}\nout_ok:\n\tret = res.acl_len;\nout_free:\n\tfor (i = 0; i < npages; i++)\n\t\tif (pages[i])\n\t\t\t__free_page(pages[i]);\n\tif (res.acl_scratch)\n\t\t__free_page(res.acl_scratch);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tif (buf) {",
          "\t\tif (res.acl_len > buflen) {",
          "\t\t\tret = -ERANGE;",
          "\t\t\tgoto out_free;",
          "\t\t}",
          "\t}"
        ],
        "deleted": [
          "\tif (buf)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for buffer size before copying data from an array to a buffer.",
      "trigger_condition": "A local user triggers a getxattr system call for a specific extended attribute of a pathname on an NFSv4 filesystem, leading to a buffer overflow due to copying data without checking if it exceeds the buffer size.",
      "specific_code_behavior_causing_vulnerability": "The code copies data from an array to a buffer without verifying if the length of the data to be copied exceeds the size of the buffer, potentially causing a buffer overflow vulnerability.",
      "id": 44,
      "code_after_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, void *VAR2, size_t VAR3)\n{\nstruct page *VAR4[VAR5] = {NULL, };\nstruct nfs_getaclargs VAR6 = {\n.VAR7 = FUN2(VAR1),\n.VAR8 = VAR4,\n.VAR9 = VAR3,\n};\nstruct nfs_getaclres VAR10 = {\n.VAR9 = VAR3,\n};\nstruct rpc_message VAR11 = {\n.VAR12 = &VAR13[VAR14],\n.VAR15 = &VAR6,\n.VAR16 = &VAR10,\n};\nunsigned int VAR17 = FUN3(VAR3, VAR18);\nint VAR19 = -VAR20, VAR21;\nif (VAR17 == 0)\nVAR17 = 1;\nif (VAR17 > FUN4(VAR4))\nreturn -VAR22;\nfor (VAR21 = 0; VAR21 < VAR17; VAR21++) {\nVAR4[VAR21] = FUN5(VAR23);\nif (!VAR4[VAR21])\ngoto VAR24;\n}\nVAR10.VAR25 = FUN5(VAR23);\nif (!VAR10.VAR25)\ngoto VAR24;\nVAR6.VAR9 = VAR17 * VAR18;\nVAR6.VAR26 = 0;\nFUN6(\"STR\",\nVAR27, VAR2, VAR3, VAR17, VAR6.VAR9);\nVAR19 = FUN7(FUN8(VAR1)->VAR28, FUN8(VAR1),\n&VAR11, &VAR6.VAR29, &VAR10.VAR30, 0);\nif (VAR19)\ngoto VAR24;\nif (VAR10.VAR31 & VAR32) {\nif (VAR2 == NULL)\ngoto VAR33;\nVAR19 = -VAR22;\ngoto VAR24;\n}\nFUN9(VAR1, VAR4, VAR10.VAR34, VAR10.VAR9);\nif (VAR2) {\nif (VAR10.VAR9 > VAR3) {\nVAR19 = -VAR22;\ngoto VAR24;\n}\nFUN10(VAR2, VAR4, VAR10.VAR34, VAR10.VAR9);\n}\nVAR33:\nVAR19 = VAR10.VAR9;\nVAR24:\nfor (VAR21 = 0; VAR21 < VAR17; VAR21++)\nif (VAR4[VAR21])\nFUN11(VAR4[VAR21]);\nif (VAR10.VAR25)\nFUN11(VAR10.VAR25);\nreturn VAR19;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, void *VAR2, size_t VAR3)\n{\nstruct page *VAR4[VAR5] = {NULL, };\nstruct nfs_getaclargs VAR6 = {\n.VAR7 = FUN2(VAR1),\n.VAR8 = VAR4,\n.VAR9 = VAR3,\n};\nstruct nfs_getaclres VAR10 = {\n.VAR9 = VAR3,\n};\nstruct rpc_message VAR11 = {\n.VAR12 = &VAR13[VAR14],\n.VAR15 = &VAR6,\n.VAR16 = &VAR10,\n};\nunsigned int VAR17 = FUN3(VAR3, VAR18);\nint VAR19 = -VAR20, VAR21;\nif (VAR17 == 0)\nVAR17 = 1;\nif (VAR17 > FUN4(VAR4))\nreturn -VAR22;\nfor (VAR21 = 0; VAR21 < VAR17; VAR21++) {\nVAR4[VAR21] = FUN5(VAR23);\nif (!VAR4[VAR21])\ngoto VAR24;\n}\nVAR10.VAR25 = FUN5(VAR23);\nif (!VAR10.VAR25)\ngoto VAR24;\nVAR6.VAR9 = VAR17 * VAR18;\nVAR6.VAR26 = 0;\nFUN6(\"STR\",\nVAR27, VAR2, VAR3, VAR17, VAR6.VAR9);\nVAR19 = FUN7(FUN8(VAR1)->VAR28, FUN8(VAR1),\n&VAR11, &VAR6.VAR29, &VAR10.VAR30, 0);\nif (VAR19)\ngoto VAR24;\nif (VAR10.VAR31 & VAR32) {\nif (VAR2 == NULL)\ngoto VAR33;\nVAR19 = -VAR22;\ngoto VAR24;\n}\nFUN9(VAR1, VAR4, VAR10.VAR34, VAR10.VAR9);\nif (VAR2)\nFUN10(VAR2, VAR4, VAR10.VAR34, VAR10.VAR9);\nVAR33:\nVAR19 = VAR10.VAR9;\nVAR24:\nfor (VAR21 = 0; VAR21 < VAR17; VAR21++)\nif (VAR4[VAR21])\nFUN11(VAR4[VAR21]);\nif (VAR10.VAR25)\nFUN11(VAR10.VAR25);\nreturn VAR19;\n}\n",
      "code_after_change_raw": "static ssize_t __nfs4_get_acl_uncached(struct inode *inode, void *buf, size_t buflen)\n{\nstruct page *pages[NFS4ACL_MAXPAGES] = {NULL, };\nstruct nfs_getaclargs args = {\n.fh = NFS_FH(inode),\n.acl_pages = pages,\n.acl_len = buflen,\n};\nstruct nfs_getaclres res = {\n.acl_len = buflen,\n};\nstruct rpc_message msg = {\n.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_GETACL],\n.rpc_argp = &args,\n.rpc_resp = &res,\n};\nunsigned int npages = DIV_ROUND_UP(buflen, PAGE_SIZE);\nint ret = -ENOMEM, i;\nif (npages == 0)\nnpages = 1;\nif (npages > ARRAY_SIZE(pages))\nreturn -ERANGE;\nfor (i = 0; i < npages; i++) {\npages[i] = alloc_page(GFP_KERNEL);\nif (!pages[i])\ngoto out_free;\n}\nres.acl_scratch = alloc_page(GFP_KERNEL);\nif (!res.acl_scratch)\ngoto out_free;\nargs.acl_len = npages * PAGE_SIZE;\nargs.acl_pgbase = 0;\ndprintk(\"%s  buf %p buflen %zu npages %d args.acl_len %zu\\n\",\n__func__, buf, buflen, npages, args.acl_len);\nret = nfs4_call_sync(NFS_SERVER(inode)->client, NFS_SERVER(inode),\n&msg, &args.seq_args, &res.seq_res, 0);\nif (ret)\ngoto out_free;\nif (res.acl_flags & NFS4_ACL_TRUNC) {\nif (buf == NULL)\ngoto out_ok;\nret = -ERANGE;\ngoto out_free;\n}\nnfs4_write_cached_acl(inode, pages, res.acl_data_offset, res.acl_len);\nif (buf) {\nif (res.acl_len > buflen) {\nret = -ERANGE;\ngoto out_free;\n}\n_copy_from_pages(buf, pages, res.acl_data_offset, res.acl_len);\n}\nout_ok:\nret = res.acl_len;\nout_free:\nfor (i = 0; i < npages; i++)\nif (pages[i])\n__free_page(pages[i]);\nif (res.acl_scratch)\n__free_page(res.acl_scratch);\nreturn ret;\n}\n",
      "code_before_change_raw": "static ssize_t __nfs4_get_acl_uncached(struct inode *inode, void *buf, size_t buflen)\n{\nstruct page *pages[NFS4ACL_MAXPAGES] = {NULL, };\nstruct nfs_getaclargs args = {\n.fh = NFS_FH(inode),\n.acl_pages = pages,\n.acl_len = buflen,\n};\nstruct nfs_getaclres res = {\n.acl_len = buflen,\n};\nstruct rpc_message msg = {\n.rpc_proc = &nfs4_procedures[NFSPROC4_CLNT_GETACL],\n.rpc_argp = &args,\n.rpc_resp = &res,\n};\nunsigned int npages = DIV_ROUND_UP(buflen, PAGE_SIZE);\nint ret = -ENOMEM, i;\nif (npages == 0)\nnpages = 1;\nif (npages > ARRAY_SIZE(pages))\nreturn -ERANGE;\nfor (i = 0; i < npages; i++) {\npages[i] = alloc_page(GFP_KERNEL);\nif (!pages[i])\ngoto out_free;\n}\nres.acl_scratch = alloc_page(GFP_KERNEL);\nif (!res.acl_scratch)\ngoto out_free;\nargs.acl_len = npages * PAGE_SIZE;\nargs.acl_pgbase = 0;\ndprintk(\"%s  buf %p buflen %zu npages %d args.acl_len %zu\\n\",\n__func__, buf, buflen, npages, args.acl_len);\nret = nfs4_call_sync(NFS_SERVER(inode)->client, NFS_SERVER(inode),\n&msg, &args.seq_args, &res.seq_res, 0);\nif (ret)\ngoto out_free;\nif (res.acl_flags & NFS4_ACL_TRUNC) {\nif (buf == NULL)\ngoto out_ok;\nret = -ERANGE;\ngoto out_free;\n}\nnfs4_write_cached_acl(inode, pages, res.acl_data_offset, res.acl_len);\nif (buf)\n_copy_from_pages(buf, pages, res.acl_data_offset, res.acl_len);\nout_ok:\nret = res.acl_len;\nout_free:\nfor (i = 0; i < npages; i++)\nif (pages[i])\n__free_page(pages[i]);\nif (res.acl_scratch)\n__free_page(res.acl_scratch);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2013-6381": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation of the length value provided in an SNMP ioctl call.",
        "trigger_condition": "An SNMP ioctl call with a length value that is incompatible with the command-buffer size.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the length value provided in the SNMP ioctl call exceeds the maximum allowed size for the command buffer, leading to a potential buffer overflow."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the length value provided in the SNMP ioctl call does not exceed the maximum allowed size for the command buffer. By adding this validation step, the code prevents buffer overflow issues that could be exploited by providing an incompatible length value.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2013-6381, which involves a buffer overflow in the qeth_snmp_command function. \n\nThe vulnerability arises from the lack of proper validation of the length value provided in the SNMP ioctl call, which can lead to a buffer overflow if the length value is incompatible with the command-buffer size. By adding the following check after reading the length value:\n```c\nif (req_len > (QETH_BUFSIZE - IPA_PDU_HEADER_SIZE -\n               sizeof(struct qeth_ipacmd_hdr) -\n               sizeof(struct qeth_ipacmd_setadpparms_hdr)))\n    return -EINVAL;\n```\nThis check ensures that the length value does not exceed the maximum allowed size for the command buffer, thus preventing a buffer overflow. If the length value is greater than the allowed size, the function returns an error code (-EINVAL) to indicate that the request is invalid.\n\nTherefore, this modification helps to mitigate the vulnerability by enforcing a limit on the length value provided in the SNMP ioctl call, thereby preventing potential buffer overflow issues.",
      "GPT_purpose": "Handling SNMP commands for a qeth_card network device, including processing user data and sending SNMP commands.",
      "GPT_function": "\n1. Check if the card is in guest LAN mode.\n2. Check if the adapter supports SNMP control and if it is not in layer 2 mode.\n3. Copy data length from user input and allocate memory for SNMP request.\n4. Prepare and send an SNMP command to the adapter.\n5. Handle the response and copy data back to user space.\n6. Free allocated memory before returning.",
      "CVE_id": "CVE-2013-6381",
      "code_before_change": "int qeth_snmp_command(struct qeth_card *card, char __user *udata)\n{\n\tstruct qeth_cmd_buffer *iob;\n\tstruct qeth_ipa_cmd *cmd;\n\tstruct qeth_snmp_ureq *ureq;\n\tint req_len;\n\tstruct qeth_arp_query_info qinfo = {0, };\n\tint rc = 0;\n\n\tQETH_CARD_TEXT(card, 3, \"snmpcmd\");\n\n\tif (card->info.guestlan)\n\t\treturn -EOPNOTSUPP;\n\n\tif ((!qeth_adp_supported(card, IPA_SETADP_SET_SNMP_CONTROL)) &&\n\t    (!card->options.layer2)) {\n\t\treturn -EOPNOTSUPP;\n\t}\n\t/* skip 4 bytes (data_len struct member) to get req_len */\n\tif (copy_from_user(&req_len, udata + sizeof(int), sizeof(int)))\n\t\treturn -EFAULT;\n\tureq = memdup_user(udata, req_len + sizeof(struct qeth_snmp_ureq_hdr));\n\tif (IS_ERR(ureq)) {\n\t\tQETH_CARD_TEXT(card, 2, \"snmpnome\");\n\t\treturn PTR_ERR(ureq);\n\t}\n\tqinfo.udata_len = ureq->hdr.data_len;\n\tqinfo.udata = kzalloc(qinfo.udata_len, GFP_KERNEL);\n\tif (!qinfo.udata) {\n\t\tkfree(ureq);\n\t\treturn -ENOMEM;\n\t}\n\tqinfo.udata_offset = sizeof(struct qeth_snmp_ureq_hdr);\n\n\tiob = qeth_get_adapter_cmd(card, IPA_SETADP_SET_SNMP_CONTROL,\n\t\t\t\t   QETH_SNMP_SETADP_CMDLENGTH + req_len);\n\tcmd = (struct qeth_ipa_cmd *)(iob->data+IPA_PDU_HEADER_SIZE);\n\tmemcpy(&cmd->data.setadapterparms.data.snmp, &ureq->cmd, req_len);\n\trc = qeth_send_ipa_snmp_cmd(card, iob, QETH_SETADP_BASE_LEN + req_len,\n\t\t\t\t    qeth_snmp_command_cb, (void *)&qinfo);\n\tif (rc)\n\t\tQETH_DBF_MESSAGE(2, \"SNMP command failed on %s: (0x%x)\\n\",\n\t\t\t   QETH_CARD_IFNAME(card), rc);\n\telse {\n\t\tif (copy_to_user(udata, qinfo.udata, qinfo.udata_len))\n\t\t\trc = -EFAULT;\n\t}\n\n\tkfree(ureq);\n\tkfree(qinfo.udata);\n\treturn rc;\n}",
      "code_after_change": "int qeth_snmp_command(struct qeth_card *card, char __user *udata)\n{\n\tstruct qeth_cmd_buffer *iob;\n\tstruct qeth_ipa_cmd *cmd;\n\tstruct qeth_snmp_ureq *ureq;\n\tunsigned int req_len;\n\tstruct qeth_arp_query_info qinfo = {0, };\n\tint rc = 0;\n\n\tQETH_CARD_TEXT(card, 3, \"snmpcmd\");\n\n\tif (card->info.guestlan)\n\t\treturn -EOPNOTSUPP;\n\n\tif ((!qeth_adp_supported(card, IPA_SETADP_SET_SNMP_CONTROL)) &&\n\t    (!card->options.layer2)) {\n\t\treturn -EOPNOTSUPP;\n\t}\n\t/* skip 4 bytes (data_len struct member) to get req_len */\n\tif (copy_from_user(&req_len, udata + sizeof(int), sizeof(int)))\n\t\treturn -EFAULT;\n\tif (req_len > (QETH_BUFSIZE - IPA_PDU_HEADER_SIZE -\n\t\t       sizeof(struct qeth_ipacmd_hdr) -\n\t\t       sizeof(struct qeth_ipacmd_setadpparms_hdr)))\n\t\treturn -EINVAL;\n\tureq = memdup_user(udata, req_len + sizeof(struct qeth_snmp_ureq_hdr));\n\tif (IS_ERR(ureq)) {\n\t\tQETH_CARD_TEXT(card, 2, \"snmpnome\");\n\t\treturn PTR_ERR(ureq);\n\t}\n\tqinfo.udata_len = ureq->hdr.data_len;\n\tqinfo.udata = kzalloc(qinfo.udata_len, GFP_KERNEL);\n\tif (!qinfo.udata) {\n\t\tkfree(ureq);\n\t\treturn -ENOMEM;\n\t}\n\tqinfo.udata_offset = sizeof(struct qeth_snmp_ureq_hdr);\n\n\tiob = qeth_get_adapter_cmd(card, IPA_SETADP_SET_SNMP_CONTROL,\n\t\t\t\t   QETH_SNMP_SETADP_CMDLENGTH + req_len);\n\tcmd = (struct qeth_ipa_cmd *)(iob->data+IPA_PDU_HEADER_SIZE);\n\tmemcpy(&cmd->data.setadapterparms.data.snmp, &ureq->cmd, req_len);\n\trc = qeth_send_ipa_snmp_cmd(card, iob, QETH_SETADP_BASE_LEN + req_len,\n\t\t\t\t    qeth_snmp_command_cb, (void *)&qinfo);\n\tif (rc)\n\t\tQETH_DBF_MESSAGE(2, \"SNMP command failed on %s: (0x%x)\\n\",\n\t\t\t   QETH_CARD_IFNAME(card), rc);\n\telse {\n\t\tif (copy_to_user(udata, qinfo.udata, qinfo.udata_len))\n\t\t\trc = -EFAULT;\n\t}\n\n\tkfree(ureq);\n\tkfree(qinfo.udata);\n\treturn rc;\n}",
      "modified_lines": {
        "added": [
          "\tunsigned int req_len;",
          "\tif (req_len > (QETH_BUFSIZE - IPA_PDU_HEADER_SIZE -",
          "\t\t       sizeof(struct qeth_ipacmd_hdr) -",
          "\t\t       sizeof(struct qeth_ipacmd_setadpparms_hdr)))",
          "\t\treturn -EINVAL;"
        ],
        "deleted": [
          "\tint req_len;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation of the length value provided in an SNMP ioctl call.",
      "trigger_condition": "An SNMP ioctl call with a length value that is incompatible with the command-buffer size.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the length value provided in the SNMP ioctl call exceeds the maximum allowed size for the command buffer, leading to a potential buffer overflow.",
      "id": 45,
      "code_after_change_normalized": "int FUN1(struct qeth_card *VAR1, char __user *VAR2)\n{\nstruct qeth_cmd_buffer *VAR3;\nstruct qeth_ipa_cmd *VAR4;\nstruct qeth_snmp_ureq *VAR5;\nunsigned int VAR6;\nstruct qeth_arp_query_info VAR7 = {0, };\nint VAR8 = 0;\nFUN2(VAR1, 3, \"STR\");\nif (VAR1->VAR9.VAR10)\nreturn -VAR11;\nif ((!FUN3(VAR1, VAR12)) &&\n(!VAR1->VAR13.VAR14)) {\nreturn -VAR11;\n}\nif (FUN4(&VAR6, VAR2 + sizeof(int), sizeof(int)))\nreturn -VAR15;\nif (VAR6 > (VAR16 - VAR17 -\nsizeof(struct VAR18) -\nsizeof(struct VAR19)))\nreturn -VAR20;\nVAR5 = FUN5(VAR2, VAR6 + sizeof(struct VAR21));\nif (FUN6(VAR5)) {\nFUN2(VAR1, 2, \"STR\");\nreturn FUN7(VAR5);\n}\nVAR7.VAR22 = VAR5->VAR23.VAR24;\nVAR7.VAR2 = FUN8(VAR7.VAR22, VAR25);\nif (!VAR7.VAR2) {\nFUN9(VAR5);\nreturn -VAR26;\n}\nVAR7.VAR27 = sizeof(struct VAR21);\nVAR3 = FUN10(VAR1, VAR12,\nVAR28 + VAR6);\nVAR4 = (struct VAR29 *)(VAR3->VAR30+VAR17);\nFUN11(&VAR4->VAR30.VAR31.VAR30.VAR32, &VAR5->VAR4, VAR6);\nVAR8 = FUN12(VAR1, VAR3, VAR33 + VAR6,\nVAR34, (void *)&VAR7);\nif (VAR8)\nFUN13(2, \"STR\",\nFUN14(VAR1), VAR8);\nelse {\nif (FUN15(VAR2, VAR7.VAR2, VAR7.VAR22))\nVAR8 = -VAR15;\n}\nFUN9(VAR5);\nFUN9(VAR7.VAR2);\nreturn VAR8;\n}\n",
      "code_before_change_normalized": "int FUN1(struct qeth_card *VAR1, char __user *VAR2)\n{\nstruct qeth_cmd_buffer *VAR3;\nstruct qeth_ipa_cmd *VAR4;\nstruct qeth_snmp_ureq *VAR5;\nint VAR6;\nstruct qeth_arp_query_info VAR7 = {0, };\nint VAR8 = 0;\nFUN2(VAR1, 3, \"STR\");\nif (VAR1->VAR9.VAR10)\nreturn -VAR11;\nif ((!FUN3(VAR1, VAR12)) &&\n(!VAR1->VAR13.VAR14)) {\nreturn -VAR11;\n}\nif (FUN4(&VAR6, VAR2 + sizeof(int), sizeof(int)))\nreturn -VAR15;\nVAR5 = FUN5(VAR2, VAR6 + sizeof(struct VAR16));\nif (FUN6(VAR5)) {\nFUN2(VAR1, 2, \"STR\");\nreturn FUN7(VAR5);\n}\nVAR7.VAR17 = VAR5->VAR18.VAR19;\nVAR7.VAR2 = FUN8(VAR7.VAR17, VAR20);\nif (!VAR7.VAR2) {\nFUN9(VAR5);\nreturn -VAR21;\n}\nVAR7.VAR22 = sizeof(struct VAR16);\nVAR3 = FUN10(VAR1, VAR12,\nVAR23 + VAR6);\nVAR4 = (struct VAR24 *)(VAR3->VAR25+VAR26);\nFUN11(&VAR4->VAR25.VAR27.VAR25.VAR28, &VAR5->VAR4, VAR6);\nVAR8 = FUN12(VAR1, VAR3, VAR29 + VAR6,\nVAR30, (void *)&VAR7);\nif (VAR8)\nFUN13(2, \"STR\",\nFUN14(VAR1), VAR8);\nelse {\nif (FUN15(VAR2, VAR7.VAR2, VAR7.VAR17))\nVAR8 = -VAR15;\n}\nFUN9(VAR5);\nFUN9(VAR7.VAR2);\nreturn VAR8;\n}\n",
      "code_after_change_raw": "int qeth_snmp_command(struct qeth_card *card, char __user *udata)\n{\nstruct qeth_cmd_buffer *iob;\nstruct qeth_ipa_cmd *cmd;\nstruct qeth_snmp_ureq *ureq;\nunsigned int req_len;\nstruct qeth_arp_query_info qinfo = {0, };\nint rc = 0;\nQETH_CARD_TEXT(card, 3, \"snmpcmd\");\nif (card->info.guestlan)\nreturn -EOPNOTSUPP;\nif ((!qeth_adp_supported(card, IPA_SETADP_SET_SNMP_CONTROL)) &&\n(!card->options.layer2)) {\nreturn -EOPNOTSUPP;\n}\nif (copy_from_user(&req_len, udata + sizeof(int), sizeof(int)))\nreturn -EFAULT;\nif (req_len > (QETH_BUFSIZE - IPA_PDU_HEADER_SIZE -\nsizeof(struct qeth_ipacmd_hdr) -\nsizeof(struct qeth_ipacmd_setadpparms_hdr)))\nreturn -EINVAL;\nureq = memdup_user(udata, req_len + sizeof(struct qeth_snmp_ureq_hdr));\nif (IS_ERR(ureq)) {\nQETH_CARD_TEXT(card, 2, \"snmpnome\");\nreturn PTR_ERR(ureq);\n}\nqinfo.udata_len = ureq->hdr.data_len;\nqinfo.udata = kzalloc(qinfo.udata_len, GFP_KERNEL);\nif (!qinfo.udata) {\nkfree(ureq);\nreturn -ENOMEM;\n}\nqinfo.udata_offset = sizeof(struct qeth_snmp_ureq_hdr);\niob = qeth_get_adapter_cmd(card, IPA_SETADP_SET_SNMP_CONTROL,\nQETH_SNMP_SETADP_CMDLENGTH + req_len);\ncmd = (struct qeth_ipa_cmd *)(iob->data+IPA_PDU_HEADER_SIZE);\nmemcpy(&cmd->data.setadapterparms.data.snmp, &ureq->cmd, req_len);\nrc = qeth_send_ipa_snmp_cmd(card, iob, QETH_SETADP_BASE_LEN + req_len,\nqeth_snmp_command_cb, (void *)&qinfo);\nif (rc)\nQETH_DBF_MESSAGE(2, \"SNMP command failed on %s: (0x%x)\\n\",\nQETH_CARD_IFNAME(card), rc);\nelse {\nif (copy_to_user(udata, qinfo.udata, qinfo.udata_len))\nrc = -EFAULT;\n}\nkfree(ureq);\nkfree(qinfo.udata);\nreturn rc;\n}\n",
      "code_before_change_raw": "int qeth_snmp_command(struct qeth_card *card, char __user *udata)\n{\nstruct qeth_cmd_buffer *iob;\nstruct qeth_ipa_cmd *cmd;\nstruct qeth_snmp_ureq *ureq;\nint req_len;\nstruct qeth_arp_query_info qinfo = {0, };\nint rc = 0;\nQETH_CARD_TEXT(card, 3, \"snmpcmd\");\nif (card->info.guestlan)\nreturn -EOPNOTSUPP;\nif ((!qeth_adp_supported(card, IPA_SETADP_SET_SNMP_CONTROL)) &&\n(!card->options.layer2)) {\nreturn -EOPNOTSUPP;\n}\nif (copy_from_user(&req_len, udata + sizeof(int), sizeof(int)))\nreturn -EFAULT;\nureq = memdup_user(udata, req_len + sizeof(struct qeth_snmp_ureq_hdr));\nif (IS_ERR(ureq)) {\nQETH_CARD_TEXT(card, 2, \"snmpnome\");\nreturn PTR_ERR(ureq);\n}\nqinfo.udata_len = ureq->hdr.data_len;\nqinfo.udata = kzalloc(qinfo.udata_len, GFP_KERNEL);\nif (!qinfo.udata) {\nkfree(ureq);\nreturn -ENOMEM;\n}\nqinfo.udata_offset = sizeof(struct qeth_snmp_ureq_hdr);\niob = qeth_get_adapter_cmd(card, IPA_SETADP_SET_SNMP_CONTROL,\nQETH_SNMP_SETADP_CMDLENGTH + req_len);\ncmd = (struct qeth_ipa_cmd *)(iob->data+IPA_PDU_HEADER_SIZE);\nmemcpy(&cmd->data.setadapterparms.data.snmp, &ureq->cmd, req_len);\nrc = qeth_send_ipa_snmp_cmd(card, iob, QETH_SETADP_BASE_LEN + req_len,\nqeth_snmp_command_cb, (void *)&qinfo);\nif (rc)\nQETH_DBF_MESSAGE(2, \"SNMP command failed on %s: (0x%x)\\n\",\nQETH_CARD_IFNAME(card), rc);\nelse {\nif (copy_to_user(udata, qinfo.udata, qinfo.udata_len))\nrc = -EFAULT;\n}\nkfree(ureq);\nkfree(qinfo.udata);\nreturn rc;\n}\n"
    }
  ],
  "CVE-2013-6382": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation of buffer size input in the XFS implementation.",
        "trigger_condition": "A local user leverages the CAP_SYS_ADMIN capability for a specific ioctl call with a crafted length value, leading to a buffer underflow vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the input buffer size, allowing a potential buffer underflow when handling the ioctl call.",
        "solution": "To mitigate the vulnerability, it is necessary to validate the input buffer size to ensure it is within a valid range. Specifically, the code should check that the buffer size is not smaller than the size of a specific structure and not larger than a defined maximum size. This prevents buffer underflows and enhances the security of the code."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2013-6382, which involves buffer underflows in the XFS implementation in the Linux kernel. By checking that the `al_hreq.buflen` is within a valid range (greater than or equal to the size of `struct attrlist` and less than or equal to `XATTR_LIST_MAX`), the code ensures that the buffer size is appropriate and prevents potential buffer underflows that could lead to memory corruption or other unspecified impacts.\n\nBy adding the check `al_hreq.buflen < sizeof(struct attrlist)`, the code ensures that the buffer size is not smaller than the size of the `struct attrlist`, preventing a buffer underflow. This helps to mitigate the vulnerability and make the code more secure.",
      "GPT_purpose": "Retrieve attribute list by handle for XFS filesystem.",
      "GPT_function": "\n1. Check if the user has CAP_SYS_ADMIN capability.\n2. Copy data from user space to kernel space.\n3. Validate the length of the buffer.\n4. Reject certain flags and only allow specific namespaces.\n5. Convert a handle request to a dentry.\n6. Allocate memory for a buffer.\n7. Perform an attribute list operation.\n8. Copy data from kernel space to user space.\n9. Free allocated memory.\n10. Release the dentry.",
      "CVE_id": "CVE-2013-6382",
      "code_before_change": "STATIC int\nxfs_attrlist_by_handle(\n\tstruct file\t\t*parfilp,\n\tvoid\t\t\t__user *arg)\n{\n\tint\t\t\terror = -ENOMEM;\n\tattrlist_cursor_kern_t\t*cursor;\n\txfs_fsop_attrlist_handlereq_t al_hreq;\n\tstruct dentry\t\t*dentry;\n\tchar\t\t\t*kbuf;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -XFS_ERROR(EPERM);\n\tif (copy_from_user(&al_hreq, arg, sizeof(xfs_fsop_attrlist_handlereq_t)))\n\t\treturn -XFS_ERROR(EFAULT);\n\tif (al_hreq.buflen > XATTR_LIST_MAX)\n\t\treturn -XFS_ERROR(EINVAL);\n\n\t/*\n\t * Reject flags, only allow namespaces.\n\t */\n\tif (al_hreq.flags & ~(ATTR_ROOT | ATTR_SECURE))\n\t\treturn -XFS_ERROR(EINVAL);\n\n\tdentry = xfs_handlereq_to_dentry(parfilp, &al_hreq.hreq);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\tkbuf = kmem_zalloc_large(al_hreq.buflen, KM_SLEEP);\n\tif (!kbuf)\n\t\tgoto out_dput;\n\n\tcursor = (attrlist_cursor_kern_t *)&al_hreq.pos;\n\terror = -xfs_attr_list(XFS_I(dentry->d_inode), kbuf, al_hreq.buflen,\n\t\t\t\t\tal_hreq.flags, cursor);\n\tif (error)\n\t\tgoto out_kfree;\n\n\tif (copy_to_user(al_hreq.buffer, kbuf, al_hreq.buflen))\n\t\terror = -EFAULT;\n\nout_kfree:\n\tkmem_free(kbuf);\nout_dput:\n\tdput(dentry);\n\treturn error;\n}",
      "code_after_change": "STATIC int\nxfs_attrlist_by_handle(\n\tstruct file\t\t*parfilp,\n\tvoid\t\t\t__user *arg)\n{\n\tint\t\t\terror = -ENOMEM;\n\tattrlist_cursor_kern_t\t*cursor;\n\txfs_fsop_attrlist_handlereq_t al_hreq;\n\tstruct dentry\t\t*dentry;\n\tchar\t\t\t*kbuf;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -XFS_ERROR(EPERM);\n\tif (copy_from_user(&al_hreq, arg, sizeof(xfs_fsop_attrlist_handlereq_t)))\n\t\treturn -XFS_ERROR(EFAULT);\n\tif (al_hreq.buflen < sizeof(struct attrlist) ||\n\t    al_hreq.buflen > XATTR_LIST_MAX)\n\t\treturn -XFS_ERROR(EINVAL);\n\n\t/*\n\t * Reject flags, only allow namespaces.\n\t */\n\tif (al_hreq.flags & ~(ATTR_ROOT | ATTR_SECURE))\n\t\treturn -XFS_ERROR(EINVAL);\n\n\tdentry = xfs_handlereq_to_dentry(parfilp, &al_hreq.hreq);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\tkbuf = kmem_zalloc_large(al_hreq.buflen, KM_SLEEP);\n\tif (!kbuf)\n\t\tgoto out_dput;\n\n\tcursor = (attrlist_cursor_kern_t *)&al_hreq.pos;\n\terror = -xfs_attr_list(XFS_I(dentry->d_inode), kbuf, al_hreq.buflen,\n\t\t\t\t\tal_hreq.flags, cursor);\n\tif (error)\n\t\tgoto out_kfree;\n\n\tif (copy_to_user(al_hreq.buffer, kbuf, al_hreq.buflen))\n\t\terror = -EFAULT;\n\nout_kfree:\n\tkmem_free(kbuf);\nout_dput:\n\tdput(dentry);\n\treturn error;\n}",
      "modified_lines": {
        "added": [
          "\tif (al_hreq.buflen < sizeof(struct attrlist) ||",
          "\t    al_hreq.buflen > XATTR_LIST_MAX)"
        ],
        "deleted": [
          "\tif (al_hreq.buflen > XATTR_LIST_MAX)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation of buffer size input in the XFS implementation.",
      "trigger_condition": "A local user leverages the CAP_SYS_ADMIN capability for a specific ioctl call with a crafted length value, leading to a buffer underflow vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the input buffer size, allowing a potential buffer underflow when handling the ioctl call.",
      "solution": "To mitigate the vulnerability, it is necessary to validate the input buffer size to ensure it is within a valid range. Specifically, the code should check that the buffer size is not smaller than the size of a specific structure and not larger than a defined maximum size. This prevents buffer underflows and enhances the security of the code.",
      "id": 46,
      "code_after_change_normalized": "STATIC int\nFUN1(\nstruct file\t\t*VAR1,\nvoid\t\t\t__user *VAR2)\n{\nint\t\t\tVAR3 = -VAR4;\nattrlist_cursor_kern_t\t*VAR5;\nxfs_fsop_attrlist_handlereq_t VAR6;\nstruct VAR7\t\t*VAR7;\nchar\t\t\t*VAR8;\nif (!FUN2(VAR9))\nreturn -FUN3(VAR10);\nif (FUN4(&VAR6, VAR2, sizeof(VAR11)))\nreturn -FUN3(VAR12);\nif (VAR6.VAR13 < sizeof(struct VAR14) ||\nVAR6.VAR13 > VAR15)\nreturn -FUN3(VAR16);\nif (VAR6.VAR17 & ~(VAR18 | VAR19))\nreturn -FUN3(VAR16);\nVAR7 = FUN5(VAR1, &VAR6.VAR20);\nif (FUN6(VAR7))\nreturn FUN7(VAR7);\nVAR8 = FUN8(VAR6.VAR13, VAR21);\nif (!VAR8)\ngoto VAR22;\nVAR5 = (VAR23 *)&VAR6.VAR24;\nVAR3 = -FUN9(FUN10(VAR7->VAR25), VAR8, VAR6.VAR13,\nVAR6.VAR17, VAR5);\nif (VAR3)\ngoto VAR26;\nif (FUN11(VAR6.VAR27, VAR8, VAR6.VAR13))\nVAR3 = -VAR12;\nVAR26:\nFUN12(VAR8);\nVAR22:\nFUN13(VAR7);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "STATIC int\nFUN1(\nstruct file\t\t*VAR1,\nvoid\t\t\t__user *VAR2)\n{\nint\t\t\tVAR3 = -VAR4;\nattrlist_cursor_kern_t\t*VAR5;\nxfs_fsop_attrlist_handlereq_t VAR6;\nstruct VAR7\t\t*VAR7;\nchar\t\t\t*VAR8;\nif (!FUN2(VAR9))\nreturn -FUN3(VAR10);\nif (FUN4(&VAR6, VAR2, sizeof(VAR11)))\nreturn -FUN3(VAR12);\nif (VAR6.VAR13 > VAR14)\nreturn -FUN3(VAR15);\nif (VAR6.VAR16 & ~(VAR17 | VAR18))\nreturn -FUN3(VAR15);\nVAR7 = FUN5(VAR1, &VAR6.VAR19);\nif (FUN6(VAR7))\nreturn FUN7(VAR7);\nVAR8 = FUN8(VAR6.VAR13, VAR20);\nif (!VAR8)\ngoto VAR21;\nVAR5 = (VAR22 *)&VAR6.VAR23;\nVAR3 = -FUN9(FUN10(VAR7->VAR24), VAR8, VAR6.VAR13,\nVAR6.VAR16, VAR5);\nif (VAR3)\ngoto VAR25;\nif (FUN11(VAR6.VAR26, VAR8, VAR6.VAR13))\nVAR3 = -VAR12;\nVAR25:\nFUN12(VAR8);\nVAR21:\nFUN13(VAR7);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "STATIC int\nxfs_attrlist_by_handle(\nstruct file\t\t*parfilp,\nvoid\t\t\t__user *arg)\n{\nint\t\t\terror = -ENOMEM;\nattrlist_cursor_kern_t\t*cursor;\nxfs_fsop_attrlist_handlereq_t al_hreq;\nstruct dentry\t\t*dentry;\nchar\t\t\t*kbuf;\nif (!capable(CAP_SYS_ADMIN))\nreturn -XFS_ERROR(EPERM);\nif (copy_from_user(&al_hreq, arg, sizeof(xfs_fsop_attrlist_handlereq_t)))\nreturn -XFS_ERROR(EFAULT);\nif (al_hreq.buflen < sizeof(struct attrlist) ||\nal_hreq.buflen > XATTR_LIST_MAX)\nreturn -XFS_ERROR(EINVAL);\nif (al_hreq.flags & ~(ATTR_ROOT | ATTR_SECURE))\nreturn -XFS_ERROR(EINVAL);\ndentry = xfs_handlereq_to_dentry(parfilp, &al_hreq.hreq);\nif (IS_ERR(dentry))\nreturn PTR_ERR(dentry);\nkbuf = kmem_zalloc_large(al_hreq.buflen, KM_SLEEP);\nif (!kbuf)\ngoto out_dput;\ncursor = (attrlist_cursor_kern_t *)&al_hreq.pos;\nerror = -xfs_attr_list(XFS_I(dentry->d_inode), kbuf, al_hreq.buflen,\nal_hreq.flags, cursor);\nif (error)\ngoto out_kfree;\nif (copy_to_user(al_hreq.buffer, kbuf, al_hreq.buflen))\nerror = -EFAULT;\nout_kfree:\nkmem_free(kbuf);\nout_dput:\ndput(dentry);\nreturn error;\n}\n",
      "code_before_change_raw": "STATIC int\nxfs_attrlist_by_handle(\nstruct file\t\t*parfilp,\nvoid\t\t\t__user *arg)\n{\nint\t\t\terror = -ENOMEM;\nattrlist_cursor_kern_t\t*cursor;\nxfs_fsop_attrlist_handlereq_t al_hreq;\nstruct dentry\t\t*dentry;\nchar\t\t\t*kbuf;\nif (!capable(CAP_SYS_ADMIN))\nreturn -XFS_ERROR(EPERM);\nif (copy_from_user(&al_hreq, arg, sizeof(xfs_fsop_attrlist_handlereq_t)))\nreturn -XFS_ERROR(EFAULT);\nif (al_hreq.buflen > XATTR_LIST_MAX)\nreturn -XFS_ERROR(EINVAL);\nif (al_hreq.flags & ~(ATTR_ROOT | ATTR_SECURE))\nreturn -XFS_ERROR(EINVAL);\ndentry = xfs_handlereq_to_dentry(parfilp, &al_hreq.hreq);\nif (IS_ERR(dentry))\nreturn PTR_ERR(dentry);\nkbuf = kmem_zalloc_large(al_hreq.buflen, KM_SLEEP);\nif (!kbuf)\ngoto out_dput;\ncursor = (attrlist_cursor_kern_t *)&al_hreq.pos;\nerror = -xfs_attr_list(XFS_I(dentry->d_inode), kbuf, al_hreq.buflen,\nal_hreq.flags, cursor);\nif (error)\ngoto out_kfree;\nif (copy_to_user(al_hreq.buffer, kbuf, al_hreq.buflen))\nerror = -EFAULT;\nout_kfree:\nkmem_free(kbuf);\nout_dput:\ndput(dentry);\nreturn error;\n}\n"
    }
  ],
  "CVE-2013-7027": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper boundary checking for radiotap header length, allowing for potential buffer over-read.",
        "trigger_condition": "An attacker crafts a radiotap header with a length that extends beyond the specified maximum length, causing the code to read data outside of the expected bounds.",
        "specific_code_behavior_causing_vulnerability": "The code does not verify that the radiotap header length is within the specified maximum length before processing it, leading to a buffer over-read vulnerability. This oversight allows an attacker to manipulate the header length to read data outside of the intended boundaries."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the radiotap header can actually be present within the specified maximum length before proceeding with further processing. Additionally, the calculation for checking the extension beyond the radiotap header length should be adjusted to prevent buffer over-read issues. By incorporating these changes, the code can effectively prevent buffer over-read vulnerabilities and enhance its security posture.",
      "GPT_analysis": "The modification made to the code snippet is necessary to address the vulnerability CVE-2013-7027, which allows attackers to cause a denial of service (buffer over-read) by crafting a header that contains data outside of the expected bounds.\n\nThe vulnerability arises from the fact that the original code does not check whether a frame contains any data outside of the header before processing it. By adding the check `if (max_length < sizeof(struct ieee80211_radiotap_header))`, the modified code ensures that the radiotap header can actually be present within the specified maximum length before proceeding with further processing.\n\nAdditionally, the modification adjusts the calculation in the check for extending beyond the stated radiotap header length to prevent buffer over-read issues. By updating the calculation to `(unsigned long)iterator->_rtheader + sizeof(uint32_t)` instead of just `(unsigned long)iterator->_rtheader`, the code now correctly checks for potential buffer over-read scenarios and returns an error if such a condition is detected.\n\nOverall, these modifications enhance the security of the code by adding necessary checks to prevent buffer over-read vulnerabilities, thereby addressing the identified security issue.",
      "GPT_purpose": "Initialize an iterator for parsing radiotap headers in wireless communication.",
      "GPT_function": "\n1. Initialize the radiotap iterator with the provided radiotap header and parameters.\n2. Perform sanity checks on the radiotap header length and version.\n3. Handle extended radiotap headers and check for potential buffer over-read vulnerabilities.",
      "CVE_id": "CVE-2013-7027",
      "code_before_change": "int ieee80211_radiotap_iterator_init(\n\tstruct ieee80211_radiotap_iterator *iterator,\n\tstruct ieee80211_radiotap_header *radiotap_header,\n\tint max_length, const struct ieee80211_radiotap_vendor_namespaces *vns)\n{\n\t/* Linux only supports version 0 radiotap format */\n\tif (radiotap_header->it_version)\n\t\treturn -EINVAL;\n\n\t/* sanity check for allowed length and radiotap length field */\n\tif (max_length < get_unaligned_le16(&radiotap_header->it_len))\n\t\treturn -EINVAL;\n\n\titerator->_rtheader = radiotap_header;\n\titerator->_max_length = get_unaligned_le16(&radiotap_header->it_len);\n\titerator->_arg_index = 0;\n\titerator->_bitmap_shifter = get_unaligned_le32(&radiotap_header->it_present);\n\titerator->_arg = (uint8_t *)radiotap_header + sizeof(*radiotap_header);\n\titerator->_reset_on_ext = 0;\n\titerator->_next_bitmap = &radiotap_header->it_present;\n\titerator->_next_bitmap++;\n\titerator->_vns = vns;\n\titerator->current_namespace = &radiotap_ns;\n\titerator->is_radiotap_ns = 1;\n\n\t/* find payload start allowing for extended bitmap(s) */\n\n\tif (iterator->_bitmap_shifter & (1<<IEEE80211_RADIOTAP_EXT)) {\n\t\twhile (get_unaligned_le32(iterator->_arg) &\n\t\t\t\t\t(1 << IEEE80211_RADIOTAP_EXT)) {\n\t\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t\t/*\n\t\t\t * check for insanity where the present bitmaps\n\t\t\t * keep claiming to extend up to or even beyond the\n\t\t\t * stated radiotap header length\n\t\t\t */\n\n\t\t\tif ((unsigned long)iterator->_arg -\n\t\t\t    (unsigned long)iterator->_rtheader >\n\t\t\t    (unsigned long)iterator->_max_length)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t/*\n\t\t * no need to check again for blowing past stated radiotap\n\t\t * header length, because ieee80211_radiotap_iterator_next\n\t\t * checks it before it is dereferenced\n\t\t */\n\t}\n\n\titerator->this_arg = iterator->_arg;\n\n\t/* we are all initialized happily */\n\n\treturn 0;\n}",
      "code_after_change": "int ieee80211_radiotap_iterator_init(\n\tstruct ieee80211_radiotap_iterator *iterator,\n\tstruct ieee80211_radiotap_header *radiotap_header,\n\tint max_length, const struct ieee80211_radiotap_vendor_namespaces *vns)\n{\n\t/* check the radiotap header can actually be present */\n\tif (max_length < sizeof(struct ieee80211_radiotap_header))\n\t\treturn -EINVAL;\n\n\t/* Linux only supports version 0 radiotap format */\n\tif (radiotap_header->it_version)\n\t\treturn -EINVAL;\n\n\t/* sanity check for allowed length and radiotap length field */\n\tif (max_length < get_unaligned_le16(&radiotap_header->it_len))\n\t\treturn -EINVAL;\n\n\titerator->_rtheader = radiotap_header;\n\titerator->_max_length = get_unaligned_le16(&radiotap_header->it_len);\n\titerator->_arg_index = 0;\n\titerator->_bitmap_shifter = get_unaligned_le32(&radiotap_header->it_present);\n\titerator->_arg = (uint8_t *)radiotap_header + sizeof(*radiotap_header);\n\titerator->_reset_on_ext = 0;\n\titerator->_next_bitmap = &radiotap_header->it_present;\n\titerator->_next_bitmap++;\n\titerator->_vns = vns;\n\titerator->current_namespace = &radiotap_ns;\n\titerator->is_radiotap_ns = 1;\n\n\t/* find payload start allowing for extended bitmap(s) */\n\n\tif (iterator->_bitmap_shifter & (1<<IEEE80211_RADIOTAP_EXT)) {\n\t\twhile (get_unaligned_le32(iterator->_arg) &\n\t\t\t\t\t(1 << IEEE80211_RADIOTAP_EXT)) {\n\t\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t\t/*\n\t\t\t * check for insanity where the present bitmaps\n\t\t\t * keep claiming to extend up to or even beyond the\n\t\t\t * stated radiotap header length\n\t\t\t */\n\n\t\t\tif ((unsigned long)iterator->_arg -\n\t\t\t    (unsigned long)iterator->_rtheader +\n\t\t\t    sizeof(uint32_t) >\n\t\t\t    (unsigned long)iterator->_max_length)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t/*\n\t\t * no need to check again for blowing past stated radiotap\n\t\t * header length, because ieee80211_radiotap_iterator_next\n\t\t * checks it before it is dereferenced\n\t\t */\n\t}\n\n\titerator->this_arg = iterator->_arg;\n\n\t/* we are all initialized happily */\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t/* check the radiotap header can actually be present */",
          "\tif (max_length < sizeof(struct ieee80211_radiotap_header))",
          "\t\treturn -EINVAL;",
          "",
          "\t\t\t    (unsigned long)iterator->_rtheader +",
          "\t\t\t    sizeof(uint32_t) >"
        ],
        "deleted": [
          "\t\t\t    (unsigned long)iterator->_rtheader >"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper boundary checking for radiotap header length, allowing for potential buffer over-read.",
      "trigger_condition": "An attacker crafts a radiotap header with a length that extends beyond the specified maximum length, causing the code to read data outside of the expected bounds.",
      "specific_code_behavior_causing_vulnerability": "The code does not verify that the radiotap header length is within the specified maximum length before processing it, leading to a buffer over-read vulnerability. This oversight allows an attacker to manipulate the header length to read data outside of the intended boundaries.",
      "id": 47,
      "code_after_change_normalized": "int FUN1(\nstruct ieee80211_radiotap_iterator *VAR1,\nstruct ieee80211_radiotap_header *VAR2,\nint VAR3, const struct ieee80211_radiotap_vendor_namespaces *VAR4)\n{\nif (VAR3 < sizeof(struct VAR5))\nreturn -VAR6;\nif (VAR2->VAR7)\nreturn -VAR6;\nif (VAR3 < FUN2(&VAR2->VAR8))\nreturn -VAR6;\nVAR1->VAR9 = VAR2;\nVAR1->VAR10 = FUN2(&VAR2->VAR8);\nVAR1->VAR11 = 0;\nVAR1->VAR12 = FUN3(&VAR2->VAR13);\nVAR1->VAR14 = (VAR15 *)VAR2 + sizeof(*VAR2);\nVAR1->VAR16 = 0;\nVAR1->VAR17 = &VAR2->VAR13;\nVAR1->VAR17++;\nVAR1->VAR18 = VAR4;\nVAR1->VAR19 = &VAR20;\nVAR1->VAR21 = 1;\nif (VAR1->VAR12 & (1<<VAR22)) {\nwhile (FUN3(VAR1->VAR14) &\n(1 << VAR22)) {\nVAR1->VAR14 += sizeof(VAR23);\nif ((unsigned long)VAR1->VAR14 -\n(unsigned long)VAR1->VAR9 +\nsizeof(VAR23) >\n(unsigned long)VAR1->VAR10)\nreturn -VAR6;\n}\nVAR1->VAR14 += sizeof(VAR23);\n}\nVAR1->VAR24 = VAR1->VAR14;\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(\nstruct ieee80211_radiotap_iterator *VAR1,\nstruct ieee80211_radiotap_header *VAR2,\nint VAR3, const struct ieee80211_radiotap_vendor_namespaces *VAR4)\n{\nif (VAR2->VAR5)\nreturn -VAR6;\nif (VAR3 < FUN2(&VAR2->VAR7))\nreturn -VAR6;\nVAR1->VAR8 = VAR2;\nVAR1->VAR9 = FUN2(&VAR2->VAR7);\nVAR1->VAR10 = 0;\nVAR1->VAR11 = FUN3(&VAR2->VAR12);\nVAR1->VAR13 = (VAR14 *)VAR2 + sizeof(*VAR2);\nVAR1->VAR15 = 0;\nVAR1->VAR16 = &VAR2->VAR12;\nVAR1->VAR16++;\nVAR1->VAR17 = VAR4;\nVAR1->VAR18 = &VAR19;\nVAR1->VAR20 = 1;\nif (VAR1->VAR11 & (1<<VAR21)) {\nwhile (FUN3(VAR1->VAR13) &\n(1 << VAR21)) {\nVAR1->VAR13 += sizeof(VAR22);\nif ((unsigned long)VAR1->VAR13 -\n(unsigned long)VAR1->VAR8 >\n(unsigned long)VAR1->VAR9)\nreturn -VAR6;\n}\nVAR1->VAR13 += sizeof(VAR22);\n}\nVAR1->VAR23 = VAR1->VAR13;\nreturn 0;\n}\n",
      "code_after_change_raw": "int ieee80211_radiotap_iterator_init(\nstruct ieee80211_radiotap_iterator *iterator,\nstruct ieee80211_radiotap_header *radiotap_header,\nint max_length, const struct ieee80211_radiotap_vendor_namespaces *vns)\n{\nif (max_length < sizeof(struct ieee80211_radiotap_header))\nreturn -EINVAL;\nif (radiotap_header->it_version)\nreturn -EINVAL;\nif (max_length < get_unaligned_le16(&radiotap_header->it_len))\nreturn -EINVAL;\niterator->_rtheader = radiotap_header;\niterator->_max_length = get_unaligned_le16(&radiotap_header->it_len);\niterator->_arg_index = 0;\niterator->_bitmap_shifter = get_unaligned_le32(&radiotap_header->it_present);\niterator->_arg = (uint8_t *)radiotap_header + sizeof(*radiotap_header);\niterator->_reset_on_ext = 0;\niterator->_next_bitmap = &radiotap_header->it_present;\niterator->_next_bitmap++;\niterator->_vns = vns;\niterator->current_namespace = &radiotap_ns;\niterator->is_radiotap_ns = 1;\nif (iterator->_bitmap_shifter & (1<<IEEE80211_RADIOTAP_EXT)) {\nwhile (get_unaligned_le32(iterator->_arg) &\n(1 << IEEE80211_RADIOTAP_EXT)) {\niterator->_arg += sizeof(uint32_t);\nif ((unsigned long)iterator->_arg -\n(unsigned long)iterator->_rtheader +\nsizeof(uint32_t) >\n(unsigned long)iterator->_max_length)\nreturn -EINVAL;\n}\niterator->_arg += sizeof(uint32_t);\n}\niterator->this_arg = iterator->_arg;\nreturn 0;\n}\n",
      "code_before_change_raw": "int ieee80211_radiotap_iterator_init(\nstruct ieee80211_radiotap_iterator *iterator,\nstruct ieee80211_radiotap_header *radiotap_header,\nint max_length, const struct ieee80211_radiotap_vendor_namespaces *vns)\n{\nif (radiotap_header->it_version)\nreturn -EINVAL;\nif (max_length < get_unaligned_le16(&radiotap_header->it_len))\nreturn -EINVAL;\niterator->_rtheader = radiotap_header;\niterator->_max_length = get_unaligned_le16(&radiotap_header->it_len);\niterator->_arg_index = 0;\niterator->_bitmap_shifter = get_unaligned_le32(&radiotap_header->it_present);\niterator->_arg = (uint8_t *)radiotap_header + sizeof(*radiotap_header);\niterator->_reset_on_ext = 0;\niterator->_next_bitmap = &radiotap_header->it_present;\niterator->_next_bitmap++;\niterator->_vns = vns;\niterator->current_namespace = &radiotap_ns;\niterator->is_radiotap_ns = 1;\nif (iterator->_bitmap_shifter & (1<<IEEE80211_RADIOTAP_EXT)) {\nwhile (get_unaligned_le32(iterator->_arg) &\n(1 << IEEE80211_RADIOTAP_EXT)) {\niterator->_arg += sizeof(uint32_t);\nif ((unsigned long)iterator->_arg -\n(unsigned long)iterator->_rtheader >\n(unsigned long)iterator->_max_length)\nreturn -EINVAL;\n}\niterator->_arg += sizeof(uint32_t);\n}\niterator->this_arg = iterator->_arg;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2014-0069": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for uncached write operations that copy fewer than the requested number of bytes.",
        "trigger_condition": "A local user executes a writev system call with a crafted pointer, causing the copy operation to copy less data than expected.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check and handle cases where the copy operation does not copy the expected amount of data, potentially leading to sensitive information disclosure, denial of service, or privilege escalation."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add additional checks and handling in the code to ensure that the copy operation copies the expected amount of data. Specifically, the solution involves checking the number of bytes copied after each page copy, stopping the copying process if the expected amount is not copied, handling cases where no data is copied at all, and freeing any unused pages after the copy operation.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability described as CVE-2014-0069. The vulnerability arises from the fact that the original code does not properly handle uncached write operations that copy fewer than the requested number of bytes. This can lead to various security issues such as obtaining sensitive information from kernel memory, causing a denial of service (memory corruption and system crash), or potentially gaining privileges via a crafted pointer in a writev system call.\n\nThe modification addresses this vulnerability by adding additional checks and handling for cases where the copy operation does not copy as much data as expected. Specifically, the modification includes the following changes:\n\n1. Added a check after copying each page to ensure that the expected number of bytes are copied. If the copied bytes are less than expected, it indicates a potential issue with accessing unmapped memory, and the copying process is stopped to prevent further issues.\n\n2. Added a check to handle cases where no data is copied at all, which likely indicates a failure in the copy operation due to a bogus address in the iovec. In such cases, the modification sets the return code to -EFAULT, frees any allocated resources, and exits the loop.\n\n3. Adjusted the handling of unused pages after the copy operation to free any pages that were not actually used in the copy phase.\n\nBy making these modifications, the code is better equipped to handle scenarios where the copy operation encounters issues or does not copy the expected amount of data, thereby mitigating the vulnerability and improving the overall security and reliability of the function.",
      "GPT_purpose": "Perform write operations for CIFS (Common Internet File System) files using an iovec structure.",
      "GPT_function": "\n1. Perform generic write checks.\n2. Allocate and write data to pages.\n3. Handle retries and wait for completion of write operations.",
      "CVE_id": "CVE-2014-0069",
      "code_before_change": "static ssize_t\ncifs_iovec_write(struct file *file, const struct iovec *iov,\n\t\t unsigned long nr_segs, loff_t *poffset)\n{\n\tunsigned long nr_pages, i;\n\tsize_t copied, len, cur_len;\n\tssize_t total_written = 0;\n\tloff_t offset;\n\tstruct iov_iter it;\n\tstruct cifsFileInfo *open_file;\n\tstruct cifs_tcon *tcon;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct cifs_writedata *wdata, *tmp;\n\tstruct list_head wdata_list;\n\tint rc;\n\tpid_t pid;\n\n\tlen = iov_length(iov, nr_segs);\n\tif (!len)\n\t\treturn 0;\n\n\trc = generic_write_checks(file, poffset, &len, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tINIT_LIST_HEAD(&wdata_list);\n\tcifs_sb = CIFS_SB(file->f_path.dentry->d_sb);\n\topen_file = file->private_data;\n\ttcon = tlink_tcon(open_file->tlink);\n\n\tif (!tcon->ses->server->ops->async_writev)\n\t\treturn -ENOSYS;\n\n\toffset = *poffset;\n\n\tif (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD)\n\t\tpid = open_file->pid;\n\telse\n\t\tpid = current->tgid;\n\n\tiov_iter_init(&it, iov, nr_segs, len, 0);\n\tdo {\n\t\tsize_t save_len;\n\n\t\tnr_pages = get_numpages(cifs_sb->wsize, len, &cur_len);\n\t\twdata = cifs_writedata_alloc(nr_pages,\n\t\t\t\t\t     cifs_uncached_writev_complete);\n\t\tif (!wdata) {\n\t\t\trc = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\trc = cifs_write_allocate_pages(wdata->pages, nr_pages);\n\t\tif (rc) {\n\t\t\tkfree(wdata);\n\t\t\tbreak;\n\t\t}\n\n\t\tsave_len = cur_len;\n\t\tfor (i = 0; i < nr_pages; i++) {\n\t\t\tcopied = min_t(const size_t, cur_len, PAGE_SIZE);\n\t\t\tcopied = iov_iter_copy_from_user(wdata->pages[i], &it,\n\t\t\t\t\t\t\t 0, copied);\n\t\t\tcur_len -= copied;\n\t\t\tiov_iter_advance(&it, copied);\n\t\t}\n\t\tcur_len = save_len - cur_len;\n\n\t\twdata->sync_mode = WB_SYNC_ALL;\n\t\twdata->nr_pages = nr_pages;\n\t\twdata->offset = (__u64)offset;\n\t\twdata->cfile = cifsFileInfo_get(open_file);\n\t\twdata->pid = pid;\n\t\twdata->bytes = cur_len;\n\t\twdata->pagesz = PAGE_SIZE;\n\t\twdata->tailsz = cur_len - ((nr_pages - 1) * PAGE_SIZE);\n\t\trc = cifs_uncached_retry_writev(wdata);\n\t\tif (rc) {\n\t\t\tkref_put(&wdata->refcount,\n\t\t\t\t cifs_uncached_writedata_release);\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add_tail(&wdata->list, &wdata_list);\n\t\toffset += cur_len;\n\t\tlen -= cur_len;\n\t} while (len > 0);\n\n\t/*\n\t * If at least one write was successfully sent, then discard any rc\n\t * value from the later writes. If the other write succeeds, then\n\t * we'll end up returning whatever was written. If it fails, then\n\t * we'll get a new rc value from that.\n\t */\n\tif (!list_empty(&wdata_list))\n\t\trc = 0;\n\n\t/*\n\t * Wait for and collect replies for any successful sends in order of\n\t * increasing offset. Once an error is hit or we get a fatal signal\n\t * while waiting, then return without waiting for any more replies.\n\t */\nrestart_loop:\n\tlist_for_each_entry_safe(wdata, tmp, &wdata_list, list) {\n\t\tif (!rc) {\n\t\t\t/* FIXME: freezable too? */\n\t\t\trc = wait_for_completion_killable(&wdata->done);\n\t\t\tif (rc)\n\t\t\t\trc = -EINTR;\n\t\t\telse if (wdata->result)\n\t\t\t\trc = wdata->result;\n\t\t\telse\n\t\t\t\ttotal_written += wdata->bytes;\n\n\t\t\t/* resend call if it's a retryable error */\n\t\t\tif (rc == -EAGAIN) {\n\t\t\t\trc = cifs_uncached_retry_writev(wdata);\n\t\t\t\tgoto restart_loop;\n\t\t\t}\n\t\t}\n\t\tlist_del_init(&wdata->list);\n\t\tkref_put(&wdata->refcount, cifs_uncached_writedata_release);\n\t}\n\n\tif (total_written > 0)\n\t\t*poffset += total_written;\n\n\tcifs_stats_bytes_written(tcon, total_written);\n\treturn total_written ? total_written : (ssize_t)rc;\n}",
      "code_after_change": "static ssize_t\ncifs_iovec_write(struct file *file, const struct iovec *iov,\n\t\t unsigned long nr_segs, loff_t *poffset)\n{\n\tunsigned long nr_pages, i;\n\tsize_t bytes, copied, len, cur_len;\n\tssize_t total_written = 0;\n\tloff_t offset;\n\tstruct iov_iter it;\n\tstruct cifsFileInfo *open_file;\n\tstruct cifs_tcon *tcon;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct cifs_writedata *wdata, *tmp;\n\tstruct list_head wdata_list;\n\tint rc;\n\tpid_t pid;\n\n\tlen = iov_length(iov, nr_segs);\n\tif (!len)\n\t\treturn 0;\n\n\trc = generic_write_checks(file, poffset, &len, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tINIT_LIST_HEAD(&wdata_list);\n\tcifs_sb = CIFS_SB(file->f_path.dentry->d_sb);\n\topen_file = file->private_data;\n\ttcon = tlink_tcon(open_file->tlink);\n\n\tif (!tcon->ses->server->ops->async_writev)\n\t\treturn -ENOSYS;\n\n\toffset = *poffset;\n\n\tif (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD)\n\t\tpid = open_file->pid;\n\telse\n\t\tpid = current->tgid;\n\n\tiov_iter_init(&it, iov, nr_segs, len, 0);\n\tdo {\n\t\tsize_t save_len;\n\n\t\tnr_pages = get_numpages(cifs_sb->wsize, len, &cur_len);\n\t\twdata = cifs_writedata_alloc(nr_pages,\n\t\t\t\t\t     cifs_uncached_writev_complete);\n\t\tif (!wdata) {\n\t\t\trc = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\trc = cifs_write_allocate_pages(wdata->pages, nr_pages);\n\t\tif (rc) {\n\t\t\tkfree(wdata);\n\t\t\tbreak;\n\t\t}\n\n\t\tsave_len = cur_len;\n\t\tfor (i = 0; i < nr_pages; i++) {\n\t\t\tbytes = min_t(const size_t, cur_len, PAGE_SIZE);\n\t\t\tcopied = iov_iter_copy_from_user(wdata->pages[i], &it,\n\t\t\t\t\t\t\t 0, bytes);\n\t\t\tcur_len -= copied;\n\t\t\tiov_iter_advance(&it, copied);\n\t\t\t/*\n\t\t\t * If we didn't copy as much as we expected, then that\n\t\t\t * may mean we trod into an unmapped area. Stop copying\n\t\t\t * at that point. On the next pass through the big\n\t\t\t * loop, we'll likely end up getting a zero-length\n\t\t\t * write and bailing out of it.\n\t\t\t */\n\t\t\tif (copied < bytes)\n\t\t\t\tbreak;\n\t\t}\n\t\tcur_len = save_len - cur_len;\n\n\t\t/*\n\t\t * If we have no data to send, then that probably means that\n\t\t * the copy above failed altogether. That's most likely because\n\t\t * the address in the iovec was bogus. Set the rc to -EFAULT,\n\t\t * free anything we allocated and bail out.\n\t\t */\n\t\tif (!cur_len) {\n\t\t\tfor (i = 0; i < nr_pages; i++)\n\t\t\t\tput_page(wdata->pages[i]);\n\t\t\tkfree(wdata);\n\t\t\trc = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * i + 1 now represents the number of pages we actually used in\n\t\t * the copy phase above. Bring nr_pages down to that, and free\n\t\t * any pages that we didn't use.\n\t\t */\n\t\tfor ( ; nr_pages > i + 1; nr_pages--)\n\t\t\tput_page(wdata->pages[nr_pages - 1]);\n\n\t\twdata->sync_mode = WB_SYNC_ALL;\n\t\twdata->nr_pages = nr_pages;\n\t\twdata->offset = (__u64)offset;\n\t\twdata->cfile = cifsFileInfo_get(open_file);\n\t\twdata->pid = pid;\n\t\twdata->bytes = cur_len;\n\t\twdata->pagesz = PAGE_SIZE;\n\t\twdata->tailsz = cur_len - ((nr_pages - 1) * PAGE_SIZE);\n\t\trc = cifs_uncached_retry_writev(wdata);\n\t\tif (rc) {\n\t\t\tkref_put(&wdata->refcount,\n\t\t\t\t cifs_uncached_writedata_release);\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add_tail(&wdata->list, &wdata_list);\n\t\toffset += cur_len;\n\t\tlen -= cur_len;\n\t} while (len > 0);\n\n\t/*\n\t * If at least one write was successfully sent, then discard any rc\n\t * value from the later writes. If the other write succeeds, then\n\t * we'll end up returning whatever was written. If it fails, then\n\t * we'll get a new rc value from that.\n\t */\n\tif (!list_empty(&wdata_list))\n\t\trc = 0;\n\n\t/*\n\t * Wait for and collect replies for any successful sends in order of\n\t * increasing offset. Once an error is hit or we get a fatal signal\n\t * while waiting, then return without waiting for any more replies.\n\t */\nrestart_loop:\n\tlist_for_each_entry_safe(wdata, tmp, &wdata_list, list) {\n\t\tif (!rc) {\n\t\t\t/* FIXME: freezable too? */\n\t\t\trc = wait_for_completion_killable(&wdata->done);\n\t\t\tif (rc)\n\t\t\t\trc = -EINTR;\n\t\t\telse if (wdata->result)\n\t\t\t\trc = wdata->result;\n\t\t\telse\n\t\t\t\ttotal_written += wdata->bytes;\n\n\t\t\t/* resend call if it's a retryable error */\n\t\t\tif (rc == -EAGAIN) {\n\t\t\t\trc = cifs_uncached_retry_writev(wdata);\n\t\t\t\tgoto restart_loop;\n\t\t\t}\n\t\t}\n\t\tlist_del_init(&wdata->list);\n\t\tkref_put(&wdata->refcount, cifs_uncached_writedata_release);\n\t}\n\n\tif (total_written > 0)\n\t\t*poffset += total_written;\n\n\tcifs_stats_bytes_written(tcon, total_written);\n\treturn total_written ? total_written : (ssize_t)rc;\n}",
      "modified_lines": {
        "added": [
          "\tsize_t bytes, copied, len, cur_len;",
          "\t\t\tbytes = min_t(const size_t, cur_len, PAGE_SIZE);",
          "\t\t\t\t\t\t\t 0, bytes);",
          "\t\t\t/*",
          "\t\t\t * If we didn't copy as much as we expected, then that",
          "\t\t\t * may mean we trod into an unmapped area. Stop copying",
          "\t\t\t * at that point. On the next pass through the big",
          "\t\t\t * loop, we'll likely end up getting a zero-length",
          "\t\t\t * write and bailing out of it.",
          "\t\t\t */",
          "\t\t\tif (copied < bytes)",
          "\t\t\t\tbreak;",
          "",
          "\t\t/*",
          "\t\t * If we have no data to send, then that probably means that",
          "\t\t * the copy above failed altogether. That's most likely because",
          "\t\t * the address in the iovec was bogus. Set the rc to -EFAULT,",
          "\t\t * free anything we allocated and bail out.",
          "\t\t */",
          "\t\tif (!cur_len) {",
          "\t\t\tfor (i = 0; i < nr_pages; i++)",
          "\t\t\t\tput_page(wdata->pages[i]);",
          "\t\t\tkfree(wdata);",
          "\t\t\trc = -EFAULT;",
          "\t\t\tbreak;",
          "\t\t}",
          "",
          "\t\t/*",
          "\t\t * i + 1 now represents the number of pages we actually used in",
          "\t\t * the copy phase above. Bring nr_pages down to that, and free",
          "\t\t * any pages that we didn't use.",
          "\t\t */",
          "\t\tfor ( ; nr_pages > i + 1; nr_pages--)",
          "\t\t\tput_page(wdata->pages[nr_pages - 1]);"
        ],
        "deleted": [
          "\tsize_t copied, len, cur_len;",
          "\t\t\tcopied = min_t(const size_t, cur_len, PAGE_SIZE);",
          "\t\t\t\t\t\t\t 0, copied);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for uncached write operations that copy fewer than the requested number of bytes.",
      "trigger_condition": "A local user executes a writev system call with a crafted pointer, causing the copy operation to copy less data than expected.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check and handle cases where the copy operation does not copy the expected amount of data, potentially leading to sensitive information disclosure, denial of service, or privilege escalation.",
      "id": 48,
      "code_after_change_normalized": "static VAR1\nFUN1(struct VAR2 *VAR2, const struct iovec *VAR3,\nunsigned long VAR4, loff_t *VAR5)\n{\nunsigned long VAR6, VAR7;\nsize_t VAR8, VAR9, VAR10, VAR11;\nssize_t VAR12 = 0;\nloff_t VAR13;\nstruct iov_iter VAR14;\nstruct cifsFileInfo *VAR15;\nstruct cifs_tcon *VAR16;\nstruct cifs_sb_info *VAR17;\nstruct cifs_writedata *VAR18, *VAR19;\nstruct list_head VAR20;\nint VAR21;\npid_t VAR22;\nVAR10 = FUN2(VAR3, VAR4);\nif (!VAR10)\nreturn 0;\nVAR21 = FUN3(VAR2, VAR5, &VAR10, 0);\nif (VAR21)\nreturn VAR21;\nFUN4(&VAR20);\nVAR17 = FUN5(VAR2->VAR23.VAR24->VAR25);\nVAR15 = VAR2->VAR26;\nVAR16 = FUN6(VAR15->VAR27);\nif (!VAR16->VAR28->VAR29->VAR30->VAR31)\nreturn -VAR32;\nVAR13 = *VAR5;\nif (VAR17->VAR33 & VAR34)\nVAR22 = VAR15->VAR22;\nelse\nVAR22 = VAR35->VAR36;\nFUN7(&VAR14, VAR3, VAR4, VAR10, 0);\ndo {\nsize_t VAR37;\nVAR6 = FUN8(VAR17->VAR38, VAR10, &VAR11);\nVAR18 = FUN9(VAR6,\nVAR39);\nif (!VAR18) {\nVAR21 = -VAR40;\nbreak;\n}\nVAR21 = FUN10(VAR18->VAR41, VAR6);\nif (VAR21) {\nFUN11(VAR18);\nbreak;\n}\nVAR37 = VAR11;\nfor (VAR7 = 0; VAR7 < VAR6; VAR7++) {\nVAR8 = FUN12(const VAR42, VAR11, VAR43);\nVAR9 = FUN13(VAR18->VAR41[VAR7], &VAR14,\n0, VAR8);\nVAR11 -= VAR9;\nFUN14(&VAR14, VAR9);\nif (VAR9 < VAR8)\nbreak;\n}\nVAR11 = VAR37 - VAR11;\nif (!VAR11) {\nfor (VAR7 = 0; VAR7 < VAR6; VAR7++)\nFUN15(VAR18->VAR41[VAR7]);\nFUN11(VAR18);\nVAR21 = -VAR44;\nbreak;\n}\nfor ( ; VAR6 > VAR7 + 1; VAR6--)\nFUN15(VAR18->VAR41[VAR6 - 1]);\nVAR18->VAR45 = VAR46;\nVAR18->VAR6 = VAR6;\nVAR18->VAR13 = (VAR47)VAR13;\nVAR18->VAR48 = FUN16(VAR15);\nVAR18->VAR22 = VAR22;\nVAR18->VAR8 = VAR11;\nVAR18->VAR49 = VAR43;\nVAR18->VAR50 = VAR11 - ((VAR6 - 1) * VAR43);\nVAR21 = FUN17(VAR18);\nif (VAR21) {\nFUN18(&VAR18->VAR51,\nVAR52);\nbreak;\n}\nFUN19(&VAR18->VAR53, &VAR20);\nVAR13 += VAR11;\nVAR10 -= VAR11;\n} while (VAR10 > 0);\nif (!FUN20(&VAR20))\nVAR21 = 0;\nVAR54:\nFUN21(VAR18, VAR19, &VAR20, VAR53) {\nif (!VAR21) {\nVAR21 = FUN22(&VAR18->VAR55);\nif (VAR21)\nVAR21 = -VAR56;\nelse if (VAR18->VAR57)\nVAR21 = VAR18->VAR57;\nelse\nVAR12 += VAR18->VAR8;\nif (VAR21 == -VAR58) {\nVAR21 = FUN17(VAR18);\ngoto VAR54;\n}\n}\nFUN23(&VAR18->VAR53);\nFUN18(&VAR18->VAR51, VAR52);\n}\nif (VAR12 > 0)\n*VAR5 += VAR12;\nFUN24(VAR16, VAR12);\nreturn VAR12 ? VAR12 : (VAR1)VAR21;\n}\n",
      "code_before_change_normalized": "static VAR1\nFUN1(struct VAR2 *VAR2, const struct iovec *VAR3,\nunsigned long VAR4, loff_t *VAR5)\n{\nunsigned long VAR6, VAR7;\nsize_t VAR8, VAR9, VAR10;\nssize_t VAR11 = 0;\nloff_t VAR12;\nstruct iov_iter VAR13;\nstruct cifsFileInfo *VAR14;\nstruct cifs_tcon *VAR15;\nstruct cifs_sb_info *VAR16;\nstruct cifs_writedata *VAR17, *VAR18;\nstruct list_head VAR19;\nint VAR20;\npid_t VAR21;\nVAR9 = FUN2(VAR3, VAR4);\nif (!VAR9)\nreturn 0;\nVAR20 = FUN3(VAR2, VAR5, &VAR9, 0);\nif (VAR20)\nreturn VAR20;\nFUN4(&VAR19);\nVAR16 = FUN5(VAR2->VAR22.VAR23->VAR24);\nVAR14 = VAR2->VAR25;\nVAR15 = FUN6(VAR14->VAR26);\nif (!VAR15->VAR27->VAR28->VAR29->VAR30)\nreturn -VAR31;\nVAR12 = *VAR5;\nif (VAR16->VAR32 & VAR33)\nVAR21 = VAR14->VAR21;\nelse\nVAR21 = VAR34->VAR35;\nFUN7(&VAR13, VAR3, VAR4, VAR9, 0);\ndo {\nsize_t VAR36;\nVAR6 = FUN8(VAR16->VAR37, VAR9, &VAR10);\nVAR17 = FUN9(VAR6,\nVAR38);\nif (!VAR17) {\nVAR20 = -VAR39;\nbreak;\n}\nVAR20 = FUN10(VAR17->VAR40, VAR6);\nif (VAR20) {\nFUN11(VAR17);\nbreak;\n}\nVAR36 = VAR10;\nfor (VAR7 = 0; VAR7 < VAR6; VAR7++) {\nVAR8 = FUN12(const VAR41, VAR10, VAR42);\nVAR8 = FUN13(VAR17->VAR40[VAR7], &VAR13,\n0, VAR8);\nVAR10 -= VAR8;\nFUN14(&VAR13, VAR8);\n}\nVAR10 = VAR36 - VAR10;\nVAR17->VAR43 = VAR44;\nVAR17->VAR6 = VAR6;\nVAR17->VAR12 = (VAR45)VAR12;\nVAR17->VAR46 = FUN15(VAR14);\nVAR17->VAR21 = VAR21;\nVAR17->VAR47 = VAR10;\nVAR17->VAR48 = VAR42;\nVAR17->VAR49 = VAR10 - ((VAR6 - 1) * VAR42);\nVAR20 = FUN16(VAR17);\nif (VAR20) {\nFUN17(&VAR17->VAR50,\nVAR51);\nbreak;\n}\nFUN18(&VAR17->VAR52, &VAR19);\nVAR12 += VAR10;\nVAR9 -= VAR10;\n} while (VAR9 > 0);\nif (!FUN19(&VAR19))\nVAR20 = 0;\nVAR53:\nFUN20(VAR17, VAR18, &VAR19, VAR52) {\nif (!VAR20) {\nVAR20 = FUN21(&VAR17->VAR54);\nif (VAR20)\nVAR20 = -VAR55;\nelse if (VAR17->VAR56)\nVAR20 = VAR17->VAR56;\nelse\nVAR11 += VAR17->VAR47;\nif (VAR20 == -VAR57) {\nVAR20 = FUN16(VAR17);\ngoto VAR53;\n}\n}\nFUN22(&VAR17->VAR52);\nFUN17(&VAR17->VAR50, VAR51);\n}\nif (VAR11 > 0)\n*VAR5 += VAR11;\nFUN23(VAR15, VAR11);\nreturn VAR11 ? VAR11 : (VAR1)VAR20;\n}\n",
      "code_after_change_raw": "static ssize_t\ncifs_iovec_write(struct file *file, const struct iovec *iov,\nunsigned long nr_segs, loff_t *poffset)\n{\nunsigned long nr_pages, i;\nsize_t bytes, copied, len, cur_len;\nssize_t total_written = 0;\nloff_t offset;\nstruct iov_iter it;\nstruct cifsFileInfo *open_file;\nstruct cifs_tcon *tcon;\nstruct cifs_sb_info *cifs_sb;\nstruct cifs_writedata *wdata, *tmp;\nstruct list_head wdata_list;\nint rc;\npid_t pid;\nlen = iov_length(iov, nr_segs);\nif (!len)\nreturn 0;\nrc = generic_write_checks(file, poffset, &len, 0);\nif (rc)\nreturn rc;\nINIT_LIST_HEAD(&wdata_list);\ncifs_sb = CIFS_SB(file->f_path.dentry->d_sb);\nopen_file = file->private_data;\ntcon = tlink_tcon(open_file->tlink);\nif (!tcon->ses->server->ops->async_writev)\nreturn -ENOSYS;\noffset = *poffset;\nif (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD)\npid = open_file->pid;\nelse\npid = current->tgid;\niov_iter_init(&it, iov, nr_segs, len, 0);\ndo {\nsize_t save_len;\nnr_pages = get_numpages(cifs_sb->wsize, len, &cur_len);\nwdata = cifs_writedata_alloc(nr_pages,\ncifs_uncached_writev_complete);\nif (!wdata) {\nrc = -ENOMEM;\nbreak;\n}\nrc = cifs_write_allocate_pages(wdata->pages, nr_pages);\nif (rc) {\nkfree(wdata);\nbreak;\n}\nsave_len = cur_len;\nfor (i = 0; i < nr_pages; i++) {\nbytes = min_t(const size_t, cur_len, PAGE_SIZE);\ncopied = iov_iter_copy_from_user(wdata->pages[i], &it,\n0, bytes);\ncur_len -= copied;\niov_iter_advance(&it, copied);\nif (copied < bytes)\nbreak;\n}\ncur_len = save_len - cur_len;\nif (!cur_len) {\nfor (i = 0; i < nr_pages; i++)\nput_page(wdata->pages[i]);\nkfree(wdata);\nrc = -EFAULT;\nbreak;\n}\nfor ( ; nr_pages > i + 1; nr_pages--)\nput_page(wdata->pages[nr_pages - 1]);\nwdata->sync_mode = WB_SYNC_ALL;\nwdata->nr_pages = nr_pages;\nwdata->offset = (__u64)offset;\nwdata->cfile = cifsFileInfo_get(open_file);\nwdata->pid = pid;\nwdata->bytes = cur_len;\nwdata->pagesz = PAGE_SIZE;\nwdata->tailsz = cur_len - ((nr_pages - 1) * PAGE_SIZE);\nrc = cifs_uncached_retry_writev(wdata);\nif (rc) {\nkref_put(&wdata->refcount,\ncifs_uncached_writedata_release);\nbreak;\n}\nlist_add_tail(&wdata->list, &wdata_list);\noffset += cur_len;\nlen -= cur_len;\n} while (len > 0);\nif (!list_empty(&wdata_list))\nrc = 0;\nrestart_loop:\nlist_for_each_entry_safe(wdata, tmp, &wdata_list, list) {\nif (!rc) {\nrc = wait_for_completion_killable(&wdata->done);\nif (rc)\nrc = -EINTR;\nelse if (wdata->result)\nrc = wdata->result;\nelse\ntotal_written += wdata->bytes;\nif (rc == -EAGAIN) {\nrc = cifs_uncached_retry_writev(wdata);\ngoto restart_loop;\n}\n}\nlist_del_init(&wdata->list);\nkref_put(&wdata->refcount, cifs_uncached_writedata_release);\n}\nif (total_written > 0)\n*poffset += total_written;\ncifs_stats_bytes_written(tcon, total_written);\nreturn total_written ? total_written : (ssize_t)rc;\n}\n",
      "code_before_change_raw": "static ssize_t\ncifs_iovec_write(struct file *file, const struct iovec *iov,\nunsigned long nr_segs, loff_t *poffset)\n{\nunsigned long nr_pages, i;\nsize_t copied, len, cur_len;\nssize_t total_written = 0;\nloff_t offset;\nstruct iov_iter it;\nstruct cifsFileInfo *open_file;\nstruct cifs_tcon *tcon;\nstruct cifs_sb_info *cifs_sb;\nstruct cifs_writedata *wdata, *tmp;\nstruct list_head wdata_list;\nint rc;\npid_t pid;\nlen = iov_length(iov, nr_segs);\nif (!len)\nreturn 0;\nrc = generic_write_checks(file, poffset, &len, 0);\nif (rc)\nreturn rc;\nINIT_LIST_HEAD(&wdata_list);\ncifs_sb = CIFS_SB(file->f_path.dentry->d_sb);\nopen_file = file->private_data;\ntcon = tlink_tcon(open_file->tlink);\nif (!tcon->ses->server->ops->async_writev)\nreturn -ENOSYS;\noffset = *poffset;\nif (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD)\npid = open_file->pid;\nelse\npid = current->tgid;\niov_iter_init(&it, iov, nr_segs, len, 0);\ndo {\nsize_t save_len;\nnr_pages = get_numpages(cifs_sb->wsize, len, &cur_len);\nwdata = cifs_writedata_alloc(nr_pages,\ncifs_uncached_writev_complete);\nif (!wdata) {\nrc = -ENOMEM;\nbreak;\n}\nrc = cifs_write_allocate_pages(wdata->pages, nr_pages);\nif (rc) {\nkfree(wdata);\nbreak;\n}\nsave_len = cur_len;\nfor (i = 0; i < nr_pages; i++) {\ncopied = min_t(const size_t, cur_len, PAGE_SIZE);\ncopied = iov_iter_copy_from_user(wdata->pages[i], &it,\n0, copied);\ncur_len -= copied;\niov_iter_advance(&it, copied);\n}\ncur_len = save_len - cur_len;\nwdata->sync_mode = WB_SYNC_ALL;\nwdata->nr_pages = nr_pages;\nwdata->offset = (__u64)offset;\nwdata->cfile = cifsFileInfo_get(open_file);\nwdata->pid = pid;\nwdata->bytes = cur_len;\nwdata->pagesz = PAGE_SIZE;\nwdata->tailsz = cur_len - ((nr_pages - 1) * PAGE_SIZE);\nrc = cifs_uncached_retry_writev(wdata);\nif (rc) {\nkref_put(&wdata->refcount,\ncifs_uncached_writedata_release);\nbreak;\n}\nlist_add_tail(&wdata->list, &wdata_list);\noffset += cur_len;\nlen -= cur_len;\n} while (len > 0);\nif (!list_empty(&wdata_list))\nrc = 0;\nrestart_loop:\nlist_for_each_entry_safe(wdata, tmp, &wdata_list, list) {\nif (!rc) {\nrc = wait_for_completion_killable(&wdata->done);\nif (rc)\nrc = -EINTR;\nelse if (wdata->result)\nrc = wdata->result;\nelse\ntotal_written += wdata->bytes;\nif (rc == -EAGAIN) {\nrc = cifs_uncached_retry_writev(wdata);\ngoto restart_loop;\n}\n}\nlist_del_init(&wdata->list);\nkref_put(&wdata->refcount, cifs_uncached_writedata_release);\n}\nif (total_written > 0)\n*poffset += total_written;\ncifs_stats_bytes_written(tcon, total_written);\nreturn total_written ? total_written : (ssize_t)rc;\n}\n"
    }
  ],
  "CVE-2014-0205": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper maintenance of a reference count during requeue operations in the futex_wait function.",
        "trigger_condition": "A local user triggers a zero count during a requeue operation, leading to a use-after-free vulnerability and system crash.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly maintain the reference count during requeue operations, allowing a zero count to be triggered by a crafted application. This results in a use-after-free scenario and potential privilege escalation."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper management of the reference count during requeue operations in the futex_wait function. This involves adding/modifying code to correctly handle the reference count and prevent a zero count from being triggered. By addressing this issue, the vulnerability can be fixed, preventing the use-after-free vulnerability and potential system crash or privilege escalation.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2014-0205, which involves a use-after-free issue and system crash caused by improper maintenance of a reference count during requeue operations in the futex_wait function. By adding the modified lines, you can ensure that the reference count is properly managed, preventing the possibility of a zero count being triggered by a crafted application. This fix helps to prevent denial of service attacks and potential privilege escalation that could result from exploiting this vulnerability.",
      "GPT_purpose": "Unlock a queue and drop references to a futex key.",
      "GPT_function": "\n1. Unlock a futex queue by releasing the lock on a hash bucket.\n2. Drop reference counts for a futex key.",
      "CVE_id": "CVE-2014-0205",
      "code_before_change": "static inline void\nqueue_unlock(struct futex_q *q, struct futex_hash_bucket *hb)\n{\n\tspin_unlock(&hb->lock);\n\tdrop_futex_key_refs(&q->key);\n}",
      "code_after_change": "static inline void\nqueue_unlock(struct futex_q *q, struct futex_hash_bucket *hb)\n{\n\tspin_unlock(&hb->lock);\n}",
      "modified_lines": {
        "added": [],
        "deleted": [
          "\tdrop_futex_key_refs(&q->key);"
        ]
      },
      "preconditions_for_vulnerability": "Improper maintenance of a reference count during requeue operations in the futex_wait function.",
      "trigger_condition": "A local user triggers a zero count during a requeue operation, leading to a use-after-free vulnerability and system crash.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly maintain the reference count during requeue operations, allowing a zero count to be triggered by a crafted application. This results in a use-after-free scenario and potential privilege escalation.",
      "id": 49,
      "code_after_change_normalized": "static inline void\nFUN1(struct futex_q *VAR1, struct futex_hash_bucket *VAR2)\n{\nFUN2(&VAR2->VAR3);\n}\n",
      "code_before_change_normalized": "static inline void\nFUN1(struct futex_q *VAR1, struct futex_hash_bucket *VAR2)\n{\nFUN2(&VAR2->VAR3);\nFUN3(&VAR1->VAR4);\n}\n",
      "code_after_change_raw": "static inline void\nqueue_unlock(struct futex_q *q, struct futex_hash_bucket *hb)\n{\nspin_unlock(&hb->lock);\n}\n",
      "code_before_change_raw": "static inline void\nqueue_unlock(struct futex_q *q, struct futex_hash_bucket *hb)\n{\nspin_unlock(&hb->lock);\ndrop_futex_key_refs(&q->key);\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper reference count maintenance during requeue operations in the futex_wait function.",
        "trigger_condition": "Local users trigger a zero count during requeue operations, leading to a denial of service, use-after-free, and system crash vulnerabilities.",
        "specific_code_behavior_causing_vulnerability": "The code in the futex_wait function does not properly maintain a reference count during requeue operations, allowing for a zero count to be triggered by a crafted application. This can result in a denial of service, use-after-free, and system crash vulnerabilities."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper maintenance of the reference count during requeue operations in the futex_wait function. This involves adding code to correctly handle the reference count to prevent a zero count scenario. By addressing this issue, the vulnerability can be fixed, and the system's security and stability can be improved.",
      "GPT_analysis": "The modification is necessary to fix the vulnerability CVE-2014-0205 by properly maintaining the reference count during requeue operations in the futex_wait function. By adding the modified lines, you ensure that the reference count is correctly handled, preventing a use-after-free scenario and potential system crash or privilege escalation that could be triggered by a crafted application causing a zero count. This fix helps to address the vulnerability and improve the security and stability of the system.",
      "GPT_purpose": "Lock a futex queue for synchronization purposes.",
      "GPT_function": "\n1. Increments the reference count of a futex key.\n2. Retrieves the hash bucket for the futex key.\n3. Acquires a spin lock on the hash bucket's lock.",
      "CVE_id": "CVE-2014-0205",
      "code_before_change": "static inline struct futex_hash_bucket *queue_lock(struct futex_q *q)\n{\n\tstruct futex_hash_bucket *hb;\n\n\tget_futex_key_refs(&q->key);\n\thb = hash_futex(&q->key);\n\tq->lock_ptr = &hb->lock;\n\n\tspin_lock(&hb->lock);\n\treturn hb;\n}",
      "code_after_change": "static inline struct futex_hash_bucket *queue_lock(struct futex_q *q)\n{\n\tstruct futex_hash_bucket *hb;\n\n\thb = hash_futex(&q->key);\n\tq->lock_ptr = &hb->lock;\n\n\tspin_lock(&hb->lock);\n\treturn hb;\n}",
      "modified_lines": {
        "added": [],
        "deleted": [
          "\tget_futex_key_refs(&q->key);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper reference count maintenance during requeue operations in the futex_wait function.",
      "trigger_condition": "Local users trigger a zero count during requeue operations, leading to a denial of service, use-after-free, and system crash vulnerabilities.",
      "specific_code_behavior_causing_vulnerability": "The code in the futex_wait function does not properly maintain a reference count during requeue operations, allowing for a zero count to be triggered by a crafted application. This can result in a denial of service, use-after-free, and system crash vulnerabilities.",
      "id": 50,
      "code_after_change_normalized": "static inline struct futex_hash_bucket *FUN1(struct futex_q *VAR1)\n{\nstruct futex_hash_bucket *VAR2;\nVAR2 = FUN2(&VAR1->VAR3);\nVAR1->VAR4 = &VAR2->VAR5;\nFUN3(&VAR2->VAR5);\nreturn VAR2;\n}\n",
      "code_before_change_normalized": "static inline struct futex_hash_bucket *FUN1(struct futex_q *VAR1)\n{\nstruct futex_hash_bucket *VAR2;\nFUN2(&VAR1->VAR3);\nVAR2 = FUN3(&VAR1->VAR3);\nVAR1->VAR4 = &VAR2->VAR5;\nFUN4(&VAR2->VAR5);\nreturn VAR2;\n}\n",
      "code_after_change_raw": "static inline struct futex_hash_bucket *queue_lock(struct futex_q *q)\n{\nstruct futex_hash_bucket *hb;\nhb = hash_futex(&q->key);\nq->lock_ptr = &hb->lock;\nspin_lock(&hb->lock);\nreturn hb;\n}\n",
      "code_before_change_raw": "static inline struct futex_hash_bucket *queue_lock(struct futex_q *q)\n{\nstruct futex_hash_bucket *hb;\nget_futex_key_refs(&q->key);\nhb = hash_futex(&q->key);\nq->lock_ptr = &hb->lock;\nspin_lock(&hb->lock);\nreturn hb;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper maintenance of reference count during requeue operations in the futex subsystem.",
        "trigger_condition": "Local users trigger a zero count during requeue operations, leading to a use-after-free vulnerability and potential denial of service or privilege escalation.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly decrement and check the reference count before freeing the pi_state structure, allowing for a use-after-free scenario if the count is manipulated to zero."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper reference count maintenance during requeue operations. This involves adding a check to decrement and verify the reference count before freeing the pi_state structure. By implementing this change, the code can prevent the use-after-free vulnerability and associated risks of denial of service or privilege escalation.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2014-0205, which involves a use-after-free issue in the futex subsystem of the Linux kernel. In the vulnerable code snippet provided, the function unqueue_me_pi is responsible for dequeuing a futex queue entry and freeing associated resources. However, there is a flaw in the reference count maintenance during requeue operations, which can lead to a use-after-free scenario.\n\nBy adding the following lines to the code snippet:\n'''\nif (!refcount_dec_and_test(&q->pi_state->refcount))\n\treturn;\n'''\nand deleting the line:\n'''\nBUG_ON(!q->pi_state);\n'''\nwe ensure that the reference count is properly decremented and checked before freeing the pi_state structure. This modification prevents the use-after-free vulnerability by ensuring that the pi_state structure is only freed when the reference count reaches zero, indicating that it is safe to do so.\n\nIn summary, the modification is necessary to fix the vulnerability by addressing the incorrect reference count maintenance that could lead to a use-after-free scenario and potential denial of service or privilege escalation issues.",
      "GPT_purpose": "Unqueues a futex queue and releases associated resources.",
      "GPT_function": "\n1. Unqueues a futex queue.\n2. Deletes a node from a priority list.\n3. Frees a PI state.\n4. Unlocks a spinlock.\n5. Drops futex key references.",
      "CVE_id": "CVE-2014-0205",
      "code_before_change": "static void unqueue_me_pi(struct futex_q *q)\n{\n\tWARN_ON(plist_node_empty(&q->list));\n\tplist_del(&q->list, &q->list.plist);\n\n\tBUG_ON(!q->pi_state);\n\tfree_pi_state(q->pi_state);\n\tq->pi_state = NULL;\n\n\tspin_unlock(q->lock_ptr);\n\n\tdrop_futex_key_refs(&q->key);\n}",
      "code_after_change": "static void unqueue_me_pi(struct futex_q *q)\n{\n\tWARN_ON(plist_node_empty(&q->list));\n\tplist_del(&q->list, &q->list.plist);\n\n\tBUG_ON(!q->pi_state);\n\tfree_pi_state(q->pi_state);\n\tq->pi_state = NULL;\n\n\tspin_unlock(q->lock_ptr);\n}",
      "modified_lines": {
        "added": [],
        "deleted": [
          "",
          "\tdrop_futex_key_refs(&q->key);"
        ]
      },
      "preconditions_for_vulnerability": "Improper maintenance of reference count during requeue operations in the futex subsystem.",
      "trigger_condition": "Local users trigger a zero count during requeue operations, leading to a use-after-free vulnerability and potential denial of service or privilege escalation.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly decrement and check the reference count before freeing the pi_state structure, allowing for a use-after-free scenario if the count is manipulated to zero.",
      "id": 51,
      "code_after_change_normalized": "static void FUN1(struct futex_q *VAR1)\n{\nFUN2(FUN3(&VAR1->VAR2));\nFUN4(&VAR1->VAR2, &VAR1->VAR2.VAR3);\nFUN5(!VAR1->VAR4);\nFUN6(VAR1->VAR4);\nVAR1->VAR4 = NULL;\nFUN7(VAR1->VAR5);\n}\n",
      "code_before_change_normalized": "static void FUN1(struct futex_q *VAR1)\n{\nFUN2(FUN3(&VAR1->VAR2));\nFUN4(&VAR1->VAR2, &VAR1->VAR2.VAR3);\nFUN5(!VAR1->VAR4);\nFUN6(VAR1->VAR4);\nVAR1->VAR4 = NULL;\nFUN7(VAR1->VAR5);\nFUN8(&VAR1->VAR6);\n}\n",
      "code_after_change_raw": "static void unqueue_me_pi(struct futex_q *q)\n{\nWARN_ON(plist_node_empty(&q->list));\nplist_del(&q->list, &q->list.plist);\nBUG_ON(!q->pi_state);\nfree_pi_state(q->pi_state);\nq->pi_state = NULL;\nspin_unlock(q->lock_ptr);\n}\n",
      "code_before_change_raw": "static void unqueue_me_pi(struct futex_q *q)\n{\nWARN_ON(plist_node_empty(&q->list));\nplist_del(&q->list, &q->list.plist);\nBUG_ON(!q->pi_state);\nfree_pi_state(q->pi_state);\nq->pi_state = NULL;\nspin_unlock(q->lock_ptr);\ndrop_futex_key_refs(&q->key);\n}\n"
    }
  ],
  "CVE-2014-2309": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper counting of route additions in the code.",
        "trigger_condition": "Receiving a flood of ICMPv6 Router Advertisement packets.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly count the addition of routes, leading to a denial of service due to memory consumption when flooded with ICMPv6 Router Advertisement packets."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper counting of route additions in the code. Specifically, the modification involves adding a condition to the ip6_dst_alloc function call to handle the RTF_ADDRCONF flag appropriately. This change ensures that routes are allocated correctly and efficiently, preventing the denial of service attack caused by the flood of ICMPv6 Router Advertisement packets.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2014-2309, which allows remote attackers to cause a denial of service (memory consumption) via a flood of ICMPv6 Router Advertisement packets. By adding the condition `(cfg->fc_flags & RTF_ADDRCONF) ? 0 :` when allocating the route in the `ip6_dst_alloc` function call, the code properly counts the addition of routes and prevents the denial of service attack by limiting memory consumption caused by the flood of ICMPv6 Router Advertisement packets. This modification ensures that routes are added correctly and efficiently, mitigating the vulnerability in the code.",
      "GPT_purpose": "Add an IPv6 route to the routing table.",
      "GPT_function": "\n1. Add an IPv6 route.\n2. Handle various configurations and parameters for the route.\n3. Check for specific conditions and flags to determine route behavior.\n4. Allocate memory for route information.\n5. Set route properties such as expiration time, protocol, and input/output functions.\n6. Handle different types of routes (e.g., reject, blackhole, prohibit).\n7. Set gateway address for the route.\n8. Check and validate source address and preferred source address.\n9. Handle metrics for the route.\n10. Install the route with specified configurations.\n11. Handle memory cleanup and error handling.",
      "CVE_id": "CVE-2014-2309",
      "code_before_change": "int ip6_route_add(struct fib6_config *cfg)\n{\n\tint err;\n\tstruct net *net = cfg->fc_nlinfo.nl_net;\n\tstruct rt6_info *rt = NULL;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_dev *idev = NULL;\n\tstruct fib6_table *table;\n\tint addr_type;\n\n\tif (cfg->fc_dst_len > 128 || cfg->fc_src_len > 128)\n\t\treturn -EINVAL;\n#ifndef CONFIG_IPV6_SUBTREES\n\tif (cfg->fc_src_len)\n\t\treturn -EINVAL;\n#endif\n\tif (cfg->fc_ifindex) {\n\t\terr = -ENODEV;\n\t\tdev = dev_get_by_index(net, cfg->fc_ifindex);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\tgoto out;\n\t}\n\n\tif (cfg->fc_metric == 0)\n\t\tcfg->fc_metric = IP6_RT_PRIO_USER;\n\n\terr = -ENOBUFS;\n\tif (cfg->fc_nlinfo.nlh &&\n\t    !(cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_CREATE)) {\n\t\ttable = fib6_get_table(net, cfg->fc_table);\n\t\tif (!table) {\n\t\t\tpr_warn(\"NLM_F_CREATE should be specified when creating new route\\n\");\n\t\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t\t}\n\t} else {\n\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t}\n\n\tif (!table)\n\t\tgoto out;\n\n\trt = ip6_dst_alloc(net, NULL, DST_NOCOUNT, table);\n\n\tif (!rt) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (cfg->fc_flags & RTF_EXPIRES)\n\t\trt6_set_expires(rt, jiffies +\n\t\t\t\tclock_t_to_jiffies(cfg->fc_expires));\n\telse\n\t\trt6_clean_expires(rt);\n\n\tif (cfg->fc_protocol == RTPROT_UNSPEC)\n\t\tcfg->fc_protocol = RTPROT_BOOT;\n\trt->rt6i_protocol = cfg->fc_protocol;\n\n\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\n\tif (addr_type & IPV6_ADDR_MULTICAST)\n\t\trt->dst.input = ip6_mc_input;\n\telse if (cfg->fc_flags & RTF_LOCAL)\n\t\trt->dst.input = ip6_input;\n\telse\n\t\trt->dst.input = ip6_forward;\n\n\trt->dst.output = ip6_output;\n\n\tipv6_addr_prefix(&rt->rt6i_dst.addr, &cfg->fc_dst, cfg->fc_dst_len);\n\trt->rt6i_dst.plen = cfg->fc_dst_len;\n\tif (rt->rt6i_dst.plen == 128)\n\t       rt->dst.flags |= DST_HOST;\n\n\tif (!(rt->dst.flags & DST_HOST) && cfg->fc_mx) {\n\t\tu32 *metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);\n\t\tif (!metrics) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tdst_init_metrics(&rt->dst, metrics, 0);\n\t}\n#ifdef CONFIG_IPV6_SUBTREES\n\tipv6_addr_prefix(&rt->rt6i_src.addr, &cfg->fc_src, cfg->fc_src_len);\n\trt->rt6i_src.plen = cfg->fc_src_len;\n#endif\n\n\trt->rt6i_metric = cfg->fc_metric;\n\n\t/* We cannot add true routes via loopback here,\n\t   they would result in kernel looping; promote them to reject routes\n\t */\n\tif ((cfg->fc_flags & RTF_REJECT) ||\n\t    (dev && (dev->flags & IFF_LOOPBACK) &&\n\t     !(addr_type & IPV6_ADDR_LOOPBACK) &&\n\t     !(cfg->fc_flags & RTF_LOCAL))) {\n\t\t/* hold loopback dev/idev if we haven't done so. */\n\t\tif (dev != net->loopback_dev) {\n\t\t\tif (dev) {\n\t\t\t\tdev_put(dev);\n\t\t\t\tin6_dev_put(idev);\n\t\t\t}\n\t\t\tdev = net->loopback_dev;\n\t\t\tdev_hold(dev);\n\t\t\tidev = in6_dev_get(dev);\n\t\t\tif (!idev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\trt->rt6i_flags = RTF_REJECT|RTF_NONEXTHOP;\n\t\tswitch (cfg->fc_type) {\n\t\tcase RTN_BLACKHOLE:\n\t\t\trt->dst.error = -EINVAL;\n\t\t\trt->dst.output = dst_discard;\n\t\t\trt->dst.input = dst_discard;\n\t\t\tbreak;\n\t\tcase RTN_PROHIBIT:\n\t\t\trt->dst.error = -EACCES;\n\t\t\trt->dst.output = ip6_pkt_prohibit_out;\n\t\t\trt->dst.input = ip6_pkt_prohibit;\n\t\t\tbreak;\n\t\tcase RTN_THROW:\n\t\tdefault:\n\t\t\trt->dst.error = (cfg->fc_type == RTN_THROW) ? -EAGAIN\n\t\t\t\t\t: -ENETUNREACH;\n\t\t\trt->dst.output = ip6_pkt_discard_out;\n\t\t\trt->dst.input = ip6_pkt_discard;\n\t\t\tbreak;\n\t\t}\n\t\tgoto install_route;\n\t}\n\n\tif (cfg->fc_flags & RTF_GATEWAY) {\n\t\tconst struct in6_addr *gw_addr;\n\t\tint gwa_type;\n\n\t\tgw_addr = &cfg->fc_gateway;\n\t\trt->rt6i_gateway = *gw_addr;\n\t\tgwa_type = ipv6_addr_type(gw_addr);\n\n\t\tif (gwa_type != (IPV6_ADDR_LINKLOCAL|IPV6_ADDR_UNICAST)) {\n\t\t\tstruct rt6_info *grt;\n\n\t\t\t/* IPv6 strictly inhibits using not link-local\n\t\t\t   addresses as nexthop address.\n\t\t\t   Otherwise, router will not able to send redirects.\n\t\t\t   It is very good, but in some (rare!) circumstances\n\t\t\t   (SIT, PtP, NBMA NOARP links) it is handy to allow\n\t\t\t   some exceptions. --ANK\n\t\t\t */\n\t\t\terr = -EINVAL;\n\t\t\tif (!(gwa_type & IPV6_ADDR_UNICAST))\n\t\t\t\tgoto out;\n\n\t\t\tgrt = rt6_lookup(net, gw_addr, NULL, cfg->fc_ifindex, 1);\n\n\t\t\terr = -EHOSTUNREACH;\n\t\t\tif (!grt)\n\t\t\t\tgoto out;\n\t\t\tif (dev) {\n\t\t\t\tif (dev != grt->dst.dev) {\n\t\t\t\t\tip6_rt_put(grt);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev = grt->dst.dev;\n\t\t\t\tidev = grt->rt6i_idev;\n\t\t\t\tdev_hold(dev);\n\t\t\t\tin6_dev_hold(grt->rt6i_idev);\n\t\t\t}\n\t\t\tif (!(grt->rt6i_flags & RTF_GATEWAY))\n\t\t\t\terr = 0;\n\t\t\tip6_rt_put(grt);\n\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\t\terr = -EINVAL;\n\t\tif (!dev || (dev->flags & IFF_LOOPBACK))\n\t\t\tgoto out;\n\t}\n\n\terr = -ENODEV;\n\tif (!dev)\n\t\tgoto out;\n\n\tif (!ipv6_addr_any(&cfg->fc_prefsrc)) {\n\t\tif (!ipv6_chk_addr(net, &cfg->fc_prefsrc, dev, 0)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\trt->rt6i_prefsrc.addr = cfg->fc_prefsrc;\n\t\trt->rt6i_prefsrc.plen = 128;\n\t} else\n\t\trt->rt6i_prefsrc.plen = 0;\n\n\trt->rt6i_flags = cfg->fc_flags;\n\ninstall_route:\n\tif (cfg->fc_mx) {\n\t\tstruct nlattr *nla;\n\t\tint remaining;\n\n\t\tnla_for_each_attr(nla, cfg->fc_mx, cfg->fc_mx_len, remaining) {\n\t\t\tint type = nla_type(nla);\n\n\t\t\tif (type) {\n\t\t\t\tif (type > RTAX_MAX) {\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tdst_metric_set(&rt->dst, type, nla_get_u32(nla));\n\t\t\t}\n\t\t}\n\t}\n\n\trt->dst.dev = dev;\n\trt->rt6i_idev = idev;\n\trt->rt6i_table = table;\n\n\tcfg->fc_nlinfo.nl_net = dev_net(dev);\n\n\treturn __ip6_ins_rt(rt, &cfg->fc_nlinfo);\n\nout:\n\tif (dev)\n\t\tdev_put(dev);\n\tif (idev)\n\t\tin6_dev_put(idev);\n\tif (rt)\n\t\tdst_free(&rt->dst);\n\treturn err;\n}",
      "code_after_change": "int ip6_route_add(struct fib6_config *cfg)\n{\n\tint err;\n\tstruct net *net = cfg->fc_nlinfo.nl_net;\n\tstruct rt6_info *rt = NULL;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_dev *idev = NULL;\n\tstruct fib6_table *table;\n\tint addr_type;\n\n\tif (cfg->fc_dst_len > 128 || cfg->fc_src_len > 128)\n\t\treturn -EINVAL;\n#ifndef CONFIG_IPV6_SUBTREES\n\tif (cfg->fc_src_len)\n\t\treturn -EINVAL;\n#endif\n\tif (cfg->fc_ifindex) {\n\t\terr = -ENODEV;\n\t\tdev = dev_get_by_index(net, cfg->fc_ifindex);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\tgoto out;\n\t}\n\n\tif (cfg->fc_metric == 0)\n\t\tcfg->fc_metric = IP6_RT_PRIO_USER;\n\n\terr = -ENOBUFS;\n\tif (cfg->fc_nlinfo.nlh &&\n\t    !(cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_CREATE)) {\n\t\ttable = fib6_get_table(net, cfg->fc_table);\n\t\tif (!table) {\n\t\t\tpr_warn(\"NLM_F_CREATE should be specified when creating new route\\n\");\n\t\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t\t}\n\t} else {\n\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t}\n\n\tif (!table)\n\t\tgoto out;\n\n\trt = ip6_dst_alloc(net, NULL, (cfg->fc_flags & RTF_ADDRCONF) ? 0 : DST_NOCOUNT, table);\n\n\tif (!rt) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (cfg->fc_flags & RTF_EXPIRES)\n\t\trt6_set_expires(rt, jiffies +\n\t\t\t\tclock_t_to_jiffies(cfg->fc_expires));\n\telse\n\t\trt6_clean_expires(rt);\n\n\tif (cfg->fc_protocol == RTPROT_UNSPEC)\n\t\tcfg->fc_protocol = RTPROT_BOOT;\n\trt->rt6i_protocol = cfg->fc_protocol;\n\n\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\n\tif (addr_type & IPV6_ADDR_MULTICAST)\n\t\trt->dst.input = ip6_mc_input;\n\telse if (cfg->fc_flags & RTF_LOCAL)\n\t\trt->dst.input = ip6_input;\n\telse\n\t\trt->dst.input = ip6_forward;\n\n\trt->dst.output = ip6_output;\n\n\tipv6_addr_prefix(&rt->rt6i_dst.addr, &cfg->fc_dst, cfg->fc_dst_len);\n\trt->rt6i_dst.plen = cfg->fc_dst_len;\n\tif (rt->rt6i_dst.plen == 128)\n\t       rt->dst.flags |= DST_HOST;\n\n\tif (!(rt->dst.flags & DST_HOST) && cfg->fc_mx) {\n\t\tu32 *metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);\n\t\tif (!metrics) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tdst_init_metrics(&rt->dst, metrics, 0);\n\t}\n#ifdef CONFIG_IPV6_SUBTREES\n\tipv6_addr_prefix(&rt->rt6i_src.addr, &cfg->fc_src, cfg->fc_src_len);\n\trt->rt6i_src.plen = cfg->fc_src_len;\n#endif\n\n\trt->rt6i_metric = cfg->fc_metric;\n\n\t/* We cannot add true routes via loopback here,\n\t   they would result in kernel looping; promote them to reject routes\n\t */\n\tif ((cfg->fc_flags & RTF_REJECT) ||\n\t    (dev && (dev->flags & IFF_LOOPBACK) &&\n\t     !(addr_type & IPV6_ADDR_LOOPBACK) &&\n\t     !(cfg->fc_flags & RTF_LOCAL))) {\n\t\t/* hold loopback dev/idev if we haven't done so. */\n\t\tif (dev != net->loopback_dev) {\n\t\t\tif (dev) {\n\t\t\t\tdev_put(dev);\n\t\t\t\tin6_dev_put(idev);\n\t\t\t}\n\t\t\tdev = net->loopback_dev;\n\t\t\tdev_hold(dev);\n\t\t\tidev = in6_dev_get(dev);\n\t\t\tif (!idev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\trt->rt6i_flags = RTF_REJECT|RTF_NONEXTHOP;\n\t\tswitch (cfg->fc_type) {\n\t\tcase RTN_BLACKHOLE:\n\t\t\trt->dst.error = -EINVAL;\n\t\t\trt->dst.output = dst_discard;\n\t\t\trt->dst.input = dst_discard;\n\t\t\tbreak;\n\t\tcase RTN_PROHIBIT:\n\t\t\trt->dst.error = -EACCES;\n\t\t\trt->dst.output = ip6_pkt_prohibit_out;\n\t\t\trt->dst.input = ip6_pkt_prohibit;\n\t\t\tbreak;\n\t\tcase RTN_THROW:\n\t\tdefault:\n\t\t\trt->dst.error = (cfg->fc_type == RTN_THROW) ? -EAGAIN\n\t\t\t\t\t: -ENETUNREACH;\n\t\t\trt->dst.output = ip6_pkt_discard_out;\n\t\t\trt->dst.input = ip6_pkt_discard;\n\t\t\tbreak;\n\t\t}\n\t\tgoto install_route;\n\t}\n\n\tif (cfg->fc_flags & RTF_GATEWAY) {\n\t\tconst struct in6_addr *gw_addr;\n\t\tint gwa_type;\n\n\t\tgw_addr = &cfg->fc_gateway;\n\t\trt->rt6i_gateway = *gw_addr;\n\t\tgwa_type = ipv6_addr_type(gw_addr);\n\n\t\tif (gwa_type != (IPV6_ADDR_LINKLOCAL|IPV6_ADDR_UNICAST)) {\n\t\t\tstruct rt6_info *grt;\n\n\t\t\t/* IPv6 strictly inhibits using not link-local\n\t\t\t   addresses as nexthop address.\n\t\t\t   Otherwise, router will not able to send redirects.\n\t\t\t   It is very good, but in some (rare!) circumstances\n\t\t\t   (SIT, PtP, NBMA NOARP links) it is handy to allow\n\t\t\t   some exceptions. --ANK\n\t\t\t */\n\t\t\terr = -EINVAL;\n\t\t\tif (!(gwa_type & IPV6_ADDR_UNICAST))\n\t\t\t\tgoto out;\n\n\t\t\tgrt = rt6_lookup(net, gw_addr, NULL, cfg->fc_ifindex, 1);\n\n\t\t\terr = -EHOSTUNREACH;\n\t\t\tif (!grt)\n\t\t\t\tgoto out;\n\t\t\tif (dev) {\n\t\t\t\tif (dev != grt->dst.dev) {\n\t\t\t\t\tip6_rt_put(grt);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev = grt->dst.dev;\n\t\t\t\tidev = grt->rt6i_idev;\n\t\t\t\tdev_hold(dev);\n\t\t\t\tin6_dev_hold(grt->rt6i_idev);\n\t\t\t}\n\t\t\tif (!(grt->rt6i_flags & RTF_GATEWAY))\n\t\t\t\terr = 0;\n\t\t\tip6_rt_put(grt);\n\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\t\terr = -EINVAL;\n\t\tif (!dev || (dev->flags & IFF_LOOPBACK))\n\t\t\tgoto out;\n\t}\n\n\terr = -ENODEV;\n\tif (!dev)\n\t\tgoto out;\n\n\tif (!ipv6_addr_any(&cfg->fc_prefsrc)) {\n\t\tif (!ipv6_chk_addr(net, &cfg->fc_prefsrc, dev, 0)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\trt->rt6i_prefsrc.addr = cfg->fc_prefsrc;\n\t\trt->rt6i_prefsrc.plen = 128;\n\t} else\n\t\trt->rt6i_prefsrc.plen = 0;\n\n\trt->rt6i_flags = cfg->fc_flags;\n\ninstall_route:\n\tif (cfg->fc_mx) {\n\t\tstruct nlattr *nla;\n\t\tint remaining;\n\n\t\tnla_for_each_attr(nla, cfg->fc_mx, cfg->fc_mx_len, remaining) {\n\t\t\tint type = nla_type(nla);\n\n\t\t\tif (type) {\n\t\t\t\tif (type > RTAX_MAX) {\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tdst_metric_set(&rt->dst, type, nla_get_u32(nla));\n\t\t\t}\n\t\t}\n\t}\n\n\trt->dst.dev = dev;\n\trt->rt6i_idev = idev;\n\trt->rt6i_table = table;\n\n\tcfg->fc_nlinfo.nl_net = dev_net(dev);\n\n\treturn __ip6_ins_rt(rt, &cfg->fc_nlinfo);\n\nout:\n\tif (dev)\n\t\tdev_put(dev);\n\tif (idev)\n\t\tin6_dev_put(idev);\n\tif (rt)\n\t\tdst_free(&rt->dst);\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\trt = ip6_dst_alloc(net, NULL, (cfg->fc_flags & RTF_ADDRCONF) ? 0 : DST_NOCOUNT, table);"
        ],
        "deleted": [
          "\trt = ip6_dst_alloc(net, NULL, DST_NOCOUNT, table);"
        ]
      },
      "preconditions_for_vulnerability": "Improper counting of route additions in the code.",
      "trigger_condition": "Receiving a flood of ICMPv6 Router Advertisement packets.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly count the addition of routes, leading to a denial of service due to memory consumption when flooded with ICMPv6 Router Advertisement packets.",
      "id": 52,
      "code_after_change_normalized": "int FUN1(struct fib6_config *VAR1)\n{\nint VAR2;\nstruct VAR3 *VAR3 = VAR1->VAR4.VAR5;\nstruct rt6_info *VAR6 = NULL;\nstruct net_device *VAR7 = NULL;\nstruct inet6_dev *VAR8 = NULL;\nstruct fib6_table *VAR9;\nint VAR10;\nif (VAR1->VAR11 > 128 || VAR1->VAR12 > 128)\nreturn -VAR13;\n#ifndef VAR14\nif (VAR1->VAR12)\nreturn -VAR13;\n#VAR15\nif (VAR1->VAR16) {\nVAR2 = -VAR17;\nVAR7 = FUN2(VAR3, VAR1->VAR16);\nif (!VAR7)\ngoto VAR18;\nVAR8 = FUN3(VAR7);\nif (!VAR8)\ngoto VAR18;\n}\nif (VAR1->VAR19 == 0)\nVAR1->VAR19 = VAR20;\nVAR2 = -VAR21;\nif (VAR1->VAR4.VAR22 &&\n!(VAR1->VAR4.VAR22->VAR23 & VAR24)) {\nVAR9 = FUN4(VAR3, VAR1->VAR25);\nif (!VAR9) {\nFUN5(\"STR\");\nVAR9 = FUN6(VAR3, VAR1->VAR25);\n}\n} else {\nVAR9 = FUN6(VAR3, VAR1->VAR25);\n}\nif (!VAR9)\ngoto VAR18;\nVAR6 = FUN7(VAR3, NULL, (VAR1->VAR26 & VAR27) ? 0 : VAR28, VAR9);\nif (!VAR6) {\nVAR2 = -VAR29;\ngoto VAR18;\n}\nif (VAR1->VAR26 & VAR30)\nFUN8(VAR6, VAR31 +\nFUN9(VAR1->VAR32));\nelse\nFUN10(VAR6);\nif (VAR1->VAR33 == VAR34)\nVAR1->VAR33 = VAR35;\nVAR6->VAR36 = VAR1->VAR33;\nVAR10 = FUN11(&VAR1->VAR37);\nif (VAR10 & VAR38)\nVAR6->VAR39.VAR40 = VAR41;\nelse if (VAR1->VAR26 & VAR42)\nVAR6->VAR39.VAR40 = VAR43;\nelse\nVAR6->VAR39.VAR40 = VAR44;\nVAR6->VAR39.VAR45 = VAR46;\nFUN12(&VAR6->VAR47.VAR48, &VAR1->VAR37, VAR1->VAR11);\nVAR6->VAR47.VAR49 = VAR1->VAR11;\nif (VAR6->VAR47.VAR49 == 128)\nVAR6->VAR39.VAR50 |= VAR51;\nif (!(VAR6->VAR39.VAR50 & VAR51) && VAR1->VAR52) {\nVAR54 *VAR53 = FUN13(sizeof(VAR54) * VAR55, VAR56);\nif (!VAR53) {\nVAR2 = -VAR29;\ngoto VAR18;\n}\nFUN14(&VAR6->VAR39, VAR53, 0);\n}\n#ifdef VAR14\nFUN12(&VAR6->VAR57.VAR48, &VAR1->VAR58, VAR1->VAR12);\nVAR6->VAR57.VAR49 = VAR1->VAR12;\n#VAR15\nVAR6->VAR59 = VAR1->VAR19;\nif ((VAR1->VAR26 & VAR60) ||\n(VAR7 && (VAR7->VAR50 & VAR61) &&\n!(VAR10 & VAR62) &&\n!(VAR1->VAR26 & VAR42))) {\nif (VAR7 != VAR3->VAR63) {\nif (VAR7) {\nFUN15(VAR7);\nFUN16(VAR8);\n}\nVAR7 = VAR3->VAR63;\nFUN17(VAR7);\nVAR8 = FUN3(VAR7);\nif (!VAR8) {\nVAR2 = -VAR17;\ngoto VAR18;\n}\n}\nVAR6->VAR64 = VAR60|VAR65;\nswitch (VAR1->VAR66) {\ncase VAR67:\nVAR6->VAR39.VAR68 = -VAR13;\nVAR6->VAR39.VAR45 = VAR69;\nVAR6->VAR39.VAR40 = VAR69;\nbreak;\ncase VAR70:\nVAR6->VAR39.VAR68 = -VAR71;\nVAR6->VAR39.VAR45 = VAR72;\nVAR6->VAR39.VAR40 = VAR73;\nbreak;\ncase VAR74:\ndefault:\nVAR6->VAR39.VAR68 = (VAR1->VAR66 == VAR74) ? -VAR75\n: -VAR76;\nVAR6->VAR39.VAR45 = VAR77;\nVAR6->VAR39.VAR40 = VAR78;\nbreak;\n}\ngoto VAR79;\n}\nif (VAR1->VAR26 & VAR80) {\nconst struct in6_addr *VAR81;\nint VAR82;\nVAR81 = &VAR1->VAR83;\nVAR6->VAR84 = *VAR81;\nVAR82 = FUN11(VAR81);\nif (VAR82 != (VAR85|VAR86)) {\nstruct rt6_info *VAR87;\nVAR2 = -VAR13;\nif (!(VAR82 & VAR86))\ngoto VAR18;\nVAR87 = FUN18(VAR3, VAR81, NULL, VAR1->VAR16, 1);\nVAR2 = -VAR88;\nif (!VAR87)\ngoto VAR18;\nif (VAR7) {\nif (VAR7 != VAR87->VAR39.VAR7) {\nFUN19(VAR87);\ngoto VAR18;\n}\n} else {\nVAR7 = VAR87->VAR39.VAR7;\nVAR8 = VAR87->VAR89;\nFUN17(VAR7);\nFUN20(VAR87->VAR89);\n}\nif (!(VAR87->VAR64 & VAR80))\nVAR2 = 0;\nFUN19(VAR87);\nif (VAR2)\ngoto VAR18;\n}\nVAR2 = -VAR13;\nif (!VAR7 || (VAR7->VAR50 & VAR61))\ngoto VAR18;\n}\nVAR2 = -VAR17;\nif (!VAR7)\ngoto VAR18;\nif (!FUN21(&VAR1->VAR90)) {\nif (!FUN22(VAR3, &VAR1->VAR90, VAR7, 0)) {\nVAR2 = -VAR13;\ngoto VAR18;\n}\nVAR6->VAR91.VAR48 = VAR1->VAR90;\nVAR6->VAR91.VAR49 = 128;\n} else\nVAR6->VAR91.VAR49 = 0;\nVAR6->VAR64 = VAR1->VAR26;\nVAR79:\nif (VAR1->VAR52) {\nstruct nlattr *VAR92;\nint VAR93;\nFUN23(VAR92, VAR1->VAR52, VAR1->VAR94, VAR93) {\nint VAR95 = FUN24(VAR92);\nif (VAR95) {\nif (VAR95 > VAR55) {\nVAR2 = -VAR13;\ngoto VAR18;\n}\nFUN25(&VAR6->VAR39, VAR95, FUN26(VAR92));\n}\n}\n}\nVAR6->VAR39.VAR7 = VAR7;\nVAR6->VAR89 = VAR8;\nVAR6->VAR96 = VAR9;\nVAR1->VAR4.VAR5 = FUN27(VAR7);\nreturn FUN28(VAR6, &VAR1->VAR4);\nVAR18:\nif (VAR7)\nFUN15(VAR7);\nif (VAR8)\nFUN16(VAR8);\nif (VAR6)\nFUN29(&VAR6->VAR39);\nreturn VAR2;\n}\n",
      "code_before_change_normalized": "int FUN1(struct fib6_config *VAR1)\n{\nint VAR2;\nstruct VAR3 *VAR3 = VAR1->VAR4.VAR5;\nstruct rt6_info *VAR6 = NULL;\nstruct net_device *VAR7 = NULL;\nstruct inet6_dev *VAR8 = NULL;\nstruct fib6_table *VAR9;\nint VAR10;\nif (VAR1->VAR11 > 128 || VAR1->VAR12 > 128)\nreturn -VAR13;\n#ifndef VAR14\nif (VAR1->VAR12)\nreturn -VAR13;\n#VAR15\nif (VAR1->VAR16) {\nVAR2 = -VAR17;\nVAR7 = FUN2(VAR3, VAR1->VAR16);\nif (!VAR7)\ngoto VAR18;\nVAR8 = FUN3(VAR7);\nif (!VAR8)\ngoto VAR18;\n}\nif (VAR1->VAR19 == 0)\nVAR1->VAR19 = VAR20;\nVAR2 = -VAR21;\nif (VAR1->VAR4.VAR22 &&\n!(VAR1->VAR4.VAR22->VAR23 & VAR24)) {\nVAR9 = FUN4(VAR3, VAR1->VAR25);\nif (!VAR9) {\nFUN5(\"STR\");\nVAR9 = FUN6(VAR3, VAR1->VAR25);\n}\n} else {\nVAR9 = FUN6(VAR3, VAR1->VAR25);\n}\nif (!VAR9)\ngoto VAR18;\nVAR6 = FUN7(VAR3, NULL, VAR26, VAR9);\nif (!VAR6) {\nVAR2 = -VAR27;\ngoto VAR18;\n}\nif (VAR1->VAR28 & VAR29)\nFUN8(VAR6, VAR30 +\nFUN9(VAR1->VAR31));\nelse\nFUN10(VAR6);\nif (VAR1->VAR32 == VAR33)\nVAR1->VAR32 = VAR34;\nVAR6->VAR35 = VAR1->VAR32;\nVAR10 = FUN11(&VAR1->VAR36);\nif (VAR10 & VAR37)\nVAR6->VAR38.VAR39 = VAR40;\nelse if (VAR1->VAR28 & VAR41)\nVAR6->VAR38.VAR39 = VAR42;\nelse\nVAR6->VAR38.VAR39 = VAR43;\nVAR6->VAR38.VAR44 = VAR45;\nFUN12(&VAR6->VAR46.VAR47, &VAR1->VAR36, VAR1->VAR11);\nVAR6->VAR46.VAR48 = VAR1->VAR11;\nif (VAR6->VAR46.VAR48 == 128)\nVAR6->VAR38.VAR49 |= VAR50;\nif (!(VAR6->VAR38.VAR49 & VAR50) && VAR1->VAR51) {\nVAR53 *VAR52 = FUN13(sizeof(VAR53) * VAR54, VAR55);\nif (!VAR52) {\nVAR2 = -VAR27;\ngoto VAR18;\n}\nFUN14(&VAR6->VAR38, VAR52, 0);\n}\n#ifdef VAR14\nFUN12(&VAR6->VAR56.VAR47, &VAR1->VAR57, VAR1->VAR12);\nVAR6->VAR56.VAR48 = VAR1->VAR12;\n#VAR15\nVAR6->VAR58 = VAR1->VAR19;\nif ((VAR1->VAR28 & VAR59) ||\n(VAR7 && (VAR7->VAR49 & VAR60) &&\n!(VAR10 & VAR61) &&\n!(VAR1->VAR28 & VAR41))) {\nif (VAR7 != VAR3->VAR62) {\nif (VAR7) {\nFUN15(VAR7);\nFUN16(VAR8);\n}\nVAR7 = VAR3->VAR62;\nFUN17(VAR7);\nVAR8 = FUN3(VAR7);\nif (!VAR8) {\nVAR2 = -VAR17;\ngoto VAR18;\n}\n}\nVAR6->VAR63 = VAR59|VAR64;\nswitch (VAR1->VAR65) {\ncase VAR66:\nVAR6->VAR38.VAR67 = -VAR13;\nVAR6->VAR38.VAR44 = VAR68;\nVAR6->VAR38.VAR39 = VAR68;\nbreak;\ncase VAR69:\nVAR6->VAR38.VAR67 = -VAR70;\nVAR6->VAR38.VAR44 = VAR71;\nVAR6->VAR38.VAR39 = VAR72;\nbreak;\ncase VAR73:\ndefault:\nVAR6->VAR38.VAR67 = (VAR1->VAR65 == VAR73) ? -VAR74\n: -VAR75;\nVAR6->VAR38.VAR44 = VAR76;\nVAR6->VAR38.VAR39 = VAR77;\nbreak;\n}\ngoto VAR78;\n}\nif (VAR1->VAR28 & VAR79) {\nconst struct in6_addr *VAR80;\nint VAR81;\nVAR80 = &VAR1->VAR82;\nVAR6->VAR83 = *VAR80;\nVAR81 = FUN11(VAR80);\nif (VAR81 != (VAR84|VAR85)) {\nstruct rt6_info *VAR86;\nVAR2 = -VAR13;\nif (!(VAR81 & VAR85))\ngoto VAR18;\nVAR86 = FUN18(VAR3, VAR80, NULL, VAR1->VAR16, 1);\nVAR2 = -VAR87;\nif (!VAR86)\ngoto VAR18;\nif (VAR7) {\nif (VAR7 != VAR86->VAR38.VAR7) {\nFUN19(VAR86);\ngoto VAR18;\n}\n} else {\nVAR7 = VAR86->VAR38.VAR7;\nVAR8 = VAR86->VAR88;\nFUN17(VAR7);\nFUN20(VAR86->VAR88);\n}\nif (!(VAR86->VAR63 & VAR79))\nVAR2 = 0;\nFUN19(VAR86);\nif (VAR2)\ngoto VAR18;\n}\nVAR2 = -VAR13;\nif (!VAR7 || (VAR7->VAR49 & VAR60))\ngoto VAR18;\n}\nVAR2 = -VAR17;\nif (!VAR7)\ngoto VAR18;\nif (!FUN21(&VAR1->VAR89)) {\nif (!FUN22(VAR3, &VAR1->VAR89, VAR7, 0)) {\nVAR2 = -VAR13;\ngoto VAR18;\n}\nVAR6->VAR90.VAR47 = VAR1->VAR89;\nVAR6->VAR90.VAR48 = 128;\n} else\nVAR6->VAR90.VAR48 = 0;\nVAR6->VAR63 = VAR1->VAR28;\nVAR78:\nif (VAR1->VAR51) {\nstruct nlattr *VAR91;\nint VAR92;\nFUN23(VAR91, VAR1->VAR51, VAR1->VAR93, VAR92) {\nint VAR94 = FUN24(VAR91);\nif (VAR94) {\nif (VAR94 > VAR54) {\nVAR2 = -VAR13;\ngoto VAR18;\n}\nFUN25(&VAR6->VAR38, VAR94, FUN26(VAR91));\n}\n}\n}\nVAR6->VAR38.VAR7 = VAR7;\nVAR6->VAR88 = VAR8;\nVAR6->VAR95 = VAR9;\nVAR1->VAR4.VAR5 = FUN27(VAR7);\nreturn FUN28(VAR6, &VAR1->VAR4);\nVAR18:\nif (VAR7)\nFUN15(VAR7);\nif (VAR8)\nFUN16(VAR8);\nif (VAR6)\nFUN29(&VAR6->VAR38);\nreturn VAR2;\n}\n",
      "code_after_change_raw": "int ip6_route_add(struct fib6_config *cfg)\n{\nint err;\nstruct net *net = cfg->fc_nlinfo.nl_net;\nstruct rt6_info *rt = NULL;\nstruct net_device *dev = NULL;\nstruct inet6_dev *idev = NULL;\nstruct fib6_table *table;\nint addr_type;\nif (cfg->fc_dst_len > 128 || cfg->fc_src_len > 128)\nreturn -EINVAL;\n#ifndef CONFIG_IPV6_SUBTREES\nif (cfg->fc_src_len)\nreturn -EINVAL;\n#endif\nif (cfg->fc_ifindex) {\nerr = -ENODEV;\ndev = dev_get_by_index(net, cfg->fc_ifindex);\nif (!dev)\ngoto out;\nidev = in6_dev_get(dev);\nif (!idev)\ngoto out;\n}\nif (cfg->fc_metric == 0)\ncfg->fc_metric = IP6_RT_PRIO_USER;\nerr = -ENOBUFS;\nif (cfg->fc_nlinfo.nlh &&\n!(cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_CREATE)) {\ntable = fib6_get_table(net, cfg->fc_table);\nif (!table) {\npr_warn(\"NLM_F_CREATE should be specified when creating new route\\n\");\ntable = fib6_new_table(net, cfg->fc_table);\n}\n} else {\ntable = fib6_new_table(net, cfg->fc_table);\n}\nif (!table)\ngoto out;\nrt = ip6_dst_alloc(net, NULL, (cfg->fc_flags & RTF_ADDRCONF) ? 0 : DST_NOCOUNT, table);\nif (!rt) {\nerr = -ENOMEM;\ngoto out;\n}\nif (cfg->fc_flags & RTF_EXPIRES)\nrt6_set_expires(rt, jiffies +\nclock_t_to_jiffies(cfg->fc_expires));\nelse\nrt6_clean_expires(rt);\nif (cfg->fc_protocol == RTPROT_UNSPEC)\ncfg->fc_protocol = RTPROT_BOOT;\nrt->rt6i_protocol = cfg->fc_protocol;\naddr_type = ipv6_addr_type(&cfg->fc_dst);\nif (addr_type & IPV6_ADDR_MULTICAST)\nrt->dst.input = ip6_mc_input;\nelse if (cfg->fc_flags & RTF_LOCAL)\nrt->dst.input = ip6_input;\nelse\nrt->dst.input = ip6_forward;\nrt->dst.output = ip6_output;\nipv6_addr_prefix(&rt->rt6i_dst.addr, &cfg->fc_dst, cfg->fc_dst_len);\nrt->rt6i_dst.plen = cfg->fc_dst_len;\nif (rt->rt6i_dst.plen == 128)\nrt->dst.flags |= DST_HOST;\nif (!(rt->dst.flags & DST_HOST) && cfg->fc_mx) {\nu32 *metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);\nif (!metrics) {\nerr = -ENOMEM;\ngoto out;\n}\ndst_init_metrics(&rt->dst, metrics, 0);\n}\n#ifdef CONFIG_IPV6_SUBTREES\nipv6_addr_prefix(&rt->rt6i_src.addr, &cfg->fc_src, cfg->fc_src_len);\nrt->rt6i_src.plen = cfg->fc_src_len;\n#endif\nrt->rt6i_metric = cfg->fc_metric;\nif ((cfg->fc_flags & RTF_REJECT) ||\n(dev && (dev->flags & IFF_LOOPBACK) &&\n!(addr_type & IPV6_ADDR_LOOPBACK) &&\n!(cfg->fc_flags & RTF_LOCAL))) {\nif (dev != net->loopback_dev) {\nif (dev) {\ndev_put(dev);\nin6_dev_put(idev);\n}\ndev = net->loopback_dev;\ndev_hold(dev);\nidev = in6_dev_get(dev);\nif (!idev) {\nerr = -ENODEV;\ngoto out;\n}\n}\nrt->rt6i_flags = RTF_REJECT|RTF_NONEXTHOP;\nswitch (cfg->fc_type) {\ncase RTN_BLACKHOLE:\nrt->dst.error = -EINVAL;\nrt->dst.output = dst_discard;\nrt->dst.input = dst_discard;\nbreak;\ncase RTN_PROHIBIT:\nrt->dst.error = -EACCES;\nrt->dst.output = ip6_pkt_prohibit_out;\nrt->dst.input = ip6_pkt_prohibit;\nbreak;\ncase RTN_THROW:\ndefault:\nrt->dst.error = (cfg->fc_type == RTN_THROW) ? -EAGAIN\n: -ENETUNREACH;\nrt->dst.output = ip6_pkt_discard_out;\nrt->dst.input = ip6_pkt_discard;\nbreak;\n}\ngoto install_route;\n}\nif (cfg->fc_flags & RTF_GATEWAY) {\nconst struct in6_addr *gw_addr;\nint gwa_type;\ngw_addr = &cfg->fc_gateway;\nrt->rt6i_gateway = *gw_addr;\ngwa_type = ipv6_addr_type(gw_addr);\nif (gwa_type != (IPV6_ADDR_LINKLOCAL|IPV6_ADDR_UNICAST)) {\nstruct rt6_info *grt;\nerr = -EINVAL;\nif (!(gwa_type & IPV6_ADDR_UNICAST))\ngoto out;\ngrt = rt6_lookup(net, gw_addr, NULL, cfg->fc_ifindex, 1);\nerr = -EHOSTUNREACH;\nif (!grt)\ngoto out;\nif (dev) {\nif (dev != grt->dst.dev) {\nip6_rt_put(grt);\ngoto out;\n}\n} else {\ndev = grt->dst.dev;\nidev = grt->rt6i_idev;\ndev_hold(dev);\nin6_dev_hold(grt->rt6i_idev);\n}\nif (!(grt->rt6i_flags & RTF_GATEWAY))\nerr = 0;\nip6_rt_put(grt);\nif (err)\ngoto out;\n}\nerr = -EINVAL;\nif (!dev || (dev->flags & IFF_LOOPBACK))\ngoto out;\n}\nerr = -ENODEV;\nif (!dev)\ngoto out;\nif (!ipv6_addr_any(&cfg->fc_prefsrc)) {\nif (!ipv6_chk_addr(net, &cfg->fc_prefsrc, dev, 0)) {\nerr = -EINVAL;\ngoto out;\n}\nrt->rt6i_prefsrc.addr = cfg->fc_prefsrc;\nrt->rt6i_prefsrc.plen = 128;\n} else\nrt->rt6i_prefsrc.plen = 0;\nrt->rt6i_flags = cfg->fc_flags;\ninstall_route:\nif (cfg->fc_mx) {\nstruct nlattr *nla;\nint remaining;\nnla_for_each_attr(nla, cfg->fc_mx, cfg->fc_mx_len, remaining) {\nint type = nla_type(nla);\nif (type) {\nif (type > RTAX_MAX) {\nerr = -EINVAL;\ngoto out;\n}\ndst_metric_set(&rt->dst, type, nla_get_u32(nla));\n}\n}\n}\nrt->dst.dev = dev;\nrt->rt6i_idev = idev;\nrt->rt6i_table = table;\ncfg->fc_nlinfo.nl_net = dev_net(dev);\nreturn __ip6_ins_rt(rt, &cfg->fc_nlinfo);\nout:\nif (dev)\ndev_put(dev);\nif (idev)\nin6_dev_put(idev);\nif (rt)\ndst_free(&rt->dst);\nreturn err;\n}\n",
      "code_before_change_raw": "int ip6_route_add(struct fib6_config *cfg)\n{\nint err;\nstruct net *net = cfg->fc_nlinfo.nl_net;\nstruct rt6_info *rt = NULL;\nstruct net_device *dev = NULL;\nstruct inet6_dev *idev = NULL;\nstruct fib6_table *table;\nint addr_type;\nif (cfg->fc_dst_len > 128 || cfg->fc_src_len > 128)\nreturn -EINVAL;\n#ifndef CONFIG_IPV6_SUBTREES\nif (cfg->fc_src_len)\nreturn -EINVAL;\n#endif\nif (cfg->fc_ifindex) {\nerr = -ENODEV;\ndev = dev_get_by_index(net, cfg->fc_ifindex);\nif (!dev)\ngoto out;\nidev = in6_dev_get(dev);\nif (!idev)\ngoto out;\n}\nif (cfg->fc_metric == 0)\ncfg->fc_metric = IP6_RT_PRIO_USER;\nerr = -ENOBUFS;\nif (cfg->fc_nlinfo.nlh &&\n!(cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_CREATE)) {\ntable = fib6_get_table(net, cfg->fc_table);\nif (!table) {\npr_warn(\"NLM_F_CREATE should be specified when creating new route\\n\");\ntable = fib6_new_table(net, cfg->fc_table);\n}\n} else {\ntable = fib6_new_table(net, cfg->fc_table);\n}\nif (!table)\ngoto out;\nrt = ip6_dst_alloc(net, NULL, DST_NOCOUNT, table);\nif (!rt) {\nerr = -ENOMEM;\ngoto out;\n}\nif (cfg->fc_flags & RTF_EXPIRES)\nrt6_set_expires(rt, jiffies +\nclock_t_to_jiffies(cfg->fc_expires));\nelse\nrt6_clean_expires(rt);\nif (cfg->fc_protocol == RTPROT_UNSPEC)\ncfg->fc_protocol = RTPROT_BOOT;\nrt->rt6i_protocol = cfg->fc_protocol;\naddr_type = ipv6_addr_type(&cfg->fc_dst);\nif (addr_type & IPV6_ADDR_MULTICAST)\nrt->dst.input = ip6_mc_input;\nelse if (cfg->fc_flags & RTF_LOCAL)\nrt->dst.input = ip6_input;\nelse\nrt->dst.input = ip6_forward;\nrt->dst.output = ip6_output;\nipv6_addr_prefix(&rt->rt6i_dst.addr, &cfg->fc_dst, cfg->fc_dst_len);\nrt->rt6i_dst.plen = cfg->fc_dst_len;\nif (rt->rt6i_dst.plen == 128)\nrt->dst.flags |= DST_HOST;\nif (!(rt->dst.flags & DST_HOST) && cfg->fc_mx) {\nu32 *metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);\nif (!metrics) {\nerr = -ENOMEM;\ngoto out;\n}\ndst_init_metrics(&rt->dst, metrics, 0);\n}\n#ifdef CONFIG_IPV6_SUBTREES\nipv6_addr_prefix(&rt->rt6i_src.addr, &cfg->fc_src, cfg->fc_src_len);\nrt->rt6i_src.plen = cfg->fc_src_len;\n#endif\nrt->rt6i_metric = cfg->fc_metric;\nif ((cfg->fc_flags & RTF_REJECT) ||\n(dev && (dev->flags & IFF_LOOPBACK) &&\n!(addr_type & IPV6_ADDR_LOOPBACK) &&\n!(cfg->fc_flags & RTF_LOCAL))) {\nif (dev != net->loopback_dev) {\nif (dev) {\ndev_put(dev);\nin6_dev_put(idev);\n}\ndev = net->loopback_dev;\ndev_hold(dev);\nidev = in6_dev_get(dev);\nif (!idev) {\nerr = -ENODEV;\ngoto out;\n}\n}\nrt->rt6i_flags = RTF_REJECT|RTF_NONEXTHOP;\nswitch (cfg->fc_type) {\ncase RTN_BLACKHOLE:\nrt->dst.error = -EINVAL;\nrt->dst.output = dst_discard;\nrt->dst.input = dst_discard;\nbreak;\ncase RTN_PROHIBIT:\nrt->dst.error = -EACCES;\nrt->dst.output = ip6_pkt_prohibit_out;\nrt->dst.input = ip6_pkt_prohibit;\nbreak;\ncase RTN_THROW:\ndefault:\nrt->dst.error = (cfg->fc_type == RTN_THROW) ? -EAGAIN\n: -ENETUNREACH;\nrt->dst.output = ip6_pkt_discard_out;\nrt->dst.input = ip6_pkt_discard;\nbreak;\n}\ngoto install_route;\n}\nif (cfg->fc_flags & RTF_GATEWAY) {\nconst struct in6_addr *gw_addr;\nint gwa_type;\ngw_addr = &cfg->fc_gateway;\nrt->rt6i_gateway = *gw_addr;\ngwa_type = ipv6_addr_type(gw_addr);\nif (gwa_type != (IPV6_ADDR_LINKLOCAL|IPV6_ADDR_UNICAST)) {\nstruct rt6_info *grt;\nerr = -EINVAL;\nif (!(gwa_type & IPV6_ADDR_UNICAST))\ngoto out;\ngrt = rt6_lookup(net, gw_addr, NULL, cfg->fc_ifindex, 1);\nerr = -EHOSTUNREACH;\nif (!grt)\ngoto out;\nif (dev) {\nif (dev != grt->dst.dev) {\nip6_rt_put(grt);\ngoto out;\n}\n} else {\ndev = grt->dst.dev;\nidev = grt->rt6i_idev;\ndev_hold(dev);\nin6_dev_hold(grt->rt6i_idev);\n}\nif (!(grt->rt6i_flags & RTF_GATEWAY))\nerr = 0;\nip6_rt_put(grt);\nif (err)\ngoto out;\n}\nerr = -EINVAL;\nif (!dev || (dev->flags & IFF_LOOPBACK))\ngoto out;\n}\nerr = -ENODEV;\nif (!dev)\ngoto out;\nif (!ipv6_addr_any(&cfg->fc_prefsrc)) {\nif (!ipv6_chk_addr(net, &cfg->fc_prefsrc, dev, 0)) {\nerr = -EINVAL;\ngoto out;\n}\nrt->rt6i_prefsrc.addr = cfg->fc_prefsrc;\nrt->rt6i_prefsrc.plen = 128;\n} else\nrt->rt6i_prefsrc.plen = 0;\nrt->rt6i_flags = cfg->fc_flags;\ninstall_route:\nif (cfg->fc_mx) {\nstruct nlattr *nla;\nint remaining;\nnla_for_each_attr(nla, cfg->fc_mx, cfg->fc_mx_len, remaining) {\nint type = nla_type(nla);\nif (type) {\nif (type > RTAX_MAX) {\nerr = -EINVAL;\ngoto out;\n}\ndst_metric_set(&rt->dst, type, nla_get_u32(nla));\n}\n}\n}\nrt->dst.dev = dev;\nrt->rt6i_idev = idev;\nrt->rt6i_table = table;\ncfg->fc_nlinfo.nl_net = dev_net(dev);\nreturn __ip6_ins_rt(rt, &cfg->fc_nlinfo);\nout:\nif (dev)\ndev_put(dev);\nif (idev)\nin6_dev_put(idev);\nif (rt)\ndst_free(&rt->dst);\nreturn err;\n}\n"
    }
  ],
  "CVE-2014-3181": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of bounds checking on the number of touch points received from a device, allowing for a large amount of data to overflow the stack buffer.",
        "trigger_condition": "A physically proximate attacker provides a crafted device that sends a large amount of data associated with an event, causing a stack-based buffer overflow in the magicmouse_raw_event function.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the number of touch points received from the device, leading to a potential buffer overflow when processing the touch data."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add bounds checking on the number of touch points received from the device to prevent a stack-based buffer overflow. In this case, the solution involves adding a check to ensure that the number of touch points does not exceed a safe limit (e.g., 15) before processing the touch data. By limiting the number of touch points, the code prevents the buffer overflow vulnerability from being exploited.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2014-3181, which involves multiple stack-based buffer overflows in the `magicmouse_raw_event` function in the Magic Mouse HID driver in the Linux kernel. \n\nBy adding the check `if (npoints > 15)` after calculating the number of touch points in both the `TRACKPAD_REPORT_ID` and `MOUSE_REPORT_ID` cases, the code ensures that the `npoints` value does not exceed 15. This check prevents a physically proximate attacker from providing a large amount of data associated with an event, which could lead to a buffer overflow and potentially allow the attacker to cause a denial of service or execute arbitrary code.\n\nTherefore, by limiting the number of touch points to a safe value (in this case, 15), the modified code helps mitigate the risk of exploitation of the buffer overflow vulnerability described in the CVE-2014-3181 advisory.",
      "GPT_purpose": "Handle raw input events from a Magic Mouse or Magic Trackpad HID device in the Linux kernel.",
      "GPT_function": "\n1. Process raw input events from a Magic Mouse HID device.\n2. Handle different types of reports from the Magic Mouse HID device.\n3. Emit touch data and handle click events based on the received data.\n4. Report relative X and Y movements or mouse button clicks to the input subsystem.\n5. Handle specific cases such as multiple touch reports in one packet.",
      "CVE_id": "CVE-2014-3181",
      "code_before_change": "static int magicmouse_raw_event(struct hid_device *hdev,\n\t\tstruct hid_report *report, u8 *data, int size)\n{\n\tstruct magicmouse_sc *msc = hid_get_drvdata(hdev);\n\tstruct input_dev *input = msc->input;\n\tint x = 0, y = 0, ii, clicks = 0, npoints;\n\n\tswitch (data[0]) {\n\tcase TRACKPAD_REPORT_ID:\n\t\t/* Expect four bytes of prefix, and N*9 bytes of touch data. */\n\t\tif (size < 4 || ((size - 4) % 9) != 0)\n\t\t\treturn 0;\n\t\tnpoints = (size - 4) / 9;\n\t\tmsc->ntouches = 0;\n\t\tfor (ii = 0; ii < npoints; ii++)\n\t\t\tmagicmouse_emit_touch(msc, ii, data + ii * 9 + 4);\n\n\t\tclicks = data[1];\n\n\t\t/* The following bits provide a device specific timestamp. They\n\t\t * are unused here.\n\t\t *\n\t\t * ts = data[1] >> 6 | data[2] << 2 | data[3] << 10;\n\t\t */\n\t\tbreak;\n\tcase MOUSE_REPORT_ID:\n\t\t/* Expect six bytes of prefix, and N*8 bytes of touch data. */\n\t\tif (size < 6 || ((size - 6) % 8) != 0)\n\t\t\treturn 0;\n\t\tnpoints = (size - 6) / 8;\n\t\tmsc->ntouches = 0;\n\t\tfor (ii = 0; ii < npoints; ii++)\n\t\t\tmagicmouse_emit_touch(msc, ii, data + ii * 8 + 6);\n\n\t\t/* When emulating three-button mode, it is important\n\t\t * to have the current touch information before\n\t\t * generating a click event.\n\t\t */\n\t\tx = (int)(((data[3] & 0x0c) << 28) | (data[1] << 22)) >> 22;\n\t\ty = (int)(((data[3] & 0x30) << 26) | (data[2] << 22)) >> 22;\n\t\tclicks = data[3];\n\n\t\t/* The following bits provide a device specific timestamp. They\n\t\t * are unused here.\n\t\t *\n\t\t * ts = data[3] >> 6 | data[4] << 2 | data[5] << 10;\n\t\t */\n\t\tbreak;\n\tcase DOUBLE_REPORT_ID:\n\t\t/* Sometimes the trackpad sends two touch reports in one\n\t\t * packet.\n\t\t */\n\t\tmagicmouse_raw_event(hdev, report, data + 2, data[1]);\n\t\tmagicmouse_raw_event(hdev, report, data + 2 + data[1],\n\t\t\tsize - 2 - data[1]);\n\t\tbreak;\n\tdefault:\n\t\treturn 0;\n\t}\n\n\tif (input->id.product == USB_DEVICE_ID_APPLE_MAGICMOUSE) {\n\t\tmagicmouse_emit_buttons(msc, clicks & 3);\n\t\tinput_report_rel(input, REL_X, x);\n\t\tinput_report_rel(input, REL_Y, y);\n\t} else { /* USB_DEVICE_ID_APPLE_MAGICTRACKPAD */\n\t\tinput_report_key(input, BTN_MOUSE, clicks & 1);\n\t\tinput_mt_report_pointer_emulation(input, true);\n\t}\n\n\tinput_sync(input);\n\treturn 1;\n}",
      "code_after_change": "static int magicmouse_raw_event(struct hid_device *hdev,\n\t\tstruct hid_report *report, u8 *data, int size)\n{\n\tstruct magicmouse_sc *msc = hid_get_drvdata(hdev);\n\tstruct input_dev *input = msc->input;\n\tint x = 0, y = 0, ii, clicks = 0, npoints;\n\n\tswitch (data[0]) {\n\tcase TRACKPAD_REPORT_ID:\n\t\t/* Expect four bytes of prefix, and N*9 bytes of touch data. */\n\t\tif (size < 4 || ((size - 4) % 9) != 0)\n\t\t\treturn 0;\n\t\tnpoints = (size - 4) / 9;\n\t\tif (npoints > 15) {\n\t\t\thid_warn(hdev, \"invalid size value (%d) for TRACKPAD_REPORT_ID\\n\",\n\t\t\t\t\tsize);\n\t\t\treturn 0;\n\t\t}\n\t\tmsc->ntouches = 0;\n\t\tfor (ii = 0; ii < npoints; ii++)\n\t\t\tmagicmouse_emit_touch(msc, ii, data + ii * 9 + 4);\n\n\t\tclicks = data[1];\n\n\t\t/* The following bits provide a device specific timestamp. They\n\t\t * are unused here.\n\t\t *\n\t\t * ts = data[1] >> 6 | data[2] << 2 | data[3] << 10;\n\t\t */\n\t\tbreak;\n\tcase MOUSE_REPORT_ID:\n\t\t/* Expect six bytes of prefix, and N*8 bytes of touch data. */\n\t\tif (size < 6 || ((size - 6) % 8) != 0)\n\t\t\treturn 0;\n\t\tnpoints = (size - 6) / 8;\n\t\tif (npoints > 15) {\n\t\t\thid_warn(hdev, \"invalid size value (%d) for MOUSE_REPORT_ID\\n\",\n\t\t\t\t\tsize);\n\t\t\treturn 0;\n\t\t}\n\t\tmsc->ntouches = 0;\n\t\tfor (ii = 0; ii < npoints; ii++)\n\t\t\tmagicmouse_emit_touch(msc, ii, data + ii * 8 + 6);\n\n\t\t/* When emulating three-button mode, it is important\n\t\t * to have the current touch information before\n\t\t * generating a click event.\n\t\t */\n\t\tx = (int)(((data[3] & 0x0c) << 28) | (data[1] << 22)) >> 22;\n\t\ty = (int)(((data[3] & 0x30) << 26) | (data[2] << 22)) >> 22;\n\t\tclicks = data[3];\n\n\t\t/* The following bits provide a device specific timestamp. They\n\t\t * are unused here.\n\t\t *\n\t\t * ts = data[3] >> 6 | data[4] << 2 | data[5] << 10;\n\t\t */\n\t\tbreak;\n\tcase DOUBLE_REPORT_ID:\n\t\t/* Sometimes the trackpad sends two touch reports in one\n\t\t * packet.\n\t\t */\n\t\tmagicmouse_raw_event(hdev, report, data + 2, data[1]);\n\t\tmagicmouse_raw_event(hdev, report, data + 2 + data[1],\n\t\t\tsize - 2 - data[1]);\n\t\tbreak;\n\tdefault:\n\t\treturn 0;\n\t}\n\n\tif (input->id.product == USB_DEVICE_ID_APPLE_MAGICMOUSE) {\n\t\tmagicmouse_emit_buttons(msc, clicks & 3);\n\t\tinput_report_rel(input, REL_X, x);\n\t\tinput_report_rel(input, REL_Y, y);\n\t} else { /* USB_DEVICE_ID_APPLE_MAGICTRACKPAD */\n\t\tinput_report_key(input, BTN_MOUSE, clicks & 1);\n\t\tinput_mt_report_pointer_emulation(input, true);\n\t}\n\n\tinput_sync(input);\n\treturn 1;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (npoints > 15) {",
          "\t\t\thid_warn(hdev, \"invalid size value (%d) for TRACKPAD_REPORT_ID\\n\",",
          "\t\t\t\t\tsize);",
          "\t\t\treturn 0;",
          "\t\t}",
          "\t\tif (npoints > 15) {",
          "\t\t\thid_warn(hdev, \"invalid size value (%d) for MOUSE_REPORT_ID\\n\",",
          "\t\t\t\t\tsize);",
          "\t\t\treturn 0;",
          "\t\t}"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of bounds checking on the number of touch points received from a device, allowing for a large amount of data to overflow the stack buffer.",
      "trigger_condition": "A physically proximate attacker provides a crafted device that sends a large amount of data associated with an event, causing a stack-based buffer overflow in the magicmouse_raw_event function.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the number of touch points received from the device, leading to a potential buffer overflow when processing the touch data.",
      "id": 53,
      "code_after_change_normalized": "static int FUN1(struct hid_device *VAR1,\nstruct hid_report *VAR2, u8 *VAR3, int VAR4)\n{\nstruct magicmouse_sc *VAR5 = FUN2(VAR1);\nstruct input_dev *VAR6 = VAR5->VAR6;\nint VAR7 = 0, VAR8 = 0, VAR9, VAR10 = 0, VAR11;\nswitch (VAR3[0]) {\ncase VAR12:\nif (VAR4 < 4 || ((VAR4 - 4) % 9) != 0)\nreturn 0;\nVAR11 = (VAR4 - 4) / 9;\nif (VAR11 > 15) {\nFUN3(VAR1, \"STR\",\nVAR4);\nreturn 0;\n}\nVAR5->VAR13 = 0;\nfor (VAR9 = 0; VAR9 < VAR11; VAR9++)\nFUN4(VAR5, VAR9, VAR3 + VAR9 * 9 + 4);\nVAR10 = VAR3[1];\nbreak;\ncase VAR14:\nif (VAR4 < 6 || ((VAR4 - 6) % 8) != 0)\nreturn 0;\nVAR11 = (VAR4 - 6) / 8;\nif (VAR11 > 15) {\nFUN3(VAR1, \"STR\",\nVAR4);\nreturn 0;\n}\nVAR5->VAR13 = 0;\nfor (VAR9 = 0; VAR9 < VAR11; VAR9++)\nFUN4(VAR5, VAR9, VAR3 + VAR9 * 8 + 6);\nVAR7 = (int)(((VAR3[3] & VAR15) << 28) | (VAR3[1] << 22)) >> 22;\nVAR8 = (int)(((VAR3[3] & VAR15) << 26) | (VAR3[2] << 22)) >> 22;\nVAR10 = VAR3[3];\nbreak;\ncase VAR16:\nFUN1(VAR1, VAR2, VAR3 + 2, VAR3[1]);\nFUN1(VAR1, VAR2, VAR3 + 2 + VAR3[1],\nVAR4 - 2 - VAR3[1]);\nbreak;\ndefault:\nreturn 0;\n}\nif (VAR6->VAR17.VAR18 == VAR19) {\nFUN5(VAR5, VAR10 & 3);\nFUN6(VAR6, VAR20, VAR7);\nFUN6(VAR6, VAR21, VAR8);\n} else { \nFUN7(VAR6, VAR22, VAR10 & 1);\nFUN8(VAR6, true);\n}\nFUN9(VAR6);\nreturn 1;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct hid_device *VAR1,\nstruct hid_report *VAR2, u8 *VAR3, int VAR4)\n{\nstruct magicmouse_sc *VAR5 = FUN2(VAR1);\nstruct input_dev *VAR6 = VAR5->VAR6;\nint VAR7 = 0, VAR8 = 0, VAR9, VAR10 = 0, VAR11;\nswitch (VAR3[0]) {\ncase VAR12:\nif (VAR4 < 4 || ((VAR4 - 4) % 9) != 0)\nreturn 0;\nVAR11 = (VAR4 - 4) / 9;\nVAR5->VAR13 = 0;\nfor (VAR9 = 0; VAR9 < VAR11; VAR9++)\nFUN3(VAR5, VAR9, VAR3 + VAR9 * 9 + 4);\nVAR10 = VAR3[1];\nbreak;\ncase VAR14:\nif (VAR4 < 6 || ((VAR4 - 6) % 8) != 0)\nreturn 0;\nVAR11 = (VAR4 - 6) / 8;\nVAR5->VAR13 = 0;\nfor (VAR9 = 0; VAR9 < VAR11; VAR9++)\nFUN3(VAR5, VAR9, VAR3 + VAR9 * 8 + 6);\nVAR7 = (int)(((VAR3[3] & VAR15) << 28) | (VAR3[1] << 22)) >> 22;\nVAR8 = (int)(((VAR3[3] & VAR15) << 26) | (VAR3[2] << 22)) >> 22;\nVAR10 = VAR3[3];\nbreak;\ncase VAR16:\nFUN1(VAR1, VAR2, VAR3 + 2, VAR3[1]);\nFUN1(VAR1, VAR2, VAR3 + 2 + VAR3[1],\nVAR4 - 2 - VAR3[1]);\nbreak;\ndefault:\nreturn 0;\n}\nif (VAR6->VAR17.VAR18 == VAR19) {\nFUN4(VAR5, VAR10 & 3);\nFUN5(VAR6, VAR20, VAR7);\nFUN5(VAR6, VAR21, VAR8);\n} else { \nFUN6(VAR6, VAR22, VAR10 & 1);\nFUN7(VAR6, true);\n}\nFUN8(VAR6);\nreturn 1;\n}\n",
      "code_after_change_raw": "static int magicmouse_raw_event(struct hid_device *hdev,\nstruct hid_report *report, u8 *data, int size)\n{\nstruct magicmouse_sc *msc = hid_get_drvdata(hdev);\nstruct input_dev *input = msc->input;\nint x = 0, y = 0, ii, clicks = 0, npoints;\nswitch (data[0]) {\ncase TRACKPAD_REPORT_ID:\nif (size < 4 || ((size - 4) % 9) != 0)\nreturn 0;\nnpoints = (size - 4) / 9;\nif (npoints > 15) {\nhid_warn(hdev, \"invalid size value (%d) for TRACKPAD_REPORT_ID\\n\",\nsize);\nreturn 0;\n}\nmsc->ntouches = 0;\nfor (ii = 0; ii < npoints; ii++)\nmagicmouse_emit_touch(msc, ii, data + ii * 9 + 4);\nclicks = data[1];\nbreak;\ncase MOUSE_REPORT_ID:\nif (size < 6 || ((size - 6) % 8) != 0)\nreturn 0;\nnpoints = (size - 6) / 8;\nif (npoints > 15) {\nhid_warn(hdev, \"invalid size value (%d) for MOUSE_REPORT_ID\\n\",\nsize);\nreturn 0;\n}\nmsc->ntouches = 0;\nfor (ii = 0; ii < npoints; ii++)\nmagicmouse_emit_touch(msc, ii, data + ii * 8 + 6);\nx = (int)(((data[3] & 0x0c) << 28) | (data[1] << 22)) >> 22;\ny = (int)(((data[3] & 0x30) << 26) | (data[2] << 22)) >> 22;\nclicks = data[3];\nbreak;\ncase DOUBLE_REPORT_ID:\nmagicmouse_raw_event(hdev, report, data + 2, data[1]);\nmagicmouse_raw_event(hdev, report, data + 2 + data[1],\nsize - 2 - data[1]);\nbreak;\ndefault:\nreturn 0;\n}\nif (input->id.product == USB_DEVICE_ID_APPLE_MAGICMOUSE) {\nmagicmouse_emit_buttons(msc, clicks & 3);\ninput_report_rel(input, REL_X, x);\ninput_report_rel(input, REL_Y, y);\n} else { \ninput_report_key(input, BTN_MOUSE, clicks & 1);\ninput_mt_report_pointer_emulation(input, true);\n}\ninput_sync(input);\nreturn 1;\n}\n",
      "code_before_change_raw": "static int magicmouse_raw_event(struct hid_device *hdev,\nstruct hid_report *report, u8 *data, int size)\n{\nstruct magicmouse_sc *msc = hid_get_drvdata(hdev);\nstruct input_dev *input = msc->input;\nint x = 0, y = 0, ii, clicks = 0, npoints;\nswitch (data[0]) {\ncase TRACKPAD_REPORT_ID:\nif (size < 4 || ((size - 4) % 9) != 0)\nreturn 0;\nnpoints = (size - 4) / 9;\nmsc->ntouches = 0;\nfor (ii = 0; ii < npoints; ii++)\nmagicmouse_emit_touch(msc, ii, data + ii * 9 + 4);\nclicks = data[1];\nbreak;\ncase MOUSE_REPORT_ID:\nif (size < 6 || ((size - 6) % 8) != 0)\nreturn 0;\nnpoints = (size - 6) / 8;\nmsc->ntouches = 0;\nfor (ii = 0; ii < npoints; ii++)\nmagicmouse_emit_touch(msc, ii, data + ii * 8 + 6);\nx = (int)(((data[3] & 0x0c) << 28) | (data[1] << 22)) >> 22;\ny = (int)(((data[3] & 0x30) << 26) | (data[2] << 22)) >> 22;\nclicks = data[3];\nbreak;\ncase DOUBLE_REPORT_ID:\nmagicmouse_raw_event(hdev, report, data + 2, data[1]);\nmagicmouse_raw_event(hdev, report, data + 2 + data[1],\nsize - 2 - data[1]);\nbreak;\ndefault:\nreturn 0;\n}\nif (input->id.product == USB_DEVICE_ID_APPLE_MAGICMOUSE) {\nmagicmouse_emit_buttons(msc, clicks & 3);\ninput_report_rel(input, REL_X, x);\ninput_report_rel(input, REL_Y, y);\n} else { \ninput_report_key(input, BTN_MOUSE, clicks & 1);\ninput_mt_report_pointer_emulation(input, true);\n}\ninput_sync(input);\nreturn 1;\n}\n"
    }
  ],
  "CVE-2014-3182": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper array index validation and memory management in handling device pairing information.",
        "trigger_condition": "Receiving a malformed REPORT_TYPE_NOTIF_DEVICE_UNPAIRED value from a crafted device, leading to an array index error and invalid memory deallocation.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the device index bounds before accessing the array paired_dj_devices, potentially leading to out-of-bounds access. Additionally, there is a lack of proper cleanup if an error occurs during memory allocation for dj_dev, which can result in memory leaks and invalid memory access.",
        "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure the device index is within valid bounds before accessing the array paired_dj_devices. Additionally, proper cleanup should be implemented in case of an error during memory allocation for dj_dev, including freeing the allocated memory and destroying the HID device to prevent memory leaks and potential issues with invalid memory access. These measures will enhance the code's robustness and security by addressing array index errors and memory management issues."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2014-3182 by properly handling memory allocation and deallocation in the code snippet. Specifically, the vulnerability involves a potential array index error that could lead to executing arbitrary code or causing a denial of service due to a malformed REPORT_TYPE_NOTIF_DEVICE_UNPAIRED value.\n\nTo fix this vulnerability, the following modifications are recommended:\n1. Add a check to ensure that the device index is within valid bounds before accessing the array `djrcv_dev->paired_dj_devices`.\n2. If an error occurs during the allocation of `dj_dev`, properly handle the cleanup by freeing the allocated memory and destroying the HID device to prevent memory leaks and potential issues with invalid memory access.\n\nBy adding the provided lines, the code will be more robust and secure, reducing the risk of exploitation related to array index errors and memory management issues.",
      "GPT_purpose": "This function adds a Logitech Unifying Device to the system based on a received report from a Logitech DJ receiver device.",
      "GPT_function": "\n1. Allocate and initialize a new HID device for a Logitech Unifying Device.\n2. Populate the HID device with vendor and product information, as well as physical path and device index.\n3. Add the HID device to the system and store information about the device in a data structure.",
      "CVE_id": "CVE-2014-3182",
      "code_before_change": "static void logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,\n\t\t\t\t\t  struct dj_report *dj_report)\n{\n\t/* Called in delayed work context */\n\tstruct hid_device *djrcv_hdev = djrcv_dev->hdev;\n\tstruct usb_interface *intf = to_usb_interface(djrcv_hdev->dev.parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(intf);\n\tstruct hid_device *dj_hiddev;\n\tstruct dj_device *dj_dev;\n\n\t/* Device index goes from 1 to 6, we need 3 bytes to store the\n\t * semicolon, the index, and a null terminator\n\t */\n\tunsigned char tmpstr[3];\n\n\tif (dj_report->report_params[DEVICE_PAIRED_PARAM_SPFUNCTION] &\n\t    SPFUNCTION_DEVICE_LIST_EMPTY) {\n\t\tdbg_hid(\"%s: device list is empty\\n\", __func__);\n\t\tdjrcv_dev->querying_devices = false;\n\t\treturn;\n\t}\n\n\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||\n\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: invalid device index:%d\\n\",\n\t\t\t__func__, dj_report->device_index);\n\t\treturn;\n\t}\n\n\tif (djrcv_dev->paired_dj_devices[dj_report->device_index]) {\n\t\t/* The device is already known. No need to reallocate it. */\n\t\tdbg_hid(\"%s: device is already known\\n\", __func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev = hid_allocate_device();\n\tif (IS_ERR(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: hid_allocate_device failed\\n\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev->ll_driver = &logi_dj_ll_driver;\n\n\tdj_hiddev->dev.parent = &djrcv_hdev->dev;\n\tdj_hiddev->bus = BUS_USB;\n\tdj_hiddev->vendor = le16_to_cpu(usbdev->descriptor.idVendor);\n\tdj_hiddev->product = le16_to_cpu(usbdev->descriptor.idProduct);\n\tsnprintf(dj_hiddev->name, sizeof(dj_hiddev->name),\n\t\t\"Logitech Unifying Device. Wireless PID:%02x%02x\",\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_MSB],\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_LSB]);\n\n\tusb_make_path(usbdev, dj_hiddev->phys, sizeof(dj_hiddev->phys));\n\tsnprintf(tmpstr, sizeof(tmpstr), \":%d\", dj_report->device_index);\n\tstrlcat(dj_hiddev->phys, tmpstr, sizeof(dj_hiddev->phys));\n\n\tdj_dev = kzalloc(sizeof(struct dj_device), GFP_KERNEL);\n\n\tif (!dj_dev) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed allocating dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto dj_device_allocate_fail;\n\t}\n\n\tdj_dev->reports_supported = get_unaligned_le32(\n\t\tdj_report->report_params + DEVICE_PAIRED_RF_REPORT_TYPE);\n\tdj_dev->hdev = dj_hiddev;\n\tdj_dev->dj_receiver_dev = djrcv_dev;\n\tdj_dev->device_index = dj_report->device_index;\n\tdj_hiddev->driver_data = dj_dev;\n\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = dj_dev;\n\n\tif (hid_add_device(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed adding dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto hid_add_device_fail;\n\t}\n\n\treturn;\n\nhid_add_device_fail:\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;\n\tkfree(dj_dev);\ndj_device_allocate_fail:\n\thid_destroy_device(dj_hiddev);\n}",
      "code_after_change": "static void logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,\n\t\t\t\t\t  struct dj_report *dj_report)\n{\n\t/* Called in delayed work context */\n\tstruct hid_device *djrcv_hdev = djrcv_dev->hdev;\n\tstruct usb_interface *intf = to_usb_interface(djrcv_hdev->dev.parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(intf);\n\tstruct hid_device *dj_hiddev;\n\tstruct dj_device *dj_dev;\n\n\t/* Device index goes from 1 to 6, we need 3 bytes to store the\n\t * semicolon, the index, and a null terminator\n\t */\n\tunsigned char tmpstr[3];\n\n\tif (dj_report->report_params[DEVICE_PAIRED_PARAM_SPFUNCTION] &\n\t    SPFUNCTION_DEVICE_LIST_EMPTY) {\n\t\tdbg_hid(\"%s: device list is empty\\n\", __func__);\n\t\tdjrcv_dev->querying_devices = false;\n\t\treturn;\n\t}\n\n\tif (djrcv_dev->paired_dj_devices[dj_report->device_index]) {\n\t\t/* The device is already known. No need to reallocate it. */\n\t\tdbg_hid(\"%s: device is already known\\n\", __func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev = hid_allocate_device();\n\tif (IS_ERR(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: hid_allocate_device failed\\n\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev->ll_driver = &logi_dj_ll_driver;\n\n\tdj_hiddev->dev.parent = &djrcv_hdev->dev;\n\tdj_hiddev->bus = BUS_USB;\n\tdj_hiddev->vendor = le16_to_cpu(usbdev->descriptor.idVendor);\n\tdj_hiddev->product = le16_to_cpu(usbdev->descriptor.idProduct);\n\tsnprintf(dj_hiddev->name, sizeof(dj_hiddev->name),\n\t\t\"Logitech Unifying Device. Wireless PID:%02x%02x\",\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_MSB],\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_LSB]);\n\n\tusb_make_path(usbdev, dj_hiddev->phys, sizeof(dj_hiddev->phys));\n\tsnprintf(tmpstr, sizeof(tmpstr), \":%d\", dj_report->device_index);\n\tstrlcat(dj_hiddev->phys, tmpstr, sizeof(dj_hiddev->phys));\n\n\tdj_dev = kzalloc(sizeof(struct dj_device), GFP_KERNEL);\n\n\tif (!dj_dev) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed allocating dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto dj_device_allocate_fail;\n\t}\n\n\tdj_dev->reports_supported = get_unaligned_le32(\n\t\tdj_report->report_params + DEVICE_PAIRED_RF_REPORT_TYPE);\n\tdj_dev->hdev = dj_hiddev;\n\tdj_dev->dj_receiver_dev = djrcv_dev;\n\tdj_dev->device_index = dj_report->device_index;\n\tdj_hiddev->driver_data = dj_dev;\n\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = dj_dev;\n\n\tif (hid_add_device(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed adding dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto hid_add_device_fail;\n\t}\n\n\treturn;\n\nhid_add_device_fail:\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;\n\tkfree(dj_dev);\ndj_device_allocate_fail:\n\thid_destroy_device(dj_hiddev);\n}",
      "modified_lines": {
        "added": [],
        "deleted": [
          "\t\treturn;",
          "\t}",
          "",
          "\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||",
          "\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {",
          "\t\tdev_err(&djrcv_hdev->dev, \"%s: invalid device index:%d\\n\",",
          "\t\t\t__func__, dj_report->device_index);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper array index validation and memory management in handling device pairing information.",
      "trigger_condition": "Receiving a malformed REPORT_TYPE_NOTIF_DEVICE_UNPAIRED value from a crafted device, leading to an array index error and invalid memory deallocation.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the device index bounds before accessing the array paired_dj_devices, potentially leading to out-of-bounds access. Additionally, there is a lack of proper cleanup if an error occurs during memory allocation for dj_dev, which can result in memory leaks and invalid memory access.",
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure the device index is within valid bounds before accessing the array paired_dj_devices. Additionally, proper cleanup should be implemented in case of an error during memory allocation for dj_dev, including freeing the allocated memory and destroying the HID device to prevent memory leaks and potential issues with invalid memory access. These measures will enhance the code's robustness and security by addressing array index errors and memory management issues.",
      "id": 54,
      "code_after_change_normalized": "static void FUN1(struct dj_receiver_dev *VAR1,\nstruct VAR2 *VAR2)\n{\nstruct hid_device *VAR3 = VAR1->VAR4;\nstruct usb_interface *VAR5 = FUN2(VAR3->VAR6.VAR7);\nstruct usb_device *VAR8 = FUN3(VAR5);\nstruct hid_device *VAR9;\nstruct dj_device *VAR10;\nunsigned char VAR11[3];\nif (VAR2->VAR12[VAR13] &\nVAR14) {\nFUN4(\"STR\", VAR15);\nVAR1->VAR16 = false;\nreturn;\n}\nif (VAR1->VAR17[VAR2->VAR18]) {\nFUN4(\"STR\", VAR15);\nreturn;\n}\nVAR9 = FUN5();\nif (FUN6(VAR9)) {\nFUN7(&VAR3->VAR6, \"STR\",\nVAR15);\nreturn;\n}\nVAR9->VAR19 = &VAR20;\nVAR9->VAR6.VAR7 = &VAR3->VAR6;\nVAR9->VAR21 = VAR22;\nVAR9->VAR23 = FUN8(VAR8->VAR24.VAR25);\nVAR9->VAR26 = FUN8(VAR8->VAR24.VAR27);\nFUN9(VAR9->VAR28, sizeof(VAR9->VAR28),\n\"STR\",\nVAR2->VAR12[VAR29],\nVAR2->VAR12[VAR30]);\nFUN10(VAR8, VAR9->VAR31, sizeof(VAR9->VAR31));\nFUN9(VAR11, sizeof(VAR11), \"STR\", VAR2->VAR18);\nFUN11(VAR9->VAR31, VAR11, sizeof(VAR9->VAR31));\nVAR10 = FUN12(sizeof(struct VAR32), VAR33);\nif (!VAR10) {\nFUN7(&VAR3->VAR6, \"STR\",\nVAR15);\ngoto VAR34;\n}\nVAR10->VAR35 = FUN13(\nVAR2->VAR12 + VAR36);\nVAR10->VAR4 = VAR9;\nVAR10->VAR37 = VAR1;\nVAR10->VAR18 = VAR2->VAR18;\nVAR9->VAR38 = VAR10;\nVAR1->VAR17[VAR2->VAR18] = VAR10;\nif (FUN14(VAR9)) {\nFUN7(&VAR3->VAR6, \"STR\",\nVAR15);\ngoto VAR39;\n}\nreturn;\nVAR39:\nVAR1->VAR17[VAR2->VAR18] = NULL;\nFUN15(VAR10);\nVAR34:\nFUN16(VAR9);\n}\n",
      "code_before_change_normalized": "static void FUN1(struct dj_receiver_dev *VAR1,\nstruct VAR2 *VAR2)\n{\nstruct hid_device *VAR3 = VAR1->VAR4;\nstruct usb_interface *VAR5 = FUN2(VAR3->VAR6.VAR7);\nstruct usb_device *VAR8 = FUN3(VAR5);\nstruct hid_device *VAR9;\nstruct dj_device *VAR10;\nunsigned char VAR11[3];\nif (VAR2->VAR12[VAR13] &\nVAR14) {\nFUN4(\"STR\", VAR15);\nVAR1->VAR16 = false;\nreturn;\n}\nif ((VAR2->VAR17 < VAR18) ||\n(VAR2->VAR17 > VAR19)) {\nFUN5(&VAR3->VAR6, \"STR\",\nVAR15, VAR2->VAR17);\nreturn;\n}\nif (VAR1->VAR20[VAR2->VAR17]) {\nFUN4(\"STR\", VAR15);\nreturn;\n}\nVAR9 = FUN6();\nif (FUN7(VAR9)) {\nFUN5(&VAR3->VAR6, \"STR\",\nVAR15);\nreturn;\n}\nVAR9->VAR21 = &VAR22;\nVAR9->VAR6.VAR7 = &VAR3->VAR6;\nVAR9->VAR23 = VAR24;\nVAR9->VAR25 = FUN8(VAR8->VAR26.VAR27);\nVAR9->VAR28 = FUN8(VAR8->VAR26.VAR29);\nFUN9(VAR9->VAR30, sizeof(VAR9->VAR30),\n\"STR\",\nVAR2->VAR12[VAR31],\nVAR2->VAR12[VAR32]);\nFUN10(VAR8, VAR9->VAR33, sizeof(VAR9->VAR33));\nFUN9(VAR11, sizeof(VAR11), \"STR\", VAR2->VAR17);\nFUN11(VAR9->VAR33, VAR11, sizeof(VAR9->VAR33));\nVAR10 = FUN12(sizeof(struct VAR34), VAR35);\nif (!VAR10) {\nFUN5(&VAR3->VAR6, \"STR\",\nVAR15);\ngoto VAR36;\n}\nVAR10->VAR37 = FUN13(\nVAR2->VAR12 + VAR38);\nVAR10->VAR4 = VAR9;\nVAR10->VAR39 = VAR1;\nVAR10->VAR17 = VAR2->VAR17;\nVAR9->VAR40 = VAR10;\nVAR1->VAR20[VAR2->VAR17] = VAR10;\nif (FUN14(VAR9)) {\nFUN5(&VAR3->VAR6, \"STR\",\nVAR15);\ngoto VAR41;\n}\nreturn;\nVAR41:\nVAR1->VAR20[VAR2->VAR17] = NULL;\nFUN15(VAR10);\nVAR36:\nFUN16(VAR9);\n}\n",
      "code_after_change_raw": "static void logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,\nstruct dj_report *dj_report)\n{\nstruct hid_device *djrcv_hdev = djrcv_dev->hdev;\nstruct usb_interface *intf = to_usb_interface(djrcv_hdev->dev.parent);\nstruct usb_device *usbdev = interface_to_usbdev(intf);\nstruct hid_device *dj_hiddev;\nstruct dj_device *dj_dev;\nunsigned char tmpstr[3];\nif (dj_report->report_params[DEVICE_PAIRED_PARAM_SPFUNCTION] &\nSPFUNCTION_DEVICE_LIST_EMPTY) {\ndbg_hid(\"%s: device list is empty\\n\", __func__);\ndjrcv_dev->querying_devices = false;\nreturn;\n}\nif (djrcv_dev->paired_dj_devices[dj_report->device_index]) {\ndbg_hid(\"%s: device is already known\\n\", __func__);\nreturn;\n}\ndj_hiddev = hid_allocate_device();\nif (IS_ERR(dj_hiddev)) {\ndev_err(&djrcv_hdev->dev, \"%s: hid_allocate_device failed\\n\",\n__func__);\nreturn;\n}\ndj_hiddev->ll_driver = &logi_dj_ll_driver;\ndj_hiddev->dev.parent = &djrcv_hdev->dev;\ndj_hiddev->bus = BUS_USB;\ndj_hiddev->vendor = le16_to_cpu(usbdev->descriptor.idVendor);\ndj_hiddev->product = le16_to_cpu(usbdev->descriptor.idProduct);\nsnprintf(dj_hiddev->name, sizeof(dj_hiddev->name),\n\"Logitech Unifying Device. Wireless PID:%02x%02x\",\ndj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_MSB],\ndj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_LSB]);\nusb_make_path(usbdev, dj_hiddev->phys, sizeof(dj_hiddev->phys));\nsnprintf(tmpstr, sizeof(tmpstr), \":%d\", dj_report->device_index);\nstrlcat(dj_hiddev->phys, tmpstr, sizeof(dj_hiddev->phys));\ndj_dev = kzalloc(sizeof(struct dj_device), GFP_KERNEL);\nif (!dj_dev) {\ndev_err(&djrcv_hdev->dev, \"%s: failed allocating dj_device\\n\",\n__func__);\ngoto dj_device_allocate_fail;\n}\ndj_dev->reports_supported = get_unaligned_le32(\ndj_report->report_params + DEVICE_PAIRED_RF_REPORT_TYPE);\ndj_dev->hdev = dj_hiddev;\ndj_dev->dj_receiver_dev = djrcv_dev;\ndj_dev->device_index = dj_report->device_index;\ndj_hiddev->driver_data = dj_dev;\ndjrcv_dev->paired_dj_devices[dj_report->device_index] = dj_dev;\nif (hid_add_device(dj_hiddev)) {\ndev_err(&djrcv_hdev->dev, \"%s: failed adding dj_device\\n\",\n__func__);\ngoto hid_add_device_fail;\n}\nreturn;\nhid_add_device_fail:\ndjrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;\nkfree(dj_dev);\ndj_device_allocate_fail:\nhid_destroy_device(dj_hiddev);\n}\n",
      "code_before_change_raw": "static void logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,\nstruct dj_report *dj_report)\n{\nstruct hid_device *djrcv_hdev = djrcv_dev->hdev;\nstruct usb_interface *intf = to_usb_interface(djrcv_hdev->dev.parent);\nstruct usb_device *usbdev = interface_to_usbdev(intf);\nstruct hid_device *dj_hiddev;\nstruct dj_device *dj_dev;\nunsigned char tmpstr[3];\nif (dj_report->report_params[DEVICE_PAIRED_PARAM_SPFUNCTION] &\nSPFUNCTION_DEVICE_LIST_EMPTY) {\ndbg_hid(\"%s: device list is empty\\n\", __func__);\ndjrcv_dev->querying_devices = false;\nreturn;\n}\nif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||\n(dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {\ndev_err(&djrcv_hdev->dev, \"%s: invalid device index:%d\\n\",\n__func__, dj_report->device_index);\nreturn;\n}\nif (djrcv_dev->paired_dj_devices[dj_report->device_index]) {\ndbg_hid(\"%s: device is already known\\n\", __func__);\nreturn;\n}\ndj_hiddev = hid_allocate_device();\nif (IS_ERR(dj_hiddev)) {\ndev_err(&djrcv_hdev->dev, \"%s: hid_allocate_device failed\\n\",\n__func__);\nreturn;\n}\ndj_hiddev->ll_driver = &logi_dj_ll_driver;\ndj_hiddev->dev.parent = &djrcv_hdev->dev;\ndj_hiddev->bus = BUS_USB;\ndj_hiddev->vendor = le16_to_cpu(usbdev->descriptor.idVendor);\ndj_hiddev->product = le16_to_cpu(usbdev->descriptor.idProduct);\nsnprintf(dj_hiddev->name, sizeof(dj_hiddev->name),\n\"Logitech Unifying Device. Wireless PID:%02x%02x\",\ndj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_MSB],\ndj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_LSB]);\nusb_make_path(usbdev, dj_hiddev->phys, sizeof(dj_hiddev->phys));\nsnprintf(tmpstr, sizeof(tmpstr), \":%d\", dj_report->device_index);\nstrlcat(dj_hiddev->phys, tmpstr, sizeof(dj_hiddev->phys));\ndj_dev = kzalloc(sizeof(struct dj_device), GFP_KERNEL);\nif (!dj_dev) {\ndev_err(&djrcv_hdev->dev, \"%s: failed allocating dj_device\\n\",\n__func__);\ngoto dj_device_allocate_fail;\n}\ndj_dev->reports_supported = get_unaligned_le32(\ndj_report->report_params + DEVICE_PAIRED_RF_REPORT_TYPE);\ndj_dev->hdev = dj_hiddev;\ndj_dev->dj_receiver_dev = djrcv_dev;\ndj_dev->device_index = dj_report->device_index;\ndj_hiddev->driver_data = dj_dev;\ndjrcv_dev->paired_dj_devices[dj_report->device_index] = dj_dev;\nif (hid_add_device(dj_hiddev)) {\ndev_err(&djrcv_hdev->dev, \"%s: failed adding dj_device\\n\",\n__func__);\ngoto hid_add_device_fail;\n}\nreturn;\nhid_add_device_fail:\ndjrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;\nkfree(dj_dev);\ndj_device_allocate_fail:\nhid_destroy_device(dj_hiddev);\n}\n"
    }
  ],
  "CVE-2014-3183": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for the size of the data being copied into a buffer, specifically related to LED report sizes.",
        "trigger_condition": "A crafted device specifies a large report size for an LED report, causing the count variable to exceed the allowed buffer size.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check the size of the data to be copied into the out_buf buffer, leading to a potential heap-based buffer overflow if the count value is not constrained within the buffer limits."
      },
      "solution": "To mitigate the vulnerability, it is necessary to validate the size of the data being copied into the buffer before performing the copy operation. In this case, the solution involves checking if the count value exceeds the allowed buffer size and adjusting it accordingly to prevent buffer overflow. By ensuring that only a safe amount of data is copied into the buffer, the code can prevent potential security exploits related to buffer overflows.",
      "GPT_analysis": "The modification made in the code snippet is necessary to address the vulnerability CVE-2014-3183, which is a heap-based buffer overflow issue. \n\nIn the original code snippet, the count variable is being used to determine the size of the data to be copied into the out_buf buffer. However, there is a vulnerability in the code where the count value is not properly checked before copying data into the out_buf buffer. This can lead to a buffer overflow if a crafted device specifies a large report size for an LED report, causing a denial of service or potentially allowing an attacker to execute arbitrary code.\n\nBy modifying the code to check if the count is greater than the allowed size (DJREPORT_SHORT_LENGTH - 2) and adjusting it accordingly, we can prevent the buffer overflow vulnerability. This modification ensures that only a safe amount of data is copied into the out_buf buffer, mitigating the risk of buffer overflow and potential security exploits.",
      "GPT_purpose": "Handle raw requests for Logitech DJ devices, specifically for LED reports, with a vulnerability that can lead to a denial of service or potential code execution.",
      "GPT_function": "\n1. Check if the report type is not REPORT_TYPE_LEDS and return an error.\n2. Allocate memory for out_buf with a specific length.\n3. Copy data from buf to out_buf with a limit on the count.\n4. Set values in out_buf for report ID and device index.\n5. Perform a raw request using hid_hw_raw_request with specific parameters.\n6. Free the allocated memory for out_buf before returning the result.",
      "CVE_id": "CVE-2014-3183",
      "code_before_change": "static int logi_dj_ll_raw_request(struct hid_device *hid,\n\t\t\t\t  unsigned char reportnum, __u8 *buf,\n\t\t\t\t  size_t count, unsigned char report_type,\n\t\t\t\t  int reqtype)\n{\n\tstruct dj_device *djdev = hid->driver_data;\n\tstruct dj_receiver_dev *djrcv_dev = djdev->dj_receiver_dev;\n\tu8 *out_buf;\n\tint ret;\n\n\tif (buf[0] != REPORT_TYPE_LEDS)\n\t\treturn -EINVAL;\n\n\tout_buf = kzalloc(DJREPORT_SHORT_LENGTH, GFP_ATOMIC);\n\tif (!out_buf)\n\t\treturn -ENOMEM;\n\n\tif (count < DJREPORT_SHORT_LENGTH - 2)\n\t\tcount = DJREPORT_SHORT_LENGTH - 2;\n\n\tout_buf[0] = REPORT_ID_DJ_SHORT;\n\tout_buf[1] = djdev->device_index;\n\tmemcpy(out_buf + 2, buf, count);\n\n\tret = hid_hw_raw_request(djrcv_dev->hdev, out_buf[0], out_buf,\n\t\tDJREPORT_SHORT_LENGTH, report_type, reqtype);\n\n\tkfree(out_buf);\n\treturn ret;\n}",
      "code_after_change": "static int logi_dj_ll_raw_request(struct hid_device *hid,\n\t\t\t\t  unsigned char reportnum, __u8 *buf,\n\t\t\t\t  size_t count, unsigned char report_type,\n\t\t\t\t  int reqtype)\n{\n\tstruct dj_device *djdev = hid->driver_data;\n\tstruct dj_receiver_dev *djrcv_dev = djdev->dj_receiver_dev;\n\tu8 *out_buf;\n\tint ret;\n\n\tif (buf[0] != REPORT_TYPE_LEDS)\n\t\treturn -EINVAL;\n\n\tout_buf = kzalloc(DJREPORT_SHORT_LENGTH, GFP_ATOMIC);\n\tif (!out_buf)\n\t\treturn -ENOMEM;\n\n\tif (count > DJREPORT_SHORT_LENGTH - 2)\n\t\tcount = DJREPORT_SHORT_LENGTH - 2;\n\n\tout_buf[0] = REPORT_ID_DJ_SHORT;\n\tout_buf[1] = djdev->device_index;\n\tmemcpy(out_buf + 2, buf, count);\n\n\tret = hid_hw_raw_request(djrcv_dev->hdev, out_buf[0], out_buf,\n\t\tDJREPORT_SHORT_LENGTH, report_type, reqtype);\n\n\tkfree(out_buf);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tif (count > DJREPORT_SHORT_LENGTH - 2)"
        ],
        "deleted": [
          "\tif (count < DJREPORT_SHORT_LENGTH - 2)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for the size of the data being copied into a buffer, specifically related to LED report sizes.",
      "trigger_condition": "A crafted device specifies a large report size for an LED report, causing the count variable to exceed the allowed buffer size.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check the size of the data to be copied into the out_buf buffer, leading to a potential heap-based buffer overflow if the count value is not constrained within the buffer limits.",
      "id": 55,
      "code_after_change_normalized": "static int FUN1(struct hid_device *VAR1,\nunsigned char VAR2, __u8 *VAR3,\nsize_t VAR4, unsigned char VAR5,\nint VAR6)\n{\nstruct dj_device *VAR7 = VAR1->VAR8;\nstruct VAR10 *VAR9 = VAR7->VAR10;\nu8 *VAR11;\nint VAR12;\nif (VAR3[0] != VAR13)\nreturn -VAR14;\nVAR11 = FUN2(VAR15, VAR16);\nif (!VAR11)\nreturn -VAR17;\nif (VAR4 > VAR15 - 2)\nVAR4 = VAR15 - 2;\nVAR11[0] = VAR18;\nVAR11[1] = VAR7->VAR19;\nFUN3(VAR11 + 2, VAR3, VAR4);\nVAR12 = FUN4(VAR9->VAR20, VAR11[0], VAR11,\nVAR15, VAR5, VAR6);\nFUN5(VAR11);\nreturn VAR12;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct hid_device *VAR1,\nunsigned char VAR2, __u8 *VAR3,\nsize_t VAR4, unsigned char VAR5,\nint VAR6)\n{\nstruct dj_device *VAR7 = VAR1->VAR8;\nstruct VAR10 *VAR9 = VAR7->VAR10;\nu8 *VAR11;\nint VAR12;\nif (VAR3[0] != VAR13)\nreturn -VAR14;\nVAR11 = FUN2(VAR15, VAR16);\nif (!VAR11)\nreturn -VAR17;\nif (VAR4 < VAR15 - 2)\nVAR4 = VAR15 - 2;\nVAR11[0] = VAR18;\nVAR11[1] = VAR7->VAR19;\nFUN3(VAR11 + 2, VAR3, VAR4);\nVAR12 = FUN4(VAR9->VAR20, VAR11[0], VAR11,\nVAR15, VAR5, VAR6);\nFUN5(VAR11);\nreturn VAR12;\n}\n",
      "code_after_change_raw": "static int logi_dj_ll_raw_request(struct hid_device *hid,\nunsigned char reportnum, __u8 *buf,\nsize_t count, unsigned char report_type,\nint reqtype)\n{\nstruct dj_device *djdev = hid->driver_data;\nstruct dj_receiver_dev *djrcv_dev = djdev->dj_receiver_dev;\nu8 *out_buf;\nint ret;\nif (buf[0] != REPORT_TYPE_LEDS)\nreturn -EINVAL;\nout_buf = kzalloc(DJREPORT_SHORT_LENGTH, GFP_ATOMIC);\nif (!out_buf)\nreturn -ENOMEM;\nif (count > DJREPORT_SHORT_LENGTH - 2)\ncount = DJREPORT_SHORT_LENGTH - 2;\nout_buf[0] = REPORT_ID_DJ_SHORT;\nout_buf[1] = djdev->device_index;\nmemcpy(out_buf + 2, buf, count);\nret = hid_hw_raw_request(djrcv_dev->hdev, out_buf[0], out_buf,\nDJREPORT_SHORT_LENGTH, report_type, reqtype);\nkfree(out_buf);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int logi_dj_ll_raw_request(struct hid_device *hid,\nunsigned char reportnum, __u8 *buf,\nsize_t count, unsigned char report_type,\nint reqtype)\n{\nstruct dj_device *djdev = hid->driver_data;\nstruct dj_receiver_dev *djrcv_dev = djdev->dj_receiver_dev;\nu8 *out_buf;\nint ret;\nif (buf[0] != REPORT_TYPE_LEDS)\nreturn -EINVAL;\nout_buf = kzalloc(DJREPORT_SHORT_LENGTH, GFP_ATOMIC);\nif (!out_buf)\nreturn -ENOMEM;\nif (count < DJREPORT_SHORT_LENGTH - 2)\ncount = DJREPORT_SHORT_LENGTH - 2;\nout_buf[0] = REPORT_ID_DJ_SHORT;\nout_buf[1] = djdev->device_index;\nmemcpy(out_buf + 2, buf, count);\nret = hid_hw_raw_request(djrcv_dev->hdev, out_buf[0], out_buf,\nDJREPORT_SHORT_LENGTH, report_type, reqtype);\nkfree(out_buf);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2014-3184": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Inadequate validation of the size of the report descriptor buffer.",
        "trigger_condition": "A physically proximate attacker provides a crafted device with a small report descriptor, leading to an out-of-bounds write vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check the size of the report descriptor buffer before attempting to write values to specific indices. This lack of validation allows an attacker to trigger an out-of-bounds write by providing a small report descriptor that overflows the buffer."
      },
      "solution": "To mitigate the vulnerability, it is necessary to enhance the validation of the report descriptor buffer size before performing any write operations. By ensuring that the buffer has sufficient space to accommodate the write operations, the code can prevent out-of-bounds writes and potential denial of service attacks. In this case, the solution involves modifying the code to check if the size of the report descriptor buffer is greater than or equal to the required size before proceeding with any write operations.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2014-3184, which involves an out-of-bounds write issue in the report_fixup functions of the HID subsystem in the Linux kernel. By checking if the size of the report descriptor is greater than or equal to 18 bytes instead of 17 bytes, the modified code ensures that there is enough space in the buffer to safely write the values to rdesc[16] and rdesc[17]. This change helps prevent a physically proximate attacker from exploiting the vulnerability and causing a denial of service by providing a crafted device with a small report descriptor that could lead to an out-of-bounds write.",
      "GPT_purpose": "This function is a fixup for a specific Cherry Cymotion report descriptor in the HID subsystem of the Linux kernel.",
      "GPT_function": "\n1. Modifies the report descriptor for a Cherry Cymotion device.\n2. Checks if the report descriptor size is at least 17 bytes.\n3. Updates specific bytes in the report descriptor if certain conditions are met.",
      "CVE_id": "CVE-2014-3184",
      "code_before_change": "static __u8 *ch_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 17 && rdesc[11] == 0x3c && rdesc[12] == 0x02) {\n\t\thid_info(hdev, \"fixing up Cherry Cymotion report descriptor\\n\");\n\t\trdesc[11] = rdesc[16] = 0xff;\n\t\trdesc[12] = rdesc[17] = 0x03;\n\t}\n\treturn rdesc;\n}",
      "code_after_change": "static __u8 *ch_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 18 && rdesc[11] == 0x3c && rdesc[12] == 0x02) {\n\t\thid_info(hdev, \"fixing up Cherry Cymotion report descriptor\\n\");\n\t\trdesc[11] = rdesc[16] = 0xff;\n\t\trdesc[12] = rdesc[17] = 0x03;\n\t}\n\treturn rdesc;\n}",
      "modified_lines": {
        "added": [
          "\tif (*rsize >= 18 && rdesc[11] == 0x3c && rdesc[12] == 0x02) {"
        ],
        "deleted": [
          "\tif (*rsize >= 17 && rdesc[11] == 0x3c && rdesc[12] == 0x02) {"
        ]
      },
      "preconditions_for_vulnerability": "Inadequate validation of the size of the report descriptor buffer.",
      "trigger_condition": "A physically proximate attacker provides a crafted device with a small report descriptor, leading to an out-of-bounds write vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check the size of the report descriptor buffer before attempting to write values to specific indices. This lack of validation allows an attacker to trigger an out-of-bounds write by providing a small report descriptor that overflows the buffer.",
      "id": 56,
      "code_after_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 18 && VAR2[11] == VAR4 && VAR2[12] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[11] = VAR2[16] = VAR4;\nVAR2[12] = VAR2[17] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_before_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 17 && VAR2[11] == VAR4 && VAR2[12] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[11] = VAR2[16] = VAR4;\nVAR2[12] = VAR2[17] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_after_change_raw": "static __u8 *ch_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 18 && rdesc[11] == 0x3c && rdesc[12] == 0x02) {\nhid_info(hdev, \"fixing up Cherry Cymotion report descriptor\\n\");\nrdesc[11] = rdesc[16] = 0xff;\nrdesc[12] = rdesc[17] = 0x03;\n}\nreturn rdesc;\n}\n",
      "code_before_change_raw": "static __u8 *ch_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 17 && rdesc[11] == 0x3c && rdesc[12] == 0x02) {\nhid_info(hdev, \"fixing up Cherry Cymotion report descriptor\\n\");\nrdesc[11] = rdesc[16] = 0xff;\nrdesc[12] = rdesc[17] = 0x03;\n}\nreturn rdesc;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Inadequate bounds checking in the report_fixup function of the HID subsystem in the Linux kernel before version 3.16.2.",
        "trigger_condition": "A crafted device with a small report descriptor triggers an out-of-bounds write vulnerability when processed by the vulnerable code.",
        "specific_code_behavior_causing_vulnerability": "The code incorrectly checks the size of the report descriptor and accesses an out-of-bounds index without proper validation, leading to a denial of service vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper bounds checking before accessing elements in the report descriptor. Specifically, the code should validate that the descriptor size is sufficient before attempting to access specific indices. In this case, the solution involves modifying the condition to check if the descriptor size is at least 31 bytes before accessing index 30, thereby preventing the out-of-bounds write vulnerability.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2014-3184, which involves an out-of-bounds write issue in the report_fixup functions of the HID subsystem in the Linux kernel before version 3.16.2. \n\nIn the original code snippet provided, the condition `if (*rsize >= 30 && rdesc[29] == 0x05 && rdesc[30] == 0x09)` checks if the size of the report descriptor is at least 30 bytes and if specific values are present at index 29 and 30 in the descriptor. However, the vulnerability arises because the check `rdesc[30] == 0x09` is incorrect. It should be `*rsize >= 31` to ensure that there are at least 31 bytes in the descriptor before accessing index 30.\n\nBy modifying the condition to `if (*rsize >= 31 && rdesc[29] == 0x05 && rdesc[30] == 0x09)`, we ensure that the code does not attempt to access an out-of-bounds index in the report descriptor, thus preventing the potential denial of service caused by the out-of-bounds write vulnerability.",
      "GPT_purpose": "To fix up a button/consumer in the HID report descriptor by changing a specific byte if certain conditions are met.",
      "GPT_function": "\n1. Modifies a specific byte in the HID report descriptor if certain conditions are met.",
      "CVE_id": "CVE-2014-3184",
      "code_before_change": "static __u8 *mr_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 30 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\n\t\thid_info(hdev, \"fixing up button/consumer in HID report descriptor\\n\");\n\t\trdesc[30] = 0x0c;\n\t}\n\treturn rdesc;\n}",
      "code_after_change": "static __u8 *mr_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 31 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\n\t\thid_info(hdev, \"fixing up button/consumer in HID report descriptor\\n\");\n\t\trdesc[30] = 0x0c;\n\t}\n\treturn rdesc;\n}",
      "modified_lines": {
        "added": [
          "\tif (*rsize >= 31 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {"
        ],
        "deleted": [
          "\tif (*rsize >= 30 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {"
        ]
      },
      "preconditions_for_vulnerability": "Inadequate bounds checking in the report_fixup function of the HID subsystem in the Linux kernel before version 3.16.2.",
      "trigger_condition": "A crafted device with a small report descriptor triggers an out-of-bounds write vulnerability when processed by the vulnerable code.",
      "specific_code_behavior_causing_vulnerability": "The code incorrectly checks the size of the report descriptor and accesses an out-of-bounds index without proper validation, leading to a denial of service vulnerability.",
      "id": 57,
      "code_after_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 31 && VAR2[29] == VAR4 && VAR2[30] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[30] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_before_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 30 && VAR2[29] == VAR4 && VAR2[30] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[30] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_after_change_raw": "static __u8 *mr_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 31 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\nhid_info(hdev, \"fixing up button/consumer in HID report descriptor\\n\");\nrdesc[30] = 0x0c;\n}\nreturn rdesc;\n}\n",
      "code_before_change_raw": "static __u8 *mr_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 30 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\nhid_info(hdev, \"fixing up button/consumer in HID report descriptor\\n\");\nrdesc[30] = 0x0c;\n}\nreturn rdesc;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper array bounds checking in the report_fixup function within the HID subsystem of the Linux kernel.",
        "trigger_condition": "A physically proximate attacker provides a small report descriptor from a crafted device, causing an out-of-bounds write vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not verify that the array has enough elements before accessing specific indexes, leading to an out-of-bounds write vulnerability when attempting to modify elements at indexes 60 and 61 without proper bounds checking."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the array has sufficient elements before accessing specific indexes to prevent out-of-bounds writes. In this case, the solution involves updating the condition in the code to check if the array size is greater than or equal to 62 before accessing elements at indexes 60 and 61. This modification adds the necessary bounds checking to prevent the out-of-bounds write vulnerability.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2014-3184, which involves an out-of-bounds write issue in the report_fixup function within the HID subsystem of the Linux kernel. By changing the condition from `*rsize >= 60` to `*rsize >= 62`, the code ensures that there are enough elements in the `rdesc` array to safely access the elements at indexes 60 and 61 without going out of bounds.\n\nIn the vulnerable code snippet, the condition `rdesc[60] == 0xf9 && rdesc[61] == 0x00` is used to check specific values at indexes 60 and 61 of the `rdesc` array. However, if the size of the array is less than 62 (i.e., `*rsize < 62`), accessing elements at indexes 60 and 61 would lead to an out-of-bounds write vulnerability.\n\nBy updating the condition to `*rsize >= 62`, the code ensures that the array has at least 62 elements before attempting to access elements at indexes 60 and 61. This modification helps prevent the out-of-bounds write vulnerability and enhances the security of the code.",
      "GPT_purpose": "This function is used to fix a specific issue in the report descriptor for a Petalynx Maxter Remote device by modifying certain values in the descriptor.",
      "GPT_function": "\n1. Fixing up Petalynx Maxter Remote report descriptor\n2. Modifying specific values in the report descriptor if certain conditions are met",
      "CVE_id": "CVE-2014-3184",
      "code_before_change": "static __u8 *pl_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 60 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\n\t\t\trdesc[41] == 0x00 && rdesc[59] == 0x26 &&\n\t\t\trdesc[60] == 0xf9 && rdesc[61] == 0x00) {\n\t\thid_info(hdev, \"fixing up Petalynx Maxter Remote report descriptor\\n\");\n\t\trdesc[60] = 0xfa;\n\t\trdesc[40] = 0xfa;\n\t}\n\treturn rdesc;\n}",
      "code_after_change": "static __u8 *pl_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 62 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\n\t\t\trdesc[41] == 0x00 && rdesc[59] == 0x26 &&\n\t\t\trdesc[60] == 0xf9 && rdesc[61] == 0x00) {\n\t\thid_info(hdev, \"fixing up Petalynx Maxter Remote report descriptor\\n\");\n\t\trdesc[60] = 0xfa;\n\t\trdesc[40] = 0xfa;\n\t}\n\treturn rdesc;\n}",
      "modified_lines": {
        "added": [
          "\tif (*rsize >= 62 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&"
        ],
        "deleted": [
          "\tif (*rsize >= 60 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper array bounds checking in the report_fixup function within the HID subsystem of the Linux kernel.",
      "trigger_condition": "A physically proximate attacker provides a small report descriptor from a crafted device, causing an out-of-bounds write vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not verify that the array has enough elements before accessing specific indexes, leading to an out-of-bounds write vulnerability when attempting to modify elements at indexes 60 and 61 without proper bounds checking.",
      "id": 58,
      "code_after_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 62 && VAR2[39] == VAR4 && VAR2[40] == VAR4 &&\nVAR2[41] == VAR4 && VAR2[59] == VAR4 &&\nVAR2[60] == VAR4 && VAR2[61] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[60] = VAR4;\nVAR2[40] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_before_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 60 && VAR2[39] == VAR4 && VAR2[40] == VAR4 &&\nVAR2[41] == VAR4 && VAR2[59] == VAR4 &&\nVAR2[60] == VAR4 && VAR2[61] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[60] = VAR4;\nVAR2[40] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_after_change_raw": "static __u8 *pl_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 62 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\nrdesc[41] == 0x00 && rdesc[59] == 0x26 &&\nrdesc[60] == 0xf9 && rdesc[61] == 0x00) {\nhid_info(hdev, \"fixing up Petalynx Maxter Remote report descriptor\\n\");\nrdesc[60] = 0xfa;\nrdesc[40] = 0xfa;\n}\nreturn rdesc;\n}\n",
      "code_before_change_raw": "static __u8 *pl_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 60 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\nrdesc[41] == 0x00 && rdesc[59] == 0x26 &&\nrdesc[60] == 0xf9 && rdesc[61] == 0x00) {\nhid_info(hdev, \"fixing up Petalynx Maxter Remote report descriptor\\n\");\nrdesc[60] = 0xfa;\nrdesc[40] = 0xfa;\n}\nreturn rdesc;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Inadequate bounds checking in the report_fixup function of the HID subsystem.",
        "trigger_condition": "A crafted device provides a small report descriptor, causing the code to attempt an out-of-bounds write operation.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check the size of the array before accessing and modifying elements at specific indexes, leading to an out-of-bounds write vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to enhance bounds checking in the report_fixup function by ensuring that the array size is sufficient before attempting to access and modify elements. In this case, the solution involves modifying the code to check for a minimum size of 112 before accessing indexes 110 and 111, thereby preventing the out-of-bounds write issue.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2014-3184, which involves an out-of-bounds write issue in the report_fixup functions of the HID subsystem in the Linux kernel. By changing the condition from `*rsize >= 107` to `*rsize >= 112`, the code ensures that there are enough elements in the `rdesc` array to safely access and modify elements at indexes 110 and 111.\n\nThe vulnerability arises when a crafted device provides a small report descriptor, causing the code to attempt to write values beyond the bounds of the `rdesc` array. This can lead to a denial of service due to the out-of-bounds write.\n\nBy modifying the code to check for a minimum size of 112 before accessing indexes 110 and 111, the vulnerability is mitigated, and the code is made more secure by preventing the out-of-bounds write issue.",
      "GPT_purpose": "Fixing up Sunplus Wireless Desktop report descriptor by modifying specific bytes in the report descriptor.",
      "GPT_function": "\n1. Fixes up the Sunplus Wireless Desktop report descriptor by changing specific values at certain positions.",
      "CVE_id": "CVE-2014-3184",
      "code_before_change": "static __u8 *sp_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 107 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\n\t\t\trdesc[106] == 0x03) {\n\t\thid_info(hdev, \"fixing up Sunplus Wireless Desktop report descriptor\\n\");\n\t\trdesc[105] = rdesc[110] = 0x03;\n\t\trdesc[106] = rdesc[111] = 0x21;\n\t}\n\treturn rdesc;\n}",
      "code_after_change": "static __u8 *sp_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 112 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\n\t\t\trdesc[106] == 0x03) {\n\t\thid_info(hdev, \"fixing up Sunplus Wireless Desktop report descriptor\\n\");\n\t\trdesc[105] = rdesc[110] = 0x03;\n\t\trdesc[106] = rdesc[111] = 0x21;\n\t}\n\treturn rdesc;\n}",
      "modified_lines": {
        "added": [
          "\tif (*rsize >= 112 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&"
        ],
        "deleted": [
          "\tif (*rsize >= 107 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&"
        ]
      },
      "preconditions_for_vulnerability": "Inadequate bounds checking in the report_fixup function of the HID subsystem.",
      "trigger_condition": "A crafted device provides a small report descriptor, causing the code to attempt an out-of-bounds write operation.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check the size of the array before accessing and modifying elements at specific indexes, leading to an out-of-bounds write vulnerability.",
      "id": 59,
      "code_after_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 112 && VAR2[104] == VAR4 && VAR2[105] == VAR4 &&\nVAR2[106] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[105] = VAR2[110] = VAR4;\nVAR2[106] = VAR2[111] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_before_change_normalized": "static __u8 *FUN1(struct hid_device *VAR1, __u8 *VAR2,\nunsigned int *VAR3)\n{\nif (*VAR3 >= 107 && VAR2[104] == VAR4 && VAR2[105] == VAR4 &&\nVAR2[106] == VAR4) {\nFUN2(VAR1, \"STR\");\nVAR2[105] = VAR2[110] = VAR4;\nVAR2[106] = VAR2[111] = VAR4;\n}\nreturn VAR2;\n}\n",
      "code_after_change_raw": "static __u8 *sp_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 112 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\nrdesc[106] == 0x03) {\nhid_info(hdev, \"fixing up Sunplus Wireless Desktop report descriptor\\n\");\nrdesc[105] = rdesc[110] = 0x03;\nrdesc[106] = rdesc[111] = 0x21;\n}\nreturn rdesc;\n}\n",
      "code_before_change_raw": "static __u8 *sp_report_fixup(struct hid_device *hdev, __u8 *rdesc,\nunsigned int *rsize)\n{\nif (*rsize >= 107 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\nrdesc[106] == 0x03) {\nhid_info(hdev, \"fixing up Sunplus Wireless Desktop report descriptor\\n\");\nrdesc[105] = rdesc[110] = 0x03;\nrdesc[106] = rdesc[111] = 0x21;\n}\nreturn rdesc;\n}\n"
    }
  ],
  "CVE-2014-3185": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper bounds checking and handling of response data in the command_port_read_callback function.",
        "trigger_condition": "Receiving a large amount of data associated with a bulk response from a crafted device, leading to buffer overflows and memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code does not check for empty response data or verify the size of the data being copied into a buffer, allowing potential buffer overflows and memory corruption to occur."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add checks for empty response data and ensure that the size of the data being copied into buffers does not exceed the buffer size. This involves adding conditions to handle empty responses and verifying the length of data being copied to prevent buffer overflows. By implementing these checks, the code becomes more resilient against buffer overflow vulnerabilities and reduces the risk of memory corruption and system crashes.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2014-3185, which involves buffer overflows in the `command_port_read_callback` function. By making the following changes in the code:\n\n1. Checking for `!urb->actual_length` to handle empty responses: This check ensures that the response data is not empty before processing it. This helps prevent potential buffer overflows that could occur if the response data is unexpectedly empty.\n\n2. Adding a check for the size of `command_info->result_buffer`: By verifying that the length of the data being copied into `command_info->result_buffer` does not exceed the size of the buffer, we prevent buffer overflows that could lead to memory corruption and potentially allow an attacker to execute arbitrary code.\n\nThese modifications help mitigate the risk of memory corruption and system crashes that could be caused by a crafted device providing a large amount of data associated with a bulk response, as described in the vulnerability. By ensuring proper bounds checking and handling of response data, the code becomes more resilient against potential exploitation of buffer overflow vulnerabilities.",
      "GPT_purpose": "Handle read callbacks for the Whiteheat USB Serial Driver, processing received data and waking up waiting commands.",
      "GPT_function": "\n1. Handle read callback for a USB serial port.\n2. Check and process the received data.\n3. Resubmit the URB for continuous reading.",
      "CVE_id": "CVE-2014-3185",
      "code_before_change": "static void command_port_read_callback(struct urb *urb)\n{\n\tstruct usb_serial_port *command_port = urb->context;\n\tstruct whiteheat_command_private *command_info;\n\tint status = urb->status;\n\tunsigned char *data = urb->transfer_buffer;\n\tint result;\n\n\tcommand_info = usb_get_serial_port_data(command_port);\n\tif (!command_info) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - command_info is NULL, exiting.\\n\", __func__);\n\t\treturn;\n\t}\n\tif (status) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - nonzero urb status: %d\\n\", __func__, status);\n\t\tif (status != -ENOENT)\n\t\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t\treturn;\n\t}\n\n\tusb_serial_debug_data(&command_port->dev, __func__, urb->actual_length, data);\n\n\tif (data[0] == WHITEHEAT_CMD_COMPLETE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_CMD_FAILURE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_EVENT) {\n\t\t/* These are unsolicited reports from the firmware, hence no\n\t\t   waiting command to wakeup */\n\t\tdev_dbg(&urb->dev->dev, \"%s - event received\\n\", __func__);\n\t} else if (data[0] == WHITEHEAT_GET_DTR_RTS) {\n\t\tmemcpy(command_info->result_buffer, &data[1],\n\t\t\t\t\t\turb->actual_length - 1);\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else\n\t\tdev_dbg(&urb->dev->dev, \"%s - bad reply from firmware\\n\", __func__);\n\n\t/* Continue trying to always read */\n\tresult = usb_submit_urb(command_port->read_urb, GFP_ATOMIC);\n\tif (result)\n\t\tdev_dbg(&urb->dev->dev, \"%s - failed resubmitting read urb, error %d\\n\",\n\t\t\t__func__, result);\n}",
      "code_after_change": "static void command_port_read_callback(struct urb *urb)\n{\n\tstruct usb_serial_port *command_port = urb->context;\n\tstruct whiteheat_command_private *command_info;\n\tint status = urb->status;\n\tunsigned char *data = urb->transfer_buffer;\n\tint result;\n\n\tcommand_info = usb_get_serial_port_data(command_port);\n\tif (!command_info) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - command_info is NULL, exiting.\\n\", __func__);\n\t\treturn;\n\t}\n\tif (!urb->actual_length) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - empty response, exiting.\\n\", __func__);\n\t\treturn;\n\t}\n\tif (status) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - nonzero urb status: %d\\n\", __func__, status);\n\t\tif (status != -ENOENT)\n\t\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t\treturn;\n\t}\n\n\tusb_serial_debug_data(&command_port->dev, __func__, urb->actual_length, data);\n\n\tif (data[0] == WHITEHEAT_CMD_COMPLETE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_CMD_FAILURE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_EVENT) {\n\t\t/* These are unsolicited reports from the firmware, hence no\n\t\t   waiting command to wakeup */\n\t\tdev_dbg(&urb->dev->dev, \"%s - event received\\n\", __func__);\n\t} else if ((data[0] == WHITEHEAT_GET_DTR_RTS) &&\n\t\t(urb->actual_length - 1 <= sizeof(command_info->result_buffer))) {\n\t\tmemcpy(command_info->result_buffer, &data[1],\n\t\t\t\t\t\turb->actual_length - 1);\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else\n\t\tdev_dbg(&urb->dev->dev, \"%s - bad reply from firmware\\n\", __func__);\n\n\t/* Continue trying to always read */\n\tresult = usb_submit_urb(command_port->read_urb, GFP_ATOMIC);\n\tif (result)\n\t\tdev_dbg(&urb->dev->dev, \"%s - failed resubmitting read urb, error %d\\n\",\n\t\t\t__func__, result);\n}",
      "modified_lines": {
        "added": [
          "\t\treturn;",
          "\t}",
          "\tif (!urb->actual_length) {",
          "\t\tdev_dbg(&urb->dev->dev, \"%s - empty response, exiting.\\n\", __func__);",
          "\t} else if ((data[0] == WHITEHEAT_GET_DTR_RTS) &&",
          "\t\t(urb->actual_length - 1 <= sizeof(command_info->result_buffer))) {"
        ],
        "deleted": [
          "\t} else if (data[0] == WHITEHEAT_GET_DTR_RTS) {"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper bounds checking and handling of response data in the command_port_read_callback function.",
      "trigger_condition": "Receiving a large amount of data associated with a bulk response from a crafted device, leading to buffer overflows and memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code does not check for empty response data or verify the size of the data being copied into a buffer, allowing potential buffer overflows and memory corruption to occur.",
      "id": 60,
      "code_after_change_normalized": "static void FUN1(struct VAR1 *VAR1)\n{\nstruct usb_serial_port *VAR2 = VAR1->VAR3;\nstruct whiteheat_command_private *VAR4;\nint VAR5 = VAR1->VAR5;\nunsigned char *VAR6 = VAR1->VAR7;\nint VAR8;\nVAR4 = FUN2(VAR2);\nif (!VAR4) {\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10);\nreturn;\n}\nif (!VAR1->VAR11) {\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10);\nreturn;\n}\nif (VAR5) {\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10, VAR5);\nif (VAR5 != -VAR12)\nVAR4->VAR13 = VAR14;\nFUN4(&VAR4->VAR15);\nreturn;\n}\nFUN5(&VAR2->VAR9, VAR10, VAR1->VAR11, VAR6);\nif (VAR6[0] == VAR16) {\nVAR4->VAR13 = VAR16;\nFUN4(&VAR4->VAR15);\n} else if (VAR6[0] == VAR14) {\nVAR4->VAR13 = VAR14;\nFUN4(&VAR4->VAR15);\n} else if (VAR6[0] == VAR17) {\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10);\n} else if ((VAR6[0] == VAR18) &&\n(VAR1->VAR11 - 1 <= sizeof(VAR4->VAR19))) {\nFUN6(VAR4->VAR19, &VAR6[1],\nVAR1->VAR11 - 1);\nVAR4->VAR13 = VAR16;\nFUN4(&VAR4->VAR15);\n} else\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10);\nVAR8 = FUN7(VAR2->VAR20, VAR21);\nif (VAR8)\nFUN3(&VAR1->VAR9->VAR9, \"STR\",\nVAR10, VAR8);\n}\n",
      "code_before_change_normalized": "static void FUN1(struct VAR1 *VAR1)\n{\nstruct usb_serial_port *VAR2 = VAR1->VAR3;\nstruct whiteheat_command_private *VAR4;\nint VAR5 = VAR1->VAR5;\nunsigned char *VAR6 = VAR1->VAR7;\nint VAR8;\nVAR4 = FUN2(VAR2);\nif (!VAR4) {\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10);\nreturn;\n}\nif (VAR5) {\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10, VAR5);\nif (VAR5 != -VAR11)\nVAR4->VAR12 = VAR13;\nFUN4(&VAR4->VAR14);\nreturn;\n}\nFUN5(&VAR2->VAR9, VAR10, VAR1->VAR15, VAR6);\nif (VAR6[0] == VAR16) {\nVAR4->VAR12 = VAR16;\nFUN4(&VAR4->VAR14);\n} else if (VAR6[0] == VAR13) {\nVAR4->VAR12 = VAR13;\nFUN4(&VAR4->VAR14);\n} else if (VAR6[0] == VAR17) {\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10);\n} else if (VAR6[0] == VAR18) {\nFUN6(VAR4->VAR19, &VAR6[1],\nVAR1->VAR15 - 1);\nVAR4->VAR12 = VAR16;\nFUN4(&VAR4->VAR14);\n} else\nFUN3(&VAR1->VAR9->VAR9, \"STR\", VAR10);\nVAR8 = FUN7(VAR2->VAR20, VAR21);\nif (VAR8)\nFUN3(&VAR1->VAR9->VAR9, \"STR\",\nVAR10, VAR8);\n}\n",
      "code_after_change_raw": "static void command_port_read_callback(struct urb *urb)\n{\nstruct usb_serial_port *command_port = urb->context;\nstruct whiteheat_command_private *command_info;\nint status = urb->status;\nunsigned char *data = urb->transfer_buffer;\nint result;\ncommand_info = usb_get_serial_port_data(command_port);\nif (!command_info) {\ndev_dbg(&urb->dev->dev, \"%s - command_info is NULL, exiting.\\n\", __func__);\nreturn;\n}\nif (!urb->actual_length) {\ndev_dbg(&urb->dev->dev, \"%s - empty response, exiting.\\n\", __func__);\nreturn;\n}\nif (status) {\ndev_dbg(&urb->dev->dev, \"%s - nonzero urb status: %d\\n\", __func__, status);\nif (status != -ENOENT)\ncommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\nwake_up(&command_info->wait_command);\nreturn;\n}\nusb_serial_debug_data(&command_port->dev, __func__, urb->actual_length, data);\nif (data[0] == WHITEHEAT_CMD_COMPLETE) {\ncommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\nwake_up(&command_info->wait_command);\n} else if (data[0] == WHITEHEAT_CMD_FAILURE) {\ncommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\nwake_up(&command_info->wait_command);\n} else if (data[0] == WHITEHEAT_EVENT) {\ndev_dbg(&urb->dev->dev, \"%s - event received\\n\", __func__);\n} else if ((data[0] == WHITEHEAT_GET_DTR_RTS) &&\n(urb->actual_length - 1 <= sizeof(command_info->result_buffer))) {\nmemcpy(command_info->result_buffer, &data[1],\nurb->actual_length - 1);\ncommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\nwake_up(&command_info->wait_command);\n} else\ndev_dbg(&urb->dev->dev, \"%s - bad reply from firmware\\n\", __func__);\nresult = usb_submit_urb(command_port->read_urb, GFP_ATOMIC);\nif (result)\ndev_dbg(&urb->dev->dev, \"%s - failed resubmitting read urb, error %d\\n\",\n__func__, result);\n}\n",
      "code_before_change_raw": "static void command_port_read_callback(struct urb *urb)\n{\nstruct usb_serial_port *command_port = urb->context;\nstruct whiteheat_command_private *command_info;\nint status = urb->status;\nunsigned char *data = urb->transfer_buffer;\nint result;\ncommand_info = usb_get_serial_port_data(command_port);\nif (!command_info) {\ndev_dbg(&urb->dev->dev, \"%s - command_info is NULL, exiting.\\n\", __func__);\nreturn;\n}\nif (status) {\ndev_dbg(&urb->dev->dev, \"%s - nonzero urb status: %d\\n\", __func__, status);\nif (status != -ENOENT)\ncommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\nwake_up(&command_info->wait_command);\nreturn;\n}\nusb_serial_debug_data(&command_port->dev, __func__, urb->actual_length, data);\nif (data[0] == WHITEHEAT_CMD_COMPLETE) {\ncommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\nwake_up(&command_info->wait_command);\n} else if (data[0] == WHITEHEAT_CMD_FAILURE) {\ncommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\nwake_up(&command_info->wait_command);\n} else if (data[0] == WHITEHEAT_EVENT) {\ndev_dbg(&urb->dev->dev, \"%s - event received\\n\", __func__);\n} else if (data[0] == WHITEHEAT_GET_DTR_RTS) {\nmemcpy(command_info->result_buffer, &data[1],\nurb->actual_length - 1);\ncommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\nwake_up(&command_info->wait_command);\n} else\ndev_dbg(&urb->dev->dev, \"%s - bad reply from firmware\\n\", __func__);\nresult = usb_submit_urb(command_port->read_urb, GFP_ATOMIC);\nif (result)\ndev_dbg(&urb->dev->dev, \"%s - failed resubmitting read urb, error %d\\n\",\n__func__, result);\n}\n"
    }
  ],
  "CVE-2014-3186": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of size validation for input data in the picolcd_raw_event function, allowing for the processing of large reports without proper bounds checking.",
        "trigger_condition": "A physically proximate attacker sends a crafted device that includes a large report to trigger a buffer overflow in the vulnerable code.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the size of the input data, leading to a buffer overflow vulnerability when processing reports larger than the expected size."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a size check to ensure that the input data does not exceed a safe limit. By validating the size of the input data and returning early if it exceeds the limit, the code prevents buffer overflow attacks that could lead to denial of service or arbitrary code execution. In this case, the solution involves adding a check for the input data size and returning 0 if the size exceeds a specified threshold.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2014-3186, which is a buffer overflow issue in the picolcd_raw_event function. The vulnerability allows physically proximate attackers to cause a denial of service (system crash) or potentially execute arbitrary code by sending a large report to the device.\n\nBy adding the check `if (size > 64)` and returning 0 if the size exceeds 64, the code ensures that the input data size is limited to a safe value. This prevents the buffer overflow vulnerability by restricting the amount of data that can be processed, thus mitigating the risk of a potential exploit.\n\nIn summary, the modification is necessary to prevent the buffer overflow vulnerability and enhance the security of the code handling the HID device driver.",
      "GPT_purpose": "Handle raw events from a PicoLCD HID device, including processing key state reports and infrared data, and forwarding other reports to be checked by the caller of picolcd_send_and_wait().",
      "GPT_function": "\n1. Handle raw events for the PicoLCD device.\n2. Process key state reports for input keys.\n3. Process IR data reports.\n4. Copy raw data to pending structure if a report is pending.\n5. Debug and log raw events.",
      "CVE_id": "CVE-2014-3186",
      "code_before_change": "static int picolcd_raw_event(struct hid_device *hdev,\n\t\tstruct hid_report *report, u8 *raw_data, int size)\n{\n\tstruct picolcd_data *data = hid_get_drvdata(hdev);\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (!data)\n\t\treturn 1;\n\n\tif (report->id == REPORT_KEY_STATE) {\n\t\tif (data->input_keys)\n\t\t\tret = picolcd_raw_keypad(data, report, raw_data+1, size-1);\n\t} else if (report->id == REPORT_IR_DATA) {\n\t\tret = picolcd_raw_cir(data, report, raw_data+1, size-1);\n\t} else {\n\t\tspin_lock_irqsave(&data->lock, flags);\n\t\t/*\n\t\t * We let the caller of picolcd_send_and_wait() check if the\n\t\t * report we got is one of the expected ones or not.\n\t\t */\n\t\tif (data->pending) {\n\t\t\tmemcpy(data->pending->raw_data, raw_data+1, size-1);\n\t\t\tdata->pending->raw_size  = size-1;\n\t\t\tdata->pending->in_report = report;\n\t\t\tcomplete(&data->pending->ready);\n\t\t}\n\t\tspin_unlock_irqrestore(&data->lock, flags);\n\t}\n\n\tpicolcd_debug_raw_event(data, hdev, report, raw_data, size);\n\treturn 1;\n}",
      "code_after_change": "static int picolcd_raw_event(struct hid_device *hdev,\n\t\tstruct hid_report *report, u8 *raw_data, int size)\n{\n\tstruct picolcd_data *data = hid_get_drvdata(hdev);\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (!data)\n\t\treturn 1;\n\n\tif (size > 64) {\n\t\thid_warn(hdev, \"invalid size value (%d) for picolcd raw event\\n\",\n\t\t\t\tsize);\n\t\treturn 0;\n\t}\n\n\tif (report->id == REPORT_KEY_STATE) {\n\t\tif (data->input_keys)\n\t\t\tret = picolcd_raw_keypad(data, report, raw_data+1, size-1);\n\t} else if (report->id == REPORT_IR_DATA) {\n\t\tret = picolcd_raw_cir(data, report, raw_data+1, size-1);\n\t} else {\n\t\tspin_lock_irqsave(&data->lock, flags);\n\t\t/*\n\t\t * We let the caller of picolcd_send_and_wait() check if the\n\t\t * report we got is one of the expected ones or not.\n\t\t */\n\t\tif (data->pending) {\n\t\t\tmemcpy(data->pending->raw_data, raw_data+1, size-1);\n\t\t\tdata->pending->raw_size  = size-1;\n\t\t\tdata->pending->in_report = report;\n\t\t\tcomplete(&data->pending->ready);\n\t\t}\n\t\tspin_unlock_irqrestore(&data->lock, flags);\n\t}\n\n\tpicolcd_debug_raw_event(data, hdev, report, raw_data, size);\n\treturn 1;\n}",
      "modified_lines": {
        "added": [
          "",
          "\tif (size > 64) {",
          "\t\thid_warn(hdev, \"invalid size value (%d) for picolcd raw event\\n\",",
          "\t\t\t\tsize);",
          "\t\treturn 0;",
          "\t}"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of size validation for input data in the picolcd_raw_event function, allowing for the processing of large reports without proper bounds checking.",
      "trigger_condition": "A physically proximate attacker sends a crafted device that includes a large report to trigger a buffer overflow in the vulnerable code.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the size of the input data, leading to a buffer overflow vulnerability when processing reports larger than the expected size.",
      "id": 61,
      "code_after_change_normalized": "static int FUN1(struct hid_device *VAR1,\nstruct hid_report *VAR2, u8 *VAR3, int VAR4)\n{\nstruct picolcd_data *VAR5 = FUN2(VAR1);\nunsigned long VAR6;\nint VAR7 = 0;\nif (!VAR5)\nreturn 1;\nif (VAR4 > 64) {\nFUN3(VAR1, \"STR\",\nVAR4);\nreturn 0;\n}\nif (VAR2->VAR8 == VAR9) {\nif (VAR5->VAR10)\nVAR7 = FUN4(VAR5, VAR2, VAR3+1, VAR4-1);\n} else if (VAR2->VAR8 == VAR11) {\nVAR7 = FUN5(VAR5, VAR2, VAR3+1, VAR4-1);\n} else {\nFUN6(&VAR5->VAR12, VAR6);\nif (VAR5->VAR13) {\nFUN7(VAR5->VAR13->VAR3, VAR3+1, VAR4-1);\nVAR5->VAR13->VAR14  = VAR4-1;\nVAR5->VAR13->VAR15 = VAR2;\nFUN8(&VAR5->VAR13->VAR16);\n}\nFUN9(&VAR5->VAR12, VAR6);\n}\nFUN10(VAR5, VAR1, VAR2, VAR3, VAR4);\nreturn 1;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct hid_device *VAR1,\nstruct hid_report *VAR2, u8 *VAR3, int VAR4)\n{\nstruct picolcd_data *VAR5 = FUN2(VAR1);\nunsigned long VAR6;\nint VAR7 = 0;\nif (!VAR5)\nreturn 1;\nif (VAR2->VAR8 == VAR9) {\nif (VAR5->VAR10)\nVAR7 = FUN3(VAR5, VAR2, VAR3+1, VAR4-1);\n} else if (VAR2->VAR8 == VAR11) {\nVAR7 = FUN4(VAR5, VAR2, VAR3+1, VAR4-1);\n} else {\nFUN5(&VAR5->VAR12, VAR6);\nif (VAR5->VAR13) {\nFUN6(VAR5->VAR13->VAR3, VAR3+1, VAR4-1);\nVAR5->VAR13->VAR14  = VAR4-1;\nVAR5->VAR13->VAR15 = VAR2;\nFUN7(&VAR5->VAR13->VAR16);\n}\nFUN8(&VAR5->VAR12, VAR6);\n}\nFUN9(VAR5, VAR1, VAR2, VAR3, VAR4);\nreturn 1;\n}\n",
      "code_after_change_raw": "static int picolcd_raw_event(struct hid_device *hdev,\nstruct hid_report *report, u8 *raw_data, int size)\n{\nstruct picolcd_data *data = hid_get_drvdata(hdev);\nunsigned long flags;\nint ret = 0;\nif (!data)\nreturn 1;\nif (size > 64) {\nhid_warn(hdev, \"invalid size value (%d) for picolcd raw event\\n\",\nsize);\nreturn 0;\n}\nif (report->id == REPORT_KEY_STATE) {\nif (data->input_keys)\nret = picolcd_raw_keypad(data, report, raw_data+1, size-1);\n} else if (report->id == REPORT_IR_DATA) {\nret = picolcd_raw_cir(data, report, raw_data+1, size-1);\n} else {\nspin_lock_irqsave(&data->lock, flags);\nif (data->pending) {\nmemcpy(data->pending->raw_data, raw_data+1, size-1);\ndata->pending->raw_size  = size-1;\ndata->pending->in_report = report;\ncomplete(&data->pending->ready);\n}\nspin_unlock_irqrestore(&data->lock, flags);\n}\npicolcd_debug_raw_event(data, hdev, report, raw_data, size);\nreturn 1;\n}\n",
      "code_before_change_raw": "static int picolcd_raw_event(struct hid_device *hdev,\nstruct hid_report *report, u8 *raw_data, int size)\n{\nstruct picolcd_data *data = hid_get_drvdata(hdev);\nunsigned long flags;\nint ret = 0;\nif (!data)\nreturn 1;\nif (report->id == REPORT_KEY_STATE) {\nif (data->input_keys)\nret = picolcd_raw_keypad(data, report, raw_data+1, size-1);\n} else if (report->id == REPORT_IR_DATA) {\nret = picolcd_raw_cir(data, report, raw_data+1, size-1);\n} else {\nspin_lock_irqsave(&data->lock, flags);\nif (data->pending) {\nmemcpy(data->pending->raw_data, raw_data+1, size-1);\ndata->pending->raw_size  = size-1;\ndata->pending->in_report = report;\ncomplete(&data->pending->ready);\n}\nspin_unlock_irqrestore(&data->lock, flags);\n}\npicolcd_debug_raw_event(data, hdev, report, raw_data, size);\nreturn 1;\n}\n"
    }
  ],
  "CVE-2014-6416": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation and handling of input data size in the ceph_x_verify_authorizer_reply function.",
        "trigger_condition": "Receiving a long unencrypted auth ticket can trigger a buffer overflow vulnerability in the code.",
        "specific_code_behavior_causing_vulnerability": "The code directly passes the reply structure as an argument to ceph_x_decrypt without ensuring that the input data size is properly validated, leading to a potential buffer overflow vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the input data size is properly validated before passing the reply structure to ceph_x_decrypt. The solution involves modifying the code to pass the address of the reply structure as an argument to ceph_x_decrypt instead of passing the structure itself. This change helps prevent buffer overflow by ensuring that the function operates on the correct memory location and size, enhancing the security of the code.",
      "GPT_analysis": "The modification in the code snippet is necessary to prevent a buffer overflow vulnerability (CVE-2014-6416) in the Ceph code. The vulnerability arises from the use of the `reply` structure directly as an argument to `ceph_x_decrypt`, which can lead to memory corruption and potentially a denial of service or other impacts when processing a long unencrypted auth ticket.\n\nBy modifying the code to pass the address of the `reply` structure (`&reply`) as an argument to `ceph_x_decrypt` instead of passing the structure itself, the potential buffer overflow vulnerability is mitigated. This change ensures that the function `ceph_x_decrypt` operates on the correct memory location and size, preventing the possibility of writing beyond the boundaries of the `reply` structure and causing memory corruption.\n\nIn summary, the modification ensures that the `reply` structure is passed correctly to `ceph_x_decrypt`, addressing the vulnerability and enhancing the security of the code.",
      "GPT_purpose": "Verify the authorizer reply by decrypting and checking the nonce value.",
      "GPT_function": "\n1. Verify the authorizer reply by decrypting the received data.\n2. Check if the nonce in the reply matches the expected nonce.\n3. Return the result of the verification process.",
      "CVE_id": "CVE-2014-6416",
      "code_before_change": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\n\t\t\t\t\t  struct ceph_authorizer *a, size_t len)\n{\n\tstruct ceph_x_authorizer *au = (void *)a;\n\tstruct ceph_x_ticket_handler *th;\n\tint ret = 0;\n\tstruct ceph_x_authorize_reply reply;\n\tvoid *p = au->reply_buf;\n\tvoid *end = p + sizeof(au->reply_buf);\n\n\tth = get_ticket_handler(ac, au->service);\n\tif (IS_ERR(th))\n\t\treturn PTR_ERR(th);\n\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret != sizeof(reply))\n\t\treturn -EPERM;\n\n\tif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\n\t\tret = -EPERM;\n\telse\n\t\tret = 0;\n\tdout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\n\t     au->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\n\treturn ret;\n}",
      "code_after_change": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\n\t\t\t\t\t  struct ceph_authorizer *a, size_t len)\n{\n\tstruct ceph_x_authorizer *au = (void *)a;\n\tstruct ceph_x_ticket_handler *th;\n\tint ret = 0;\n\tstruct ceph_x_authorize_reply reply;\n\tvoid *preply = &reply;\n\tvoid *p = au->reply_buf;\n\tvoid *end = p + sizeof(au->reply_buf);\n\n\tth = get_ticket_handler(ac, au->service);\n\tif (IS_ERR(th))\n\t\treturn PTR_ERR(th);\n\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret != sizeof(reply))\n\t\treturn -EPERM;\n\n\tif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\n\t\tret = -EPERM;\n\telse\n\t\tret = 0;\n\tdout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\n\t     au->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tvoid *preply = &reply;",
          "\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));"
        ],
        "deleted": [
          "\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation and handling of input data size in the ceph_x_verify_authorizer_reply function.",
      "trigger_condition": "Receiving a long unencrypted auth ticket can trigger a buffer overflow vulnerability in the code.",
      "specific_code_behavior_causing_vulnerability": "The code directly passes the reply structure as an argument to ceph_x_decrypt without ensuring that the input data size is properly validated, leading to a potential buffer overflow vulnerability.",
      "id": 62,
      "code_after_change_normalized": "static int FUN1(struct ceph_auth_client *VAR1,\nstruct ceph_authorizer *VAR2, size_t VAR3)\n{\nstruct ceph_x_authorizer *VAR4 = (void *)VAR2;\nstruct ceph_x_ticket_handler *VAR5;\nint VAR6 = 0;\nstruct ceph_x_authorize_reply VAR7;\nvoid *VAR8 = &VAR7;\nvoid *VAR9 = VAR4->VAR10;\nvoid *VAR11 = VAR9 + sizeof(VAR4->VAR10);\nVAR5 = FUN2(VAR1, VAR4->VAR12);\nif (FUN3(VAR5))\nreturn FUN4(VAR5);\nVAR6 = FUN5(&VAR5->VAR13, &VAR9, VAR11, &VAR8, sizeof(VAR7));\nif (VAR6 < 0)\nreturn VAR6;\nif (VAR6 != sizeof(VAR7))\nreturn -VAR14;\nif (VAR4->VAR15 + 1 != FUN6(VAR7.VAR16))\nVAR6 = -VAR14;\nelse\nVAR6 = 0;\nFUN7(\"STR\",\nVAR4->VAR15, FUN6(VAR7.VAR16), VAR6);\nreturn VAR6;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct ceph_auth_client *VAR1,\nstruct ceph_authorizer *VAR2, size_t VAR3)\n{\nstruct ceph_x_authorizer *VAR4 = (void *)VAR2;\nstruct ceph_x_ticket_handler *VAR5;\nint VAR6 = 0;\nstruct ceph_x_authorize_reply VAR7;\nvoid *VAR8 = VAR4->VAR9;\nvoid *VAR10 = VAR8 + sizeof(VAR4->VAR9);\nVAR5 = FUN2(VAR1, VAR4->VAR11);\nif (FUN3(VAR5))\nreturn FUN4(VAR5);\nVAR6 = FUN5(&VAR5->VAR12, &VAR8, VAR10, &VAR7, sizeof(VAR7));\nif (VAR6 < 0)\nreturn VAR6;\nif (VAR6 != sizeof(VAR7))\nreturn -VAR13;\nif (VAR4->VAR14 + 1 != FUN6(VAR7.VAR15))\nVAR6 = -VAR13;\nelse\nVAR6 = 0;\nFUN7(\"STR\",\nVAR4->VAR14, FUN6(VAR7.VAR15), VAR6);\nreturn VAR6;\n}\n",
      "code_after_change_raw": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\nstruct ceph_authorizer *a, size_t len)\n{\nstruct ceph_x_authorizer *au = (void *)a;\nstruct ceph_x_ticket_handler *th;\nint ret = 0;\nstruct ceph_x_authorize_reply reply;\nvoid *preply = &reply;\nvoid *p = au->reply_buf;\nvoid *end = p + sizeof(au->reply_buf);\nth = get_ticket_handler(ac, au->service);\nif (IS_ERR(th))\nreturn PTR_ERR(th);\nret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));\nif (ret < 0)\nreturn ret;\nif (ret != sizeof(reply))\nreturn -EPERM;\nif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\nret = -EPERM;\nelse\nret = 0;\ndout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\nau->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\nstruct ceph_authorizer *a, size_t len)\n{\nstruct ceph_x_authorizer *au = (void *)a;\nstruct ceph_x_ticket_handler *th;\nint ret = 0;\nstruct ceph_x_authorize_reply reply;\nvoid *p = au->reply_buf;\nvoid *end = p + sizeof(au->reply_buf);\nth = get_ticket_handler(ac, au->service);\nif (IS_ERR(th))\nreturn PTR_ERR(th);\nret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));\nif (ret < 0)\nreturn ret;\nif (ret != sizeof(reply))\nreturn -EPERM;\nif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\nret = -EPERM;\nelse\nret = 0;\ndout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\nau->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2014-8369": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of accurate calculation of the number of pages during memory pinning and mapping process.",
        "trigger_condition": "A mapping failure occurs, leading to a miscalculation of the number of pages to unpin and unmap, potentially causing a denial of service or other unspecified impacts.",
        "specific_code_behavior_causing_vulnerability": "The code incorrectly calculates the page size to unpin and unmap memory pages, leading to potential issues when handling a mapping failure. This can result in incorrect calculations and impact the host OS page unpinning process."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure the correct number of pages is used when pinning and mapping memory pages. The solution involves adjusting the code to use 'page_size >> PAGE_SHIFT' when pinning and mapping pages, ensuring accurate calculations and preventing potential issues. This modification helps address the vulnerability and improves the security and reliability of the code.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2014-8369. The vulnerability arises from a miscalculation of the number of pages during the handling of a mapping failure in the kvm_iommu_map_pages function. This miscalculation can lead to a denial of service (host OS page unpinning) or potentially have other unspecified impacts when leveraged by guest OS users with privileges.\n\nThe correct way to fix this vulnerability is to ensure that the correct number of pages is used when pinning and mapping memory pages. In the original code, the page_size was not correctly adjusted when pinning and mapping pages, which could lead to incorrect calculations and potential issues.\n\nBy modifying the code to use `page_size >> PAGE_SHIFT` when pinning and mapping pages, the correct number of pages is considered, addressing the vulnerability and ensuring that the calculations are accurate. This modification helps prevent the exploitation of the vulnerability and improves the security and reliability of the code.",
      "GPT_purpose": "Mapping guest memory pages into the IO address space using an IOMMU in a KVM virtualization environment.",
      "GPT_function": "\n1. Map pages in the IOMMU domain for a given memory slot in a KVM instance.\n2. Check if the IOMMU exists and is in use.\n3. Handle mapping failures and unpin pages in case of an error.",
      "CVE_id": "CVE-2014-8369",
      "code_before_change": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tgfn_t gfn, end_gfn;\n\tpfn_t pfn;\n\tint r = 0;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint flags;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tgfn     = slot->base_gfn;\n\tend_gfn = gfn + slot->npages;\n\n\tflags = IOMMU_READ;\n\tif (!(slot->flags & KVM_MEM_READONLY))\n\t\tflags |= IOMMU_WRITE;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tflags |= IOMMU_CACHE;\n\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long page_size;\n\n\t\t/* Check if already mapped */\n\t\tif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get the page size we could use to map */\n\t\tpage_size = kvm_host_page_size(kvm, gfn);\n\n\t\t/* Make sure the page_size does not exceed the memslot */\n\t\twhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure gfn is aligned to the page size we want to map */\n\t\twhile ((gfn << PAGE_SHIFT) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure hva is aligned to the page size we want to map */\n\t\twhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/*\n\t\t * Pin all pages we are about to map in memory. This is\n\t\t * important because we unmap and unpin in 4kb steps later.\n\t\t */\n\t\tpfn = kvm_pin_pages(slot, gfn, page_size);\n\t\tif (is_error_noslot_pfn(pfn)) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Map into IO address space */\n\t\tr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\n\t\t\t      page_size, flags);\n\t\tif (r) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", pfn);\n\t\t\tkvm_unpin_pages(kvm, pfn, page_size);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tgfn += page_size >> PAGE_SHIFT;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, gfn - slot->base_gfn);\n\treturn r;\n}",
      "code_after_change": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tgfn_t gfn, end_gfn;\n\tpfn_t pfn;\n\tint r = 0;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint flags;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tgfn     = slot->base_gfn;\n\tend_gfn = gfn + slot->npages;\n\n\tflags = IOMMU_READ;\n\tif (!(slot->flags & KVM_MEM_READONLY))\n\t\tflags |= IOMMU_WRITE;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tflags |= IOMMU_CACHE;\n\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long page_size;\n\n\t\t/* Check if already mapped */\n\t\tif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get the page size we could use to map */\n\t\tpage_size = kvm_host_page_size(kvm, gfn);\n\n\t\t/* Make sure the page_size does not exceed the memslot */\n\t\twhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure gfn is aligned to the page size we want to map */\n\t\twhile ((gfn << PAGE_SHIFT) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure hva is aligned to the page size we want to map */\n\t\twhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/*\n\t\t * Pin all pages we are about to map in memory. This is\n\t\t * important because we unmap and unpin in 4kb steps later.\n\t\t */\n\t\tpfn = kvm_pin_pages(slot, gfn, page_size >> PAGE_SHIFT);\n\t\tif (is_error_noslot_pfn(pfn)) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Map into IO address space */\n\t\tr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\n\t\t\t      page_size, flags);\n\t\tif (r) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", pfn);\n\t\t\tkvm_unpin_pages(kvm, pfn, page_size >> PAGE_SHIFT);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tgfn += page_size >> PAGE_SHIFT;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, gfn - slot->base_gfn);\n\treturn r;\n}",
      "modified_lines": {
        "added": [
          "\t\tpfn = kvm_pin_pages(slot, gfn, page_size >> PAGE_SHIFT);",
          "\t\t\tkvm_unpin_pages(kvm, pfn, page_size >> PAGE_SHIFT);"
        ],
        "deleted": [
          "\t\tpfn = kvm_pin_pages(slot, gfn, page_size);",
          "\t\t\tkvm_unpin_pages(kvm, pfn, page_size);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of accurate calculation of the number of pages during memory pinning and mapping process.",
      "trigger_condition": "A mapping failure occurs, leading to a miscalculation of the number of pages to unpin and unmap, potentially causing a denial of service or other unspecified impacts.",
      "specific_code_behavior_causing_vulnerability": "The code incorrectly calculates the page size to unpin and unmap memory pages, leading to potential issues when handling a mapping failure. This can result in incorrect calculations and impact the host OS page unpinning process.",
      "id": 63,
      "code_after_change_normalized": "int FUN1(struct VAR1 *VAR1, struct kvm_memory_slot *VAR2)\n{\ngfn_t VAR3, VAR4;\npfn_t VAR5;\nint VAR6 = 0;\nstruct VAR9 *VAR7 = VAR1->VAR8.VAR9;\nint VAR10;\nif (!VAR7)\nreturn 0;\nVAR3     = VAR2->VAR11;\nVAR4 = VAR3 + VAR2->VAR12;\nVAR10 = VAR13;\nif (!(VAR2->VAR10 & VAR14))\nVAR10 |= VAR15;\nif (!VAR1->VAR8.VAR16)\nVAR10 |= VAR17;\nwhile (VAR3 < VAR4) {\nunsigned long VAR18;\nif (FUN2(VAR7, FUN3(VAR3))) {\nVAR3 += 1;\ncontinue;\n}\nVAR18 = FUN4(VAR1, VAR3);\nwhile ((VAR3 + (VAR18 >> VAR19)) > VAR4)\nVAR18 >>= 1;\nwhile ((VAR3 << VAR19) & (VAR18 - 1))\nVAR18 >>= 1;\nwhile (FUN5(VAR2, VAR3) & (VAR18 - 1))\nVAR18 >>= 1;\nVAR5 = FUN6(VAR2, VAR3, VAR18 >> VAR19);\nif (FUN7(VAR5)) {\nVAR3 += 1;\ncontinue;\n}\nVAR6 = FUN8(VAR7, FUN3(VAR3), FUN9(VAR5),\nVAR18, VAR10);\nif (VAR6) {\nFUN10(VAR20 \"STR\"\n\"STR\", VAR5);\nFUN11(VAR1, VAR5, VAR18 >> VAR19);\ngoto VAR21;\n}\nVAR3 += VAR18 >> VAR19;\n}\nreturn 0;\nVAR21:\nFUN12(VAR1, VAR2->VAR11, VAR3 - VAR2->VAR11);\nreturn VAR6;\n}\n",
      "code_before_change_normalized": "int FUN1(struct VAR1 *VAR1, struct kvm_memory_slot *VAR2)\n{\ngfn_t VAR3, VAR4;\npfn_t VAR5;\nint VAR6 = 0;\nstruct VAR9 *VAR7 = VAR1->VAR8.VAR9;\nint VAR10;\nif (!VAR7)\nreturn 0;\nVAR3     = VAR2->VAR11;\nVAR4 = VAR3 + VAR2->VAR12;\nVAR10 = VAR13;\nif (!(VAR2->VAR10 & VAR14))\nVAR10 |= VAR15;\nif (!VAR1->VAR8.VAR16)\nVAR10 |= VAR17;\nwhile (VAR3 < VAR4) {\nunsigned long VAR18;\nif (FUN2(VAR7, FUN3(VAR3))) {\nVAR3 += 1;\ncontinue;\n}\nVAR18 = FUN4(VAR1, VAR3);\nwhile ((VAR3 + (VAR18 >> VAR19)) > VAR4)\nVAR18 >>= 1;\nwhile ((VAR3 << VAR19) & (VAR18 - 1))\nVAR18 >>= 1;\nwhile (FUN5(VAR2, VAR3) & (VAR18 - 1))\nVAR18 >>= 1;\nVAR5 = FUN6(VAR2, VAR3, VAR18);\nif (FUN7(VAR5)) {\nVAR3 += 1;\ncontinue;\n}\nVAR6 = FUN8(VAR7, FUN3(VAR3), FUN9(VAR5),\nVAR18, VAR10);\nif (VAR6) {\nFUN10(VAR20 \"STR\"\n\"STR\", VAR5);\nFUN11(VAR1, VAR5, VAR18);\ngoto VAR21;\n}\nVAR3 += VAR18 >> VAR19;\n}\nreturn 0;\nVAR21:\nFUN12(VAR1, VAR2->VAR11, VAR3 - VAR2->VAR11);\nreturn VAR6;\n}\n",
      "code_after_change_raw": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\ngfn_t gfn, end_gfn;\npfn_t pfn;\nint r = 0;\nstruct iommu_domain *domain = kvm->arch.iommu_domain;\nint flags;\nif (!domain)\nreturn 0;\ngfn     = slot->base_gfn;\nend_gfn = gfn + slot->npages;\nflags = IOMMU_READ;\nif (!(slot->flags & KVM_MEM_READONLY))\nflags |= IOMMU_WRITE;\nif (!kvm->arch.iommu_noncoherent)\nflags |= IOMMU_CACHE;\nwhile (gfn < end_gfn) {\nunsigned long page_size;\nif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\ngfn += 1;\ncontinue;\n}\npage_size = kvm_host_page_size(kvm, gfn);\nwhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\npage_size >>= 1;\nwhile ((gfn << PAGE_SHIFT) & (page_size - 1))\npage_size >>= 1;\nwhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\npage_size >>= 1;\npfn = kvm_pin_pages(slot, gfn, page_size >> PAGE_SHIFT);\nif (is_error_noslot_pfn(pfn)) {\ngfn += 1;\ncontinue;\n}\nr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\npage_size, flags);\nif (r) {\nprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\"iommu failed to map pfn=%llx\\n\", pfn);\nkvm_unpin_pages(kvm, pfn, page_size >> PAGE_SHIFT);\ngoto unmap_pages;\n}\ngfn += page_size >> PAGE_SHIFT;\n}\nreturn 0;\nunmap_pages:\nkvm_iommu_put_pages(kvm, slot->base_gfn, gfn - slot->base_gfn);\nreturn r;\n}\n",
      "code_before_change_raw": "int kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\ngfn_t gfn, end_gfn;\npfn_t pfn;\nint r = 0;\nstruct iommu_domain *domain = kvm->arch.iommu_domain;\nint flags;\nif (!domain)\nreturn 0;\ngfn     = slot->base_gfn;\nend_gfn = gfn + slot->npages;\nflags = IOMMU_READ;\nif (!(slot->flags & KVM_MEM_READONLY))\nflags |= IOMMU_WRITE;\nif (!kvm->arch.iommu_noncoherent)\nflags |= IOMMU_CACHE;\nwhile (gfn < end_gfn) {\nunsigned long page_size;\nif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\ngfn += 1;\ncontinue;\n}\npage_size = kvm_host_page_size(kvm, gfn);\nwhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\npage_size >>= 1;\nwhile ((gfn << PAGE_SHIFT) & (page_size - 1))\npage_size >>= 1;\nwhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\npage_size >>= 1;\npfn = kvm_pin_pages(slot, gfn, page_size);\nif (is_error_noslot_pfn(pfn)) {\ngfn += 1;\ncontinue;\n}\nr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\npage_size, flags);\nif (r) {\nprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\"iommu failed to map pfn=%llx\\n\", pfn);\nkvm_unpin_pages(kvm, pfn, page_size);\ngoto unmap_pages;\n}\ngfn += page_size >> PAGE_SHIFT;\n}\nreturn 0;\nunmap_pages:\nkvm_iommu_put_pages(kvm, slot->base_gfn, gfn - slot->base_gfn);\nreturn r;\n}\n"
    }
  ],
  "CVE-2014-8884": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper input validation and boundary checking for message length in an ioctl call.",
        "trigger_condition": "A local user provides a large message length in an ioctl call to the vulnerable function, causing a stack-based buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code blindly copies the message data into a fixed-size buffer without verifying if the message length exceeds the available space in the buffer, leading to a buffer overflow vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add input validation to check if the message length provided in the ioctl call exceeds the available space in the buffer. By verifying the message length before copying the data, the code can prevent a stack-based buffer overflow. In this case, the solution involves adding a check to ensure that the message length does not exceed the buffer size before performing the memcpy operation.",
      "GPT_analysis": "The modification is necessary to prevent a stack-based buffer overflow vulnerability in the `ttusbdecfe_dvbs_diseqc_send_master_cmd` function. \n\nIn the original code snippet, the `memcpy` function copies the `cmd->msg` data into the `b` buffer without checking if the length of `cmd->msg` exceeds the available space in the `b` buffer. This can lead to a buffer overflow if `cmd->msg_len` is larger than the remaining space in the `b` buffer.\n\nBy adding the check `if (cmd->msg_len > sizeof(b) - 4)` before the `memcpy` call, the modified code ensures that the length of `cmd->msg` does not exceed the available space in the `b` buffer. If the length is too large, the function returns an error (`-EINVAL`) instead of allowing the buffer overflow to occur.\n\nThis modification helps to prevent potential exploitation of the vulnerability, thereby improving the security of the code.",
      "GPT_purpose": "Send a DVB-S DiSEqC master command using a stack-based buffer in the Linux kernel.",
      "GPT_function": "\n1. Send a DVB-S DiSEqC master command using a given frontend and command message.\n2. Copy the command message into a buffer.\n3. Call a function to send the command with the buffer data.",
      "CVE_id": "CVE-2014-8884",
      "code_before_change": "static int ttusbdecfe_dvbs_diseqc_send_master_cmd(struct dvb_frontend* fe, struct dvb_diseqc_master_cmd *cmd)\n{\n\tstruct ttusbdecfe_state* state = (struct ttusbdecfe_state*) fe->demodulator_priv;\n\tu8 b[] = { 0x00, 0xff, 0x00, 0x00,\n\t\t   0x00, 0x00, 0x00, 0x00,\n\t\t   0x00, 0x00 };\n\n\tmemcpy(&b[4], cmd->msg, cmd->msg_len);\n\n\tstate->config->send_command(fe, 0x72,\n\t\t\t\t    sizeof(b) - (6 - cmd->msg_len), b,\n\t\t\t\t    NULL, NULL);\n\n\treturn 0;\n}",
      "code_after_change": "static int ttusbdecfe_dvbs_diseqc_send_master_cmd(struct dvb_frontend* fe, struct dvb_diseqc_master_cmd *cmd)\n{\n\tstruct ttusbdecfe_state* state = (struct ttusbdecfe_state*) fe->demodulator_priv;\n\tu8 b[] = { 0x00, 0xff, 0x00, 0x00,\n\t\t   0x00, 0x00, 0x00, 0x00,\n\t\t   0x00, 0x00 };\n\n\tif (cmd->msg_len > sizeof(b) - 4)\n\t\treturn -EINVAL;\n\n\tmemcpy(&b[4], cmd->msg, cmd->msg_len);\n\n\tstate->config->send_command(fe, 0x72,\n\t\t\t\t    sizeof(b) - (6 - cmd->msg_len), b,\n\t\t\t\t    NULL, NULL);\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "",
          "\tif (cmd->msg_len > sizeof(b) - 4)",
          "\t\treturn -EINVAL;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper input validation and boundary checking for message length in an ioctl call.",
      "trigger_condition": "A local user provides a large message length in an ioctl call to the vulnerable function, causing a stack-based buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code blindly copies the message data into a fixed-size buffer without verifying if the message length exceeds the available space in the buffer, leading to a buffer overflow vulnerability.",
      "id": 64,
      "code_after_change_normalized": "static int FUN1(struct VAR1* VAR2, struct dvb_diseqc_master_cmd *VAR3)\n{\nstruct VAR4* VAR5 = (struct VAR4*) VAR2->VAR6;\nu8 VAR7[] = { VAR8, VAR8, VAR8, VAR8,\nVAR8, VAR8, VAR8, VAR8,\nVAR8, VAR8 };\nif (VAR3->VAR9 > sizeof(VAR7) - 4)\nreturn -VAR10;\nFUN2(&VAR7[4], VAR3->VAR11, VAR3->VAR9);\nVAR5->VAR12->FUN3(VAR2, VAR8,\nsizeof(VAR7) - (6 - VAR3->VAR9), VAR7,\nNULL, NULL);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1* VAR2, struct dvb_diseqc_master_cmd *VAR3)\n{\nstruct VAR4* VAR5 = (struct VAR4*) VAR2->VAR6;\nu8 VAR7[] = { VAR8, VAR8, VAR8, VAR8,\nVAR8, VAR8, VAR8, VAR8,\nVAR8, VAR8 };\nFUN2(&VAR7[4], VAR3->VAR9, VAR3->VAR10);\nVAR5->VAR11->FUN3(VAR2, VAR8,\nsizeof(VAR7) - (6 - VAR3->VAR10), VAR7,\nNULL, NULL);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int ttusbdecfe_dvbs_diseqc_send_master_cmd(struct dvb_frontend* fe, struct dvb_diseqc_master_cmd *cmd)\n{\nstruct ttusbdecfe_state* state = (struct ttusbdecfe_state*) fe->demodulator_priv;\nu8 b[] = { 0x00, 0xff, 0x00, 0x00,\n0x00, 0x00, 0x00, 0x00,\n0x00, 0x00 };\nif (cmd->msg_len > sizeof(b) - 4)\nreturn -EINVAL;\nmemcpy(&b[4], cmd->msg, cmd->msg_len);\nstate->config->send_command(fe, 0x72,\nsizeof(b) - (6 - cmd->msg_len), b,\nNULL, NULL);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int ttusbdecfe_dvbs_diseqc_send_master_cmd(struct dvb_frontend* fe, struct dvb_diseqc_master_cmd *cmd)\n{\nstruct ttusbdecfe_state* state = (struct ttusbdecfe_state*) fe->demodulator_priv;\nu8 b[] = { 0x00, 0xff, 0x00, 0x00,\n0x00, 0x00, 0x00, 0x00,\n0x00, 0x00 };\nmemcpy(&b[4], cmd->msg, cmd->msg_len);\nstate->config->send_command(fe, 0x72,\nsizeof(b) - (6 - cmd->msg_len), b,\nNULL, NULL);\nreturn 0;\n}\n"
    }
  ],
  "CVE-2014-9728": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for certain lengths in the UDF filesystem implementation.",
        "trigger_condition": "A local user provides a crafted filesystem image that exploits the lack of length validation, leading to a buffer over-read and system crash.",
        "specific_code_behavior_causing_vulnerability": "The code does not perform proper validation for file sizes stored in the ICB, allowing potential confusion and buffer over-read issues when handling files stored in the ICB.",
        "solution": "To mitigate the vulnerability, it is necessary to add sanity checks for files stored in the ICB to ensure that file sizes match the allocated sizes and that the file data fits within the designated space. By performing these validations, the code can prevent buffer over-read and potential system crashes that could be triggered by a crafted filesystem image exploiting the lack of length validation."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2014-9728, which involves a denial of service (buffer over-read and system crash) caused by the UDF filesystem implementation in the Linux kernel not validating certain lengths. By adding the following lines to the code snippet, we can perform sanity checks for files stored in the ICB (Index Control Block) to prevent confusion and potential issues later on:\n\n```c\n/* Sanity checks for files in ICB so that we don't get confused later */\nif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {\n    /*\n     * For file in ICB data is stored in allocation descriptor\n     * so sizes should match\n     */\n    if (iinfo->i_lenAlloc != inode->i_size)\n        goto out;\n    /* File in ICB has to fit in there... */\n    if (inode->i_size > inode->i_sb->s_blocksize -\n                udf_file_entry_alloc_offset(inode))\n        goto out;\n}\n```\n\nThese checks ensure that the sizes of files stored in the ICB match the allocated sizes and that the file data fits within the designated space. By performing these validations, we can prevent buffer over-read and potential system crashes that could be triggered by a crafted filesystem image exploiting the lack of length validation in the original code.",
      "GPT_purpose": "Read and initialize inode information for a UDF filesystem.",
      "GPT_function": "\n1. Read the UDF inode information.\n2. Handle different types of file entries and extended file entries.\n3. Set inode attributes such as UID, GID, mode, size, timestamps, and file type based on the UDF filesystem metadata.\n4. Handle special file types like directories, regular files, symlinks, block devices, character devices, FIFOs, and sockets.\n5. Check and handle device specifications for character and block devices.\n6. Handle metadata files like metadata file, metadata mirror file, and metadata bitmap file.\n7. Handle unknown file types and log errors.\n8. Return appropriate error codes and release buffer heads.",
      "CVE_id": "CVE-2014-9728",
      "code_before_change": "static int udf_read_inode(struct inode *inode, bool hidden_inode)\n{\n\tstruct buffer_head *bh = NULL;\n\tstruct fileEntry *fe;\n\tstruct extendedFileEntry *efe;\n\tuint16_t ident;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\n\tstruct kernel_lb_addr *iloc = &iinfo->i_location;\n\tunsigned int link_count;\n\tunsigned int indirections = 0;\n\tint ret = -EIO;\n\nreread:\n\tif (iloc->logicalBlockNum >=\n\t    sbi->s_partmaps[iloc->partitionReferenceNum].s_partition_len) {\n\t\tudf_debug(\"block=%d, partition=%d out of range\\n\",\n\t\t\t  iloc->logicalBlockNum, iloc->partitionReferenceNum);\n\t\treturn -EIO;\n\t}\n\n\t/*\n\t * Set defaults, but the inode is still incomplete!\n\t * Note: get_new_inode() sets the following on a new inode:\n\t *      i_sb = sb\n\t *      i_no = ino\n\t *      i_flags = sb->s_flags\n\t *      i_state = 0\n\t * clean_inode(): zero fills and sets\n\t *      i_count = 1\n\t *      i_nlink = 1\n\t *      i_op = NULL;\n\t */\n\tbh = udf_read_ptagged(inode->i_sb, iloc, 0, &ident);\n\tif (!bh) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\n\t\treturn -EIO;\n\t}\n\n\tif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\n\t    ident != TAG_IDENT_USE) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\n\t\t\tinode->i_ino, ident);\n\t\tgoto out;\n\t}\n\n\tfe = (struct fileEntry *)bh->b_data;\n\tefe = (struct extendedFileEntry *)bh->b_data;\n\n\tif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\n\t\tstruct buffer_head *ibh;\n\n\t\tibh = udf_read_ptagged(inode->i_sb, iloc, 1, &ident);\n\t\tif (ident == TAG_IDENT_IE && ibh) {\n\t\t\tstruct kernel_lb_addr loc;\n\t\t\tstruct indirectEntry *ie;\n\n\t\t\tie = (struct indirectEntry *)ibh->b_data;\n\t\t\tloc = lelb_to_cpu(ie->indirectICB.extLocation);\n\n\t\t\tif (ie->indirectICB.extLength) {\n\t\t\t\tbrelse(ibh);\n\t\t\t\tmemcpy(&iinfo->i_location, &loc,\n\t\t\t\t       sizeof(struct kernel_lb_addr));\n\t\t\t\tif (++indirections > UDF_MAX_ICB_NESTING) {\n\t\t\t\t\tudf_err(inode->i_sb,\n\t\t\t\t\t\t\"too many ICBs in ICB hierarchy\"\n\t\t\t\t\t\t\" (max %d supported)\\n\",\n\t\t\t\t\t\tUDF_MAX_ICB_NESTING);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tbrelse(bh);\n\t\t\t\tgoto reread;\n\t\t\t}\n\t\t}\n\t\tbrelse(ibh);\n\t} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\n\t\tudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\n\t\t\tle16_to_cpu(fe->icbTag.strategyType));\n\t\tgoto out;\n\t}\n\tif (fe->icbTag.strategyType == cpu_to_le16(4))\n\t\tiinfo->i_strat4096 = 0;\n\telse /* if (fe->icbTag.strategyType == cpu_to_le16(4096)) */\n\t\tiinfo->i_strat4096 = 1;\n\n\tiinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\n\t\t\t\t\t\t\tICBTAG_FLAG_AD_MASK;\n\tiinfo->i_unique = 0;\n\tiinfo->i_lenEAttr = 0;\n\tiinfo->i_lenExtents = 0;\n\tiinfo->i_lenAlloc = 0;\n\tiinfo->i_next_alloc_block = 0;\n\tiinfo->i_next_alloc_goal = 0;\n\tif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\n\t\tiinfo->i_efe = 1;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct extendedFileEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\t\tsizeof(struct fileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct fileEntry),\n\t\t       inode->i_sb->s_blocksize - sizeof(struct fileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 1;\n\t\tiinfo->i_lenAlloc = le32_to_cpu(\n\t\t\t\t((struct unallocSpaceEntry *)bh->b_data)->\n\t\t\t\t lengthAllocDescs);\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct unallocSpaceEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\treturn 0;\n\t}\n\n\tret = -EIO;\n\tread_lock(&sbi->s_cred_lock);\n\ti_uid_write(inode, le32_to_cpu(fe->uid));\n\tif (!uid_valid(inode->i_uid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\n\t\tinode->i_uid = UDF_SB(inode->i_sb)->s_uid;\n\n\ti_gid_write(inode, le32_to_cpu(fe->gid));\n\tif (!gid_valid(inode->i_gid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\n\t\tinode->i_gid = UDF_SB(inode->i_sb)->s_gid;\n\n\tif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_fmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_fmode;\n\telse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_dmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_dmode;\n\telse\n\t\tinode->i_mode = udf_convert_permissions(fe);\n\tinode->i_mode &= ~sbi->s_umask;\n\tread_unlock(&sbi->s_cred_lock);\n\n\tlink_count = le16_to_cpu(fe->fileLinkCount);\n\tif (!link_count) {\n\t\tif (!hidden_inode) {\n\t\t\tret = -ESTALE;\n\t\t\tgoto out;\n\t\t}\n\t\tlink_count = 1;\n\t}\n\tset_nlink(inode, link_count);\n\n\tinode->i_size = le64_to_cpu(fe->informationLength);\n\tiinfo->i_lenExtents = inode->i_size;\n\n\tif (iinfo->i_efe == 0) {\n\t\tinode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n\t\t\t(inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    fe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(fe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n\t} else {\n\t\tinode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n\t\t    (inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    efe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\n\t\t\tiinfo->i_crtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(efe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n\t}\n\tinode->i_generation = iinfo->i_unique;\n\n\tswitch (fe->icbTag.fileType) {\n\tcase ICBTAG_FILE_TYPE_DIRECTORY:\n\t\tinode->i_op = &udf_dir_inode_operations;\n\t\tinode->i_fop = &udf_dir_operations;\n\t\tinode->i_mode |= S_IFDIR;\n\t\tinc_nlink(inode);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_REALTIME:\n\tcase ICBTAG_FILE_TYPE_REGULAR:\n\tcase ICBTAG_FILE_TYPE_UNDEF:\n\tcase ICBTAG_FILE_TYPE_VAT20:\n\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\telse\n\t\t\tinode->i_data.a_ops = &udf_aops;\n\t\tinode->i_op = &udf_file_inode_operations;\n\t\tinode->i_fop = &udf_file_operations;\n\t\tinode->i_mode |= S_IFREG;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BLOCK:\n\t\tinode->i_mode |= S_IFBLK;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_CHAR:\n\t\tinode->i_mode |= S_IFCHR;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_FIFO:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SOCKET:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SYMLINK:\n\t\tinode->i_data.a_ops = &udf_symlink_aops;\n\t\tinode->i_op = &udf_symlink_inode_operations;\n\t\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MAIN:\n\t\tudf_debug(\"METADATA FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MIRROR:\n\t\tudf_debug(\"METADATA MIRROR FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BITMAP:\n\t\tudf_debug(\"METADATA BITMAP FILE-----\\n\");\n\t\tbreak;\n\tdefault:\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\n\t\t\tinode->i_ino, fe->icbTag.fileType);\n\t\tgoto out;\n\t}\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tstruct deviceSpec *dsea =\n\t\t\t(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\n\t\tif (dsea) {\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t\tMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\n\t\t\t\t      le32_to_cpu(dsea->minorDeviceIdent)));\n\t\t\t/* Developer ID ??? */\n\t\t} else\n\t\t\tgoto out;\n\t}\n\tret = 0;\nout:\n\tbrelse(bh);\n\treturn ret;\n}",
      "code_after_change": "static int udf_read_inode(struct inode *inode, bool hidden_inode)\n{\n\tstruct buffer_head *bh = NULL;\n\tstruct fileEntry *fe;\n\tstruct extendedFileEntry *efe;\n\tuint16_t ident;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\n\tstruct kernel_lb_addr *iloc = &iinfo->i_location;\n\tunsigned int link_count;\n\tunsigned int indirections = 0;\n\tint ret = -EIO;\n\nreread:\n\tif (iloc->logicalBlockNum >=\n\t    sbi->s_partmaps[iloc->partitionReferenceNum].s_partition_len) {\n\t\tudf_debug(\"block=%d, partition=%d out of range\\n\",\n\t\t\t  iloc->logicalBlockNum, iloc->partitionReferenceNum);\n\t\treturn -EIO;\n\t}\n\n\t/*\n\t * Set defaults, but the inode is still incomplete!\n\t * Note: get_new_inode() sets the following on a new inode:\n\t *      i_sb = sb\n\t *      i_no = ino\n\t *      i_flags = sb->s_flags\n\t *      i_state = 0\n\t * clean_inode(): zero fills and sets\n\t *      i_count = 1\n\t *      i_nlink = 1\n\t *      i_op = NULL;\n\t */\n\tbh = udf_read_ptagged(inode->i_sb, iloc, 0, &ident);\n\tif (!bh) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\n\t\treturn -EIO;\n\t}\n\n\tif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\n\t    ident != TAG_IDENT_USE) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\n\t\t\tinode->i_ino, ident);\n\t\tgoto out;\n\t}\n\n\tfe = (struct fileEntry *)bh->b_data;\n\tefe = (struct extendedFileEntry *)bh->b_data;\n\n\tif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\n\t\tstruct buffer_head *ibh;\n\n\t\tibh = udf_read_ptagged(inode->i_sb, iloc, 1, &ident);\n\t\tif (ident == TAG_IDENT_IE && ibh) {\n\t\t\tstruct kernel_lb_addr loc;\n\t\t\tstruct indirectEntry *ie;\n\n\t\t\tie = (struct indirectEntry *)ibh->b_data;\n\t\t\tloc = lelb_to_cpu(ie->indirectICB.extLocation);\n\n\t\t\tif (ie->indirectICB.extLength) {\n\t\t\t\tbrelse(ibh);\n\t\t\t\tmemcpy(&iinfo->i_location, &loc,\n\t\t\t\t       sizeof(struct kernel_lb_addr));\n\t\t\t\tif (++indirections > UDF_MAX_ICB_NESTING) {\n\t\t\t\t\tudf_err(inode->i_sb,\n\t\t\t\t\t\t\"too many ICBs in ICB hierarchy\"\n\t\t\t\t\t\t\" (max %d supported)\\n\",\n\t\t\t\t\t\tUDF_MAX_ICB_NESTING);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tbrelse(bh);\n\t\t\t\tgoto reread;\n\t\t\t}\n\t\t}\n\t\tbrelse(ibh);\n\t} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\n\t\tudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\n\t\t\tle16_to_cpu(fe->icbTag.strategyType));\n\t\tgoto out;\n\t}\n\tif (fe->icbTag.strategyType == cpu_to_le16(4))\n\t\tiinfo->i_strat4096 = 0;\n\telse /* if (fe->icbTag.strategyType == cpu_to_le16(4096)) */\n\t\tiinfo->i_strat4096 = 1;\n\n\tiinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\n\t\t\t\t\t\t\tICBTAG_FLAG_AD_MASK;\n\tiinfo->i_unique = 0;\n\tiinfo->i_lenEAttr = 0;\n\tiinfo->i_lenExtents = 0;\n\tiinfo->i_lenAlloc = 0;\n\tiinfo->i_next_alloc_block = 0;\n\tiinfo->i_next_alloc_goal = 0;\n\tif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\n\t\tiinfo->i_efe = 1;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct extendedFileEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\t\tsizeof(struct fileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct fileEntry),\n\t\t       inode->i_sb->s_blocksize - sizeof(struct fileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 1;\n\t\tiinfo->i_lenAlloc = le32_to_cpu(\n\t\t\t\t((struct unallocSpaceEntry *)bh->b_data)->\n\t\t\t\t lengthAllocDescs);\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct unallocSpaceEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\treturn 0;\n\t}\n\n\tret = -EIO;\n\tread_lock(&sbi->s_cred_lock);\n\ti_uid_write(inode, le32_to_cpu(fe->uid));\n\tif (!uid_valid(inode->i_uid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\n\t\tinode->i_uid = UDF_SB(inode->i_sb)->s_uid;\n\n\ti_gid_write(inode, le32_to_cpu(fe->gid));\n\tif (!gid_valid(inode->i_gid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\n\t\tinode->i_gid = UDF_SB(inode->i_sb)->s_gid;\n\n\tif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_fmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_fmode;\n\telse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_dmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_dmode;\n\telse\n\t\tinode->i_mode = udf_convert_permissions(fe);\n\tinode->i_mode &= ~sbi->s_umask;\n\tread_unlock(&sbi->s_cred_lock);\n\n\tlink_count = le16_to_cpu(fe->fileLinkCount);\n\tif (!link_count) {\n\t\tif (!hidden_inode) {\n\t\t\tret = -ESTALE;\n\t\t\tgoto out;\n\t\t}\n\t\tlink_count = 1;\n\t}\n\tset_nlink(inode, link_count);\n\n\tinode->i_size = le64_to_cpu(fe->informationLength);\n\tiinfo->i_lenExtents = inode->i_size;\n\n\tif (iinfo->i_efe == 0) {\n\t\tinode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n\t\t\t(inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    fe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(fe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n\t} else {\n\t\tinode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n\t\t    (inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    efe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\n\t\t\tiinfo->i_crtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(efe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n\t}\n\tinode->i_generation = iinfo->i_unique;\n\n\t/* Sanity checks for files in ICB so that we don't get confused later */\n\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {\n\t\t/*\n\t\t * For file in ICB data is stored in allocation descriptor\n\t\t * so sizes should match\n\t\t */\n\t\tif (iinfo->i_lenAlloc != inode->i_size)\n\t\t\tgoto out;\n\t\t/* File in ICB has to fit in there... */\n\t\tif (inode->i_size > inode->i_sb->s_blocksize -\n\t\t\t\t\tudf_file_entry_alloc_offset(inode))\n\t\t\tgoto out;\n\t}\n\n\tswitch (fe->icbTag.fileType) {\n\tcase ICBTAG_FILE_TYPE_DIRECTORY:\n\t\tinode->i_op = &udf_dir_inode_operations;\n\t\tinode->i_fop = &udf_dir_operations;\n\t\tinode->i_mode |= S_IFDIR;\n\t\tinc_nlink(inode);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_REALTIME:\n\tcase ICBTAG_FILE_TYPE_REGULAR:\n\tcase ICBTAG_FILE_TYPE_UNDEF:\n\tcase ICBTAG_FILE_TYPE_VAT20:\n\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\telse\n\t\t\tinode->i_data.a_ops = &udf_aops;\n\t\tinode->i_op = &udf_file_inode_operations;\n\t\tinode->i_fop = &udf_file_operations;\n\t\tinode->i_mode |= S_IFREG;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BLOCK:\n\t\tinode->i_mode |= S_IFBLK;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_CHAR:\n\t\tinode->i_mode |= S_IFCHR;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_FIFO:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SOCKET:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SYMLINK:\n\t\tinode->i_data.a_ops = &udf_symlink_aops;\n\t\tinode->i_op = &udf_symlink_inode_operations;\n\t\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MAIN:\n\t\tudf_debug(\"METADATA FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MIRROR:\n\t\tudf_debug(\"METADATA MIRROR FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BITMAP:\n\t\tudf_debug(\"METADATA BITMAP FILE-----\\n\");\n\t\tbreak;\n\tdefault:\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\n\t\t\tinode->i_ino, fe->icbTag.fileType);\n\t\tgoto out;\n\t}\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tstruct deviceSpec *dsea =\n\t\t\t(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\n\t\tif (dsea) {\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t\tMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\n\t\t\t\t      le32_to_cpu(dsea->minorDeviceIdent)));\n\t\t\t/* Developer ID ??? */\n\t\t} else\n\t\t\tgoto out;\n\t}\n\tret = 0;\nout:\n\tbrelse(bh);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\t/* Sanity checks for files in ICB so that we don't get confused later */",
          "\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {",
          "\t\t/*",
          "\t\t * For file in ICB data is stored in allocation descriptor",
          "\t\t * so sizes should match",
          "\t\t */",
          "\t\tif (iinfo->i_lenAlloc != inode->i_size)",
          "\t\t\tgoto out;",
          "\t\t/* File in ICB has to fit in there... */",
          "\t\tif (inode->i_size > inode->i_sb->s_blocksize -",
          "\t\t\t\t\tudf_file_entry_alloc_offset(inode))",
          "\t\t\tgoto out;",
          "\t}",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation for certain lengths in the UDF filesystem implementation.",
      "trigger_condition": "A local user provides a crafted filesystem image that exploits the lack of length validation, leading to a buffer over-read and system crash.",
      "specific_code_behavior_causing_vulnerability": "The code does not perform proper validation for file sizes stored in the ICB, allowing potential confusion and buffer over-read issues when handling files stored in the ICB.",
      "solution": "To mitigate the vulnerability, it is necessary to add sanity checks for files stored in the ICB to ensure that file sizes match the allocated sizes and that the file data fits within the designated space. By performing these validations, the code can prevent buffer over-read and potential system crashes that could be triggered by a crafted filesystem image exploiting the lack of length validation.",
      "id": 65,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1, bool VAR2)\n{\nstruct buffer_head *VAR3 = NULL;\nstruct fileEntry *VAR4;\nstruct extendedFileEntry *VAR5;\nuint16_t VAR6;\nstruct udf_inode_info *VAR7 = FUN2(VAR1);\nstruct udf_sb_info *VAR8 = FUN3(VAR1->VAR9);\nstruct kernel_lb_addr *VAR10 = &VAR7->VAR11;\nunsigned int VAR12;\nunsigned int VAR13 = 0;\nint VAR14 = -VAR15;\nVAR16:\nif (VAR10->VAR17 >=\nVAR8->VAR18[VAR10->VAR19].VAR20) {\nFUN4(\"STR\",\nVAR10->VAR17, VAR10->VAR19);\nreturn -VAR15;\n}\nVAR3 = FUN5(VAR1->VAR9, VAR10, 0, &VAR6);\nif (!VAR3) {\nFUN6(VAR1->VAR9, \"STR\", VAR1->VAR21);\nreturn -VAR15;\n}\nif (VAR6 != VAR22 && VAR6 != VAR23 &&\nVAR6 != VAR24) {\nFUN6(VAR1->VAR9, \"STR\",\nVAR1->VAR21, VAR6);\ngoto VAR25;\n}\nVAR4 = (struct VAR26 *)VAR3->VAR27;\nVAR5 = (struct VAR28 *)VAR3->VAR27;\nif (VAR4->VAR29.VAR30 == FUN7(4096)) {\nstruct buffer_head *VAR31;\nVAR31 = FUN5(VAR1->VAR9, VAR10, 1, &VAR6);\nif (VAR6 == VAR32 && VAR31) {\nstruct kernel_lb_addr VAR33;\nstruct indirectEntry *VAR34;\nVAR34 = (struct VAR35 *)VAR31->VAR27;\nVAR33 = FUN8(VAR34->VAR36.VAR37);\nif (VAR34->VAR36.VAR38) {\nFUN9(VAR31);\nFUN10(&VAR7->VAR11, &VAR33,\nsizeof(struct VAR39));\nif (++VAR13 > VAR40) {\nFUN6(VAR1->VAR9,\n\"STR\"\n\"STR\",\nVAR40);\ngoto VAR25;\n}\nFUN9(VAR3);\ngoto VAR16;\n}\n}\nFUN9(VAR31);\n} else if (VAR4->VAR29.VAR30 != FUN7(4)) {\nFUN6(VAR1->VAR9, \"STR\",\nFUN11(VAR4->VAR29.VAR30));\ngoto VAR25;\n}\nif (VAR4->VAR29.VAR30 == FUN7(4))\nVAR7->VAR41 = 0;\nelse \nVAR7->VAR41 = 1;\nVAR7->VAR42 = FUN11(VAR4->VAR29.VAR43) &\nVAR44;\nVAR7->VAR45 = 0;\nVAR7->VAR46 = 0;\nVAR7->VAR47 = 0;\nVAR7->VAR48 = 0;\nVAR7->VAR49 = 0;\nVAR7->VAR50 = 0;\nif (VAR4->VAR51.VAR52 == FUN7(VAR23)) {\nVAR7->VAR53 = 1;\nVAR7->VAR54 = 0;\nVAR14 = FUN12(VAR1, VAR1->VAR9->VAR55 -\nsizeof(struct VAR28));\nif (VAR14)\ngoto VAR25;\nFUN10(VAR7->VAR56.VAR57,\nVAR3->VAR27 + sizeof(struct VAR28),\nVAR1->VAR9->VAR55 -\nsizeof(struct VAR28));\n} else if (VAR4->VAR51.VAR52 == FUN7(VAR22)) {\nVAR7->VAR53 = 0;\nVAR7->VAR54 = 0;\nVAR14 = FUN12(VAR1, VAR1->VAR9->VAR55 -\nsizeof(struct VAR26));\nif (VAR14)\ngoto VAR25;\nFUN10(VAR7->VAR56.VAR57,\nVAR3->VAR27 + sizeof(struct VAR26),\nVAR1->VAR9->VAR55 - sizeof(struct VAR26));\n} else if (VAR4->VAR51.VAR52 == FUN7(VAR24)) {\nVAR7->VAR53 = 0;\nVAR7->VAR54 = 1;\nVAR7->VAR48 = FUN13(\n((struct VAR58 *)VAR3->VAR27)->\nVAR59);\nVAR14 = FUN12(VAR1, VAR1->VAR9->VAR55 -\nsizeof(struct VAR58));\nif (VAR14)\ngoto VAR25;\nFUN10(VAR7->VAR56.VAR57,\nVAR3->VAR27 + sizeof(struct VAR58),\nVAR1->VAR9->VAR55 -\nsizeof(struct VAR58));\nreturn 0;\n}\nVAR14 = -VAR15;\nFUN14(&VAR8->VAR60);\nFUN15(VAR1, FUN13(VAR4->VAR61));\nif (!FUN16(VAR1->VAR62) ||\nFUN17(VAR1->VAR9, VAR63) ||\nFUN17(VAR1->VAR9, VAR64))\nVAR1->VAR62 = FUN3(VAR1->VAR9)->VAR65;\nFUN18(VAR1, FUN13(VAR4->VAR66));\nif (!FUN19(VAR1->VAR67) ||\nFUN17(VAR1->VAR9, VAR68) ||\nFUN17(VAR1->VAR9, VAR69))\nVAR1->VAR67 = FUN3(VAR1->VAR9)->VAR70;\nif (VAR4->VAR29.VAR71 != VAR72 &&\nVAR8->VAR73 != VAR74)\nVAR1->VAR75 = VAR8->VAR73;\nelse if (VAR4->VAR29.VAR71 == VAR72 &&\nVAR8->VAR76 != VAR74)\nVAR1->VAR75 = VAR8->VAR76;\nelse\nVAR1->VAR75 = FUN20(VAR4);\nVAR1->VAR75 &= ~VAR8->VAR77;\nFUN21(&VAR8->VAR60);\nVAR12 = FUN11(VAR4->VAR78);\nif (!VAR12) {\nif (!VAR2) {\nVAR14 = -VAR79;\ngoto VAR25;\n}\nVAR12 = 1;\n}\nFUN22(VAR1, VAR12);\nVAR1->VAR80 = FUN23(VAR4->VAR81);\nVAR7->VAR47 = VAR1->VAR80;\nif (VAR7->VAR53 == 0) {\nVAR1->VAR82 = FUN23(VAR4->VAR83) <<\n(VAR1->VAR9->VAR84 - 9);\nif (!FUN24(&VAR1->VAR85, VAR4->VAR86))\nVAR1->VAR85 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR88,\nVAR4->VAR89))\nVAR1->VAR88 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR90, VAR4->VAR91))\nVAR1->VAR90 = VAR8->VAR87;\nVAR7->VAR45 = FUN23(VAR4->VAR92);\nVAR7->VAR46 = FUN13(VAR4->VAR93);\nVAR7->VAR48 = FUN13(VAR4->VAR59);\nVAR7->VAR94 = FUN13(VAR4->VAR95);\n} else {\nVAR1->VAR82 = FUN23(VAR5->VAR83) <<\n(VAR1->VAR9->VAR84 - 9);\nif (!FUN24(&VAR1->VAR85, VAR5->VAR86))\nVAR1->VAR85 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR88,\nVAR5->VAR89))\nVAR1->VAR88 = VAR8->VAR87;\nif (!FUN24(&VAR7->VAR96, VAR5->VAR97))\nVAR7->VAR96 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR90, VAR5->VAR91))\nVAR1->VAR90 = VAR8->VAR87;\nVAR7->VAR45 = FUN23(VAR5->VAR92);\nVAR7->VAR46 = FUN13(VAR5->VAR93);\nVAR7->VAR48 = FUN13(VAR5->VAR59);\nVAR7->VAR94 = FUN13(VAR5->VAR95);\n}\nVAR1->VAR98 = VAR7->VAR45;\nif (VAR7->VAR42 == VAR99) {\nif (VAR7->VAR48 != VAR1->VAR80)\ngoto VAR25;\nif (VAR1->VAR80 > VAR1->VAR9->VAR55 -\nFUN25(VAR1))\ngoto VAR25;\n}\nswitch (VAR4->VAR29.VAR71) {\ncase VAR72:\nVAR1->VAR100 = &VAR101;\nVAR1->VAR102 = &VAR103;\nVAR1->VAR75 |= VAR104;\nFUN26(VAR1);\nbreak;\ncase VAR105:\ncase VAR106:\ncase VAR107:\ncase VAR108:\nif (VAR7->VAR42 == VAR99)\nVAR1->VAR57.VAR109 = &VAR110;\nelse\nVAR1->VAR57.VAR109 = &VAR111;\nVAR1->VAR100 = &VAR112;\nVAR1->VAR102 = &VAR113;\nVAR1->VAR75 |= VAR114;\nbreak;\ncase VAR115:\nVAR1->VAR75 |= VAR116;\nbreak;\ncase VAR117:\nVAR1->VAR75 |= VAR118;\nbreak;\ncase VAR119:\nFUN27(VAR1, VAR1->VAR75 | VAR120, 0);\nbreak;\ncase VAR121:\nFUN27(VAR1, VAR1->VAR75 | VAR122, 0);\nbreak;\ncase VAR123:\nVAR1->VAR57.VAR109 = &VAR124;\nVAR1->VAR100 = &VAR125;\nVAR1->VAR75 = VAR126 | VAR127;\nbreak;\ncase VAR128:\nFUN4(\"STR\");\nbreak;\ncase VAR129:\nFUN4(\"STR\");\nbreak;\ncase VAR130:\nFUN4(\"STR\");\nbreak;\ndefault:\nFUN6(VAR1->VAR9, \"STR\",\nVAR1->VAR21, VAR4->VAR29.VAR71);\ngoto VAR25;\n}\nif (FUN28(VAR1->VAR75) || FUN29(VAR1->VAR75)) {\nstruct deviceSpec *VAR131 =\n(struct VAR132 *)FUN30(VAR1, 12, 1);\nif (VAR131) {\nFUN27(VAR1, VAR1->VAR75,\nFUN31(FUN13(VAR131->VAR133),\nFUN13(VAR131->VAR134)));\n} else\ngoto VAR25;\n}\nVAR14 = 0;\nVAR25:\nFUN9(VAR3);\nreturn VAR14;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1, bool VAR2)\n{\nstruct buffer_head *VAR3 = NULL;\nstruct fileEntry *VAR4;\nstruct extendedFileEntry *VAR5;\nuint16_t VAR6;\nstruct udf_inode_info *VAR7 = FUN2(VAR1);\nstruct udf_sb_info *VAR8 = FUN3(VAR1->VAR9);\nstruct kernel_lb_addr *VAR10 = &VAR7->VAR11;\nunsigned int VAR12;\nunsigned int VAR13 = 0;\nint VAR14 = -VAR15;\nVAR16:\nif (VAR10->VAR17 >=\nVAR8->VAR18[VAR10->VAR19].VAR20) {\nFUN4(\"STR\",\nVAR10->VAR17, VAR10->VAR19);\nreturn -VAR15;\n}\nVAR3 = FUN5(VAR1->VAR9, VAR10, 0, &VAR6);\nif (!VAR3) {\nFUN6(VAR1->VAR9, \"STR\", VAR1->VAR21);\nreturn -VAR15;\n}\nif (VAR6 != VAR22 && VAR6 != VAR23 &&\nVAR6 != VAR24) {\nFUN6(VAR1->VAR9, \"STR\",\nVAR1->VAR21, VAR6);\ngoto VAR25;\n}\nVAR4 = (struct VAR26 *)VAR3->VAR27;\nVAR5 = (struct VAR28 *)VAR3->VAR27;\nif (VAR4->VAR29.VAR30 == FUN7(4096)) {\nstruct buffer_head *VAR31;\nVAR31 = FUN5(VAR1->VAR9, VAR10, 1, &VAR6);\nif (VAR6 == VAR32 && VAR31) {\nstruct kernel_lb_addr VAR33;\nstruct indirectEntry *VAR34;\nVAR34 = (struct VAR35 *)VAR31->VAR27;\nVAR33 = FUN8(VAR34->VAR36.VAR37);\nif (VAR34->VAR36.VAR38) {\nFUN9(VAR31);\nFUN10(&VAR7->VAR11, &VAR33,\nsizeof(struct VAR39));\nif (++VAR13 > VAR40) {\nFUN6(VAR1->VAR9,\n\"STR\"\n\"STR\",\nVAR40);\ngoto VAR25;\n}\nFUN9(VAR3);\ngoto VAR16;\n}\n}\nFUN9(VAR31);\n} else if (VAR4->VAR29.VAR30 != FUN7(4)) {\nFUN6(VAR1->VAR9, \"STR\",\nFUN11(VAR4->VAR29.VAR30));\ngoto VAR25;\n}\nif (VAR4->VAR29.VAR30 == FUN7(4))\nVAR7->VAR41 = 0;\nelse \nVAR7->VAR41 = 1;\nVAR7->VAR42 = FUN11(VAR4->VAR29.VAR43) &\nVAR44;\nVAR7->VAR45 = 0;\nVAR7->VAR46 = 0;\nVAR7->VAR47 = 0;\nVAR7->VAR48 = 0;\nVAR7->VAR49 = 0;\nVAR7->VAR50 = 0;\nif (VAR4->VAR51.VAR52 == FUN7(VAR23)) {\nVAR7->VAR53 = 1;\nVAR7->VAR54 = 0;\nVAR14 = FUN12(VAR1, VAR1->VAR9->VAR55 -\nsizeof(struct VAR28));\nif (VAR14)\ngoto VAR25;\nFUN10(VAR7->VAR56.VAR57,\nVAR3->VAR27 + sizeof(struct VAR28),\nVAR1->VAR9->VAR55 -\nsizeof(struct VAR28));\n} else if (VAR4->VAR51.VAR52 == FUN7(VAR22)) {\nVAR7->VAR53 = 0;\nVAR7->VAR54 = 0;\nVAR14 = FUN12(VAR1, VAR1->VAR9->VAR55 -\nsizeof(struct VAR26));\nif (VAR14)\ngoto VAR25;\nFUN10(VAR7->VAR56.VAR57,\nVAR3->VAR27 + sizeof(struct VAR26),\nVAR1->VAR9->VAR55 - sizeof(struct VAR26));\n} else if (VAR4->VAR51.VAR52 == FUN7(VAR24)) {\nVAR7->VAR53 = 0;\nVAR7->VAR54 = 1;\nVAR7->VAR48 = FUN13(\n((struct VAR58 *)VAR3->VAR27)->\nVAR59);\nVAR14 = FUN12(VAR1, VAR1->VAR9->VAR55 -\nsizeof(struct VAR58));\nif (VAR14)\ngoto VAR25;\nFUN10(VAR7->VAR56.VAR57,\nVAR3->VAR27 + sizeof(struct VAR58),\nVAR1->VAR9->VAR55 -\nsizeof(struct VAR58));\nreturn 0;\n}\nVAR14 = -VAR15;\nFUN14(&VAR8->VAR60);\nFUN15(VAR1, FUN13(VAR4->VAR61));\nif (!FUN16(VAR1->VAR62) ||\nFUN17(VAR1->VAR9, VAR63) ||\nFUN17(VAR1->VAR9, VAR64))\nVAR1->VAR62 = FUN3(VAR1->VAR9)->VAR65;\nFUN18(VAR1, FUN13(VAR4->VAR66));\nif (!FUN19(VAR1->VAR67) ||\nFUN17(VAR1->VAR9, VAR68) ||\nFUN17(VAR1->VAR9, VAR69))\nVAR1->VAR67 = FUN3(VAR1->VAR9)->VAR70;\nif (VAR4->VAR29.VAR71 != VAR72 &&\nVAR8->VAR73 != VAR74)\nVAR1->VAR75 = VAR8->VAR73;\nelse if (VAR4->VAR29.VAR71 == VAR72 &&\nVAR8->VAR76 != VAR74)\nVAR1->VAR75 = VAR8->VAR76;\nelse\nVAR1->VAR75 = FUN20(VAR4);\nVAR1->VAR75 &= ~VAR8->VAR77;\nFUN21(&VAR8->VAR60);\nVAR12 = FUN11(VAR4->VAR78);\nif (!VAR12) {\nif (!VAR2) {\nVAR14 = -VAR79;\ngoto VAR25;\n}\nVAR12 = 1;\n}\nFUN22(VAR1, VAR12);\nVAR1->VAR80 = FUN23(VAR4->VAR81);\nVAR7->VAR47 = VAR1->VAR80;\nif (VAR7->VAR53 == 0) {\nVAR1->VAR82 = FUN23(VAR4->VAR83) <<\n(VAR1->VAR9->VAR84 - 9);\nif (!FUN24(&VAR1->VAR85, VAR4->VAR86))\nVAR1->VAR85 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR88,\nVAR4->VAR89))\nVAR1->VAR88 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR90, VAR4->VAR91))\nVAR1->VAR90 = VAR8->VAR87;\nVAR7->VAR45 = FUN23(VAR4->VAR92);\nVAR7->VAR46 = FUN13(VAR4->VAR93);\nVAR7->VAR48 = FUN13(VAR4->VAR59);\nVAR7->VAR94 = FUN13(VAR4->VAR95);\n} else {\nVAR1->VAR82 = FUN23(VAR5->VAR83) <<\n(VAR1->VAR9->VAR84 - 9);\nif (!FUN24(&VAR1->VAR85, VAR5->VAR86))\nVAR1->VAR85 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR88,\nVAR5->VAR89))\nVAR1->VAR88 = VAR8->VAR87;\nif (!FUN24(&VAR7->VAR96, VAR5->VAR97))\nVAR7->VAR96 = VAR8->VAR87;\nif (!FUN24(&VAR1->VAR90, VAR5->VAR91))\nVAR1->VAR90 = VAR8->VAR87;\nVAR7->VAR45 = FUN23(VAR5->VAR92);\nVAR7->VAR46 = FUN13(VAR5->VAR93);\nVAR7->VAR48 = FUN13(VAR5->VAR59);\nVAR7->VAR94 = FUN13(VAR5->VAR95);\n}\nVAR1->VAR98 = VAR7->VAR45;\nswitch (VAR4->VAR29.VAR71) {\ncase VAR72:\nVAR1->VAR99 = &VAR100;\nVAR1->VAR101 = &VAR102;\nVAR1->VAR75 |= VAR103;\nFUN25(VAR1);\nbreak;\ncase VAR104:\ncase VAR105:\ncase VAR106:\ncase VAR107:\nif (VAR7->VAR42 == VAR108)\nVAR1->VAR57.VAR109 = &VAR110;\nelse\nVAR1->VAR57.VAR109 = &VAR111;\nVAR1->VAR99 = &VAR112;\nVAR1->VAR101 = &VAR113;\nVAR1->VAR75 |= VAR114;\nbreak;\ncase VAR115:\nVAR1->VAR75 |= VAR116;\nbreak;\ncase VAR117:\nVAR1->VAR75 |= VAR118;\nbreak;\ncase VAR119:\nFUN26(VAR1, VAR1->VAR75 | VAR120, 0);\nbreak;\ncase VAR121:\nFUN26(VAR1, VAR1->VAR75 | VAR122, 0);\nbreak;\ncase VAR123:\nVAR1->VAR57.VAR109 = &VAR124;\nVAR1->VAR99 = &VAR125;\nVAR1->VAR75 = VAR126 | VAR127;\nbreak;\ncase VAR128:\nFUN4(\"STR\");\nbreak;\ncase VAR129:\nFUN4(\"STR\");\nbreak;\ncase VAR130:\nFUN4(\"STR\");\nbreak;\ndefault:\nFUN6(VAR1->VAR9, \"STR\",\nVAR1->VAR21, VAR4->VAR29.VAR71);\ngoto VAR25;\n}\nif (FUN27(VAR1->VAR75) || FUN28(VAR1->VAR75)) {\nstruct deviceSpec *VAR131 =\n(struct VAR132 *)FUN29(VAR1, 12, 1);\nif (VAR131) {\nFUN26(VAR1, VAR1->VAR75,\nFUN30(FUN13(VAR131->VAR133),\nFUN13(VAR131->VAR134)));\n} else\ngoto VAR25;\n}\nVAR14 = 0;\nVAR25:\nFUN9(VAR3);\nreturn VAR14;\n}\n",
      "code_after_change_raw": "static int udf_read_inode(struct inode *inode, bool hidden_inode)\n{\nstruct buffer_head *bh = NULL;\nstruct fileEntry *fe;\nstruct extendedFileEntry *efe;\nuint16_t ident;\nstruct udf_inode_info *iinfo = UDF_I(inode);\nstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\nstruct kernel_lb_addr *iloc = &iinfo->i_location;\nunsigned int link_count;\nunsigned int indirections = 0;\nint ret = -EIO;\nreread:\nif (iloc->logicalBlockNum >=\nsbi->s_partmaps[iloc->partitionReferenceNum].s_partition_len) {\nudf_debug(\"block=%d, partition=%d out of range\\n\",\niloc->logicalBlockNum, iloc->partitionReferenceNum);\nreturn -EIO;\n}\nbh = udf_read_ptagged(inode->i_sb, iloc, 0, &ident);\nif (!bh) {\nudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\nreturn -EIO;\n}\nif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\nident != TAG_IDENT_USE) {\nudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\ninode->i_ino, ident);\ngoto out;\n}\nfe = (struct fileEntry *)bh->b_data;\nefe = (struct extendedFileEntry *)bh->b_data;\nif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\nstruct buffer_head *ibh;\nibh = udf_read_ptagged(inode->i_sb, iloc, 1, &ident);\nif (ident == TAG_IDENT_IE && ibh) {\nstruct kernel_lb_addr loc;\nstruct indirectEntry *ie;\nie = (struct indirectEntry *)ibh->b_data;\nloc = lelb_to_cpu(ie->indirectICB.extLocation);\nif (ie->indirectICB.extLength) {\nbrelse(ibh);\nmemcpy(&iinfo->i_location, &loc,\nsizeof(struct kernel_lb_addr));\nif (++indirections > UDF_MAX_ICB_NESTING) {\nudf_err(inode->i_sb,\n\"too many ICBs in ICB hierarchy\"\n\" (max %d supported)\\n\",\nUDF_MAX_ICB_NESTING);\ngoto out;\n}\nbrelse(bh);\ngoto reread;\n}\n}\nbrelse(ibh);\n} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\nudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\nle16_to_cpu(fe->icbTag.strategyType));\ngoto out;\n}\nif (fe->icbTag.strategyType == cpu_to_le16(4))\niinfo->i_strat4096 = 0;\nelse \niinfo->i_strat4096 = 1;\niinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\nICBTAG_FLAG_AD_MASK;\niinfo->i_unique = 0;\niinfo->i_lenEAttr = 0;\niinfo->i_lenExtents = 0;\niinfo->i_lenAlloc = 0;\niinfo->i_next_alloc_block = 0;\niinfo->i_next_alloc_goal = 0;\nif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\niinfo->i_efe = 1;\niinfo->i_use = 0;\nret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\nsizeof(struct extendedFileEntry));\nif (ret)\ngoto out;\nmemcpy(iinfo->i_ext.i_data,\nbh->b_data + sizeof(struct extendedFileEntry),\ninode->i_sb->s_blocksize -\nsizeof(struct extendedFileEntry));\n} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\niinfo->i_efe = 0;\niinfo->i_use = 0;\nret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\nsizeof(struct fileEntry));\nif (ret)\ngoto out;\nmemcpy(iinfo->i_ext.i_data,\nbh->b_data + sizeof(struct fileEntry),\ninode->i_sb->s_blocksize - sizeof(struct fileEntry));\n} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\niinfo->i_efe = 0;\niinfo->i_use = 1;\niinfo->i_lenAlloc = le32_to_cpu(\n((struct unallocSpaceEntry *)bh->b_data)->\nlengthAllocDescs);\nret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\nsizeof(struct unallocSpaceEntry));\nif (ret)\ngoto out;\nmemcpy(iinfo->i_ext.i_data,\nbh->b_data + sizeof(struct unallocSpaceEntry),\ninode->i_sb->s_blocksize -\nsizeof(struct unallocSpaceEntry));\nreturn 0;\n}\nret = -EIO;\nread_lock(&sbi->s_cred_lock);\ni_uid_write(inode, le32_to_cpu(fe->uid));\nif (!uid_valid(inode->i_uid) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\ninode->i_uid = UDF_SB(inode->i_sb)->s_uid;\ni_gid_write(inode, le32_to_cpu(fe->gid));\nif (!gid_valid(inode->i_gid) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\ninode->i_gid = UDF_SB(inode->i_sb)->s_gid;\nif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\nsbi->s_fmode != UDF_INVALID_MODE)\ninode->i_mode = sbi->s_fmode;\nelse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\nsbi->s_dmode != UDF_INVALID_MODE)\ninode->i_mode = sbi->s_dmode;\nelse\ninode->i_mode = udf_convert_permissions(fe);\ninode->i_mode &= ~sbi->s_umask;\nread_unlock(&sbi->s_cred_lock);\nlink_count = le16_to_cpu(fe->fileLinkCount);\nif (!link_count) {\nif (!hidden_inode) {\nret = -ESTALE;\ngoto out;\n}\nlink_count = 1;\n}\nset_nlink(inode, link_count);\ninode->i_size = le64_to_cpu(fe->informationLength);\niinfo->i_lenExtents = inode->i_size;\nif (iinfo->i_efe == 0) {\ninode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n(inode->i_sb->s_blocksize_bits - 9);\nif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\ninode->i_atime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_mtime,\nfe->modificationTime))\ninode->i_mtime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\ninode->i_ctime = sbi->s_record_time;\niinfo->i_unique = le64_to_cpu(fe->uniqueID);\niinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\niinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\niinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n} else {\ninode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n(inode->i_sb->s_blocksize_bits - 9);\nif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\ninode->i_atime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_mtime,\nefe->modificationTime))\ninode->i_mtime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\niinfo->i_crtime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\ninode->i_ctime = sbi->s_record_time;\niinfo->i_unique = le64_to_cpu(efe->uniqueID);\niinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\niinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\niinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n}\ninode->i_generation = iinfo->i_unique;\nif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {\nif (iinfo->i_lenAlloc != inode->i_size)\ngoto out;\nif (inode->i_size > inode->i_sb->s_blocksize -\nudf_file_entry_alloc_offset(inode))\ngoto out;\n}\nswitch (fe->icbTag.fileType) {\ncase ICBTAG_FILE_TYPE_DIRECTORY:\ninode->i_op = &udf_dir_inode_operations;\ninode->i_fop = &udf_dir_operations;\ninode->i_mode |= S_IFDIR;\ninc_nlink(inode);\nbreak;\ncase ICBTAG_FILE_TYPE_REALTIME:\ncase ICBTAG_FILE_TYPE_REGULAR:\ncase ICBTAG_FILE_TYPE_UNDEF:\ncase ICBTAG_FILE_TYPE_VAT20:\nif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\ninode->i_data.a_ops = &udf_adinicb_aops;\nelse\ninode->i_data.a_ops = &udf_aops;\ninode->i_op = &udf_file_inode_operations;\ninode->i_fop = &udf_file_operations;\ninode->i_mode |= S_IFREG;\nbreak;\ncase ICBTAG_FILE_TYPE_BLOCK:\ninode->i_mode |= S_IFBLK;\nbreak;\ncase ICBTAG_FILE_TYPE_CHAR:\ninode->i_mode |= S_IFCHR;\nbreak;\ncase ICBTAG_FILE_TYPE_FIFO:\ninit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\nbreak;\ncase ICBTAG_FILE_TYPE_SOCKET:\ninit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\nbreak;\ncase ICBTAG_FILE_TYPE_SYMLINK:\ninode->i_data.a_ops = &udf_symlink_aops;\ninode->i_op = &udf_symlink_inode_operations;\ninode->i_mode = S_IFLNK | S_IRWXUGO;\nbreak;\ncase ICBTAG_FILE_TYPE_MAIN:\nudf_debug(\"METADATA FILE-----\\n\");\nbreak;\ncase ICBTAG_FILE_TYPE_MIRROR:\nudf_debug(\"METADATA MIRROR FILE-----\\n\");\nbreak;\ncase ICBTAG_FILE_TYPE_BITMAP:\nudf_debug(\"METADATA BITMAP FILE-----\\n\");\nbreak;\ndefault:\nudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\ninode->i_ino, fe->icbTag.fileType);\ngoto out;\n}\nif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\nstruct deviceSpec *dsea =\n(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\nif (dsea) {\ninit_special_inode(inode, inode->i_mode,\nMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\nle32_to_cpu(dsea->minorDeviceIdent)));\n} else\ngoto out;\n}\nret = 0;\nout:\nbrelse(bh);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int udf_read_inode(struct inode *inode, bool hidden_inode)\n{\nstruct buffer_head *bh = NULL;\nstruct fileEntry *fe;\nstruct extendedFileEntry *efe;\nuint16_t ident;\nstruct udf_inode_info *iinfo = UDF_I(inode);\nstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\nstruct kernel_lb_addr *iloc = &iinfo->i_location;\nunsigned int link_count;\nunsigned int indirections = 0;\nint ret = -EIO;\nreread:\nif (iloc->logicalBlockNum >=\nsbi->s_partmaps[iloc->partitionReferenceNum].s_partition_len) {\nudf_debug(\"block=%d, partition=%d out of range\\n\",\niloc->logicalBlockNum, iloc->partitionReferenceNum);\nreturn -EIO;\n}\nbh = udf_read_ptagged(inode->i_sb, iloc, 0, &ident);\nif (!bh) {\nudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\nreturn -EIO;\n}\nif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\nident != TAG_IDENT_USE) {\nudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\ninode->i_ino, ident);\ngoto out;\n}\nfe = (struct fileEntry *)bh->b_data;\nefe = (struct extendedFileEntry *)bh->b_data;\nif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\nstruct buffer_head *ibh;\nibh = udf_read_ptagged(inode->i_sb, iloc, 1, &ident);\nif (ident == TAG_IDENT_IE && ibh) {\nstruct kernel_lb_addr loc;\nstruct indirectEntry *ie;\nie = (struct indirectEntry *)ibh->b_data;\nloc = lelb_to_cpu(ie->indirectICB.extLocation);\nif (ie->indirectICB.extLength) {\nbrelse(ibh);\nmemcpy(&iinfo->i_location, &loc,\nsizeof(struct kernel_lb_addr));\nif (++indirections > UDF_MAX_ICB_NESTING) {\nudf_err(inode->i_sb,\n\"too many ICBs in ICB hierarchy\"\n\" (max %d supported)\\n\",\nUDF_MAX_ICB_NESTING);\ngoto out;\n}\nbrelse(bh);\ngoto reread;\n}\n}\nbrelse(ibh);\n} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\nudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\nle16_to_cpu(fe->icbTag.strategyType));\ngoto out;\n}\nif (fe->icbTag.strategyType == cpu_to_le16(4))\niinfo->i_strat4096 = 0;\nelse \niinfo->i_strat4096 = 1;\niinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\nICBTAG_FLAG_AD_MASK;\niinfo->i_unique = 0;\niinfo->i_lenEAttr = 0;\niinfo->i_lenExtents = 0;\niinfo->i_lenAlloc = 0;\niinfo->i_next_alloc_block = 0;\niinfo->i_next_alloc_goal = 0;\nif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\niinfo->i_efe = 1;\niinfo->i_use = 0;\nret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\nsizeof(struct extendedFileEntry));\nif (ret)\ngoto out;\nmemcpy(iinfo->i_ext.i_data,\nbh->b_data + sizeof(struct extendedFileEntry),\ninode->i_sb->s_blocksize -\nsizeof(struct extendedFileEntry));\n} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\niinfo->i_efe = 0;\niinfo->i_use = 0;\nret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\nsizeof(struct fileEntry));\nif (ret)\ngoto out;\nmemcpy(iinfo->i_ext.i_data,\nbh->b_data + sizeof(struct fileEntry),\ninode->i_sb->s_blocksize - sizeof(struct fileEntry));\n} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\niinfo->i_efe = 0;\niinfo->i_use = 1;\niinfo->i_lenAlloc = le32_to_cpu(\n((struct unallocSpaceEntry *)bh->b_data)->\nlengthAllocDescs);\nret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\nsizeof(struct unallocSpaceEntry));\nif (ret)\ngoto out;\nmemcpy(iinfo->i_ext.i_data,\nbh->b_data + sizeof(struct unallocSpaceEntry),\ninode->i_sb->s_blocksize -\nsizeof(struct unallocSpaceEntry));\nreturn 0;\n}\nret = -EIO;\nread_lock(&sbi->s_cred_lock);\ni_uid_write(inode, le32_to_cpu(fe->uid));\nif (!uid_valid(inode->i_uid) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\ninode->i_uid = UDF_SB(inode->i_sb)->s_uid;\ni_gid_write(inode, le32_to_cpu(fe->gid));\nif (!gid_valid(inode->i_gid) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\nUDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\ninode->i_gid = UDF_SB(inode->i_sb)->s_gid;\nif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\nsbi->s_fmode != UDF_INVALID_MODE)\ninode->i_mode = sbi->s_fmode;\nelse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\nsbi->s_dmode != UDF_INVALID_MODE)\ninode->i_mode = sbi->s_dmode;\nelse\ninode->i_mode = udf_convert_permissions(fe);\ninode->i_mode &= ~sbi->s_umask;\nread_unlock(&sbi->s_cred_lock);\nlink_count = le16_to_cpu(fe->fileLinkCount);\nif (!link_count) {\nif (!hidden_inode) {\nret = -ESTALE;\ngoto out;\n}\nlink_count = 1;\n}\nset_nlink(inode, link_count);\ninode->i_size = le64_to_cpu(fe->informationLength);\niinfo->i_lenExtents = inode->i_size;\nif (iinfo->i_efe == 0) {\ninode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n(inode->i_sb->s_blocksize_bits - 9);\nif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\ninode->i_atime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_mtime,\nfe->modificationTime))\ninode->i_mtime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\ninode->i_ctime = sbi->s_record_time;\niinfo->i_unique = le64_to_cpu(fe->uniqueID);\niinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\niinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\niinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n} else {\ninode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n(inode->i_sb->s_blocksize_bits - 9);\nif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\ninode->i_atime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_mtime,\nefe->modificationTime))\ninode->i_mtime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\niinfo->i_crtime = sbi->s_record_time;\nif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\ninode->i_ctime = sbi->s_record_time;\niinfo->i_unique = le64_to_cpu(efe->uniqueID);\niinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\niinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\niinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n}\ninode->i_generation = iinfo->i_unique;\nswitch (fe->icbTag.fileType) {\ncase ICBTAG_FILE_TYPE_DIRECTORY:\ninode->i_op = &udf_dir_inode_operations;\ninode->i_fop = &udf_dir_operations;\ninode->i_mode |= S_IFDIR;\ninc_nlink(inode);\nbreak;\ncase ICBTAG_FILE_TYPE_REALTIME:\ncase ICBTAG_FILE_TYPE_REGULAR:\ncase ICBTAG_FILE_TYPE_UNDEF:\ncase ICBTAG_FILE_TYPE_VAT20:\nif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\ninode->i_data.a_ops = &udf_adinicb_aops;\nelse\ninode->i_data.a_ops = &udf_aops;\ninode->i_op = &udf_file_inode_operations;\ninode->i_fop = &udf_file_operations;\ninode->i_mode |= S_IFREG;\nbreak;\ncase ICBTAG_FILE_TYPE_BLOCK:\ninode->i_mode |= S_IFBLK;\nbreak;\ncase ICBTAG_FILE_TYPE_CHAR:\ninode->i_mode |= S_IFCHR;\nbreak;\ncase ICBTAG_FILE_TYPE_FIFO:\ninit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\nbreak;\ncase ICBTAG_FILE_TYPE_SOCKET:\ninit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\nbreak;\ncase ICBTAG_FILE_TYPE_SYMLINK:\ninode->i_data.a_ops = &udf_symlink_aops;\ninode->i_op = &udf_symlink_inode_operations;\ninode->i_mode = S_IFLNK | S_IRWXUGO;\nbreak;\ncase ICBTAG_FILE_TYPE_MAIN:\nudf_debug(\"METADATA FILE-----\\n\");\nbreak;\ncase ICBTAG_FILE_TYPE_MIRROR:\nudf_debug(\"METADATA MIRROR FILE-----\\n\");\nbreak;\ncase ICBTAG_FILE_TYPE_BITMAP:\nudf_debug(\"METADATA BITMAP FILE-----\\n\");\nbreak;\ndefault:\nudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\ninode->i_ino, fe->icbTag.fileType);\ngoto out;\n}\nif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\nstruct deviceSpec *dsea =\n(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\nif (dsea) {\ninit_special_inode(inode, inode->i_mode,\nMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\nle32_to_cpu(dsea->minorDeviceIdent)));\n} else\ngoto out;\n}\nret = 0;\nout:\nbrelse(bh);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2015-1333": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for memory allocation and release based on the state of a data structure.",
        "trigger_condition": "Multiple system calls referencing existing keys without proper memory allocation and release handling.",
        "specific_code_behavior_causing_vulnerability": "The code snippet does not properly check the state of a data structure before performing memory allocation and editing operations, potentially leading to memory leaks if memory is allocated but not released.",
        "solution": "To mitigate the vulnerability, it is necessary to check the state of the data structure before performing memory allocation and editing operations. Specifically, the code should ensure that memory allocation and editing are only performed when the data structure is in the appropriate state. In this case, the solution involves modifying the code to check if the data structure is not NULL and then separately checking a specific condition before proceeding with memory allocation and editing operations."
      },
      "GPT_analysis": "The modification is necessary to prevent a memory leak vulnerability in the __key_link_end function. In the original code snippet, there is a condition that checks if `edit` is not NULL and `edit->dead_leaf` is false before performing memory allocation and editing operations. However, the code does not handle the case where `edit` is not NULL but `edit->dead_leaf` is true. This can lead to a memory leak issue where memory is allocated but not properly released, causing memory consumption over time.\n\nBy modifying the code to check if `edit` is not NULL and then separately checking if `edit->dead_leaf` is false before performing memory allocation and editing operations, we ensure that memory is only allocated and edited when necessary. This modification helps prevent the memory leak vulnerability described in CVE-2015-1333 by properly handling the conditions for memory allocation and release based on the state of the `edit` structure.",
      "GPT_purpose": "Release locks and resources associated with a keyring operation in the Linux kernel.",
      "GPT_function": "\n1. Release the keyring semaphore.\n2. Release the keyring serialise link semaphore.\n3. Check for a specific type of key and perform corresponding actions.\n4. Reserve key payload space and cancel edit if conditions are met.\n5. Release the keyring semaphore again.",
      "CVE_id": "CVE-2015-1333",
      "code_before_change": "void __key_link_end(struct key *keyring,\n\t\t    const struct keyring_index_key *index_key,\n\t\t    struct assoc_array_edit *edit)\n\t__releases(&keyring->sem)\n\t__releases(&keyring_serialise_link_sem)\n{\n\tBUG_ON(index_key->type == NULL);\n\tkenter(\"%d,%s,\", keyring->serial, index_key->type->name);\n\n\tif (index_key->type == &key_type_keyring)\n\t\tup_write(&keyring_serialise_link_sem);\n\n\tif (edit && !edit->dead_leaf) {\n\t\tkey_payload_reserve(keyring,\n\t\t\t\t    keyring->datalen - KEYQUOTA_LINK_BYTES);\n\t\tassoc_array_cancel_edit(edit);\n\t}\n\tup_write(&keyring->sem);\n}",
      "code_after_change": "void __key_link_end(struct key *keyring,\n\t\t    const struct keyring_index_key *index_key,\n\t\t    struct assoc_array_edit *edit)\n\t__releases(&keyring->sem)\n\t__releases(&keyring_serialise_link_sem)\n{\n\tBUG_ON(index_key->type == NULL);\n\tkenter(\"%d,%s,\", keyring->serial, index_key->type->name);\n\n\tif (index_key->type == &key_type_keyring)\n\t\tup_write(&keyring_serialise_link_sem);\n\n\tif (edit) {\n\t\tif (!edit->dead_leaf) {\n\t\t\tkey_payload_reserve(keyring,\n\t\t\t\tkeyring->datalen - KEYQUOTA_LINK_BYTES);\n\t\t}\n\t\tassoc_array_cancel_edit(edit);\n\t}\n\tup_write(&keyring->sem);\n}",
      "modified_lines": {
        "added": [
          "\tif (edit) {",
          "\t\tif (!edit->dead_leaf) {",
          "\t\t\tkey_payload_reserve(keyring,",
          "\t\t\t\tkeyring->datalen - KEYQUOTA_LINK_BYTES);",
          "\t\t}"
        ],
        "deleted": [
          "\tif (edit && !edit->dead_leaf) {",
          "\t\tkey_payload_reserve(keyring,",
          "\t\t\t\t    keyring->datalen - KEYQUOTA_LINK_BYTES);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for memory allocation and release based on the state of a data structure.",
      "trigger_condition": "Multiple system calls referencing existing keys without proper memory allocation and release handling.",
      "specific_code_behavior_causing_vulnerability": "The code snippet does not properly check the state of a data structure before performing memory allocation and editing operations, potentially leading to memory leaks if memory is allocated but not released.",
      "solution": "To mitigate the vulnerability, it is necessary to check the state of the data structure before performing memory allocation and editing operations. Specifically, the code should ensure that memory allocation and editing are only performed when the data structure is in the appropriate state. In this case, the solution involves modifying the code to check if the data structure is not NULL and then separately checking a specific condition before proceeding with memory allocation and editing operations.",
      "id": 66,
      "code_after_change_normalized": "void FUN1(struct key *VAR1,\nconst struct keyring_index_key *VAR2,\nstruct assoc_array_edit *VAR3)\nFUN2(&VAR1->VAR4)\nFUN2(&VAR5)\n{\nFUN3(VAR2->VAR6 == NULL);\nFUN4(\"STR\", VAR1->VAR7, VAR2->VAR6->VAR8);\nif (VAR2->VAR6 == &VAR9)\nFUN5(&VAR5);\nif (VAR3) {\nif (!VAR3->VAR10) {\nFUN6(VAR1,\nVAR1->VAR11 - VAR12);\n}\nFUN7(VAR3);\n}\nFUN5(&VAR1->VAR4);\n}\n",
      "code_before_change_normalized": "void FUN1(struct key *VAR1,\nconst struct keyring_index_key *VAR2,\nstruct assoc_array_edit *VAR3)\nFUN2(&VAR1->VAR4)\nFUN2(&VAR5)\n{\nFUN3(VAR2->VAR6 == NULL);\nFUN4(\"STR\", VAR1->VAR7, VAR2->VAR6->VAR8);\nif (VAR2->VAR6 == &VAR9)\nFUN5(&VAR5);\nif (VAR3 && !VAR3->VAR10) {\nFUN6(VAR1,\nVAR1->VAR11 - VAR12);\nFUN7(VAR3);\n}\nFUN5(&VAR1->VAR4);\n}\n",
      "code_after_change_raw": "void __key_link_end(struct key *keyring,\nconst struct keyring_index_key *index_key,\nstruct assoc_array_edit *edit)\n__releases(&keyring->sem)\n__releases(&keyring_serialise_link_sem)\n{\nBUG_ON(index_key->type == NULL);\nkenter(\"%d,%s,\", keyring->serial, index_key->type->name);\nif (index_key->type == &key_type_keyring)\nup_write(&keyring_serialise_link_sem);\nif (edit) {\nif (!edit->dead_leaf) {\nkey_payload_reserve(keyring,\nkeyring->datalen - KEYQUOTA_LINK_BYTES);\n}\nassoc_array_cancel_edit(edit);\n}\nup_write(&keyring->sem);\n}\n",
      "code_before_change_raw": "void __key_link_end(struct key *keyring,\nconst struct keyring_index_key *index_key,\nstruct assoc_array_edit *edit)\n__releases(&keyring->sem)\n__releases(&keyring_serialise_link_sem)\n{\nBUG_ON(index_key->type == NULL);\nkenter(\"%d,%s,\", keyring->serial, index_key->type->name);\nif (index_key->type == &key_type_keyring)\nup_write(&keyring_serialise_link_sem);\nif (edit && !edit->dead_leaf) {\nkey_payload_reserve(keyring,\nkeyring->datalen - KEYQUOTA_LINK_BYTES);\nassoc_array_cancel_edit(edit);\n}\nup_write(&keyring->sem);\n}\n"
    }
  ],
  "CVE-2015-2666": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of boundary checking when saving microcode patches in the mc_saved_tmp array.",
        "trigger_condition": "An attacker constructs a crafted microcode header to overflow the mc_saved_tmp array, potentially gaining privileges.",
        "specific_code_behavior_causing_vulnerability": "The code iterates over microcode patches without checking the array size of mc_saved_tmp, allowing a potential buffer overflow if too many patches are saved.",
        "solution": "To mitigate the vulnerability, it is necessary to add a condition to the while loop to check if the mc_saved_count is less than the array size of mc_saved_tmp before saving additional microcode patches. This ensures that the code does not overflow the mc_saved_tmp array and prevents potential privilege escalation through a crafted microcode header."
      },
      "GPT_analysis": "The modification is necessary to prevent a stack-based buffer overflow vulnerability in the `get_matching_model_microcode` function. By adding the condition `mc_saved_count < ARRAY_SIZE(mc_saved_tmp)` to the `while` loop, the code ensures that the `mc_saved_tmp` array does not overflow.\n\nThe vulnerability CVE-2015-2666 occurs due to the lack of boundary checking when saving microcode patches in the `mc_saved_tmp` array. An attacker could construct a crafted microcode header to exploit this vulnerability and potentially gain privileges by overflowing the `mc_saved_tmp` array.\n\nBy adding the condition `mc_saved_count < ARRAY_SIZE(mc_saved_tmp)`, the code ensures that the loop will only continue as long as there is space available in the `mc_saved_tmp` array to store microcode patches. This prevents the buffer overflow vulnerability and helps to secure the function against potential attacks.",
      "GPT_purpose": "This function is used to retrieve and save microcode patches with the same family and model as the BSP (Boot Strap Processor) in the Linux kernel.",
      "GPT_function": "\n1. Iterates through microcode data to find and save patches with the same family and model as the BSP.\n2. Checks microcode size and performs a sanity check.\n3. Saves matching microcode patches.\n4. Handles error cases and updates the state accordingly.",
      "CVE_id": "CVE-2015-2666",
      "code_before_change": "static enum ucode_state __init\nget_matching_model_microcode(int cpu, unsigned long start,\n\t\t\t     void *data, size_t size,\n\t\t\t     struct mc_saved_data *mc_saved_data,\n\t\t\t     unsigned long *mc_saved_in_initrd,\n\t\t\t     struct ucode_cpu_info *uci)\n{\n\tu8 *ucode_ptr = data;\n\tunsigned int leftover = size;\n\tenum ucode_state state = UCODE_OK;\n\tunsigned int mc_size;\n\tstruct microcode_header_intel *mc_header;\n\tstruct microcode_intel *mc_saved_tmp[MAX_UCODE_COUNT];\n\tunsigned int mc_saved_count = mc_saved_data->mc_saved_count;\n\tint i;\n\n\twhile (leftover) {\n\t\tmc_header = (struct microcode_header_intel *)ucode_ptr;\n\n\t\tmc_size = get_totalsize(mc_header);\n\t\tif (!mc_size || mc_size > leftover ||\n\t\t\tmicrocode_sanity_check(ucode_ptr, 0) < 0)\n\t\t\tbreak;\n\n\t\tleftover -= mc_size;\n\n\t\t/*\n\t\t * Since APs with same family and model as the BSP may boot in\n\t\t * the platform, we need to find and save microcode patches\n\t\t * with the same family and model as the BSP.\n\t\t */\n\t\tif (matching_model_microcode(mc_header, uci->cpu_sig.sig) !=\n\t\t\t UCODE_OK) {\n\t\t\tucode_ptr += mc_size;\n\t\t\tcontinue;\n\t\t}\n\n\t\t_save_mc(mc_saved_tmp, ucode_ptr, &mc_saved_count);\n\n\t\tucode_ptr += mc_size;\n\t}\n\n\tif (leftover) {\n\t\tstate = UCODE_ERROR;\n\t\tgoto out;\n\t}\n\n\tif (mc_saved_count == 0) {\n\t\tstate = UCODE_NFOUND;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < mc_saved_count; i++)\n\t\tmc_saved_in_initrd[i] = (unsigned long)mc_saved_tmp[i] - start;\n\n\tmc_saved_data->mc_saved_count = mc_saved_count;\nout:\n\treturn state;\n}",
      "code_after_change": "static enum ucode_state __init\nget_matching_model_microcode(int cpu, unsigned long start,\n\t\t\t     void *data, size_t size,\n\t\t\t     struct mc_saved_data *mc_saved_data,\n\t\t\t     unsigned long *mc_saved_in_initrd,\n\t\t\t     struct ucode_cpu_info *uci)\n{\n\tu8 *ucode_ptr = data;\n\tunsigned int leftover = size;\n\tenum ucode_state state = UCODE_OK;\n\tunsigned int mc_size;\n\tstruct microcode_header_intel *mc_header;\n\tstruct microcode_intel *mc_saved_tmp[MAX_UCODE_COUNT];\n\tunsigned int mc_saved_count = mc_saved_data->mc_saved_count;\n\tint i;\n\n\twhile (leftover && mc_saved_count < ARRAY_SIZE(mc_saved_tmp)) {\n\t\tmc_header = (struct microcode_header_intel *)ucode_ptr;\n\n\t\tmc_size = get_totalsize(mc_header);\n\t\tif (!mc_size || mc_size > leftover ||\n\t\t\tmicrocode_sanity_check(ucode_ptr, 0) < 0)\n\t\t\tbreak;\n\n\t\tleftover -= mc_size;\n\n\t\t/*\n\t\t * Since APs with same family and model as the BSP may boot in\n\t\t * the platform, we need to find and save microcode patches\n\t\t * with the same family and model as the BSP.\n\t\t */\n\t\tif (matching_model_microcode(mc_header, uci->cpu_sig.sig) !=\n\t\t\t UCODE_OK) {\n\t\t\tucode_ptr += mc_size;\n\t\t\tcontinue;\n\t\t}\n\n\t\t_save_mc(mc_saved_tmp, ucode_ptr, &mc_saved_count);\n\n\t\tucode_ptr += mc_size;\n\t}\n\n\tif (leftover) {\n\t\tstate = UCODE_ERROR;\n\t\tgoto out;\n\t}\n\n\tif (mc_saved_count == 0) {\n\t\tstate = UCODE_NFOUND;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < mc_saved_count; i++)\n\t\tmc_saved_in_initrd[i] = (unsigned long)mc_saved_tmp[i] - start;\n\n\tmc_saved_data->mc_saved_count = mc_saved_count;\nout:\n\treturn state;\n}",
      "modified_lines": {
        "added": [
          "\twhile (leftover && mc_saved_count < ARRAY_SIZE(mc_saved_tmp)) {"
        ],
        "deleted": [
          "\twhile (leftover) {"
        ]
      },
      "preconditions_for_vulnerability": "Lack of boundary checking when saving microcode patches in the mc_saved_tmp array.",
      "trigger_condition": "An attacker constructs a crafted microcode header to overflow the mc_saved_tmp array, potentially gaining privileges.",
      "specific_code_behavior_causing_vulnerability": "The code iterates over microcode patches without checking the array size of mc_saved_tmp, allowing a potential buffer overflow if too many patches are saved.",
      "solution": "To mitigate the vulnerability, it is necessary to add a condition to the while loop to check if the mc_saved_count is less than the array size of mc_saved_tmp before saving additional microcode patches. This ensures that the code does not overflow the mc_saved_tmp array and prevents potential privilege escalation through a crafted microcode header.",
      "id": 67,
      "code_after_change_normalized": "static enum ucode_state VAR1\nFUN1(int VAR2, unsigned long VAR3,\nvoid *VAR4, size_t VAR5,\nstruct VAR6 *VAR6,\nunsigned long *VAR7,\nstruct ucode_cpu_info *VAR8)\n{\nu8 *VAR9 = VAR4;\nunsigned int VAR10 = VAR5;\nenum ucode_state VAR11 = VAR12;\nunsigned int VAR13;\nstruct microcode_header_intel *VAR14;\nstruct microcode_intel *VAR15[VAR16];\nunsigned int VAR17 = VAR6->VAR17;\nint VAR18;\nwhile (VAR10 && VAR17 < FUN2(VAR15)) {\nVAR14 = (struct VAR19 *)VAR9;\nVAR13 = FUN3(VAR14);\nif (!VAR13 || VAR13 > VAR10 ||\nFUN4(VAR9, 0) < 0)\nbreak;\nVAR10 -= VAR13;\nif (FUN5(VAR14, VAR8->VAR20.VAR21) !=\nVAR12) {\nVAR9 += VAR13;\ncontinue;\n}\nFUN6(VAR15, VAR9, &VAR17);\nVAR9 += VAR13;\n}\nif (VAR10) {\nVAR11 = VAR22;\ngoto VAR23;\n}\nif (VAR17 == 0) {\nVAR11 = VAR24;\ngoto VAR23;\n}\nfor (VAR18 = 0; VAR18 < VAR17; VAR18++)\nVAR7[VAR18] = (unsigned long)VAR15[VAR18] - VAR3;\nVAR6->VAR17 = VAR17;\nVAR23:\nreturn VAR11;\n}\n",
      "code_before_change_normalized": "static enum ucode_state VAR1\nFUN1(int VAR2, unsigned long VAR3,\nvoid *VAR4, size_t VAR5,\nstruct VAR6 *VAR6,\nunsigned long *VAR7,\nstruct ucode_cpu_info *VAR8)\n{\nu8 *VAR9 = VAR4;\nunsigned int VAR10 = VAR5;\nenum ucode_state VAR11 = VAR12;\nunsigned int VAR13;\nstruct microcode_header_intel *VAR14;\nstruct microcode_intel *VAR15[VAR16];\nunsigned int VAR17 = VAR6->VAR17;\nint VAR18;\nwhile (VAR10) {\nVAR14 = (struct VAR19 *)VAR9;\nVAR13 = FUN2(VAR14);\nif (!VAR13 || VAR13 > VAR10 ||\nFUN3(VAR9, 0) < 0)\nbreak;\nVAR10 -= VAR13;\nif (FUN4(VAR14, VAR8->VAR20.VAR21) !=\nVAR12) {\nVAR9 += VAR13;\ncontinue;\n}\nFUN5(VAR15, VAR9, &VAR17);\nVAR9 += VAR13;\n}\nif (VAR10) {\nVAR11 = VAR22;\ngoto VAR23;\n}\nif (VAR17 == 0) {\nVAR11 = VAR24;\ngoto VAR23;\n}\nfor (VAR18 = 0; VAR18 < VAR17; VAR18++)\nVAR7[VAR18] = (unsigned long)VAR15[VAR18] - VAR3;\nVAR6->VAR17 = VAR17;\nVAR23:\nreturn VAR11;\n}\n",
      "code_after_change_raw": "static enum ucode_state __init\nget_matching_model_microcode(int cpu, unsigned long start,\nvoid *data, size_t size,\nstruct mc_saved_data *mc_saved_data,\nunsigned long *mc_saved_in_initrd,\nstruct ucode_cpu_info *uci)\n{\nu8 *ucode_ptr = data;\nunsigned int leftover = size;\nenum ucode_state state = UCODE_OK;\nunsigned int mc_size;\nstruct microcode_header_intel *mc_header;\nstruct microcode_intel *mc_saved_tmp[MAX_UCODE_COUNT];\nunsigned int mc_saved_count = mc_saved_data->mc_saved_count;\nint i;\nwhile (leftover && mc_saved_count < ARRAY_SIZE(mc_saved_tmp)) {\nmc_header = (struct microcode_header_intel *)ucode_ptr;\nmc_size = get_totalsize(mc_header);\nif (!mc_size || mc_size > leftover ||\nmicrocode_sanity_check(ucode_ptr, 0) < 0)\nbreak;\nleftover -= mc_size;\nif (matching_model_microcode(mc_header, uci->cpu_sig.sig) !=\nUCODE_OK) {\nucode_ptr += mc_size;\ncontinue;\n}\n_save_mc(mc_saved_tmp, ucode_ptr, &mc_saved_count);\nucode_ptr += mc_size;\n}\nif (leftover) {\nstate = UCODE_ERROR;\ngoto out;\n}\nif (mc_saved_count == 0) {\nstate = UCODE_NFOUND;\ngoto out;\n}\nfor (i = 0; i < mc_saved_count; i++)\nmc_saved_in_initrd[i] = (unsigned long)mc_saved_tmp[i] - start;\nmc_saved_data->mc_saved_count = mc_saved_count;\nout:\nreturn state;\n}\n",
      "code_before_change_raw": "static enum ucode_state __init\nget_matching_model_microcode(int cpu, unsigned long start,\nvoid *data, size_t size,\nstruct mc_saved_data *mc_saved_data,\nunsigned long *mc_saved_in_initrd,\nstruct ucode_cpu_info *uci)\n{\nu8 *ucode_ptr = data;\nunsigned int leftover = size;\nenum ucode_state state = UCODE_OK;\nunsigned int mc_size;\nstruct microcode_header_intel *mc_header;\nstruct microcode_intel *mc_saved_tmp[MAX_UCODE_COUNT];\nunsigned int mc_saved_count = mc_saved_data->mc_saved_count;\nint i;\nwhile (leftover) {\nmc_header = (struct microcode_header_intel *)ucode_ptr;\nmc_size = get_totalsize(mc_header);\nif (!mc_size || mc_size > leftover ||\nmicrocode_sanity_check(ucode_ptr, 0) < 0)\nbreak;\nleftover -= mc_size;\nif (matching_model_microcode(mc_header, uci->cpu_sig.sig) !=\nUCODE_OK) {\nucode_ptr += mc_size;\ncontinue;\n}\n_save_mc(mc_saved_tmp, ucode_ptr, &mc_saved_count);\nucode_ptr += mc_size;\n}\nif (leftover) {\nstate = UCODE_ERROR;\ngoto out;\n}\nif (mc_saved_count == 0) {\nstate = UCODE_NFOUND;\ngoto out;\n}\nfor (i = 0; i < mc_saved_count; i++)\nmc_saved_in_initrd[i] = (unsigned long)mc_saved_tmp[i] - start;\nmc_saved_data->mc_saved_count = mc_saved_count;\nout:\nreturn state;\n}\n"
    }
  ],
  "CVE-2015-3214": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of distinction between read lengths and write lengths in the code logic.",
        "trigger_condition": "Guest OS users trigger use of an invalid index during read operations, leading to arbitrary code execution on the host OS.",
        "specific_code_behavior_causing_vulnerability": "The code does not differentiate between read lengths and write lengths, allowing for potential exploitation of an invalid index during read operations, which can result in arbitrary code execution on the host OS."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to distinguish between read lengths and write lengths in the code logic. Specifically, adding a condition to return early if the address corresponds to an invalid index helps prevent the exploitation of the vulnerability. This ensures that the code handles read operations securely and reduces the risk of arbitrary code execution on the host OS.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2015-3214, which arises from the pit_ioport_read function not distinguishing between read lengths and write lengths. By adding the check `if (addr == 3) return 0;`, the modified code ensures that if the address is 3, the function will return 0 without proceeding further. This prevents potential exploitation of the vulnerability by invalid index usage, which could lead to arbitrary code execution on the host OS. By adding this check, the code becomes more secure and mitigates the risk associated with the vulnerability.",
      "GPT_purpose": "Read data from the Programmable Interval Timer (PIT) device in a virtualized environment.",
      "GPT_function": "\n1. Read from the PIT I/O port.\n2. Handle different read states and count latched values.\n3. Copy the read data to the provided buffer.",
      "CVE_id": "CVE-2015-3214",
      "code_before_change": "static int pit_ioport_read(struct kvm_io_device *this,\n\t\t\t   gpa_t addr, int len, void *data)\n{\n\tstruct kvm_pit *pit = dev_to_pit(this);\n\tstruct kvm_kpit_state *pit_state = &pit->pit_state;\n\tstruct kvm *kvm = pit->kvm;\n\tint ret, count;\n\tstruct kvm_kpit_channel_state *s;\n\tif (!pit_in_range(addr))\n\t\treturn -EOPNOTSUPP;\n\n\taddr &= KVM_PIT_CHANNEL_MASK;\n\ts = &pit_state->channels[addr];\n\n\tmutex_lock(&pit_state->lock);\n\n\tif (s->status_latched) {\n\t\ts->status_latched = 0;\n\t\tret = s->status;\n\t} else if (s->count_latched) {\n\t\tswitch (s->count_latched) {\n\t\tdefault:\n\t\tcase RW_STATE_LSB:\n\t\t\tret = s->latched_count & 0xff;\n\t\t\ts->count_latched = 0;\n\t\t\tbreak;\n\t\tcase RW_STATE_MSB:\n\t\t\tret = s->latched_count >> 8;\n\t\t\ts->count_latched = 0;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD0:\n\t\t\tret = s->latched_count & 0xff;\n\t\t\ts->count_latched = RW_STATE_MSB;\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tswitch (s->read_state) {\n\t\tdefault:\n\t\tcase RW_STATE_LSB:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = count & 0xff;\n\t\t\tbreak;\n\t\tcase RW_STATE_MSB:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = (count >> 8) & 0xff;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD0:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = count & 0xff;\n\t\t\ts->read_state = RW_STATE_WORD1;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD1:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = (count >> 8) & 0xff;\n\t\t\ts->read_state = RW_STATE_WORD0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (len > sizeof(ret))\n\t\tlen = sizeof(ret);\n\tmemcpy(data, (char *)&ret, len);\n\n\tmutex_unlock(&pit_state->lock);\n\treturn 0;\n}",
      "code_after_change": "static int pit_ioport_read(struct kvm_io_device *this,\n\t\t\t   gpa_t addr, int len, void *data)\n{\n\tstruct kvm_pit *pit = dev_to_pit(this);\n\tstruct kvm_kpit_state *pit_state = &pit->pit_state;\n\tstruct kvm *kvm = pit->kvm;\n\tint ret, count;\n\tstruct kvm_kpit_channel_state *s;\n\tif (!pit_in_range(addr))\n\t\treturn -EOPNOTSUPP;\n\n\taddr &= KVM_PIT_CHANNEL_MASK;\n\tif (addr == 3)\n\t\treturn 0;\n\n\ts = &pit_state->channels[addr];\n\n\tmutex_lock(&pit_state->lock);\n\n\tif (s->status_latched) {\n\t\ts->status_latched = 0;\n\t\tret = s->status;\n\t} else if (s->count_latched) {\n\t\tswitch (s->count_latched) {\n\t\tdefault:\n\t\tcase RW_STATE_LSB:\n\t\t\tret = s->latched_count & 0xff;\n\t\t\ts->count_latched = 0;\n\t\t\tbreak;\n\t\tcase RW_STATE_MSB:\n\t\t\tret = s->latched_count >> 8;\n\t\t\ts->count_latched = 0;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD0:\n\t\t\tret = s->latched_count & 0xff;\n\t\t\ts->count_latched = RW_STATE_MSB;\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tswitch (s->read_state) {\n\t\tdefault:\n\t\tcase RW_STATE_LSB:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = count & 0xff;\n\t\t\tbreak;\n\t\tcase RW_STATE_MSB:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = (count >> 8) & 0xff;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD0:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = count & 0xff;\n\t\t\ts->read_state = RW_STATE_WORD1;\n\t\t\tbreak;\n\t\tcase RW_STATE_WORD1:\n\t\t\tcount = pit_get_count(kvm, addr);\n\t\t\tret = (count >> 8) & 0xff;\n\t\t\ts->read_state = RW_STATE_WORD0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (len > sizeof(ret))\n\t\tlen = sizeof(ret);\n\tmemcpy(data, (char *)&ret, len);\n\n\tmutex_unlock(&pit_state->lock);\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tif (addr == 3)",
          "\t\treturn 0;",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of distinction between read lengths and write lengths in the code logic.",
      "trigger_condition": "Guest OS users trigger use of an invalid index during read operations, leading to arbitrary code execution on the host OS.",
      "specific_code_behavior_causing_vulnerability": "The code does not differentiate between read lengths and write lengths, allowing for potential exploitation of an invalid index during read operations, which can result in arbitrary code execution on the host OS.",
      "id": 68,
      "code_after_change_normalized": "static int FUN1(struct kvm_io_device *this,\ngpa_t VAR1, int VAR2, void *VAR3)\n{\nstruct kvm_pit *VAR4 = FUN2(this);\nstruct kvm_kpit_state *VAR5 = &VAR4->VAR5;\nstruct VAR6 *VAR6 = VAR4->VAR6;\nint VAR7, VAR8;\nstruct kvm_kpit_channel_state *VAR9;\nif (!FUN3(VAR1))\nreturn -VAR10;\nVAR1 &= VAR11;\nif (VAR1 == 3)\nreturn 0;\nVAR9 = &VAR5->VAR12[VAR1];\nFUN4(&VAR5->VAR13);\nif (VAR9->VAR14) {\nVAR9->VAR14 = 0;\nVAR7 = VAR9->VAR15;\n} else if (VAR9->VAR16) {\nswitch (VAR9->VAR16) {\ndefault:\ncase VAR17:\nVAR7 = VAR9->VAR18 & VAR19;\nVAR9->VAR16 = 0;\nbreak;\ncase VAR20:\nVAR7 = VAR9->VAR18 >> 8;\nVAR9->VAR16 = 0;\nbreak;\ncase VAR21:\nVAR7 = VAR9->VAR18 & VAR19;\nVAR9->VAR16 = VAR20;\nbreak;\n}\n} else {\nswitch (VAR9->VAR22) {\ndefault:\ncase VAR17:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = VAR8 & VAR19;\nbreak;\ncase VAR20:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = (VAR8 >> 8) & VAR19;\nbreak;\ncase VAR21:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = VAR8 & VAR19;\nVAR9->VAR22 = VAR23;\nbreak;\ncase VAR23:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = (VAR8 >> 8) & VAR19;\nVAR9->VAR22 = VAR21;\nbreak;\n}\n}\nif (VAR2 > sizeof(VAR7))\nVAR2 = sizeof(VAR7);\nFUN6(VAR3, (char *)&VAR7, VAR2);\nFUN7(&VAR5->VAR13);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct kvm_io_device *this,\ngpa_t VAR1, int VAR2, void *VAR3)\n{\nstruct kvm_pit *VAR4 = FUN2(this);\nstruct kvm_kpit_state *VAR5 = &VAR4->VAR5;\nstruct VAR6 *VAR6 = VAR4->VAR6;\nint VAR7, VAR8;\nstruct kvm_kpit_channel_state *VAR9;\nif (!FUN3(VAR1))\nreturn -VAR10;\nVAR1 &= VAR11;\nVAR9 = &VAR5->VAR12[VAR1];\nFUN4(&VAR5->VAR13);\nif (VAR9->VAR14) {\nVAR9->VAR14 = 0;\nVAR7 = VAR9->VAR15;\n} else if (VAR9->VAR16) {\nswitch (VAR9->VAR16) {\ndefault:\ncase VAR17:\nVAR7 = VAR9->VAR18 & VAR19;\nVAR9->VAR16 = 0;\nbreak;\ncase VAR20:\nVAR7 = VAR9->VAR18 >> 8;\nVAR9->VAR16 = 0;\nbreak;\ncase VAR21:\nVAR7 = VAR9->VAR18 & VAR19;\nVAR9->VAR16 = VAR20;\nbreak;\n}\n} else {\nswitch (VAR9->VAR22) {\ndefault:\ncase VAR17:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = VAR8 & VAR19;\nbreak;\ncase VAR20:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = (VAR8 >> 8) & VAR19;\nbreak;\ncase VAR21:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = VAR8 & VAR19;\nVAR9->VAR22 = VAR23;\nbreak;\ncase VAR23:\nVAR8 = FUN5(VAR6, VAR1);\nVAR7 = (VAR8 >> 8) & VAR19;\nVAR9->VAR22 = VAR21;\nbreak;\n}\n}\nif (VAR2 > sizeof(VAR7))\nVAR2 = sizeof(VAR7);\nFUN6(VAR3, (char *)&VAR7, VAR2);\nFUN7(&VAR5->VAR13);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int pit_ioport_read(struct kvm_io_device *this,\ngpa_t addr, int len, void *data)\n{\nstruct kvm_pit *pit = dev_to_pit(this);\nstruct kvm_kpit_state *pit_state = &pit->pit_state;\nstruct kvm *kvm = pit->kvm;\nint ret, count;\nstruct kvm_kpit_channel_state *s;\nif (!pit_in_range(addr))\nreturn -EOPNOTSUPP;\naddr &= KVM_PIT_CHANNEL_MASK;\nif (addr == 3)\nreturn 0;\ns = &pit_state->channels[addr];\nmutex_lock(&pit_state->lock);\nif (s->status_latched) {\ns->status_latched = 0;\nret = s->status;\n} else if (s->count_latched) {\nswitch (s->count_latched) {\ndefault:\ncase RW_STATE_LSB:\nret = s->latched_count & 0xff;\ns->count_latched = 0;\nbreak;\ncase RW_STATE_MSB:\nret = s->latched_count >> 8;\ns->count_latched = 0;\nbreak;\ncase RW_STATE_WORD0:\nret = s->latched_count & 0xff;\ns->count_latched = RW_STATE_MSB;\nbreak;\n}\n} else {\nswitch (s->read_state) {\ndefault:\ncase RW_STATE_LSB:\ncount = pit_get_count(kvm, addr);\nret = count & 0xff;\nbreak;\ncase RW_STATE_MSB:\ncount = pit_get_count(kvm, addr);\nret = (count >> 8) & 0xff;\nbreak;\ncase RW_STATE_WORD0:\ncount = pit_get_count(kvm, addr);\nret = count & 0xff;\ns->read_state = RW_STATE_WORD1;\nbreak;\ncase RW_STATE_WORD1:\ncount = pit_get_count(kvm, addr);\nret = (count >> 8) & 0xff;\ns->read_state = RW_STATE_WORD0;\nbreak;\n}\n}\nif (len > sizeof(ret))\nlen = sizeof(ret);\nmemcpy(data, (char *)&ret, len);\nmutex_unlock(&pit_state->lock);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int pit_ioport_read(struct kvm_io_device *this,\ngpa_t addr, int len, void *data)\n{\nstruct kvm_pit *pit = dev_to_pit(this);\nstruct kvm_kpit_state *pit_state = &pit->pit_state;\nstruct kvm *kvm = pit->kvm;\nint ret, count;\nstruct kvm_kpit_channel_state *s;\nif (!pit_in_range(addr))\nreturn -EOPNOTSUPP;\naddr &= KVM_PIT_CHANNEL_MASK;\ns = &pit_state->channels[addr];\nmutex_lock(&pit_state->lock);\nif (s->status_latched) {\ns->status_latched = 0;\nret = s->status;\n} else if (s->count_latched) {\nswitch (s->count_latched) {\ndefault:\ncase RW_STATE_LSB:\nret = s->latched_count & 0xff;\ns->count_latched = 0;\nbreak;\ncase RW_STATE_MSB:\nret = s->latched_count >> 8;\ns->count_latched = 0;\nbreak;\ncase RW_STATE_WORD0:\nret = s->latched_count & 0xff;\ns->count_latched = RW_STATE_MSB;\nbreak;\n}\n} else {\nswitch (s->read_state) {\ndefault:\ncase RW_STATE_LSB:\ncount = pit_get_count(kvm, addr);\nret = count & 0xff;\nbreak;\ncase RW_STATE_MSB:\ncount = pit_get_count(kvm, addr);\nret = (count >> 8) & 0xff;\nbreak;\ncase RW_STATE_WORD0:\ncount = pit_get_count(kvm, addr);\nret = count & 0xff;\ns->read_state = RW_STATE_WORD1;\nbreak;\ncase RW_STATE_WORD1:\ncount = pit_get_count(kvm, addr);\nret = (count >> 8) & 0xff;\ns->read_state = RW_STATE_WORD0;\nbreak;\n}\n}\nif (len > sizeof(ret))\nlen = sizeof(ret);\nmemcpy(data, (char *)&ret, len);\nmutex_unlock(&pit_state->lock);\nreturn 0;\n}\n"
    }
  ],
  "CVE-2015-3331": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper memory handling during buffer allocation and calculation of memory locations for encrypted data.",
        "trigger_condition": "The code allocates memory for 'src' and 'assoc' buffers based on incorrect calculations, leading to potential buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code incorrectly calculates the memory location for the 'assoc' buffer as (src + req->cryptlen + auth_tag_len), which may result in writing beyond the allocated memory region for 'src' and 'assoc', causing a buffer overflow.",
        "solution": "To mitigate the vulnerability, it is necessary to adjust the calculation for the 'assoc' pointer to (src + req->cryptlen) to ensure that memory is accessed within the bounds of the allocated buffer for 'src'. This correction helps prevent buffer overflows and ensures proper memory handling."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to fix a vulnerability identified as CVE-2015-3331. The vulnerability arises from improper memory handling in the __driver_rfc4106_decrypt function, which can lead to a buffer overflow and system crash or potentially allow an attacker to execute arbitrary code.\n\nThe vulnerability occurs when allocating memory for the 'src' and 'assoc' buffers in the else block of the code. The original code allocates memory for 'src' as req->cryptlen + req->assoclen, but then calculates the 'assoc' pointer incorrectly as (src + req->cryptlen + auth_tag_len). This calculation may lead to writing beyond the allocated memory region for 'src' and 'assoc', causing a buffer overflow.\n\nThe modification corrects this issue by adjusting the calculation for the 'assoc' pointer to (src + req->cryptlen) to ensure that memory is accessed within the bounds of the allocated buffer for 'src'. This change helps prevent buffer overflows and ensures proper memory handling, addressing the vulnerability and enhancing the security of the code.",
      "GPT_purpose": "Decrypting data using the AES-GCM algorithm with RFC4106 mode and checking the authenticity of the decrypted data.",
      "GPT_function": "\n1. Decrypts data using the AESNI RFC4106 algorithm.\n2. Checks for valid input parameters and key length.\n3. Handles memory allocation and mapping for input and output data.\n4. Performs AES-GCM decryption with the provided parameters.\n5. Compares the generated authentication tag with the input tag to verify integrity.\n6. Cleans up allocated memory and scatterwalk structures after decryption.",
      "CVE_id": "CVE-2015-3331",
      "code_before_change": "static int __driver_rfc4106_decrypt(struct aead_request *req)\n{\n\tu8 one_entry_in_sg = 0;\n\tu8 *src, *dst, *assoc;\n\tunsigned long tempCipherLen = 0;\n\t__be32 counter = cpu_to_be32(1);\n\tint retval = 0;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\tu32 key_len = ctx->aes_key_expanded.key_length;\n\tvoid *aes_ctx = &(ctx->aes_key_expanded);\n\tunsigned long auth_tag_len = crypto_aead_authsize(tfm);\n\tu8 iv_and_authTag[32+AESNI_ALIGN];\n\tu8 *iv = (u8 *) PTR_ALIGN((u8 *)iv_and_authTag, AESNI_ALIGN);\n\tu8 *authTag = iv + 16;\n\tstruct scatter_walk src_sg_walk;\n\tstruct scatter_walk assoc_sg_walk;\n\tstruct scatter_walk dst_sg_walk;\n\tunsigned int i;\n\n\tif (unlikely((req->cryptlen < auth_tag_len) ||\n\t\t(req->assoclen != 8 && req->assoclen != 12)))\n\t\treturn -EINVAL;\n\tif (unlikely(auth_tag_len != 8 && auth_tag_len != 12 && auth_tag_len != 16))\n\t        return -EINVAL;\n\tif (unlikely(key_len != AES_KEYSIZE_128 &&\n\t             key_len != AES_KEYSIZE_192 &&\n\t             key_len != AES_KEYSIZE_256))\n\t        return -EINVAL;\n\n\t/* Assuming we are supporting rfc4106 64-bit extended */\n\t/* sequence numbers We need to have the AAD length */\n\t/* equal to 8 or 12 bytes */\n\n\ttempCipherLen = (unsigned long)(req->cryptlen - auth_tag_len);\n\t/* IV below built */\n\tfor (i = 0; i < 4; i++)\n\t\t*(iv+i) = ctx->nonce[i];\n\tfor (i = 0; i < 8; i++)\n\t\t*(iv+4+i) = req->iv[i];\n\t*((__be32 *)(iv+12)) = counter;\n\n\tif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\n\t\tone_entry_in_sg = 1;\n\t\tscatterwalk_start(&src_sg_walk, req->src);\n\t\tscatterwalk_start(&assoc_sg_walk, req->assoc);\n\t\tsrc = scatterwalk_map(&src_sg_walk);\n\t\tassoc = scatterwalk_map(&assoc_sg_walk);\n\t\tdst = src;\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_start(&dst_sg_walk, req->dst);\n\t\t\tdst = scatterwalk_map(&dst_sg_walk);\n\t\t}\n\n\t} else {\n\t\t/* Allocate memory for src, dst, assoc */\n\t\tsrc = kmalloc(req->cryptlen + req->assoclen, GFP_ATOMIC);\n\t\tif (!src)\n\t\t\treturn -ENOMEM;\n\t\tassoc = (src + req->cryptlen + auth_tag_len);\n\t\tscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\n\t\tscatterwalk_map_and_copy(assoc, req->assoc, 0,\n\t\t\treq->assoclen, 0);\n\t\tdst = src;\n\t}\n\n\taesni_gcm_dec_tfm(aes_ctx, dst, src, tempCipherLen, iv,\n\t\tctx->hash_subkey, assoc, (unsigned long)req->assoclen,\n\t\tauthTag, auth_tag_len);\n\n\t/* Compare generated tag with passed in tag. */\n\tretval = crypto_memneq(src + tempCipherLen, authTag, auth_tag_len) ?\n\t\t-EBADMSG : 0;\n\n\tif (one_entry_in_sg) {\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_unmap(dst);\n\t\t\tscatterwalk_done(&dst_sg_walk, 0, 0);\n\t\t}\n\t\tscatterwalk_unmap(src);\n\t\tscatterwalk_unmap(assoc);\n\t\tscatterwalk_done(&src_sg_walk, 0, 0);\n\t\tscatterwalk_done(&assoc_sg_walk, 0, 0);\n\t} else {\n\t\tscatterwalk_map_and_copy(dst, req->dst, 0, req->cryptlen, 1);\n\t\tkfree(src);\n\t}\n\treturn retval;\n}",
      "code_after_change": "static int __driver_rfc4106_decrypt(struct aead_request *req)\n{\n\tu8 one_entry_in_sg = 0;\n\tu8 *src, *dst, *assoc;\n\tunsigned long tempCipherLen = 0;\n\t__be32 counter = cpu_to_be32(1);\n\tint retval = 0;\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\n\tu32 key_len = ctx->aes_key_expanded.key_length;\n\tvoid *aes_ctx = &(ctx->aes_key_expanded);\n\tunsigned long auth_tag_len = crypto_aead_authsize(tfm);\n\tu8 iv_and_authTag[32+AESNI_ALIGN];\n\tu8 *iv = (u8 *) PTR_ALIGN((u8 *)iv_and_authTag, AESNI_ALIGN);\n\tu8 *authTag = iv + 16;\n\tstruct scatter_walk src_sg_walk;\n\tstruct scatter_walk assoc_sg_walk;\n\tstruct scatter_walk dst_sg_walk;\n\tunsigned int i;\n\n\tif (unlikely((req->cryptlen < auth_tag_len) ||\n\t\t(req->assoclen != 8 && req->assoclen != 12)))\n\t\treturn -EINVAL;\n\tif (unlikely(auth_tag_len != 8 && auth_tag_len != 12 && auth_tag_len != 16))\n\t        return -EINVAL;\n\tif (unlikely(key_len != AES_KEYSIZE_128 &&\n\t             key_len != AES_KEYSIZE_192 &&\n\t             key_len != AES_KEYSIZE_256))\n\t        return -EINVAL;\n\n\t/* Assuming we are supporting rfc4106 64-bit extended */\n\t/* sequence numbers We need to have the AAD length */\n\t/* equal to 8 or 12 bytes */\n\n\ttempCipherLen = (unsigned long)(req->cryptlen - auth_tag_len);\n\t/* IV below built */\n\tfor (i = 0; i < 4; i++)\n\t\t*(iv+i) = ctx->nonce[i];\n\tfor (i = 0; i < 8; i++)\n\t\t*(iv+4+i) = req->iv[i];\n\t*((__be32 *)(iv+12)) = counter;\n\n\tif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\n\t\tone_entry_in_sg = 1;\n\t\tscatterwalk_start(&src_sg_walk, req->src);\n\t\tscatterwalk_start(&assoc_sg_walk, req->assoc);\n\t\tsrc = scatterwalk_map(&src_sg_walk);\n\t\tassoc = scatterwalk_map(&assoc_sg_walk);\n\t\tdst = src;\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_start(&dst_sg_walk, req->dst);\n\t\t\tdst = scatterwalk_map(&dst_sg_walk);\n\t\t}\n\n\t} else {\n\t\t/* Allocate memory for src, dst, assoc */\n\t\tsrc = kmalloc(req->cryptlen + req->assoclen, GFP_ATOMIC);\n\t\tif (!src)\n\t\t\treturn -ENOMEM;\n\t\tassoc = (src + req->cryptlen);\n\t\tscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\n\t\tscatterwalk_map_and_copy(assoc, req->assoc, 0,\n\t\t\treq->assoclen, 0);\n\t\tdst = src;\n\t}\n\n\taesni_gcm_dec_tfm(aes_ctx, dst, src, tempCipherLen, iv,\n\t\tctx->hash_subkey, assoc, (unsigned long)req->assoclen,\n\t\tauthTag, auth_tag_len);\n\n\t/* Compare generated tag with passed in tag. */\n\tretval = crypto_memneq(src + tempCipherLen, authTag, auth_tag_len) ?\n\t\t-EBADMSG : 0;\n\n\tif (one_entry_in_sg) {\n\t\tif (unlikely(req->src != req->dst)) {\n\t\t\tscatterwalk_unmap(dst);\n\t\t\tscatterwalk_done(&dst_sg_walk, 0, 0);\n\t\t}\n\t\tscatterwalk_unmap(src);\n\t\tscatterwalk_unmap(assoc);\n\t\tscatterwalk_done(&src_sg_walk, 0, 0);\n\t\tscatterwalk_done(&assoc_sg_walk, 0, 0);\n\t} else {\n\t\tscatterwalk_map_and_copy(dst, req->dst, 0, tempCipherLen, 1);\n\t\tkfree(src);\n\t}\n\treturn retval;\n}",
      "modified_lines": {
        "added": [
          "\t\tassoc = (src + req->cryptlen);",
          "\t\tscatterwalk_map_and_copy(dst, req->dst, 0, tempCipherLen, 1);"
        ],
        "deleted": [
          "\t\tassoc = (src + req->cryptlen + auth_tag_len);",
          "\t\tscatterwalk_map_and_copy(dst, req->dst, 0, req->cryptlen, 1);"
        ]
      },
      "preconditions_for_vulnerability": "Improper memory handling during buffer allocation and calculation of memory locations for encrypted data.",
      "trigger_condition": "The code allocates memory for 'src' and 'assoc' buffers based on incorrect calculations, leading to potential buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code incorrectly calculates the memory location for the 'assoc' buffer as (src + req->cryptlen + auth_tag_len), which may result in writing beyond the allocated memory region for 'src' and 'assoc', causing a buffer overflow.",
      "solution": "To mitigate the vulnerability, it is necessary to adjust the calculation for the 'assoc' pointer to (src + req->cryptlen) to ensure that memory is accessed within the bounds of the allocated buffer for 'src'. This correction helps prevent buffer overflows and ensures proper memory handling.",
      "id": 69,
      "code_after_change_normalized": "static int FUN1(struct aead_request *VAR1)\n{\nu8 VAR2 = 0;\nu8 *VAR3, *VAR4, *VAR5;\nunsigned long VAR6 = 0;\n__be32 VAR7 = FUN2(1);\nint VAR8 = 0;\nstruct crypto_aead *VAR9 = FUN3(VAR1);\nstruct aesni_rfc4106_gcm_ctx *VAR10 = FUN4(VAR9);\nu32 VAR11 = VAR10->VAR12.VAR13;\nvoid *VAR14 = &(VAR10->VAR12);\nunsigned long VAR15 = FUN5(VAR9);\nu8 VAR16[32+VAR17];\nVAR19 *VAR18 = (VAR19 *) FUN6((VAR19 *)VAR16, VAR17);\nu8 *VAR20 = VAR18 + 16;\nstruct scatter_walk VAR21;\nstruct scatter_walk VAR22;\nstruct scatter_walk VAR23;\nunsigned int VAR24;\nif (FUN7((VAR1->VAR25 < VAR15) ||\n(VAR1->VAR26 != 8 && VAR1->VAR26 != 12)))\nreturn -VAR27;\nif (FUN7(VAR15 != 8 && VAR15 != 12 && VAR15 != 16))\nreturn -VAR27;\nif (FUN7(VAR11 != VAR28 &&\nVAR11 != VAR29 &&\nVAR11 != VAR30))\nreturn -VAR27;\nVAR6 = (unsigned long)(VAR1->VAR25 - VAR15);\nfor (VAR24 = 0; VAR24 < 4; VAR24++)\n*(VAR18+VAR24) = VAR10->VAR31[VAR24];\nfor (VAR24 = 0; VAR24 < 8; VAR24++)\n*(VAR18+4+VAR24) = VAR1->VAR18[VAR24];\n*((VAR32 *)(VAR18+12)) = VAR7;\nif ((FUN8(VAR1->VAR3)) && (FUN8(VAR1->VAR5))) {\nVAR2 = 1;\nFUN9(&VAR21, VAR1->VAR3);\nFUN9(&VAR22, VAR1->VAR5);\nVAR3 = FUN10(&VAR21);\nVAR5 = FUN10(&VAR22);\nVAR4 = VAR3;\nif (FUN7(VAR1->VAR3 != VAR1->VAR4)) {\nFUN9(&VAR23, VAR1->VAR4);\nVAR4 = FUN10(&VAR23);\n}\n} else {\nVAR3 = FUN11(VAR1->VAR25 + VAR1->VAR26, VAR33);\nif (!VAR3)\nreturn -VAR34;\nVAR5 = (VAR3 + VAR1->VAR25);\nFUN12(VAR3, VAR1->VAR3, 0, VAR1->VAR25, 0);\nFUN12(VAR5, VAR1->VAR5, 0,\nVAR1->VAR26, 0);\nVAR4 = VAR3;\n}\nFUN13(VAR14, VAR4, VAR3, VAR6, VAR18,\nVAR10->VAR35, VAR5, (unsigned long)VAR1->VAR26,\nVAR20, VAR15);\nVAR8 = FUN14(VAR3 + VAR6, VAR20, VAR15) ?\n-VAR36 : 0;\nif (VAR2) {\nif (FUN7(VAR1->VAR3 != VAR1->VAR4)) {\nFUN15(VAR4);\nFUN16(&VAR23, 0, 0);\n}\nFUN15(VAR3);\nFUN15(VAR5);\nFUN16(&VAR21, 0, 0);\nFUN16(&VAR22, 0, 0);\n} else {\nFUN12(VAR4, VAR1->VAR4, 0, VAR6, 1);\nFUN17(VAR3);\n}\nreturn VAR8;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct aead_request *VAR1)\n{\nu8 VAR2 = 0;\nu8 *VAR3, *VAR4, *VAR5;\nunsigned long VAR6 = 0;\n__be32 VAR7 = FUN2(1);\nint VAR8 = 0;\nstruct crypto_aead *VAR9 = FUN3(VAR1);\nstruct aesni_rfc4106_gcm_ctx *VAR10 = FUN4(VAR9);\nu32 VAR11 = VAR10->VAR12.VAR13;\nvoid *VAR14 = &(VAR10->VAR12);\nunsigned long VAR15 = FUN5(VAR9);\nu8 VAR16[32+VAR17];\nVAR19 *VAR18 = (VAR19 *) FUN6((VAR19 *)VAR16, VAR17);\nu8 *VAR20 = VAR18 + 16;\nstruct scatter_walk VAR21;\nstruct scatter_walk VAR22;\nstruct scatter_walk VAR23;\nunsigned int VAR24;\nif (FUN7((VAR1->VAR25 < VAR15) ||\n(VAR1->VAR26 != 8 && VAR1->VAR26 != 12)))\nreturn -VAR27;\nif (FUN7(VAR15 != 8 && VAR15 != 12 && VAR15 != 16))\nreturn -VAR27;\nif (FUN7(VAR11 != VAR28 &&\nVAR11 != VAR29 &&\nVAR11 != VAR30))\nreturn -VAR27;\nVAR6 = (unsigned long)(VAR1->VAR25 - VAR15);\nfor (VAR24 = 0; VAR24 < 4; VAR24++)\n*(VAR18+VAR24) = VAR10->VAR31[VAR24];\nfor (VAR24 = 0; VAR24 < 8; VAR24++)\n*(VAR18+4+VAR24) = VAR1->VAR18[VAR24];\n*((VAR32 *)(VAR18+12)) = VAR7;\nif ((FUN8(VAR1->VAR3)) && (FUN8(VAR1->VAR5))) {\nVAR2 = 1;\nFUN9(&VAR21, VAR1->VAR3);\nFUN9(&VAR22, VAR1->VAR5);\nVAR3 = FUN10(&VAR21);\nVAR5 = FUN10(&VAR22);\nVAR4 = VAR3;\nif (FUN7(VAR1->VAR3 != VAR1->VAR4)) {\nFUN9(&VAR23, VAR1->VAR4);\nVAR4 = FUN10(&VAR23);\n}\n} else {\nVAR3 = FUN11(VAR1->VAR25 + VAR1->VAR26, VAR33);\nif (!VAR3)\nreturn -VAR34;\nVAR5 = (VAR3 + VAR1->VAR25 + VAR15);\nFUN12(VAR3, VAR1->VAR3, 0, VAR1->VAR25, 0);\nFUN12(VAR5, VAR1->VAR5, 0,\nVAR1->VAR26, 0);\nVAR4 = VAR3;\n}\nFUN13(VAR14, VAR4, VAR3, VAR6, VAR18,\nVAR10->VAR35, VAR5, (unsigned long)VAR1->VAR26,\nVAR20, VAR15);\nVAR8 = FUN14(VAR3 + VAR6, VAR20, VAR15) ?\n-VAR36 : 0;\nif (VAR2) {\nif (FUN7(VAR1->VAR3 != VAR1->VAR4)) {\nFUN15(VAR4);\nFUN16(&VAR23, 0, 0);\n}\nFUN15(VAR3);\nFUN15(VAR5);\nFUN16(&VAR21, 0, 0);\nFUN16(&VAR22, 0, 0);\n} else {\nFUN12(VAR4, VAR1->VAR4, 0, VAR1->VAR25, 1);\nFUN17(VAR3);\n}\nreturn VAR8;\n}\n",
      "code_after_change_raw": "static int __driver_rfc4106_decrypt(struct aead_request *req)\n{\nu8 one_entry_in_sg = 0;\nu8 *src, *dst, *assoc;\nunsigned long tempCipherLen = 0;\n__be32 counter = cpu_to_be32(1);\nint retval = 0;\nstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\nstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\nu32 key_len = ctx->aes_key_expanded.key_length;\nvoid *aes_ctx = &(ctx->aes_key_expanded);\nunsigned long auth_tag_len = crypto_aead_authsize(tfm);\nu8 iv_and_authTag[32+AESNI_ALIGN];\nu8 *iv = (u8 *) PTR_ALIGN((u8 *)iv_and_authTag, AESNI_ALIGN);\nu8 *authTag = iv + 16;\nstruct scatter_walk src_sg_walk;\nstruct scatter_walk assoc_sg_walk;\nstruct scatter_walk dst_sg_walk;\nunsigned int i;\nif (unlikely((req->cryptlen < auth_tag_len) ||\n(req->assoclen != 8 && req->assoclen != 12)))\nreturn -EINVAL;\nif (unlikely(auth_tag_len != 8 && auth_tag_len != 12 && auth_tag_len != 16))\nreturn -EINVAL;\nif (unlikely(key_len != AES_KEYSIZE_128 &&\nkey_len != AES_KEYSIZE_192 &&\nkey_len != AES_KEYSIZE_256))\nreturn -EINVAL;\ntempCipherLen = (unsigned long)(req->cryptlen - auth_tag_len);\nfor (i = 0; i < 4; i++)\n*(iv+i) = ctx->nonce[i];\nfor (i = 0; i < 8; i++)\n*(iv+4+i) = req->iv[i];\n*((__be32 *)(iv+12)) = counter;\nif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\none_entry_in_sg = 1;\nscatterwalk_start(&src_sg_walk, req->src);\nscatterwalk_start(&assoc_sg_walk, req->assoc);\nsrc = scatterwalk_map(&src_sg_walk);\nassoc = scatterwalk_map(&assoc_sg_walk);\ndst = src;\nif (unlikely(req->src != req->dst)) {\nscatterwalk_start(&dst_sg_walk, req->dst);\ndst = scatterwalk_map(&dst_sg_walk);\n}\n} else {\nsrc = kmalloc(req->cryptlen + req->assoclen, GFP_ATOMIC);\nif (!src)\nreturn -ENOMEM;\nassoc = (src + req->cryptlen);\nscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\nscatterwalk_map_and_copy(assoc, req->assoc, 0,\nreq->assoclen, 0);\ndst = src;\n}\naesni_gcm_dec_tfm(aes_ctx, dst, src, tempCipherLen, iv,\nctx->hash_subkey, assoc, (unsigned long)req->assoclen,\nauthTag, auth_tag_len);\nretval = crypto_memneq(src + tempCipherLen, authTag, auth_tag_len) ?\n-EBADMSG : 0;\nif (one_entry_in_sg) {\nif (unlikely(req->src != req->dst)) {\nscatterwalk_unmap(dst);\nscatterwalk_done(&dst_sg_walk, 0, 0);\n}\nscatterwalk_unmap(src);\nscatterwalk_unmap(assoc);\nscatterwalk_done(&src_sg_walk, 0, 0);\nscatterwalk_done(&assoc_sg_walk, 0, 0);\n} else {\nscatterwalk_map_and_copy(dst, req->dst, 0, tempCipherLen, 1);\nkfree(src);\n}\nreturn retval;\n}\n",
      "code_before_change_raw": "static int __driver_rfc4106_decrypt(struct aead_request *req)\n{\nu8 one_entry_in_sg = 0;\nu8 *src, *dst, *assoc;\nunsigned long tempCipherLen = 0;\n__be32 counter = cpu_to_be32(1);\nint retval = 0;\nstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\nstruct aesni_rfc4106_gcm_ctx *ctx = aesni_rfc4106_gcm_ctx_get(tfm);\nu32 key_len = ctx->aes_key_expanded.key_length;\nvoid *aes_ctx = &(ctx->aes_key_expanded);\nunsigned long auth_tag_len = crypto_aead_authsize(tfm);\nu8 iv_and_authTag[32+AESNI_ALIGN];\nu8 *iv = (u8 *) PTR_ALIGN((u8 *)iv_and_authTag, AESNI_ALIGN);\nu8 *authTag = iv + 16;\nstruct scatter_walk src_sg_walk;\nstruct scatter_walk assoc_sg_walk;\nstruct scatter_walk dst_sg_walk;\nunsigned int i;\nif (unlikely((req->cryptlen < auth_tag_len) ||\n(req->assoclen != 8 && req->assoclen != 12)))\nreturn -EINVAL;\nif (unlikely(auth_tag_len != 8 && auth_tag_len != 12 && auth_tag_len != 16))\nreturn -EINVAL;\nif (unlikely(key_len != AES_KEYSIZE_128 &&\nkey_len != AES_KEYSIZE_192 &&\nkey_len != AES_KEYSIZE_256))\nreturn -EINVAL;\ntempCipherLen = (unsigned long)(req->cryptlen - auth_tag_len);\nfor (i = 0; i < 4; i++)\n*(iv+i) = ctx->nonce[i];\nfor (i = 0; i < 8; i++)\n*(iv+4+i) = req->iv[i];\n*((__be32 *)(iv+12)) = counter;\nif ((sg_is_last(req->src)) && (sg_is_last(req->assoc))) {\none_entry_in_sg = 1;\nscatterwalk_start(&src_sg_walk, req->src);\nscatterwalk_start(&assoc_sg_walk, req->assoc);\nsrc = scatterwalk_map(&src_sg_walk);\nassoc = scatterwalk_map(&assoc_sg_walk);\ndst = src;\nif (unlikely(req->src != req->dst)) {\nscatterwalk_start(&dst_sg_walk, req->dst);\ndst = scatterwalk_map(&dst_sg_walk);\n}\n} else {\nsrc = kmalloc(req->cryptlen + req->assoclen, GFP_ATOMIC);\nif (!src)\nreturn -ENOMEM;\nassoc = (src + req->cryptlen + auth_tag_len);\nscatterwalk_map_and_copy(src, req->src, 0, req->cryptlen, 0);\nscatterwalk_map_and_copy(assoc, req->assoc, 0,\nreq->assoclen, 0);\ndst = src;\n}\naesni_gcm_dec_tfm(aes_ctx, dst, src, tempCipherLen, iv,\nctx->hash_subkey, assoc, (unsigned long)req->assoclen,\nauthTag, auth_tag_len);\nretval = crypto_memneq(src + tempCipherLen, authTag, auth_tag_len) ?\n-EBADMSG : 0;\nif (one_entry_in_sg) {\nif (unlikely(req->src != req->dst)) {\nscatterwalk_unmap(dst);\nscatterwalk_done(&dst_sg_walk, 0, 0);\n}\nscatterwalk_unmap(src);\nscatterwalk_unmap(assoc);\nscatterwalk_done(&src_sg_walk, 0, 0);\nscatterwalk_done(&assoc_sg_walk, 0, 0);\n} else {\nscatterwalk_map_and_copy(dst, req->dst, 0, req->cryptlen, 1);\nkfree(src);\n}\nreturn retval;\n}\n"
    }
  ],
  "CVE-2015-4002": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Insufficient validation of length values in data packets received by the code.",
        "trigger_condition": "Receiving crafted packets with insufficient length values can lead to buffer overflows or memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code performs calculations and memory accesses based on length values of received packets without adequately verifying that the lengths are sufficient, potentially allowing attackers to exploit the code by sending crafted packets with manipulated length values."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add explicit checks to validate the length of data packets before performing calculations or accessing memory locations based on those lengths. By ensuring that the length values are sufficient, the code can prevent buffer overflows and memory corruption issues when processing received packets. In this case, the solution involves adding checks to verify that the length of the received packet is large enough before proceeding with calculations or memory accesses based on those lengths.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2015-4002, which allows remote attackers to cause a denial of service or potentially execute arbitrary code via a crafted packet. The vulnerability arises due to insufficient checks on certain length values in the code.\n\nIn the original code snippet, there are calculations involving the length of data packets received, such as calculating data_len in the OZ_GET_DESC_RSP case. However, these calculations do not ensure that the length values are sufficiently large, which can lead to buffer overflows or other security issues when processing crafted packets.\n\nThe modification introduces additional checks to validate the length of data packets before performing calculations or accessing memory locations based on those lengths. Specifically, the modified code snippet includes checks to ensure that the length of the received packet is large enough to prevent buffer overflows or memory corruption.\n\nBy adding these checks, the code becomes more robust and secure, mitigating the vulnerability and reducing the risk of exploitation by malicious actors sending specially crafted packets.",
      "GPT_purpose": "Handle USB receive operations and process different types of USB packets in the OZWPAN driver.",
      "GPT_function": "\n1. oz_usb_rx: Receives USB data packets and processes them based on the type of packet received.\n2. oz_usb_handle_ep_data: Handles USB endpoint data packets and performs actions based on the data received.",
      "CVE_id": "CVE-2015-4002",
      "code_before_change": "void oz_usb_rx(struct oz_pd *pd, struct oz_elt *elt)\n{\n\tstruct oz_usb_hdr *usb_hdr = (struct oz_usb_hdr *)(elt + 1);\n\tstruct oz_usb_ctx *usb_ctx;\n\n\tspin_lock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tusb_ctx = (struct oz_usb_ctx *)pd->app_ctx[OZ_APPID_USB];\n\tif (usb_ctx)\n\t\toz_usb_get(usb_ctx);\n\tspin_unlock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tif (usb_ctx == NULL)\n\t\treturn; /* Context has gone so nothing to do. */\n\tif (usb_ctx->stopped)\n\t\tgoto done;\n\t/* If sequence number is non-zero then check it is not a duplicate.\n\t * Zero sequence numbers are always accepted.\n\t */\n\tif (usb_hdr->elt_seq_num != 0) {\n\t\tif (((usb_ctx->rx_seq_num - usb_hdr->elt_seq_num) & 0x80) == 0)\n\t\t\t/* Reject duplicate element. */\n\t\t\tgoto done;\n\t}\n\tusb_ctx->rx_seq_num = usb_hdr->elt_seq_num;\n\tswitch (usb_hdr->type) {\n\tcase OZ_GET_DESC_RSP: {\n\t\t\tstruct oz_get_desc_rsp *body =\n\t\t\t\t(struct oz_get_desc_rsp *)usb_hdr;\n\t\t\tint data_len = elt->length -\n\t\t\t\t\tsizeof(struct oz_get_desc_rsp) + 1;\n\t\t\tu16 offs = le16_to_cpu(get_unaligned(&body->offset));\n\t\t\tu16 total_size =\n\t\t\t\tle16_to_cpu(get_unaligned(&body->total_size));\n\t\t\toz_dbg(ON, \"USB_REQ_GET_DESCRIPTOR - cnf\\n\");\n\t\t\toz_hcd_get_desc_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\t\tbody->rcode, body->data,\n\t\t\t\t\tdata_len, offs, total_size);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_CONFIG_RSP: {\n\t\t\tstruct oz_set_config_rsp *body =\n\t\t\t\t(struct oz_set_config_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_INTERFACE_RSP: {\n\t\t\tstruct oz_set_interface_rsp *body =\n\t\t\t\t(struct oz_set_interface_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport,\n\t\t\t\tbody->req_id, body->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_VENDOR_CLASS_RSP: {\n\t\t\tstruct oz_vendor_class_rsp *body =\n\t\t\t\t(struct oz_vendor_class_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, body->data, elt->length-\n\t\t\t\tsizeof(struct oz_vendor_class_rsp)+1);\n\t\t}\n\t\tbreak;\n\tcase OZ_USB_ENDPOINT_DATA:\n\t\toz_usb_handle_ep_data(usb_ctx, usb_hdr, elt->length);\n\t\tbreak;\n\t}\ndone:\n\toz_usb_put(usb_ctx);\n}",
      "code_after_change": "void oz_usb_rx(struct oz_pd *pd, struct oz_elt *elt)\n{\n\tstruct oz_usb_hdr *usb_hdr = (struct oz_usb_hdr *)(elt + 1);\n\tstruct oz_usb_ctx *usb_ctx;\n\n\tspin_lock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tusb_ctx = (struct oz_usb_ctx *)pd->app_ctx[OZ_APPID_USB];\n\tif (usb_ctx)\n\t\toz_usb_get(usb_ctx);\n\tspin_unlock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tif (usb_ctx == NULL)\n\t\treturn; /* Context has gone so nothing to do. */\n\tif (usb_ctx->stopped)\n\t\tgoto done;\n\t/* If sequence number is non-zero then check it is not a duplicate.\n\t * Zero sequence numbers are always accepted.\n\t */\n\tif (usb_hdr->elt_seq_num != 0) {\n\t\tif (((usb_ctx->rx_seq_num - usb_hdr->elt_seq_num) & 0x80) == 0)\n\t\t\t/* Reject duplicate element. */\n\t\t\tgoto done;\n\t}\n\tusb_ctx->rx_seq_num = usb_hdr->elt_seq_num;\n\tswitch (usb_hdr->type) {\n\tcase OZ_GET_DESC_RSP: {\n\t\t\tstruct oz_get_desc_rsp *body =\n\t\t\t\t(struct oz_get_desc_rsp *)usb_hdr;\n\t\t\tu16 offs, total_size;\n\t\t\tu8 data_len;\n\n\t\t\tif (elt->length < sizeof(struct oz_get_desc_rsp) - 1)\n\t\t\t\tbreak;\n\t\t\tdata_len = elt->length -\n\t\t\t\t\t(sizeof(struct oz_get_desc_rsp) - 1);\n\t\t\toffs = le16_to_cpu(get_unaligned(&body->offset));\n\t\t\ttotal_size =\n\t\t\t\tle16_to_cpu(get_unaligned(&body->total_size));\n\t\t\toz_dbg(ON, \"USB_REQ_GET_DESCRIPTOR - cnf\\n\");\n\t\t\toz_hcd_get_desc_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\t\tbody->rcode, body->data,\n\t\t\t\t\tdata_len, offs, total_size);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_CONFIG_RSP: {\n\t\t\tstruct oz_set_config_rsp *body =\n\t\t\t\t(struct oz_set_config_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_INTERFACE_RSP: {\n\t\t\tstruct oz_set_interface_rsp *body =\n\t\t\t\t(struct oz_set_interface_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport,\n\t\t\t\tbody->req_id, body->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_VENDOR_CLASS_RSP: {\n\t\t\tstruct oz_vendor_class_rsp *body =\n\t\t\t\t(struct oz_vendor_class_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, body->data, elt->length-\n\t\t\t\tsizeof(struct oz_vendor_class_rsp)+1);\n\t\t}\n\t\tbreak;\n\tcase OZ_USB_ENDPOINT_DATA:\n\t\toz_usb_handle_ep_data(usb_ctx, usb_hdr, elt->length);\n\t\tbreak;\n\t}\ndone:\n\toz_usb_put(usb_ctx);\n}",
      "modified_lines": {
        "added": [
          "\t\t\tu16 offs, total_size;",
          "\t\t\tu8 data_len;",
          "",
          "\t\t\tif (elt->length < sizeof(struct oz_get_desc_rsp) - 1)",
          "\t\t\t\tbreak;",
          "\t\t\tdata_len = elt->length -",
          "\t\t\t\t\t(sizeof(struct oz_get_desc_rsp) - 1);",
          "\t\t\toffs = le16_to_cpu(get_unaligned(&body->offset));",
          "\t\t\ttotal_size ="
        ],
        "deleted": [
          "\t\t\tint data_len = elt->length -",
          "\t\t\t\t\tsizeof(struct oz_get_desc_rsp) + 1;",
          "\t\t\tu16 offs = le16_to_cpu(get_unaligned(&body->offset));",
          "\t\t\tu16 total_size ="
        ]
      },
      "preconditions_for_vulnerability": "Insufficient validation of length values in data packets received by the code.",
      "trigger_condition": "Receiving crafted packets with insufficient length values can lead to buffer overflows or memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code performs calculations and memory accesses based on length values of received packets without adequately verifying that the lengths are sufficient, potentially allowing attackers to exploit the code by sending crafted packets with manipulated length values.",
      "id": 70,
      "code_after_change_normalized": "void FUN1(struct oz_pd *VAR1, struct oz_elt *VAR2)\n{\nstruct VAR4 *VAR3 = (struct VAR4 *)(VAR2 + 1);\nstruct oz_usb_ctx *VAR5;\nFUN2(&VAR1->VAR6[VAR7]);\nVAR5 = (struct VAR8 *)VAR1->VAR9[VAR7];\nif (VAR5)\nFUN3(VAR5);\nFUN4(&VAR1->VAR6[VAR7]);\nif (VAR5 == NULL)\nreturn; \nif (VAR5->VAR10)\ngoto VAR11;\nif (VAR3->VAR12 != 0) {\nif (((VAR5->VAR13 - VAR3->VAR12) & VAR14) == 0)\ngoto VAR11;\n}\nVAR5->VAR13 = VAR3->VAR12;\nswitch (VAR3->VAR15) {\ncase VAR16: {\nstruct oz_get_desc_rsp *VAR17 =\n(struct VAR18 *)VAR3;\nu16 VAR19, VAR20;\nu8 VAR21;\nif (VAR2->VAR22 < sizeof(struct VAR18) - 1)\nbreak;\nVAR21 = VAR2->VAR22 -\n(sizeof(struct VAR18) - 1);\nVAR19 = FUN5(FUN6(&VAR17->VAR23));\nVAR20 =\nFUN5(FUN6(&VAR17->VAR20));\nFUN7(VAR24, \"STR\");\nFUN8(VAR5->VAR25, VAR17->VAR26,\nVAR17->VAR27, VAR17->VAR28,\nVAR21, VAR19, VAR20);\n}\nbreak;\ncase VAR29: {\nstruct oz_set_config_rsp *VAR17 =\n(struct VAR30 *)VAR3;\nFUN9(VAR5->VAR25, VAR17->VAR26,\nVAR17->VAR27, NULL, 0);\n}\nbreak;\ncase VAR31: {\nstruct oz_set_interface_rsp *VAR17 =\n(struct VAR32 *)VAR3;\nFUN9(VAR5->VAR25,\nVAR17->VAR26, VAR17->VAR27, NULL, 0);\n}\nbreak;\ncase VAR33: {\nstruct oz_vendor_class_rsp *VAR17 =\n(struct VAR34 *)VAR3;\nFUN9(VAR5->VAR25, VAR17->VAR26,\nVAR17->VAR27, VAR17->VAR28, VAR2->VAR22-\nsizeof(struct VAR34)+1);\n}\nbreak;\ncase VAR35:\nFUN10(VAR5, VAR3, VAR2->VAR22);\nbreak;\n}\nVAR11:\nFUN11(VAR5);\n}\n",
      "code_before_change_normalized": "void FUN1(struct oz_pd *VAR1, struct oz_elt *VAR2)\n{\nstruct VAR4 *VAR3 = (struct VAR4 *)(VAR2 + 1);\nstruct oz_usb_ctx *VAR5;\nFUN2(&VAR1->VAR6[VAR7]);\nVAR5 = (struct VAR8 *)VAR1->VAR9[VAR7];\nif (VAR5)\nFUN3(VAR5);\nFUN4(&VAR1->VAR6[VAR7]);\nif (VAR5 == NULL)\nreturn; \nif (VAR5->VAR10)\ngoto VAR11;\nif (VAR3->VAR12 != 0) {\nif (((VAR5->VAR13 - VAR3->VAR12) & VAR14) == 0)\ngoto VAR11;\n}\nVAR5->VAR13 = VAR3->VAR12;\nswitch (VAR3->VAR15) {\ncase VAR16: {\nstruct oz_get_desc_rsp *VAR17 =\n(struct VAR18 *)VAR3;\nint VAR19 = VAR2->VAR20 -\nsizeof(struct VAR18) + 1;\nu16 VAR21 = FUN5(FUN6(&VAR17->VAR22));\nu16 VAR23 =\nFUN5(FUN6(&VAR17->VAR23));\nFUN7(VAR24, \"STR\");\nFUN8(VAR5->VAR25, VAR17->VAR26,\nVAR17->VAR27, VAR17->VAR28,\nVAR19, VAR21, VAR23);\n}\nbreak;\ncase VAR29: {\nstruct oz_set_config_rsp *VAR17 =\n(struct VAR30 *)VAR3;\nFUN9(VAR5->VAR25, VAR17->VAR26,\nVAR17->VAR27, NULL, 0);\n}\nbreak;\ncase VAR31: {\nstruct oz_set_interface_rsp *VAR17 =\n(struct VAR32 *)VAR3;\nFUN9(VAR5->VAR25,\nVAR17->VAR26, VAR17->VAR27, NULL, 0);\n}\nbreak;\ncase VAR33: {\nstruct oz_vendor_class_rsp *VAR17 =\n(struct VAR34 *)VAR3;\nFUN9(VAR5->VAR25, VAR17->VAR26,\nVAR17->VAR27, VAR17->VAR28, VAR2->VAR20-\nsizeof(struct VAR34)+1);\n}\nbreak;\ncase VAR35:\nFUN10(VAR5, VAR3, VAR2->VAR20);\nbreak;\n}\nVAR11:\nFUN11(VAR5);\n}\n",
      "code_after_change_raw": "void oz_usb_rx(struct oz_pd *pd, struct oz_elt *elt)\n{\nstruct oz_usb_hdr *usb_hdr = (struct oz_usb_hdr *)(elt + 1);\nstruct oz_usb_ctx *usb_ctx;\nspin_lock_bh(&pd->app_lock[OZ_APPID_USB]);\nusb_ctx = (struct oz_usb_ctx *)pd->app_ctx[OZ_APPID_USB];\nif (usb_ctx)\noz_usb_get(usb_ctx);\nspin_unlock_bh(&pd->app_lock[OZ_APPID_USB]);\nif (usb_ctx == NULL)\nreturn; \nif (usb_ctx->stopped)\ngoto done;\nif (usb_hdr->elt_seq_num != 0) {\nif (((usb_ctx->rx_seq_num - usb_hdr->elt_seq_num) & 0x80) == 0)\ngoto done;\n}\nusb_ctx->rx_seq_num = usb_hdr->elt_seq_num;\nswitch (usb_hdr->type) {\ncase OZ_GET_DESC_RSP: {\nstruct oz_get_desc_rsp *body =\n(struct oz_get_desc_rsp *)usb_hdr;\nu16 offs, total_size;\nu8 data_len;\nif (elt->length < sizeof(struct oz_get_desc_rsp) - 1)\nbreak;\ndata_len = elt->length -\n(sizeof(struct oz_get_desc_rsp) - 1);\noffs = le16_to_cpu(get_unaligned(&body->offset));\ntotal_size =\nle16_to_cpu(get_unaligned(&body->total_size));\noz_dbg(ON, \"USB_REQ_GET_DESCRIPTOR - cnf\\n\");\noz_hcd_get_desc_cnf(usb_ctx->hport, body->req_id,\nbody->rcode, body->data,\ndata_len, offs, total_size);\n}\nbreak;\ncase OZ_SET_CONFIG_RSP: {\nstruct oz_set_config_rsp *body =\n(struct oz_set_config_rsp *)usb_hdr;\noz_hcd_control_cnf(usb_ctx->hport, body->req_id,\nbody->rcode, NULL, 0);\n}\nbreak;\ncase OZ_SET_INTERFACE_RSP: {\nstruct oz_set_interface_rsp *body =\n(struct oz_set_interface_rsp *)usb_hdr;\noz_hcd_control_cnf(usb_ctx->hport,\nbody->req_id, body->rcode, NULL, 0);\n}\nbreak;\ncase OZ_VENDOR_CLASS_RSP: {\nstruct oz_vendor_class_rsp *body =\n(struct oz_vendor_class_rsp *)usb_hdr;\noz_hcd_control_cnf(usb_ctx->hport, body->req_id,\nbody->rcode, body->data, elt->length-\nsizeof(struct oz_vendor_class_rsp)+1);\n}\nbreak;\ncase OZ_USB_ENDPOINT_DATA:\noz_usb_handle_ep_data(usb_ctx, usb_hdr, elt->length);\nbreak;\n}\ndone:\noz_usb_put(usb_ctx);\n}\n",
      "code_before_change_raw": "void oz_usb_rx(struct oz_pd *pd, struct oz_elt *elt)\n{\nstruct oz_usb_hdr *usb_hdr = (struct oz_usb_hdr *)(elt + 1);\nstruct oz_usb_ctx *usb_ctx;\nspin_lock_bh(&pd->app_lock[OZ_APPID_USB]);\nusb_ctx = (struct oz_usb_ctx *)pd->app_ctx[OZ_APPID_USB];\nif (usb_ctx)\noz_usb_get(usb_ctx);\nspin_unlock_bh(&pd->app_lock[OZ_APPID_USB]);\nif (usb_ctx == NULL)\nreturn; \nif (usb_ctx->stopped)\ngoto done;\nif (usb_hdr->elt_seq_num != 0) {\nif (((usb_ctx->rx_seq_num - usb_hdr->elt_seq_num) & 0x80) == 0)\ngoto done;\n}\nusb_ctx->rx_seq_num = usb_hdr->elt_seq_num;\nswitch (usb_hdr->type) {\ncase OZ_GET_DESC_RSP: {\nstruct oz_get_desc_rsp *body =\n(struct oz_get_desc_rsp *)usb_hdr;\nint data_len = elt->length -\nsizeof(struct oz_get_desc_rsp) + 1;\nu16 offs = le16_to_cpu(get_unaligned(&body->offset));\nu16 total_size =\nle16_to_cpu(get_unaligned(&body->total_size));\noz_dbg(ON, \"USB_REQ_GET_DESCRIPTOR - cnf\\n\");\noz_hcd_get_desc_cnf(usb_ctx->hport, body->req_id,\nbody->rcode, body->data,\ndata_len, offs, total_size);\n}\nbreak;\ncase OZ_SET_CONFIG_RSP: {\nstruct oz_set_config_rsp *body =\n(struct oz_set_config_rsp *)usb_hdr;\noz_hcd_control_cnf(usb_ctx->hport, body->req_id,\nbody->rcode, NULL, 0);\n}\nbreak;\ncase OZ_SET_INTERFACE_RSP: {\nstruct oz_set_interface_rsp *body =\n(struct oz_set_interface_rsp *)usb_hdr;\noz_hcd_control_cnf(usb_ctx->hport,\nbody->req_id, body->rcode, NULL, 0);\n}\nbreak;\ncase OZ_VENDOR_CLASS_RSP: {\nstruct oz_vendor_class_rsp *body =\n(struct oz_vendor_class_rsp *)usb_hdr;\noz_hcd_control_cnf(usb_ctx->hport, body->req_id,\nbody->rcode, body->data, elt->length-\nsizeof(struct oz_vendor_class_rsp)+1);\n}\nbreak;\ncase OZ_USB_ENDPOINT_DATA:\noz_usb_handle_ep_data(usb_ctx, usb_hdr, elt->length);\nbreak;\n}\ndone:\noz_usb_put(usb_ctx);\n}\n"
    }
  ],
  "CVE-2015-4036": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper input validation and boundary checking for user-supplied data in a specific function.",
        "trigger_condition": "A malicious user provides crafted input to a specific function, leading to an array index error and potential memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the input 'name' parameter and does not check the boundary conditions for the 'tpgt' value derived from the input. This allows an attacker to manipulate the input in a way that causes an array index error and potential memory corruption."
      },
      "solution": "To mitigate the vulnerability, it is necessary to enhance input validation and boundary checking in the specific function. This involves validating the format and content of the 'name' parameter to ensure it meets expected criteria and checking that the derived 'tpgt' value is within the allowed range. By implementing these checks, the code can prevent malicious manipulation of input data that leads to array index errors and memory corruption. In this case, the solution includes verifying the 'name' parameter format and range of the 'tpgt' value before proceeding with further operations.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2015-4036, which involves an array index error in the `vhost_scsi_make_tpg` function. The vulnerability allows guest OS users to cause a denial of service (memory corruption) or potentially have other unspecified impacts via a crafted `VHOST_SCSI_SET_ENDPOINT` ioctl call.\n\nThe key changes made in the modified code snippet are:\n1. Changed the data type of `tpgt` from `unsigned long` to `u16` (unsigned 16-bit integer) to ensure that the value is within a specific range.\n2. Replaced the check `tpgt > UINT_MAX` with `tpgt >= VHOST_SCSI_MAX_TARGET` to ensure that `tpgt` does not exceed the maximum target value allowed in the system.\n\nBy making these changes, the modified code snippet helps prevent potential memory corruption and other impacts that could be caused by malicious input triggering an array index error.",
      "GPT_purpose": "Create a new target portal group for vhost-scsi based on the provided parameters.",
      "GPT_function": "\n1. Check if the name contains \"tpgt_\".\n2. Convert the substring after \"tpgt_\" to an unsigned long.\n3. Allocate memory for a struct vhost_scsi_tpg and initialize its fields.\n4. Register the TPG with the core and add it to a list.\n5. Return a pointer to the registered TPG.",
      "CVE_id": "CVE-2015-4036",
      "code_before_change": "static struct se_portal_group *\nvhost_scsi_make_tpg(struct se_wwn *wwn,\n\t\t   struct config_group *group,\n\t\t   const char *name)\n{\n\tstruct vhost_scsi_tport *tport = container_of(wwn,\n\t\t\tstruct vhost_scsi_tport, tport_wwn);\n\n\tstruct vhost_scsi_tpg *tpg;\n\tunsigned long tpgt;\n\tint ret;\n\n\tif (strstr(name, \"tpgt_\") != name)\n\t\treturn ERR_PTR(-EINVAL);\n\tif (kstrtoul(name + 5, 10, &tpgt) || tpgt > UINT_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\n\ttpg = kzalloc(sizeof(struct vhost_scsi_tpg), GFP_KERNEL);\n\tif (!tpg) {\n\t\tpr_err(\"Unable to allocate struct vhost_scsi_tpg\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tmutex_init(&tpg->tv_tpg_mutex);\n\tINIT_LIST_HEAD(&tpg->tv_tpg_list);\n\ttpg->tport = tport;\n\ttpg->tport_tpgt = tpgt;\n\n\tret = core_tpg_register(&vhost_scsi_fabric_configfs->tf_ops, wwn,\n\t\t\t\t&tpg->se_tpg, tpg, TRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0) {\n\t\tkfree(tpg);\n\t\treturn NULL;\n\t}\n\tmutex_lock(&vhost_scsi_mutex);\n\tlist_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);\n\tmutex_unlock(&vhost_scsi_mutex);\n\n\treturn &tpg->se_tpg;\n}",
      "code_after_change": "static struct se_portal_group *\nvhost_scsi_make_tpg(struct se_wwn *wwn,\n\t\t   struct config_group *group,\n\t\t   const char *name)\n{\n\tstruct vhost_scsi_tport *tport = container_of(wwn,\n\t\t\tstruct vhost_scsi_tport, tport_wwn);\n\n\tstruct vhost_scsi_tpg *tpg;\n\tu16 tpgt;\n\tint ret;\n\n\tif (strstr(name, \"tpgt_\") != name)\n\t\treturn ERR_PTR(-EINVAL);\n\tif (kstrtou16(name + 5, 10, &tpgt) || tpgt >= VHOST_SCSI_MAX_TARGET)\n\t\treturn ERR_PTR(-EINVAL);\n\n\ttpg = kzalloc(sizeof(struct vhost_scsi_tpg), GFP_KERNEL);\n\tif (!tpg) {\n\t\tpr_err(\"Unable to allocate struct vhost_scsi_tpg\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tmutex_init(&tpg->tv_tpg_mutex);\n\tINIT_LIST_HEAD(&tpg->tv_tpg_list);\n\ttpg->tport = tport;\n\ttpg->tport_tpgt = tpgt;\n\n\tret = core_tpg_register(&vhost_scsi_fabric_configfs->tf_ops, wwn,\n\t\t\t\t&tpg->se_tpg, tpg, TRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0) {\n\t\tkfree(tpg);\n\t\treturn NULL;\n\t}\n\tmutex_lock(&vhost_scsi_mutex);\n\tlist_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);\n\tmutex_unlock(&vhost_scsi_mutex);\n\n\treturn &tpg->se_tpg;\n}",
      "modified_lines": {
        "added": [
          "\tu16 tpgt;",
          "\tif (kstrtou16(name + 5, 10, &tpgt) || tpgt >= VHOST_SCSI_MAX_TARGET)"
        ],
        "deleted": [
          "\tunsigned long tpgt;",
          "\tif (kstrtoul(name + 5, 10, &tpgt) || tpgt > UINT_MAX)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper input validation and boundary checking for user-supplied data in a specific function.",
      "trigger_condition": "A malicious user provides crafted input to a specific function, leading to an array index error and potential memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the input 'name' parameter and does not check the boundary conditions for the 'tpgt' value derived from the input. This allows an attacker to manipulate the input in a way that causes an array index error and potential memory corruption.",
      "id": 71,
      "code_after_change_normalized": "static struct VAR1 *\nFUN1(struct se_wwn *VAR2,\nstruct config_group *VAR3,\nconst char *VAR4)\n{\nstruct vhost_scsi_tport *VAR5 = FUN2(VAR2,\nstruct VAR6, VAR7);\nstruct vhost_scsi_tpg *VAR8;\nu16 VAR9;\nint VAR10;\nif (FUN3(VAR4, \"STR\") != VAR4)\nreturn FUN4(-VAR11);\nif (FUN5(VAR4 + 5, 10, &VAR9) || VAR9 >= VAR12)\nreturn FUN4(-VAR11);\nVAR8 = FUN6(sizeof(struct VAR13), VAR14);\nif (!VAR8) {\nFUN7(\"STR\");\nreturn FUN4(-VAR15);\n}\nFUN8(&VAR8->VAR16);\nFUN9(&VAR8->VAR17);\nVAR8->VAR5 = VAR5;\nVAR8->VAR18 = VAR9;\nVAR10 = FUN10(&VAR19->VAR20, VAR2,\n&VAR8->VAR21, VAR8, VAR22);\nif (VAR10 < 0) {\nFUN11(VAR8);\nreturn NULL;\n}\nFUN12(&VAR23);\nFUN13(&VAR8->VAR17, &VAR24);\nFUN14(&VAR23);\nreturn &VAR8->VAR21;\n}\n",
      "code_before_change_normalized": "static struct VAR1 *\nFUN1(struct se_wwn *VAR2,\nstruct config_group *VAR3,\nconst char *VAR4)\n{\nstruct vhost_scsi_tport *VAR5 = FUN2(VAR2,\nstruct VAR6, VAR7);\nstruct vhost_scsi_tpg *VAR8;\nunsigned long VAR9;\nint VAR10;\nif (FUN3(VAR4, \"STR\") != VAR4)\nreturn FUN4(-VAR11);\nif (FUN5(VAR4 + 5, 10, &VAR9) || VAR9 > VAR12)\nreturn FUN4(-VAR11);\nVAR8 = FUN6(sizeof(struct VAR13), VAR14);\nif (!VAR8) {\nFUN7(\"STR\");\nreturn FUN4(-VAR15);\n}\nFUN8(&VAR8->VAR16);\nFUN9(&VAR8->VAR17);\nVAR8->VAR5 = VAR5;\nVAR8->VAR18 = VAR9;\nVAR10 = FUN10(&VAR19->VAR20, VAR2,\n&VAR8->VAR21, VAR8, VAR22);\nif (VAR10 < 0) {\nFUN11(VAR8);\nreturn NULL;\n}\nFUN12(&VAR23);\nFUN13(&VAR8->VAR17, &VAR24);\nFUN14(&VAR23);\nreturn &VAR8->VAR21;\n}\n",
      "code_after_change_raw": "static struct se_portal_group *\nvhost_scsi_make_tpg(struct se_wwn *wwn,\nstruct config_group *group,\nconst char *name)\n{\nstruct vhost_scsi_tport *tport = container_of(wwn,\nstruct vhost_scsi_tport, tport_wwn);\nstruct vhost_scsi_tpg *tpg;\nu16 tpgt;\nint ret;\nif (strstr(name, \"tpgt_\") != name)\nreturn ERR_PTR(-EINVAL);\nif (kstrtou16(name + 5, 10, &tpgt) || tpgt >= VHOST_SCSI_MAX_TARGET)\nreturn ERR_PTR(-EINVAL);\ntpg = kzalloc(sizeof(struct vhost_scsi_tpg), GFP_KERNEL);\nif (!tpg) {\npr_err(\"Unable to allocate struct vhost_scsi_tpg\");\nreturn ERR_PTR(-ENOMEM);\n}\nmutex_init(&tpg->tv_tpg_mutex);\nINIT_LIST_HEAD(&tpg->tv_tpg_list);\ntpg->tport = tport;\ntpg->tport_tpgt = tpgt;\nret = core_tpg_register(&vhost_scsi_fabric_configfs->tf_ops, wwn,\n&tpg->se_tpg, tpg, TRANSPORT_TPG_TYPE_NORMAL);\nif (ret < 0) {\nkfree(tpg);\nreturn NULL;\n}\nmutex_lock(&vhost_scsi_mutex);\nlist_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);\nmutex_unlock(&vhost_scsi_mutex);\nreturn &tpg->se_tpg;\n}\n",
      "code_before_change_raw": "static struct se_portal_group *\nvhost_scsi_make_tpg(struct se_wwn *wwn,\nstruct config_group *group,\nconst char *name)\n{\nstruct vhost_scsi_tport *tport = container_of(wwn,\nstruct vhost_scsi_tport, tport_wwn);\nstruct vhost_scsi_tpg *tpg;\nunsigned long tpgt;\nint ret;\nif (strstr(name, \"tpgt_\") != name)\nreturn ERR_PTR(-EINVAL);\nif (kstrtoul(name + 5, 10, &tpgt) || tpgt > UINT_MAX)\nreturn ERR_PTR(-EINVAL);\ntpg = kzalloc(sizeof(struct vhost_scsi_tpg), GFP_KERNEL);\nif (!tpg) {\npr_err(\"Unable to allocate struct vhost_scsi_tpg\");\nreturn ERR_PTR(-ENOMEM);\n}\nmutex_init(&tpg->tv_tpg_mutex);\nINIT_LIST_HEAD(&tpg->tv_tpg_list);\ntpg->tport = tport;\ntpg->tport_tpgt = tpgt;\nret = core_tpg_register(&vhost_scsi_fabric_configfs->tf_ops, wwn,\n&tpg->se_tpg, tpg, TRANSPORT_TPG_TYPE_NORMAL);\nif (ret < 0) {\nkfree(tpg);\nreturn NULL;\n}\nmutex_lock(&vhost_scsi_mutex);\nlist_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);\nmutex_unlock(&vhost_scsi_mutex);\nreturn &tpg->se_tpg;\n}\n"
    }
  ],
  "CVE-2015-5156": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Attempt to support a FRAGLIST feature without proper memory allocation.",
        "trigger_condition": "Crafted sequence of fragmented packets triggers buffer overflow and memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code attempts to support the FRAGLIST feature without ensuring proper memory allocation, leading to a denial of service vulnerability due to buffer overflow and memory corruption when handling fragmented packets."
      },
      "solution": "To mitigate the vulnerability, it is necessary to remove the unsupported FRAGLIST feature from the code. By removing the unsupported feature, the code avoids the potential buffer overflow and memory corruption issues associated with it. This solution ensures the security and stability of the system by preventing malicious exploitation of the vulnerability.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2015-5156 in the code snippet. The vulnerability arises from the attempt to support a FRAGLIST feature without proper memory allocation. This can lead to a denial of service (buffer overflow and memory corruption) when handling a crafted sequence of fragmented packets.\n\nTo fix this vulnerability, the modification involves removing the unsupported FRAGLIST feature from the code snippet. By removing the unsupported feature, the code avoids the potential buffer overflow and memory corruption issues associated with it. This modification helps ensure the security and stability of the system by preventing malicious exploitation of the vulnerability.",
      "GPT_purpose": "Initialize a network device for a virtio_net driver with specific features and configurations.",
      "GPT_function": "\n1. Allocate a network device with room for information.\n2. Set up network device features based on virtio features.\n3. Initialize device-specific information and work structures.\n4. Register the network device.\n5. Set up receive buffers and handle errors accordingly.",
      "CVE_id": "CVE-2015-5156",
      "code_before_change": "static int virtnet_probe(struct virtio_device *vdev)\n{\n\tint i, err;\n\tstruct net_device *dev;\n\tstruct virtnet_info *vi;\n\tu16 max_queue_pairs;\n\n\tif (!vdev->config->get) {\n\t\tdev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!virtnet_validate_features(vdev))\n\t\treturn -EINVAL;\n\n\t/* Find if host supports multiqueue virtio_net device */\n\terr = virtio_cread_feature(vdev, VIRTIO_NET_F_MQ,\n\t\t\t\t   struct virtio_net_config,\n\t\t\t\t   max_virtqueue_pairs, &max_queue_pairs);\n\n\t/* We need at least 2 queue's */\n\tif (err || max_queue_pairs < VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MIN ||\n\t    max_queue_pairs > VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MAX ||\n\t    !virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tmax_queue_pairs = 1;\n\n\t/* Allocate ourselves a network device with room for our info */\n\tdev = alloc_etherdev_mq(sizeof(struct virtnet_info), max_queue_pairs);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\t/* Set up network device as normal. */\n\tdev->priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\n\tdev->netdev_ops = &virtnet_netdev;\n\tdev->features = NETIF_F_HIGHDMA;\n\n\tdev->ethtool_ops = &virtnet_ethtool_ops;\n\tSET_NETDEV_DEV(dev, &vdev->dev);\n\n\t/* Do we support \"hardware\" checksums? */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {\n\t\t/* This opens up the world of extra features. */\n\t\tdev->hw_features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\n\t\tif (csum)\n\t\t\tdev->features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\n\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {\n\t\t\tdev->hw_features |= NETIF_F_TSO | NETIF_F_UFO\n\t\t\t\t| NETIF_F_TSO_ECN | NETIF_F_TSO6;\n\t\t}\n\t\t/* Individual feature bits: what can host handle? */\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO4))\n\t\t\tdev->hw_features |= NETIF_F_TSO;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO6))\n\t\t\tdev->hw_features |= NETIF_F_TSO6;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_ECN))\n\t\t\tdev->hw_features |= NETIF_F_TSO_ECN;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_UFO))\n\t\t\tdev->hw_features |= NETIF_F_UFO;\n\n\t\tdev->features |= NETIF_F_GSO_ROBUST;\n\n\t\tif (gso)\n\t\t\tdev->features |= dev->hw_features & (NETIF_F_ALL_TSO|NETIF_F_UFO);\n\t\t/* (!csum && gso) case will be fixed by register_netdev() */\n\t}\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_CSUM))\n\t\tdev->features |= NETIF_F_RXCSUM;\n\n\tdev->vlan_features = dev->features;\n\n\t/* Configuration may specify what MAC to use.  Otherwise random. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MAC))\n\t\tvirtio_cread_bytes(vdev,\n\t\t\t\t   offsetof(struct virtio_net_config, mac),\n\t\t\t\t   dev->dev_addr, dev->addr_len);\n\telse\n\t\teth_hw_addr_random(dev);\n\n\t/* Set up our device-specific information */\n\tvi = netdev_priv(dev);\n\tvi->dev = dev;\n\tvi->vdev = vdev;\n\tvdev->priv = vi;\n\tvi->stats = alloc_percpu(struct virtnet_stats);\n\terr = -ENOMEM;\n\tif (vi->stats == NULL)\n\t\tgoto free;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct virtnet_stats *virtnet_stats;\n\t\tvirtnet_stats = per_cpu_ptr(vi->stats, i);\n\t\tu64_stats_init(&virtnet_stats->tx_syncp);\n\t\tu64_stats_init(&virtnet_stats->rx_syncp);\n\t}\n\n\tINIT_WORK(&vi->config_work, virtnet_config_changed_work);\n\n\t/* If we can receive ANY GSO packets, we must allocate large ones. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO4) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO6) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_ECN) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_UFO))\n\t\tvi->big_packets = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF))\n\t\tvi->mergeable_rx_bufs = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr_mrg_rxbuf);\n\telse\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr);\n\n\tif (virtio_has_feature(vdev, VIRTIO_F_ANY_LAYOUT) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->any_header_sg = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tvi->has_cvq = true;\n\n\tif (vi->any_header_sg)\n\t\tdev->needed_headroom = vi->hdr_len;\n\n\t/* Use single tx/rx queue pair as default */\n\tvi->curr_queue_pairs = 1;\n\tvi->max_queue_pairs = max_queue_pairs;\n\n\t/* Allocate/initialize the rx/tx queues, and invoke find_vqs */\n\terr = init_vqs(vi);\n\tif (err)\n\t\tgoto free_stats;\n\n#ifdef CONFIG_SYSFS\n\tif (vi->mergeable_rx_bufs)\n\t\tdev->sysfs_rx_queue_group = &virtio_net_mrg_rx_group;\n#endif\n\tnetif_set_real_num_tx_queues(dev, vi->curr_queue_pairs);\n\tnetif_set_real_num_rx_queues(dev, vi->curr_queue_pairs);\n\n\terr = register_netdev(dev);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering device failed\\n\");\n\t\tgoto free_vqs;\n\t}\n\n\tvirtio_device_ready(vdev);\n\n\t/* Last of all, set up some receive buffers. */\n\tfor (i = 0; i < vi->curr_queue_pairs; i++) {\n\t\ttry_fill_recv(vi, &vi->rq[i], GFP_KERNEL);\n\n\t\t/* If we didn't even get one input buffer, we're useless. */\n\t\tif (vi->rq[i].vq->num_free ==\n\t\t    virtqueue_get_vring_size(vi->rq[i].vq)) {\n\t\t\tfree_unused_bufs(vi);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free_recv_bufs;\n\t\t}\n\t}\n\n\tvi->nb.notifier_call = &virtnet_cpu_callback;\n\terr = register_hotcpu_notifier(&vi->nb);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering cpu notifier failed\\n\");\n\t\tgoto free_recv_bufs;\n\t}\n\n\t/* Assume link up if device can't report link status,\n\t   otherwise get link status from config. */\n\tif (virtio_has_feature(vi->vdev, VIRTIO_NET_F_STATUS)) {\n\t\tnetif_carrier_off(dev);\n\t\tschedule_work(&vi->config_work);\n\t} else {\n\t\tvi->status = VIRTIO_NET_S_LINK_UP;\n\t\tnetif_carrier_on(dev);\n\t}\n\n\tpr_debug(\"virtnet: registered device %s with %d RX and TX vq's\\n\",\n\t\t dev->name, max_queue_pairs);\n\n\treturn 0;\n\nfree_recv_bufs:\n\tvi->vdev->config->reset(vdev);\n\n\tfree_receive_bufs(vi);\n\tunregister_netdev(dev);\nfree_vqs:\n\tcancel_delayed_work_sync(&vi->refill);\n\tfree_receive_page_frags(vi);\n\tvirtnet_del_vqs(vi);\nfree_stats:\n\tfree_percpu(vi->stats);\nfree:\n\tfree_netdev(dev);\n\treturn err;\n}",
      "code_after_change": "static int virtnet_probe(struct virtio_device *vdev)\n{\n\tint i, err;\n\tstruct net_device *dev;\n\tstruct virtnet_info *vi;\n\tu16 max_queue_pairs;\n\n\tif (!vdev->config->get) {\n\t\tdev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!virtnet_validate_features(vdev))\n\t\treturn -EINVAL;\n\n\t/* Find if host supports multiqueue virtio_net device */\n\terr = virtio_cread_feature(vdev, VIRTIO_NET_F_MQ,\n\t\t\t\t   struct virtio_net_config,\n\t\t\t\t   max_virtqueue_pairs, &max_queue_pairs);\n\n\t/* We need at least 2 queue's */\n\tif (err || max_queue_pairs < VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MIN ||\n\t    max_queue_pairs > VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MAX ||\n\t    !virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tmax_queue_pairs = 1;\n\n\t/* Allocate ourselves a network device with room for our info */\n\tdev = alloc_etherdev_mq(sizeof(struct virtnet_info), max_queue_pairs);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\t/* Set up network device as normal. */\n\tdev->priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\n\tdev->netdev_ops = &virtnet_netdev;\n\tdev->features = NETIF_F_HIGHDMA;\n\n\tdev->ethtool_ops = &virtnet_ethtool_ops;\n\tSET_NETDEV_DEV(dev, &vdev->dev);\n\n\t/* Do we support \"hardware\" checksums? */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {\n\t\t/* This opens up the world of extra features. */\n\t\tdev->hw_features |= NETIF_F_HW_CSUM | NETIF_F_SG;\n\t\tif (csum)\n\t\t\tdev->features |= NETIF_F_HW_CSUM | NETIF_F_SG;\n\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {\n\t\t\tdev->hw_features |= NETIF_F_TSO | NETIF_F_UFO\n\t\t\t\t| NETIF_F_TSO_ECN | NETIF_F_TSO6;\n\t\t}\n\t\t/* Individual feature bits: what can host handle? */\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO4))\n\t\t\tdev->hw_features |= NETIF_F_TSO;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO6))\n\t\t\tdev->hw_features |= NETIF_F_TSO6;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_ECN))\n\t\t\tdev->hw_features |= NETIF_F_TSO_ECN;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_UFO))\n\t\t\tdev->hw_features |= NETIF_F_UFO;\n\n\t\tdev->features |= NETIF_F_GSO_ROBUST;\n\n\t\tif (gso)\n\t\t\tdev->features |= dev->hw_features & (NETIF_F_ALL_TSO|NETIF_F_UFO);\n\t\t/* (!csum && gso) case will be fixed by register_netdev() */\n\t}\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_CSUM))\n\t\tdev->features |= NETIF_F_RXCSUM;\n\n\tdev->vlan_features = dev->features;\n\n\t/* Configuration may specify what MAC to use.  Otherwise random. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MAC))\n\t\tvirtio_cread_bytes(vdev,\n\t\t\t\t   offsetof(struct virtio_net_config, mac),\n\t\t\t\t   dev->dev_addr, dev->addr_len);\n\telse\n\t\teth_hw_addr_random(dev);\n\n\t/* Set up our device-specific information */\n\tvi = netdev_priv(dev);\n\tvi->dev = dev;\n\tvi->vdev = vdev;\n\tvdev->priv = vi;\n\tvi->stats = alloc_percpu(struct virtnet_stats);\n\terr = -ENOMEM;\n\tif (vi->stats == NULL)\n\t\tgoto free;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct virtnet_stats *virtnet_stats;\n\t\tvirtnet_stats = per_cpu_ptr(vi->stats, i);\n\t\tu64_stats_init(&virtnet_stats->tx_syncp);\n\t\tu64_stats_init(&virtnet_stats->rx_syncp);\n\t}\n\n\tINIT_WORK(&vi->config_work, virtnet_config_changed_work);\n\n\t/* If we can receive ANY GSO packets, we must allocate large ones. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO4) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO6) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_ECN) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_UFO))\n\t\tvi->big_packets = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF))\n\t\tvi->mergeable_rx_bufs = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr_mrg_rxbuf);\n\telse\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr);\n\n\tif (virtio_has_feature(vdev, VIRTIO_F_ANY_LAYOUT) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->any_header_sg = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tvi->has_cvq = true;\n\n\tif (vi->any_header_sg)\n\t\tdev->needed_headroom = vi->hdr_len;\n\n\t/* Use single tx/rx queue pair as default */\n\tvi->curr_queue_pairs = 1;\n\tvi->max_queue_pairs = max_queue_pairs;\n\n\t/* Allocate/initialize the rx/tx queues, and invoke find_vqs */\n\terr = init_vqs(vi);\n\tif (err)\n\t\tgoto free_stats;\n\n#ifdef CONFIG_SYSFS\n\tif (vi->mergeable_rx_bufs)\n\t\tdev->sysfs_rx_queue_group = &virtio_net_mrg_rx_group;\n#endif\n\tnetif_set_real_num_tx_queues(dev, vi->curr_queue_pairs);\n\tnetif_set_real_num_rx_queues(dev, vi->curr_queue_pairs);\n\n\terr = register_netdev(dev);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering device failed\\n\");\n\t\tgoto free_vqs;\n\t}\n\n\tvirtio_device_ready(vdev);\n\n\t/* Last of all, set up some receive buffers. */\n\tfor (i = 0; i < vi->curr_queue_pairs; i++) {\n\t\ttry_fill_recv(vi, &vi->rq[i], GFP_KERNEL);\n\n\t\t/* If we didn't even get one input buffer, we're useless. */\n\t\tif (vi->rq[i].vq->num_free ==\n\t\t    virtqueue_get_vring_size(vi->rq[i].vq)) {\n\t\t\tfree_unused_bufs(vi);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free_recv_bufs;\n\t\t}\n\t}\n\n\tvi->nb.notifier_call = &virtnet_cpu_callback;\n\terr = register_hotcpu_notifier(&vi->nb);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering cpu notifier failed\\n\");\n\t\tgoto free_recv_bufs;\n\t}\n\n\t/* Assume link up if device can't report link status,\n\t   otherwise get link status from config. */\n\tif (virtio_has_feature(vi->vdev, VIRTIO_NET_F_STATUS)) {\n\t\tnetif_carrier_off(dev);\n\t\tschedule_work(&vi->config_work);\n\t} else {\n\t\tvi->status = VIRTIO_NET_S_LINK_UP;\n\t\tnetif_carrier_on(dev);\n\t}\n\n\tpr_debug(\"virtnet: registered device %s with %d RX and TX vq's\\n\",\n\t\t dev->name, max_queue_pairs);\n\n\treturn 0;\n\nfree_recv_bufs:\n\tvi->vdev->config->reset(vdev);\n\n\tfree_receive_bufs(vi);\n\tunregister_netdev(dev);\nfree_vqs:\n\tcancel_delayed_work_sync(&vi->refill);\n\tfree_receive_page_frags(vi);\n\tvirtnet_del_vqs(vi);\nfree_stats:\n\tfree_percpu(vi->stats);\nfree:\n\tfree_netdev(dev);\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\t\tdev->hw_features |= NETIF_F_HW_CSUM | NETIF_F_SG;",
          "\t\t\tdev->features |= NETIF_F_HW_CSUM | NETIF_F_SG;"
        ],
        "deleted": [
          "\t\tdev->hw_features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;",
          "\t\t\tdev->features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;"
        ]
      },
      "preconditions_for_vulnerability": "Attempt to support a FRAGLIST feature without proper memory allocation.",
      "trigger_condition": "Crafted sequence of fragmented packets triggers buffer overflow and memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code attempts to support the FRAGLIST feature without ensuring proper memory allocation, leading to a denial of service vulnerability due to buffer overflow and memory corruption when handling fragmented packets.",
      "id": 72,
      "code_after_change_normalized": "static int FUN1(struct virtio_device *VAR1)\n{\nint VAR2, VAR3;\nstruct net_device *VAR4;\nstruct virtnet_info *VAR5;\nu16 VAR6;\nif (!VAR1->VAR7->VAR8) {\nFUN2(&VAR1->VAR4, \"STR\",\nVAR9);\nreturn -VAR10;\n}\nif (!FUN3(VAR1))\nreturn -VAR10;\nVAR3 = FUN4(VAR1, VAR11,\nstruct VAR12,\nVAR13, &VAR6);\nif (VAR3 || VAR6 < VAR14 ||\nVAR6 > VAR15 ||\n!FUN5(VAR1, VAR16))\nVAR6 = 1;\nVAR4 = FUN6(sizeof(struct VAR17), VAR6);\nif (!VAR4)\nreturn -VAR18;\nVAR4->VAR19 |= VAR20 | VAR21;\nVAR4->VAR22 = &VAR23;\nVAR4->VAR24 = VAR25;\nVAR4->VAR26 = &VAR27;\nFUN7(VAR4, &VAR1->VAR4);\nif (FUN5(VAR1, VAR28)) {\nVAR4->VAR29 |= VAR30 | VAR31;\nif (VAR32)\nVAR4->VAR24 |= VAR30 | VAR31;\nif (FUN5(VAR1, VAR33)) {\nVAR4->VAR29 |= VAR34 | VAR35\n| VAR36 | VAR37;\n}\nif (FUN5(VAR1, VAR38))\nVAR4->VAR29 |= VAR34;\nif (FUN5(VAR1, VAR39))\nVAR4->VAR29 |= VAR37;\nif (FUN5(VAR1, VAR40))\nVAR4->VAR29 |= VAR36;\nif (FUN5(VAR1, VAR41))\nVAR4->VAR29 |= VAR35;\nVAR4->VAR24 |= VAR42;\nif (VAR43)\nVAR4->VAR24 |= VAR4->VAR29 & (VAR44|VAR35);\n}\nif (FUN5(VAR1, VAR45))\nVAR4->VAR24 |= VAR46;\nVAR4->VAR47 = VAR4->VAR24;\nif (FUN5(VAR1, VAR48))\nFUN8(VAR1,\nFUN9(struct VAR12, VAR49),\nVAR4->VAR50, VAR4->VAR51);\nelse\nFUN10(VAR4);\nVAR5 = FUN11(VAR4);\nVAR5->VAR4 = VAR4;\nVAR5->VAR1 = VAR1;\nVAR1->VAR52 = VAR5;\nVAR5->VAR53 = FUN12(struct VAR54);\nVAR3 = -VAR18;\nif (VAR5->VAR53 == NULL)\ngoto VAR55;\nFUN13(VAR2) {\nstruct VAR54 *VAR54;\nVAR54 = FUN14(VAR5->VAR53, VAR2);\nFUN15(&VAR54->VAR56);\nFUN15(&VAR54->VAR57);\n}\nFUN16(&VAR5->VAR58, VAR59);\nif (FUN5(VAR1, VAR60) ||\nFUN5(VAR1, VAR61) ||\nFUN5(VAR1, VAR62) ||\nFUN5(VAR1, VAR63))\nVAR5->VAR64 = true;\nif (FUN5(VAR1, VAR65))\nVAR5->VAR66 = true;\nif (FUN5(VAR1, VAR65) ||\nFUN5(VAR1, VAR67))\nVAR5->VAR68 = sizeof(struct VAR69);\nelse\nVAR5->VAR68 = sizeof(struct VAR70);\nif (FUN5(VAR1, VAR71) ||\nFUN5(VAR1, VAR67))\nVAR5->VAR72 = true;\nif (FUN5(VAR1, VAR16))\nVAR5->VAR73 = true;\nif (VAR5->VAR72)\nVAR4->VAR74 = VAR5->VAR68;\nVAR5->VAR75 = 1;\nVAR5->VAR6 = VAR6;\nVAR3 = FUN17(VAR5);\nif (VAR3)\ngoto VAR76;\n#ifdef VAR77\nif (VAR5->VAR66)\nVAR4->VAR78 = &VAR79;\n#VAR80\nFUN18(VAR4, VAR5->VAR75);\nFUN19(VAR4, VAR5->VAR75);\nVAR3 = FUN20(VAR4);\nif (VAR3) {\nFUN21(\"STR\");\ngoto VAR81;\n}\nFUN22(VAR1);\nfor (VAR2 = 0; VAR2 < VAR5->VAR75; VAR2++) {\nFUN23(VAR5, &VAR5->VAR82[VAR2], VAR83);\nif (VAR5->VAR82[VAR2].VAR84->VAR85 ==\nFUN24(VAR5->VAR82[VAR2].VAR84)) {\nFUN25(VAR5);\nVAR3 = -VAR18;\ngoto VAR86;\n}\n}\nVAR5->VAR87.VAR88 = &VAR89;\nVAR3 = FUN26(&VAR5->VAR87);\nif (VAR3) {\nFUN21(\"STR\");\ngoto VAR86;\n}\nif (FUN5(VAR5->VAR1, VAR90)) {\nFUN27(VAR4);\nFUN28(&VAR5->VAR58);\n} else {\nVAR5->VAR91 = VAR92;\nFUN29(VAR4);\n}\nFUN21(\"STR\",\nVAR4->VAR93, VAR6);\nreturn 0;\nVAR86:\nVAR5->VAR1->VAR7->FUN30(VAR1);\nFUN31(VAR5);\nFUN32(VAR4);\nVAR81:\nFUN33(&VAR5->VAR94);\nFUN34(VAR5);\nFUN35(VAR5);\nVAR76:\nFUN36(VAR5->VAR53);\nVAR55:\nFUN37(VAR4);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct virtio_device *VAR1)\n{\nint VAR2, VAR3;\nstruct net_device *VAR4;\nstruct virtnet_info *VAR5;\nu16 VAR6;\nif (!VAR1->VAR7->VAR8) {\nFUN2(&VAR1->VAR4, \"STR\",\nVAR9);\nreturn -VAR10;\n}\nif (!FUN3(VAR1))\nreturn -VAR10;\nVAR3 = FUN4(VAR1, VAR11,\nstruct VAR12,\nVAR13, &VAR6);\nif (VAR3 || VAR6 < VAR14 ||\nVAR6 > VAR15 ||\n!FUN5(VAR1, VAR16))\nVAR6 = 1;\nVAR4 = FUN6(sizeof(struct VAR17), VAR6);\nif (!VAR4)\nreturn -VAR18;\nVAR4->VAR19 |= VAR20 | VAR21;\nVAR4->VAR22 = &VAR23;\nVAR4->VAR24 = VAR25;\nVAR4->VAR26 = &VAR27;\nFUN7(VAR4, &VAR1->VAR4);\nif (FUN5(VAR1, VAR28)) {\nVAR4->VAR29 |= VAR30|VAR31|VAR32;\nif (VAR33)\nVAR4->VAR24 |= VAR30|VAR31|VAR32;\nif (FUN5(VAR1, VAR34)) {\nVAR4->VAR29 |= VAR35 | VAR36\n| VAR37 | VAR38;\n}\nif (FUN5(VAR1, VAR39))\nVAR4->VAR29 |= VAR35;\nif (FUN5(VAR1, VAR40))\nVAR4->VAR29 |= VAR38;\nif (FUN5(VAR1, VAR41))\nVAR4->VAR29 |= VAR37;\nif (FUN5(VAR1, VAR42))\nVAR4->VAR29 |= VAR36;\nVAR4->VAR24 |= VAR43;\nif (VAR44)\nVAR4->VAR24 |= VAR4->VAR29 & (VAR45|VAR36);\n}\nif (FUN5(VAR1, VAR46))\nVAR4->VAR24 |= VAR47;\nVAR4->VAR48 = VAR4->VAR24;\nif (FUN5(VAR1, VAR49))\nFUN8(VAR1,\nFUN9(struct VAR12, VAR50),\nVAR4->VAR51, VAR4->VAR52);\nelse\nFUN10(VAR4);\nVAR5 = FUN11(VAR4);\nVAR5->VAR4 = VAR4;\nVAR5->VAR1 = VAR1;\nVAR1->VAR53 = VAR5;\nVAR5->VAR54 = FUN12(struct VAR55);\nVAR3 = -VAR18;\nif (VAR5->VAR54 == NULL)\ngoto VAR56;\nFUN13(VAR2) {\nstruct VAR55 *VAR55;\nVAR55 = FUN14(VAR5->VAR54, VAR2);\nFUN15(&VAR55->VAR57);\nFUN15(&VAR55->VAR58);\n}\nFUN16(&VAR5->VAR59, VAR60);\nif (FUN5(VAR1, VAR61) ||\nFUN5(VAR1, VAR62) ||\nFUN5(VAR1, VAR63) ||\nFUN5(VAR1, VAR64))\nVAR5->VAR65 = true;\nif (FUN5(VAR1, VAR66))\nVAR5->VAR67 = true;\nif (FUN5(VAR1, VAR66) ||\nFUN5(VAR1, VAR68))\nVAR5->VAR69 = sizeof(struct VAR70);\nelse\nVAR5->VAR69 = sizeof(struct VAR71);\nif (FUN5(VAR1, VAR72) ||\nFUN5(VAR1, VAR68))\nVAR5->VAR73 = true;\nif (FUN5(VAR1, VAR16))\nVAR5->VAR74 = true;\nif (VAR5->VAR73)\nVAR4->VAR75 = VAR5->VAR69;\nVAR5->VAR76 = 1;\nVAR5->VAR6 = VAR6;\nVAR3 = FUN17(VAR5);\nif (VAR3)\ngoto VAR77;\n#ifdef VAR78\nif (VAR5->VAR67)\nVAR4->VAR79 = &VAR80;\n#VAR81\nFUN18(VAR4, VAR5->VAR76);\nFUN19(VAR4, VAR5->VAR76);\nVAR3 = FUN20(VAR4);\nif (VAR3) {\nFUN21(\"STR\");\ngoto VAR82;\n}\nFUN22(VAR1);\nfor (VAR2 = 0; VAR2 < VAR5->VAR76; VAR2++) {\nFUN23(VAR5, &VAR5->VAR83[VAR2], VAR84);\nif (VAR5->VAR83[VAR2].VAR85->VAR86 ==\nFUN24(VAR5->VAR83[VAR2].VAR85)) {\nFUN25(VAR5);\nVAR3 = -VAR18;\ngoto VAR87;\n}\n}\nVAR5->VAR88.VAR89 = &VAR90;\nVAR3 = FUN26(&VAR5->VAR88);\nif (VAR3) {\nFUN21(\"STR\");\ngoto VAR87;\n}\nif (FUN5(VAR5->VAR1, VAR91)) {\nFUN27(VAR4);\nFUN28(&VAR5->VAR59);\n} else {\nVAR5->VAR92 = VAR93;\nFUN29(VAR4);\n}\nFUN21(\"STR\",\nVAR4->VAR94, VAR6);\nreturn 0;\nVAR87:\nVAR5->VAR1->VAR7->FUN30(VAR1);\nFUN31(VAR5);\nFUN32(VAR4);\nVAR82:\nFUN33(&VAR5->VAR95);\nFUN34(VAR5);\nFUN35(VAR5);\nVAR77:\nFUN36(VAR5->VAR54);\nVAR56:\nFUN37(VAR4);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static int virtnet_probe(struct virtio_device *vdev)\n{\nint i, err;\nstruct net_device *dev;\nstruct virtnet_info *vi;\nu16 max_queue_pairs;\nif (!vdev->config->get) {\ndev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n__func__);\nreturn -EINVAL;\n}\nif (!virtnet_validate_features(vdev))\nreturn -EINVAL;\nerr = virtio_cread_feature(vdev, VIRTIO_NET_F_MQ,\nstruct virtio_net_config,\nmax_virtqueue_pairs, &max_queue_pairs);\nif (err || max_queue_pairs < VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MIN ||\nmax_queue_pairs > VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MAX ||\n!virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\nmax_queue_pairs = 1;\ndev = alloc_etherdev_mq(sizeof(struct virtnet_info), max_queue_pairs);\nif (!dev)\nreturn -ENOMEM;\ndev->priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\ndev->netdev_ops = &virtnet_netdev;\ndev->features = NETIF_F_HIGHDMA;\ndev->ethtool_ops = &virtnet_ethtool_ops;\nSET_NETDEV_DEV(dev, &vdev->dev);\nif (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {\ndev->hw_features |= NETIF_F_HW_CSUM | NETIF_F_SG;\nif (csum)\ndev->features |= NETIF_F_HW_CSUM | NETIF_F_SG;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {\ndev->hw_features |= NETIF_F_TSO | NETIF_F_UFO\n| NETIF_F_TSO_ECN | NETIF_F_TSO6;\n}\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO4))\ndev->hw_features |= NETIF_F_TSO;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO6))\ndev->hw_features |= NETIF_F_TSO6;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_ECN))\ndev->hw_features |= NETIF_F_TSO_ECN;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_UFO))\ndev->hw_features |= NETIF_F_UFO;\ndev->features |= NETIF_F_GSO_ROBUST;\nif (gso)\ndev->features |= dev->hw_features & (NETIF_F_ALL_TSO|NETIF_F_UFO);\n}\nif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_CSUM))\ndev->features |= NETIF_F_RXCSUM;\ndev->vlan_features = dev->features;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_MAC))\nvirtio_cread_bytes(vdev,\noffsetof(struct virtio_net_config, mac),\ndev->dev_addr, dev->addr_len);\nelse\neth_hw_addr_random(dev);\nvi = netdev_priv(dev);\nvi->dev = dev;\nvi->vdev = vdev;\nvdev->priv = vi;\nvi->stats = alloc_percpu(struct virtnet_stats);\nerr = -ENOMEM;\nif (vi->stats == NULL)\ngoto free;\nfor_each_possible_cpu(i) {\nstruct virtnet_stats *virtnet_stats;\nvirtnet_stats = per_cpu_ptr(vi->stats, i);\nu64_stats_init(&virtnet_stats->tx_syncp);\nu64_stats_init(&virtnet_stats->rx_syncp);\n}\nINIT_WORK(&vi->config_work, virtnet_config_changed_work);\nif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO4) ||\nvirtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO6) ||\nvirtio_has_feature(vdev, VIRTIO_NET_F_GUEST_ECN) ||\nvirtio_has_feature(vdev, VIRTIO_NET_F_GUEST_UFO))\nvi->big_packets = true;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF))\nvi->mergeable_rx_bufs = true;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF) ||\nvirtio_has_feature(vdev, VIRTIO_F_VERSION_1))\nvi->hdr_len = sizeof(struct virtio_net_hdr_mrg_rxbuf);\nelse\nvi->hdr_len = sizeof(struct virtio_net_hdr);\nif (virtio_has_feature(vdev, VIRTIO_F_ANY_LAYOUT) ||\nvirtio_has_feature(vdev, VIRTIO_F_VERSION_1))\nvi->any_header_sg = true;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\nvi->has_cvq = true;\nif (vi->any_header_sg)\ndev->needed_headroom = vi->hdr_len;\nvi->curr_queue_pairs = 1;\nvi->max_queue_pairs = max_queue_pairs;\nerr = init_vqs(vi);\nif (err)\ngoto free_stats;\n#ifdef CONFIG_SYSFS\nif (vi->mergeable_rx_bufs)\ndev->sysfs_rx_queue_group = &virtio_net_mrg_rx_group;\n#endif\nnetif_set_real_num_tx_queues(dev, vi->curr_queue_pairs);\nnetif_set_real_num_rx_queues(dev, vi->curr_queue_pairs);\nerr = register_netdev(dev);\nif (err) {\npr_debug(\"virtio_net: registering device failed\\n\");\ngoto free_vqs;\n}\nvirtio_device_ready(vdev);\nfor (i = 0; i < vi->curr_queue_pairs; i++) {\ntry_fill_recv(vi, &vi->rq[i], GFP_KERNEL);\nif (vi->rq[i].vq->num_free ==\nvirtqueue_get_vring_size(vi->rq[i].vq)) {\nfree_unused_bufs(vi);\nerr = -ENOMEM;\ngoto free_recv_bufs;\n}\n}\nvi->nb.notifier_call = &virtnet_cpu_callback;\nerr = register_hotcpu_notifier(&vi->nb);\nif (err) {\npr_debug(\"virtio_net: registering cpu notifier failed\\n\");\ngoto free_recv_bufs;\n}\nif (virtio_has_feature(vi->vdev, VIRTIO_NET_F_STATUS)) {\nnetif_carrier_off(dev);\nschedule_work(&vi->config_work);\n} else {\nvi->status = VIRTIO_NET_S_LINK_UP;\nnetif_carrier_on(dev);\n}\npr_debug(\"virtnet: registered device %s with %d RX and TX vq's\\n\",\ndev->name, max_queue_pairs);\nreturn 0;\nfree_recv_bufs:\nvi->vdev->config->reset(vdev);\nfree_receive_bufs(vi);\nunregister_netdev(dev);\nfree_vqs:\ncancel_delayed_work_sync(&vi->refill);\nfree_receive_page_frags(vi);\nvirtnet_del_vqs(vi);\nfree_stats:\nfree_percpu(vi->stats);\nfree:\nfree_netdev(dev);\nreturn err;\n}\n",
      "code_before_change_raw": "static int virtnet_probe(struct virtio_device *vdev)\n{\nint i, err;\nstruct net_device *dev;\nstruct virtnet_info *vi;\nu16 max_queue_pairs;\nif (!vdev->config->get) {\ndev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n__func__);\nreturn -EINVAL;\n}\nif (!virtnet_validate_features(vdev))\nreturn -EINVAL;\nerr = virtio_cread_feature(vdev, VIRTIO_NET_F_MQ,\nstruct virtio_net_config,\nmax_virtqueue_pairs, &max_queue_pairs);\nif (err || max_queue_pairs < VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MIN ||\nmax_queue_pairs > VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MAX ||\n!virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\nmax_queue_pairs = 1;\ndev = alloc_etherdev_mq(sizeof(struct virtnet_info), max_queue_pairs);\nif (!dev)\nreturn -ENOMEM;\ndev->priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\ndev->netdev_ops = &virtnet_netdev;\ndev->features = NETIF_F_HIGHDMA;\ndev->ethtool_ops = &virtnet_ethtool_ops;\nSET_NETDEV_DEV(dev, &vdev->dev);\nif (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {\ndev->hw_features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\nif (csum)\ndev->features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {\ndev->hw_features |= NETIF_F_TSO | NETIF_F_UFO\n| NETIF_F_TSO_ECN | NETIF_F_TSO6;\n}\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO4))\ndev->hw_features |= NETIF_F_TSO;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO6))\ndev->hw_features |= NETIF_F_TSO6;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_ECN))\ndev->hw_features |= NETIF_F_TSO_ECN;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_UFO))\ndev->hw_features |= NETIF_F_UFO;\ndev->features |= NETIF_F_GSO_ROBUST;\nif (gso)\ndev->features |= dev->hw_features & (NETIF_F_ALL_TSO|NETIF_F_UFO);\n}\nif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_CSUM))\ndev->features |= NETIF_F_RXCSUM;\ndev->vlan_features = dev->features;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_MAC))\nvirtio_cread_bytes(vdev,\noffsetof(struct virtio_net_config, mac),\ndev->dev_addr, dev->addr_len);\nelse\neth_hw_addr_random(dev);\nvi = netdev_priv(dev);\nvi->dev = dev;\nvi->vdev = vdev;\nvdev->priv = vi;\nvi->stats = alloc_percpu(struct virtnet_stats);\nerr = -ENOMEM;\nif (vi->stats == NULL)\ngoto free;\nfor_each_possible_cpu(i) {\nstruct virtnet_stats *virtnet_stats;\nvirtnet_stats = per_cpu_ptr(vi->stats, i);\nu64_stats_init(&virtnet_stats->tx_syncp);\nu64_stats_init(&virtnet_stats->rx_syncp);\n}\nINIT_WORK(&vi->config_work, virtnet_config_changed_work);\nif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO4) ||\nvirtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO6) ||\nvirtio_has_feature(vdev, VIRTIO_NET_F_GUEST_ECN) ||\nvirtio_has_feature(vdev, VIRTIO_NET_F_GUEST_UFO))\nvi->big_packets = true;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF))\nvi->mergeable_rx_bufs = true;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF) ||\nvirtio_has_feature(vdev, VIRTIO_F_VERSION_1))\nvi->hdr_len = sizeof(struct virtio_net_hdr_mrg_rxbuf);\nelse\nvi->hdr_len = sizeof(struct virtio_net_hdr);\nif (virtio_has_feature(vdev, VIRTIO_F_ANY_LAYOUT) ||\nvirtio_has_feature(vdev, VIRTIO_F_VERSION_1))\nvi->any_header_sg = true;\nif (virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\nvi->has_cvq = true;\nif (vi->any_header_sg)\ndev->needed_headroom = vi->hdr_len;\nvi->curr_queue_pairs = 1;\nvi->max_queue_pairs = max_queue_pairs;\nerr = init_vqs(vi);\nif (err)\ngoto free_stats;\n#ifdef CONFIG_SYSFS\nif (vi->mergeable_rx_bufs)\ndev->sysfs_rx_queue_group = &virtio_net_mrg_rx_group;\n#endif\nnetif_set_real_num_tx_queues(dev, vi->curr_queue_pairs);\nnetif_set_real_num_rx_queues(dev, vi->curr_queue_pairs);\nerr = register_netdev(dev);\nif (err) {\npr_debug(\"virtio_net: registering device failed\\n\");\ngoto free_vqs;\n}\nvirtio_device_ready(vdev);\nfor (i = 0; i < vi->curr_queue_pairs; i++) {\ntry_fill_recv(vi, &vi->rq[i], GFP_KERNEL);\nif (vi->rq[i].vq->num_free ==\nvirtqueue_get_vring_size(vi->rq[i].vq)) {\nfree_unused_bufs(vi);\nerr = -ENOMEM;\ngoto free_recv_bufs;\n}\n}\nvi->nb.notifier_call = &virtnet_cpu_callback;\nerr = register_hotcpu_notifier(&vi->nb);\nif (err) {\npr_debug(\"virtio_net: registering cpu notifier failed\\n\");\ngoto free_recv_bufs;\n}\nif (virtio_has_feature(vi->vdev, VIRTIO_NET_F_STATUS)) {\nnetif_carrier_off(dev);\nschedule_work(&vi->config_work);\n} else {\nvi->status = VIRTIO_NET_S_LINK_UP;\nnetif_carrier_on(dev);\n}\npr_debug(\"virtnet: registered device %s with %d RX and TX vq's\\n\",\ndev->name, max_queue_pairs);\nreturn 0;\nfree_recv_bufs:\nvi->vdev->config->reset(vdev);\nfree_receive_bufs(vi);\nunregister_netdev(dev);\nfree_vqs:\ncancel_delayed_work_sync(&vi->refill);\nfree_receive_page_frags(vi);\nvirtnet_del_vqs(vi);\nfree_stats:\nfree_percpu(vi->stats);\nfree:\nfree_netdev(dev);\nreturn err;\n}\n"
    }
  ],
  "CVE-2015-5283": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect sequence of protocol-initialization steps in the sctp_init function.",
        "trigger_condition": "Local users creating SCTP sockets before all initialization steps have finished, leading to a denial of service (panic or memory corruption).",
        "specific_code_behavior_causing_vulnerability": "The code in sctp_init function does not complete all necessary protocol-initialization steps before allowing SCTP sockets to be created, potentially causing a denial of service or memory corruption if sockets are created prematurely."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that all protocol-initialization steps are completed in the correct order before allowing SCTP sockets to be created. This involves registering pernet subsystems for SCTP operations in the correct sequence and ensuring that all necessary steps are finished before socket creation is permitted. By following the correct initialization order, the vulnerability can be addressed and the system's security and stability can be enhanced.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2015-5283, which involves an incorrect sequence of protocol-initialization steps in the sctp_init function. This vulnerability allows local users to cause a denial of service (panic or memory corruption) by creating SCTP sockets before all of the initialization steps have finished.\n\nThe modification involves changing the registration of pernet subsystems for SCTP operations. By registering the pernet subsystems in the correct order and ensuring that all necessary steps are completed before allowing SCTP sockets to be created, the vulnerability can be mitigated. This ensures that the initialization of SCTP protocol components is done in the correct sequence, preventing potential issues that could lead to denial of service or memory corruption.\n\nIn summary, the modification is necessary to ensure that the initialization steps for SCTP protocol components are completed in the correct order, thereby addressing the vulnerability and enhancing the overall security and stability of the system.",
      "GPT_purpose": "Initialize the SCTP protocol by setting up various data structures and hash tables.",
      "GPT_function": "\n1. Initialize SCTP protocol-specific variables and parameters.\n2. Allocate and initialize various hash tables for associations, endpoints, and ports.\n3. Register SCTP with the networking subsystem.\n4. Handle error cases and cleanup resources appropriately.",
      "CVE_id": "CVE-2015-5283",
      "code_before_change": "static __init int sctp_init(void)\n{\n\tint i;\n\tint status = -EINVAL;\n\tunsigned long goal;\n\tunsigned long limit;\n\tint max_share;\n\tint order;\n\n\tsock_skb_cb_check_size(sizeof(struct sctp_ulpevent));\n\n\t/* Allocate bind_bucket and chunk caches. */\n\tstatus = -ENOBUFS;\n\tsctp_bucket_cachep = kmem_cache_create(\"sctp_bind_bucket\",\n\t\t\t\t\t       sizeof(struct sctp_bind_bucket),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_bucket_cachep)\n\t\tgoto out;\n\n\tsctp_chunk_cachep = kmem_cache_create(\"sctp_chunk\",\n\t\t\t\t\t       sizeof(struct sctp_chunk),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_chunk_cachep)\n\t\tgoto err_chunk_cachep;\n\n\tstatus = percpu_counter_init(&sctp_sockets_allocated, 0, GFP_KERNEL);\n\tif (status)\n\t\tgoto err_percpu_counter_init;\n\n\t/* Implementation specific variables. */\n\n\t/* Initialize default stream count setup information. */\n\tsctp_max_instreams    \t\t= SCTP_DEFAULT_INSTREAMS;\n\tsctp_max_outstreams   \t\t= SCTP_DEFAULT_OUTSTREAMS;\n\n\t/* Initialize handle used for association ids. */\n\tidr_init(&sctp_assocs_id);\n\n\tlimit = nr_free_buffer_pages() / 8;\n\tlimit = max(limit, 128UL);\n\tsysctl_sctp_mem[0] = limit / 4 * 3;\n\tsysctl_sctp_mem[1] = limit;\n\tsysctl_sctp_mem[2] = sysctl_sctp_mem[0] * 2;\n\n\t/* Set per-socket limits to no more than 1/128 the pressure threshold*/\n\tlimit = (sysctl_sctp_mem[1]) << (PAGE_SHIFT - 7);\n\tmax_share = min(4UL*1024*1024, limit);\n\n\tsysctl_sctp_rmem[0] = SK_MEM_QUANTUM; /* give each asoc 1 page min */\n\tsysctl_sctp_rmem[1] = 1500 * SKB_TRUESIZE(1);\n\tsysctl_sctp_rmem[2] = max(sysctl_sctp_rmem[1], max_share);\n\n\tsysctl_sctp_wmem[0] = SK_MEM_QUANTUM;\n\tsysctl_sctp_wmem[1] = 16*1024;\n\tsysctl_sctp_wmem[2] = max(64*1024, max_share);\n\n\t/* Size and allocate the association hash table.\n\t * The methodology is similar to that of the tcp hash tables.\n\t */\n\tif (totalram_pages >= (128 * 1024))\n\t\tgoal = totalram_pages >> (22 - PAGE_SHIFT);\n\telse\n\t\tgoal = totalram_pages >> (24 - PAGE_SHIFT);\n\n\tfor (order = 0; (1UL << order) < goal; order++)\n\t\t;\n\n\tdo {\n\t\tsctp_assoc_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_hashbucket);\n\t\tif ((sctp_assoc_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_assoc_hashtable = (struct sctp_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_assoc_hashtable && --order > 0);\n\tif (!sctp_assoc_hashtable) {\n\t\tpr_err(\"Failed association hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ahash_alloc;\n\t}\n\tfor (i = 0; i < sctp_assoc_hashsize; i++) {\n\t\trwlock_init(&sctp_assoc_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_assoc_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the endpoint hash table.  */\n\tsctp_ep_hashsize = 64;\n\tsctp_ep_hashtable =\n\t\tkmalloc(64 * sizeof(struct sctp_hashbucket), GFP_KERNEL);\n\tif (!sctp_ep_hashtable) {\n\t\tpr_err(\"Failed endpoint_hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ehash_alloc;\n\t}\n\tfor (i = 0; i < sctp_ep_hashsize; i++) {\n\t\trwlock_init(&sctp_ep_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_ep_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the SCTP port hash table.  */\n\tdo {\n\t\tsctp_port_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_bind_hashbucket);\n\t\tif ((sctp_port_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_port_hashtable = (struct sctp_bind_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_port_hashtable && --order > 0);\n\tif (!sctp_port_hashtable) {\n\t\tpr_err(\"Failed bind hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_bhash_alloc;\n\t}\n\tfor (i = 0; i < sctp_port_hashsize; i++) {\n\t\tspin_lock_init(&sctp_port_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_port_hashtable[i].chain);\n\t}\n\n\tpr_info(\"Hash tables configured (established %d bind %d)\\n\",\n\t\tsctp_assoc_hashsize, sctp_port_hashsize);\n\n\tsctp_sysctl_register();\n\n\tINIT_LIST_HEAD(&sctp_address_families);\n\tsctp_v4_pf_init();\n\tsctp_v6_pf_init();\n\n\tstatus = sctp_v4_protosw_init();\n\n\tif (status)\n\t\tgoto err_protosw_init;\n\n\tstatus = sctp_v6_protosw_init();\n\tif (status)\n\t\tgoto err_v6_protosw_init;\n\n\tstatus = register_pernet_subsys(&sctp_net_ops);\n\tif (status)\n\t\tgoto err_register_pernet_subsys;\n\n\tstatus = sctp_v4_add_protocol();\n\tif (status)\n\t\tgoto err_add_protocol;\n\n\t/* Register SCTP with inet6 layer.  */\n\tstatus = sctp_v6_add_protocol();\n\tif (status)\n\t\tgoto err_v6_add_protocol;\n\nout:\n\treturn status;\nerr_v6_add_protocol:\n\tsctp_v4_del_protocol();\nerr_add_protocol:\n\tunregister_pernet_subsys(&sctp_net_ops);\nerr_register_pernet_subsys:\n\tsctp_v6_protosw_exit();\nerr_v6_protosw_init:\n\tsctp_v4_protosw_exit();\nerr_protosw_init:\n\tsctp_v4_pf_exit();\n\tsctp_v6_pf_exit();\n\tsctp_sysctl_unregister();\n\tfree_pages((unsigned long)sctp_port_hashtable,\n\t\t   get_order(sctp_port_hashsize *\n\t\t\t     sizeof(struct sctp_bind_hashbucket)));\nerr_bhash_alloc:\n\tkfree(sctp_ep_hashtable);\nerr_ehash_alloc:\n\tfree_pages((unsigned long)sctp_assoc_hashtable,\n\t\t   get_order(sctp_assoc_hashsize *\n\t\t\t     sizeof(struct sctp_hashbucket)));\nerr_ahash_alloc:\n\tpercpu_counter_destroy(&sctp_sockets_allocated);\nerr_percpu_counter_init:\n\tkmem_cache_destroy(sctp_chunk_cachep);\nerr_chunk_cachep:\n\tkmem_cache_destroy(sctp_bucket_cachep);\n\tgoto out;\n}",
      "code_after_change": "static __init int sctp_init(void)\n{\n\tint i;\n\tint status = -EINVAL;\n\tunsigned long goal;\n\tunsigned long limit;\n\tint max_share;\n\tint order;\n\n\tsock_skb_cb_check_size(sizeof(struct sctp_ulpevent));\n\n\t/* Allocate bind_bucket and chunk caches. */\n\tstatus = -ENOBUFS;\n\tsctp_bucket_cachep = kmem_cache_create(\"sctp_bind_bucket\",\n\t\t\t\t\t       sizeof(struct sctp_bind_bucket),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_bucket_cachep)\n\t\tgoto out;\n\n\tsctp_chunk_cachep = kmem_cache_create(\"sctp_chunk\",\n\t\t\t\t\t       sizeof(struct sctp_chunk),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_chunk_cachep)\n\t\tgoto err_chunk_cachep;\n\n\tstatus = percpu_counter_init(&sctp_sockets_allocated, 0, GFP_KERNEL);\n\tif (status)\n\t\tgoto err_percpu_counter_init;\n\n\t/* Implementation specific variables. */\n\n\t/* Initialize default stream count setup information. */\n\tsctp_max_instreams    \t\t= SCTP_DEFAULT_INSTREAMS;\n\tsctp_max_outstreams   \t\t= SCTP_DEFAULT_OUTSTREAMS;\n\n\t/* Initialize handle used for association ids. */\n\tidr_init(&sctp_assocs_id);\n\n\tlimit = nr_free_buffer_pages() / 8;\n\tlimit = max(limit, 128UL);\n\tsysctl_sctp_mem[0] = limit / 4 * 3;\n\tsysctl_sctp_mem[1] = limit;\n\tsysctl_sctp_mem[2] = sysctl_sctp_mem[0] * 2;\n\n\t/* Set per-socket limits to no more than 1/128 the pressure threshold*/\n\tlimit = (sysctl_sctp_mem[1]) << (PAGE_SHIFT - 7);\n\tmax_share = min(4UL*1024*1024, limit);\n\n\tsysctl_sctp_rmem[0] = SK_MEM_QUANTUM; /* give each asoc 1 page min */\n\tsysctl_sctp_rmem[1] = 1500 * SKB_TRUESIZE(1);\n\tsysctl_sctp_rmem[2] = max(sysctl_sctp_rmem[1], max_share);\n\n\tsysctl_sctp_wmem[0] = SK_MEM_QUANTUM;\n\tsysctl_sctp_wmem[1] = 16*1024;\n\tsysctl_sctp_wmem[2] = max(64*1024, max_share);\n\n\t/* Size and allocate the association hash table.\n\t * The methodology is similar to that of the tcp hash tables.\n\t */\n\tif (totalram_pages >= (128 * 1024))\n\t\tgoal = totalram_pages >> (22 - PAGE_SHIFT);\n\telse\n\t\tgoal = totalram_pages >> (24 - PAGE_SHIFT);\n\n\tfor (order = 0; (1UL << order) < goal; order++)\n\t\t;\n\n\tdo {\n\t\tsctp_assoc_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_hashbucket);\n\t\tif ((sctp_assoc_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_assoc_hashtable = (struct sctp_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_assoc_hashtable && --order > 0);\n\tif (!sctp_assoc_hashtable) {\n\t\tpr_err(\"Failed association hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ahash_alloc;\n\t}\n\tfor (i = 0; i < sctp_assoc_hashsize; i++) {\n\t\trwlock_init(&sctp_assoc_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_assoc_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the endpoint hash table.  */\n\tsctp_ep_hashsize = 64;\n\tsctp_ep_hashtable =\n\t\tkmalloc(64 * sizeof(struct sctp_hashbucket), GFP_KERNEL);\n\tif (!sctp_ep_hashtable) {\n\t\tpr_err(\"Failed endpoint_hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ehash_alloc;\n\t}\n\tfor (i = 0; i < sctp_ep_hashsize; i++) {\n\t\trwlock_init(&sctp_ep_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_ep_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the SCTP port hash table.  */\n\tdo {\n\t\tsctp_port_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_bind_hashbucket);\n\t\tif ((sctp_port_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_port_hashtable = (struct sctp_bind_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_port_hashtable && --order > 0);\n\tif (!sctp_port_hashtable) {\n\t\tpr_err(\"Failed bind hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_bhash_alloc;\n\t}\n\tfor (i = 0; i < sctp_port_hashsize; i++) {\n\t\tspin_lock_init(&sctp_port_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_port_hashtable[i].chain);\n\t}\n\n\tpr_info(\"Hash tables configured (established %d bind %d)\\n\",\n\t\tsctp_assoc_hashsize, sctp_port_hashsize);\n\n\tsctp_sysctl_register();\n\n\tINIT_LIST_HEAD(&sctp_address_families);\n\tsctp_v4_pf_init();\n\tsctp_v6_pf_init();\n\n\tstatus = register_pernet_subsys(&sctp_defaults_ops);\n\tif (status)\n\t\tgoto err_register_defaults;\n\n\tstatus = sctp_v4_protosw_init();\n\tif (status)\n\t\tgoto err_protosw_init;\n\n\tstatus = sctp_v6_protosw_init();\n\tif (status)\n\t\tgoto err_v6_protosw_init;\n\n\tstatus = register_pernet_subsys(&sctp_ctrlsock_ops);\n\tif (status)\n\t\tgoto err_register_ctrlsock;\n\n\tstatus = sctp_v4_add_protocol();\n\tif (status)\n\t\tgoto err_add_protocol;\n\n\t/* Register SCTP with inet6 layer.  */\n\tstatus = sctp_v6_add_protocol();\n\tif (status)\n\t\tgoto err_v6_add_protocol;\n\nout:\n\treturn status;\nerr_v6_add_protocol:\n\tsctp_v4_del_protocol();\nerr_add_protocol:\n\tunregister_pernet_subsys(&sctp_ctrlsock_ops);\nerr_register_ctrlsock:\n\tsctp_v6_protosw_exit();\nerr_v6_protosw_init:\n\tsctp_v4_protosw_exit();\nerr_protosw_init:\n\tunregister_pernet_subsys(&sctp_defaults_ops);\nerr_register_defaults:\n\tsctp_v4_pf_exit();\n\tsctp_v6_pf_exit();\n\tsctp_sysctl_unregister();\n\tfree_pages((unsigned long)sctp_port_hashtable,\n\t\t   get_order(sctp_port_hashsize *\n\t\t\t     sizeof(struct sctp_bind_hashbucket)));\nerr_bhash_alloc:\n\tkfree(sctp_ep_hashtable);\nerr_ehash_alloc:\n\tfree_pages((unsigned long)sctp_assoc_hashtable,\n\t\t   get_order(sctp_assoc_hashsize *\n\t\t\t     sizeof(struct sctp_hashbucket)));\nerr_ahash_alloc:\n\tpercpu_counter_destroy(&sctp_sockets_allocated);\nerr_percpu_counter_init:\n\tkmem_cache_destroy(sctp_chunk_cachep);\nerr_chunk_cachep:\n\tkmem_cache_destroy(sctp_bucket_cachep);\n\tgoto out;\n}",
      "modified_lines": {
        "added": [
          "\tstatus = register_pernet_subsys(&sctp_defaults_ops);",
          "\tif (status)",
          "\t\tgoto err_register_defaults;",
          "",
          "\tstatus = register_pernet_subsys(&sctp_ctrlsock_ops);",
          "\t\tgoto err_register_ctrlsock;",
          "\tunregister_pernet_subsys(&sctp_ctrlsock_ops);",
          "err_register_ctrlsock:",
          "\tunregister_pernet_subsys(&sctp_defaults_ops);",
          "err_register_defaults:"
        ],
        "deleted": [
          "",
          "\tstatus = register_pernet_subsys(&sctp_net_ops);",
          "\t\tgoto err_register_pernet_subsys;",
          "\tunregister_pernet_subsys(&sctp_net_ops);",
          "err_register_pernet_subsys:"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect sequence of protocol-initialization steps in the sctp_init function.",
      "trigger_condition": "Local users creating SCTP sockets before all initialization steps have finished, leading to a denial of service (panic or memory corruption).",
      "specific_code_behavior_causing_vulnerability": "The code in sctp_init function does not complete all necessary protocol-initialization steps before allowing SCTP sockets to be created, potentially causing a denial of service or memory corruption if sockets are created prematurely.",
      "id": 73,
      "code_after_change_normalized": "static __init int FUN1(void)\n{\nint VAR1;\nint VAR2 = -VAR3;\nunsigned long VAR4;\nunsigned long VAR5;\nint VAR6;\nint VAR7;\nFUN2(sizeof(struct VAR8));\nVAR2 = -VAR9;\nVAR10 = FUN3(\"STR\",\nsizeof(struct VAR11),\n0, VAR12,\nNULL);\nif (!VAR10)\ngoto VAR13;\nVAR14 = FUN3(\"STR\",\nsizeof(struct VAR15),\n0, VAR12,\nNULL);\nif (!VAR14)\ngoto VAR16;\nVAR2 = FUN4(&VAR17, 0, VAR18);\nif (VAR2)\ngoto VAR19;\nVAR20    \t\t= VAR21;\nVAR22   \t\t= VAR23;\nFUN5(&VAR24);\nVAR5 = FUN6() / 8;\nVAR5 = FUN7(VAR5, 128UL);\nVAR25[0] = VAR5 / 4 * 3;\nVAR25[1] = VAR5;\nVAR25[2] = VAR25[0] * 2;\nVAR5 = (VAR25[1]) << (VAR26 - 7);\nVAR6 = FUN8(4UL*1024*1024, VAR5);\nVAR27[0] = VAR28; \nVAR27[1] = 1500 * FUN9(1);\nVAR27[2] = FUN7(VAR27[1], VAR6);\nVAR29[0] = VAR28;\nVAR29[1] = 16*1024;\nVAR29[2] = FUN7(64*1024, VAR6);\nif (VAR30 >= (128 * 1024))\nVAR4 = VAR30 >> (22 - VAR26);\nelse\nVAR4 = VAR30 >> (24 - VAR26);\nfor (VAR7 = 0; (1UL << VAR7) < VAR4; VAR7++)\n;\ndo {\nVAR31 = (1UL << VAR7) * VAR32 /\nsizeof(struct VAR33);\nif ((VAR31 > (64 * 1024)) && VAR7 > 0)\ncontinue;\nVAR34 = (struct VAR33 *)\nFUN10(VAR35|VAR36, VAR7);\n} while (!VAR34 && --VAR7 > 0);\nif (!VAR34) {\nFUN11(\"STR\");\nVAR2 = -VAR37;\ngoto VAR38;\n}\nfor (VAR1 = 0; VAR1 < VAR31; VAR1++) {\nFUN12(&VAR34[VAR1].VAR39);\nFUN13(&VAR34[VAR1].VAR40);\n}\nVAR41 = 64;\nVAR42 =\nFUN14(64 * sizeof(struct VAR33), VAR18);\nif (!VAR42) {\nFUN11(\"STR\");\nVAR2 = -VAR37;\ngoto VAR43;\n}\nfor (VAR1 = 0; VAR1 < VAR41; VAR1++) {\nFUN12(&VAR42[VAR1].VAR39);\nFUN13(&VAR42[VAR1].VAR40);\n}\ndo {\nVAR44 = (1UL << VAR7) * VAR32 /\nsizeof(struct VAR45);\nif ((VAR44 > (64 * 1024)) && VAR7 > 0)\ncontinue;\nVAR46 = (struct VAR45 *)\nFUN10(VAR35|VAR36, VAR7);\n} while (!VAR46 && --VAR7 > 0);\nif (!VAR46) {\nFUN11(\"STR\");\nVAR2 = -VAR37;\ngoto VAR47;\n}\nfor (VAR1 = 0; VAR1 < VAR44; VAR1++) {\nFUN15(&VAR46[VAR1].VAR39);\nFUN13(&VAR46[VAR1].VAR40);\n}\nFUN16(\"STR\",\nVAR31, VAR44);\nFUN17();\nFUN18(&VAR48);\nFUN19();\nFUN20();\nVAR2 = FUN21(&VAR49);\nif (VAR2)\ngoto VAR50;\nVAR2 = FUN22();\nif (VAR2)\ngoto VAR51;\nVAR2 = FUN23();\nif (VAR2)\ngoto VAR52;\nVAR2 = FUN21(&VAR53);\nif (VAR2)\ngoto VAR54;\nVAR2 = FUN24();\nif (VAR2)\ngoto VAR55;\nVAR2 = FUN25();\nif (VAR2)\ngoto VAR56;\nVAR13:\nreturn VAR2;\nVAR56:\nFUN26();\nVAR55:\nFUN27(&VAR53);\nVAR54:\nFUN28();\nVAR52:\nFUN29();\nVAR51:\nFUN27(&VAR49);\nVAR50:\nFUN30();\nFUN31();\nFUN32();\nFUN33((unsigned long)VAR46,\nFUN34(VAR44 *\nsizeof(struct VAR45)));\nVAR47:\nFUN35(VAR42);\nVAR43:\nFUN33((unsigned long)VAR34,\nFUN34(VAR31 *\nsizeof(struct VAR33)));\nVAR38:\nFUN36(&VAR17);\nVAR19:\nFUN37(VAR14);\nVAR16:\nFUN37(VAR10);\ngoto VAR13;\n}\n",
      "code_before_change_normalized": "static __init int FUN1(void)\n{\nint VAR1;\nint VAR2 = -VAR3;\nunsigned long VAR4;\nunsigned long VAR5;\nint VAR6;\nint VAR7;\nFUN2(sizeof(struct VAR8));\nVAR2 = -VAR9;\nVAR10 = FUN3(\"STR\",\nsizeof(struct VAR11),\n0, VAR12,\nNULL);\nif (!VAR10)\ngoto VAR13;\nVAR14 = FUN3(\"STR\",\nsizeof(struct VAR15),\n0, VAR12,\nNULL);\nif (!VAR14)\ngoto VAR16;\nVAR2 = FUN4(&VAR17, 0, VAR18);\nif (VAR2)\ngoto VAR19;\nVAR20    \t\t= VAR21;\nVAR22   \t\t= VAR23;\nFUN5(&VAR24);\nVAR5 = FUN6() / 8;\nVAR5 = FUN7(VAR5, 128UL);\nVAR25[0] = VAR5 / 4 * 3;\nVAR25[1] = VAR5;\nVAR25[2] = VAR25[0] * 2;\nVAR5 = (VAR25[1]) << (VAR26 - 7);\nVAR6 = FUN8(4UL*1024*1024, VAR5);\nVAR27[0] = VAR28; \nVAR27[1] = 1500 * FUN9(1);\nVAR27[2] = FUN7(VAR27[1], VAR6);\nVAR29[0] = VAR28;\nVAR29[1] = 16*1024;\nVAR29[2] = FUN7(64*1024, VAR6);\nif (VAR30 >= (128 * 1024))\nVAR4 = VAR30 >> (22 - VAR26);\nelse\nVAR4 = VAR30 >> (24 - VAR26);\nfor (VAR7 = 0; (1UL << VAR7) < VAR4; VAR7++)\n;\ndo {\nVAR31 = (1UL << VAR7) * VAR32 /\nsizeof(struct VAR33);\nif ((VAR31 > (64 * 1024)) && VAR7 > 0)\ncontinue;\nVAR34 = (struct VAR33 *)\nFUN10(VAR35|VAR36, VAR7);\n} while (!VAR34 && --VAR7 > 0);\nif (!VAR34) {\nFUN11(\"STR\");\nVAR2 = -VAR37;\ngoto VAR38;\n}\nfor (VAR1 = 0; VAR1 < VAR31; VAR1++) {\nFUN12(&VAR34[VAR1].VAR39);\nFUN13(&VAR34[VAR1].VAR40);\n}\nVAR41 = 64;\nVAR42 =\nFUN14(64 * sizeof(struct VAR33), VAR18);\nif (!VAR42) {\nFUN11(\"STR\");\nVAR2 = -VAR37;\ngoto VAR43;\n}\nfor (VAR1 = 0; VAR1 < VAR41; VAR1++) {\nFUN12(&VAR42[VAR1].VAR39);\nFUN13(&VAR42[VAR1].VAR40);\n}\ndo {\nVAR44 = (1UL << VAR7) * VAR32 /\nsizeof(struct VAR45);\nif ((VAR44 > (64 * 1024)) && VAR7 > 0)\ncontinue;\nVAR46 = (struct VAR45 *)\nFUN10(VAR35|VAR36, VAR7);\n} while (!VAR46 && --VAR7 > 0);\nif (!VAR46) {\nFUN11(\"STR\");\nVAR2 = -VAR37;\ngoto VAR47;\n}\nfor (VAR1 = 0; VAR1 < VAR44; VAR1++) {\nFUN15(&VAR46[VAR1].VAR39);\nFUN13(&VAR46[VAR1].VAR40);\n}\nFUN16(\"STR\",\nVAR31, VAR44);\nFUN17();\nFUN18(&VAR48);\nFUN19();\nFUN20();\nVAR2 = FUN21();\nif (VAR2)\ngoto VAR49;\nVAR2 = FUN22();\nif (VAR2)\ngoto VAR50;\nVAR2 = FUN23(&VAR51);\nif (VAR2)\ngoto VAR52;\nVAR2 = FUN24();\nif (VAR2)\ngoto VAR53;\nVAR2 = FUN25();\nif (VAR2)\ngoto VAR54;\nVAR13:\nreturn VAR2;\nVAR54:\nFUN26();\nVAR53:\nFUN27(&VAR51);\nVAR52:\nFUN28();\nVAR50:\nFUN29();\nVAR49:\nFUN30();\nFUN31();\nFUN32();\nFUN33((unsigned long)VAR46,\nFUN34(VAR44 *\nsizeof(struct VAR45)));\nVAR47:\nFUN35(VAR42);\nVAR43:\nFUN33((unsigned long)VAR34,\nFUN34(VAR31 *\nsizeof(struct VAR33)));\nVAR38:\nFUN36(&VAR17);\nVAR19:\nFUN37(VAR14);\nVAR16:\nFUN37(VAR10);\ngoto VAR13;\n}\n",
      "code_after_change_raw": "static __init int sctp_init(void)\n{\nint i;\nint status = -EINVAL;\nunsigned long goal;\nunsigned long limit;\nint max_share;\nint order;\nsock_skb_cb_check_size(sizeof(struct sctp_ulpevent));\nstatus = -ENOBUFS;\nsctp_bucket_cachep = kmem_cache_create(\"sctp_bind_bucket\",\nsizeof(struct sctp_bind_bucket),\n0, SLAB_HWCACHE_ALIGN,\nNULL);\nif (!sctp_bucket_cachep)\ngoto out;\nsctp_chunk_cachep = kmem_cache_create(\"sctp_chunk\",\nsizeof(struct sctp_chunk),\n0, SLAB_HWCACHE_ALIGN,\nNULL);\nif (!sctp_chunk_cachep)\ngoto err_chunk_cachep;\nstatus = percpu_counter_init(&sctp_sockets_allocated, 0, GFP_KERNEL);\nif (status)\ngoto err_percpu_counter_init;\nsctp_max_instreams    \t\t= SCTP_DEFAULT_INSTREAMS;\nsctp_max_outstreams   \t\t= SCTP_DEFAULT_OUTSTREAMS;\nidr_init(&sctp_assocs_id);\nlimit = nr_free_buffer_pages() / 8;\nlimit = max(limit, 128UL);\nsysctl_sctp_mem[0] = limit / 4 * 3;\nsysctl_sctp_mem[1] = limit;\nsysctl_sctp_mem[2] = sysctl_sctp_mem[0] * 2;\nlimit = (sysctl_sctp_mem[1]) << (PAGE_SHIFT - 7);\nmax_share = min(4UL*1024*1024, limit);\nsysctl_sctp_rmem[0] = SK_MEM_QUANTUM; \nsysctl_sctp_rmem[1] = 1500 * SKB_TRUESIZE(1);\nsysctl_sctp_rmem[2] = max(sysctl_sctp_rmem[1], max_share);\nsysctl_sctp_wmem[0] = SK_MEM_QUANTUM;\nsysctl_sctp_wmem[1] = 16*1024;\nsysctl_sctp_wmem[2] = max(64*1024, max_share);\nif (totalram_pages >= (128 * 1024))\ngoal = totalram_pages >> (22 - PAGE_SHIFT);\nelse\ngoal = totalram_pages >> (24 - PAGE_SHIFT);\nfor (order = 0; (1UL << order) < goal; order++)\n;\ndo {\nsctp_assoc_hashsize = (1UL << order) * PAGE_SIZE /\nsizeof(struct sctp_hashbucket);\nif ((sctp_assoc_hashsize > (64 * 1024)) && order > 0)\ncontinue;\nsctp_assoc_hashtable = (struct sctp_hashbucket *)\n__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n} while (!sctp_assoc_hashtable && --order > 0);\nif (!sctp_assoc_hashtable) {\npr_err(\"Failed association hash alloc\\n\");\nstatus = -ENOMEM;\ngoto err_ahash_alloc;\n}\nfor (i = 0; i < sctp_assoc_hashsize; i++) {\nrwlock_init(&sctp_assoc_hashtable[i].lock);\nINIT_HLIST_HEAD(&sctp_assoc_hashtable[i].chain);\n}\nsctp_ep_hashsize = 64;\nsctp_ep_hashtable =\nkmalloc(64 * sizeof(struct sctp_hashbucket), GFP_KERNEL);\nif (!sctp_ep_hashtable) {\npr_err(\"Failed endpoint_hash alloc\\n\");\nstatus = -ENOMEM;\ngoto err_ehash_alloc;\n}\nfor (i = 0; i < sctp_ep_hashsize; i++) {\nrwlock_init(&sctp_ep_hashtable[i].lock);\nINIT_HLIST_HEAD(&sctp_ep_hashtable[i].chain);\n}\ndo {\nsctp_port_hashsize = (1UL << order) * PAGE_SIZE /\nsizeof(struct sctp_bind_hashbucket);\nif ((sctp_port_hashsize > (64 * 1024)) && order > 0)\ncontinue;\nsctp_port_hashtable = (struct sctp_bind_hashbucket *)\n__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n} while (!sctp_port_hashtable && --order > 0);\nif (!sctp_port_hashtable) {\npr_err(\"Failed bind hash alloc\\n\");\nstatus = -ENOMEM;\ngoto err_bhash_alloc;\n}\nfor (i = 0; i < sctp_port_hashsize; i++) {\nspin_lock_init(&sctp_port_hashtable[i].lock);\nINIT_HLIST_HEAD(&sctp_port_hashtable[i].chain);\n}\npr_info(\"Hash tables configured (established %d bind %d)\\n\",\nsctp_assoc_hashsize, sctp_port_hashsize);\nsctp_sysctl_register();\nINIT_LIST_HEAD(&sctp_address_families);\nsctp_v4_pf_init();\nsctp_v6_pf_init();\nstatus = register_pernet_subsys(&sctp_defaults_ops);\nif (status)\ngoto err_register_defaults;\nstatus = sctp_v4_protosw_init();\nif (status)\ngoto err_protosw_init;\nstatus = sctp_v6_protosw_init();\nif (status)\ngoto err_v6_protosw_init;\nstatus = register_pernet_subsys(&sctp_ctrlsock_ops);\nif (status)\ngoto err_register_ctrlsock;\nstatus = sctp_v4_add_protocol();\nif (status)\ngoto err_add_protocol;\nstatus = sctp_v6_add_protocol();\nif (status)\ngoto err_v6_add_protocol;\nout:\nreturn status;\nerr_v6_add_protocol:\nsctp_v4_del_protocol();\nerr_add_protocol:\nunregister_pernet_subsys(&sctp_ctrlsock_ops);\nerr_register_ctrlsock:\nsctp_v6_protosw_exit();\nerr_v6_protosw_init:\nsctp_v4_protosw_exit();\nerr_protosw_init:\nunregister_pernet_subsys(&sctp_defaults_ops);\nerr_register_defaults:\nsctp_v4_pf_exit();\nsctp_v6_pf_exit();\nsctp_sysctl_unregister();\nfree_pages((unsigned long)sctp_port_hashtable,\nget_order(sctp_port_hashsize *\nsizeof(struct sctp_bind_hashbucket)));\nerr_bhash_alloc:\nkfree(sctp_ep_hashtable);\nerr_ehash_alloc:\nfree_pages((unsigned long)sctp_assoc_hashtable,\nget_order(sctp_assoc_hashsize *\nsizeof(struct sctp_hashbucket)));\nerr_ahash_alloc:\npercpu_counter_destroy(&sctp_sockets_allocated);\nerr_percpu_counter_init:\nkmem_cache_destroy(sctp_chunk_cachep);\nerr_chunk_cachep:\nkmem_cache_destroy(sctp_bucket_cachep);\ngoto out;\n}\n",
      "code_before_change_raw": "static __init int sctp_init(void)\n{\nint i;\nint status = -EINVAL;\nunsigned long goal;\nunsigned long limit;\nint max_share;\nint order;\nsock_skb_cb_check_size(sizeof(struct sctp_ulpevent));\nstatus = -ENOBUFS;\nsctp_bucket_cachep = kmem_cache_create(\"sctp_bind_bucket\",\nsizeof(struct sctp_bind_bucket),\n0, SLAB_HWCACHE_ALIGN,\nNULL);\nif (!sctp_bucket_cachep)\ngoto out;\nsctp_chunk_cachep = kmem_cache_create(\"sctp_chunk\",\nsizeof(struct sctp_chunk),\n0, SLAB_HWCACHE_ALIGN,\nNULL);\nif (!sctp_chunk_cachep)\ngoto err_chunk_cachep;\nstatus = percpu_counter_init(&sctp_sockets_allocated, 0, GFP_KERNEL);\nif (status)\ngoto err_percpu_counter_init;\nsctp_max_instreams    \t\t= SCTP_DEFAULT_INSTREAMS;\nsctp_max_outstreams   \t\t= SCTP_DEFAULT_OUTSTREAMS;\nidr_init(&sctp_assocs_id);\nlimit = nr_free_buffer_pages() / 8;\nlimit = max(limit, 128UL);\nsysctl_sctp_mem[0] = limit / 4 * 3;\nsysctl_sctp_mem[1] = limit;\nsysctl_sctp_mem[2] = sysctl_sctp_mem[0] * 2;\nlimit = (sysctl_sctp_mem[1]) << (PAGE_SHIFT - 7);\nmax_share = min(4UL*1024*1024, limit);\nsysctl_sctp_rmem[0] = SK_MEM_QUANTUM; \nsysctl_sctp_rmem[1] = 1500 * SKB_TRUESIZE(1);\nsysctl_sctp_rmem[2] = max(sysctl_sctp_rmem[1], max_share);\nsysctl_sctp_wmem[0] = SK_MEM_QUANTUM;\nsysctl_sctp_wmem[1] = 16*1024;\nsysctl_sctp_wmem[2] = max(64*1024, max_share);\nif (totalram_pages >= (128 * 1024))\ngoal = totalram_pages >> (22 - PAGE_SHIFT);\nelse\ngoal = totalram_pages >> (24 - PAGE_SHIFT);\nfor (order = 0; (1UL << order) < goal; order++)\n;\ndo {\nsctp_assoc_hashsize = (1UL << order) * PAGE_SIZE /\nsizeof(struct sctp_hashbucket);\nif ((sctp_assoc_hashsize > (64 * 1024)) && order > 0)\ncontinue;\nsctp_assoc_hashtable = (struct sctp_hashbucket *)\n__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n} while (!sctp_assoc_hashtable && --order > 0);\nif (!sctp_assoc_hashtable) {\npr_err(\"Failed association hash alloc\\n\");\nstatus = -ENOMEM;\ngoto err_ahash_alloc;\n}\nfor (i = 0; i < sctp_assoc_hashsize; i++) {\nrwlock_init(&sctp_assoc_hashtable[i].lock);\nINIT_HLIST_HEAD(&sctp_assoc_hashtable[i].chain);\n}\nsctp_ep_hashsize = 64;\nsctp_ep_hashtable =\nkmalloc(64 * sizeof(struct sctp_hashbucket), GFP_KERNEL);\nif (!sctp_ep_hashtable) {\npr_err(\"Failed endpoint_hash alloc\\n\");\nstatus = -ENOMEM;\ngoto err_ehash_alloc;\n}\nfor (i = 0; i < sctp_ep_hashsize; i++) {\nrwlock_init(&sctp_ep_hashtable[i].lock);\nINIT_HLIST_HEAD(&sctp_ep_hashtable[i].chain);\n}\ndo {\nsctp_port_hashsize = (1UL << order) * PAGE_SIZE /\nsizeof(struct sctp_bind_hashbucket);\nif ((sctp_port_hashsize > (64 * 1024)) && order > 0)\ncontinue;\nsctp_port_hashtable = (struct sctp_bind_hashbucket *)\n__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n} while (!sctp_port_hashtable && --order > 0);\nif (!sctp_port_hashtable) {\npr_err(\"Failed bind hash alloc\\n\");\nstatus = -ENOMEM;\ngoto err_bhash_alloc;\n}\nfor (i = 0; i < sctp_port_hashsize; i++) {\nspin_lock_init(&sctp_port_hashtable[i].lock);\nINIT_HLIST_HEAD(&sctp_port_hashtable[i].chain);\n}\npr_info(\"Hash tables configured (established %d bind %d)\\n\",\nsctp_assoc_hashsize, sctp_port_hashsize);\nsctp_sysctl_register();\nINIT_LIST_HEAD(&sctp_address_families);\nsctp_v4_pf_init();\nsctp_v6_pf_init();\nstatus = sctp_v4_protosw_init();\nif (status)\ngoto err_protosw_init;\nstatus = sctp_v6_protosw_init();\nif (status)\ngoto err_v6_protosw_init;\nstatus = register_pernet_subsys(&sctp_net_ops);\nif (status)\ngoto err_register_pernet_subsys;\nstatus = sctp_v4_add_protocol();\nif (status)\ngoto err_add_protocol;\nstatus = sctp_v6_add_protocol();\nif (status)\ngoto err_v6_add_protocol;\nout:\nreturn status;\nerr_v6_add_protocol:\nsctp_v4_del_protocol();\nerr_add_protocol:\nunregister_pernet_subsys(&sctp_net_ops);\nerr_register_pernet_subsys:\nsctp_v6_protosw_exit();\nerr_v6_protosw_init:\nsctp_v4_protosw_exit();\nerr_protosw_init:\nsctp_v4_pf_exit();\nsctp_v6_pf_exit();\nsctp_sysctl_unregister();\nfree_pages((unsigned long)sctp_port_hashtable,\nget_order(sctp_port_hashsize *\nsizeof(struct sctp_bind_hashbucket)));\nerr_bhash_alloc:\nkfree(sctp_ep_hashtable);\nerr_ehash_alloc:\nfree_pages((unsigned long)sctp_assoc_hashtable,\nget_order(sctp_assoc_hashsize *\nsizeof(struct sctp_hashbucket)));\nerr_ahash_alloc:\npercpu_counter_destroy(&sctp_sockets_allocated);\nerr_percpu_counter_init:\nkmem_cache_destroy(sctp_chunk_cachep);\nerr_chunk_cachep:\nkmem_cache_destroy(sctp_bucket_cachep);\ngoto out;\n}\n"
    }
  ],
  "CVE-2016-10154": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Interaction of the smbhash function with the CONFIG_VMAP_STACK option in the Linux kernel.",
        "trigger_condition": "Use of more than one virtual page for a scatterlist during the encryption process.",
        "specific_code_behavior_causing_vulnerability": "The original code snippet uses the skcipher API, which interacts incorrectly with CONFIG_VMAP_STACK when more than one virtual page is used for a scatterlist. This can lead to a denial of service (system crash or memory corruption) due to improper handling of scatterlists.",
        "solution": "The vulnerability can be mitigated by replacing the skcipher API with the cipher API. By using the cipher API, the code avoids the problematic interaction with CONFIG_VMAP_STACK and reduces the risk of system crashes or memory corruption. The modified code snippet simplifies the encryption process by directly encrypting the input data using the cipher API functions, which helps in avoiding the vulnerability associated with scatterlist usage."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2016-10154. The vulnerability arises due to the interaction of the smbhash function with the CONFIG_VMAP_STACK option, which can lead to a denial of service or memory corruption when more than one virtual page is used for a scatterlist.\n\nThe corrected code snippet replaces the usage of the skcipher API with the cipher API. By using the cipher API, the code avoids the problematic interaction with CONFIG_VMAP_STACK and reduces the risk of system crashes or memory corruption.\n\nAdditionally, the modified code simplifies the encryption process by directly encrypting the input data using the cipher API functions, which helps in avoiding the vulnerability associated with the scatterlist usage in the original code.\n\nTherefore, the modification is necessary to mitigate the vulnerability and ensure the secure operation of the smbhash function.",
      "GPT_purpose": "Encrypting data using the DES algorithm in the context of SMB hashing.",
      "GPT_function": "\n1. Perform a DES encryption operation using a provided key and input data.\n2. Allocate and initialize a DES symmetric key cipher object.\n3. Set the key for the DES cipher object.\n4. Initialize scatterlist structures for input and output data.\n5. Encrypt the input data using the DES cipher object.\n6. Free resources allocated for the DES cipher object.",
      "CVE_id": "CVE-2016-10154",
      "code_before_change": "static int\nsmbhash(unsigned char *out, const unsigned char *in, unsigned char *key)\n{\n\tint rc;\n\tunsigned char key2[8];\n\tstruct crypto_skcipher *tfm_des;\n\tstruct scatterlist sgin, sgout;\n\tstruct skcipher_request *req;\n\n\tstr_to_key(key, key2);\n\n\ttfm_des = crypto_alloc_skcipher(\"ecb(des)\", 0, CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(tfm_des)) {\n\t\trc = PTR_ERR(tfm_des);\n\t\tcifs_dbg(VFS, \"could not allocate des crypto API\\n\");\n\t\tgoto smbhash_err;\n\t}\n\n\treq = skcipher_request_alloc(tfm_des, GFP_KERNEL);\n\tif (!req) {\n\t\trc = -ENOMEM;\n\t\tcifs_dbg(VFS, \"could not allocate des crypto API\\n\");\n\t\tgoto smbhash_free_skcipher;\n\t}\n\n\tcrypto_skcipher_setkey(tfm_des, key2, 8);\n\n\tsg_init_one(&sgin, in, 8);\n\tsg_init_one(&sgout, out, 8);\n\n\tskcipher_request_set_callback(req, 0, NULL, NULL);\n\tskcipher_request_set_crypt(req, &sgin, &sgout, 8, NULL);\n\n\trc = crypto_skcipher_encrypt(req);\n\tif (rc)\n\t\tcifs_dbg(VFS, \"could not encrypt crypt key rc: %d\\n\", rc);\n\n\tskcipher_request_free(req);\n\nsmbhash_free_skcipher:\n\tcrypto_free_skcipher(tfm_des);\nsmbhash_err:\n\treturn rc;\n}",
      "code_after_change": "static int\nsmbhash(unsigned char *out, const unsigned char *in, unsigned char *key)\n{\n\tunsigned char key2[8];\n\tstruct crypto_cipher *tfm_des;\n\n\tstr_to_key(key, key2);\n\n\ttfm_des = crypto_alloc_cipher(\"des\", 0, 0);\n\tif (IS_ERR(tfm_des)) {\n\t\tcifs_dbg(VFS, \"could not allocate des crypto API\\n\");\n\t\treturn PTR_ERR(tfm_des);\n\t}\n\n\tcrypto_cipher_setkey(tfm_des, key2, 8);\n\tcrypto_cipher_encrypt_one(tfm_des, out, in);\n\tcrypto_free_cipher(tfm_des);\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tstruct crypto_cipher *tfm_des;",
          "\ttfm_des = crypto_alloc_cipher(\"des\", 0, 0);",
          "\t\treturn PTR_ERR(tfm_des);",
          "\tcrypto_cipher_setkey(tfm_des, key2, 8);",
          "\tcrypto_cipher_encrypt_one(tfm_des, out, in);",
          "\tcrypto_free_cipher(tfm_des);",
          "\treturn 0;"
        ],
        "deleted": [
          "\tint rc;",
          "\tstruct crypto_skcipher *tfm_des;",
          "\tstruct scatterlist sgin, sgout;",
          "\tstruct skcipher_request *req;",
          "\ttfm_des = crypto_alloc_skcipher(\"ecb(des)\", 0, CRYPTO_ALG_ASYNC);",
          "\t\trc = PTR_ERR(tfm_des);",
          "\t\tgoto smbhash_err;",
          "\treq = skcipher_request_alloc(tfm_des, GFP_KERNEL);",
          "\tif (!req) {",
          "\t\trc = -ENOMEM;",
          "\t\tcifs_dbg(VFS, \"could not allocate des crypto API\\n\");",
          "\t\tgoto smbhash_free_skcipher;",
          "\t}",
          "\tcrypto_skcipher_setkey(tfm_des, key2, 8);",
          "",
          "\tsg_init_one(&sgin, in, 8);",
          "\tsg_init_one(&sgout, out, 8);",
          "",
          "\tskcipher_request_set_callback(req, 0, NULL, NULL);",
          "\tskcipher_request_set_crypt(req, &sgin, &sgout, 8, NULL);",
          "",
          "\trc = crypto_skcipher_encrypt(req);",
          "\tif (rc)",
          "\t\tcifs_dbg(VFS, \"could not encrypt crypt key rc: %d\\n\", rc);",
          "",
          "\tskcipher_request_free(req);",
          "",
          "smbhash_free_skcipher:",
          "\tcrypto_free_skcipher(tfm_des);",
          "smbhash_err:",
          "\treturn rc;"
        ]
      },
      "preconditions_for_vulnerability": "Interaction of the smbhash function with the CONFIG_VMAP_STACK option in the Linux kernel.",
      "trigger_condition": "Use of more than one virtual page for a scatterlist during the encryption process.",
      "specific_code_behavior_causing_vulnerability": "The original code snippet uses the skcipher API, which interacts incorrectly with CONFIG_VMAP_STACK when more than one virtual page is used for a scatterlist. This can lead to a denial of service (system crash or memory corruption) due to improper handling of scatterlists.",
      "solution": "The vulnerability can be mitigated by replacing the skcipher API with the cipher API. By using the cipher API, the code avoids the problematic interaction with CONFIG_VMAP_STACK and reduces the risk of system crashes or memory corruption. The modified code snippet simplifies the encryption process by directly encrypting the input data using the cipher API functions, which helps in avoiding the vulnerability associated with scatterlist usage.",
      "id": 74,
      "code_after_change_normalized": "static int\nFUN1(unsigned char *VAR1, const unsigned char *VAR2, unsigned char *VAR3)\n{\nunsigned char VAR4[8];\nstruct crypto_cipher *VAR5;\nFUN2(VAR3, VAR4);\nVAR5 = FUN3(\"STR\", 0, 0);\nif (FUN4(VAR5)) {\nFUN5(VAR6, \"STR\");\nreturn FUN6(VAR5);\n}\nFUN7(VAR5, VAR4, 8);\nFUN8(VAR5, VAR1, VAR2);\nFUN9(VAR5);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(unsigned char *VAR1, const unsigned char *VAR2, unsigned char *VAR3)\n{\nint VAR4;\nunsigned char VAR5[8];\nstruct crypto_skcipher *VAR6;\nstruct scatterlist VAR7, VAR8;\nstruct skcipher_request *VAR9;\nFUN2(VAR3, VAR5);\nVAR6 = FUN3(\"STR\", 0, VAR10);\nif (FUN4(VAR6)) {\nVAR4 = FUN5(VAR6);\nFUN6(VAR11, \"STR\");\ngoto VAR12;\n}\nVAR9 = FUN7(VAR6, VAR13);\nif (!VAR9) {\nVAR4 = -VAR14;\nFUN6(VAR11, \"STR\");\ngoto VAR15;\n}\nFUN8(VAR6, VAR5, 8);\nFUN9(&VAR7, VAR2, 8);\nFUN9(&VAR8, VAR1, 8);\nFUN10(VAR9, 0, NULL, NULL);\nFUN11(VAR9, &VAR7, &VAR8, 8, NULL);\nVAR4 = FUN12(VAR9);\nif (VAR4)\nFUN6(VAR11, \"STR\", VAR4);\nFUN13(VAR9);\nVAR15:\nFUN14(VAR6);\nVAR12:\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int\nsmbhash(unsigned char *out, const unsigned char *in, unsigned char *key)\n{\nunsigned char key2[8];\nstruct crypto_cipher *tfm_des;\nstr_to_key(key, key2);\ntfm_des = crypto_alloc_cipher(\"des\", 0, 0);\nif (IS_ERR(tfm_des)) {\ncifs_dbg(VFS, \"could not allocate des crypto API\\n\");\nreturn PTR_ERR(tfm_des);\n}\ncrypto_cipher_setkey(tfm_des, key2, 8);\ncrypto_cipher_encrypt_one(tfm_des, out, in);\ncrypto_free_cipher(tfm_des);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int\nsmbhash(unsigned char *out, const unsigned char *in, unsigned char *key)\n{\nint rc;\nunsigned char key2[8];\nstruct crypto_skcipher *tfm_des;\nstruct scatterlist sgin, sgout;\nstruct skcipher_request *req;\nstr_to_key(key, key2);\ntfm_des = crypto_alloc_skcipher(\"ecb(des)\", 0, CRYPTO_ALG_ASYNC);\nif (IS_ERR(tfm_des)) {\nrc = PTR_ERR(tfm_des);\ncifs_dbg(VFS, \"could not allocate des crypto API\\n\");\ngoto smbhash_err;\n}\nreq = skcipher_request_alloc(tfm_des, GFP_KERNEL);\nif (!req) {\nrc = -ENOMEM;\ncifs_dbg(VFS, \"could not allocate des crypto API\\n\");\ngoto smbhash_free_skcipher;\n}\ncrypto_skcipher_setkey(tfm_des, key2, 8);\nsg_init_one(&sgin, in, 8);\nsg_init_one(&sgout, out, 8);\nskcipher_request_set_callback(req, 0, NULL, NULL);\nskcipher_request_set_crypt(req, &sgin, &sgout, 8, NULL);\nrc = crypto_skcipher_encrypt(req);\nif (rc)\ncifs_dbg(VFS, \"could not encrypt crypt key rc: %d\\n\", rc);\nskcipher_request_free(req);\nsmbhash_free_skcipher:\ncrypto_free_skcipher(tfm_des);\nsmbhash_err:\nreturn rc;\n}\n"
    }
  ],
  "CVE-2016-10764": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper validation of chip select value against the maximum chip select value.",
        "trigger_condition": "The chip select value exceeds the maximum allowed value, leading to an out-of-bounds access in the array.",
        "specific_code_behavior_causing_vulnerability": "The code compares the chip select value using '>' instead of '>=' against the maximum chip select value, potentially allowing access to an array element beyond its bounds."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation of the chip select value against the maximum chip select value. Specifically, the comparison should be modified to use '>=' instead of '>' to prevent out-of-bounds access. By making this change, the code correctly checks that the chip select value falls within the valid range, enhancing the security and stability of the code.",
      "GPT_analysis": "The modification is necessary to fix a vulnerability in the code snippet. The vulnerability is related to an off-by-one error in the comparison of the chip select value (`cs`) with the maximum chip select value (`CQSPI_MAX_CHIPSELECT`). \n\nIn the original code snippet, the comparison `if (cs > CQSPI_MAX_CHIPSELECT)` is used to check if the chip select value is out of range. However, this comparison should be `if (cs >= CQSPI_MAX_CHIPSELECT)` to ensure that the chip select value is within the valid range of 0 to `CQSPI_MAX_CHIPSELECT - 1`. \n\nBy changing the comparison to `>=`, we ensure that the chip select value is correctly validated against the maximum allowed value, preventing any potential out-of-bounds access or other issues that could arise from accessing an array element beyond its bounds. This modification helps to improve the security and stability of the code.",
      "GPT_purpose": "Setting up flash devices for Cadence Quad SPI controller.",
      "GPT_function": "\n1. Set up flash device data for CQSPI controller.\n2. Initialize SPI NOR flash memory.\n3. Register the MTD device for each flash device.\n4. Handle errors and unregister MTD devices if needed.",
      "CVE_id": "CVE-2016-10764",
      "code_before_change": "static int cqspi_setup_flash(struct cqspi_st *cqspi, struct device_node *np)\n{\n\tstruct platform_device *pdev = cqspi->pdev;\n\tstruct device *dev = &pdev->dev;\n\tstruct cqspi_flash_pdata *f_pdata;\n\tstruct spi_nor *nor;\n\tstruct mtd_info *mtd;\n\tunsigned int cs;\n\tint i, ret;\n\n\t/* Get flash device data */\n\tfor_each_available_child_of_node(dev->of_node, np) {\n\t\tif (of_property_read_u32(np, \"reg\", &cs)) {\n\t\t\tdev_err(dev, \"Couldn't determine chip select.\\n\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (cs > CQSPI_MAX_CHIPSELECT) {\n\t\t\tdev_err(dev, \"Chip select %d out of range.\\n\", cs);\n\t\t\tgoto err;\n\t\t}\n\n\t\tf_pdata = &cqspi->f_pdata[cs];\n\t\tf_pdata->cqspi = cqspi;\n\t\tf_pdata->cs = cs;\n\n\t\tret = cqspi_of_get_flash_pdata(pdev, f_pdata, np);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tnor = &f_pdata->nor;\n\t\tmtd = &nor->mtd;\n\n\t\tmtd->priv = nor;\n\n\t\tnor->dev = dev;\n\t\tspi_nor_set_flash_node(nor, np);\n\t\tnor->priv = f_pdata;\n\n\t\tnor->read_reg = cqspi_read_reg;\n\t\tnor->write_reg = cqspi_write_reg;\n\t\tnor->read = cqspi_read;\n\t\tnor->write = cqspi_write;\n\t\tnor->erase = cqspi_erase;\n\t\tnor->prepare = cqspi_prep;\n\t\tnor->unprepare = cqspi_unprep;\n\n\t\tmtd->name = devm_kasprintf(dev, GFP_KERNEL, \"%s.%d\",\n\t\t\t\t\t   dev_name(dev), cs);\n\t\tif (!mtd->name) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = spi_nor_scan(nor, NULL, SPI_NOR_QUAD);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = mtd_device_register(mtd, NULL, 0);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tf_pdata->registered = true;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (i = 0; i < CQSPI_MAX_CHIPSELECT; i++)\n\t\tif (cqspi->f_pdata[i].registered)\n\t\t\tmtd_device_unregister(&cqspi->f_pdata[i].nor.mtd);\n\treturn ret;\n}",
      "code_after_change": "static int cqspi_setup_flash(struct cqspi_st *cqspi, struct device_node *np)\n{\n\tstruct platform_device *pdev = cqspi->pdev;\n\tstruct device *dev = &pdev->dev;\n\tstruct cqspi_flash_pdata *f_pdata;\n\tstruct spi_nor *nor;\n\tstruct mtd_info *mtd;\n\tunsigned int cs;\n\tint i, ret;\n\n\t/* Get flash device data */\n\tfor_each_available_child_of_node(dev->of_node, np) {\n\t\tif (of_property_read_u32(np, \"reg\", &cs)) {\n\t\t\tdev_err(dev, \"Couldn't determine chip select.\\n\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (cs >= CQSPI_MAX_CHIPSELECT) {\n\t\t\tdev_err(dev, \"Chip select %d out of range.\\n\", cs);\n\t\t\tgoto err;\n\t\t}\n\n\t\tf_pdata = &cqspi->f_pdata[cs];\n\t\tf_pdata->cqspi = cqspi;\n\t\tf_pdata->cs = cs;\n\n\t\tret = cqspi_of_get_flash_pdata(pdev, f_pdata, np);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tnor = &f_pdata->nor;\n\t\tmtd = &nor->mtd;\n\n\t\tmtd->priv = nor;\n\n\t\tnor->dev = dev;\n\t\tspi_nor_set_flash_node(nor, np);\n\t\tnor->priv = f_pdata;\n\n\t\tnor->read_reg = cqspi_read_reg;\n\t\tnor->write_reg = cqspi_write_reg;\n\t\tnor->read = cqspi_read;\n\t\tnor->write = cqspi_write;\n\t\tnor->erase = cqspi_erase;\n\t\tnor->prepare = cqspi_prep;\n\t\tnor->unprepare = cqspi_unprep;\n\n\t\tmtd->name = devm_kasprintf(dev, GFP_KERNEL, \"%s.%d\",\n\t\t\t\t\t   dev_name(dev), cs);\n\t\tif (!mtd->name) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = spi_nor_scan(nor, NULL, SPI_NOR_QUAD);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = mtd_device_register(mtd, NULL, 0);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tf_pdata->registered = true;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (i = 0; i < CQSPI_MAX_CHIPSELECT; i++)\n\t\tif (cqspi->f_pdata[i].registered)\n\t\t\tmtd_device_unregister(&cqspi->f_pdata[i].nor.mtd);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (cs >= CQSPI_MAX_CHIPSELECT) {"
        ],
        "deleted": [
          "\t\tif (cs > CQSPI_MAX_CHIPSELECT) {"
        ]
      },
      "preconditions_for_vulnerability": "Improper validation of chip select value against the maximum chip select value.",
      "trigger_condition": "The chip select value exceeds the maximum allowed value, leading to an out-of-bounds access in the array.",
      "specific_code_behavior_causing_vulnerability": "The code compares the chip select value using '>' instead of '>=' against the maximum chip select value, potentially allowing access to an array element beyond its bounds.",
      "id": 75,
      "code_after_change_normalized": "static int FUN1(struct cqspi_st *VAR1, struct device_node *VAR2)\n{\nstruct platform_device *VAR3 = VAR1->VAR3;\nstruct device *VAR4 = &VAR3->VAR4;\nstruct cqspi_flash_pdata *VAR5;\nstruct spi_nor *VAR6;\nstruct mtd_info *VAR7;\nunsigned int VAR8;\nint VAR9, VAR10;\nFUN2(VAR4->VAR11, VAR2) {\nif (FUN3(VAR2, \"STR\", &VAR8)) {\nFUN4(VAR4, \"STR\");\ngoto VAR12;\n}\nif (VAR8 >= VAR13) {\nFUN4(VAR4, \"STR\", VAR8);\ngoto VAR12;\n}\nVAR5 = &VAR1->VAR5[VAR8];\nVAR5->VAR1 = VAR1;\nVAR5->VAR8 = VAR8;\nVAR10 = FUN5(VAR3, VAR5, VAR2);\nif (VAR10)\ngoto VAR12;\nVAR6 = &VAR5->VAR6;\nVAR7 = &VAR6->VAR7;\nVAR7->VAR14 = VAR6;\nVAR6->VAR4 = VAR4;\nFUN6(VAR6, VAR2);\nVAR6->VAR14 = VAR5;\nVAR6->VAR15 = VAR16;\nVAR6->VAR17 = VAR18;\nVAR6->VAR19 = VAR20;\nVAR6->VAR21 = VAR22;\nVAR6->VAR23 = VAR24;\nVAR6->VAR25 = VAR26;\nVAR6->VAR27 = VAR28;\nVAR7->VAR29 = FUN7(VAR4, VAR30, \"STR\",\nFUN8(VAR4), VAR8);\nif (!VAR7->VAR29) {\nVAR10 = -VAR31;\ngoto VAR12;\n}\nVAR10 = FUN9(VAR6, NULL, VAR32);\nif (VAR10)\ngoto VAR12;\nVAR10 = FUN10(VAR7, NULL, 0);\nif (VAR10)\ngoto VAR12;\nVAR5->VAR33 = true;\n}\nreturn 0;\nVAR12:\nfor (VAR9 = 0; VAR9 < VAR13; VAR9++)\nif (VAR1->VAR5[VAR9].VAR33)\nFUN11(&VAR1->VAR5[VAR9].VAR6.VAR7);\nreturn VAR10;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct cqspi_st *VAR1, struct device_node *VAR2)\n{\nstruct platform_device *VAR3 = VAR1->VAR3;\nstruct device *VAR4 = &VAR3->VAR4;\nstruct cqspi_flash_pdata *VAR5;\nstruct spi_nor *VAR6;\nstruct mtd_info *VAR7;\nunsigned int VAR8;\nint VAR9, VAR10;\nFUN2(VAR4->VAR11, VAR2) {\nif (FUN3(VAR2, \"STR\", &VAR8)) {\nFUN4(VAR4, \"STR\");\ngoto VAR12;\n}\nif (VAR8 > VAR13) {\nFUN4(VAR4, \"STR\", VAR8);\ngoto VAR12;\n}\nVAR5 = &VAR1->VAR5[VAR8];\nVAR5->VAR1 = VAR1;\nVAR5->VAR8 = VAR8;\nVAR10 = FUN5(VAR3, VAR5, VAR2);\nif (VAR10)\ngoto VAR12;\nVAR6 = &VAR5->VAR6;\nVAR7 = &VAR6->VAR7;\nVAR7->VAR14 = VAR6;\nVAR6->VAR4 = VAR4;\nFUN6(VAR6, VAR2);\nVAR6->VAR14 = VAR5;\nVAR6->VAR15 = VAR16;\nVAR6->VAR17 = VAR18;\nVAR6->VAR19 = VAR20;\nVAR6->VAR21 = VAR22;\nVAR6->VAR23 = VAR24;\nVAR6->VAR25 = VAR26;\nVAR6->VAR27 = VAR28;\nVAR7->VAR29 = FUN7(VAR4, VAR30, \"STR\",\nFUN8(VAR4), VAR8);\nif (!VAR7->VAR29) {\nVAR10 = -VAR31;\ngoto VAR12;\n}\nVAR10 = FUN9(VAR6, NULL, VAR32);\nif (VAR10)\ngoto VAR12;\nVAR10 = FUN10(VAR7, NULL, 0);\nif (VAR10)\ngoto VAR12;\nVAR5->VAR33 = true;\n}\nreturn 0;\nVAR12:\nfor (VAR9 = 0; VAR9 < VAR13; VAR9++)\nif (VAR1->VAR5[VAR9].VAR33)\nFUN11(&VAR1->VAR5[VAR9].VAR6.VAR7);\nreturn VAR10;\n}\n",
      "code_after_change_raw": "static int cqspi_setup_flash(struct cqspi_st *cqspi, struct device_node *np)\n{\nstruct platform_device *pdev = cqspi->pdev;\nstruct device *dev = &pdev->dev;\nstruct cqspi_flash_pdata *f_pdata;\nstruct spi_nor *nor;\nstruct mtd_info *mtd;\nunsigned int cs;\nint i, ret;\nfor_each_available_child_of_node(dev->of_node, np) {\nif (of_property_read_u32(np, \"reg\", &cs)) {\ndev_err(dev, \"Couldn't determine chip select.\\n\");\ngoto err;\n}\nif (cs >= CQSPI_MAX_CHIPSELECT) {\ndev_err(dev, \"Chip select %d out of range.\\n\", cs);\ngoto err;\n}\nf_pdata = &cqspi->f_pdata[cs];\nf_pdata->cqspi = cqspi;\nf_pdata->cs = cs;\nret = cqspi_of_get_flash_pdata(pdev, f_pdata, np);\nif (ret)\ngoto err;\nnor = &f_pdata->nor;\nmtd = &nor->mtd;\nmtd->priv = nor;\nnor->dev = dev;\nspi_nor_set_flash_node(nor, np);\nnor->priv = f_pdata;\nnor->read_reg = cqspi_read_reg;\nnor->write_reg = cqspi_write_reg;\nnor->read = cqspi_read;\nnor->write = cqspi_write;\nnor->erase = cqspi_erase;\nnor->prepare = cqspi_prep;\nnor->unprepare = cqspi_unprep;\nmtd->name = devm_kasprintf(dev, GFP_KERNEL, \"%s.%d\",\ndev_name(dev), cs);\nif (!mtd->name) {\nret = -ENOMEM;\ngoto err;\n}\nret = spi_nor_scan(nor, NULL, SPI_NOR_QUAD);\nif (ret)\ngoto err;\nret = mtd_device_register(mtd, NULL, 0);\nif (ret)\ngoto err;\nf_pdata->registered = true;\n}\nreturn 0;\nerr:\nfor (i = 0; i < CQSPI_MAX_CHIPSELECT; i++)\nif (cqspi->f_pdata[i].registered)\nmtd_device_unregister(&cqspi->f_pdata[i].nor.mtd);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int cqspi_setup_flash(struct cqspi_st *cqspi, struct device_node *np)\n{\nstruct platform_device *pdev = cqspi->pdev;\nstruct device *dev = &pdev->dev;\nstruct cqspi_flash_pdata *f_pdata;\nstruct spi_nor *nor;\nstruct mtd_info *mtd;\nunsigned int cs;\nint i, ret;\nfor_each_available_child_of_node(dev->of_node, np) {\nif (of_property_read_u32(np, \"reg\", &cs)) {\ndev_err(dev, \"Couldn't determine chip select.\\n\");\ngoto err;\n}\nif (cs > CQSPI_MAX_CHIPSELECT) {\ndev_err(dev, \"Chip select %d out of range.\\n\", cs);\ngoto err;\n}\nf_pdata = &cqspi->f_pdata[cs];\nf_pdata->cqspi = cqspi;\nf_pdata->cs = cs;\nret = cqspi_of_get_flash_pdata(pdev, f_pdata, np);\nif (ret)\ngoto err;\nnor = &f_pdata->nor;\nmtd = &nor->mtd;\nmtd->priv = nor;\nnor->dev = dev;\nspi_nor_set_flash_node(nor, np);\nnor->priv = f_pdata;\nnor->read_reg = cqspi_read_reg;\nnor->write_reg = cqspi_write_reg;\nnor->read = cqspi_read;\nnor->write = cqspi_write;\nnor->erase = cqspi_erase;\nnor->prepare = cqspi_prep;\nnor->unprepare = cqspi_unprep;\nmtd->name = devm_kasprintf(dev, GFP_KERNEL, \"%s.%d\",\ndev_name(dev), cs);\nif (!mtd->name) {\nret = -ENOMEM;\ngoto err;\n}\nret = spi_nor_scan(nor, NULL, SPI_NOR_QUAD);\nif (ret)\ngoto err;\nret = mtd_device_register(mtd, NULL, 0);\nif (ret)\ngoto err;\nf_pdata->registered = true;\n}\nreturn 0;\nerr:\nfor (i = 0; i < CQSPI_MAX_CHIPSELECT; i++)\nif (cqspi->f_pdata[i].registered)\nmtd_device_unregister(&cqspi->f_pdata[i].nor.mtd);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2016-1583": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of mmap calls for /proc pathnames in the ecryptfs_privileged_open function.",
        "trigger_condition": "Crafted mmap calls for /proc pathnames lead to recursive pagefault handling, causing stack memory consumption and potential privilege escalation or denial of service.",
        "specific_code_behavior_causing_vulnerability": "The original code does not limit the stack depth for the proc filesystem, allowing crafted mmap calls to trigger recursive pagefault handling and potentially exploit the system."
      },
      "solution": "To mitigate the vulnerability, it is necessary to limit the stack depth for the proc filesystem by setting the s_stack_depth field of the super_block structure to a maximum value. This prevents recursive pagefault handling caused by crafted mmap calls for /proc pathnames and reduces the risk of privilege escalation or denial of service attacks.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-1583 related to the ecryptfs_privileged_open function in the Linux kernel. By setting the s_stack_depth field of the super_block structure to FILESYSTEM_MAX_STACK_DEPTH, the modification prevents potential issues caused by recursive pagefault handling when dealing with crafted mmap calls for /proc pathnames.\n\nSpecifically, the added comment explains that procfs isn't a stacking filesystem, but due to the complexity and special behavior of the proc filesystem, it is necessary to limit the stack depth to prevent potential vulnerabilities or denial of service attacks related to recursive pagefault handling.\n\nBy making this modification, the code ensures that the stack depth is limited, which helps mitigate the risk of privilege escalation or denial of service attacks that could be triggered by crafted mmap calls for /proc pathnames.",
      "GPT_purpose": "Mount a file system on the /proc directory with specified options and check for privilege over the pid namespace.",
      "GPT_function": "\n1. Mounts a filesystem using the provided file_system_type.\n2. Checks mount flags and handles privilege over the pid namespace.\n3. Parses mount options and fills the super block with proc-specific information.",
      "CVE_id": "CVE-2016-1583",
      "code_before_change": "static struct dentry *proc_mount(struct file_system_type *fs_type,\n\tint flags, const char *dev_name, void *data)\n{\n\tint err;\n\tstruct super_block *sb;\n\tstruct pid_namespace *ns;\n\tchar *options;\n\n\tif (flags & MS_KERNMOUNT) {\n\t\tns = (struct pid_namespace *)data;\n\t\toptions = NULL;\n\t} else {\n\t\tns = task_active_pid_ns(current);\n\t\toptions = data;\n\n\t\t/* Does the mounter have privilege over the pid namespace? */\n\t\tif (!ns_capable(ns->user_ns, CAP_SYS_ADMIN))\n\t\t\treturn ERR_PTR(-EPERM);\n\t}\n\n\tsb = sget(fs_type, proc_test_super, proc_set_super, flags, ns);\n\tif (IS_ERR(sb))\n\t\treturn ERR_CAST(sb);\n\n\tif (!proc_parse_options(options, ns)) {\n\t\tdeactivate_locked_super(sb);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!sb->s_root) {\n\t\terr = proc_fill_super(sb);\n\t\tif (err) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\n\t\tsb->s_flags |= MS_ACTIVE;\n\t\t/* User space would break if executables appear on proc */\n\t\tsb->s_iflags |= SB_I_NOEXEC;\n\t}\n\n\treturn dget(sb->s_root);\n}",
      "code_after_change": "static struct dentry *proc_mount(struct file_system_type *fs_type,\n\tint flags, const char *dev_name, void *data)\n{\n\tint err;\n\tstruct super_block *sb;\n\tstruct pid_namespace *ns;\n\tchar *options;\n\n\tif (flags & MS_KERNMOUNT) {\n\t\tns = (struct pid_namespace *)data;\n\t\toptions = NULL;\n\t} else {\n\t\tns = task_active_pid_ns(current);\n\t\toptions = data;\n\n\t\t/* Does the mounter have privilege over the pid namespace? */\n\t\tif (!ns_capable(ns->user_ns, CAP_SYS_ADMIN))\n\t\t\treturn ERR_PTR(-EPERM);\n\t}\n\n\tsb = sget(fs_type, proc_test_super, proc_set_super, flags, ns);\n\tif (IS_ERR(sb))\n\t\treturn ERR_CAST(sb);\n\n\t/*\n\t * procfs isn't actually a stacking filesystem; however, there is\n\t * too much magic going on inside it to permit stacking things on\n\t * top of it\n\t */\n\tsb->s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH;\n\n\tif (!proc_parse_options(options, ns)) {\n\t\tdeactivate_locked_super(sb);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!sb->s_root) {\n\t\terr = proc_fill_super(sb);\n\t\tif (err) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\n\t\tsb->s_flags |= MS_ACTIVE;\n\t\t/* User space would break if executables appear on proc */\n\t\tsb->s_iflags |= SB_I_NOEXEC;\n\t}\n\n\treturn dget(sb->s_root);\n}",
      "modified_lines": {
        "added": [
          "\t/*",
          "\t * procfs isn't actually a stacking filesystem; however, there is",
          "\t * too much magic going on inside it to permit stacking things on",
          "\t * top of it",
          "\t */",
          "\tsb->s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH;",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Improper handling of mmap calls for /proc pathnames in the ecryptfs_privileged_open function.",
      "trigger_condition": "Crafted mmap calls for /proc pathnames lead to recursive pagefault handling, causing stack memory consumption and potential privilege escalation or denial of service.",
      "specific_code_behavior_causing_vulnerability": "The original code does not limit the stack depth for the proc filesystem, allowing crafted mmap calls to trigger recursive pagefault handling and potentially exploit the system.",
      "id": 76,
      "code_after_change_normalized": "static struct dentry *FUN1(struct file_system_type *VAR1,\nint VAR2, const char *VAR3, void *VAR4)\n{\nint VAR5;\nstruct super_block *VAR6;\nstruct pid_namespace *VAR7;\nchar *VAR8;\nif (VAR2 & VAR9) {\nVAR7 = (struct VAR10 *)VAR4;\nVAR8 = NULL;\n} else {\nVAR7 = FUN2(VAR11);\nVAR8 = VAR4;\nif (!FUN3(VAR7->VAR12, VAR13))\nreturn FUN4(-VAR14);\n}\nVAR6 = FUN5(VAR1, VAR15, VAR16, VAR2, VAR7);\nif (FUN6(VAR6))\nreturn FUN7(VAR6);\nVAR6->VAR17 = VAR18;\nif (!FUN8(VAR8, VAR7)) {\nFUN9(VAR6);\nreturn FUN4(-VAR19);\n}\nif (!VAR6->VAR20) {\nVAR5 = FUN10(VAR6);\nif (VAR5) {\nFUN9(VAR6);\nreturn FUN4(VAR5);\n}\nVAR6->VAR21 |= VAR22;\nVAR6->VAR23 |= VAR24;\n}\nreturn FUN11(VAR6->VAR20);\n}\n",
      "code_before_change_normalized": "static struct dentry *FUN1(struct file_system_type *VAR1,\nint VAR2, const char *VAR3, void *VAR4)\n{\nint VAR5;\nstruct super_block *VAR6;\nstruct pid_namespace *VAR7;\nchar *VAR8;\nif (VAR2 & VAR9) {\nVAR7 = (struct VAR10 *)VAR4;\nVAR8 = NULL;\n} else {\nVAR7 = FUN2(VAR11);\nVAR8 = VAR4;\nif (!FUN3(VAR7->VAR12, VAR13))\nreturn FUN4(-VAR14);\n}\nVAR6 = FUN5(VAR1, VAR15, VAR16, VAR2, VAR7);\nif (FUN6(VAR6))\nreturn FUN7(VAR6);\nif (!FUN8(VAR8, VAR7)) {\nFUN9(VAR6);\nreturn FUN4(-VAR17);\n}\nif (!VAR6->VAR18) {\nVAR5 = FUN10(VAR6);\nif (VAR5) {\nFUN9(VAR6);\nreturn FUN4(VAR5);\n}\nVAR6->VAR19 |= VAR20;\nVAR6->VAR21 |= VAR22;\n}\nreturn FUN11(VAR6->VAR18);\n}\n",
      "code_after_change_raw": "static struct dentry *proc_mount(struct file_system_type *fs_type,\nint flags, const char *dev_name, void *data)\n{\nint err;\nstruct super_block *sb;\nstruct pid_namespace *ns;\nchar *options;\nif (flags & MS_KERNMOUNT) {\nns = (struct pid_namespace *)data;\noptions = NULL;\n} else {\nns = task_active_pid_ns(current);\noptions = data;\nif (!ns_capable(ns->user_ns, CAP_SYS_ADMIN))\nreturn ERR_PTR(-EPERM);\n}\nsb = sget(fs_type, proc_test_super, proc_set_super, flags, ns);\nif (IS_ERR(sb))\nreturn ERR_CAST(sb);\nsb->s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH;\nif (!proc_parse_options(options, ns)) {\ndeactivate_locked_super(sb);\nreturn ERR_PTR(-EINVAL);\n}\nif (!sb->s_root) {\nerr = proc_fill_super(sb);\nif (err) {\ndeactivate_locked_super(sb);\nreturn ERR_PTR(err);\n}\nsb->s_flags |= MS_ACTIVE;\nsb->s_iflags |= SB_I_NOEXEC;\n}\nreturn dget(sb->s_root);\n}\n",
      "code_before_change_raw": "static struct dentry *proc_mount(struct file_system_type *fs_type,\nint flags, const char *dev_name, void *data)\n{\nint err;\nstruct super_block *sb;\nstruct pid_namespace *ns;\nchar *options;\nif (flags & MS_KERNMOUNT) {\nns = (struct pid_namespace *)data;\noptions = NULL;\n} else {\nns = task_active_pid_ns(current);\noptions = data;\nif (!ns_capable(ns->user_ns, CAP_SYS_ADMIN))\nreturn ERR_PTR(-EPERM);\n}\nsb = sget(fs_type, proc_test_super, proc_set_super, flags, ns);\nif (IS_ERR(sb))\nreturn ERR_CAST(sb);\nif (!proc_parse_options(options, ns)) {\ndeactivate_locked_super(sb);\nreturn ERR_PTR(-EINVAL);\n}\nif (!sb->s_root) {\nerr = proc_fill_super(sb);\nif (err) {\ndeactivate_locked_super(sb);\nreturn ERR_PTR(err);\n}\nsb->s_flags |= MS_ACTIVE;\nsb->s_iflags |= SB_I_NOEXEC;\n}\nreturn dget(sb->s_root);\n}\n"
    }
  ],
  "CVE-2016-3134": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation of certain offset fields in the netfilter subsystem.",
        "trigger_condition": "Local users making an IPT_SO_SET_REPLACE setsockopt call can exploit the lack of validation to gain privileges or cause a denial of service through heap memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate offset fields, allowing for potential memory corruption and privilege escalation."
      },
      "solution": "To mitigate the vulnerability, it is necessary to enforce proper validation of offset fields within the code. Specifically, the modification involves adding a debug message to inform about the correct usage of underflows with the STANDARD target and ACCEPT/DROP actions. This helps prevent misuse of underflows and enhances the security of the system.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-3134, which involves a lack of validation of certain offset fields in the netfilter subsystem of the Linux kernel. By not properly validating these offset fields, local users could exploit this vulnerability to gain privileges or cause a denial of service through heap memory corruption when making an IPT_SO_SET_REPLACE setsockopt call.\n\nThe modification involves adding the following line:\n```\npr_debug(\"Underflows must be unconditional and \"\n         \"use the STANDARD target with \"\n         \"ACCEPT/DROP\\n\");\n```\nThis line adds a debug message to inform about the required conditions for underflows, which helps in preventing the misuse of underflows and ensures that they are used correctly with the STANDARD target and ACCEPT/DROP actions. By providing this additional information and enforcing the correct usage of underflows, the vulnerability can be mitigated, and the system's security can be improved.",
      "GPT_purpose": "Check the size and hooks of an arpt_entry structure for validity in the netfilter subsystem.",
      "GPT_function": "\n1. Check the entry size and hooks for a given arpt_entry.\n2. Validate the offset fields to prevent heap memory corruption.\n3. Clear counters and comefrom fields in the arpt_entry.",
      "CVE_id": "CVE-2016-3134",
      "code_before_change": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_err(\"Underflows must be unconditional and \"\n\t\t\t\t       \"use the STANDARD target with \"\n\t\t\t\t       \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
      "code_after_change": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\t\t\tpr_debug(\"Underflows must be unconditional and \"",
          "\t\t\t\t\t \"use the STANDARD target with \"",
          "\t\t\t\t\t \"ACCEPT/DROP\\n\");"
        ],
        "deleted": [
          "\t\t\t\tpr_err(\"Underflows must be unconditional and \"",
          "\t\t\t\t       \"use the STANDARD target with \"",
          "\t\t\t\t       \"ACCEPT/DROP\\n\");"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation of certain offset fields in the netfilter subsystem.",
      "trigger_condition": "Local users making an IPT_SO_SET_REPLACE setsockopt call can exploit the lack of validation to gain privileges or cause a denial of service through heap memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate offset fields, allowing for potential memory corruption and privilege escalation.",
      "id": 77,
      "code_after_change_normalized": "static inline int FUN1(struct arpt_entry *VAR1,\nstruct xt_table_info *VAR2,\nconst unsigned char *VAR3,\nconst unsigned char *VAR4,\nconst unsigned int *VAR5,\nconst unsigned int *VAR6,\nunsigned int VAR7)\n{\nunsigned int VAR8;\nint VAR9;\nif ((unsigned long)VAR1 % FUN2(struct VAR10) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR10) >= VAR4 ||\n(unsigned char *)VAR1 + VAR1->VAR11 > VAR4) {\nFUN3(\"STR\", VAR1);\nreturn -VAR12;\n}\nif (VAR1->VAR11\n< sizeof(struct VAR10) + sizeof(struct VAR13)) {\nFUN3(\"STR\",\nVAR1, VAR1->VAR11);\nreturn -VAR12;\n}\nVAR9 = FUN4(VAR1);\nif (VAR9)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR14; VAR8++) {\nif (!(VAR7 & (1 << VAR8)))\ncontinue;\nif ((unsigned char *)VAR1 - VAR3 == VAR5[VAR8])\nVAR2->VAR15[VAR8] = VAR5[VAR8];\nif ((unsigned char *)VAR1 - VAR3 == VAR6[VAR8]) {\nif (!FUN5(VAR1)) {\nFUN6(\"STR\"\n\"STR\"\n\"STR\");\nreturn -VAR12;\n}\nVAR2->VAR16[VAR8] = VAR6[VAR8];\n}\n}\nVAR1->VAR17 = ((struct VAR18) { 0, 0 });\nVAR1->VAR19 = 0;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static inline int FUN1(struct arpt_entry *VAR1,\nstruct xt_table_info *VAR2,\nconst unsigned char *VAR3,\nconst unsigned char *VAR4,\nconst unsigned int *VAR5,\nconst unsigned int *VAR6,\nunsigned int VAR7)\n{\nunsigned int VAR8;\nint VAR9;\nif ((unsigned long)VAR1 % FUN2(struct VAR10) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR10) >= VAR4 ||\n(unsigned char *)VAR1 + VAR1->VAR11 > VAR4) {\nFUN3(\"STR\", VAR1);\nreturn -VAR12;\n}\nif (VAR1->VAR11\n< sizeof(struct VAR10) + sizeof(struct VAR13)) {\nFUN3(\"STR\",\nVAR1, VAR1->VAR11);\nreturn -VAR12;\n}\nVAR9 = FUN4(VAR1);\nif (VAR9)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR14; VAR8++) {\nif (!(VAR7 & (1 << VAR8)))\ncontinue;\nif ((unsigned char *)VAR1 - VAR3 == VAR5[VAR8])\nVAR2->VAR15[VAR8] = VAR5[VAR8];\nif ((unsigned char *)VAR1 - VAR3 == VAR6[VAR8]) {\nif (!FUN5(VAR1)) {\nFUN6(\"STR\"\n\"STR\"\n\"STR\");\nreturn -VAR12;\n}\nVAR2->VAR16[VAR8] = VAR6[VAR8];\n}\n}\nVAR1->VAR17 = ((struct VAR18) { 0, 0 });\nVAR1->VAR19 = 0;\nreturn 0;\n}\n",
      "code_after_change_raw": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\nstruct xt_table_info *newinfo,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nunsigned int valid_hooks)\n{\nunsigned int h;\nint err;\nif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n(unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p\\n\", e);\nreturn -EINVAL;\n}\nif (e->next_offset\n< sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nerr = check_entry(e);\nif (err)\nreturn err;\nfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\nif (!(valid_hooks & (1 << h)))\ncontinue;\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h]) {\nif (!check_underflow(e)) {\npr_debug(\"Underflows must be unconditional and \"\n\"use the STANDARD target with \"\n\"ACCEPT/DROP\\n\");\nreturn -EINVAL;\n}\nnewinfo->underflow[h] = underflows[h];\n}\n}\ne->counters = ((struct xt_counters) { 0, 0 });\ne->comefrom = 0;\nreturn 0;\n}\n",
      "code_before_change_raw": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\nstruct xt_table_info *newinfo,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nunsigned int valid_hooks)\n{\nunsigned int h;\nint err;\nif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n(unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p\\n\", e);\nreturn -EINVAL;\n}\nif (e->next_offset\n< sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nerr = check_entry(e);\nif (err)\nreturn err;\nfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\nif (!(valid_hooks & (1 << h)))\ncontinue;\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h]) {\nif (!check_underflow(e)) {\npr_err(\"Underflows must be unconditional and \"\n\"use the STANDARD target with \"\n\"ACCEPT/DROP\\n\");\nreturn -EINVAL;\n}\nnewinfo->underflow[h] = underflows[h];\n}\n}\ne->counters = ((struct xt_counters) { 0, 0 });\ne->comefrom = 0;\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for certain offset fields in the netfilter subsystem of the Linux kernel.",
        "trigger_condition": "A local user makes a specific setsockopt call, leading to a potential heap memory corruption vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code snippet uses the ipt_get_target_c function without proper validation of certain offset fields, allowing for potential heap memory corruption when a specific setsockopt call is made.",
        "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation of offset fields in the netfilter subsystem. In this case, the modification involves calling the unconditional function with the correct argument and removing the incorrect offset usage. This change helps prevent heap memory corruption and enhances the security of the code."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-3134, which involves a potential heap memory corruption issue due to the lack of validation of certain offset fields in the netfilter subsystem of the Linux kernel.\n\nIn the original code snippet, the vulnerability arises from the use of the `ipt_get_target_c` function, which does not properly validate certain offset fields. This lack of validation can be exploited by a local user to gain privileges or cause a denial of service through a specific setsockopt call.\n\nBy modifying the code as suggested, the `unconditional` function is called with the correct argument `e` instead of `&e->ip`, which helps in addressing the vulnerability by ensuring proper validation. This modification helps prevent potential heap memory corruption and enhances the security of the code.",
      "GPT_purpose": "Check if the given ipt_entry structure has an underflow vulnerability by manipulating the verdict value.",
      "GPT_function": "\n1. Check if the ipt_entry structure has an unconditional rule.\n2. Retrieve the target of the ipt_entry.\n3. Verify if the target is a standard target and check the verdict value for NF_DROP or NF_ACCEPT.",
      "CVE_id": "CVE-2016-3134",
      "code_before_change": "static bool check_underflow(const struct ipt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(&e->ip))\n\t\treturn false;\n\tt = ipt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}",
      "code_after_change": "static bool check_underflow(const struct ipt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = ipt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}",
      "modified_lines": {
        "added": [
          "\tif (!unconditional(e))"
        ],
        "deleted": [
          "\tif (!unconditional(&e->ip))"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation for certain offset fields in the netfilter subsystem of the Linux kernel.",
      "trigger_condition": "A local user makes a specific setsockopt call, leading to a potential heap memory corruption vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code snippet uses the ipt_get_target_c function without proper validation of certain offset fields, allowing for potential heap memory corruption when a specific setsockopt call is made.",
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation of offset fields in the netfilter subsystem. In this case, the modification involves calling the unconditional function with the correct argument and removing the incorrect offset usage. This change helps prevent heap memory corruption and enhances the security of the code.",
      "id": 78,
      "code_after_change_normalized": "static bool FUN1(const struct ipt_entry *VAR1)\n{\nconst struct xt_entry_target *VAR2;\nunsigned int VAR3;\nif (!FUN2(VAR1))\nreturn false;\nVAR2 = FUN3(VAR1);\nif (FUN4(VAR2->VAR4.VAR5.VAR6, VAR7) != 0)\nreturn false;\nVAR3 = ((struct VAR8 *)VAR2)->VAR3;\nVAR3 = -VAR3 - 1;\nreturn VAR3 == VAR9 || VAR3 == VAR10;\n}\n",
      "code_before_change_normalized": "static bool FUN1(const struct ipt_entry *VAR1)\n{\nconst struct xt_entry_target *VAR2;\nunsigned int VAR3;\nif (!FUN2(&VAR1->VAR4))\nreturn false;\nVAR2 = FUN3(VAR1);\nif (FUN4(VAR2->VAR5.VAR6.VAR7, VAR8) != 0)\nreturn false;\nVAR3 = ((struct VAR9 *)VAR2)->VAR3;\nVAR3 = -VAR3 - 1;\nreturn VAR3 == VAR10 || VAR3 == VAR11;\n}\n",
      "code_after_change_raw": "static bool check_underflow(const struct ipt_entry *e)\n{\nconst struct xt_entry_target *t;\nunsigned int verdict;\nif (!unconditional(e))\nreturn false;\nt = ipt_get_target_c(e);\nif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\nreturn false;\nverdict = ((struct xt_standard_target *)t)->verdict;\nverdict = -verdict - 1;\nreturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n",
      "code_before_change_raw": "static bool check_underflow(const struct ipt_entry *e)\n{\nconst struct xt_entry_target *t;\nunsigned int verdict;\nif (!unconditional(&e->ip))\nreturn false;\nt = ipt_get_target_c(e);\nif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\nreturn false;\nverdict = ((struct xt_standard_target *)t)->verdict;\nverdict = -verdict - 1;\nreturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for certain offset fields in the netfilter subsystem.",
        "trigger_condition": "An attacker leverages the lack of validation by making an IPT_SO_SET_REPLACE setsockopt call, leading to heap memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code uses the target_offset field without proper validation, allowing an attacker to exploit this vulnerability by manipulating the setsockopt call to trigger heap memory corruption."
      },
      "solution": "To mitigate the vulnerability, it is necessary to remove the vulnerable condition related to the target_offset field and improve validation by checking a more secure condition, such as the unconditional(s) condition. This change enhances the security of the code and prevents potential heap memory corruption. In this case, the solution involves modifying the code to eliminate the use of target_offset for validation and replacing it with a more secure condition.",
      "GPT_analysis": "The modification is necessary to address the vulnerability described in CVE-2016-3134 related to the netfilter subsystem in the Linux kernel. The vulnerability arises from the lack of validation of certain offset fields, which can lead to local users gaining privileges or causing denial of service through an IPT_SO_SET_REPLACE setsockopt call.\n\nIn the original code snippet, the vulnerability is present due to the use of the `target_offset` field without proper validation. By modifying the code as suggested, the vulnerable condition `s->target_offset == sizeof(struct ip6t_entry)` is removed, and the validation is improved by checking the `unconditional(s)` condition instead. This change helps prevent potential heap memory corruption and enhances the security of the code.\n\nTherefore, the modification is necessary to mitigate the vulnerability and ensure the safe and correct operation of the code within the netfilter subsystem in the Linux kernel.",
      "GPT_purpose": "Get the chain name and rule number from an IPv6 table entry.",
      "GPT_function": "\n1. Determine the chainname and rulenum based on the target type.\n2. Handle the case where the target is an ERROR target at the head of a user chain.\n3. Increment the rulenum and set the comment for the tail of chains with a STANDARD target.",
      "CVE_id": "CVE-2016-3134",
      "code_before_change": "static inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (s->target_offset == sizeof(struct ip6t_entry) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t    t->verdict < 0 &&\n\t\t    unconditional(&s->ipv6)) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP6_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP6_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}",
      "code_after_change": "static inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (unconditional(s) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t    t->verdict < 0) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP6_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP6_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (unconditional(s) &&",
          "\t\t    t->verdict < 0) {"
        ],
        "deleted": [
          "\t\tif (s->target_offset == sizeof(struct ip6t_entry) &&",
          "\t\t    t->verdict < 0 &&",
          "\t\t    unconditional(&s->ipv6)) {"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation for certain offset fields in the netfilter subsystem.",
      "trigger_condition": "An attacker leverages the lack of validation by making an IPT_SO_SET_REPLACE setsockopt call, leading to heap memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code uses the target_offset field without proper validation, allowing an attacker to exploit this vulnerability by manipulating the setsockopt call to trigger heap memory corruption.",
      "id": 79,
      "code_after_change_normalized": "static inline int\nFUN1(const struct ip6t_entry *VAR1, const struct ip6t_entry *VAR2,\nconst char *VAR3, const char **VAR4,\nconst char **VAR5, unsigned int *VAR6)\n{\nconst struct xt_standard_target *VAR7 = (void *)FUN2(VAR1);\nif (FUN3(VAR7->VAR8.VAR9.VAR10.VAR8->VAR11, VAR12) == 0) {\n*VAR4 = VAR7->VAR8.VAR13;\n(*VAR6) = 0;\n} else if (VAR1 == VAR2) {\n(*VAR6)++;\nif (FUN4(VAR1) &&\nFUN3(VAR7->VAR8.VAR9.VAR10.VAR8->VAR11,\nVAR14) == 0 &&\nVAR7->VAR15 < 0) {\n*VAR5 = *VAR4 == VAR3\n? VAR16[VAR17]\n: VAR16[VAR18];\n}\nreturn 1;\n} else\n(*VAR6)++;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static inline int\nFUN1(const struct ip6t_entry *VAR1, const struct ip6t_entry *VAR2,\nconst char *VAR3, const char **VAR4,\nconst char **VAR5, unsigned int *VAR6)\n{\nconst struct xt_standard_target *VAR7 = (void *)FUN2(VAR1);\nif (FUN3(VAR7->VAR8.VAR9.VAR10.VAR8->VAR11, VAR12) == 0) {\n*VAR4 = VAR7->VAR8.VAR13;\n(*VAR6) = 0;\n} else if (VAR1 == VAR2) {\n(*VAR6)++;\nif (VAR1->VAR14 == sizeof(struct VAR15) &&\nFUN3(VAR7->VAR8.VAR9.VAR10.VAR8->VAR11,\nVAR16) == 0 &&\nVAR7->VAR17 < 0 &&\nFUN4(&VAR1->VAR18)) {\n*VAR5 = *VAR4 == VAR3\n? VAR19[VAR20]\n: VAR19[VAR21];\n}\nreturn 1;\n} else\n(*VAR6)++;\nreturn 0;\n}\n",
      "code_after_change_raw": "static inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\nconst char *hookname, const char **chainname,\nconst char **comment, unsigned int *rulenum)\n{\nconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\nif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n*chainname = t->target.data;\n(*rulenum) = 0;\n} else if (s == e) {\n(*rulenum)++;\nif (unconditional(s) &&\nstrcmp(t->target.u.kernel.target->name,\nXT_STANDARD_TARGET) == 0 &&\nt->verdict < 0) {\n*comment = *chainname == hookname\n? comments[NF_IP6_TRACE_COMMENT_POLICY]\n: comments[NF_IP6_TRACE_COMMENT_RETURN];\n}\nreturn 1;\n} else\n(*rulenum)++;\nreturn 0;\n}\n",
      "code_before_change_raw": "static inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\nconst char *hookname, const char **chainname,\nconst char **comment, unsigned int *rulenum)\n{\nconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\nif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n*chainname = t->target.data;\n(*rulenum) = 0;\n} else if (s == e) {\n(*rulenum)++;\nif (s->target_offset == sizeof(struct ip6t_entry) &&\nstrcmp(t->target.u.kernel.target->name,\nXT_STANDARD_TARGET) == 0 &&\nt->verdict < 0 &&\nunconditional(&s->ipv6)) {\n*comment = *chainname == hookname\n? comments[NF_IP6_TRACE_COMMENT_POLICY]\n: comments[NF_IP6_TRACE_COMMENT_RETURN];\n}\nreturn 1;\n} else\n(*rulenum)++;\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation of certain offset fields in the netfilter subsystem.",
        "trigger_condition": "A local user makes an IPT_SO_SET_REPLACE setsockopt call, exploiting the lack of validation to gain privileges or cause a denial of service (heap memory corruption).",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate certain offset fields, allowing an attacker to manipulate these fields through a setsockopt call and potentially corrupt heap memory, leading to privilege escalation or denial of service.",
        "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation of the offset fields in the netfilter subsystem. This involves modifying the code to validate the fields correctly to prevent unauthorized manipulation and potential heap memory corruption. In this case, the solution includes updating the conditional check in the code snippet to validate the offset fields securely."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-3134, which involves a security issue related to the netfilter subsystem in the Linux kernel. The vulnerability allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.\n\nThe modification involves changing the conditional check in the code snippet from `if (!unconditional(&e->ipv6))` to `if (!unconditional(e))`. This change is important because the original code snippet is vulnerable to a heap memory corruption issue due to the lack of proper validation of certain offset fields.\n\nBy making this modification, the code snippet is updated to address the vulnerability and ensure that the offset fields are properly validated, thereby preventing potential security risks associated with the vulnerability.",
      "GPT_purpose": "Check if the given iptables entry is vulnerable to underflow exploitation.",
      "GPT_function": "\n1. Check if the condition for underflow is met.\n2. Retrieve the target of the IPv6 entry.\n3. Validate the target name and check if the verdict is NF_DROP or NF_ACCEPT.",
      "CVE_id": "CVE-2016-3134",
      "code_before_change": "static bool check_underflow(const struct ip6t_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(&e->ipv6))\n\t\treturn false;\n\tt = ip6t_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}",
      "code_after_change": "static bool check_underflow(const struct ip6t_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = ip6t_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}",
      "modified_lines": {
        "added": [
          "\tif (!unconditional(e))"
        ],
        "deleted": [
          "\tif (!unconditional(&e->ipv6))"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation of certain offset fields in the netfilter subsystem.",
      "trigger_condition": "A local user makes an IPT_SO_SET_REPLACE setsockopt call, exploiting the lack of validation to gain privileges or cause a denial of service (heap memory corruption).",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate certain offset fields, allowing an attacker to manipulate these fields through a setsockopt call and potentially corrupt heap memory, leading to privilege escalation or denial of service.",
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation of the offset fields in the netfilter subsystem. This involves modifying the code to validate the fields correctly to prevent unauthorized manipulation and potential heap memory corruption. In this case, the solution includes updating the conditional check in the code snippet to validate the offset fields securely.",
      "id": 80,
      "code_after_change_normalized": "static bool FUN1(const struct ip6t_entry *VAR1)\n{\nconst struct xt_entry_target *VAR2;\nunsigned int VAR3;\nif (!FUN2(VAR1))\nreturn false;\nVAR2 = FUN3(VAR1);\nif (FUN4(VAR2->VAR4.VAR5.VAR6, VAR7) != 0)\nreturn false;\nVAR3 = ((struct VAR8 *)VAR2)->VAR3;\nVAR3 = -VAR3 - 1;\nreturn VAR3 == VAR9 || VAR3 == VAR10;\n}\n",
      "code_before_change_normalized": "static bool FUN1(const struct ip6t_entry *VAR1)\n{\nconst struct xt_entry_target *VAR2;\nunsigned int VAR3;\nif (!FUN2(&VAR1->VAR4))\nreturn false;\nVAR2 = FUN3(VAR1);\nif (FUN4(VAR2->VAR5.VAR6.VAR7, VAR8) != 0)\nreturn false;\nVAR3 = ((struct VAR9 *)VAR2)->VAR3;\nVAR3 = -VAR3 - 1;\nreturn VAR3 == VAR10 || VAR3 == VAR11;\n}\n",
      "code_after_change_raw": "static bool check_underflow(const struct ip6t_entry *e)\n{\nconst struct xt_entry_target *t;\nunsigned int verdict;\nif (!unconditional(e))\nreturn false;\nt = ip6t_get_target_c(e);\nif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\nreturn false;\nverdict = ((struct xt_standard_target *)t)->verdict;\nverdict = -verdict - 1;\nreturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n",
      "code_before_change_raw": "static bool check_underflow(const struct ip6t_entry *e)\n{\nconst struct xt_entry_target *t;\nunsigned int verdict;\nif (!unconditional(&e->ipv6))\nreturn false;\nt = ip6t_get_target_c(e);\nif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\nreturn false;\nverdict = ((struct xt_standard_target *)t)->verdict;\nverdict = -verdict - 1;\nreturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for certain offset fields in the netfilter subsystem of the Linux kernel.",
        "trigger_condition": "Local users can exploit the vulnerability by making an IPT_SO_SET_REPLACE setsockopt call, leading to heap memory corruption and potential privilege escalation.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate offset fields in a specific function, allowing for potential out-of-bounds access and memory corruption."
      },
      "solution": "To address the vulnerability, it is necessary to ensure proper validation of offset fields in the affected function. Specifically, modifying the code to use pr_debug instead of pr_err for logging messages related to underflows ensures that debug messages are used appropriately, improving code quality and security.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-3134, which is caused by the netfilter subsystem in the Linux kernel not validating certain offset fields. By not properly validating these offset fields, local users can exploit this vulnerability to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.\n\nThe modification involves adding the `pr_debug` function call instead of `pr_err` in the code snippet. This change is important because `pr_err` prints an error message to the kernel log with a severity level of KERN_ERR, which is typically used for critical errors. In contrast, `pr_debug` prints a debug message to the kernel log with a severity level of KERN_DEBUG, which is intended for debugging purposes and does not have the same impact as an error message.\n\nBy using `pr_debug` instead of `pr_err` in this context, the modification ensures that the message about underflows being unconditional and using the STANDARD target with ACCEPT/DROP is logged as a debug message rather than an error message. This adjustment helps maintain proper logging practices and ensures that the severity level of the message matches its intended purpose, thereby improving the overall code quality and security of the system.",
      "GPT_purpose": "Check the size and hooks of an IP6tables entry for validity and set corresponding values in a new table info structure.",
      "GPT_function": "\n1. Check the entry size and hooks for a given ip6t_entry structure.\n2. Validate the offset fields to prevent heap memory corruption.\n3. Clear counters and comefrom fields in the ip6t_entry structure.",
      "CVE_id": "CVE-2016-3134",
      "code_before_change": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_err(\"Underflows must be unconditional and \"\n\t\t\t\t       \"use the STANDARD target with \"\n\t\t\t\t       \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
      "code_after_change": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\t\t\tpr_debug(\"Underflows must be unconditional and \"",
          "\t\t\t\t\t \"use the STANDARD target with \"",
          "\t\t\t\t\t \"ACCEPT/DROP\\n\");"
        ],
        "deleted": [
          "\t\t\t\tpr_err(\"Underflows must be unconditional and \"",
          "\t\t\t\t       \"use the STANDARD target with \"",
          "\t\t\t\t       \"ACCEPT/DROP\\n\");"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation for certain offset fields in the netfilter subsystem of the Linux kernel.",
      "trigger_condition": "Local users can exploit the vulnerability by making an IPT_SO_SET_REPLACE setsockopt call, leading to heap memory corruption and potential privilege escalation.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate offset fields in a specific function, allowing for potential out-of-bounds access and memory corruption.",
      "id": 81,
      "code_after_change_normalized": "static int\nFUN1(struct ip6t_entry *VAR1,\nstruct xt_table_info *VAR2,\nconst unsigned char *VAR3,\nconst unsigned char *VAR4,\nconst unsigned int *VAR5,\nconst unsigned int *VAR6,\nunsigned int VAR7)\n{\nunsigned int VAR8;\nint VAR9;\nif ((unsigned long)VAR1 % FUN2(struct VAR10) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR10) >= VAR4 ||\n(unsigned char *)VAR1 + VAR1->VAR11 > VAR4) {\nFUN3(\"STR\", VAR1);\nreturn -VAR12;\n}\nif (VAR1->VAR11\n< sizeof(struct VAR10) + sizeof(struct VAR13)) {\nFUN3(\"STR\",\nVAR1, VAR1->VAR11);\nreturn -VAR12;\n}\nVAR9 = FUN4(VAR1);\nif (VAR9)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR14; VAR8++) {\nif (!(VAR7 & (1 << VAR8)))\ncontinue;\nif ((unsigned char *)VAR1 - VAR3 == VAR5[VAR8])\nVAR2->VAR15[VAR8] = VAR5[VAR8];\nif ((unsigned char *)VAR1 - VAR3 == VAR6[VAR8]) {\nif (!FUN5(VAR1)) {\nFUN6(\"STR\"\n\"STR\"\n\"STR\");\nreturn -VAR12;\n}\nVAR2->VAR16[VAR8] = VAR6[VAR8];\n}\n}\nVAR1->VAR17 = ((struct VAR18) { 0, 0 });\nVAR1->VAR19 = 0;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(struct ip6t_entry *VAR1,\nstruct xt_table_info *VAR2,\nconst unsigned char *VAR3,\nconst unsigned char *VAR4,\nconst unsigned int *VAR5,\nconst unsigned int *VAR6,\nunsigned int VAR7)\n{\nunsigned int VAR8;\nint VAR9;\nif ((unsigned long)VAR1 % FUN2(struct VAR10) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR10) >= VAR4 ||\n(unsigned char *)VAR1 + VAR1->VAR11 > VAR4) {\nFUN3(\"STR\", VAR1);\nreturn -VAR12;\n}\nif (VAR1->VAR11\n< sizeof(struct VAR10) + sizeof(struct VAR13)) {\nFUN3(\"STR\",\nVAR1, VAR1->VAR11);\nreturn -VAR12;\n}\nVAR9 = FUN4(VAR1);\nif (VAR9)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR14; VAR8++) {\nif (!(VAR7 & (1 << VAR8)))\ncontinue;\nif ((unsigned char *)VAR1 - VAR3 == VAR5[VAR8])\nVAR2->VAR15[VAR8] = VAR5[VAR8];\nif ((unsigned char *)VAR1 - VAR3 == VAR6[VAR8]) {\nif (!FUN5(VAR1)) {\nFUN6(\"STR\"\n\"STR\"\n\"STR\");\nreturn -VAR12;\n}\nVAR2->VAR16[VAR8] = VAR6[VAR8];\n}\n}\nVAR1->VAR17 = ((struct VAR18) { 0, 0 });\nVAR1->VAR19 = 0;\nreturn 0;\n}\n",
      "code_after_change_raw": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\nstruct xt_table_info *newinfo,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nunsigned int valid_hooks)\n{\nunsigned int h;\nint err;\nif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n(unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p\\n\", e);\nreturn -EINVAL;\n}\nif (e->next_offset\n< sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nerr = check_entry(e);\nif (err)\nreturn err;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif (!(valid_hooks & (1 << h)))\ncontinue;\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h]) {\nif (!check_underflow(e)) {\npr_debug(\"Underflows must be unconditional and \"\n\"use the STANDARD target with \"\n\"ACCEPT/DROP\\n\");\nreturn -EINVAL;\n}\nnewinfo->underflow[h] = underflows[h];\n}\n}\ne->counters = ((struct xt_counters) { 0, 0 });\ne->comefrom = 0;\nreturn 0;\n}\n",
      "code_before_change_raw": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\nstruct xt_table_info *newinfo,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nunsigned int valid_hooks)\n{\nunsigned int h;\nint err;\nif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n(unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p\\n\", e);\nreturn -EINVAL;\n}\nif (e->next_offset\n< sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nerr = check_entry(e);\nif (err)\nreturn err;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif (!(valid_hooks & (1 << h)))\ncontinue;\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h]) {\nif (!check_underflow(e)) {\npr_err(\"Underflows must be unconditional and \"\n\"use the STANDARD target with \"\n\"ACCEPT/DROP\\n\");\nreturn -EINVAL;\n}\nnewinfo->underflow[h] = underflows[h];\n}\n}\ne->counters = ((struct xt_counters) { 0, 0 });\ne->comefrom = 0;\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for certain offset fields in the netfilter subsystem of the Linux kernel.",
        "trigger_condition": "A local user invokes a specific setsockopt call, leading to a denial of service or privilege escalation due to heap memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate certain offset fields, allowing an attacker to manipulate these fields through a setsockopt call, leading to heap memory corruption and potential privilege escalation."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation of offset fields in the code. Specifically, the code should be modified to validate the offset fields before processing them to prevent unauthorized manipulation. In this case, the solution involves updating the code to validate the offset fields properly and prevent potential heap memory corruption or privilege escalation issues.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-3134 in the code snippet. The vulnerability arises due to the netfilter subsystem in the Linux kernel not validating certain offset fields, which can lead to local users gaining privileges or causing denial of service through a specific setsockopt call.\n\nThe modification involves changing the condition in the code snippet from `(strcmp(t->target.u.user.name, XT_STANDARD_TARGET) == 0) && t->verdict < 0` to `(unconditional(e) && (strcmp(t->target.u.user.name, XT_STANDARD_TARGET) == 0) && t->verdict < 0)`. This change ensures that the code properly checks for the condition that could lead to the vulnerability.\n\nBy making this modification, the code snippet is updated to address the vulnerability by properly validating the offset fields and preventing potential heap memory corruption or privilege escalation issues that could be exploited by malicious users.",
      "GPT_purpose": "Mark source chains in the netfilter subsystem for packet filtering.",
      "GPT_function": "\n1. Mark source chains based on the provided table information and valid hooks.\n2. Set initial back pointers and save source hook bitmask.\n3. Handle unconditional returns/END and backtracking through the last big jump.\n4. Validate certain offset fields and handle jump rules or fallthru cases.\n5. Finish processing each chain and return 1 upon completion.",
      "CVE_id": "CVE-2016-3134",
      "code_before_change": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ip6t_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((e->target_offset == sizeof(struct ip6t_entry) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0 &&\n\t\t\t     unconditional(&e->ipv6)) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ip6t_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
      "code_after_change": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ip6t_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ip6t_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
      "modified_lines": {
        "added": [
          "\t\t\tif ((unconditional(e) &&",
          "\t\t\t     t->verdict < 0) || visited) {"
        ],
        "deleted": [
          "\t\t\tif ((e->target_offset == sizeof(struct ip6t_entry) &&",
          "\t\t\t     t->verdict < 0 &&",
          "\t\t\t     unconditional(&e->ipv6)) || visited) {"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for certain offset fields in the netfilter subsystem of the Linux kernel.",
      "trigger_condition": "A local user invokes a specific setsockopt call, leading to a denial of service or privilege escalation due to heap memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate certain offset fields, allowing an attacker to manipulate these fields through a setsockopt call, leading to heap memory corruption and potential privilege escalation.",
      "id": 82,
      "code_after_change_normalized": "static int\nFUN1(const struct xt_table_info *VAR1,\nunsigned int VAR2, void *VAR3)\n{\nunsigned int VAR4;\nfor (VAR4 = 0; VAR4 < VAR5; VAR4++) {\nunsigned int VAR6 = VAR1->VAR7[VAR4];\nstruct VAR9 *VAR8 = (struct VAR9 *)(VAR3 + VAR6);\nif (!(VAR2 & (1 << VAR4)))\ncontinue;\nVAR8->VAR10.VAR11 = VAR6;\nfor (;;) {\nconst struct xt_standard_target *VAR12\n= (void *)FUN2(VAR8);\nint VAR13 = VAR8->VAR14 & (1 << VAR4);\nif (VAR8->VAR14 & (1 << VAR5)) {\nFUN3(\"STR\",\nVAR4, VAR6, VAR8->VAR14);\nreturn 0;\n}\nVAR8->VAR14 |= ((1 << VAR4) | (1 << VAR5));\nif ((FUN4(VAR8) &&\n(FUN5(VAR12->VAR15.VAR16.VAR17.VAR18,\nVAR19) == 0) &&\nVAR12->VAR20 < 0) || VAR13) {\nunsigned int VAR21, VAR22;\nif ((FUN5(VAR12->VAR15.VAR16.VAR17.VAR18,\nVAR19) == 0) &&\nVAR12->VAR20 < -VAR23 - 1) {\nFUN6(\"STR\"\n\"STR\",\nVAR12->VAR20);\nreturn 0;\n}\ndo {\nVAR8->VAR14 ^= (1<<VAR5);\n#ifdef VAR24\nif (VAR8->VAR14\n& (1 << VAR5)) {\nFUN6(\"STR\"\n\"STR\"\n\"STR\",\nVAR4, VAR6);\n}\n#VAR25\nVAR21 = VAR6;\nVAR6 = VAR8->VAR10.VAR11;\nVAR8->VAR10.VAR11 = 0;\nif (VAR6 == VAR21)\ngoto VAR26;\nVAR8 = (struct VAR9 *)\n(VAR3 + VAR6);\n} while (VAR21 == VAR6 + VAR8->VAR27);\nVAR22 = VAR8->VAR27;\nVAR8 = (struct VAR9 *)\n(VAR3 + VAR6 + VAR22);\nVAR8->VAR10.VAR11 = VAR6;\nVAR6 += VAR22;\n} else {\nint VAR28 = VAR12->VAR20;\nif (FUN5(VAR12->VAR15.VAR16.VAR17.VAR18,\nVAR19) == 0 &&\nVAR28 >= 0) {\nif (VAR28 > VAR1->VAR22 -\nsizeof(struct VAR9)) {\nFUN6(\"STR\"\n\"STR\",\nVAR28);\nreturn 0;\n}\nFUN6(\"STR\",\nVAR6, VAR28);\n} else {\nVAR28 = VAR6 + VAR8->VAR27;\n}\nVAR8 = (struct VAR9 *)\n(VAR3 + VAR28);\nVAR8->VAR10.VAR11 = VAR6;\nVAR6 = VAR28;\n}\n}\nVAR26:\nFUN6(\"STR\", VAR4);\n}\nreturn 1;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(const struct xt_table_info *VAR1,\nunsigned int VAR2, void *VAR3)\n{\nunsigned int VAR4;\nfor (VAR4 = 0; VAR4 < VAR5; VAR4++) {\nunsigned int VAR6 = VAR1->VAR7[VAR4];\nstruct VAR9 *VAR8 = (struct VAR9 *)(VAR3 + VAR6);\nif (!(VAR2 & (1 << VAR4)))\ncontinue;\nVAR8->VAR10.VAR11 = VAR6;\nfor (;;) {\nconst struct xt_standard_target *VAR12\n= (void *)FUN2(VAR8);\nint VAR13 = VAR8->VAR14 & (1 << VAR4);\nif (VAR8->VAR14 & (1 << VAR5)) {\nFUN3(\"STR\",\nVAR4, VAR6, VAR8->VAR14);\nreturn 0;\n}\nVAR8->VAR14 |= ((1 << VAR4) | (1 << VAR5));\nif ((VAR8->VAR15 == sizeof(struct VAR9) &&\n(FUN4(VAR12->VAR16.VAR17.VAR18.VAR19,\nVAR20) == 0) &&\nVAR12->VAR21 < 0 &&\nFUN5(&VAR8->VAR22)) || VAR13) {\nunsigned int VAR23, VAR24;\nif ((FUN4(VAR12->VAR16.VAR17.VAR18.VAR19,\nVAR20) == 0) &&\nVAR12->VAR21 < -VAR25 - 1) {\nFUN6(\"STR\"\n\"STR\",\nVAR12->VAR21);\nreturn 0;\n}\ndo {\nVAR8->VAR14 ^= (1<<VAR5);\n#ifdef VAR26\nif (VAR8->VAR14\n& (1 << VAR5)) {\nFUN6(\"STR\"\n\"STR\"\n\"STR\",\nVAR4, VAR6);\n}\n#VAR27\nVAR23 = VAR6;\nVAR6 = VAR8->VAR10.VAR11;\nVAR8->VAR10.VAR11 = 0;\nif (VAR6 == VAR23)\ngoto VAR28;\nVAR8 = (struct VAR9 *)\n(VAR3 + VAR6);\n} while (VAR23 == VAR6 + VAR8->VAR29);\nVAR24 = VAR8->VAR29;\nVAR8 = (struct VAR9 *)\n(VAR3 + VAR6 + VAR24);\nVAR8->VAR10.VAR11 = VAR6;\nVAR6 += VAR24;\n} else {\nint VAR30 = VAR12->VAR21;\nif (FUN4(VAR12->VAR16.VAR17.VAR18.VAR19,\nVAR20) == 0 &&\nVAR30 >= 0) {\nif (VAR30 > VAR1->VAR24 -\nsizeof(struct VAR9)) {\nFUN6(\"STR\"\n\"STR\",\nVAR30);\nreturn 0;\n}\nFUN6(\"STR\",\nVAR6, VAR30);\n} else {\nVAR30 = VAR6 + VAR8->VAR29;\n}\nVAR8 = (struct VAR9 *)\n(VAR3 + VAR30);\nVAR8->VAR10.VAR11 = VAR6;\nVAR6 = VAR30;\n}\n}\nVAR28:\nFUN6(\"STR\", VAR4);\n}\nreturn 1;\n}\n",
      "code_after_change_raw": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\nunsigned int valid_hooks, void *entry0)\n{\nunsigned int hook;\nfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\nunsigned int pos = newinfo->hook_entry[hook];\nstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\nif (!(valid_hooks & (1 << hook)))\ncontinue;\ne->counters.pcnt = pos;\nfor (;;) {\nconst struct xt_standard_target *t\n= (void *)ip6t_get_target_c(e);\nint visited = e->comefrom & (1 << hook);\nif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\npr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\nhook, pos, e->comefrom);\nreturn 0;\n}\ne->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\nif ((unconditional(e) &&\n(strcmp(t->target.u.user.name,\nXT_STANDARD_TARGET) == 0) &&\nt->verdict < 0) || visited) {\nunsigned int oldpos, size;\nif ((strcmp(t->target.u.user.name,\nXT_STANDARD_TARGET) == 0) &&\nt->verdict < -NF_MAX_VERDICT - 1) {\nduprintf(\"mark_source_chains: bad \"\n\"negative verdict (%i)\\n\",\nt->verdict);\nreturn 0;\n}\ndo {\ne->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\nif (e->comefrom\n& (1 << NF_INET_NUMHOOKS)) {\nduprintf(\"Back unset \"\n\"on hook %u \"\n\"rule %u\\n\",\nhook, pos);\n}\n#endif\noldpos = pos;\npos = e->counters.pcnt;\ne->counters.pcnt = 0;\nif (pos == oldpos)\ngoto next;\ne = (struct ip6t_entry *)\n(entry0 + pos);\n} while (oldpos == pos + e->next_offset);\nsize = e->next_offset;\ne = (struct ip6t_entry *)\n(entry0 + pos + size);\ne->counters.pcnt = pos;\npos += size;\n} else {\nint newpos = t->verdict;\nif (strcmp(t->target.u.user.name,\nXT_STANDARD_TARGET) == 0 &&\nnewpos >= 0) {\nif (newpos > newinfo->size -\nsizeof(struct ip6t_entry)) {\nduprintf(\"mark_source_chains: \"\n\"bad verdict (%i)\\n\",\nnewpos);\nreturn 0;\n}\nduprintf(\"Jump rule %u -> %u\\n\",\npos, newpos);\n} else {\nnewpos = pos + e->next_offset;\n}\ne = (struct ip6t_entry *)\n(entry0 + newpos);\ne->counters.pcnt = pos;\npos = newpos;\n}\n}\nnext:\nduprintf(\"Finished chain %u\\n\", hook);\n}\nreturn 1;\n}\n",
      "code_before_change_raw": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\nunsigned int valid_hooks, void *entry0)\n{\nunsigned int hook;\nfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\nunsigned int pos = newinfo->hook_entry[hook];\nstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\nif (!(valid_hooks & (1 << hook)))\ncontinue;\ne->counters.pcnt = pos;\nfor (;;) {\nconst struct xt_standard_target *t\n= (void *)ip6t_get_target_c(e);\nint visited = e->comefrom & (1 << hook);\nif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\npr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\nhook, pos, e->comefrom);\nreturn 0;\n}\ne->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\nif ((e->target_offset == sizeof(struct ip6t_entry) &&\n(strcmp(t->target.u.user.name,\nXT_STANDARD_TARGET) == 0) &&\nt->verdict < 0 &&\nunconditional(&e->ipv6)) || visited) {\nunsigned int oldpos, size;\nif ((strcmp(t->target.u.user.name,\nXT_STANDARD_TARGET) == 0) &&\nt->verdict < -NF_MAX_VERDICT - 1) {\nduprintf(\"mark_source_chains: bad \"\n\"negative verdict (%i)\\n\",\nt->verdict);\nreturn 0;\n}\ndo {\ne->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\nif (e->comefrom\n& (1 << NF_INET_NUMHOOKS)) {\nduprintf(\"Back unset \"\n\"on hook %u \"\n\"rule %u\\n\",\nhook, pos);\n}\n#endif\noldpos = pos;\npos = e->counters.pcnt;\ne->counters.pcnt = 0;\nif (pos == oldpos)\ngoto next;\ne = (struct ip6t_entry *)\n(entry0 + pos);\n} while (oldpos == pos + e->next_offset);\nsize = e->next_offset;\ne = (struct ip6t_entry *)\n(entry0 + pos + size);\ne->counters.pcnt = pos;\npos += size;\n} else {\nint newpos = t->verdict;\nif (strcmp(t->target.u.user.name,\nXT_STANDARD_TARGET) == 0 &&\nnewpos >= 0) {\nif (newpos > newinfo->size -\nsizeof(struct ip6t_entry)) {\nduprintf(\"mark_source_chains: \"\n\"bad verdict (%i)\\n\",\nnewpos);\nreturn 0;\n}\nduprintf(\"Jump rule %u -> %u\\n\",\npos, newpos);\n} else {\nnewpos = pos + e->next_offset;\n}\ne = (struct ip6t_entry *)\n(entry0 + newpos);\ne->counters.pcnt = pos;\npos = newpos;\n}\n}\nnext:\nduprintf(\"Finished chain %u\\n\", hook);\n}\nreturn 1;\n}\n"
    }
  ],
  "CVE-2016-3955": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for the size value received from a USB/IP packet, allowing a potential out-of-bounds write.",
        "trigger_condition": "Receiving a crafted length value in a USB/IP packet that exceeds the expected transfer buffer length of the urb structure.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the size value received from the USB/IP packet exceeds the expected transfer buffer length of the urb structure, potentially leading to an out-of-bounds write vulnerability.",
        "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the size value does not exceed the expected transfer buffer length of the urb structure. If the size value is greater than the transfer buffer length, the code should handle the situation by returning an error code and adding an appropriate event to indicate a TCP error. This validation step helps prevent out-of-bounds write attempts and enhances the security of the system."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-3955, which allows remote attackers to cause a denial of service or potentially have other impacts via a crafted length value in a USB/IP packet. \n\nBy adding the check `if (size > urb->transfer_buffer_length)`, the modified code ensures that the size value received from the USB/IP packet does not exceed the expected transfer buffer length of the urb structure. If the size value is greater than the transfer buffer length, it indicates a potential out-of-bounds write attempt or a malicious packet. In such cases, the modified code handles the situation by returning an error code (-EPIPE) and adding an appropriate event to indicate a TCP error.\n\nThis modification helps prevent the vulnerability by validating the size value against the expected buffer length before proceeding with the data transfer operation, thereby enhancing the security and integrity of the system.",
      "GPT_purpose": "Receive and process USB/IP packets for a USB device, checking the direction and size of the data being transferred.",
      "GPT_function": "\n1. Receives a transfer buffer from a USB/IP device.\n2. Checks the direction of the USB request block (urb).\n3. Handles the received transfer buffer based on the direction of the urb.",
      "CVE_id": "CVE-2016-3955",
      "code_before_change": "int usbip_recv_xbuff(struct usbip_device *ud, struct urb *urb)\n{\n\tint ret;\n\tint size;\n\n\tif (ud->side == USBIP_STUB) {\n\t\t/* the direction of urb must be OUT. */\n\t\tif (usb_pipein(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->transfer_buffer_length;\n\t} else {\n\t\t/* the direction of urb must be IN. */\n\t\tif (usb_pipeout(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->actual_length;\n\t}\n\n\t/* no need to recv xbuff */\n\tif (!(size > 0))\n\t\treturn 0;\n\n\tret = usbip_recv(ud->tcp_socket, urb->transfer_buffer, size);\n\tif (ret != size) {\n\t\tdev_err(&urb->dev->dev, \"recv xbuf, %d\\n\", ret);\n\t\tif (ud->side == USBIP_STUB) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n\t\t} else {\n\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\n\t\t\treturn -EPIPE;\n\t\t}\n\t}\n\n\treturn ret;\n}",
      "code_after_change": "int usbip_recv_xbuff(struct usbip_device *ud, struct urb *urb)\n{\n\tint ret;\n\tint size;\n\n\tif (ud->side == USBIP_STUB) {\n\t\t/* the direction of urb must be OUT. */\n\t\tif (usb_pipein(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->transfer_buffer_length;\n\t} else {\n\t\t/* the direction of urb must be IN. */\n\t\tif (usb_pipeout(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->actual_length;\n\t}\n\n\t/* no need to recv xbuff */\n\tif (!(size > 0))\n\t\treturn 0;\n\n\tif (size > urb->transfer_buffer_length) {\n\t\t/* should not happen, probably malicious packet */\n\t\tif (ud->side == USBIP_STUB) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\n\t\t\treturn -EPIPE;\n\t\t}\n\t}\n\n\tret = usbip_recv(ud->tcp_socket, urb->transfer_buffer, size);\n\tif (ret != size) {\n\t\tdev_err(&urb->dev->dev, \"recv xbuf, %d\\n\", ret);\n\t\tif (ud->side == USBIP_STUB) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n\t\t} else {\n\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\n\t\t\treturn -EPIPE;\n\t\t}\n\t}\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tif (size > urb->transfer_buffer_length) {",
          "\t\t/* should not happen, probably malicious packet */",
          "\t\tif (ud->side == USBIP_STUB) {",
          "\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);",
          "\t\t\treturn 0;",
          "\t\t} else {",
          "\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);",
          "\t\t\treturn -EPIPE;",
          "\t\t}",
          "\t}",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation for the size value received from a USB/IP packet, allowing a potential out-of-bounds write.",
      "trigger_condition": "Receiving a crafted length value in a USB/IP packet that exceeds the expected transfer buffer length of the urb structure.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the size value received from the USB/IP packet exceeds the expected transfer buffer length of the urb structure, potentially leading to an out-of-bounds write vulnerability.",
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the size value does not exceed the expected transfer buffer length of the urb structure. If the size value is greater than the transfer buffer length, the code should handle the situation by returning an error code and adding an appropriate event to indicate a TCP error. This validation step helps prevent out-of-bounds write attempts and enhances the security of the system.",
      "id": 83,
      "code_after_change_normalized": "int FUN1(struct usbip_device *VAR1, struct VAR2 *VAR2)\n{\nint VAR3;\nint VAR4;\nif (VAR1->VAR5 == VAR6) {\nif (FUN2(VAR2->VAR7))\nreturn 0;\nVAR4 = VAR2->VAR8;\n} else {\nif (FUN3(VAR2->VAR7))\nreturn 0;\nVAR4 = VAR2->VAR9;\n}\nif (!(VAR4 > 0))\nreturn 0;\nif (VAR4 > VAR2->VAR8) {\nif (VAR1->VAR5 == VAR6) {\nFUN4(VAR1, VAR10);\nreturn 0;\n} else {\nFUN4(VAR1, VAR11);\nreturn -VAR12;\n}\n}\nVAR3 = FUN5(VAR1->VAR13, VAR2->VAR14, VAR4);\nif (VAR3 != VAR4) {\nFUN6(&VAR2->VAR15->VAR15, \"STR\", VAR3);\nif (VAR1->VAR5 == VAR6) {\nFUN4(VAR1, VAR10);\n} else {\nFUN4(VAR1, VAR11);\nreturn -VAR12;\n}\n}\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "int FUN1(struct usbip_device *VAR1, struct VAR2 *VAR2)\n{\nint VAR3;\nint VAR4;\nif (VAR1->VAR5 == VAR6) {\nif (FUN2(VAR2->VAR7))\nreturn 0;\nVAR4 = VAR2->VAR8;\n} else {\nif (FUN3(VAR2->VAR7))\nreturn 0;\nVAR4 = VAR2->VAR9;\n}\nif (!(VAR4 > 0))\nreturn 0;\nVAR3 = FUN4(VAR1->VAR10, VAR2->VAR11, VAR4);\nif (VAR3 != VAR4) {\nFUN5(&VAR2->VAR12->VAR12, \"STR\", VAR3);\nif (VAR1->VAR5 == VAR6) {\nFUN6(VAR1, VAR13);\n} else {\nFUN6(VAR1, VAR14);\nreturn -VAR15;\n}\n}\nreturn VAR3;\n}\n",
      "code_after_change_raw": "int usbip_recv_xbuff(struct usbip_device *ud, struct urb *urb)\n{\nint ret;\nint size;\nif (ud->side == USBIP_STUB) {\nif (usb_pipein(urb->pipe))\nreturn 0;\nsize = urb->transfer_buffer_length;\n} else {\nif (usb_pipeout(urb->pipe))\nreturn 0;\nsize = urb->actual_length;\n}\nif (!(size > 0))\nreturn 0;\nif (size > urb->transfer_buffer_length) {\nif (ud->side == USBIP_STUB) {\nusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\nreturn 0;\n} else {\nusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\nreturn -EPIPE;\n}\n}\nret = usbip_recv(ud->tcp_socket, urb->transfer_buffer, size);\nif (ret != size) {\ndev_err(&urb->dev->dev, \"recv xbuf, %d\\n\", ret);\nif (ud->side == USBIP_STUB) {\nusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n} else {\nusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\nreturn -EPIPE;\n}\n}\nreturn ret;\n}\n",
      "code_before_change_raw": "int usbip_recv_xbuff(struct usbip_device *ud, struct urb *urb)\n{\nint ret;\nint size;\nif (ud->side == USBIP_STUB) {\nif (usb_pipein(urb->pipe))\nreturn 0;\nsize = urb->transfer_buffer_length;\n} else {\nif (usb_pipeout(urb->pipe))\nreturn 0;\nsize = urb->actual_length;\n}\nif (!(size > 0))\nreturn 0;\nret = usbip_recv(ud->tcp_socket, urb->transfer_buffer, size);\nif (ret != size) {\ndev_err(&urb->dev->dev, \"recv xbuf, %d\\n\", ret);\nif (ud->side == USBIP_STUB) {\nusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n} else {\nusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\nreturn -EPIPE;\n}\n}\nreturn ret;\n}\n"
    }
  ],
  "CVE-2016-4998": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of offset values in the setsockopt implementation, allowing a local user with in-container root access to provide a crafted offset value that leads to crossing a ruleset blob boundary.",
        "trigger_condition": "Local user with in-container root access provides a crafted offset value during the setsockopt operation, causing an out-of-bounds read or potential information disclosure from kernel heap memory.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate and handle the offset values provided during the setsockopt operation, allowing for the possibility of crossing a ruleset blob boundary and accessing sensitive kernel memory out of bounds."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation and handling of offset values in the setsockopt implementation. Specifically, the code should be modified to include the correct offset parameter in the call to xt_compat_check_entry_offsets. This change helps prevent the out-of-bounds read vulnerability by ensuring that the function is called with the appropriate parameters, thus addressing the issue of crossing a ruleset blob boundary.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-4998 in the code snippet. The vulnerability allows local users to cause a denial of service or potentially obtain sensitive information from kernel heap memory by providing a crafted offset value that leads to crossing a ruleset blob boundary.\n\nThe modification specifically changes the call to `xt_compat_check_entry_offsets` by adding the `e->elems` parameter. This change ensures that the function is called with the correct parameters, which helps prevent the out-of-bounds read vulnerability described in the CVE.\n\nBy making this modification, the code is updated to handle the offset values correctly and mitigate the risk of the vulnerability being exploited.",
      "GPT_purpose": "Check the compatibility of an entry size and hooks in the netfilter subsystem.",
      "GPT_function": "\n1. Check compatibility entry size and hooks.\n2. Verify entry offset and target.\n3. Handle hooks and underflows.\n4. Clear counters and comefrom.",
      "CVE_id": "CVE-2016-4998",
      "code_before_change": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
      "code_after_change": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,"
        ],
        "deleted": [
          "\tret = xt_compat_check_entry_offsets(e, e->target_offset,"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of offset values in the setsockopt implementation, allowing a local user with in-container root access to provide a crafted offset value that leads to crossing a ruleset blob boundary.",
      "trigger_condition": "Local user with in-container root access provides a crafted offset value during the setsockopt operation, causing an out-of-bounds read or potential information disclosure from kernel heap memory.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate and handle the offset values provided during the setsockopt operation, allowing for the possibility of crossing a ruleset blob boundary and accessing sensitive kernel memory out of bounds.",
      "id": 84,
      "code_after_change_normalized": "static inline int\nFUN1(struct compat_arpt_entry *VAR1,\nstruct xt_table_info *VAR2,\nunsigned int *VAR3,\nconst unsigned char *VAR4,\nconst unsigned char *VAR5,\nconst unsigned int *VAR6,\nconst unsigned int *VAR7,\nconst char *VAR8)\n{\nstruct xt_entry_target *VAR9;\nstruct xt_target *VAR10;\nunsigned int VAR11;\nint VAR12, VAR13, VAR14;\nFUN2(\"STR\", VAR1);\nif ((unsigned long)VAR1 % FUN3(struct VAR15) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR15) >= VAR5 ||\n(unsigned char *)VAR1 + VAR1->VAR16 > VAR5) {\nFUN2(\"STR\", VAR1, VAR5);\nreturn -VAR17;\n}\nif (VAR1->VAR16 < sizeof(struct VAR15) +\nsizeof(struct VAR18)) {\nFUN2(\"STR\",\nVAR1, VAR1->VAR16);\nreturn -VAR17;\n}\nif (!FUN4(&VAR1->VAR19))\nreturn -VAR17;\nVAR12 = FUN5(VAR1, VAR1->VAR20, VAR1->VAR21,\nVAR1->VAR16);\nif (VAR12)\nreturn VAR12;\nVAR13 = sizeof(struct VAR22) - sizeof(struct VAR15);\nVAR11 = (void *)VAR1 - (void *)VAR4;\nVAR9 = FUN6(VAR1);\nVAR10 = FUN7(VAR23, VAR9->VAR24.VAR25.VAR8,\nVAR9->VAR24.VAR25.VAR26);\nif (FUN8(VAR10)) {\nFUN2(\"STR\",\nVAR9->VAR24.VAR25.VAR8);\nVAR12 = FUN9(VAR10);\ngoto VAR27;\n}\nVAR9->VAR24.VAR28.VAR10 = VAR10;\nVAR13 += FUN10(VAR10);\n*VAR3 += VAR13;\nVAR12 = FUN11(VAR23, VAR11, VAR13);\nif (VAR12)\ngoto VAR29;\nfor (VAR14 = 0; VAR14 < VAR30; VAR14++) {\nif ((unsigned char *)VAR1 - VAR4 == VAR6[VAR14])\nVAR2->VAR31[VAR14] = VAR6[VAR14];\nif ((unsigned char *)VAR1 - VAR4 == VAR7[VAR14])\nVAR2->VAR32[VAR14] = VAR7[VAR14];\n}\nFUN12(&VAR1->VAR33, 0, sizeof(VAR1->VAR33));\nVAR1->VAR34 = 0;\nreturn 0;\nVAR29:\nFUN13(VAR9->VAR24.VAR28.VAR10->VAR35);\nVAR27:\nreturn VAR12;\n}\n",
      "code_before_change_normalized": "static inline int\nFUN1(struct compat_arpt_entry *VAR1,\nstruct xt_table_info *VAR2,\nunsigned int *VAR3,\nconst unsigned char *VAR4,\nconst unsigned char *VAR5,\nconst unsigned int *VAR6,\nconst unsigned int *VAR7,\nconst char *VAR8)\n{\nstruct xt_entry_target *VAR9;\nstruct xt_target *VAR10;\nunsigned int VAR11;\nint VAR12, VAR13, VAR14;\nFUN2(\"STR\", VAR1);\nif ((unsigned long)VAR1 % FUN3(struct VAR15) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR15) >= VAR5 ||\n(unsigned char *)VAR1 + VAR1->VAR16 > VAR5) {\nFUN2(\"STR\", VAR1, VAR5);\nreturn -VAR17;\n}\nif (VAR1->VAR16 < sizeof(struct VAR15) +\nsizeof(struct VAR18)) {\nFUN2(\"STR\",\nVAR1, VAR1->VAR16);\nreturn -VAR17;\n}\nif (!FUN4(&VAR1->VAR19))\nreturn -VAR17;\nVAR12 = FUN5(VAR1, VAR1->VAR20,\nVAR1->VAR16);\nif (VAR12)\nreturn VAR12;\nVAR13 = sizeof(struct VAR21) - sizeof(struct VAR15);\nVAR11 = (void *)VAR1 - (void *)VAR4;\nVAR9 = FUN6(VAR1);\nVAR10 = FUN7(VAR22, VAR9->VAR23.VAR24.VAR8,\nVAR9->VAR23.VAR24.VAR25);\nif (FUN8(VAR10)) {\nFUN2(\"STR\",\nVAR9->VAR23.VAR24.VAR8);\nVAR12 = FUN9(VAR10);\ngoto VAR26;\n}\nVAR9->VAR23.VAR27.VAR10 = VAR10;\nVAR13 += FUN10(VAR10);\n*VAR3 += VAR13;\nVAR12 = FUN11(VAR22, VAR11, VAR13);\nif (VAR12)\ngoto VAR28;\nfor (VAR14 = 0; VAR14 < VAR29; VAR14++) {\nif ((unsigned char *)VAR1 - VAR4 == VAR6[VAR14])\nVAR2->VAR30[VAR14] = VAR6[VAR14];\nif ((unsigned char *)VAR1 - VAR4 == VAR7[VAR14])\nVAR2->VAR31[VAR14] = VAR7[VAR14];\n}\nFUN12(&VAR1->VAR32, 0, sizeof(VAR1->VAR32));\nVAR1->VAR33 = 0;\nreturn 0;\nVAR28:\nFUN13(VAR9->VAR23.VAR27.VAR10->VAR34);\nVAR26:\nreturn VAR12;\n}\n",
      "code_after_change_raw": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\nstruct xt_table_info *newinfo,\nunsigned int *size,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nconst char *name)\n{\nstruct xt_entry_target *t;\nstruct xt_target *target;\nunsigned int entry_offset;\nint ret, off, h;\nduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\nif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n(unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\nreturn -EINVAL;\n}\nif (e->next_offset < sizeof(struct compat_arpt_entry) +\nsizeof(struct compat_xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!arp_checkentry(&e->arp))\nreturn -EINVAL;\nret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\ne->next_offset);\nif (ret)\nreturn ret;\noff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\nentry_offset = (void *)e - (void *)base;\nt = compat_arpt_get_target(e);\ntarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\nt->u.user.revision);\nif (IS_ERR(target)) {\nduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\nt->u.user.name);\nret = PTR_ERR(target);\ngoto out;\n}\nt->u.kernel.target = target;\noff += xt_compat_target_offset(target);\n*size += off;\nret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\nif (ret)\ngoto release_target;\nfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h])\nnewinfo->underflow[h] = underflows[h];\n}\nmemset(&e->counters, 0, sizeof(e->counters));\ne->comefrom = 0;\nreturn 0;\nrelease_target:\nmodule_put(t->u.kernel.target->me);\nout:\nreturn ret;\n}\n",
      "code_before_change_raw": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\nstruct xt_table_info *newinfo,\nunsigned int *size,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nconst char *name)\n{\nstruct xt_entry_target *t;\nstruct xt_target *target;\nunsigned int entry_offset;\nint ret, off, h;\nduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\nif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n(unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\nreturn -EINVAL;\n}\nif (e->next_offset < sizeof(struct compat_arpt_entry) +\nsizeof(struct compat_xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!arp_checkentry(&e->arp))\nreturn -EINVAL;\nret = xt_compat_check_entry_offsets(e, e->target_offset,\ne->next_offset);\nif (ret)\nreturn ret;\noff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\nentry_offset = (void *)e - (void *)base;\nt = compat_arpt_get_target(e);\ntarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\nt->u.user.revision);\nif (IS_ERR(target)) {\nduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\nt->u.user.name);\nret = PTR_ERR(target);\ngoto out;\n}\nt->u.kernel.target = target;\noff += xt_compat_target_offset(target);\n*size += off;\nret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\nif (ret)\ngoto release_target;\nfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h])\nnewinfo->underflow[h] = underflows[h];\n}\nmemset(&e->counters, 0, sizeof(e->counters));\ne->comefrom = 0;\nreturn 0;\nrelease_target:\nmodule_put(t->u.kernel.target->me);\nout:\nreturn ret;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation and handling of offset values provided by in-container root access.",
        "trigger_condition": "A local user with in-container root access provides a crafted offset value that leads to crossing a ruleset blob boundary, causing an out-of-bounds read vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate and sanitize the offset value provided by the user, allowing it to cross a ruleset blob boundary and read sensitive kernel heap memory out-of-bounds."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the offset value provided by the user is properly validated and does not lead to out-of-bounds access. In this case, the solution involves modifying the call to xt_compat_check_entry_offsets by adding the parameter e->elems to provide the correct arguments and handle the offset value securely. This change ensures that the code properly checks and handles the offset value, preventing the out-of-bounds read vulnerability.",
      "GPT_analysis": "The modification is necessary to fix the vulnerability CVE-2016-4998 in the code snippet. The vulnerability allows local users to cause a denial of service or potentially obtain sensitive information from kernel heap memory by providing a crafted offset value that leads to crossing a ruleset blob boundary. \n\nThe modification involves changing the call to `xt_compat_check_entry_offsets` by adding the parameter `e->elems`. This change ensures that the function is provided with the correct arguments to prevent the out-of-bounds read vulnerability. By including `e->elems` in the function call, the code is updated to handle the offset value properly and prevent the security issue described in the vulnerability. \n\nTherefore, the modification is necessary to address the vulnerability and improve the security of the code.",
      "GPT_purpose": "This function checks the size and hooks of a compatibility entry in the netfilter subsystem of the Linux kernel.",
      "GPT_function": "\n1. Check compatibility entry size and hooks.\n2. Verify offsets and boundaries.\n3. Handle entry matches and targets.\n4. Check hooks and underflows.\n5. Clear counters and comefrom.",
      "CVE_id": "CVE-2016-4998",
      "code_before_change": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ipt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ip, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
      "code_after_change": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ipt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ip, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tret = xt_compat_check_entry_offsets(e, e->elems,"
        ],
        "deleted": [
          "\tret = xt_compat_check_entry_offsets(e,"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation and handling of offset values provided by in-container root access.",
      "trigger_condition": "A local user with in-container root access provides a crafted offset value that leads to crossing a ruleset blob boundary, causing an out-of-bounds read vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate and sanitize the offset value provided by the user, allowing it to cross a ruleset blob boundary and read sensitive kernel heap memory out-of-bounds.",
      "id": 85,
      "code_after_change_normalized": "static int\nFUN1(struct compat_ipt_entry *VAR1,\nstruct xt_table_info *VAR2,\nunsigned int *VAR3,\nconst unsigned char *VAR4,\nconst unsigned char *VAR5,\nconst unsigned int *VAR6,\nconst unsigned int *VAR7,\nconst char *VAR8)\n{\nstruct xt_entry_match *VAR9;\nstruct xt_entry_target *VAR10;\nstruct xt_target *VAR11;\nunsigned int VAR12;\nunsigned int VAR13;\nint VAR14, VAR15, VAR16;\nFUN2(\"STR\", VAR1);\nif ((unsigned long)VAR1 % FUN3(struct VAR17) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR17) >= VAR5 ||\n(unsigned char *)VAR1 + VAR1->VAR18 > VAR5) {\nFUN2(\"STR\", VAR1, VAR5);\nreturn -VAR19;\n}\nif (VAR1->VAR18 < sizeof(struct VAR17) +\nsizeof(struct VAR20)) {\nFUN2(\"STR\",\nVAR1, VAR1->VAR18);\nreturn -VAR19;\n}\nif (!FUN4(&VAR1->VAR21))\nreturn -VAR19;\nVAR14 = FUN5(VAR1, VAR1->VAR22,\nVAR1->VAR23, VAR1->VAR18);\nif (VAR14)\nreturn VAR14;\nVAR15 = sizeof(struct VAR24) - sizeof(struct VAR17);\nVAR12 = (void *)VAR1 - (void *)VAR4;\nVAR13 = 0;\nFUN6(VAR9, VAR1) {\nVAR14 = FUN7(VAR9, VAR8, &VAR1->VAR21, &VAR15);\nif (VAR14 != 0)\ngoto VAR25;\n++VAR13;\n}\nVAR10 = FUN8(VAR1);\nVAR11 = FUN9(VAR26, VAR10->VAR27.VAR28.VAR8,\nVAR10->VAR27.VAR28.VAR29);\nif (FUN10(VAR11)) {\nFUN2(\"STR\",\nVAR10->VAR27.VAR28.VAR8);\nVAR14 = FUN11(VAR11);\ngoto VAR25;\n}\nVAR10->VAR27.VAR30.VAR11 = VAR11;\nVAR15 += FUN12(VAR11);\n*VAR3 += VAR15;\nVAR14 = FUN13(VAR31, VAR12, VAR15);\nif (VAR14)\ngoto VAR32;\nfor (VAR16 = 0; VAR16 < VAR33; VAR16++) {\nif ((unsigned char *)VAR1 - VAR4 == VAR6[VAR16])\nVAR2->VAR34[VAR16] = VAR6[VAR16];\nif ((unsigned char *)VAR1 - VAR4 == VAR7[VAR16])\nVAR2->VAR35[VAR16] = VAR7[VAR16];\n}\nFUN14(&VAR1->VAR36, 0, sizeof(VAR1->VAR36));\nVAR1->VAR37 = 0;\nreturn 0;\nVAR32:\nFUN15(VAR10->VAR27.VAR30.VAR11->VAR38);\nVAR25:\nFUN6(VAR9, VAR1) {\nif (VAR13-- == 0)\nbreak;\nFUN15(VAR9->VAR27.VAR30.VAR39->VAR38);\n}\nreturn VAR14;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(struct compat_ipt_entry *VAR1,\nstruct xt_table_info *VAR2,\nunsigned int *VAR3,\nconst unsigned char *VAR4,\nconst unsigned char *VAR5,\nconst unsigned int *VAR6,\nconst unsigned int *VAR7,\nconst char *VAR8)\n{\nstruct xt_entry_match *VAR9;\nstruct xt_entry_target *VAR10;\nstruct xt_target *VAR11;\nunsigned int VAR12;\nunsigned int VAR13;\nint VAR14, VAR15, VAR16;\nFUN2(\"STR\", VAR1);\nif ((unsigned long)VAR1 % FUN3(struct VAR17) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR17) >= VAR5 ||\n(unsigned char *)VAR1 + VAR1->VAR18 > VAR5) {\nFUN2(\"STR\", VAR1, VAR5);\nreturn -VAR19;\n}\nif (VAR1->VAR18 < sizeof(struct VAR17) +\nsizeof(struct VAR20)) {\nFUN2(\"STR\",\nVAR1, VAR1->VAR18);\nreturn -VAR19;\n}\nif (!FUN4(&VAR1->VAR21))\nreturn -VAR19;\nVAR14 = FUN5(VAR1,\nVAR1->VAR22, VAR1->VAR18);\nif (VAR14)\nreturn VAR14;\nVAR15 = sizeof(struct VAR23) - sizeof(struct VAR17);\nVAR12 = (void *)VAR1 - (void *)VAR4;\nVAR13 = 0;\nFUN6(VAR9, VAR1) {\nVAR14 = FUN7(VAR9, VAR8, &VAR1->VAR21, &VAR15);\nif (VAR14 != 0)\ngoto VAR24;\n++VAR13;\n}\nVAR10 = FUN8(VAR1);\nVAR11 = FUN9(VAR25, VAR10->VAR26.VAR27.VAR8,\nVAR10->VAR26.VAR27.VAR28);\nif (FUN10(VAR11)) {\nFUN2(\"STR\",\nVAR10->VAR26.VAR27.VAR8);\nVAR14 = FUN11(VAR11);\ngoto VAR24;\n}\nVAR10->VAR26.VAR29.VAR11 = VAR11;\nVAR15 += FUN12(VAR11);\n*VAR3 += VAR15;\nVAR14 = FUN13(VAR30, VAR12, VAR15);\nif (VAR14)\ngoto VAR31;\nfor (VAR16 = 0; VAR16 < VAR32; VAR16++) {\nif ((unsigned char *)VAR1 - VAR4 == VAR6[VAR16])\nVAR2->VAR33[VAR16] = VAR6[VAR16];\nif ((unsigned char *)VAR1 - VAR4 == VAR7[VAR16])\nVAR2->VAR34[VAR16] = VAR7[VAR16];\n}\nFUN14(&VAR1->VAR35, 0, sizeof(VAR1->VAR35));\nVAR1->VAR36 = 0;\nreturn 0;\nVAR31:\nFUN15(VAR10->VAR26.VAR29.VAR11->VAR37);\nVAR24:\nFUN6(VAR9, VAR1) {\nif (VAR13-- == 0)\nbreak;\nFUN15(VAR9->VAR26.VAR29.VAR38->VAR37);\n}\nreturn VAR14;\n}\n",
      "code_after_change_raw": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\nstruct xt_table_info *newinfo,\nunsigned int *size,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nconst char *name)\n{\nstruct xt_entry_match *ematch;\nstruct xt_entry_target *t;\nstruct xt_target *target;\nunsigned int entry_offset;\nunsigned int j;\nint ret, off, h;\nduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\nif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n(unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\nreturn -EINVAL;\n}\nif (e->next_offset < sizeof(struct compat_ipt_entry) +\nsizeof(struct compat_xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!ip_checkentry(&e->ip))\nreturn -EINVAL;\nret = xt_compat_check_entry_offsets(e, e->elems,\ne->target_offset, e->next_offset);\nif (ret)\nreturn ret;\noff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\nentry_offset = (void *)e - (void *)base;\nj = 0;\nxt_ematch_foreach(ematch, e) {\nret = compat_find_calc_match(ematch, name, &e->ip, &off);\nif (ret != 0)\ngoto release_matches;\n++j;\n}\nt = compat_ipt_get_target(e);\ntarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\nt->u.user.revision);\nif (IS_ERR(target)) {\nduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\nt->u.user.name);\nret = PTR_ERR(target);\ngoto release_matches;\n}\nt->u.kernel.target = target;\noff += xt_compat_target_offset(target);\n*size += off;\nret = xt_compat_add_offset(AF_INET, entry_offset, off);\nif (ret)\ngoto out;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h])\nnewinfo->underflow[h] = underflows[h];\n}\nmemset(&e->counters, 0, sizeof(e->counters));\ne->comefrom = 0;\nreturn 0;\nout:\nmodule_put(t->u.kernel.target->me);\nrelease_matches:\nxt_ematch_foreach(ematch, e) {\nif (j-- == 0)\nbreak;\nmodule_put(ematch->u.kernel.match->me);\n}\nreturn ret;\n}\n",
      "code_before_change_raw": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\nstruct xt_table_info *newinfo,\nunsigned int *size,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nconst char *name)\n{\nstruct xt_entry_match *ematch;\nstruct xt_entry_target *t;\nstruct xt_target *target;\nunsigned int entry_offset;\nunsigned int j;\nint ret, off, h;\nduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\nif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n(unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\nreturn -EINVAL;\n}\nif (e->next_offset < sizeof(struct compat_ipt_entry) +\nsizeof(struct compat_xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!ip_checkentry(&e->ip))\nreturn -EINVAL;\nret = xt_compat_check_entry_offsets(e,\ne->target_offset, e->next_offset);\nif (ret)\nreturn ret;\noff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\nentry_offset = (void *)e - (void *)base;\nj = 0;\nxt_ematch_foreach(ematch, e) {\nret = compat_find_calc_match(ematch, name, &e->ip, &off);\nif (ret != 0)\ngoto release_matches;\n++j;\n}\nt = compat_ipt_get_target(e);\ntarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\nt->u.user.revision);\nif (IS_ERR(target)) {\nduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\nt->u.user.name);\nret = PTR_ERR(target);\ngoto release_matches;\n}\nt->u.kernel.target = target;\noff += xt_compat_target_offset(target);\n*size += off;\nret = xt_compat_add_offset(AF_INET, entry_offset, off);\nif (ret)\ngoto out;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h])\nnewinfo->underflow[h] = underflows[h];\n}\nmemset(&e->counters, 0, sizeof(e->counters));\ne->comefrom = 0;\nreturn 0;\nout:\nmodule_put(t->u.kernel.target->me);\nrelease_matches:\nxt_ematch_foreach(ematch, e) {\nif (j-- == 0)\nbreak;\nmodule_put(ematch->u.kernel.match->me);\n}\nreturn ret;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of offset values provided during a setsockopt operation, allowing for a potential out-of-bounds read.",
        "trigger_condition": "A local user with in-container root access provides a crafted offset value that leads to crossing a ruleset blob boundary during the setsockopt operation.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the offset values provided during the setsockopt operation, potentially allowing for an out-of-bounds read vulnerability if a crafted offset value is used to cross a ruleset blob boundary."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper validation of offset values provided during the setsockopt operation. Specifically, the code should be modified to call the function 'xt_check_entry_offsets' with additional parameters 'e->elems', 'e->target_offset', and 'e->next_offset'. This modification enhances the validation process and prevents the possibility of crossing a ruleset blob boundary, thereby addressing the out-of-bounds read vulnerability.",
      "GPT_analysis": "The modification is necessary to fix the vulnerability CVE-2016-4998, which involves a potential out-of-bounds read issue in the IPT_SO_SET_REPLACE setsockopt implementation in the netfilter subsystem of the Linux kernel. By modifying the code as shown, the function `xt_check_entry_offsets` is called with additional parameters `e->elems`, which helps ensure that the offsets are properly checked and prevent the possibility of crossing a ruleset blob boundary. This modification enhances the security of the code by addressing the vulnerability and preventing potential exploitation by malicious actors.",
      "GPT_purpose": "Check the entry size and hooks for a given ip6t_entry structure in the netfilter subsystem.",
      "GPT_function": "\n1. Check the entry size and hooks for a given ip6t_entry structure.\n2. Validate the offset values and ensure they do not exceed the limits.\n3. Verify the IPv6 entry and perform necessary checks.\n4. Check the entry offsets and return an error if needed.\n5. Verify hooks and underflows based on specified conditions.\n6. Clear counters and comefrom fields in the ip6t_entry structure.",
      "CVE_id": "CVE-2016-4998",
      "code_before_change": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
      "code_after_change": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,",
          "\t\t\t\t     e->next_offset);"
        ],
        "deleted": [
          "\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of offset values provided during a setsockopt operation, allowing for a potential out-of-bounds read.",
      "trigger_condition": "A local user with in-container root access provides a crafted offset value that leads to crossing a ruleset blob boundary during the setsockopt operation.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the offset values provided during the setsockopt operation, potentially allowing for an out-of-bounds read vulnerability if a crafted offset value is used to cross a ruleset blob boundary.",
      "id": 86,
      "code_after_change_normalized": "static int\nFUN1(struct ip6t_entry *VAR1,\nstruct xt_table_info *VAR2,\nconst unsigned char *VAR3,\nconst unsigned char *VAR4,\nconst unsigned int *VAR5,\nconst unsigned int *VAR6,\nunsigned int VAR7)\n{\nunsigned int VAR8;\nint VAR9;\nif ((unsigned long)VAR1 % FUN2(struct VAR10) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR10) >= VAR4 ||\n(unsigned char *)VAR1 + VAR1->VAR11 > VAR4) {\nFUN3(\"STR\", VAR1);\nreturn -VAR12;\n}\nif (VAR1->VAR11\n< sizeof(struct VAR10) + sizeof(struct VAR13)) {\nFUN3(\"STR\",\nVAR1, VAR1->VAR11);\nreturn -VAR12;\n}\nif (!FUN4(&VAR1->VAR14))\nreturn -VAR12;\nVAR9 = FUN5(VAR1, VAR1->VAR15, VAR1->VAR16,\nVAR1->VAR11);\nif (VAR9)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR17; VAR8++) {\nif (!(VAR7 & (1 << VAR8)))\ncontinue;\nif ((unsigned char *)VAR1 - VAR3 == VAR5[VAR8])\nVAR2->VAR18[VAR8] = VAR5[VAR8];\nif ((unsigned char *)VAR1 - VAR3 == VAR6[VAR8]) {\nif (!FUN6(VAR1)) {\nFUN7(\"STR\"\n\"STR\"\n\"STR\");\nreturn -VAR12;\n}\nVAR2->VAR19[VAR8] = VAR6[VAR8];\n}\n}\nVAR1->VAR20 = ((struct VAR21) { 0, 0 });\nVAR1->VAR22 = 0;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(struct ip6t_entry *VAR1,\nstruct xt_table_info *VAR2,\nconst unsigned char *VAR3,\nconst unsigned char *VAR4,\nconst unsigned int *VAR5,\nconst unsigned int *VAR6,\nunsigned int VAR7)\n{\nunsigned int VAR8;\nint VAR9;\nif ((unsigned long)VAR1 % FUN2(struct VAR10) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR10) >= VAR4 ||\n(unsigned char *)VAR1 + VAR1->VAR11 > VAR4) {\nFUN3(\"STR\", VAR1);\nreturn -VAR12;\n}\nif (VAR1->VAR11\n< sizeof(struct VAR10) + sizeof(struct VAR13)) {\nFUN3(\"STR\",\nVAR1, VAR1->VAR11);\nreturn -VAR12;\n}\nif (!FUN4(&VAR1->VAR14))\nreturn -VAR12;\nVAR9 = FUN5(VAR1, VAR1->VAR15, VAR1->VAR11);\nif (VAR9)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR16; VAR8++) {\nif (!(VAR7 & (1 << VAR8)))\ncontinue;\nif ((unsigned char *)VAR1 - VAR3 == VAR5[VAR8])\nVAR2->VAR17[VAR8] = VAR5[VAR8];\nif ((unsigned char *)VAR1 - VAR3 == VAR6[VAR8]) {\nif (!FUN6(VAR1)) {\nFUN7(\"STR\"\n\"STR\"\n\"STR\");\nreturn -VAR12;\n}\nVAR2->VAR18[VAR8] = VAR6[VAR8];\n}\n}\nVAR1->VAR19 = ((struct VAR20) { 0, 0 });\nVAR1->VAR21 = 0;\nreturn 0;\n}\n",
      "code_after_change_raw": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\nstruct xt_table_info *newinfo,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nunsigned int valid_hooks)\n{\nunsigned int h;\nint err;\nif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n(unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p\\n\", e);\nreturn -EINVAL;\n}\nif (e->next_offset\n< sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!ip6_checkentry(&e->ipv6))\nreturn -EINVAL;\nerr = xt_check_entry_offsets(e, e->elems, e->target_offset,\ne->next_offset);\nif (err)\nreturn err;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif (!(valid_hooks & (1 << h)))\ncontinue;\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h]) {\nif (!check_underflow(e)) {\npr_debug(\"Underflows must be unconditional and \"\n\"use the STANDARD target with \"\n\"ACCEPT/DROP\\n\");\nreturn -EINVAL;\n}\nnewinfo->underflow[h] = underflows[h];\n}\n}\ne->counters = ((struct xt_counters) { 0, 0 });\ne->comefrom = 0;\nreturn 0;\n}\n",
      "code_before_change_raw": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\nstruct xt_table_info *newinfo,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nunsigned int valid_hooks)\n{\nunsigned int h;\nint err;\nif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n(unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p\\n\", e);\nreturn -EINVAL;\n}\nif (e->next_offset\n< sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!ip6_checkentry(&e->ipv6))\nreturn -EINVAL;\nerr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\nif (err)\nreturn err;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif (!(valid_hooks & (1 << h)))\ncontinue;\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h]) {\nif (!check_underflow(e)) {\npr_debug(\"Underflows must be unconditional and \"\n\"use the STANDARD target with \"\n\"ACCEPT/DROP\\n\");\nreturn -EINVAL;\n}\nnewinfo->underflow[h] = underflows[h];\n}\n}\ne->counters = ((struct xt_counters) { 0, 0 });\ne->comefrom = 0;\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of offset values provided by in-container root access during setsockopt operation.",
        "trigger_condition": "A local user with in-container root access provides a crafted offset value that leads to crossing a ruleset blob boundary during setsockopt operation.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the offset values provided during setsockopt operation, allowing a local user to cause an out-of-bounds read or obtain sensitive information from kernel heap memory.",
        "specific_solution": "To mitigate the vulnerability, it is necessary to ensure that the offset values provided during setsockopt operation are properly validated to prevent crossing a ruleset blob boundary. In this case, the solution involves modifying the call to xt_compat_check_entry_offsets by adding the e->elems parameter to provide the correct information about the entry elements, thereby enhancing the security of the code and preventing the described exploit."
      },
      "GPT_analysis": "The modification is necessary to fix the vulnerability CVE-2016-4998 in the code snippet. The vulnerability allows local users to cause a denial of service (out-of-bounds read) or possibly obtain sensitive information from kernel heap memory by leveraging in-container root access to provide a crafted offset value that leads to crossing a ruleset blob boundary.\n\nThe modification involves changing the call to `xt_compat_check_entry_offsets` by adding the `e->elems` parameter. This change ensures that the function is provided with the correct information about the entry elements, which helps prevent the vulnerability related to crossing a ruleset blob boundary. By passing the correct parameters to the function, the code is made more secure and less susceptible to the described exploit.",
      "GPT_purpose": "Check the compatibility of an entry size and hooks in the netfilter subsystem.",
      "GPT_function": "\n1. Check compatibility entry size and hooks.\n2. Verify entry offsets and target.\n3. Add offset and handle hooks and underflows.",
      "CVE_id": "CVE-2016-4998",
      "code_before_change": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ip6t_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
      "code_after_change": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ip6t_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tret = xt_compat_check_entry_offsets(e, e->elems,"
        ],
        "deleted": [
          "\tret = xt_compat_check_entry_offsets(e,"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of offset values provided by in-container root access during setsockopt operation.",
      "trigger_condition": "A local user with in-container root access provides a crafted offset value that leads to crossing a ruleset blob boundary during setsockopt operation.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the offset values provided during setsockopt operation, allowing a local user to cause an out-of-bounds read or obtain sensitive information from kernel heap memory.",
      "id": 87,
      "code_after_change_normalized": "static int\nFUN1(struct compat_ip6t_entry *VAR1,\nstruct xt_table_info *VAR2,\nunsigned int *VAR3,\nconst unsigned char *VAR4,\nconst unsigned char *VAR5,\nconst unsigned int *VAR6,\nconst unsigned int *VAR7,\nconst char *VAR8)\n{\nstruct xt_entry_match *VAR9;\nstruct xt_entry_target *VAR10;\nstruct xt_target *VAR11;\nunsigned int VAR12;\nunsigned int VAR13;\nint VAR14, VAR15, VAR16;\nFUN2(\"STR\", VAR1);\nif ((unsigned long)VAR1 % FUN3(struct VAR17) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR17) >= VAR5 ||\n(unsigned char *)VAR1 + VAR1->VAR18 > VAR5) {\nFUN2(\"STR\", VAR1, VAR5);\nreturn -VAR19;\n}\nif (VAR1->VAR18 < sizeof(struct VAR17) +\nsizeof(struct VAR20)) {\nFUN2(\"STR\",\nVAR1, VAR1->VAR18);\nreturn -VAR19;\n}\nif (!FUN4(&VAR1->VAR21))\nreturn -VAR19;\nVAR14 = FUN5(VAR1, VAR1->VAR22,\nVAR1->VAR23, VAR1->VAR18);\nif (VAR14)\nreturn VAR14;\nVAR15 = sizeof(struct VAR24) - sizeof(struct VAR17);\nVAR12 = (void *)VAR1 - (void *)VAR4;\nVAR13 = 0;\nFUN6(VAR9, VAR1) {\nVAR14 = FUN7(VAR9, VAR8, &VAR1->VAR21, &VAR15);\nif (VAR14 != 0)\ngoto VAR25;\n++VAR13;\n}\nVAR10 = FUN8(VAR1);\nVAR11 = FUN9(VAR26, VAR10->VAR27.VAR28.VAR8,\nVAR10->VAR27.VAR28.VAR29);\nif (FUN10(VAR11)) {\nFUN2(\"STR\",\nVAR10->VAR27.VAR28.VAR8);\nVAR14 = FUN11(VAR11);\ngoto VAR25;\n}\nVAR10->VAR27.VAR30.VAR11 = VAR11;\nVAR15 += FUN12(VAR11);\n*VAR3 += VAR15;\nVAR14 = FUN13(VAR31, VAR12, VAR15);\nif (VAR14)\ngoto VAR32;\nfor (VAR16 = 0; VAR16 < VAR33; VAR16++) {\nif ((unsigned char *)VAR1 - VAR4 == VAR6[VAR16])\nVAR2->VAR34[VAR16] = VAR6[VAR16];\nif ((unsigned char *)VAR1 - VAR4 == VAR7[VAR16])\nVAR2->VAR35[VAR16] = VAR7[VAR16];\n}\nFUN14(&VAR1->VAR36, 0, sizeof(VAR1->VAR36));\nVAR1->VAR37 = 0;\nreturn 0;\nVAR32:\nFUN15(VAR10->VAR27.VAR30.VAR11->VAR38);\nVAR25:\nFUN6(VAR9, VAR1) {\nif (VAR13-- == 0)\nbreak;\nFUN15(VAR9->VAR27.VAR30.VAR39->VAR38);\n}\nreturn VAR14;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(struct compat_ip6t_entry *VAR1,\nstruct xt_table_info *VAR2,\nunsigned int *VAR3,\nconst unsigned char *VAR4,\nconst unsigned char *VAR5,\nconst unsigned int *VAR6,\nconst unsigned int *VAR7,\nconst char *VAR8)\n{\nstruct xt_entry_match *VAR9;\nstruct xt_entry_target *VAR10;\nstruct xt_target *VAR11;\nunsigned int VAR12;\nunsigned int VAR13;\nint VAR14, VAR15, VAR16;\nFUN2(\"STR\", VAR1);\nif ((unsigned long)VAR1 % FUN3(struct VAR17) != 0 ||\n(unsigned char *)VAR1 + sizeof(struct VAR17) >= VAR5 ||\n(unsigned char *)VAR1 + VAR1->VAR18 > VAR5) {\nFUN2(\"STR\", VAR1, VAR5);\nreturn -VAR19;\n}\nif (VAR1->VAR18 < sizeof(struct VAR17) +\nsizeof(struct VAR20)) {\nFUN2(\"STR\",\nVAR1, VAR1->VAR18);\nreturn -VAR19;\n}\nif (!FUN4(&VAR1->VAR21))\nreturn -VAR19;\nVAR14 = FUN5(VAR1,\nVAR1->VAR22, VAR1->VAR18);\nif (VAR14)\nreturn VAR14;\nVAR15 = sizeof(struct VAR23) - sizeof(struct VAR17);\nVAR12 = (void *)VAR1 - (void *)VAR4;\nVAR13 = 0;\nFUN6(VAR9, VAR1) {\nVAR14 = FUN7(VAR9, VAR8, &VAR1->VAR21, &VAR15);\nif (VAR14 != 0)\ngoto VAR24;\n++VAR13;\n}\nVAR10 = FUN8(VAR1);\nVAR11 = FUN9(VAR25, VAR10->VAR26.VAR27.VAR8,\nVAR10->VAR26.VAR27.VAR28);\nif (FUN10(VAR11)) {\nFUN2(\"STR\",\nVAR10->VAR26.VAR27.VAR8);\nVAR14 = FUN11(VAR11);\ngoto VAR24;\n}\nVAR10->VAR26.VAR29.VAR11 = VAR11;\nVAR15 += FUN12(VAR11);\n*VAR3 += VAR15;\nVAR14 = FUN13(VAR30, VAR12, VAR15);\nif (VAR14)\ngoto VAR31;\nfor (VAR16 = 0; VAR16 < VAR32; VAR16++) {\nif ((unsigned char *)VAR1 - VAR4 == VAR6[VAR16])\nVAR2->VAR33[VAR16] = VAR6[VAR16];\nif ((unsigned char *)VAR1 - VAR4 == VAR7[VAR16])\nVAR2->VAR34[VAR16] = VAR7[VAR16];\n}\nFUN14(&VAR1->VAR35, 0, sizeof(VAR1->VAR35));\nVAR1->VAR36 = 0;\nreturn 0;\nVAR31:\nFUN15(VAR10->VAR26.VAR29.VAR11->VAR37);\nVAR24:\nFUN6(VAR9, VAR1) {\nif (VAR13-- == 0)\nbreak;\nFUN15(VAR9->VAR26.VAR29.VAR38->VAR37);\n}\nreturn VAR14;\n}\n",
      "code_after_change_raw": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\nstruct xt_table_info *newinfo,\nunsigned int *size,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nconst char *name)\n{\nstruct xt_entry_match *ematch;\nstruct xt_entry_target *t;\nstruct xt_target *target;\nunsigned int entry_offset;\nunsigned int j;\nint ret, off, h;\nduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\nif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n(unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\nreturn -EINVAL;\n}\nif (e->next_offset < sizeof(struct compat_ip6t_entry) +\nsizeof(struct compat_xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!ip6_checkentry(&e->ipv6))\nreturn -EINVAL;\nret = xt_compat_check_entry_offsets(e, e->elems,\ne->target_offset, e->next_offset);\nif (ret)\nreturn ret;\noff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\nentry_offset = (void *)e - (void *)base;\nj = 0;\nxt_ematch_foreach(ematch, e) {\nret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\nif (ret != 0)\ngoto release_matches;\n++j;\n}\nt = compat_ip6t_get_target(e);\ntarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\nt->u.user.revision);\nif (IS_ERR(target)) {\nduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\nt->u.user.name);\nret = PTR_ERR(target);\ngoto release_matches;\n}\nt->u.kernel.target = target;\noff += xt_compat_target_offset(target);\n*size += off;\nret = xt_compat_add_offset(AF_INET6, entry_offset, off);\nif (ret)\ngoto out;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h])\nnewinfo->underflow[h] = underflows[h];\n}\nmemset(&e->counters, 0, sizeof(e->counters));\ne->comefrom = 0;\nreturn 0;\nout:\nmodule_put(t->u.kernel.target->me);\nrelease_matches:\nxt_ematch_foreach(ematch, e) {\nif (j-- == 0)\nbreak;\nmodule_put(ematch->u.kernel.match->me);\n}\nreturn ret;\n}\n",
      "code_before_change_raw": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\nstruct xt_table_info *newinfo,\nunsigned int *size,\nconst unsigned char *base,\nconst unsigned char *limit,\nconst unsigned int *hook_entries,\nconst unsigned int *underflows,\nconst char *name)\n{\nstruct xt_entry_match *ematch;\nstruct xt_entry_target *t;\nstruct xt_target *target;\nunsigned int entry_offset;\nunsigned int j;\nint ret, off, h;\nduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\nif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n(unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n(unsigned char *)e + e->next_offset > limit) {\nduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\nreturn -EINVAL;\n}\nif (e->next_offset < sizeof(struct compat_ip6t_entry) +\nsizeof(struct compat_xt_entry_target)) {\nduprintf(\"checking: element %p size %u\\n\",\ne, e->next_offset);\nreturn -EINVAL;\n}\nif (!ip6_checkentry(&e->ipv6))\nreturn -EINVAL;\nret = xt_compat_check_entry_offsets(e,\ne->target_offset, e->next_offset);\nif (ret)\nreturn ret;\noff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\nentry_offset = (void *)e - (void *)base;\nj = 0;\nxt_ematch_foreach(ematch, e) {\nret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\nif (ret != 0)\ngoto release_matches;\n++j;\n}\nt = compat_ip6t_get_target(e);\ntarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\nt->u.user.revision);\nif (IS_ERR(target)) {\nduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\nt->u.user.name);\nret = PTR_ERR(target);\ngoto release_matches;\n}\nt->u.kernel.target = target;\noff += xt_compat_target_offset(target);\n*size += off;\nret = xt_compat_add_offset(AF_INET6, entry_offset, off);\nif (ret)\ngoto out;\nfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\nif ((unsigned char *)e - base == hook_entries[h])\nnewinfo->hook_entry[h] = hook_entries[h];\nif ((unsigned char *)e - base == underflows[h])\nnewinfo->underflow[h] = underflows[h];\n}\nmemset(&e->counters, 0, sizeof(e->counters));\ne->comefrom = 0;\nreturn 0;\nout:\nmodule_put(t->u.kernel.target->me);\nrelease_matches:\nxt_ematch_foreach(ematch, e) {\nif (j-- == 0)\nbreak;\nmodule_put(ematch->u.kernel.match->me);\n}\nreturn ret;\n}\n"
    }
  ],
  "CVE-2016-5400": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper memory cleanup and resource release during device initialization process.",
        "trigger_condition": "Crafted USB device emulates multiple VFL_TYPE_SDR or VFL_TYPE_SUBDEV devices and performs numerous connect and disconnect operations, leading to memory leak vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code allocates memory for a data structure but does not release it properly in case of failure during device initialization. This can result in memory leaks and denial of service due to excessive memory consumption."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add error handling code to release allocated resources and free memory in case of failure during device initialization. Specifically, the solution involves freeing controls, unregistering the v4l2 device, and releasing memory allocated for the data structure before returning from the function in case of an error. This ensures that resources are cleaned up correctly and prevents memory leaks and denial of service issues caused by excessive memory consumption.",
      "GPT_analysis": "The modification is necessary to address a memory leak vulnerability (CVE-2016-5400) in the `airspy_probe` function of the Linux kernel's airspy USB driver. The vulnerability allows local users to cause a denial of service (memory consumption) by exploiting a crafted USB device that emulates many VFL_TYPE_SDR or VFL_TYPE_SUBDEV devices and performs many connect and disconnect operations.\n\nThe modification involves adding error handling code to properly release resources and free memory in case of failure during device initialization. Specifically, the added code ensures that controls are properly freed, the v4l2 device is unregistered, and memory allocated for the `struct airspy` is released before returning from the function in case of an error.\n\nBy adding the error handling code, the modified function ensures that resources are cleaned up correctly, preventing memory leaks and potential denial of service issues caused by excessive memory consumption when the device initialization fails.",
      "GPT_purpose": "The function airspy_probe is responsible for initializing an Airspy USB device, detecting the device, setting up video buffer queues, registering video and control devices, and handling potential errors during the process.",
      "GPT_function": "\n1. Allocate memory for the airspy structure and initialize various fields.\n2. Detect the device and retrieve board ID and firmware version information.\n3. Initialize videobuf2 queue structure and video_device structure.\n4. Register v4l2_device structure and controls.\n5. Register the video device and handle potential errors by freeing memory and unregistering devices.",
      "CVE_id": "CVE-2016-5400",
      "code_before_change": "static int airspy_probe(struct usb_interface *intf,\n\t\tconst struct usb_device_id *id)\n{\n\tstruct airspy *s;\n\tint ret;\n\tu8 u8tmp, buf[BUF_SIZE];\n\n\ts = kzalloc(sizeof(struct airspy), GFP_KERNEL);\n\tif (s == NULL) {\n\t\tdev_err(&intf->dev, \"Could not allocate memory for state\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmutex_init(&s->v4l2_lock);\n\tmutex_init(&s->vb_queue_lock);\n\tspin_lock_init(&s->queued_bufs_lock);\n\tINIT_LIST_HEAD(&s->queued_bufs);\n\ts->dev = &intf->dev;\n\ts->udev = interface_to_usbdev(intf);\n\ts->f_adc = bands[0].rangelow;\n\ts->f_rf = bands_rf[0].rangelow;\n\ts->pixelformat = formats[0].pixelformat;\n\ts->buffersize = formats[0].buffersize;\n\n\t/* Detect device */\n\tret = airspy_ctrl_msg(s, CMD_BOARD_ID_READ, 0, 0, &u8tmp, 1);\n\tif (ret == 0)\n\t\tret = airspy_ctrl_msg(s, CMD_VERSION_STRING_READ, 0, 0,\n\t\t\t\tbuf, BUF_SIZE);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Could not detect board\\n\");\n\t\tgoto err_free_mem;\n\t}\n\n\tbuf[BUF_SIZE - 1] = '\\0';\n\n\tdev_info(s->dev, \"Board ID: %02x\\n\", u8tmp);\n\tdev_info(s->dev, \"Firmware version: %s\\n\", buf);\n\n\t/* Init videobuf2 queue structure */\n\ts->vb_queue.type = V4L2_BUF_TYPE_SDR_CAPTURE;\n\ts->vb_queue.io_modes = VB2_MMAP | VB2_USERPTR | VB2_READ;\n\ts->vb_queue.drv_priv = s;\n\ts->vb_queue.buf_struct_size = sizeof(struct airspy_frame_buf);\n\ts->vb_queue.ops = &airspy_vb2_ops;\n\ts->vb_queue.mem_ops = &vb2_vmalloc_memops;\n\ts->vb_queue.timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;\n\tret = vb2_queue_init(&s->vb_queue);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Could not initialize vb2 queue\\n\");\n\t\tgoto err_free_mem;\n\t}\n\n\t/* Init video_device structure */\n\ts->vdev = airspy_template;\n\ts->vdev.queue = &s->vb_queue;\n\ts->vdev.queue->lock = &s->vb_queue_lock;\n\tvideo_set_drvdata(&s->vdev, s);\n\n\t/* Register the v4l2_device structure */\n\ts->v4l2_dev.release = airspy_video_release;\n\tret = v4l2_device_register(&intf->dev, &s->v4l2_dev);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Failed to register v4l2-device (%d)\\n\", ret);\n\t\tgoto err_free_mem;\n\t}\n\n\t/* Register controls */\n\tv4l2_ctrl_handler_init(&s->hdl, 5);\n\ts->lna_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_LNA_GAIN_AUTO, 0, 1, 1, 0);\n\ts->lna_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_LNA_GAIN, 0, 14, 1, 8);\n\tv4l2_ctrl_auto_cluster(2, &s->lna_gain_auto, 0, false);\n\ts->mixer_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_MIXER_GAIN_AUTO, 0, 1, 1, 0);\n\ts->mixer_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_MIXER_GAIN, 0, 15, 1, 8);\n\tv4l2_ctrl_auto_cluster(2, &s->mixer_gain_auto, 0, false);\n\ts->if_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_IF_GAIN, 0, 15, 1, 0);\n\tif (s->hdl.error) {\n\t\tret = s->hdl.error;\n\t\tdev_err(s->dev, \"Could not initialize controls\\n\");\n\t\tgoto err_free_controls;\n\t}\n\n\tv4l2_ctrl_handler_setup(&s->hdl);\n\n\ts->v4l2_dev.ctrl_handler = &s->hdl;\n\ts->vdev.v4l2_dev = &s->v4l2_dev;\n\ts->vdev.lock = &s->v4l2_lock;\n\n\tret = video_register_device(&s->vdev, VFL_TYPE_SDR, -1);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Failed to register as video device (%d)\\n\",\n\t\t\t\tret);\n\t\tgoto err_unregister_v4l2_dev;\n\t}\n\tdev_info(s->dev, \"Registered as %s\\n\",\n\t\t\tvideo_device_node_name(&s->vdev));\n\tdev_notice(s->dev, \"SDR API is still slightly experimental and functionality changes may follow\\n\");\n\treturn 0;\n\nerr_free_controls:\n\tv4l2_ctrl_handler_free(&s->hdl);\nerr_unregister_v4l2_dev:\n\tv4l2_device_unregister(&s->v4l2_dev);\nerr_free_mem:\n\tkfree(s);\n\treturn ret;\n}",
      "code_after_change": "static int airspy_probe(struct usb_interface *intf,\n\t\tconst struct usb_device_id *id)\n{\n\tstruct airspy *s;\n\tint ret;\n\tu8 u8tmp, buf[BUF_SIZE];\n\n\ts = kzalloc(sizeof(struct airspy), GFP_KERNEL);\n\tif (s == NULL) {\n\t\tdev_err(&intf->dev, \"Could not allocate memory for state\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmutex_init(&s->v4l2_lock);\n\tmutex_init(&s->vb_queue_lock);\n\tspin_lock_init(&s->queued_bufs_lock);\n\tINIT_LIST_HEAD(&s->queued_bufs);\n\ts->dev = &intf->dev;\n\ts->udev = interface_to_usbdev(intf);\n\ts->f_adc = bands[0].rangelow;\n\ts->f_rf = bands_rf[0].rangelow;\n\ts->pixelformat = formats[0].pixelformat;\n\ts->buffersize = formats[0].buffersize;\n\n\t/* Detect device */\n\tret = airspy_ctrl_msg(s, CMD_BOARD_ID_READ, 0, 0, &u8tmp, 1);\n\tif (ret == 0)\n\t\tret = airspy_ctrl_msg(s, CMD_VERSION_STRING_READ, 0, 0,\n\t\t\t\tbuf, BUF_SIZE);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Could not detect board\\n\");\n\t\tgoto err_free_mem;\n\t}\n\n\tbuf[BUF_SIZE - 1] = '\\0';\n\n\tdev_info(s->dev, \"Board ID: %02x\\n\", u8tmp);\n\tdev_info(s->dev, \"Firmware version: %s\\n\", buf);\n\n\t/* Init videobuf2 queue structure */\n\ts->vb_queue.type = V4L2_BUF_TYPE_SDR_CAPTURE;\n\ts->vb_queue.io_modes = VB2_MMAP | VB2_USERPTR | VB2_READ;\n\ts->vb_queue.drv_priv = s;\n\ts->vb_queue.buf_struct_size = sizeof(struct airspy_frame_buf);\n\ts->vb_queue.ops = &airspy_vb2_ops;\n\ts->vb_queue.mem_ops = &vb2_vmalloc_memops;\n\ts->vb_queue.timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;\n\tret = vb2_queue_init(&s->vb_queue);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Could not initialize vb2 queue\\n\");\n\t\tgoto err_free_mem;\n\t}\n\n\t/* Init video_device structure */\n\ts->vdev = airspy_template;\n\ts->vdev.queue = &s->vb_queue;\n\ts->vdev.queue->lock = &s->vb_queue_lock;\n\tvideo_set_drvdata(&s->vdev, s);\n\n\t/* Register the v4l2_device structure */\n\ts->v4l2_dev.release = airspy_video_release;\n\tret = v4l2_device_register(&intf->dev, &s->v4l2_dev);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Failed to register v4l2-device (%d)\\n\", ret);\n\t\tgoto err_free_mem;\n\t}\n\n\t/* Register controls */\n\tv4l2_ctrl_handler_init(&s->hdl, 5);\n\ts->lna_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_LNA_GAIN_AUTO, 0, 1, 1, 0);\n\ts->lna_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_LNA_GAIN, 0, 14, 1, 8);\n\tv4l2_ctrl_auto_cluster(2, &s->lna_gain_auto, 0, false);\n\ts->mixer_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_MIXER_GAIN_AUTO, 0, 1, 1, 0);\n\ts->mixer_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_MIXER_GAIN, 0, 15, 1, 8);\n\tv4l2_ctrl_auto_cluster(2, &s->mixer_gain_auto, 0, false);\n\ts->if_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\n\t\t\tV4L2_CID_RF_TUNER_IF_GAIN, 0, 15, 1, 0);\n\tif (s->hdl.error) {\n\t\tret = s->hdl.error;\n\t\tdev_err(s->dev, \"Could not initialize controls\\n\");\n\t\tgoto err_free_controls;\n\t}\n\n\tv4l2_ctrl_handler_setup(&s->hdl);\n\n\ts->v4l2_dev.ctrl_handler = &s->hdl;\n\ts->vdev.v4l2_dev = &s->v4l2_dev;\n\ts->vdev.lock = &s->v4l2_lock;\n\n\tret = video_register_device(&s->vdev, VFL_TYPE_SDR, -1);\n\tif (ret) {\n\t\tdev_err(s->dev, \"Failed to register as video device (%d)\\n\",\n\t\t\t\tret);\n\t\tgoto err_free_controls;\n\t}\n\tdev_info(s->dev, \"Registered as %s\\n\",\n\t\t\tvideo_device_node_name(&s->vdev));\n\tdev_notice(s->dev, \"SDR API is still slightly experimental and functionality changes may follow\\n\");\n\treturn 0;\n\nerr_free_controls:\n\tv4l2_ctrl_handler_free(&s->hdl);\n\tv4l2_device_unregister(&s->v4l2_dev);\nerr_free_mem:\n\tkfree(s);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\t\tgoto err_free_controls;"
        ],
        "deleted": [
          "\t\tgoto err_unregister_v4l2_dev;",
          "err_unregister_v4l2_dev:"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper memory cleanup and resource release during device initialization process.",
      "trigger_condition": "Crafted USB device emulates multiple VFL_TYPE_SDR or VFL_TYPE_SUBDEV devices and performs numerous connect and disconnect operations, leading to memory leak vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code allocates memory for a data structure but does not release it properly in case of failure during device initialization. This can result in memory leaks and denial of service due to excessive memory consumption.",
      "id": 88,
      "code_after_change_normalized": "static int FUN1(struct usb_interface *VAR1,\nconst struct usb_device_id *VAR2)\n{\nstruct airspy *VAR3;\nint VAR4;\nu8 VAR5, VAR6[VAR7];\nVAR3 = FUN2(sizeof(struct VAR8), VAR9);\nif (VAR3 == NULL) {\nFUN3(&VAR1->VAR10, \"STR\");\nreturn -VAR11;\n}\nFUN4(&VAR3->VAR12);\nFUN4(&VAR3->VAR13);\nFUN5(&VAR3->VAR14);\nFUN6(&VAR3->VAR15);\nVAR3->VAR10 = &VAR1->VAR10;\nVAR3->VAR16 = FUN7(VAR1);\nVAR3->VAR17 = VAR18[0].VAR19;\nVAR3->VAR20 = VAR21[0].VAR19;\nVAR3->VAR22 = VAR23[0].VAR22;\nVAR3->VAR24 = VAR23[0].VAR24;\nVAR4 = FUN8(VAR3, VAR25, 0, 0, &VAR5, 1);\nif (VAR4 == 0)\nVAR4 = FUN8(VAR3, VAR26, 0, 0,\nVAR6, VAR7);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\");\ngoto VAR27;\n}\nVAR6[VAR7 - 1] = ;\nFUN9(VAR3->VAR10, \"STR\", VAR5);\nFUN9(VAR3->VAR10, \"STR\", VAR6);\nVAR3->VAR28.VAR29 = VAR30;\nVAR3->VAR28.VAR31 = VAR32 | VAR33 | VAR34;\nVAR3->VAR28.VAR35 = VAR3;\nVAR3->VAR28.VAR36 = sizeof(struct VAR37);\nVAR3->VAR28.VAR38 = &VAR39;\nVAR3->VAR28.VAR40 = &VAR41;\nVAR3->VAR28.VAR42 = VAR43;\nVAR4 = FUN10(&VAR3->VAR28);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\");\ngoto VAR27;\n}\nVAR3->VAR44 = VAR45;\nVAR3->VAR44.VAR46 = &VAR3->VAR28;\nVAR3->VAR44.VAR46->VAR47 = &VAR3->VAR13;\nFUN11(&VAR3->VAR44, VAR3);\nVAR3->VAR48.VAR49 = VAR50;\nVAR4 = FUN12(&VAR1->VAR10, &VAR3->VAR48);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\", VAR4);\ngoto VAR27;\n}\nFUN13(&VAR3->VAR51, 5);\nVAR3->VAR52 = FUN14(&VAR3->VAR51, &VAR53,\nVAR54, 0, 1, 1, 0);\nVAR3->VAR55 = FUN14(&VAR3->VAR51, &VAR53,\nVAR56, 0, 14, 1, 8);\nFUN15(2, &VAR3->VAR52, 0, false);\nVAR3->VAR57 = FUN14(&VAR3->VAR51, &VAR53,\nVAR58, 0, 1, 1, 0);\nVAR3->VAR59 = FUN14(&VAR3->VAR51, &VAR53,\nVAR60, 0, 15, 1, 8);\nFUN15(2, &VAR3->VAR57, 0, false);\nVAR3->VAR61 = FUN14(&VAR3->VAR51, &VAR53,\nVAR62, 0, 15, 1, 0);\nif (VAR3->VAR51.VAR63) {\nVAR4 = VAR3->VAR51.VAR63;\nFUN3(VAR3->VAR10, \"STR\");\ngoto VAR64;\n}\nFUN16(&VAR3->VAR51);\nVAR3->VAR48.VAR65 = &VAR3->VAR51;\nVAR3->VAR44.VAR48 = &VAR3->VAR48;\nVAR3->VAR44.VAR47 = &VAR3->VAR12;\nVAR4 = FUN17(&VAR3->VAR44, VAR66, -1);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\",\nVAR4);\ngoto VAR64;\n}\nFUN9(VAR3->VAR10, \"STR\",\nFUN18(&VAR3->VAR44));\nFUN19(VAR3->VAR10, \"STR\");\nreturn 0;\nVAR64:\nFUN20(&VAR3->VAR51);\nFUN21(&VAR3->VAR48);\nVAR27:\nFUN22(VAR3);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct usb_interface *VAR1,\nconst struct usb_device_id *VAR2)\n{\nstruct airspy *VAR3;\nint VAR4;\nu8 VAR5, VAR6[VAR7];\nVAR3 = FUN2(sizeof(struct VAR8), VAR9);\nif (VAR3 == NULL) {\nFUN3(&VAR1->VAR10, \"STR\");\nreturn -VAR11;\n}\nFUN4(&VAR3->VAR12);\nFUN4(&VAR3->VAR13);\nFUN5(&VAR3->VAR14);\nFUN6(&VAR3->VAR15);\nVAR3->VAR10 = &VAR1->VAR10;\nVAR3->VAR16 = FUN7(VAR1);\nVAR3->VAR17 = VAR18[0].VAR19;\nVAR3->VAR20 = VAR21[0].VAR19;\nVAR3->VAR22 = VAR23[0].VAR22;\nVAR3->VAR24 = VAR23[0].VAR24;\nVAR4 = FUN8(VAR3, VAR25, 0, 0, &VAR5, 1);\nif (VAR4 == 0)\nVAR4 = FUN8(VAR3, VAR26, 0, 0,\nVAR6, VAR7);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\");\ngoto VAR27;\n}\nVAR6[VAR7 - 1] = ;\nFUN9(VAR3->VAR10, \"STR\", VAR5);\nFUN9(VAR3->VAR10, \"STR\", VAR6);\nVAR3->VAR28.VAR29 = VAR30;\nVAR3->VAR28.VAR31 = VAR32 | VAR33 | VAR34;\nVAR3->VAR28.VAR35 = VAR3;\nVAR3->VAR28.VAR36 = sizeof(struct VAR37);\nVAR3->VAR28.VAR38 = &VAR39;\nVAR3->VAR28.VAR40 = &VAR41;\nVAR3->VAR28.VAR42 = VAR43;\nVAR4 = FUN10(&VAR3->VAR28);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\");\ngoto VAR27;\n}\nVAR3->VAR44 = VAR45;\nVAR3->VAR44.VAR46 = &VAR3->VAR28;\nVAR3->VAR44.VAR46->VAR47 = &VAR3->VAR13;\nFUN11(&VAR3->VAR44, VAR3);\nVAR3->VAR48.VAR49 = VAR50;\nVAR4 = FUN12(&VAR1->VAR10, &VAR3->VAR48);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\", VAR4);\ngoto VAR27;\n}\nFUN13(&VAR3->VAR51, 5);\nVAR3->VAR52 = FUN14(&VAR3->VAR51, &VAR53,\nVAR54, 0, 1, 1, 0);\nVAR3->VAR55 = FUN14(&VAR3->VAR51, &VAR53,\nVAR56, 0, 14, 1, 8);\nFUN15(2, &VAR3->VAR52, 0, false);\nVAR3->VAR57 = FUN14(&VAR3->VAR51, &VAR53,\nVAR58, 0, 1, 1, 0);\nVAR3->VAR59 = FUN14(&VAR3->VAR51, &VAR53,\nVAR60, 0, 15, 1, 8);\nFUN15(2, &VAR3->VAR57, 0, false);\nVAR3->VAR61 = FUN14(&VAR3->VAR51, &VAR53,\nVAR62, 0, 15, 1, 0);\nif (VAR3->VAR51.VAR63) {\nVAR4 = VAR3->VAR51.VAR63;\nFUN3(VAR3->VAR10, \"STR\");\ngoto VAR64;\n}\nFUN16(&VAR3->VAR51);\nVAR3->VAR48.VAR65 = &VAR3->VAR51;\nVAR3->VAR44.VAR48 = &VAR3->VAR48;\nVAR3->VAR44.VAR47 = &VAR3->VAR12;\nVAR4 = FUN17(&VAR3->VAR44, VAR66, -1);\nif (VAR4) {\nFUN3(VAR3->VAR10, \"STR\",\nVAR4);\ngoto VAR67;\n}\nFUN9(VAR3->VAR10, \"STR\",\nFUN18(&VAR3->VAR44));\nFUN19(VAR3->VAR10, \"STR\");\nreturn 0;\nVAR64:\nFUN20(&VAR3->VAR51);\nVAR67:\nFUN21(&VAR3->VAR48);\nVAR27:\nFUN22(VAR3);\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int airspy_probe(struct usb_interface *intf,\nconst struct usb_device_id *id)\n{\nstruct airspy *s;\nint ret;\nu8 u8tmp, buf[BUF_SIZE];\ns = kzalloc(sizeof(struct airspy), GFP_KERNEL);\nif (s == NULL) {\ndev_err(&intf->dev, \"Could not allocate memory for state\\n\");\nreturn -ENOMEM;\n}\nmutex_init(&s->v4l2_lock);\nmutex_init(&s->vb_queue_lock);\nspin_lock_init(&s->queued_bufs_lock);\nINIT_LIST_HEAD(&s->queued_bufs);\ns->dev = &intf->dev;\ns->udev = interface_to_usbdev(intf);\ns->f_adc = bands[0].rangelow;\ns->f_rf = bands_rf[0].rangelow;\ns->pixelformat = formats[0].pixelformat;\ns->buffersize = formats[0].buffersize;\nret = airspy_ctrl_msg(s, CMD_BOARD_ID_READ, 0, 0, &u8tmp, 1);\nif (ret == 0)\nret = airspy_ctrl_msg(s, CMD_VERSION_STRING_READ, 0, 0,\nbuf, BUF_SIZE);\nif (ret) {\ndev_err(s->dev, \"Could not detect board\\n\");\ngoto err_free_mem;\n}\nbuf[BUF_SIZE - 1] = '\\0';\ndev_info(s->dev, \"Board ID: %02x\\n\", u8tmp);\ndev_info(s->dev, \"Firmware version: %s\\n\", buf);\ns->vb_queue.type = V4L2_BUF_TYPE_SDR_CAPTURE;\ns->vb_queue.io_modes = VB2_MMAP | VB2_USERPTR | VB2_READ;\ns->vb_queue.drv_priv = s;\ns->vb_queue.buf_struct_size = sizeof(struct airspy_frame_buf);\ns->vb_queue.ops = &airspy_vb2_ops;\ns->vb_queue.mem_ops = &vb2_vmalloc_memops;\ns->vb_queue.timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;\nret = vb2_queue_init(&s->vb_queue);\nif (ret) {\ndev_err(s->dev, \"Could not initialize vb2 queue\\n\");\ngoto err_free_mem;\n}\ns->vdev = airspy_template;\ns->vdev.queue = &s->vb_queue;\ns->vdev.queue->lock = &s->vb_queue_lock;\nvideo_set_drvdata(&s->vdev, s);\ns->v4l2_dev.release = airspy_video_release;\nret = v4l2_device_register(&intf->dev, &s->v4l2_dev);\nif (ret) {\ndev_err(s->dev, \"Failed to register v4l2-device (%d)\\n\", ret);\ngoto err_free_mem;\n}\nv4l2_ctrl_handler_init(&s->hdl, 5);\ns->lna_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_LNA_GAIN_AUTO, 0, 1, 1, 0);\ns->lna_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_LNA_GAIN, 0, 14, 1, 8);\nv4l2_ctrl_auto_cluster(2, &s->lna_gain_auto, 0, false);\ns->mixer_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_MIXER_GAIN_AUTO, 0, 1, 1, 0);\ns->mixer_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_MIXER_GAIN, 0, 15, 1, 8);\nv4l2_ctrl_auto_cluster(2, &s->mixer_gain_auto, 0, false);\ns->if_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_IF_GAIN, 0, 15, 1, 0);\nif (s->hdl.error) {\nret = s->hdl.error;\ndev_err(s->dev, \"Could not initialize controls\\n\");\ngoto err_free_controls;\n}\nv4l2_ctrl_handler_setup(&s->hdl);\ns->v4l2_dev.ctrl_handler = &s->hdl;\ns->vdev.v4l2_dev = &s->v4l2_dev;\ns->vdev.lock = &s->v4l2_lock;\nret = video_register_device(&s->vdev, VFL_TYPE_SDR, -1);\nif (ret) {\ndev_err(s->dev, \"Failed to register as video device (%d)\\n\",\nret);\ngoto err_free_controls;\n}\ndev_info(s->dev, \"Registered as %s\\n\",\nvideo_device_node_name(&s->vdev));\ndev_notice(s->dev, \"SDR API is still slightly experimental and functionality changes may follow\\n\");\nreturn 0;\nerr_free_controls:\nv4l2_ctrl_handler_free(&s->hdl);\nv4l2_device_unregister(&s->v4l2_dev);\nerr_free_mem:\nkfree(s);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int airspy_probe(struct usb_interface *intf,\nconst struct usb_device_id *id)\n{\nstruct airspy *s;\nint ret;\nu8 u8tmp, buf[BUF_SIZE];\ns = kzalloc(sizeof(struct airspy), GFP_KERNEL);\nif (s == NULL) {\ndev_err(&intf->dev, \"Could not allocate memory for state\\n\");\nreturn -ENOMEM;\n}\nmutex_init(&s->v4l2_lock);\nmutex_init(&s->vb_queue_lock);\nspin_lock_init(&s->queued_bufs_lock);\nINIT_LIST_HEAD(&s->queued_bufs);\ns->dev = &intf->dev;\ns->udev = interface_to_usbdev(intf);\ns->f_adc = bands[0].rangelow;\ns->f_rf = bands_rf[0].rangelow;\ns->pixelformat = formats[0].pixelformat;\ns->buffersize = formats[0].buffersize;\nret = airspy_ctrl_msg(s, CMD_BOARD_ID_READ, 0, 0, &u8tmp, 1);\nif (ret == 0)\nret = airspy_ctrl_msg(s, CMD_VERSION_STRING_READ, 0, 0,\nbuf, BUF_SIZE);\nif (ret) {\ndev_err(s->dev, \"Could not detect board\\n\");\ngoto err_free_mem;\n}\nbuf[BUF_SIZE - 1] = '\\0';\ndev_info(s->dev, \"Board ID: %02x\\n\", u8tmp);\ndev_info(s->dev, \"Firmware version: %s\\n\", buf);\ns->vb_queue.type = V4L2_BUF_TYPE_SDR_CAPTURE;\ns->vb_queue.io_modes = VB2_MMAP | VB2_USERPTR | VB2_READ;\ns->vb_queue.drv_priv = s;\ns->vb_queue.buf_struct_size = sizeof(struct airspy_frame_buf);\ns->vb_queue.ops = &airspy_vb2_ops;\ns->vb_queue.mem_ops = &vb2_vmalloc_memops;\ns->vb_queue.timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC;\nret = vb2_queue_init(&s->vb_queue);\nif (ret) {\ndev_err(s->dev, \"Could not initialize vb2 queue\\n\");\ngoto err_free_mem;\n}\ns->vdev = airspy_template;\ns->vdev.queue = &s->vb_queue;\ns->vdev.queue->lock = &s->vb_queue_lock;\nvideo_set_drvdata(&s->vdev, s);\ns->v4l2_dev.release = airspy_video_release;\nret = v4l2_device_register(&intf->dev, &s->v4l2_dev);\nif (ret) {\ndev_err(s->dev, \"Failed to register v4l2-device (%d)\\n\", ret);\ngoto err_free_mem;\n}\nv4l2_ctrl_handler_init(&s->hdl, 5);\ns->lna_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_LNA_GAIN_AUTO, 0, 1, 1, 0);\ns->lna_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_LNA_GAIN, 0, 14, 1, 8);\nv4l2_ctrl_auto_cluster(2, &s->lna_gain_auto, 0, false);\ns->mixer_gain_auto = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_MIXER_GAIN_AUTO, 0, 1, 1, 0);\ns->mixer_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_MIXER_GAIN, 0, 15, 1, 8);\nv4l2_ctrl_auto_cluster(2, &s->mixer_gain_auto, 0, false);\ns->if_gain = v4l2_ctrl_new_std(&s->hdl, &airspy_ctrl_ops,\nV4L2_CID_RF_TUNER_IF_GAIN, 0, 15, 1, 0);\nif (s->hdl.error) {\nret = s->hdl.error;\ndev_err(s->dev, \"Could not initialize controls\\n\");\ngoto err_free_controls;\n}\nv4l2_ctrl_handler_setup(&s->hdl);\ns->v4l2_dev.ctrl_handler = &s->hdl;\ns->vdev.v4l2_dev = &s->v4l2_dev;\ns->vdev.lock = &s->v4l2_lock;\nret = video_register_device(&s->vdev, VFL_TYPE_SDR, -1);\nif (ret) {\ndev_err(s->dev, \"Failed to register as video device (%d)\\n\",\nret);\ngoto err_unregister_v4l2_dev;\n}\ndev_info(s->dev, \"Registered as %s\\n\",\nvideo_device_node_name(&s->vdev));\ndev_notice(s->dev, \"SDR API is still slightly experimental and functionality changes may follow\\n\");\nreturn 0;\nerr_free_controls:\nv4l2_ctrl_handler_free(&s->hdl);\nerr_unregister_v4l2_dev:\nv4l2_device_unregister(&s->v4l2_dev);\nerr_free_mem:\nkfree(s);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2016-5728": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of synchronization and validation checks between multiple user space data copy operations in the ioctl function.",
        "trigger_condition": "An attacker modifies the data in user space between two copy_from_user calls, leading to a race condition and potential memory corruption.",
        "specific_code_behavior_causing_vulnerability": "The code performs two separate copy_from_user operations without validating or comparing the data consistency between them, allowing an attacker to manipulate the data in user space between the two calls."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a validation step after the second copy_from_user call to compare the original data structure with the copied data structure. This comparison ensures that the data has not been tampered with between the two reads, preventing potential exploitation of the race condition vulnerability. In this case, the solution involves adding a check using memcmp to verify the consistency of the data before proceeding with further processing.",
      "GPT_analysis": "The modification is necessary to address a race condition vulnerability known as a \"double fetch\" vulnerability in the vop_ioctl function. In the vulnerable code snippet, there are two separate calls to copy data from user space into kernel space using the copy_from_user function. An attacker could potentially modify the data between these two calls, leading to a situation where the kernel reads different values than what was originally copied.\n\nBy adding the check with memcmp to compare the original data structure (dd) with the copied data structure (dd_config) after the second copy_from_user call, the modification ensures that the data has not been tampered with between the two reads. If the data structures do not match, indicating a potential modification by an attacker, the function returns an error (-EINVAL) to prevent further processing and potential exploitation of the vulnerability.\n\nThis modification helps to prevent sensitive information leakage from kernel memory or a denial of service (memory corruption and system crash) that could result from the race condition vulnerability described in CVE-2016-5728.",
      "GPT_purpose": "Handle various IOCTL commands for the MIC VOP driver, including adding a virtual device, copying descriptors, and changing configuration, with potential vulnerability to a race condition leading to memory corruption or denial of service.",
      "GPT_function": "\n1. Handle MIC_VIRTIO_ADD_DEVICE command by adding a new virtual device.\n2. Handle MIC_VIRTIO_COPY_DESC command by copying descriptor information.\n3. Handle MIC_VIRTIO_CONFIG_CHANGE command by changing device configuration.",
      "CVE_id": "CVE-2016-5728",
      "code_before_change": "static long vop_ioctl(struct file *f, unsigned int cmd, unsigned long arg)\n{\n\tstruct vop_vdev *vdev = f->private_data;\n\tstruct vop_info *vi = vdev->vi;\n\tvoid __user *argp = (void __user *)arg;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase MIC_VIRTIO_ADD_DEVICE:\n\t{\n\t\tstruct mic_device_desc dd, *dd_config;\n\n\t\tif (copy_from_user(&dd, argp, sizeof(dd)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mic_aligned_desc_size(&dd) > MIC_MAX_DESC_BLK_SIZE ||\n\t\t    dd.num_vq > MIC_MAX_VRINGS)\n\t\t\treturn -EINVAL;\n\n\t\tdd_config = kzalloc(mic_desc_size(&dd), GFP_KERNEL);\n\t\tif (!dd_config)\n\t\t\treturn -ENOMEM;\n\t\tif (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_ret;\n\t\t}\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tmutex_lock(&vi->vop_mutex);\n\t\tret = vop_virtio_add_device(vdev, dd_config);\n\t\tif (ret)\n\t\t\tgoto unlock_ret;\n\t\tlist_add_tail(&vdev->list, &vi->vdev_list);\nunlock_ret:\n\t\tmutex_unlock(&vi->vop_mutex);\n\t\tmutex_unlock(&vdev->vdev_mutex);\nfree_ret:\n\t\tkfree(dd_config);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_COPY_DESC:\n\t{\n\t\tstruct mic_copy_desc copy;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto _unlock_ret;\n\n\t\tif (copy_from_user(&copy, argp, sizeof(copy))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto _unlock_ret;\n\t\t}\n\n\t\tret = vop_virtio_copy_desc(vdev, &copy);\n\t\tif (ret < 0)\n\t\t\tgoto _unlock_ret;\n\t\tif (copy_to_user(\n\t\t\t&((struct mic_copy_desc __user *)argp)->out_len,\n\t\t\t&copy.out_len, sizeof(copy.out_len)))\n\t\t\tret = -EFAULT;\n_unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_CONFIG_CHANGE:\n\t{\n\t\tvoid *buf;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto __unlock_ret;\n\t\tbuf = kzalloc(vdev->dd->config_len, GFP_KERNEL);\n\t\tif (!buf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto __unlock_ret;\n\t\t}\n\t\tif (copy_from_user(buf, argp, vdev->dd->config_len)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto done;\n\t\t}\n\t\tret = vop_virtio_config_change(vdev, buf);\ndone:\n\t\tkfree(buf);\n__unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t};\n\treturn 0;\n}",
      "code_after_change": "static long vop_ioctl(struct file *f, unsigned int cmd, unsigned long arg)\n{\n\tstruct vop_vdev *vdev = f->private_data;\n\tstruct vop_info *vi = vdev->vi;\n\tvoid __user *argp = (void __user *)arg;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase MIC_VIRTIO_ADD_DEVICE:\n\t{\n\t\tstruct mic_device_desc dd, *dd_config;\n\n\t\tif (copy_from_user(&dd, argp, sizeof(dd)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mic_aligned_desc_size(&dd) > MIC_MAX_DESC_BLK_SIZE ||\n\t\t    dd.num_vq > MIC_MAX_VRINGS)\n\t\t\treturn -EINVAL;\n\n\t\tdd_config = kzalloc(mic_desc_size(&dd), GFP_KERNEL);\n\t\tif (!dd_config)\n\t\t\treturn -ENOMEM;\n\t\tif (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_ret;\n\t\t}\n\t\t/* Ensure desc has not changed between the two reads */\n\t\tif (memcmp(&dd, dd_config, sizeof(dd))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto free_ret;\n\t\t}\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tmutex_lock(&vi->vop_mutex);\n\t\tret = vop_virtio_add_device(vdev, dd_config);\n\t\tif (ret)\n\t\t\tgoto unlock_ret;\n\t\tlist_add_tail(&vdev->list, &vi->vdev_list);\nunlock_ret:\n\t\tmutex_unlock(&vi->vop_mutex);\n\t\tmutex_unlock(&vdev->vdev_mutex);\nfree_ret:\n\t\tkfree(dd_config);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_COPY_DESC:\n\t{\n\t\tstruct mic_copy_desc copy;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto _unlock_ret;\n\n\t\tif (copy_from_user(&copy, argp, sizeof(copy))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto _unlock_ret;\n\t\t}\n\n\t\tret = vop_virtio_copy_desc(vdev, &copy);\n\t\tif (ret < 0)\n\t\t\tgoto _unlock_ret;\n\t\tif (copy_to_user(\n\t\t\t&((struct mic_copy_desc __user *)argp)->out_len,\n\t\t\t&copy.out_len, sizeof(copy.out_len)))\n\t\t\tret = -EFAULT;\n_unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_CONFIG_CHANGE:\n\t{\n\t\tvoid *buf;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto __unlock_ret;\n\t\tbuf = kzalloc(vdev->dd->config_len, GFP_KERNEL);\n\t\tif (!buf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto __unlock_ret;\n\t\t}\n\t\tif (copy_from_user(buf, argp, vdev->dd->config_len)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto done;\n\t\t}\n\t\tret = vop_virtio_config_change(vdev, buf);\ndone:\n\t\tkfree(buf);\n__unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t};\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\t\tgoto free_ret;",
          "\t\t}",
          "\t\t/* Ensure desc has not changed between the two reads */",
          "\t\tif (memcmp(&dd, dd_config, sizeof(dd))) {",
          "\t\t\tret = -EINVAL;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of synchronization and validation checks between multiple user space data copy operations in the ioctl function.",
      "trigger_condition": "An attacker modifies the data in user space between two copy_from_user calls, leading to a race condition and potential memory corruption.",
      "specific_code_behavior_causing_vulnerability": "The code performs two separate copy_from_user operations without validating or comparing the data consistency between them, allowing an attacker to manipulate the data in user space between the two calls.",
      "id": 89,
      "code_after_change_normalized": "static long FUN1(struct file *VAR1, unsigned int VAR2, unsigned long VAR3)\n{\nstruct vop_vdev *VAR4 = VAR1->VAR5;\nstruct vop_info *VAR6 = VAR4->VAR6;\nvoid VAR8 *VAR7 = (void VAR8 *)VAR3;\nint VAR9;\nswitch (VAR2) {\ncase VAR10:\n{\nstruct mic_device_desc VAR11, *VAR12;\nif (FUN2(&VAR11, VAR7, sizeof(VAR11)))\nreturn -VAR13;\nif (FUN3(&VAR11) > VAR14 ||\nVAR11.VAR15 > VAR16)\nreturn -VAR17;\nVAR12 = FUN4(FUN5(&VAR11), VAR18);\nif (!VAR12)\nreturn -VAR19;\nif (FUN2(VAR12, VAR7, FUN5(&VAR11))) {\nVAR9 = -VAR13;\ngoto VAR20;\n}\nif (FUN6(&VAR11, VAR12, sizeof(VAR11))) {\nVAR9 = -VAR17;\ngoto VAR20;\n}\nFUN7(&VAR4->VAR21);\nFUN7(&VAR6->VAR22);\nVAR9 = FUN8(VAR4, VAR12);\nif (VAR9)\ngoto VAR23;\nFUN9(&VAR4->VAR24, &VAR6->VAR25);\nVAR23:\nFUN10(&VAR6->VAR22);\nFUN10(&VAR4->VAR21);\nVAR20:\nFUN11(VAR12);\nreturn VAR9;\n}\ncase VAR26:\n{\nstruct mic_copy_desc VAR27;\nFUN7(&VAR4->VAR21);\nVAR9 = FUN12(VAR4);\nif (VAR9)\ngoto VAR28;\nif (FUN2(&VAR27, VAR7, sizeof(VAR27))) {\nVAR9 = -VAR13;\ngoto VAR28;\n}\nVAR9 = FUN13(VAR4, &VAR27);\nif (VAR9 < 0)\ngoto VAR28;\nif (FUN14(\n&((struct mic_copy_desc VAR8 *)VAR7)->VAR29,\n&VAR27.VAR29, sizeof(VAR27.VAR29)))\nVAR9 = -VAR13;\nVAR28:\nFUN10(&VAR4->VAR21);\nreturn VAR9;\n}\ncase VAR30:\n{\nvoid *VAR31;\nFUN7(&VAR4->VAR21);\nVAR9 = FUN12(VAR4);\nif (VAR9)\ngoto VAR32;\nVAR31 = FUN4(VAR4->VAR11->VAR33, VAR18);\nif (!VAR31) {\nVAR9 = -VAR19;\ngoto VAR32;\n}\nif (FUN2(VAR31, VAR7, VAR4->VAR11->VAR33)) {\nVAR9 = -VAR13;\ngoto VAR34;\n}\nVAR9 = FUN15(VAR4, VAR31);\nVAR34:\nFUN11(VAR31);\nVAR32:\nFUN10(&VAR4->VAR21);\nreturn VAR9;\n}\ndefault:\nreturn -VAR35;\n};\nreturn 0;\n}\n",
      "code_before_change_normalized": "static long FUN1(struct file *VAR1, unsigned int VAR2, unsigned long VAR3)\n{\nstruct vop_vdev *VAR4 = VAR1->VAR5;\nstruct vop_info *VAR6 = VAR4->VAR6;\nvoid VAR8 *VAR7 = (void VAR8 *)VAR3;\nint VAR9;\nswitch (VAR2) {\ncase VAR10:\n{\nstruct mic_device_desc VAR11, *VAR12;\nif (FUN2(&VAR11, VAR7, sizeof(VAR11)))\nreturn -VAR13;\nif (FUN3(&VAR11) > VAR14 ||\nVAR11.VAR15 > VAR16)\nreturn -VAR17;\nVAR12 = FUN4(FUN5(&VAR11), VAR18);\nif (!VAR12)\nreturn -VAR19;\nif (FUN2(VAR12, VAR7, FUN5(&VAR11))) {\nVAR9 = -VAR13;\ngoto VAR20;\n}\nFUN6(&VAR4->VAR21);\nFUN6(&VAR6->VAR22);\nVAR9 = FUN7(VAR4, VAR12);\nif (VAR9)\ngoto VAR23;\nFUN8(&VAR4->VAR24, &VAR6->VAR25);\nVAR23:\nFUN9(&VAR6->VAR22);\nFUN9(&VAR4->VAR21);\nVAR20:\nFUN10(VAR12);\nreturn VAR9;\n}\ncase VAR26:\n{\nstruct mic_copy_desc VAR27;\nFUN6(&VAR4->VAR21);\nVAR9 = FUN11(VAR4);\nif (VAR9)\ngoto VAR28;\nif (FUN2(&VAR27, VAR7, sizeof(VAR27))) {\nVAR9 = -VAR13;\ngoto VAR28;\n}\nVAR9 = FUN12(VAR4, &VAR27);\nif (VAR9 < 0)\ngoto VAR28;\nif (FUN13(\n&((struct mic_copy_desc VAR8 *)VAR7)->VAR29,\n&VAR27.VAR29, sizeof(VAR27.VAR29)))\nVAR9 = -VAR13;\nVAR28:\nFUN9(&VAR4->VAR21);\nreturn VAR9;\n}\ncase VAR30:\n{\nvoid *VAR31;\nFUN6(&VAR4->VAR21);\nVAR9 = FUN11(VAR4);\nif (VAR9)\ngoto VAR32;\nVAR31 = FUN4(VAR4->VAR11->VAR33, VAR18);\nif (!VAR31) {\nVAR9 = -VAR19;\ngoto VAR32;\n}\nif (FUN2(VAR31, VAR7, VAR4->VAR11->VAR33)) {\nVAR9 = -VAR13;\ngoto VAR34;\n}\nVAR9 = FUN14(VAR4, VAR31);\nVAR34:\nFUN10(VAR31);\nVAR32:\nFUN9(&VAR4->VAR21);\nreturn VAR9;\n}\ndefault:\nreturn -VAR35;\n};\nreturn 0;\n}\n",
      "code_after_change_raw": "static long vop_ioctl(struct file *f, unsigned int cmd, unsigned long arg)\n{\nstruct vop_vdev *vdev = f->private_data;\nstruct vop_info *vi = vdev->vi;\nvoid __user *argp = (void __user *)arg;\nint ret;\nswitch (cmd) {\ncase MIC_VIRTIO_ADD_DEVICE:\n{\nstruct mic_device_desc dd, *dd_config;\nif (copy_from_user(&dd, argp, sizeof(dd)))\nreturn -EFAULT;\nif (mic_aligned_desc_size(&dd) > MIC_MAX_DESC_BLK_SIZE ||\ndd.num_vq > MIC_MAX_VRINGS)\nreturn -EINVAL;\ndd_config = kzalloc(mic_desc_size(&dd), GFP_KERNEL);\nif (!dd_config)\nreturn -ENOMEM;\nif (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {\nret = -EFAULT;\ngoto free_ret;\n}\nif (memcmp(&dd, dd_config, sizeof(dd))) {\nret = -EINVAL;\ngoto free_ret;\n}\nmutex_lock(&vdev->vdev_mutex);\nmutex_lock(&vi->vop_mutex);\nret = vop_virtio_add_device(vdev, dd_config);\nif (ret)\ngoto unlock_ret;\nlist_add_tail(&vdev->list, &vi->vdev_list);\nunlock_ret:\nmutex_unlock(&vi->vop_mutex);\nmutex_unlock(&vdev->vdev_mutex);\nfree_ret:\nkfree(dd_config);\nreturn ret;\n}\ncase MIC_VIRTIO_COPY_DESC:\n{\nstruct mic_copy_desc copy;\nmutex_lock(&vdev->vdev_mutex);\nret = vop_vdev_inited(vdev);\nif (ret)\ngoto _unlock_ret;\nif (copy_from_user(&copy, argp, sizeof(copy))) {\nret = -EFAULT;\ngoto _unlock_ret;\n}\nret = vop_virtio_copy_desc(vdev, &copy);\nif (ret < 0)\ngoto _unlock_ret;\nif (copy_to_user(\n&((struct mic_copy_desc __user *)argp)->out_len,\n&copy.out_len, sizeof(copy.out_len)))\nret = -EFAULT;\n_unlock_ret:\nmutex_unlock(&vdev->vdev_mutex);\nreturn ret;\n}\ncase MIC_VIRTIO_CONFIG_CHANGE:\n{\nvoid *buf;\nmutex_lock(&vdev->vdev_mutex);\nret = vop_vdev_inited(vdev);\nif (ret)\ngoto __unlock_ret;\nbuf = kzalloc(vdev->dd->config_len, GFP_KERNEL);\nif (!buf) {\nret = -ENOMEM;\ngoto __unlock_ret;\n}\nif (copy_from_user(buf, argp, vdev->dd->config_len)) {\nret = -EFAULT;\ngoto done;\n}\nret = vop_virtio_config_change(vdev, buf);\ndone:\nkfree(buf);\n__unlock_ret:\nmutex_unlock(&vdev->vdev_mutex);\nreturn ret;\n}\ndefault:\nreturn -ENOIOCTLCMD;\n};\nreturn 0;\n}\n",
      "code_before_change_raw": "static long vop_ioctl(struct file *f, unsigned int cmd, unsigned long arg)\n{\nstruct vop_vdev *vdev = f->private_data;\nstruct vop_info *vi = vdev->vi;\nvoid __user *argp = (void __user *)arg;\nint ret;\nswitch (cmd) {\ncase MIC_VIRTIO_ADD_DEVICE:\n{\nstruct mic_device_desc dd, *dd_config;\nif (copy_from_user(&dd, argp, sizeof(dd)))\nreturn -EFAULT;\nif (mic_aligned_desc_size(&dd) > MIC_MAX_DESC_BLK_SIZE ||\ndd.num_vq > MIC_MAX_VRINGS)\nreturn -EINVAL;\ndd_config = kzalloc(mic_desc_size(&dd), GFP_KERNEL);\nif (!dd_config)\nreturn -ENOMEM;\nif (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {\nret = -EFAULT;\ngoto free_ret;\n}\nmutex_lock(&vdev->vdev_mutex);\nmutex_lock(&vi->vop_mutex);\nret = vop_virtio_add_device(vdev, dd_config);\nif (ret)\ngoto unlock_ret;\nlist_add_tail(&vdev->list, &vi->vdev_list);\nunlock_ret:\nmutex_unlock(&vi->vop_mutex);\nmutex_unlock(&vdev->vdev_mutex);\nfree_ret:\nkfree(dd_config);\nreturn ret;\n}\ncase MIC_VIRTIO_COPY_DESC:\n{\nstruct mic_copy_desc copy;\nmutex_lock(&vdev->vdev_mutex);\nret = vop_vdev_inited(vdev);\nif (ret)\ngoto _unlock_ret;\nif (copy_from_user(&copy, argp, sizeof(copy))) {\nret = -EFAULT;\ngoto _unlock_ret;\n}\nret = vop_virtio_copy_desc(vdev, &copy);\nif (ret < 0)\ngoto _unlock_ret;\nif (copy_to_user(\n&((struct mic_copy_desc __user *)argp)->out_len,\n&copy.out_len, sizeof(copy.out_len)))\nret = -EFAULT;\n_unlock_ret:\nmutex_unlock(&vdev->vdev_mutex);\nreturn ret;\n}\ncase MIC_VIRTIO_CONFIG_CHANGE:\n{\nvoid *buf;\nmutex_lock(&vdev->vdev_mutex);\nret = vop_vdev_inited(vdev);\nif (ret)\ngoto __unlock_ret;\nbuf = kzalloc(vdev->dd->config_len, GFP_KERNEL);\nif (!buf) {\nret = -ENOMEM;\ngoto __unlock_ret;\n}\nif (copy_from_user(buf, argp, vdev->dd->config_len)) {\nret = -EFAULT;\ngoto done;\n}\nret = vop_virtio_config_change(vdev, buf);\ndone:\nkfree(buf);\n__unlock_ret:\nmutex_unlock(&vdev->vdev_mutex);\nreturn ret;\n}\ndefault:\nreturn -ENOIOCTLCMD;\n};\nreturn 0;\n}\n"
    }
  ],
  "CVE-2016-5829": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper bounds checking and validation of input data in the ioctl handling function.",
        "trigger_condition": "Local users can exploit the lack of input validation by crafting malicious HIDIOCGUSAGES or HIDIOCSUSAGES ioctl calls, leading to heap-based buffer overflows.",
        "specific_code_behavior_causing_vulnerability": "The code does not adequately check the bounds of the input data provided through ioctl calls, allowing users to manipulate the data in a way that leads to buffer overflows and potential denial of service or other impacts."
      },
      "solution": "To address the vulnerability, it is crucial to implement proper bounds checking and validation of input data in the ioctl handling function. Specifically, the code should ensure that the input data provided through HIDIOCGUSAGES or HIDIOCSUSAGES ioctl calls does not exceed the allocated memory space and that index calculations do not go beyond the valid range. By adding these checks, the code can prevent heap-based buffer overflows and enhance the security of the system.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-5829, which involves multiple heap-based buffer overflows in the `hiddev_ioctl_usage` function in the Linux kernel. By making the specified changes, the code is updated to prevent local users from causing a denial of service or potentially having other unspecified impacts via crafted `HIDIOCGUSAGES` or `HIDIOCSUSAGES` ioctl calls.\n\nThe modifications include adding bounds checking to ensure that the `uref_multi->num_values` does not exceed `HID_MAX_MULTI_USAGES` and that the index calculations do not go beyond the allocated memory space. These checks help prevent buffer overflows and ensure the integrity of the memory operations within the function.\n\nBy implementing these modifications, the code becomes more secure and less susceptible to exploitation through malicious input, thereby mitigating the vulnerability and enhancing the overall safety and stability of the system.",
      "GPT_purpose": "Handle ioctl calls related to HID device usage information in the Linux kernel.",
      "GPT_function": "\n1. Allocate memory for hiddev_usage_ref_multi struct.\n2. Handle ioctl commands related to HID device usage information.\n3. Perform operations based on the ioctl command received.\n4. Handle potential errors and return appropriate error codes.",
      "CVE_id": "CVE-2016-5829",
      "code_before_change": "static noinline int hiddev_ioctl_usage(struct hiddev *hiddev, unsigned int cmd, void __user *user_arg)\n{\n\tstruct hid_device *hid = hiddev->hid;\n\tstruct hiddev_report_info rinfo;\n\tstruct hiddev_usage_ref_multi *uref_multi = NULL;\n\tstruct hiddev_usage_ref *uref;\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tint i;\n\n\turef_multi = kmalloc(sizeof(struct hiddev_usage_ref_multi), GFP_KERNEL);\n\tif (!uref_multi)\n\t\treturn -ENOMEM;\n\turef = &uref_multi->uref;\n\tif (cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) {\n\t\tif (copy_from_user(uref_multi, user_arg,\n\t\t\t\t   sizeof(*uref_multi)))\n\t\t\tgoto fault;\n\t} else {\n\t\tif (copy_from_user(uref, user_arg, sizeof(*uref)))\n\t\t\tgoto fault;\n\t}\n\n\tswitch (cmd) {\n\tcase HIDIOCGUCODE:\n\t\trinfo.report_type = uref->report_type;\n\t\trinfo.report_id = uref->report_id;\n\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\tgoto inval;\n\n\t\tif (uref->field_index >= report->maxfield)\n\t\t\tgoto inval;\n\n\t\tfield = report->field[uref->field_index];\n\t\tif (uref->usage_index >= field->maxusage)\n\t\t\tgoto inval;\n\n\t\turef->usage_code = field->usage[uref->usage_index].hid;\n\n\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\tgoto fault;\n\n\t\tgoto goodreturn;\n\n\tdefault:\n\t\tif (cmd != HIDIOCGUSAGE &&\n\t\t    cmd != HIDIOCGUSAGES &&\n\t\t    uref->report_type == HID_REPORT_TYPE_INPUT)\n\t\t\tgoto inval;\n\n\t\tif (uref->report_id == HID_REPORT_ID_UNKNOWN) {\n\t\t\tfield = hiddev_lookup_usage(hid, uref);\n\t\t\tif (field == NULL)\n\t\t\t\tgoto inval;\n\t\t} else {\n\t\t\trinfo.report_type = uref->report_type;\n\t\t\trinfo.report_id = uref->report_id;\n\t\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\t\tgoto inval;\n\n\t\t\tif (uref->field_index >= report->maxfield)\n\t\t\t\tgoto inval;\n\n\t\t\tfield = report->field[uref->field_index];\n\n\t\t\tif (cmd == HIDIOCGCOLLECTIONINDEX) {\n\t\t\t\tif (uref->usage_index >= field->maxusage)\n\t\t\t\t\tgoto inval;\n\t\t\t} else if (uref->usage_index >= field->report_count)\n\t\t\t\tgoto inval;\n\n\t\t\telse if ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n\t\t\t\t (uref_multi->num_values > HID_MAX_MULTI_USAGES ||\n\t\t\t\t  uref->usage_index + uref_multi->num_values > field->report_count))\n\t\t\t\tgoto inval;\n\t\t}\n\n\t\tswitch (cmd) {\n\t\tcase HIDIOCGUSAGE:\n\t\t\turef->value = field->value[uref->usage_index];\n\t\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCSUSAGE:\n\t\t\tfield->value[uref->usage_index] = uref->value;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCGCOLLECTIONINDEX:\n\t\t\ti = field->usage[uref->usage_index].collection_index;\n\t\t\tkfree(uref_multi);\n\t\t\treturn i;\n\t\tcase HIDIOCGUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\turef_multi->values[i] =\n\t\t\t\t    field->value[uref->usage_index + i];\n\t\t\tif (copy_to_user(user_arg, uref_multi,\n\t\t\t\t\t sizeof(*uref_multi)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\t\tcase HIDIOCSUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\tfield->value[uref->usage_index + i] =\n\t\t\t\t    uref_multi->values[i];\n\t\t\tgoto goodreturn;\n\t\t}\n\ngoodreturn:\n\t\tkfree(uref_multi);\n\t\treturn 0;\nfault:\n\t\tkfree(uref_multi);\n\t\treturn -EFAULT;\ninval:\n\t\tkfree(uref_multi);\n\t\treturn -EINVAL;\n\t}\n}",
      "code_after_change": "static noinline int hiddev_ioctl_usage(struct hiddev *hiddev, unsigned int cmd, void __user *user_arg)\n{\n\tstruct hid_device *hid = hiddev->hid;\n\tstruct hiddev_report_info rinfo;\n\tstruct hiddev_usage_ref_multi *uref_multi = NULL;\n\tstruct hiddev_usage_ref *uref;\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tint i;\n\n\turef_multi = kmalloc(sizeof(struct hiddev_usage_ref_multi), GFP_KERNEL);\n\tif (!uref_multi)\n\t\treturn -ENOMEM;\n\turef = &uref_multi->uref;\n\tif (cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) {\n\t\tif (copy_from_user(uref_multi, user_arg,\n\t\t\t\t   sizeof(*uref_multi)))\n\t\t\tgoto fault;\n\t} else {\n\t\tif (copy_from_user(uref, user_arg, sizeof(*uref)))\n\t\t\tgoto fault;\n\t}\n\n\tswitch (cmd) {\n\tcase HIDIOCGUCODE:\n\t\trinfo.report_type = uref->report_type;\n\t\trinfo.report_id = uref->report_id;\n\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\tgoto inval;\n\n\t\tif (uref->field_index >= report->maxfield)\n\t\t\tgoto inval;\n\n\t\tfield = report->field[uref->field_index];\n\t\tif (uref->usage_index >= field->maxusage)\n\t\t\tgoto inval;\n\n\t\turef->usage_code = field->usage[uref->usage_index].hid;\n\n\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\tgoto fault;\n\n\t\tgoto goodreturn;\n\n\tdefault:\n\t\tif (cmd != HIDIOCGUSAGE &&\n\t\t    cmd != HIDIOCGUSAGES &&\n\t\t    uref->report_type == HID_REPORT_TYPE_INPUT)\n\t\t\tgoto inval;\n\n\t\tif (uref->report_id == HID_REPORT_ID_UNKNOWN) {\n\t\t\tfield = hiddev_lookup_usage(hid, uref);\n\t\t\tif (field == NULL)\n\t\t\t\tgoto inval;\n\t\t} else {\n\t\t\trinfo.report_type = uref->report_type;\n\t\t\trinfo.report_id = uref->report_id;\n\t\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\t\tgoto inval;\n\n\t\t\tif (uref->field_index >= report->maxfield)\n\t\t\t\tgoto inval;\n\n\t\t\tfield = report->field[uref->field_index];\n\n\t\t\tif (cmd == HIDIOCGCOLLECTIONINDEX) {\n\t\t\t\tif (uref->usage_index >= field->maxusage)\n\t\t\t\t\tgoto inval;\n\t\t\t} else if (uref->usage_index >= field->report_count)\n\t\t\t\tgoto inval;\n\t\t}\n\n\t\tif ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n\t\t    (uref_multi->num_values > HID_MAX_MULTI_USAGES ||\n\t\t     uref->usage_index + uref_multi->num_values > field->report_count))\n\t\t\tgoto inval;\n\n\t\tswitch (cmd) {\n\t\tcase HIDIOCGUSAGE:\n\t\t\turef->value = field->value[uref->usage_index];\n\t\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCSUSAGE:\n\t\t\tfield->value[uref->usage_index] = uref->value;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCGCOLLECTIONINDEX:\n\t\t\ti = field->usage[uref->usage_index].collection_index;\n\t\t\tkfree(uref_multi);\n\t\t\treturn i;\n\t\tcase HIDIOCGUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\turef_multi->values[i] =\n\t\t\t\t    field->value[uref->usage_index + i];\n\t\t\tif (copy_to_user(user_arg, uref_multi,\n\t\t\t\t\t sizeof(*uref_multi)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\t\tcase HIDIOCSUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\tfield->value[uref->usage_index + i] =\n\t\t\t\t    uref_multi->values[i];\n\t\t\tgoto goodreturn;\n\t\t}\n\ngoodreturn:\n\t\tkfree(uref_multi);\n\t\treturn 0;\nfault:\n\t\tkfree(uref_multi);\n\t\treturn -EFAULT;\ninval:\n\t\tkfree(uref_multi);\n\t\treturn -EINVAL;\n\t}\n}",
      "modified_lines": {
        "added": [
          "\t\t}",
          "\t\tif ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&",
          "\t\t    (uref_multi->num_values > HID_MAX_MULTI_USAGES ||",
          "\t\t     uref->usage_index + uref_multi->num_values > field->report_count))",
          "\t\t\tgoto inval;"
        ],
        "deleted": [
          "\t\t\telse if ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&",
          "\t\t\t\t (uref_multi->num_values > HID_MAX_MULTI_USAGES ||",
          "\t\t\t\t  uref->usage_index + uref_multi->num_values > field->report_count))",
          "\t\t\t\tgoto inval;",
          "\t\t}"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper bounds checking and validation of input data in the ioctl handling function.",
      "trigger_condition": "Local users can exploit the lack of input validation by crafting malicious HIDIOCGUSAGES or HIDIOCSUSAGES ioctl calls, leading to heap-based buffer overflows.",
      "specific_code_behavior_causing_vulnerability": "The code does not adequately check the bounds of the input data provided through ioctl calls, allowing users to manipulate the data in a way that leads to buffer overflows and potential denial of service or other impacts.",
      "id": 90,
      "code_after_change_normalized": "static noinline int FUN1(struct VAR1 *VAR1, unsigned int VAR2, void __user *VAR3)\n{\nstruct hid_device *VAR4 = VAR1->VAR4;\nstruct hiddev_report_info VAR5;\nstruct hiddev_usage_ref_multi *VAR6 = NULL;\nstruct hiddev_usage_ref *VAR7;\nstruct hid_report *VAR8;\nstruct hid_field *VAR9;\nint VAR10;\nVAR6 = FUN2(sizeof(struct VAR11), VAR12);\nif (!VAR6)\nreturn -VAR13;\nVAR7 = &VAR6->VAR7;\nif (VAR2 == VAR14 || VAR2 == VAR15) {\nif (FUN3(VAR6, VAR3,\nsizeof(*VAR6)))\ngoto VAR16;\n} else {\nif (FUN3(VAR7, VAR3, sizeof(*VAR7)))\ngoto VAR16;\n}\nswitch (VAR2) {\ncase VAR17:\nVAR5.VAR18 = VAR7->VAR18;\nVAR5.VAR19 = VAR7->VAR19;\nif ((VAR8 = FUN4(VAR4, &VAR5)) == NULL)\ngoto VAR20;\nif (VAR7->VAR21 >= VAR8->VAR22)\ngoto VAR20;\nVAR9 = VAR8->VAR9[VAR7->VAR21];\nif (VAR7->VAR23 >= VAR9->VAR24)\ngoto VAR20;\nVAR7->VAR25 = VAR9->VAR26[VAR7->VAR23].VAR4;\nif (FUN5(VAR3, VAR7, sizeof(*VAR7)))\ngoto VAR16;\ngoto VAR27;\ndefault:\nif (VAR2 != VAR28 &&\nVAR2 != VAR14 &&\nVAR7->VAR18 == VAR29)\ngoto VAR20;\nif (VAR7->VAR19 == VAR30) {\nVAR9 = FUN6(VAR4, VAR7);\nif (VAR9 == NULL)\ngoto VAR20;\n} else {\nVAR5.VAR18 = VAR7->VAR18;\nVAR5.VAR19 = VAR7->VAR19;\nif ((VAR8 = FUN4(VAR4, &VAR5)) == NULL)\ngoto VAR20;\nif (VAR7->VAR21 >= VAR8->VAR22)\ngoto VAR20;\nVAR9 = VAR8->VAR9[VAR7->VAR21];\nif (VAR2 == VAR31) {\nif (VAR7->VAR23 >= VAR9->VAR24)\ngoto VAR20;\n} else if (VAR7->VAR23 >= VAR9->VAR32)\ngoto VAR20;\n}\nif ((VAR2 == VAR14 || VAR2 == VAR15) &&\n(VAR6->VAR33 > VAR34 ||\nVAR7->VAR23 + VAR6->VAR33 > VAR9->VAR32))\ngoto VAR20;\nswitch (VAR2) {\ncase VAR28:\nVAR7->VAR35 = VAR9->VAR35[VAR7->VAR23];\nif (FUN5(VAR3, VAR7, sizeof(*VAR7)))\ngoto VAR16;\ngoto VAR27;\ncase VAR36:\nVAR9->VAR35[VAR7->VAR23] = VAR7->VAR35;\ngoto VAR27;\ncase VAR31:\nVAR10 = VAR9->VAR26[VAR7->VAR23].VAR37;\nFUN7(VAR6);\nreturn VAR10;\ncase VAR14:\nfor (VAR10 = 0; VAR10 < VAR6->VAR33; VAR10++)\nVAR6->VAR38[VAR10] =\nVAR9->VAR35[VAR7->VAR23 + VAR10];\nif (FUN5(VAR3, VAR6,\nsizeof(*VAR6)))\ngoto VAR16;\ngoto VAR27;\ncase VAR15:\nfor (VAR10 = 0; VAR10 < VAR6->VAR33; VAR10++)\nVAR9->VAR35[VAR7->VAR23 + VAR10] =\nVAR6->VAR38[VAR10];\ngoto VAR27;\n}\nVAR27:\nFUN7(VAR6);\nreturn 0;\nVAR16:\nFUN7(VAR6);\nreturn -VAR39;\nVAR20:\nFUN7(VAR6);\nreturn -VAR40;\n}\n}\n",
      "code_before_change_normalized": "static noinline int FUN1(struct VAR1 *VAR1, unsigned int VAR2, void __user *VAR3)\n{\nstruct hid_device *VAR4 = VAR1->VAR4;\nstruct hiddev_report_info VAR5;\nstruct hiddev_usage_ref_multi *VAR6 = NULL;\nstruct hiddev_usage_ref *VAR7;\nstruct hid_report *VAR8;\nstruct hid_field *VAR9;\nint VAR10;\nVAR6 = FUN2(sizeof(struct VAR11), VAR12);\nif (!VAR6)\nreturn -VAR13;\nVAR7 = &VAR6->VAR7;\nif (VAR2 == VAR14 || VAR2 == VAR15) {\nif (FUN3(VAR6, VAR3,\nsizeof(*VAR6)))\ngoto VAR16;\n} else {\nif (FUN3(VAR7, VAR3, sizeof(*VAR7)))\ngoto VAR16;\n}\nswitch (VAR2) {\ncase VAR17:\nVAR5.VAR18 = VAR7->VAR18;\nVAR5.VAR19 = VAR7->VAR19;\nif ((VAR8 = FUN4(VAR4, &VAR5)) == NULL)\ngoto VAR20;\nif (VAR7->VAR21 >= VAR8->VAR22)\ngoto VAR20;\nVAR9 = VAR8->VAR9[VAR7->VAR21];\nif (VAR7->VAR23 >= VAR9->VAR24)\ngoto VAR20;\nVAR7->VAR25 = VAR9->VAR26[VAR7->VAR23].VAR4;\nif (FUN5(VAR3, VAR7, sizeof(*VAR7)))\ngoto VAR16;\ngoto VAR27;\ndefault:\nif (VAR2 != VAR28 &&\nVAR2 != VAR14 &&\nVAR7->VAR18 == VAR29)\ngoto VAR20;\nif (VAR7->VAR19 == VAR30) {\nVAR9 = FUN6(VAR4, VAR7);\nif (VAR9 == NULL)\ngoto VAR20;\n} else {\nVAR5.VAR18 = VAR7->VAR18;\nVAR5.VAR19 = VAR7->VAR19;\nif ((VAR8 = FUN4(VAR4, &VAR5)) == NULL)\ngoto VAR20;\nif (VAR7->VAR21 >= VAR8->VAR22)\ngoto VAR20;\nVAR9 = VAR8->VAR9[VAR7->VAR21];\nif (VAR2 == VAR31) {\nif (VAR7->VAR23 >= VAR9->VAR24)\ngoto VAR20;\n} else if (VAR7->VAR23 >= VAR9->VAR32)\ngoto VAR20;\nelse if ((VAR2 == VAR14 || VAR2 == VAR15) &&\n(VAR6->VAR33 > VAR34 ||\nVAR7->VAR23 + VAR6->VAR33 > VAR9->VAR32))\ngoto VAR20;\n}\nswitch (VAR2) {\ncase VAR28:\nVAR7->VAR35 = VAR9->VAR35[VAR7->VAR23];\nif (FUN5(VAR3, VAR7, sizeof(*VAR7)))\ngoto VAR16;\ngoto VAR27;\ncase VAR36:\nVAR9->VAR35[VAR7->VAR23] = VAR7->VAR35;\ngoto VAR27;\ncase VAR31:\nVAR10 = VAR9->VAR26[VAR7->VAR23].VAR37;\nFUN7(VAR6);\nreturn VAR10;\ncase VAR14:\nfor (VAR10 = 0; VAR10 < VAR6->VAR33; VAR10++)\nVAR6->VAR38[VAR10] =\nVAR9->VAR35[VAR7->VAR23 + VAR10];\nif (FUN5(VAR3, VAR6,\nsizeof(*VAR6)))\ngoto VAR16;\ngoto VAR27;\ncase VAR15:\nfor (VAR10 = 0; VAR10 < VAR6->VAR33; VAR10++)\nVAR9->VAR35[VAR7->VAR23 + VAR10] =\nVAR6->VAR38[VAR10];\ngoto VAR27;\n}\nVAR27:\nFUN7(VAR6);\nreturn 0;\nVAR16:\nFUN7(VAR6);\nreturn -VAR39;\nVAR20:\nFUN7(VAR6);\nreturn -VAR40;\n}\n}\n",
      "code_after_change_raw": "static noinline int hiddev_ioctl_usage(struct hiddev *hiddev, unsigned int cmd, void __user *user_arg)\n{\nstruct hid_device *hid = hiddev->hid;\nstruct hiddev_report_info rinfo;\nstruct hiddev_usage_ref_multi *uref_multi = NULL;\nstruct hiddev_usage_ref *uref;\nstruct hid_report *report;\nstruct hid_field *field;\nint i;\nuref_multi = kmalloc(sizeof(struct hiddev_usage_ref_multi), GFP_KERNEL);\nif (!uref_multi)\nreturn -ENOMEM;\nuref = &uref_multi->uref;\nif (cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) {\nif (copy_from_user(uref_multi, user_arg,\nsizeof(*uref_multi)))\ngoto fault;\n} else {\nif (copy_from_user(uref, user_arg, sizeof(*uref)))\ngoto fault;\n}\nswitch (cmd) {\ncase HIDIOCGUCODE:\nrinfo.report_type = uref->report_type;\nrinfo.report_id = uref->report_id;\nif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\ngoto inval;\nif (uref->field_index >= report->maxfield)\ngoto inval;\nfield = report->field[uref->field_index];\nif (uref->usage_index >= field->maxusage)\ngoto inval;\nuref->usage_code = field->usage[uref->usage_index].hid;\nif (copy_to_user(user_arg, uref, sizeof(*uref)))\ngoto fault;\ngoto goodreturn;\ndefault:\nif (cmd != HIDIOCGUSAGE &&\ncmd != HIDIOCGUSAGES &&\nuref->report_type == HID_REPORT_TYPE_INPUT)\ngoto inval;\nif (uref->report_id == HID_REPORT_ID_UNKNOWN) {\nfield = hiddev_lookup_usage(hid, uref);\nif (field == NULL)\ngoto inval;\n} else {\nrinfo.report_type = uref->report_type;\nrinfo.report_id = uref->report_id;\nif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\ngoto inval;\nif (uref->field_index >= report->maxfield)\ngoto inval;\nfield = report->field[uref->field_index];\nif (cmd == HIDIOCGCOLLECTIONINDEX) {\nif (uref->usage_index >= field->maxusage)\ngoto inval;\n} else if (uref->usage_index >= field->report_count)\ngoto inval;\n}\nif ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n(uref_multi->num_values > HID_MAX_MULTI_USAGES ||\nuref->usage_index + uref_multi->num_values > field->report_count))\ngoto inval;\nswitch (cmd) {\ncase HIDIOCGUSAGE:\nuref->value = field->value[uref->usage_index];\nif (copy_to_user(user_arg, uref, sizeof(*uref)))\ngoto fault;\ngoto goodreturn;\ncase HIDIOCSUSAGE:\nfield->value[uref->usage_index] = uref->value;\ngoto goodreturn;\ncase HIDIOCGCOLLECTIONINDEX:\ni = field->usage[uref->usage_index].collection_index;\nkfree(uref_multi);\nreturn i;\ncase HIDIOCGUSAGES:\nfor (i = 0; i < uref_multi->num_values; i++)\nuref_multi->values[i] =\nfield->value[uref->usage_index + i];\nif (copy_to_user(user_arg, uref_multi,\nsizeof(*uref_multi)))\ngoto fault;\ngoto goodreturn;\ncase HIDIOCSUSAGES:\nfor (i = 0; i < uref_multi->num_values; i++)\nfield->value[uref->usage_index + i] =\nuref_multi->values[i];\ngoto goodreturn;\n}\ngoodreturn:\nkfree(uref_multi);\nreturn 0;\nfault:\nkfree(uref_multi);\nreturn -EFAULT;\ninval:\nkfree(uref_multi);\nreturn -EINVAL;\n}\n}\n",
      "code_before_change_raw": "static noinline int hiddev_ioctl_usage(struct hiddev *hiddev, unsigned int cmd, void __user *user_arg)\n{\nstruct hid_device *hid = hiddev->hid;\nstruct hiddev_report_info rinfo;\nstruct hiddev_usage_ref_multi *uref_multi = NULL;\nstruct hiddev_usage_ref *uref;\nstruct hid_report *report;\nstruct hid_field *field;\nint i;\nuref_multi = kmalloc(sizeof(struct hiddev_usage_ref_multi), GFP_KERNEL);\nif (!uref_multi)\nreturn -ENOMEM;\nuref = &uref_multi->uref;\nif (cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) {\nif (copy_from_user(uref_multi, user_arg,\nsizeof(*uref_multi)))\ngoto fault;\n} else {\nif (copy_from_user(uref, user_arg, sizeof(*uref)))\ngoto fault;\n}\nswitch (cmd) {\ncase HIDIOCGUCODE:\nrinfo.report_type = uref->report_type;\nrinfo.report_id = uref->report_id;\nif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\ngoto inval;\nif (uref->field_index >= report->maxfield)\ngoto inval;\nfield = report->field[uref->field_index];\nif (uref->usage_index >= field->maxusage)\ngoto inval;\nuref->usage_code = field->usage[uref->usage_index].hid;\nif (copy_to_user(user_arg, uref, sizeof(*uref)))\ngoto fault;\ngoto goodreturn;\ndefault:\nif (cmd != HIDIOCGUSAGE &&\ncmd != HIDIOCGUSAGES &&\nuref->report_type == HID_REPORT_TYPE_INPUT)\ngoto inval;\nif (uref->report_id == HID_REPORT_ID_UNKNOWN) {\nfield = hiddev_lookup_usage(hid, uref);\nif (field == NULL)\ngoto inval;\n} else {\nrinfo.report_type = uref->report_type;\nrinfo.report_id = uref->report_id;\nif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\ngoto inval;\nif (uref->field_index >= report->maxfield)\ngoto inval;\nfield = report->field[uref->field_index];\nif (cmd == HIDIOCGCOLLECTIONINDEX) {\nif (uref->usage_index >= field->maxusage)\ngoto inval;\n} else if (uref->usage_index >= field->report_count)\ngoto inval;\nelse if ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n(uref_multi->num_values > HID_MAX_MULTI_USAGES ||\nuref->usage_index + uref_multi->num_values > field->report_count))\ngoto inval;\n}\nswitch (cmd) {\ncase HIDIOCGUSAGE:\nuref->value = field->value[uref->usage_index];\nif (copy_to_user(user_arg, uref, sizeof(*uref)))\ngoto fault;\ngoto goodreturn;\ncase HIDIOCSUSAGE:\nfield->value[uref->usage_index] = uref->value;\ngoto goodreturn;\ncase HIDIOCGCOLLECTIONINDEX:\ni = field->usage[uref->usage_index].collection_index;\nkfree(uref_multi);\nreturn i;\ncase HIDIOCGUSAGES:\nfor (i = 0; i < uref_multi->num_values; i++)\nuref_multi->values[i] =\nfield->value[uref->usage_index + i];\nif (copy_to_user(user_arg, uref_multi,\nsizeof(*uref_multi)))\ngoto fault;\ngoto goodreturn;\ncase HIDIOCSUSAGES:\nfor (i = 0; i < uref_multi->num_values; i++)\nfield->value[uref->usage_index + i] =\nuref_multi->values[i];\ngoto goodreturn;\n}\ngoodreturn:\nkfree(uref_multi);\nreturn 0;\nfault:\nkfree(uref_multi);\nreturn -EFAULT;\ninval:\nkfree(uref_multi);\nreturn -EINVAL;\n}\n}\n"
    }
  ],
  "CVE-2016-6187": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of buffer size validation in the code handling AppArmor setprocattr hook.",
        "trigger_condition": "Local users can exploit the lack of buffer size validation to gain privileges by triggering the AppArmor setprocattr hook.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the buffer size, allowing the possibility of buffer overflow if the buffer is not null-terminated or exceeds the expected size."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper buffer handling by validating the buffer size and null-terminating the buffer if needed. This prevents buffer overflow issues and ensures compliance with AppArmor requirements. In this case, the solution involves checking if the buffer is null-terminated, null-terminating it if necessary, and allocating memory for the buffer to prevent buffer overflow vulnerabilities.",
      "GPT_analysis": "The modification made to the code snippet is necessary to address the vulnerability CVE-2016-6187, which allows local users to gain privileges by triggering an AppArmor setprocattr hook. The vulnerability arises from the lack of validation of the buffer size in the original code, which can lead to buffer overflow issues.\n\nHere's why the modification is necessary:\n\n1. **Buffer Null Termination**: The original code did not ensure that the buffer is null-terminated, which is a requirement for AppArmor. By adding the code to null-terminate the buffer if it is not already null-terminated, the modification ensures that the buffer meets AppArmor's requirements.\n\n2. **Memory Allocation**: The modified code allocates memory for the null-terminated buffer using `kmalloc`. This ensures that the buffer is of the correct size and is null-terminated, preventing potential buffer overflow vulnerabilities.\n\n3. **Proper Error Handling**: The modification includes proper error handling by checking for memory allocation failure and freeing the allocated memory before returning an error. This helps prevent memory leaks and ensures that the function behaves correctly in case of errors.\n\n4. **Correcting Error Handling**: The modification also corrects the error handling in the function by setting the error code appropriately and handling failures more effectively. This ensures that the function behaves as expected and provides meaningful error messages when necessary.\n\nIn summary, the modification addresses the vulnerability by ensuring proper buffer handling, memory allocation, and error handling in the `apparmor_setprocattr` function, thereby enhancing the security and robustness of the code.",
      "GPT_purpose": "Set process attributes in the AppArmor security module.",
      "GPT_function": "\n1. Validate buffer size for AppArmor requirements.\n2. Check if the task can only write its own attributes.\n3. Process different commands based on the attribute name and command provided.\n4. Handle specific commands like changehat, permhat, changeprofile, permprofile, and exec.\n5. Generate an audit message in case of failure.",
      "CVE_id": "CVE-2016-6187",
      "code_before_change": "static int apparmor_setprocattr(struct task_struct *task, char *name,\n\t\t\t\tvoid *value, size_t size)\n{\n\tstruct common_audit_data sa;\n\tstruct apparmor_audit_data aad = {0,};\n\tchar *command, *args = value;\n\tsize_t arg_size;\n\tint error;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\t/* args points to a PAGE_SIZE buffer, AppArmor requires that\n\t * the buffer must be null terminated or have size <= PAGE_SIZE -1\n\t * so that AppArmor can null terminate them\n\t */\n\tif (args[size - 1] != '\\0') {\n\t\tif (size == PAGE_SIZE)\n\t\t\treturn -EINVAL;\n\t\targs[size] = '\\0';\n\t}\n\n\t/* task can only write its own attributes */\n\tif (current != task)\n\t\treturn -EACCES;\n\n\targs = value;\n\targs = strim(args);\n\tcommand = strsep(&args, \" \");\n\tif (!args)\n\t\treturn -EINVAL;\n\targs = skip_spaces(args);\n\tif (!*args)\n\t\treturn -EINVAL;\n\n\targ_size = size - (args - (char *) value);\n\tif (strcmp(name, \"current\") == 0) {\n\t\tif (strcmp(command, \"changehat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permhat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t AA_DO_TEST);\n\t\t} else if (strcmp(command, \"changeprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     AA_DO_TEST);\n\t\t} else\n\t\t\tgoto fail;\n\t} else if (strcmp(name, \"exec\") == 0) {\n\t\tif (strcmp(command, \"exec\") == 0)\n\t\t\terror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\telse\n\t\t\tgoto fail;\n\t} else\n\t\t/* only support the \"current\" and \"exec\" process attributes */\n\t\treturn -EINVAL;\n\n\tif (!error)\n\t\terror = size;\n\treturn error;\n\nfail:\n\tsa.type = LSM_AUDIT_DATA_NONE;\n\tsa.aad = &aad;\n\taad.profile = aa_current_profile();\n\taad.op = OP_SETPROCATTR;\n\taad.info = name;\n\taad.error = -EINVAL;\n\taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n\treturn -EINVAL;\n}",
      "code_after_change": "static int apparmor_setprocattr(struct task_struct *task, char *name,\n\t\t\t\tvoid *value, size_t size)\n{\n\tstruct common_audit_data sa;\n\tstruct apparmor_audit_data aad = {0,};\n\tchar *command, *largs = NULL, *args = value;\n\tsize_t arg_size;\n\tint error;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\t/* task can only write its own attributes */\n\tif (current != task)\n\t\treturn -EACCES;\n\n\t/* AppArmor requires that the buffer must be null terminated atm */\n\tif (args[size - 1] != '\\0') {\n\t\t/* null terminate */\n\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);\n\t\tif (!args)\n\t\t\treturn -ENOMEM;\n\t\tmemcpy(args, value, size);\n\t\targs[size] = '\\0';\n\t}\n\n\terror = -EINVAL;\n\targs = strim(args);\n\tcommand = strsep(&args, \" \");\n\tif (!args)\n\t\tgoto out;\n\targs = skip_spaces(args);\n\tif (!*args)\n\t\tgoto out;\n\n\targ_size = size - (args - (char *) value);\n\tif (strcmp(name, \"current\") == 0) {\n\t\tif (strcmp(command, \"changehat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permhat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t AA_DO_TEST);\n\t\t} else if (strcmp(command, \"changeprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     AA_DO_TEST);\n\t\t} else\n\t\t\tgoto fail;\n\t} else if (strcmp(name, \"exec\") == 0) {\n\t\tif (strcmp(command, \"exec\") == 0)\n\t\t\terror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\telse\n\t\t\tgoto fail;\n\t} else\n\t\t/* only support the \"current\" and \"exec\" process attributes */\n\t\tgoto fail;\n\n\tif (!error)\n\t\terror = size;\nout:\n\tkfree(largs);\n\treturn error;\n\nfail:\n\tsa.type = LSM_AUDIT_DATA_NONE;\n\tsa.aad = &aad;\n\taad.profile = aa_current_profile();\n\taad.op = OP_SETPROCATTR;\n\taad.info = name;\n\taad.error = error = -EINVAL;\n\taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n\tgoto out;\n}",
      "modified_lines": {
        "added": [
          "\tchar *command, *largs = NULL, *args = value;",
          "\t/* AppArmor requires that the buffer must be null terminated atm */",
          "\tif (args[size - 1] != '\\0') {",
          "\t\t/* null terminate */",
          "\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);",
          "\t\tif (!args)",
          "\t\t\treturn -ENOMEM;",
          "\t\tmemcpy(args, value, size);",
          "\t\targs[size] = '\\0';",
          "\t}",
          "",
          "\terror = -EINVAL;",
          "\t\tgoto out;",
          "\t\tgoto out;",
          "\t\tgoto fail;",
          "out:",
          "\tkfree(largs);",
          "\taad.error = error = -EINVAL;",
          "\tgoto out;"
        ],
        "deleted": [
          "\tchar *command, *args = value;",
          "\t/* args points to a PAGE_SIZE buffer, AppArmor requires that",
          "\t * the buffer must be null terminated or have size <= PAGE_SIZE -1",
          "\t * so that AppArmor can null terminate them",
          "\t */",
          "\tif (args[size - 1] != '\\0') {",
          "\t\tif (size == PAGE_SIZE)",
          "\t\t\treturn -EINVAL;",
          "\t\targs[size] = '\\0';",
          "\t}",
          "",
          "\targs = value;",
          "\t\treturn -EINVAL;",
          "\t\treturn -EINVAL;",
          "\t\treturn -EINVAL;",
          "\taad.error = -EINVAL;",
          "\treturn -EINVAL;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of buffer size validation in the code handling AppArmor setprocattr hook.",
      "trigger_condition": "Local users can exploit the lack of buffer size validation to gain privileges by triggering the AppArmor setprocattr hook.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the buffer size, allowing the possibility of buffer overflow if the buffer is not null-terminated or exceeds the expected size.",
      "id": 91,
      "code_after_change_normalized": "static int FUN1(struct task_struct *VAR1, char *VAR2,\nvoid *VAR3, size_t VAR4)\n{\nstruct common_audit_data VAR5;\nstruct apparmor_audit_data VAR6 = {0,};\nchar *VAR7, *VAR8 = NULL, *VAR9 = VAR3;\nsize_t VAR10;\nint VAR11;\nif (VAR4 == 0)\nreturn -VAR12;\nif (VAR13 != VAR1)\nreturn -VAR14;\nif (VAR9[VAR4 - 1] != ) {\nVAR8 = VAR9 = FUN2(VAR4 + 1, VAR15);\nif (!VAR9)\nreturn -VAR16;\nFUN3(VAR9, VAR3, VAR4);\nVAR9[VAR4] = ;\n}\nVAR11 = -VAR12;\nVAR9 = FUN4(VAR9);\nVAR7 = FUN5(&VAR9, \"STR\");\nif (!VAR9)\ngoto VAR17;\nVAR9 = FUN6(VAR9);\nif (!*VAR9)\ngoto VAR17;\nVAR10 = VAR4 - (VAR9 - (char *) VAR3);\nif (FUN7(VAR2, \"STR\") == 0) {\nif (FUN7(VAR7, \"STR\") == 0) {\nVAR11 = FUN8(VAR9, VAR10,\n!VAR18);\n} else if (FUN7(VAR7, \"STR\") == 0) {\nVAR11 = FUN8(VAR9, VAR10,\nVAR18);\n} else if (FUN7(VAR7, \"STR\") == 0) {\nVAR11 = FUN9(VAR9, !VAR19,\n!VAR18);\n} else if (FUN7(VAR7, \"STR\") == 0) {\nVAR11 = FUN9(VAR9, !VAR19,\nVAR18);\n} else\ngoto VAR20;\n} else if (FUN7(VAR2, \"STR\") == 0) {\nif (FUN7(VAR7, \"STR\") == 0)\nVAR11 = FUN9(VAR9, VAR19,\n!VAR18);\nelse\ngoto VAR20;\n} else\ngoto VAR20;\nif (!VAR11)\nVAR11 = VAR4;\nVAR17:\nFUN10(VAR8);\nreturn VAR11;\nVAR20:\nVAR5.VAR21 = VAR22;\nVAR5.VAR6 = &VAR6;\nVAR6.VAR23 = FUN11();\nVAR6.VAR24 = VAR25;\nVAR6.VAR26 = VAR2;\nVAR6.VAR11 = VAR11 = -VAR12;\nFUN12(VAR27, &VAR5, NULL);\ngoto VAR17;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct task_struct *VAR1, char *VAR2,\nvoid *VAR3, size_t VAR4)\n{\nstruct common_audit_data VAR5;\nstruct apparmor_audit_data VAR6 = {0,};\nchar *VAR7, *VAR8 = VAR3;\nsize_t VAR9;\nint VAR10;\nif (VAR4 == 0)\nreturn -VAR11;\nif (VAR8[VAR4 - 1] != ) {\nif (VAR4 == VAR12)\nreturn -VAR11;\nVAR8[VAR4] = ;\n}\nif (VAR13 != VAR1)\nreturn -VAR14;\nVAR8 = VAR3;\nVAR8 = FUN2(VAR8);\nVAR7 = FUN3(&VAR8, \"STR\");\nif (!VAR8)\nreturn -VAR11;\nVAR8 = FUN4(VAR8);\nif (!*VAR8)\nreturn -VAR11;\nVAR9 = VAR4 - (VAR8 - (char *) VAR3);\nif (FUN5(VAR2, \"STR\") == 0) {\nif (FUN5(VAR7, \"STR\") == 0) {\nVAR10 = FUN6(VAR8, VAR9,\n!VAR15);\n} else if (FUN5(VAR7, \"STR\") == 0) {\nVAR10 = FUN6(VAR8, VAR9,\nVAR15);\n} else if (FUN5(VAR7, \"STR\") == 0) {\nVAR10 = FUN7(VAR8, !VAR16,\n!VAR15);\n} else if (FUN5(VAR7, \"STR\") == 0) {\nVAR10 = FUN7(VAR8, !VAR16,\nVAR15);\n} else\ngoto VAR17;\n} else if (FUN5(VAR2, \"STR\") == 0) {\nif (FUN5(VAR7, \"STR\") == 0)\nVAR10 = FUN7(VAR8, VAR16,\n!VAR15);\nelse\ngoto VAR17;\n} else\nreturn -VAR11;\nif (!VAR10)\nVAR10 = VAR4;\nreturn VAR10;\nVAR17:\nVAR5.VAR18 = VAR19;\nVAR5.VAR6 = &VAR6;\nVAR6.VAR20 = FUN8();\nVAR6.VAR21 = VAR22;\nVAR6.VAR23 = VAR2;\nVAR6.VAR10 = -VAR11;\nFUN9(VAR24, &VAR5, NULL);\nreturn -VAR11;\n}\n",
      "code_after_change_raw": "static int apparmor_setprocattr(struct task_struct *task, char *name,\nvoid *value, size_t size)\n{\nstruct common_audit_data sa;\nstruct apparmor_audit_data aad = {0,};\nchar *command, *largs = NULL, *args = value;\nsize_t arg_size;\nint error;\nif (size == 0)\nreturn -EINVAL;\nif (current != task)\nreturn -EACCES;\nif (args[size - 1] != '\\0') {\nlargs = args = kmalloc(size + 1, GFP_KERNEL);\nif (!args)\nreturn -ENOMEM;\nmemcpy(args, value, size);\nargs[size] = '\\0';\n}\nerror = -EINVAL;\nargs = strim(args);\ncommand = strsep(&args, \" \");\nif (!args)\ngoto out;\nargs = skip_spaces(args);\nif (!*args)\ngoto out;\narg_size = size - (args - (char *) value);\nif (strcmp(name, \"current\") == 0) {\nif (strcmp(command, \"changehat\") == 0) {\nerror = aa_setprocattr_changehat(args, arg_size,\n!AA_DO_TEST);\n} else if (strcmp(command, \"permhat\") == 0) {\nerror = aa_setprocattr_changehat(args, arg_size,\nAA_DO_TEST);\n} else if (strcmp(command, \"changeprofile\") == 0) {\nerror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n!AA_DO_TEST);\n} else if (strcmp(command, \"permprofile\") == 0) {\nerror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\nAA_DO_TEST);\n} else\ngoto fail;\n} else if (strcmp(name, \"exec\") == 0) {\nif (strcmp(command, \"exec\") == 0)\nerror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n!AA_DO_TEST);\nelse\ngoto fail;\n} else\ngoto fail;\nif (!error)\nerror = size;\nout:\nkfree(largs);\nreturn error;\nfail:\nsa.type = LSM_AUDIT_DATA_NONE;\nsa.aad = &aad;\naad.profile = aa_current_profile();\naad.op = OP_SETPROCATTR;\naad.info = name;\naad.error = error = -EINVAL;\naa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\ngoto out;\n}\n",
      "code_before_change_raw": "static int apparmor_setprocattr(struct task_struct *task, char *name,\nvoid *value, size_t size)\n{\nstruct common_audit_data sa;\nstruct apparmor_audit_data aad = {0,};\nchar *command, *args = value;\nsize_t arg_size;\nint error;\nif (size == 0)\nreturn -EINVAL;\nif (args[size - 1] != '\\0') {\nif (size == PAGE_SIZE)\nreturn -EINVAL;\nargs[size] = '\\0';\n}\nif (current != task)\nreturn -EACCES;\nargs = value;\nargs = strim(args);\ncommand = strsep(&args, \" \");\nif (!args)\nreturn -EINVAL;\nargs = skip_spaces(args);\nif (!*args)\nreturn -EINVAL;\narg_size = size - (args - (char *) value);\nif (strcmp(name, \"current\") == 0) {\nif (strcmp(command, \"changehat\") == 0) {\nerror = aa_setprocattr_changehat(args, arg_size,\n!AA_DO_TEST);\n} else if (strcmp(command, \"permhat\") == 0) {\nerror = aa_setprocattr_changehat(args, arg_size,\nAA_DO_TEST);\n} else if (strcmp(command, \"changeprofile\") == 0) {\nerror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n!AA_DO_TEST);\n} else if (strcmp(command, \"permprofile\") == 0) {\nerror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\nAA_DO_TEST);\n} else\ngoto fail;\n} else if (strcmp(name, \"exec\") == 0) {\nif (strcmp(command, \"exec\") == 0)\nerror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n!AA_DO_TEST);\nelse\ngoto fail;\n} else\nreturn -EINVAL;\nif (!error)\nerror = size;\nreturn error;\nfail:\nsa.type = LSM_AUDIT_DATA_NONE;\nsa.aad = &aad;\naad.profile = aa_current_profile();\naad.op = OP_SETPROCATTR;\naad.info = name;\naad.error = -EINVAL;\naa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\nreturn -EINVAL;\n}\n"
    }
  ],
  "CVE-2016-6516": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of synchronization and validation of user input data in a critical code path.",
        "trigger_condition": "A race condition occurs when a user-supplied value is fetched from user space and used for memory allocation without proper validation, allowing a malicious user to change the value between fetch and use.",
        "specific_code_behavior_causing_vulnerability": "The code fetches a user-supplied value and uses it to calculate the size for memory allocation without ensuring the value remains unchanged, leading to a potential heap-based buffer overflow vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure the user-supplied value remains consistent and unaltered between fetch and use. This can be achieved by storing the user-supplied value in a separate variable after fetching and before using it for memory allocation. In this case, the solution involves adding a line to assign the fetched value to a specific field in the data structure before proceeding with memory allocation, thereby preventing the race condition and potential buffer overflow.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2016-6516, which is a race condition leading to a double fetch vulnerability. In the original code, the 'count' value is fetched from user space and used to calculate the size for memory allocation. However, there is a window of opportunity for a malicious user to change the 'count' value after the initial fetch but before the memory allocation, leading to a heap-based buffer overflow.\n\nBy adding the line 'same->dest_count = count;' after fetching the 'count' value and before using it to calculate the size for memory allocation, the modified code ensures that the 'count' value is not changed between the fetch and the use, thus preventing the race condition and the associated vulnerability. This modification ensures that the 'count' value used for memory allocation is consistent and not tampered with by an attacker, thereby enhancing the security of the code.",
      "GPT_purpose": "This function is used to deduplicate ranges of a file by handling ioctl requests.",
      "GPT_function": "\n1. Perform an ioctl operation on a file for deduplication.\n2. Retrieve the count value from user space.\n3. Allocate memory and copy user data into the allocated memory.\n4. Perform file deduplication operation using vfs_dedupe_file_range.\n5. Copy the deduplicated data back to user space.\n6. Free the allocated memory before returning.",
      "CVE_id": "CVE-2016-6516",
      "code_before_change": "static long ioctl_file_dedupe_range(struct file *file, void __user *arg)\n{\n\tstruct file_dedupe_range __user *argp = arg;\n\tstruct file_dedupe_range *same = NULL;\n\tint ret;\n\tunsigned long size;\n\tu16 count;\n\n\tif (get_user(count, &argp->dest_count)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tsize = offsetof(struct file_dedupe_range __user, info[count]);\n\n\tsame = memdup_user(argp, size);\n\tif (IS_ERR(same)) {\n\t\tret = PTR_ERR(same);\n\t\tsame = NULL;\n\t\tgoto out;\n\t}\n\n\tret = vfs_dedupe_file_range(file, same);\n\tif (ret)\n\t\tgoto out;\n\n\tret = copy_to_user(argp, same, size);\n\tif (ret)\n\t\tret = -EFAULT;\n\nout:\n\tkfree(same);\n\treturn ret;\n}",
      "code_after_change": "static long ioctl_file_dedupe_range(struct file *file, void __user *arg)\n{\n\tstruct file_dedupe_range __user *argp = arg;\n\tstruct file_dedupe_range *same = NULL;\n\tint ret;\n\tunsigned long size;\n\tu16 count;\n\n\tif (get_user(count, &argp->dest_count)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tsize = offsetof(struct file_dedupe_range __user, info[count]);\n\n\tsame = memdup_user(argp, size);\n\tif (IS_ERR(same)) {\n\t\tret = PTR_ERR(same);\n\t\tsame = NULL;\n\t\tgoto out;\n\t}\n\n\tsame->dest_count = count;\n\tret = vfs_dedupe_file_range(file, same);\n\tif (ret)\n\t\tgoto out;\n\n\tret = copy_to_user(argp, same, size);\n\tif (ret)\n\t\tret = -EFAULT;\n\nout:\n\tkfree(same);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tsame->dest_count = count;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of synchronization and validation of user input data in a critical code path.",
      "trigger_condition": "A race condition occurs when a user-supplied value is fetched from user space and used for memory allocation without proper validation, allowing a malicious user to change the value between fetch and use.",
      "specific_code_behavior_causing_vulnerability": "The code fetches a user-supplied value and uses it to calculate the size for memory allocation without ensuring the value remains unchanged, leading to a potential heap-based buffer overflow vulnerability.",
      "id": 92,
      "code_after_change_normalized": "static long FUN1(struct VAR1 *VAR1, void __user *VAR2)\n{\nstruct file_dedupe_range __user *VAR3 = VAR2;\nstruct file_dedupe_range *VAR4 = NULL;\nint VAR5;\nunsigned long VAR6;\nu16 VAR7;\nif (FUN2(VAR7, &VAR3->VAR8)) {\nVAR5 = -VAR9;\ngoto VAR10;\n}\nVAR6 = FUN3(struct file_dedupe_range VAR11, VAR12[VAR7]);\nVAR4 = FUN4(VAR3, VAR6);\nif (FUN5(VAR4)) {\nVAR5 = FUN6(VAR4);\nVAR4 = NULL;\ngoto VAR10;\n}\nVAR4->VAR8 = VAR7;\nVAR5 = FUN7(VAR1, VAR4);\nif (VAR5)\ngoto VAR10;\nVAR5 = FUN8(VAR3, VAR4, VAR6);\nif (VAR5)\nVAR5 = -VAR9;\nVAR10:\nFUN9(VAR4);\nreturn VAR5;\n}\n",
      "code_before_change_normalized": "static long FUN1(struct VAR1 *VAR1, void __user *VAR2)\n{\nstruct file_dedupe_range __user *VAR3 = VAR2;\nstruct file_dedupe_range *VAR4 = NULL;\nint VAR5;\nunsigned long VAR6;\nu16 VAR7;\nif (FUN2(VAR7, &VAR3->VAR8)) {\nVAR5 = -VAR9;\ngoto VAR10;\n}\nVAR6 = FUN3(struct file_dedupe_range VAR11, VAR12[VAR7]);\nVAR4 = FUN4(VAR3, VAR6);\nif (FUN5(VAR4)) {\nVAR5 = FUN6(VAR4);\nVAR4 = NULL;\ngoto VAR10;\n}\nVAR5 = FUN7(VAR1, VAR4);\nif (VAR5)\ngoto VAR10;\nVAR5 = FUN8(VAR3, VAR4, VAR6);\nif (VAR5)\nVAR5 = -VAR9;\nVAR10:\nFUN9(VAR4);\nreturn VAR5;\n}\n",
      "code_after_change_raw": "static long ioctl_file_dedupe_range(struct file *file, void __user *arg)\n{\nstruct file_dedupe_range __user *argp = arg;\nstruct file_dedupe_range *same = NULL;\nint ret;\nunsigned long size;\nu16 count;\nif (get_user(count, &argp->dest_count)) {\nret = -EFAULT;\ngoto out;\n}\nsize = offsetof(struct file_dedupe_range __user, info[count]);\nsame = memdup_user(argp, size);\nif (IS_ERR(same)) {\nret = PTR_ERR(same);\nsame = NULL;\ngoto out;\n}\nsame->dest_count = count;\nret = vfs_dedupe_file_range(file, same);\nif (ret)\ngoto out;\nret = copy_to_user(argp, same, size);\nif (ret)\nret = -EFAULT;\nout:\nkfree(same);\nreturn ret;\n}\n",
      "code_before_change_raw": "static long ioctl_file_dedupe_range(struct file *file, void __user *arg)\n{\nstruct file_dedupe_range __user *argp = arg;\nstruct file_dedupe_range *same = NULL;\nint ret;\nunsigned long size;\nu16 count;\nif (get_user(count, &argp->dest_count)) {\nret = -EFAULT;\ngoto out;\n}\nsize = offsetof(struct file_dedupe_range __user, info[count]);\nsame = memdup_user(argp, size);\nif (IS_ERR(same)) {\nret = PTR_ERR(same);\nsame = NULL;\ngoto out;\n}\nret = vfs_dedupe_file_range(file, same);\nif (ret)\ngoto out;\nret = copy_to_user(argp, same, size);\nif (ret)\nret = -EFAULT;\nout:\nkfree(same);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2016-7042": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect buffer size allocation for storing timeout data in a specific function.",
        "trigger_condition": "When the GNU Compiler Collection (gcc) stack protector is enabled and the code writes more data than the allocated buffer size for storing timeout information.",
        "specific_code_behavior_causing_vulnerability": "The code snippet defines a buffer with insufficient size to hold the formatted timeout value, leading to a stack memory corruption vulnerability when writing data beyond the buffer boundaries."
      },
      "solution": "To mitigate the vulnerability, it is necessary to adjust the buffer size allocation to ensure it can accommodate the maximum expected length of the timeout value. In this case, increasing the buffer size to 16 bytes prevents stack memory corruption and denial of service attacks caused by writing data beyond the buffer boundaries.",
      "GPT_analysis": "The modification is necessary to fix a vulnerability in the code snippet related to an incorrect buffer size for certain timeout data. The vulnerability, identified as CVE-2016-7042, occurs when the GNU Compiler Collection (gcc) stack protector is enabled. In the original code snippet, the buffer size for the `xbuf` array is defined as 12 bytes:\n\n```c\nchar xbuf[12];\n```\n\nHowever, in the vulnerable scenario, the code writes more than 12 bytes to the `xbuf` array when formatting the timeout value. This can lead to stack memory corruption and potentially a denial of service when reading the `/proc/keys` file.\n\nTo address this vulnerability, the buffer size for the `xbuf` array should be increased to accommodate the maximum expected length of the timeout value. By changing the buffer size to 16 bytes in the modified code snippet:\n\n```c\nchar xbuf[16];\n```\n\nThe code ensures that the buffer is large enough to hold the formatted timeout value without exceeding its boundaries, thereby preventing stack memory corruption and potential denial of service attacks.",
      "GPT_purpose": "Display information about keys in the Linux kernel.",
      "GPT_function": "\n1. Display information about keys in the /proc/keys file.\n2. Check possession of keys by the current process.\n3. Determine timeout values for keys based on expiry time.\n4. Print key information including serial number, flags, usage, timeout, permissions, user ID, group ID, and key type.",
      "CVE_id": "CVE-2016-7042",
      "code_before_change": "static int proc_keys_show(struct seq_file *m, void *v)\n{\n\tstruct rb_node *_p = v;\n\tstruct key *key = rb_entry(_p, struct key, serial_node);\n\tstruct timespec now;\n\tunsigned long timo;\n\tkey_ref_t key_ref, skey_ref;\n\tchar xbuf[12];\n\tint rc;\n\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= key->type,\n\t\t.index_key.description\t= key->description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= lookup_user_key_possessed,\n\t\t.match_data.raw_data\t= key,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t\t.flags\t\t\t= KEYRING_SEARCH_NO_STATE_CHECK,\n\t};\n\n\tkey_ref = make_key_ref(key, 0);\n\n\t/* determine if the key is possessed by this process (a test we can\n\t * skip if the key does not indicate the possessor can view it\n\t */\n\tif (key->perm & KEY_POS_VIEW) {\n\t\tskey_ref = search_my_process_keyrings(&ctx);\n\t\tif (!IS_ERR(skey_ref)) {\n\t\t\tkey_ref_put(skey_ref);\n\t\t\tkey_ref = make_key_ref(key, 1);\n\t\t}\n\t}\n\n\t/* check whether the current task is allowed to view the key (assuming\n\t * non-possession)\n\t * - the caller holds a spinlock, and thus the RCU read lock, making our\n\t *   access to __current_cred() safe\n\t */\n\trc = key_task_permission(key_ref, ctx.cred, KEY_NEED_VIEW);\n\tif (rc < 0)\n\t\treturn 0;\n\n\tnow = current_kernel_time();\n\n\trcu_read_lock();\n\n\t/* come up with a suitable timeout value */\n\tif (key->expiry == 0) {\n\t\tmemcpy(xbuf, \"perm\", 5);\n\t} else if (now.tv_sec >= key->expiry) {\n\t\tmemcpy(xbuf, \"expd\", 5);\n\t} else {\n\t\ttimo = key->expiry - now.tv_sec;\n\n\t\tif (timo < 60)\n\t\t\tsprintf(xbuf, \"%lus\", timo);\n\t\telse if (timo < 60*60)\n\t\t\tsprintf(xbuf, \"%lum\", timo / 60);\n\t\telse if (timo < 60*60*24)\n\t\t\tsprintf(xbuf, \"%luh\", timo / (60*60));\n\t\telse if (timo < 60*60*24*7)\n\t\t\tsprintf(xbuf, \"%lud\", timo / (60*60*24));\n\t\telse\n\t\t\tsprintf(xbuf, \"%luw\", timo / (60*60*24*7));\n\t}\n\n#define showflag(KEY, LETTER, FLAG) \\\n\t(test_bit(FLAG,\t&(KEY)->flags) ? LETTER : '-')\n\n\tseq_printf(m, \"%08x %c%c%c%c%c%c%c %5d %4s %08x %5d %5d %-9.9s \",\n\t\t   key->serial,\n\t\t   showflag(key, 'I', KEY_FLAG_INSTANTIATED),\n\t\t   showflag(key, 'R', KEY_FLAG_REVOKED),\n\t\t   showflag(key, 'D', KEY_FLAG_DEAD),\n\t\t   showflag(key, 'Q', KEY_FLAG_IN_QUOTA),\n\t\t   showflag(key, 'U', KEY_FLAG_USER_CONSTRUCT),\n\t\t   showflag(key, 'N', KEY_FLAG_NEGATIVE),\n\t\t   showflag(key, 'i', KEY_FLAG_INVALIDATED),\n\t\t   atomic_read(&key->usage),\n\t\t   xbuf,\n\t\t   key->perm,\n\t\t   from_kuid_munged(seq_user_ns(m), key->uid),\n\t\t   from_kgid_munged(seq_user_ns(m), key->gid),\n\t\t   key->type->name);\n\n#undef showflag\n\n\tif (key->type->describe)\n\t\tkey->type->describe(key, m);\n\tseq_putc(m, '\\n');\n\n\trcu_read_unlock();\n\treturn 0;\n}",
      "code_after_change": "static int proc_keys_show(struct seq_file *m, void *v)\n{\n\tstruct rb_node *_p = v;\n\tstruct key *key = rb_entry(_p, struct key, serial_node);\n\tstruct timespec now;\n\tunsigned long timo;\n\tkey_ref_t key_ref, skey_ref;\n\tchar xbuf[16];\n\tint rc;\n\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= key->type,\n\t\t.index_key.description\t= key->description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= lookup_user_key_possessed,\n\t\t.match_data.raw_data\t= key,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t\t.flags\t\t\t= KEYRING_SEARCH_NO_STATE_CHECK,\n\t};\n\n\tkey_ref = make_key_ref(key, 0);\n\n\t/* determine if the key is possessed by this process (a test we can\n\t * skip if the key does not indicate the possessor can view it\n\t */\n\tif (key->perm & KEY_POS_VIEW) {\n\t\tskey_ref = search_my_process_keyrings(&ctx);\n\t\tif (!IS_ERR(skey_ref)) {\n\t\t\tkey_ref_put(skey_ref);\n\t\t\tkey_ref = make_key_ref(key, 1);\n\t\t}\n\t}\n\n\t/* check whether the current task is allowed to view the key (assuming\n\t * non-possession)\n\t * - the caller holds a spinlock, and thus the RCU read lock, making our\n\t *   access to __current_cred() safe\n\t */\n\trc = key_task_permission(key_ref, ctx.cred, KEY_NEED_VIEW);\n\tif (rc < 0)\n\t\treturn 0;\n\n\tnow = current_kernel_time();\n\n\trcu_read_lock();\n\n\t/* come up with a suitable timeout value */\n\tif (key->expiry == 0) {\n\t\tmemcpy(xbuf, \"perm\", 5);\n\t} else if (now.tv_sec >= key->expiry) {\n\t\tmemcpy(xbuf, \"expd\", 5);\n\t} else {\n\t\ttimo = key->expiry - now.tv_sec;\n\n\t\tif (timo < 60)\n\t\t\tsprintf(xbuf, \"%lus\", timo);\n\t\telse if (timo < 60*60)\n\t\t\tsprintf(xbuf, \"%lum\", timo / 60);\n\t\telse if (timo < 60*60*24)\n\t\t\tsprintf(xbuf, \"%luh\", timo / (60*60));\n\t\telse if (timo < 60*60*24*7)\n\t\t\tsprintf(xbuf, \"%lud\", timo / (60*60*24));\n\t\telse\n\t\t\tsprintf(xbuf, \"%luw\", timo / (60*60*24*7));\n\t}\n\n#define showflag(KEY, LETTER, FLAG) \\\n\t(test_bit(FLAG,\t&(KEY)->flags) ? LETTER : '-')\n\n\tseq_printf(m, \"%08x %c%c%c%c%c%c%c %5d %4s %08x %5d %5d %-9.9s \",\n\t\t   key->serial,\n\t\t   showflag(key, 'I', KEY_FLAG_INSTANTIATED),\n\t\t   showflag(key, 'R', KEY_FLAG_REVOKED),\n\t\t   showflag(key, 'D', KEY_FLAG_DEAD),\n\t\t   showflag(key, 'Q', KEY_FLAG_IN_QUOTA),\n\t\t   showflag(key, 'U', KEY_FLAG_USER_CONSTRUCT),\n\t\t   showflag(key, 'N', KEY_FLAG_NEGATIVE),\n\t\t   showflag(key, 'i', KEY_FLAG_INVALIDATED),\n\t\t   atomic_read(&key->usage),\n\t\t   xbuf,\n\t\t   key->perm,\n\t\t   from_kuid_munged(seq_user_ns(m), key->uid),\n\t\t   from_kgid_munged(seq_user_ns(m), key->gid),\n\t\t   key->type->name);\n\n#undef showflag\n\n\tif (key->type->describe)\n\t\tkey->type->describe(key, m);\n\tseq_putc(m, '\\n');\n\n\trcu_read_unlock();\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tchar xbuf[16];"
        ],
        "deleted": [
          "\tchar xbuf[12];"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect buffer size allocation for storing timeout data in a specific function.",
      "trigger_condition": "When the GNU Compiler Collection (gcc) stack protector is enabled and the code writes more data than the allocated buffer size for storing timeout information.",
      "specific_code_behavior_causing_vulnerability": "The code snippet defines a buffer with insufficient size to hold the formatted timeout value, leading to a stack memory corruption vulnerability when writing data beyond the buffer boundaries.",
      "id": 93,
      "code_after_change_normalized": "static int FUN1(struct seq_file *VAR1, void *VAR2)\n{\nstruct rb_node *VAR3 = VAR2;\nstruct VAR4 *VAR4 = FUN2(VAR3, struct VAR4, VAR5);\nstruct timespec VAR6;\nunsigned long VAR7;\nkey_ref_t VAR8, VAR9;\nchar VAR10[16];\nint VAR11;\nstruct keyring_search_context VAR12 = {\n.VAR13.VAR14\t\t= VAR4->VAR14,\n.VAR13.VAR15\t= VAR4->VAR15,\n.VAR16\t\t\t= FUN3(),\n.VAR17.VAR18\t\t= VAR19,\n.VAR17.VAR20\t= VAR4,\n.VAR17.VAR21\t= VAR22,\n.VAR23\t\t\t= VAR24,\n};\nVAR8 = FUN4(VAR4, 0);\nif (VAR4->VAR25 & VAR26) {\nVAR9 = FUN5(&VAR12);\nif (!FUN6(VAR9)) {\nFUN7(VAR9);\nVAR8 = FUN4(VAR4, 1);\n}\n}\nVAR11 = FUN8(VAR8, VAR12.VAR16, VAR27);\nif (VAR11 < 0)\nreturn 0;\nVAR6 = FUN9();\nFUN10();\nif (VAR4->VAR28 == 0) {\nFUN11(VAR10, \"STR\", 5);\n} else if (VAR6.VAR29 >= VAR4->VAR28) {\nFUN11(VAR10, \"STR\", 5);\n} else {\nVAR7 = VAR4->VAR28 - VAR6.VAR29;\nif (VAR7 < 60)\nFUN12(VAR10, \"STR\", VAR7);\nelse if (VAR7 < 60*60)\nFUN12(VAR10, \"STR\", VAR7 / 60);\nelse if (VAR7 < 60*60*24)\nFUN12(VAR10, \"STR\", VAR7 / (60*60));\nelse if (VAR7 < 60*60*24*7)\nFUN12(VAR10, \"STR\", VAR7 / (60*60*24));\nelse\nFUN12(VAR10, \"STR\", VAR7 / (60*60*24*7));\n}\n#define FUN13(VAR30, VAR31, VAR32) \\\n(FUN14(VAR32,\t&(VAR30)->VAR23) ? VAR31 : )\nFUN15(VAR1, \"STR\",\nVAR4->VAR33,\nFUN13(VAR4, , VAR34),\nFUN13(VAR4, , VAR35),\nFUN13(VAR4, , VAR36),\nFUN13(VAR4, , VAR37),\nFUN13(VAR4, , VAR38),\nFUN13(VAR4, , VAR39),\nFUN13(VAR4, , VAR40),\nFUN16(&VAR4->VAR41),\nVAR10,\nVAR4->VAR25,\nFUN17(FUN18(VAR1), VAR4->VAR42),\nFUN19(FUN18(VAR1), VAR4->VAR43),\nVAR4->VAR14->VAR44);\n#undef VAR45\nif (VAR4->VAR14->VAR46)\nVAR4->VAR14->FUN20(VAR4, VAR1);\nFUN21(VAR1, );\nFUN22();\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct seq_file *VAR1, void *VAR2)\n{\nstruct rb_node *VAR3 = VAR2;\nstruct VAR4 *VAR4 = FUN2(VAR3, struct VAR4, VAR5);\nstruct timespec VAR6;\nunsigned long VAR7;\nkey_ref_t VAR8, VAR9;\nchar VAR10[12];\nint VAR11;\nstruct keyring_search_context VAR12 = {\n.VAR13.VAR14\t\t= VAR4->VAR14,\n.VAR13.VAR15\t= VAR4->VAR15,\n.VAR16\t\t\t= FUN3(),\n.VAR17.VAR18\t\t= VAR19,\n.VAR17.VAR20\t= VAR4,\n.VAR17.VAR21\t= VAR22,\n.VAR23\t\t\t= VAR24,\n};\nVAR8 = FUN4(VAR4, 0);\nif (VAR4->VAR25 & VAR26) {\nVAR9 = FUN5(&VAR12);\nif (!FUN6(VAR9)) {\nFUN7(VAR9);\nVAR8 = FUN4(VAR4, 1);\n}\n}\nVAR11 = FUN8(VAR8, VAR12.VAR16, VAR27);\nif (VAR11 < 0)\nreturn 0;\nVAR6 = FUN9();\nFUN10();\nif (VAR4->VAR28 == 0) {\nFUN11(VAR10, \"STR\", 5);\n} else if (VAR6.VAR29 >= VAR4->VAR28) {\nFUN11(VAR10, \"STR\", 5);\n} else {\nVAR7 = VAR4->VAR28 - VAR6.VAR29;\nif (VAR7 < 60)\nFUN12(VAR10, \"STR\", VAR7);\nelse if (VAR7 < 60*60)\nFUN12(VAR10, \"STR\", VAR7 / 60);\nelse if (VAR7 < 60*60*24)\nFUN12(VAR10, \"STR\", VAR7 / (60*60));\nelse if (VAR7 < 60*60*24*7)\nFUN12(VAR10, \"STR\", VAR7 / (60*60*24));\nelse\nFUN12(VAR10, \"STR\", VAR7 / (60*60*24*7));\n}\n#define FUN13(VAR30, VAR31, VAR32) \\\n(FUN14(VAR32,\t&(VAR30)->VAR23) ? VAR31 : )\nFUN15(VAR1, \"STR\",\nVAR4->VAR33,\nFUN13(VAR4, , VAR34),\nFUN13(VAR4, , VAR35),\nFUN13(VAR4, , VAR36),\nFUN13(VAR4, , VAR37),\nFUN13(VAR4, , VAR38),\nFUN13(VAR4, , VAR39),\nFUN13(VAR4, , VAR40),\nFUN16(&VAR4->VAR41),\nVAR10,\nVAR4->VAR25,\nFUN17(FUN18(VAR1), VAR4->VAR42),\nFUN19(FUN18(VAR1), VAR4->VAR43),\nVAR4->VAR14->VAR44);\n#undef VAR45\nif (VAR4->VAR14->VAR46)\nVAR4->VAR14->FUN20(VAR4, VAR1);\nFUN21(VAR1, );\nFUN22();\nreturn 0;\n}\n",
      "code_after_change_raw": "static int proc_keys_show(struct seq_file *m, void *v)\n{\nstruct rb_node *_p = v;\nstruct key *key = rb_entry(_p, struct key, serial_node);\nstruct timespec now;\nunsigned long timo;\nkey_ref_t key_ref, skey_ref;\nchar xbuf[16];\nint rc;\nstruct keyring_search_context ctx = {\n.index_key.type\t\t= key->type,\n.index_key.description\t= key->description,\n.cred\t\t\t= current_cred(),\n.match_data.cmp\t\t= lookup_user_key_possessed,\n.match_data.raw_data\t= key,\n.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n.flags\t\t\t= KEYRING_SEARCH_NO_STATE_CHECK,\n};\nkey_ref = make_key_ref(key, 0);\nif (key->perm & KEY_POS_VIEW) {\nskey_ref = search_my_process_keyrings(&ctx);\nif (!IS_ERR(skey_ref)) {\nkey_ref_put(skey_ref);\nkey_ref = make_key_ref(key, 1);\n}\n}\nrc = key_task_permission(key_ref, ctx.cred, KEY_NEED_VIEW);\nif (rc < 0)\nreturn 0;\nnow = current_kernel_time();\nrcu_read_lock();\nif (key->expiry == 0) {\nmemcpy(xbuf, \"perm\", 5);\n} else if (now.tv_sec >= key->expiry) {\nmemcpy(xbuf, \"expd\", 5);\n} else {\ntimo = key->expiry - now.tv_sec;\nif (timo < 60)\nsprintf(xbuf, \"%lus\", timo);\nelse if (timo < 60*60)\nsprintf(xbuf, \"%lum\", timo / 60);\nelse if (timo < 60*60*24)\nsprintf(xbuf, \"%luh\", timo / (60*60));\nelse if (timo < 60*60*24*7)\nsprintf(xbuf, \"%lud\", timo / (60*60*24));\nelse\nsprintf(xbuf, \"%luw\", timo / (60*60*24*7));\n}\n#define showflag(KEY, LETTER, FLAG) \\\n(test_bit(FLAG,\t&(KEY)->flags) ? LETTER : '-')\nseq_printf(m, \"%08x %c%c%c%c%c%c%c %5d %4s %08x %5d %5d %-9.9s \",\nkey->serial,\nshowflag(key, 'I', KEY_FLAG_INSTANTIATED),\nshowflag(key, 'R', KEY_FLAG_REVOKED),\nshowflag(key, 'D', KEY_FLAG_DEAD),\nshowflag(key, 'Q', KEY_FLAG_IN_QUOTA),\nshowflag(key, 'U', KEY_FLAG_USER_CONSTRUCT),\nshowflag(key, 'N', KEY_FLAG_NEGATIVE),\nshowflag(key, 'i', KEY_FLAG_INVALIDATED),\natomic_read(&key->usage),\nxbuf,\nkey->perm,\nfrom_kuid_munged(seq_user_ns(m), key->uid),\nfrom_kgid_munged(seq_user_ns(m), key->gid),\nkey->type->name);\n#undef showflag\nif (key->type->describe)\nkey->type->describe(key, m);\nseq_putc(m, '\\n');\nrcu_read_unlock();\nreturn 0;\n}\n",
      "code_before_change_raw": "static int proc_keys_show(struct seq_file *m, void *v)\n{\nstruct rb_node *_p = v;\nstruct key *key = rb_entry(_p, struct key, serial_node);\nstruct timespec now;\nunsigned long timo;\nkey_ref_t key_ref, skey_ref;\nchar xbuf[12];\nint rc;\nstruct keyring_search_context ctx = {\n.index_key.type\t\t= key->type,\n.index_key.description\t= key->description,\n.cred\t\t\t= current_cred(),\n.match_data.cmp\t\t= lookup_user_key_possessed,\n.match_data.raw_data\t= key,\n.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n.flags\t\t\t= KEYRING_SEARCH_NO_STATE_CHECK,\n};\nkey_ref = make_key_ref(key, 0);\nif (key->perm & KEY_POS_VIEW) {\nskey_ref = search_my_process_keyrings(&ctx);\nif (!IS_ERR(skey_ref)) {\nkey_ref_put(skey_ref);\nkey_ref = make_key_ref(key, 1);\n}\n}\nrc = key_task_permission(key_ref, ctx.cred, KEY_NEED_VIEW);\nif (rc < 0)\nreturn 0;\nnow = current_kernel_time();\nrcu_read_lock();\nif (key->expiry == 0) {\nmemcpy(xbuf, \"perm\", 5);\n} else if (now.tv_sec >= key->expiry) {\nmemcpy(xbuf, \"expd\", 5);\n} else {\ntimo = key->expiry - now.tv_sec;\nif (timo < 60)\nsprintf(xbuf, \"%lus\", timo);\nelse if (timo < 60*60)\nsprintf(xbuf, \"%lum\", timo / 60);\nelse if (timo < 60*60*24)\nsprintf(xbuf, \"%luh\", timo / (60*60));\nelse if (timo < 60*60*24*7)\nsprintf(xbuf, \"%lud\", timo / (60*60*24));\nelse\nsprintf(xbuf, \"%luw\", timo / (60*60*24*7));\n}\n#define showflag(KEY, LETTER, FLAG) \\\n(test_bit(FLAG,\t&(KEY)->flags) ? LETTER : '-')\nseq_printf(m, \"%08x %c%c%c%c%c%c%c %5d %4s %08x %5d %5d %-9.9s \",\nkey->serial,\nshowflag(key, 'I', KEY_FLAG_INSTANTIATED),\nshowflag(key, 'R', KEY_FLAG_REVOKED),\nshowflag(key, 'D', KEY_FLAG_DEAD),\nshowflag(key, 'Q', KEY_FLAG_IN_QUOTA),\nshowflag(key, 'U', KEY_FLAG_USER_CONSTRUCT),\nshowflag(key, 'N', KEY_FLAG_NEGATIVE),\nshowflag(key, 'i', KEY_FLAG_INVALIDATED),\natomic_read(&key->usage),\nxbuf,\nkey->perm,\nfrom_kuid_munged(seq_user_ns(m), key->uid),\nfrom_kgid_munged(seq_user_ns(m), key->gid),\nkey->type->name);\n#undef showflag\nif (key->type->describe)\nkey->type->describe(key, m);\nseq_putc(m, '\\n');\nrcu_read_unlock();\nreturn 0;\n}\n"
    }
  ],
  "CVE-2016-7425": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation on the user_len variable representing the length of data being copied into a buffer.",
        "trigger_condition": "An attacker provides a user_len value larger than the allocated buffer size, leading to a buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the user_len variable against the maximum buffer size before copying data into the buffer, allowing a potential buffer overflow if the user_len exceeds the buffer size."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a validation check on the user_len variable to ensure it does not exceed the maximum buffer size before proceeding with the data copy operation. By adding this validation step, the code can prevent buffer overflow vulnerabilities caused by copying data larger than the allocated buffer size.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-7425, which allows local users to gain privileges or cause a denial of service (heap-based buffer overflow) via an ARCMSR_MESSAGE_WRITE_WQBUFFER control code. \n\nThe vulnerability arises from the lack of validation on the user_len variable, which represents the length of the data being copied into the buffer. Without proper validation, an attacker could provide a user_len value larger than the allocated buffer size (ARCMSR_API_DATA_BUFLEN), leading to a buffer overflow.\n\nBy adding the following lines to the code:\n'''\nif (user_len > ARCMSR_API_DATA_BUFLEN) {\n    retvalue = ARCMSR_MESSAGE_FAIL;\n    kfree(ver_addr);\n    goto message_out;\n}\n'''\nwe ensure that the user_len value is checked against the maximum buffer size before proceeding with the data copy operation. If the user_len exceeds the buffer size, the function will return an error and prevent the buffer overflow vulnerability from being exploited. \n\nThis modification helps to mitigate the security risk posed by the vulnerability and enhances the overall security of the code.",
      "GPT_purpose": "This function handles message transfers between the AdapterControlBlock and a SCSI command in the arcmsr driver, specifically for read and write operations on message buffers.",
      "GPT_function": "\n1. Transfer messages between the AdapterControlBlock and a SCSI command.\n2. Handle different control codes such as reading, writing, and clearing buffers.\n3. Manage buffer transfers and locking mechanisms.\n4. Handle specific control codes like saying hello, saying goodbye, and flushing the adapter cache.\n5. Handle unknown control codes and potential error conditions.",
      "CVE_id": "CVE-2016-7425",
      "code_before_change": "static int arcmsr_iop_message_xfer(struct AdapterControlBlock *acb,\n\t\tstruct scsi_cmnd *cmd)\n{\n\tchar *buffer;\n\tunsigned short use_sg;\n\tint retvalue = 0, transfer_len = 0;\n\tunsigned long flags;\n\tstruct CMD_MESSAGE_FIELD *pcmdmessagefld;\n\tuint32_t controlcode = (uint32_t)cmd->cmnd[5] << 24 |\n\t\t(uint32_t)cmd->cmnd[6] << 16 |\n\t\t(uint32_t)cmd->cmnd[7] << 8 |\n\t\t(uint32_t)cmd->cmnd[8];\n\tstruct scatterlist *sg;\n\n\tuse_sg = scsi_sg_count(cmd);\n\tsg = scsi_sglist(cmd);\n\tbuffer = kmap_atomic(sg_page(sg)) + sg->offset;\n\tif (use_sg > 1) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tgoto message_out;\n\t}\n\ttransfer_len += sg->length;\n\tif (transfer_len > sizeof(struct CMD_MESSAGE_FIELD)) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: ARCMSR_MESSAGE_FAIL!\\n\", __func__);\n\t\tgoto message_out;\n\t}\n\tpcmdmessagefld = (struct CMD_MESSAGE_FIELD *)buffer;\n\tswitch (controlcode) {\n\tcase ARCMSR_MESSAGE_READ_RQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tuint8_t *ptmpQbuffer;\n\t\tuint32_t allxfer_len = 0;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tpr_info(\"%s: memory not enough!\\n\", __func__);\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpQbuffer = ver_addr;\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tif (acb->rqbuf_getIndex != acb->rqbuf_putIndex) {\n\t\t\tunsigned int tail = acb->rqbuf_getIndex;\n\t\t\tunsigned int head = acb->rqbuf_putIndex;\n\t\t\tunsigned int cnt_to_end = CIRC_CNT_TO_END(head, tail, ARCMSR_MAX_QBUFFER);\n\n\t\t\tallxfer_len = CIRC_CNT(head, tail, ARCMSR_MAX_QBUFFER);\n\t\t\tif (allxfer_len > ARCMSR_API_DATA_BUFLEN)\n\t\t\t\tallxfer_len = ARCMSR_API_DATA_BUFLEN;\n\n\t\t\tif (allxfer_len <= cnt_to_end)\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, allxfer_len);\n\t\t\telse {\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, cnt_to_end);\n\t\t\t\tmemcpy(ptmpQbuffer + cnt_to_end, acb->rqbuffer, allxfer_len - cnt_to_end);\n\t\t\t}\n\t\t\tacb->rqbuf_getIndex = (acb->rqbuf_getIndex + allxfer_len) % ARCMSR_MAX_QBUFFER;\n\t\t}\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer, ver_addr,\n\t\t\tallxfer_len);\n\t\tif (acb->acb_flags & ACB_F_IOPDATA_OVERFLOW) {\n\t\t\tstruct QBUFFER __iomem *prbuffer;\n\t\t\tacb->acb_flags &= ~ACB_F_IOPDATA_OVERFLOW;\n\t\t\tprbuffer = arcmsr_get_iop_rqbuffer(acb);\n\t\t\tif (arcmsr_Read_iop_rqbuffer_data(acb, prbuffer) == 0)\n\t\t\t\tacb->acb_flags |= ACB_F_IOPDATA_OVERFLOW;\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tpcmdmessagefld->cmdmessage.Length = allxfer_len;\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_WRITE_WQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tint32_t user_len, cnt2end;\n\t\tuint8_t *pQbuffer, *ptmpuserbuffer;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpuserbuffer = ver_addr;\n\t\tuser_len = pcmdmessagefld->cmdmessage.Length;\n\t\tmemcpy(ptmpuserbuffer,\n\t\t\tpcmdmessagefld->messagedatabuffer, user_len);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tif (acb->wqbuf_putIndex != acb->wqbuf_getIndex) {\n\t\t\tstruct SENSE_DATA *sensebuffer =\n\t\t\t\t(struct SENSE_DATA *)cmd->sense_buffer;\n\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t/* has error report sensedata */\n\t\t\tsensebuffer->ErrorCode = SCSI_SENSE_CURRENT_ERRORS;\n\t\t\tsensebuffer->SenseKey = ILLEGAL_REQUEST;\n\t\t\tsensebuffer->AdditionalSenseLength = 0x0A;\n\t\t\tsensebuffer->AdditionalSenseCode = 0x20;\n\t\t\tsensebuffer->Valid = 1;\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t} else {\n\t\t\tpQbuffer = &acb->wqbuffer[acb->wqbuf_putIndex];\n\t\t\tcnt2end = ARCMSR_MAX_QBUFFER - acb->wqbuf_putIndex;\n\t\t\tif (user_len > cnt2end) {\n\t\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, cnt2end);\n\t\t\t\tptmpuserbuffer += cnt2end;\n\t\t\t\tuser_len -= cnt2end;\n\t\t\t\tacb->wqbuf_putIndex = 0;\n\t\t\t\tpQbuffer = acb->wqbuffer;\n\t\t\t}\n\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, user_len);\n\t\t\tacb->wqbuf_putIndex += user_len;\n\t\t\tacb->wqbuf_putIndex %= ARCMSR_MAX_QBUFFER;\n\t\t\tif (acb->acb_flags & ACB_F_MESSAGE_WQBUFFER_CLEARED) {\n\t\t\t\tacb->acb_flags &=\n\t\t\t\t\t\t~ACB_F_MESSAGE_WQBUFFER_CLEARED;\n\t\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_RQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->rqbuffer;\n\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_WQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->wqbuffer;\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_ALLQBUFFER: {\n\t\tuint8_t *pQbuffer;\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tpQbuffer = acb->rqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tpQbuffer = acb->wqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_RETURN_CODE_3F: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_3F;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_HELLO: {\n\t\tint8_t *hello_string = \"Hello! I am ARCMSR\";\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer,\n\t\t\thello_string, (int16_t)strlen(hello_string));\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_GOODBYE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_iop_parking(acb);\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_FLUSH_ADAPTER_CACHE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_flush_adapter_cache(acb);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: unknown controlcode!\\n\", __func__);\n\t}\nmessage_out:\n\tif (use_sg) {\n\t\tstruct scatterlist *sg = scsi_sglist(cmd);\n\t\tkunmap_atomic(buffer - sg->offset);\n\t}\n\treturn retvalue;\n}",
      "code_after_change": "static int arcmsr_iop_message_xfer(struct AdapterControlBlock *acb,\n\t\tstruct scsi_cmnd *cmd)\n{\n\tchar *buffer;\n\tunsigned short use_sg;\n\tint retvalue = 0, transfer_len = 0;\n\tunsigned long flags;\n\tstruct CMD_MESSAGE_FIELD *pcmdmessagefld;\n\tuint32_t controlcode = (uint32_t)cmd->cmnd[5] << 24 |\n\t\t(uint32_t)cmd->cmnd[6] << 16 |\n\t\t(uint32_t)cmd->cmnd[7] << 8 |\n\t\t(uint32_t)cmd->cmnd[8];\n\tstruct scatterlist *sg;\n\n\tuse_sg = scsi_sg_count(cmd);\n\tsg = scsi_sglist(cmd);\n\tbuffer = kmap_atomic(sg_page(sg)) + sg->offset;\n\tif (use_sg > 1) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tgoto message_out;\n\t}\n\ttransfer_len += sg->length;\n\tif (transfer_len > sizeof(struct CMD_MESSAGE_FIELD)) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: ARCMSR_MESSAGE_FAIL!\\n\", __func__);\n\t\tgoto message_out;\n\t}\n\tpcmdmessagefld = (struct CMD_MESSAGE_FIELD *)buffer;\n\tswitch (controlcode) {\n\tcase ARCMSR_MESSAGE_READ_RQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tuint8_t *ptmpQbuffer;\n\t\tuint32_t allxfer_len = 0;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tpr_info(\"%s: memory not enough!\\n\", __func__);\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpQbuffer = ver_addr;\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tif (acb->rqbuf_getIndex != acb->rqbuf_putIndex) {\n\t\t\tunsigned int tail = acb->rqbuf_getIndex;\n\t\t\tunsigned int head = acb->rqbuf_putIndex;\n\t\t\tunsigned int cnt_to_end = CIRC_CNT_TO_END(head, tail, ARCMSR_MAX_QBUFFER);\n\n\t\t\tallxfer_len = CIRC_CNT(head, tail, ARCMSR_MAX_QBUFFER);\n\t\t\tif (allxfer_len > ARCMSR_API_DATA_BUFLEN)\n\t\t\t\tallxfer_len = ARCMSR_API_DATA_BUFLEN;\n\n\t\t\tif (allxfer_len <= cnt_to_end)\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, allxfer_len);\n\t\t\telse {\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, cnt_to_end);\n\t\t\t\tmemcpy(ptmpQbuffer + cnt_to_end, acb->rqbuffer, allxfer_len - cnt_to_end);\n\t\t\t}\n\t\t\tacb->rqbuf_getIndex = (acb->rqbuf_getIndex + allxfer_len) % ARCMSR_MAX_QBUFFER;\n\t\t}\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer, ver_addr,\n\t\t\tallxfer_len);\n\t\tif (acb->acb_flags & ACB_F_IOPDATA_OVERFLOW) {\n\t\t\tstruct QBUFFER __iomem *prbuffer;\n\t\t\tacb->acb_flags &= ~ACB_F_IOPDATA_OVERFLOW;\n\t\t\tprbuffer = arcmsr_get_iop_rqbuffer(acb);\n\t\t\tif (arcmsr_Read_iop_rqbuffer_data(acb, prbuffer) == 0)\n\t\t\t\tacb->acb_flags |= ACB_F_IOPDATA_OVERFLOW;\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tpcmdmessagefld->cmdmessage.Length = allxfer_len;\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_WRITE_WQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tuint32_t user_len;\n\t\tint32_t cnt2end;\n\t\tuint8_t *pQbuffer, *ptmpuserbuffer;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpuserbuffer = ver_addr;\n\t\tuser_len = pcmdmessagefld->cmdmessage.Length;\n\t\tif (user_len > ARCMSR_API_DATA_BUFLEN) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tkfree(ver_addr);\n\t\t\tgoto message_out;\n\t\t}\n\t\tmemcpy(ptmpuserbuffer,\n\t\t\tpcmdmessagefld->messagedatabuffer, user_len);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tif (acb->wqbuf_putIndex != acb->wqbuf_getIndex) {\n\t\t\tstruct SENSE_DATA *sensebuffer =\n\t\t\t\t(struct SENSE_DATA *)cmd->sense_buffer;\n\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t/* has error report sensedata */\n\t\t\tsensebuffer->ErrorCode = SCSI_SENSE_CURRENT_ERRORS;\n\t\t\tsensebuffer->SenseKey = ILLEGAL_REQUEST;\n\t\t\tsensebuffer->AdditionalSenseLength = 0x0A;\n\t\t\tsensebuffer->AdditionalSenseCode = 0x20;\n\t\t\tsensebuffer->Valid = 1;\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t} else {\n\t\t\tpQbuffer = &acb->wqbuffer[acb->wqbuf_putIndex];\n\t\t\tcnt2end = ARCMSR_MAX_QBUFFER - acb->wqbuf_putIndex;\n\t\t\tif (user_len > cnt2end) {\n\t\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, cnt2end);\n\t\t\t\tptmpuserbuffer += cnt2end;\n\t\t\t\tuser_len -= cnt2end;\n\t\t\t\tacb->wqbuf_putIndex = 0;\n\t\t\t\tpQbuffer = acb->wqbuffer;\n\t\t\t}\n\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, user_len);\n\t\t\tacb->wqbuf_putIndex += user_len;\n\t\t\tacb->wqbuf_putIndex %= ARCMSR_MAX_QBUFFER;\n\t\t\tif (acb->acb_flags & ACB_F_MESSAGE_WQBUFFER_CLEARED) {\n\t\t\t\tacb->acb_flags &=\n\t\t\t\t\t\t~ACB_F_MESSAGE_WQBUFFER_CLEARED;\n\t\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_RQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->rqbuffer;\n\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_WQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->wqbuffer;\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_ALLQBUFFER: {\n\t\tuint8_t *pQbuffer;\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tpQbuffer = acb->rqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tpQbuffer = acb->wqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_RETURN_CODE_3F: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_3F;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_HELLO: {\n\t\tint8_t *hello_string = \"Hello! I am ARCMSR\";\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer,\n\t\t\thello_string, (int16_t)strlen(hello_string));\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_GOODBYE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_iop_parking(acb);\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_FLUSH_ADAPTER_CACHE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_flush_adapter_cache(acb);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: unknown controlcode!\\n\", __func__);\n\t}\nmessage_out:\n\tif (use_sg) {\n\t\tstruct scatterlist *sg = scsi_sglist(cmd);\n\t\tkunmap_atomic(buffer - sg->offset);\n\t}\n\treturn retvalue;\n}",
      "modified_lines": {
        "added": [
          "\t\tuint32_t user_len;",
          "\t\tint32_t cnt2end;",
          "\t\tif (user_len > ARCMSR_API_DATA_BUFLEN) {",
          "\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;",
          "\t\t\tkfree(ver_addr);",
          "\t\t\tgoto message_out;",
          "\t\t}"
        ],
        "deleted": [
          "\t\tint32_t user_len, cnt2end;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation on the user_len variable representing the length of data being copied into a buffer.",
      "trigger_condition": "An attacker provides a user_len value larger than the allocated buffer size, leading to a buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the user_len variable against the maximum buffer size before copying data into the buffer, allowing a potential buffer overflow if the user_len exceeds the buffer size.",
      "id": 94,
      "code_after_change_normalized": "static int FUN1(struct AdapterControlBlock *VAR1,\nstruct scsi_cmnd *VAR2)\n{\nchar *VAR3;\nunsigned short VAR4;\nint VAR5 = 0, VAR6 = 0;\nunsigned long VAR7;\nstruct CMD_MESSAGE_FIELD *VAR8;\nuint32_t VAR9 = (VAR10)VAR2->VAR11[5] << 24 |\n(VAR10)VAR2->VAR11[6] << 16 |\n(VAR10)VAR2->VAR11[7] << 8 |\n(VAR10)VAR2->VAR11[8];\nstruct scatterlist *VAR12;\nVAR4 = FUN2(VAR2);\nVAR12 = FUN3(VAR2);\nVAR3 = FUN4(FUN5(VAR12)) + VAR12->VAR13;\nif (VAR4 > 1) {\nVAR5 = VAR14;\ngoto VAR15;\n}\nVAR6 += VAR12->VAR16;\nif (VAR6 > sizeof(struct VAR17)) {\nVAR5 = VAR14;\nFUN6(\"STR\", VAR18);\ngoto VAR15;\n}\nVAR8 = (struct VAR17 *)VAR3;\nswitch (VAR9) {\ncase VAR19: {\nunsigned char *VAR20;\nuint8_t *VAR21;\nuint32_t VAR22 = 0;\nVAR20 = FUN7(VAR23, VAR24);\nif (!VAR20) {\nVAR5 = VAR14;\nFUN6(\"STR\", VAR18);\ngoto VAR15;\n}\nVAR21 = VAR20;\nFUN8(&VAR1->VAR25, VAR7);\nif (VAR1->VAR26 != VAR1->VAR27) {\nunsigned int VAR28 = VAR1->VAR26;\nunsigned int VAR29 = VAR1->VAR27;\nunsigned int VAR30 = FUN9(VAR29, VAR28, VAR31);\nVAR22 = FUN10(VAR29, VAR28, VAR31);\nif (VAR22 > VAR23)\nVAR22 = VAR23;\nif (VAR22 <= VAR30)\nFUN11(VAR21, VAR1->VAR32 + VAR28, VAR22);\nelse {\nFUN11(VAR21, VAR1->VAR32 + VAR28, VAR30);\nFUN11(VAR21 + VAR30, VAR1->VAR32, VAR22 - VAR30);\n}\nVAR1->VAR26 = (VAR1->VAR26 + VAR22) % VAR31;\n}\nFUN11(VAR8->VAR33, VAR20,\nVAR22);\nif (VAR1->VAR34 & VAR35) {\nstruct QBUFFER __iomem *VAR36;\nVAR1->VAR34 &= ~VAR35;\nVAR36 = FUN12(VAR1);\nif (FUN13(VAR1, VAR36) == 0)\nVAR1->VAR34 |= VAR35;\n}\nFUN14(&VAR1->VAR25, VAR7);\nFUN15(VAR20);\nVAR8->VAR37.VAR38 = VAR22;\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR44: {\nunsigned char *VAR20;\nuint32_t VAR45;\nint32_t VAR46;\nuint8_t *VAR47, *VAR48;\nVAR20 = FUN7(VAR23, VAR24);\nif (!VAR20) {\nVAR5 = VAR14;\ngoto VAR15;\n}\nVAR48 = VAR20;\nVAR45 = VAR8->VAR37.VAR38;\nif (VAR45 > VAR23) {\nVAR5 = VAR14;\nFUN15(VAR20);\ngoto VAR15;\n}\nFUN11(VAR48,\nVAR8->VAR33, VAR45);\nFUN8(&VAR1->VAR49, VAR7);\nif (VAR1->VAR50 != VAR1->VAR51) {\nstruct SENSE_DATA *VAR52 =\n(struct VAR53 *)VAR2->VAR54;\nFUN16(VAR1);\nVAR52->VAR55 = VAR56;\nVAR52->VAR57 = VAR58;\nVAR52->VAR59 = VAR60;\nVAR52->VAR61 = VAR60;\nVAR52->VAR62 = 1;\nVAR5 = VAR14;\n} else {\nVAR47 = &VAR1->VAR63[VAR1->VAR50];\nVAR46 = VAR31 - VAR1->VAR50;\nif (VAR45 > VAR46) {\nFUN11(VAR47, VAR48, VAR46);\nVAR48 += VAR46;\nVAR45 -= VAR46;\nVAR1->VAR50 = 0;\nVAR47 = VAR1->VAR63;\n}\nFUN11(VAR47, VAR48, VAR45);\nVAR1->VAR50 += VAR45;\nVAR1->VAR50 %= VAR31;\nif (VAR1->VAR34 & VAR64) {\nVAR1->VAR34 &=\n~VAR64;\nFUN16(VAR1);\n}\n}\nFUN14(&VAR1->VAR49, VAR7);\nFUN15(VAR20);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR65: {\nuint8_t *VAR47 = VAR1->VAR32;\nFUN17(VAR1);\nFUN8(&VAR1->VAR25, VAR7);\nVAR1->VAR34 |= VAR66;\nVAR1->VAR26 = 0;\nVAR1->VAR27 = 0;\nFUN18(VAR47, 0, VAR31);\nFUN14(&VAR1->VAR25, VAR7);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR67: {\nuint8_t *VAR47 = VAR1->VAR63;\nFUN8(&VAR1->VAR49, VAR7);\nVAR1->VAR34 |= (VAR64 |\nVAR68);\nVAR1->VAR51 = 0;\nVAR1->VAR50 = 0;\nFUN18(VAR47, 0, VAR31);\nFUN14(&VAR1->VAR49, VAR7);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR69: {\nuint8_t *VAR47;\nFUN17(VAR1);\nFUN8(&VAR1->VAR25, VAR7);\nVAR1->VAR34 |= VAR66;\nVAR1->VAR26 = 0;\nVAR1->VAR27 = 0;\nVAR47 = VAR1->VAR32;\nFUN18(VAR47, 0, sizeof(struct VAR70));\nFUN14(&VAR1->VAR25, VAR7);\nFUN8(&VAR1->VAR49, VAR7);\nVAR1->VAR34 |= (VAR64 |\nVAR68);\nVAR1->VAR51 = 0;\nVAR1->VAR50 = 0;\nVAR47 = VAR1->VAR63;\nFUN18(VAR47, 0, sizeof(struct VAR70));\nFUN14(&VAR1->VAR49, VAR7);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR71: {\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR72;\nbreak;\n}\ncase VAR73: {\nint8_t *VAR74 = \"STR\";\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nFUN11(VAR8->VAR33,\nVAR74, (VAR75)FUN19(VAR74));\nbreak;\n}\ncase VAR76: {\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nFUN20(VAR1);\nbreak;\n}\ncase VAR77: {\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nFUN21(VAR1);\nbreak;\n}\ndefault:\nVAR5 = VAR14;\nFUN6(\"STR\", VAR18);\n}\nVAR15:\nif (VAR4) {\nstruct scatterlist *VAR12 = FUN3(VAR2);\nFUN22(VAR3 - VAR12->VAR13);\n}\nreturn VAR5;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct AdapterControlBlock *VAR1,\nstruct scsi_cmnd *VAR2)\n{\nchar *VAR3;\nunsigned short VAR4;\nint VAR5 = 0, VAR6 = 0;\nunsigned long VAR7;\nstruct CMD_MESSAGE_FIELD *VAR8;\nuint32_t VAR9 = (VAR10)VAR2->VAR11[5] << 24 |\n(VAR10)VAR2->VAR11[6] << 16 |\n(VAR10)VAR2->VAR11[7] << 8 |\n(VAR10)VAR2->VAR11[8];\nstruct scatterlist *VAR12;\nVAR4 = FUN2(VAR2);\nVAR12 = FUN3(VAR2);\nVAR3 = FUN4(FUN5(VAR12)) + VAR12->VAR13;\nif (VAR4 > 1) {\nVAR5 = VAR14;\ngoto VAR15;\n}\nVAR6 += VAR12->VAR16;\nif (VAR6 > sizeof(struct VAR17)) {\nVAR5 = VAR14;\nFUN6(\"STR\", VAR18);\ngoto VAR15;\n}\nVAR8 = (struct VAR17 *)VAR3;\nswitch (VAR9) {\ncase VAR19: {\nunsigned char *VAR20;\nuint8_t *VAR21;\nuint32_t VAR22 = 0;\nVAR20 = FUN7(VAR23, VAR24);\nif (!VAR20) {\nVAR5 = VAR14;\nFUN6(\"STR\", VAR18);\ngoto VAR15;\n}\nVAR21 = VAR20;\nFUN8(&VAR1->VAR25, VAR7);\nif (VAR1->VAR26 != VAR1->VAR27) {\nunsigned int VAR28 = VAR1->VAR26;\nunsigned int VAR29 = VAR1->VAR27;\nunsigned int VAR30 = FUN9(VAR29, VAR28, VAR31);\nVAR22 = FUN10(VAR29, VAR28, VAR31);\nif (VAR22 > VAR23)\nVAR22 = VAR23;\nif (VAR22 <= VAR30)\nFUN11(VAR21, VAR1->VAR32 + VAR28, VAR22);\nelse {\nFUN11(VAR21, VAR1->VAR32 + VAR28, VAR30);\nFUN11(VAR21 + VAR30, VAR1->VAR32, VAR22 - VAR30);\n}\nVAR1->VAR26 = (VAR1->VAR26 + VAR22) % VAR31;\n}\nFUN11(VAR8->VAR33, VAR20,\nVAR22);\nif (VAR1->VAR34 & VAR35) {\nstruct QBUFFER __iomem *VAR36;\nVAR1->VAR34 &= ~VAR35;\nVAR36 = FUN12(VAR1);\nif (FUN13(VAR1, VAR36) == 0)\nVAR1->VAR34 |= VAR35;\n}\nFUN14(&VAR1->VAR25, VAR7);\nFUN15(VAR20);\nVAR8->VAR37.VAR38 = VAR22;\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR44: {\nunsigned char *VAR20;\nint32_t VAR45, VAR46;\nuint8_t *VAR47, *VAR48;\nVAR20 = FUN7(VAR23, VAR24);\nif (!VAR20) {\nVAR5 = VAR14;\ngoto VAR15;\n}\nVAR48 = VAR20;\nVAR45 = VAR8->VAR37.VAR38;\nFUN11(VAR48,\nVAR8->VAR33, VAR45);\nFUN8(&VAR1->VAR49, VAR7);\nif (VAR1->VAR50 != VAR1->VAR51) {\nstruct SENSE_DATA *VAR52 =\n(struct VAR53 *)VAR2->VAR54;\nFUN16(VAR1);\nVAR52->VAR55 = VAR56;\nVAR52->VAR57 = VAR58;\nVAR52->VAR59 = VAR60;\nVAR52->VAR61 = VAR60;\nVAR52->VAR62 = 1;\nVAR5 = VAR14;\n} else {\nVAR47 = &VAR1->VAR63[VAR1->VAR50];\nVAR46 = VAR31 - VAR1->VAR50;\nif (VAR45 > VAR46) {\nFUN11(VAR47, VAR48, VAR46);\nVAR48 += VAR46;\nVAR45 -= VAR46;\nVAR1->VAR50 = 0;\nVAR47 = VAR1->VAR63;\n}\nFUN11(VAR47, VAR48, VAR45);\nVAR1->VAR50 += VAR45;\nVAR1->VAR50 %= VAR31;\nif (VAR1->VAR34 & VAR64) {\nVAR1->VAR34 &=\n~VAR64;\nFUN16(VAR1);\n}\n}\nFUN14(&VAR1->VAR49, VAR7);\nFUN15(VAR20);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR65: {\nuint8_t *VAR47 = VAR1->VAR32;\nFUN17(VAR1);\nFUN8(&VAR1->VAR25, VAR7);\nVAR1->VAR34 |= VAR66;\nVAR1->VAR26 = 0;\nVAR1->VAR27 = 0;\nFUN18(VAR47, 0, VAR31);\nFUN14(&VAR1->VAR25, VAR7);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR67: {\nuint8_t *VAR47 = VAR1->VAR63;\nFUN8(&VAR1->VAR49, VAR7);\nVAR1->VAR34 |= (VAR64 |\nVAR68);\nVAR1->VAR51 = 0;\nVAR1->VAR50 = 0;\nFUN18(VAR47, 0, VAR31);\nFUN14(&VAR1->VAR49, VAR7);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR69: {\nuint8_t *VAR47;\nFUN17(VAR1);\nFUN8(&VAR1->VAR25, VAR7);\nVAR1->VAR34 |= VAR66;\nVAR1->VAR26 = 0;\nVAR1->VAR27 = 0;\nVAR47 = VAR1->VAR32;\nFUN18(VAR47, 0, sizeof(struct VAR70));\nFUN14(&VAR1->VAR25, VAR7);\nFUN8(&VAR1->VAR49, VAR7);\nVAR1->VAR34 |= (VAR64 |\nVAR68);\nVAR1->VAR51 = 0;\nVAR1->VAR50 = 0;\nVAR47 = VAR1->VAR63;\nFUN18(VAR47, 0, sizeof(struct VAR70));\nFUN14(&VAR1->VAR49, VAR7);\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nbreak;\n}\ncase VAR71: {\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR72;\nbreak;\n}\ncase VAR73: {\nint8_t *VAR74 = \"STR\";\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nFUN11(VAR8->VAR33,\nVAR74, (VAR75)FUN19(VAR74));\nbreak;\n}\ncase VAR76: {\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nFUN20(VAR1);\nbreak;\n}\ncase VAR77: {\nif (VAR1->VAR39 == VAR40)\nVAR8->VAR37.VAR41 =\nVAR42;\nelse\nVAR8->VAR37.VAR41 =\nVAR43;\nFUN21(VAR1);\nbreak;\n}\ndefault:\nVAR5 = VAR14;\nFUN6(\"STR\", VAR18);\n}\nVAR15:\nif (VAR4) {\nstruct scatterlist *VAR12 = FUN3(VAR2);\nFUN22(VAR3 - VAR12->VAR13);\n}\nreturn VAR5;\n}\n",
      "code_after_change_raw": "static int arcmsr_iop_message_xfer(struct AdapterControlBlock *acb,\nstruct scsi_cmnd *cmd)\n{\nchar *buffer;\nunsigned short use_sg;\nint retvalue = 0, transfer_len = 0;\nunsigned long flags;\nstruct CMD_MESSAGE_FIELD *pcmdmessagefld;\nuint32_t controlcode = (uint32_t)cmd->cmnd[5] << 24 |\n(uint32_t)cmd->cmnd[6] << 16 |\n(uint32_t)cmd->cmnd[7] << 8 |\n(uint32_t)cmd->cmnd[8];\nstruct scatterlist *sg;\nuse_sg = scsi_sg_count(cmd);\nsg = scsi_sglist(cmd);\nbuffer = kmap_atomic(sg_page(sg)) + sg->offset;\nif (use_sg > 1) {\nretvalue = ARCMSR_MESSAGE_FAIL;\ngoto message_out;\n}\ntransfer_len += sg->length;\nif (transfer_len > sizeof(struct CMD_MESSAGE_FIELD)) {\nretvalue = ARCMSR_MESSAGE_FAIL;\npr_info(\"%s: ARCMSR_MESSAGE_FAIL!\\n\", __func__);\ngoto message_out;\n}\npcmdmessagefld = (struct CMD_MESSAGE_FIELD *)buffer;\nswitch (controlcode) {\ncase ARCMSR_MESSAGE_READ_RQBUFFER: {\nunsigned char *ver_addr;\nuint8_t *ptmpQbuffer;\nuint32_t allxfer_len = 0;\nver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\nif (!ver_addr) {\nretvalue = ARCMSR_MESSAGE_FAIL;\npr_info(\"%s: memory not enough!\\n\", __func__);\ngoto message_out;\n}\nptmpQbuffer = ver_addr;\nspin_lock_irqsave(&acb->rqbuffer_lock, flags);\nif (acb->rqbuf_getIndex != acb->rqbuf_putIndex) {\nunsigned int tail = acb->rqbuf_getIndex;\nunsigned int head = acb->rqbuf_putIndex;\nunsigned int cnt_to_end = CIRC_CNT_TO_END(head, tail, ARCMSR_MAX_QBUFFER);\nallxfer_len = CIRC_CNT(head, tail, ARCMSR_MAX_QBUFFER);\nif (allxfer_len > ARCMSR_API_DATA_BUFLEN)\nallxfer_len = ARCMSR_API_DATA_BUFLEN;\nif (allxfer_len <= cnt_to_end)\nmemcpy(ptmpQbuffer, acb->rqbuffer + tail, allxfer_len);\nelse {\nmemcpy(ptmpQbuffer, acb->rqbuffer + tail, cnt_to_end);\nmemcpy(ptmpQbuffer + cnt_to_end, acb->rqbuffer, allxfer_len - cnt_to_end);\n}\nacb->rqbuf_getIndex = (acb->rqbuf_getIndex + allxfer_len) % ARCMSR_MAX_QBUFFER;\n}\nmemcpy(pcmdmessagefld->messagedatabuffer, ver_addr,\nallxfer_len);\nif (acb->acb_flags & ACB_F_IOPDATA_OVERFLOW) {\nstruct QBUFFER __iomem *prbuffer;\nacb->acb_flags &= ~ACB_F_IOPDATA_OVERFLOW;\nprbuffer = arcmsr_get_iop_rqbuffer(acb);\nif (arcmsr_Read_iop_rqbuffer_data(acb, prbuffer) == 0)\nacb->acb_flags |= ACB_F_IOPDATA_OVERFLOW;\n}\nspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\nkfree(ver_addr);\npcmdmessagefld->cmdmessage.Length = allxfer_len;\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_WRITE_WQBUFFER: {\nunsigned char *ver_addr;\nuint32_t user_len;\nint32_t cnt2end;\nuint8_t *pQbuffer, *ptmpuserbuffer;\nver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\nif (!ver_addr) {\nretvalue = ARCMSR_MESSAGE_FAIL;\ngoto message_out;\n}\nptmpuserbuffer = ver_addr;\nuser_len = pcmdmessagefld->cmdmessage.Length;\nif (user_len > ARCMSR_API_DATA_BUFLEN) {\nretvalue = ARCMSR_MESSAGE_FAIL;\nkfree(ver_addr);\ngoto message_out;\n}\nmemcpy(ptmpuserbuffer,\npcmdmessagefld->messagedatabuffer, user_len);\nspin_lock_irqsave(&acb->wqbuffer_lock, flags);\nif (acb->wqbuf_putIndex != acb->wqbuf_getIndex) {\nstruct SENSE_DATA *sensebuffer =\n(struct SENSE_DATA *)cmd->sense_buffer;\narcmsr_write_ioctldata2iop(acb);\nsensebuffer->ErrorCode = SCSI_SENSE_CURRENT_ERRORS;\nsensebuffer->SenseKey = ILLEGAL_REQUEST;\nsensebuffer->AdditionalSenseLength = 0x0A;\nsensebuffer->AdditionalSenseCode = 0x20;\nsensebuffer->Valid = 1;\nretvalue = ARCMSR_MESSAGE_FAIL;\n} else {\npQbuffer = &acb->wqbuffer[acb->wqbuf_putIndex];\ncnt2end = ARCMSR_MAX_QBUFFER - acb->wqbuf_putIndex;\nif (user_len > cnt2end) {\nmemcpy(pQbuffer, ptmpuserbuffer, cnt2end);\nptmpuserbuffer += cnt2end;\nuser_len -= cnt2end;\nacb->wqbuf_putIndex = 0;\npQbuffer = acb->wqbuffer;\n}\nmemcpy(pQbuffer, ptmpuserbuffer, user_len);\nacb->wqbuf_putIndex += user_len;\nacb->wqbuf_putIndex %= ARCMSR_MAX_QBUFFER;\nif (acb->acb_flags & ACB_F_MESSAGE_WQBUFFER_CLEARED) {\nacb->acb_flags &=\n~ACB_F_MESSAGE_WQBUFFER_CLEARED;\narcmsr_write_ioctldata2iop(acb);\n}\n}\nspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\nkfree(ver_addr);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_CLEAR_RQBUFFER: {\nuint8_t *pQbuffer = acb->rqbuffer;\narcmsr_clear_iop2drv_rqueue_buffer(acb);\nspin_lock_irqsave(&acb->rqbuffer_lock, flags);\nacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\nacb->rqbuf_getIndex = 0;\nacb->rqbuf_putIndex = 0;\nmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\nspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_CLEAR_WQBUFFER: {\nuint8_t *pQbuffer = acb->wqbuffer;\nspin_lock_irqsave(&acb->wqbuffer_lock, flags);\nacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\nACB_F_MESSAGE_WQBUFFER_READED);\nacb->wqbuf_getIndex = 0;\nacb->wqbuf_putIndex = 0;\nmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\nspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_CLEAR_ALLQBUFFER: {\nuint8_t *pQbuffer;\narcmsr_clear_iop2drv_rqueue_buffer(acb);\nspin_lock_irqsave(&acb->rqbuffer_lock, flags);\nacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\nacb->rqbuf_getIndex = 0;\nacb->rqbuf_putIndex = 0;\npQbuffer = acb->rqbuffer;\nmemset(pQbuffer, 0, sizeof(struct QBUFFER));\nspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\nspin_lock_irqsave(&acb->wqbuffer_lock, flags);\nacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\nACB_F_MESSAGE_WQBUFFER_READED);\nacb->wqbuf_getIndex = 0;\nacb->wqbuf_putIndex = 0;\npQbuffer = acb->wqbuffer;\nmemset(pQbuffer, 0, sizeof(struct QBUFFER));\nspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_RETURN_CODE_3F: {\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_3F;\nbreak;\n}\ncase ARCMSR_MESSAGE_SAY_HELLO: {\nint8_t *hello_string = \"Hello! I am ARCMSR\";\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nmemcpy(pcmdmessagefld->messagedatabuffer,\nhello_string, (int16_t)strlen(hello_string));\nbreak;\n}\ncase ARCMSR_MESSAGE_SAY_GOODBYE: {\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\narcmsr_iop_parking(acb);\nbreak;\n}\ncase ARCMSR_MESSAGE_FLUSH_ADAPTER_CACHE: {\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\narcmsr_flush_adapter_cache(acb);\nbreak;\n}\ndefault:\nretvalue = ARCMSR_MESSAGE_FAIL;\npr_info(\"%s: unknown controlcode!\\n\", __func__);\n}\nmessage_out:\nif (use_sg) {\nstruct scatterlist *sg = scsi_sglist(cmd);\nkunmap_atomic(buffer - sg->offset);\n}\nreturn retvalue;\n}\n",
      "code_before_change_raw": "static int arcmsr_iop_message_xfer(struct AdapterControlBlock *acb,\nstruct scsi_cmnd *cmd)\n{\nchar *buffer;\nunsigned short use_sg;\nint retvalue = 0, transfer_len = 0;\nunsigned long flags;\nstruct CMD_MESSAGE_FIELD *pcmdmessagefld;\nuint32_t controlcode = (uint32_t)cmd->cmnd[5] << 24 |\n(uint32_t)cmd->cmnd[6] << 16 |\n(uint32_t)cmd->cmnd[7] << 8 |\n(uint32_t)cmd->cmnd[8];\nstruct scatterlist *sg;\nuse_sg = scsi_sg_count(cmd);\nsg = scsi_sglist(cmd);\nbuffer = kmap_atomic(sg_page(sg)) + sg->offset;\nif (use_sg > 1) {\nretvalue = ARCMSR_MESSAGE_FAIL;\ngoto message_out;\n}\ntransfer_len += sg->length;\nif (transfer_len > sizeof(struct CMD_MESSAGE_FIELD)) {\nretvalue = ARCMSR_MESSAGE_FAIL;\npr_info(\"%s: ARCMSR_MESSAGE_FAIL!\\n\", __func__);\ngoto message_out;\n}\npcmdmessagefld = (struct CMD_MESSAGE_FIELD *)buffer;\nswitch (controlcode) {\ncase ARCMSR_MESSAGE_READ_RQBUFFER: {\nunsigned char *ver_addr;\nuint8_t *ptmpQbuffer;\nuint32_t allxfer_len = 0;\nver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\nif (!ver_addr) {\nretvalue = ARCMSR_MESSAGE_FAIL;\npr_info(\"%s: memory not enough!\\n\", __func__);\ngoto message_out;\n}\nptmpQbuffer = ver_addr;\nspin_lock_irqsave(&acb->rqbuffer_lock, flags);\nif (acb->rqbuf_getIndex != acb->rqbuf_putIndex) {\nunsigned int tail = acb->rqbuf_getIndex;\nunsigned int head = acb->rqbuf_putIndex;\nunsigned int cnt_to_end = CIRC_CNT_TO_END(head, tail, ARCMSR_MAX_QBUFFER);\nallxfer_len = CIRC_CNT(head, tail, ARCMSR_MAX_QBUFFER);\nif (allxfer_len > ARCMSR_API_DATA_BUFLEN)\nallxfer_len = ARCMSR_API_DATA_BUFLEN;\nif (allxfer_len <= cnt_to_end)\nmemcpy(ptmpQbuffer, acb->rqbuffer + tail, allxfer_len);\nelse {\nmemcpy(ptmpQbuffer, acb->rqbuffer + tail, cnt_to_end);\nmemcpy(ptmpQbuffer + cnt_to_end, acb->rqbuffer, allxfer_len - cnt_to_end);\n}\nacb->rqbuf_getIndex = (acb->rqbuf_getIndex + allxfer_len) % ARCMSR_MAX_QBUFFER;\n}\nmemcpy(pcmdmessagefld->messagedatabuffer, ver_addr,\nallxfer_len);\nif (acb->acb_flags & ACB_F_IOPDATA_OVERFLOW) {\nstruct QBUFFER __iomem *prbuffer;\nacb->acb_flags &= ~ACB_F_IOPDATA_OVERFLOW;\nprbuffer = arcmsr_get_iop_rqbuffer(acb);\nif (arcmsr_Read_iop_rqbuffer_data(acb, prbuffer) == 0)\nacb->acb_flags |= ACB_F_IOPDATA_OVERFLOW;\n}\nspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\nkfree(ver_addr);\npcmdmessagefld->cmdmessage.Length = allxfer_len;\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_WRITE_WQBUFFER: {\nunsigned char *ver_addr;\nint32_t user_len, cnt2end;\nuint8_t *pQbuffer, *ptmpuserbuffer;\nver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\nif (!ver_addr) {\nretvalue = ARCMSR_MESSAGE_FAIL;\ngoto message_out;\n}\nptmpuserbuffer = ver_addr;\nuser_len = pcmdmessagefld->cmdmessage.Length;\nmemcpy(ptmpuserbuffer,\npcmdmessagefld->messagedatabuffer, user_len);\nspin_lock_irqsave(&acb->wqbuffer_lock, flags);\nif (acb->wqbuf_putIndex != acb->wqbuf_getIndex) {\nstruct SENSE_DATA *sensebuffer =\n(struct SENSE_DATA *)cmd->sense_buffer;\narcmsr_write_ioctldata2iop(acb);\nsensebuffer->ErrorCode = SCSI_SENSE_CURRENT_ERRORS;\nsensebuffer->SenseKey = ILLEGAL_REQUEST;\nsensebuffer->AdditionalSenseLength = 0x0A;\nsensebuffer->AdditionalSenseCode = 0x20;\nsensebuffer->Valid = 1;\nretvalue = ARCMSR_MESSAGE_FAIL;\n} else {\npQbuffer = &acb->wqbuffer[acb->wqbuf_putIndex];\ncnt2end = ARCMSR_MAX_QBUFFER - acb->wqbuf_putIndex;\nif (user_len > cnt2end) {\nmemcpy(pQbuffer, ptmpuserbuffer, cnt2end);\nptmpuserbuffer += cnt2end;\nuser_len -= cnt2end;\nacb->wqbuf_putIndex = 0;\npQbuffer = acb->wqbuffer;\n}\nmemcpy(pQbuffer, ptmpuserbuffer, user_len);\nacb->wqbuf_putIndex += user_len;\nacb->wqbuf_putIndex %= ARCMSR_MAX_QBUFFER;\nif (acb->acb_flags & ACB_F_MESSAGE_WQBUFFER_CLEARED) {\nacb->acb_flags &=\n~ACB_F_MESSAGE_WQBUFFER_CLEARED;\narcmsr_write_ioctldata2iop(acb);\n}\n}\nspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\nkfree(ver_addr);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_CLEAR_RQBUFFER: {\nuint8_t *pQbuffer = acb->rqbuffer;\narcmsr_clear_iop2drv_rqueue_buffer(acb);\nspin_lock_irqsave(&acb->rqbuffer_lock, flags);\nacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\nacb->rqbuf_getIndex = 0;\nacb->rqbuf_putIndex = 0;\nmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\nspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_CLEAR_WQBUFFER: {\nuint8_t *pQbuffer = acb->wqbuffer;\nspin_lock_irqsave(&acb->wqbuffer_lock, flags);\nacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\nACB_F_MESSAGE_WQBUFFER_READED);\nacb->wqbuf_getIndex = 0;\nacb->wqbuf_putIndex = 0;\nmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\nspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_CLEAR_ALLQBUFFER: {\nuint8_t *pQbuffer;\narcmsr_clear_iop2drv_rqueue_buffer(acb);\nspin_lock_irqsave(&acb->rqbuffer_lock, flags);\nacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\nacb->rqbuf_getIndex = 0;\nacb->rqbuf_putIndex = 0;\npQbuffer = acb->rqbuffer;\nmemset(pQbuffer, 0, sizeof(struct QBUFFER));\nspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\nspin_lock_irqsave(&acb->wqbuffer_lock, flags);\nacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\nACB_F_MESSAGE_WQBUFFER_READED);\nacb->wqbuf_getIndex = 0;\nacb->wqbuf_putIndex = 0;\npQbuffer = acb->wqbuffer;\nmemset(pQbuffer, 0, sizeof(struct QBUFFER));\nspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nbreak;\n}\ncase ARCMSR_MESSAGE_RETURN_CODE_3F: {\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_3F;\nbreak;\n}\ncase ARCMSR_MESSAGE_SAY_HELLO: {\nint8_t *hello_string = \"Hello! I am ARCMSR\";\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\nmemcpy(pcmdmessagefld->messagedatabuffer,\nhello_string, (int16_t)strlen(hello_string));\nbreak;\n}\ncase ARCMSR_MESSAGE_SAY_GOODBYE: {\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\narcmsr_iop_parking(acb);\nbreak;\n}\ncase ARCMSR_MESSAGE_FLUSH_ADAPTER_CACHE: {\nif (acb->fw_flag == FW_DEADLOCK)\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\nelse\npcmdmessagefld->cmdmessage.ReturnCode =\nARCMSR_MESSAGE_RETURNCODE_OK;\narcmsr_flush_adapter_cache(acb);\nbreak;\n}\ndefault:\nretvalue = ARCMSR_MESSAGE_FAIL;\npr_info(\"%s: unknown controlcode!\\n\", __func__);\n}\nmessage_out:\nif (use_sg) {\nstruct scatterlist *sg = scsi_sglist(cmd);\nkunmap_atomic(buffer - sg->offset);\n}\nreturn retvalue;\n}\n"
    }
  ],
  "CVE-2016-8632": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Inadequate validation of the relationship between the minimum fragment length and the maximum packet size.",
        "trigger_condition": "Local users with CAP_NET_ADMIN capability can exploit the vulnerability to gain privileges or cause a denial of service through a heap-based buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the MTU value before setting it in the tipc_bearer structure, allowing for a potential heap-based buffer overflow if the MTU value is not within acceptable bounds."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check for a bad MTU value using the tipc_mtu_bad function before setting the MTU in the tipc_bearer structure. If the MTU value is found to be bad, the bearer should be disabled to prevent the vulnerability from being exploited. This ensures that the MTU value is properly validated before proceeding, thereby preventing a heap-based buffer overflow.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2016-8632, which involves a heap-based buffer overflow due to inadequate validation of the relationship between the minimum fragment length and the maximum packet size in the tipc_msg_build function.\n\nIn the modified code snippet, the key change is the addition of the check for a bad MTU value using the function `tipc_mtu_bad(dev, 0)`. This check ensures that the MTU value is within acceptable bounds before setting it in the `tipc_bearer` structure. If the MTU value is found to be bad, the `bearer_disable` function is called to disable the bearer, preventing the vulnerability from being exploited.\n\nBy adding this check, the code now properly validates the MTU value before proceeding with setting it, thereby mitigating the risk of a heap-based buffer overflow that could be triggered by an attacker with the CAP_NET_ADMIN capability.\n\nTherefore, the modification is necessary to enhance the security of the code and prevent potential privilege escalation or denial of service attacks.",
      "GPT_purpose": "Handle network device events for a TIPC bearer, updating bearer information and performing actions based on different network device events.",
      "GPT_function": "\n1. Handle network device events such as changes in carrier status, device going up or down, MTU changes, address changes, unregistering, and changing device name.\n2. Update the MTU of the TIPC bearer based on the network device's MTU.\n3. Set or clear a bit in the TIPC bearer structure based on the network device events.\n4. Reset the TIPC bearer and perform necessary actions when specific network device events occur.",
      "CVE_id": "CVE-2016-8632",
      "code_before_change": "static int tipc_l2_device_event(struct notifier_block *nb, unsigned long evt,\n\t\t\t\tvoid *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct net *net = dev_net(dev);\n\tstruct tipc_bearer *b;\n\n\tb = rtnl_dereference(dev->tipc_ptr);\n\tif (!b)\n\t\treturn NOTIFY_DONE;\n\n\tb->mtu = dev->mtu;\n\n\tswitch (evt) {\n\tcase NETDEV_CHANGE:\n\t\tif (netif_carrier_ok(dev))\n\t\t\tbreak;\n\tcase NETDEV_UP:\n\t\ttest_and_set_bit_lock(0, &b->up);\n\t\tbreak;\n\tcase NETDEV_GOING_DOWN:\n\t\tclear_bit_unlock(0, &b->up);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEMTU:\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEADDR:\n\t\tb->media->raw2addr(b, &b->addr,\n\t\t\t\t   (char *)dev->dev_addr);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_UNREGISTER:\n\tcase NETDEV_CHANGENAME:\n\t\tbearer_disable(dev_net(dev), b);\n\t\tbreak;\n\t}\n\treturn NOTIFY_OK;\n}",
      "code_after_change": "static int tipc_l2_device_event(struct notifier_block *nb, unsigned long evt,\n\t\t\t\tvoid *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct net *net = dev_net(dev);\n\tstruct tipc_bearer *b;\n\n\tb = rtnl_dereference(dev->tipc_ptr);\n\tif (!b)\n\t\treturn NOTIFY_DONE;\n\n\tswitch (evt) {\n\tcase NETDEV_CHANGE:\n\t\tif (netif_carrier_ok(dev))\n\t\t\tbreak;\n\tcase NETDEV_UP:\n\t\ttest_and_set_bit_lock(0, &b->up);\n\t\tbreak;\n\tcase NETDEV_GOING_DOWN:\n\t\tclear_bit_unlock(0, &b->up);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEMTU:\n\t\tif (tipc_mtu_bad(dev, 0)) {\n\t\t\tbearer_disable(net, b);\n\t\t\tbreak;\n\t\t}\n\t\tb->mtu = dev->mtu;\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEADDR:\n\t\tb->media->raw2addr(b, &b->addr,\n\t\t\t\t   (char *)dev->dev_addr);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_UNREGISTER:\n\tcase NETDEV_CHANGENAME:\n\t\tbearer_disable(dev_net(dev), b);\n\t\tbreak;\n\t}\n\treturn NOTIFY_OK;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (tipc_mtu_bad(dev, 0)) {",
          "\t\t\tbearer_disable(net, b);",
          "\t\t\tbreak;",
          "\t\t}",
          "\t\tb->mtu = dev->mtu;"
        ],
        "deleted": [
          "",
          "\tb->mtu = dev->mtu;"
        ]
      },
      "preconditions_for_vulnerability": "Inadequate validation of the relationship between the minimum fragment length and the maximum packet size.",
      "trigger_condition": "Local users with CAP_NET_ADMIN capability can exploit the vulnerability to gain privileges or cause a denial of service through a heap-based buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the MTU value before setting it in the tipc_bearer structure, allowing for a potential heap-based buffer overflow if the MTU value is not within acceptable bounds.",
      "id": 95,
      "code_after_change_normalized": "static int FUN1(struct notifier_block *VAR1, unsigned long VAR2,\nvoid *VAR3)\n{\nstruct net_device *VAR4 = FUN2(VAR3);\nstruct VAR5 *VAR5 = FUN3(VAR4);\nstruct tipc_bearer *VAR6;\nVAR6 = FUN4(VAR4->VAR7);\nif (!VAR6)\nreturn VAR8;\nswitch (VAR2) {\ncase VAR9:\nif (FUN5(VAR4))\nbreak;\ncase VAR10:\nFUN6(0, &VAR6->VAR11);\nbreak;\ncase VAR12:\nFUN7(0, &VAR6->VAR11);\nFUN8(VAR5, VAR6);\nbreak;\ncase VAR13:\nif (FUN9(VAR4, 0)) {\nFUN10(VAR5, VAR6);\nbreak;\n}\nVAR6->VAR14 = VAR4->VAR14;\nFUN8(VAR5, VAR6);\nbreak;\ncase VAR15:\nVAR6->VAR16->FUN11(VAR6, &VAR6->VAR17,\n(char *)VAR4->VAR18);\nFUN8(VAR5, VAR6);\nbreak;\ncase VAR19:\ncase VAR20:\nFUN10(FUN3(VAR4), VAR6);\nbreak;\n}\nreturn VAR21;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct notifier_block *VAR1, unsigned long VAR2,\nvoid *VAR3)\n{\nstruct net_device *VAR4 = FUN2(VAR3);\nstruct VAR5 *VAR5 = FUN3(VAR4);\nstruct tipc_bearer *VAR6;\nVAR6 = FUN4(VAR4->VAR7);\nif (!VAR6)\nreturn VAR8;\nVAR6->VAR9 = VAR4->VAR9;\nswitch (VAR2) {\ncase VAR10:\nif (FUN5(VAR4))\nbreak;\ncase VAR11:\nFUN6(0, &VAR6->VAR12);\nbreak;\ncase VAR13:\nFUN7(0, &VAR6->VAR12);\nFUN8(VAR5, VAR6);\nbreak;\ncase VAR14:\nFUN8(VAR5, VAR6);\nbreak;\ncase VAR15:\nVAR6->VAR16->FUN9(VAR6, &VAR6->VAR17,\n(char *)VAR4->VAR18);\nFUN8(VAR5, VAR6);\nbreak;\ncase VAR19:\ncase VAR20:\nFUN10(FUN3(VAR4), VAR6);\nbreak;\n}\nreturn VAR21;\n}\n",
      "code_after_change_raw": "static int tipc_l2_device_event(struct notifier_block *nb, unsigned long evt,\nvoid *ptr)\n{\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\nstruct net *net = dev_net(dev);\nstruct tipc_bearer *b;\nb = rtnl_dereference(dev->tipc_ptr);\nif (!b)\nreturn NOTIFY_DONE;\nswitch (evt) {\ncase NETDEV_CHANGE:\nif (netif_carrier_ok(dev))\nbreak;\ncase NETDEV_UP:\ntest_and_set_bit_lock(0, &b->up);\nbreak;\ncase NETDEV_GOING_DOWN:\nclear_bit_unlock(0, &b->up);\ntipc_reset_bearer(net, b);\nbreak;\ncase NETDEV_CHANGEMTU:\nif (tipc_mtu_bad(dev, 0)) {\nbearer_disable(net, b);\nbreak;\n}\nb->mtu = dev->mtu;\ntipc_reset_bearer(net, b);\nbreak;\ncase NETDEV_CHANGEADDR:\nb->media->raw2addr(b, &b->addr,\n(char *)dev->dev_addr);\ntipc_reset_bearer(net, b);\nbreak;\ncase NETDEV_UNREGISTER:\ncase NETDEV_CHANGENAME:\nbearer_disable(dev_net(dev), b);\nbreak;\n}\nreturn NOTIFY_OK;\n}\n",
      "code_before_change_raw": "static int tipc_l2_device_event(struct notifier_block *nb, unsigned long evt,\nvoid *ptr)\n{\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\nstruct net *net = dev_net(dev);\nstruct tipc_bearer *b;\nb = rtnl_dereference(dev->tipc_ptr);\nif (!b)\nreturn NOTIFY_DONE;\nb->mtu = dev->mtu;\nswitch (evt) {\ncase NETDEV_CHANGE:\nif (netif_carrier_ok(dev))\nbreak;\ncase NETDEV_UP:\ntest_and_set_bit_lock(0, &b->up);\nbreak;\ncase NETDEV_GOING_DOWN:\nclear_bit_unlock(0, &b->up);\ntipc_reset_bearer(net, b);\nbreak;\ncase NETDEV_CHANGEMTU:\ntipc_reset_bearer(net, b);\nbreak;\ncase NETDEV_CHANGEADDR:\nb->media->raw2addr(b, &b->addr,\n(char *)dev->dev_addr);\ntipc_reset_bearer(net, b);\nbreak;\ncase NETDEV_UNREGISTER:\ncase NETDEV_CHANGENAME:\nbearer_disable(dev_net(dev), b);\nbreak;\n}\nreturn NOTIFY_OK;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation of the relationship between the minimum fragment length and the maximum packet size.",
        "trigger_condition": "Local users with CAP_NET_ADMIN capability can exploit the vulnerability by manipulating the packet size to cause a heap-based buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the minimum fragment length against the maximum packet size, allowing for a potential heap-based buffer overflow if the packet size exceeds the available buffer space."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a validation check to ensure that the minimum fragment length does not exceed the maximum packet size. By verifying this relationship, the code can prevent heap-based buffer overflows and enhance security. In this case, the solution involves adding a check after determining the protocol type to validate the minimum fragment length against the maximum packet size.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-8632, which involves a heap-based buffer overflow that can be exploited by local users with the CAP_NET_ADMIN capability. By adding the check `if (tipc_mtu_bad(dev, sizeof(struct iphdr) + sizeof(struct udphdr)))` after determining the protocol type is IPv4, the code ensures that the minimum fragment length is properly validated against the maximum packet size. This check helps prevent the buffer overflow vulnerability by verifying that the packet size does not exceed the available buffer space, thus enhancing the security of the code and preventing potential privilege escalation or denial of service attacks.",
      "GPT_purpose": "Enable a TIPC UDP bearer with specified local and remote addresses and configure the UDP socket for communication.",
      "GPT_function": "\n1. Enable TIPC UDP bearer with specified configuration options.\n2. Parse UDP local and remote addresses from the provided attributes.\n3. Set up UDP configuration based on the provided local address protocol.\n4. Create a UDP socket for the bearer and set up a UDP tunnel socket.\n5. Copy the remote address to the bearer's broadcast address and handle multicast or unicast scenarios accordingly.",
      "CVE_id": "CVE-2016-8632",
      "code_before_change": "static int tipc_udp_enable(struct net *net, struct tipc_bearer *b,\n\t\t\t   struct nlattr *attrs[])\n{\n\tint err = -EINVAL;\n\tstruct udp_bearer *ub;\n\tstruct udp_media_addr remote = {0};\n\tstruct udp_media_addr local = {0};\n\tstruct udp_port_cfg udp_conf = {0};\n\tstruct udp_tunnel_sock_cfg tuncfg = {NULL};\n\tstruct nlattr *opts[TIPC_NLA_UDP_MAX + 1];\n\n\tub = kzalloc(sizeof(*ub), GFP_ATOMIC);\n\tif (!ub)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&ub->rcast.list);\n\n\tif (!attrs[TIPC_NLA_BEARER_UDP_OPTS])\n\t\tgoto err;\n\n\tif (nla_parse_nested(opts, TIPC_NLA_UDP_MAX,\n\t\t\t     attrs[TIPC_NLA_BEARER_UDP_OPTS],\n\t\t\t     tipc_nl_udp_policy))\n\t\tgoto err;\n\n\tif (!opts[TIPC_NLA_UDP_LOCAL] || !opts[TIPC_NLA_UDP_REMOTE]) {\n\t\tpr_err(\"Invalid UDP bearer configuration\");\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_LOCAL], &local,\n\t\t\t\t  &ub->ifindex);\n\tif (err)\n\t\tgoto err;\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_REMOTE], &remote, NULL);\n\tif (err)\n\t\tgoto err;\n\n\tb->bcast_addr.media_id = TIPC_MEDIA_TYPE_UDP;\n\tb->bcast_addr.broadcast = 1;\n\trcu_assign_pointer(b->media_ptr, ub);\n\trcu_assign_pointer(ub->bearer, b);\n\ttipc_udp_media_addr_set(&b->addr, &local);\n\tif (local.proto == htons(ETH_P_IP)) {\n\t\tstruct net_device *dev;\n\n\t\tdev = __ip_dev_find(net, local.ipv4.s_addr, false);\n\t\tif (!dev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tudp_conf.family = AF_INET;\n\t\tudp_conf.local_ip.s_addr = htonl(INADDR_ANY);\n\t\tudp_conf.use_udp_checksums = false;\n\t\tub->ifindex = dev->ifindex;\n\t\tb->mtu = dev->mtu - sizeof(struct iphdr)\n\t\t\t- sizeof(struct udphdr);\n#if IS_ENABLED(CONFIG_IPV6)\n\t} else if (local.proto == htons(ETH_P_IPV6)) {\n\t\tudp_conf.family = AF_INET6;\n\t\tudp_conf.use_udp6_tx_checksums = true;\n\t\tudp_conf.use_udp6_rx_checksums = true;\n\t\tudp_conf.local_ip6 = in6addr_any;\n\t\tb->mtu = 1280;\n#endif\n\t} else {\n\t\terr = -EAFNOSUPPORT;\n\t\tgoto err;\n\t}\n\tudp_conf.local_udp_port = local.port;\n\terr = udp_sock_create(net, &udp_conf, &ub->ubsock);\n\tif (err)\n\t\tgoto err;\n\ttuncfg.sk_user_data = ub;\n\ttuncfg.encap_type = 1;\n\ttuncfg.encap_rcv = tipc_udp_recv;\n\ttuncfg.encap_destroy = NULL;\n\tsetup_udp_tunnel_sock(net, ub->ubsock, &tuncfg);\n\n\t/**\n\t * The bcast media address port is used for all peers and the ip\n\t * is used if it's a multicast address.\n\t */\n\tmemcpy(&b->bcast_addr.value, &remote, sizeof(remote));\n\tif (tipc_udp_is_mcast_addr(&remote))\n\t\terr = enable_mcast(ub, &remote);\n\telse\n\t\terr = tipc_udp_rcast_add(b, &remote);\n\tif (err)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tif (ub->ubsock)\n\t\tudp_tunnel_sock_release(ub->ubsock);\n\tkfree(ub);\n\treturn err;\n}",
      "code_after_change": "static int tipc_udp_enable(struct net *net, struct tipc_bearer *b,\n\t\t\t   struct nlattr *attrs[])\n{\n\tint err = -EINVAL;\n\tstruct udp_bearer *ub;\n\tstruct udp_media_addr remote = {0};\n\tstruct udp_media_addr local = {0};\n\tstruct udp_port_cfg udp_conf = {0};\n\tstruct udp_tunnel_sock_cfg tuncfg = {NULL};\n\tstruct nlattr *opts[TIPC_NLA_UDP_MAX + 1];\n\n\tub = kzalloc(sizeof(*ub), GFP_ATOMIC);\n\tif (!ub)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&ub->rcast.list);\n\n\tif (!attrs[TIPC_NLA_BEARER_UDP_OPTS])\n\t\tgoto err;\n\n\tif (nla_parse_nested(opts, TIPC_NLA_UDP_MAX,\n\t\t\t     attrs[TIPC_NLA_BEARER_UDP_OPTS],\n\t\t\t     tipc_nl_udp_policy))\n\t\tgoto err;\n\n\tif (!opts[TIPC_NLA_UDP_LOCAL] || !opts[TIPC_NLA_UDP_REMOTE]) {\n\t\tpr_err(\"Invalid UDP bearer configuration\");\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_LOCAL], &local,\n\t\t\t\t  &ub->ifindex);\n\tif (err)\n\t\tgoto err;\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_REMOTE], &remote, NULL);\n\tif (err)\n\t\tgoto err;\n\n\tb->bcast_addr.media_id = TIPC_MEDIA_TYPE_UDP;\n\tb->bcast_addr.broadcast = 1;\n\trcu_assign_pointer(b->media_ptr, ub);\n\trcu_assign_pointer(ub->bearer, b);\n\ttipc_udp_media_addr_set(&b->addr, &local);\n\tif (local.proto == htons(ETH_P_IP)) {\n\t\tstruct net_device *dev;\n\n\t\tdev = __ip_dev_find(net, local.ipv4.s_addr, false);\n\t\tif (!dev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tudp_conf.family = AF_INET;\n\t\tudp_conf.local_ip.s_addr = htonl(INADDR_ANY);\n\t\tudp_conf.use_udp_checksums = false;\n\t\tub->ifindex = dev->ifindex;\n\t\tif (tipc_mtu_bad(dev, sizeof(struct iphdr) +\n\t\t\t\t      sizeof(struct udphdr))) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tb->mtu = dev->mtu - sizeof(struct iphdr)\n\t\t\t- sizeof(struct udphdr);\n#if IS_ENABLED(CONFIG_IPV6)\n\t} else if (local.proto == htons(ETH_P_IPV6)) {\n\t\tudp_conf.family = AF_INET6;\n\t\tudp_conf.use_udp6_tx_checksums = true;\n\t\tudp_conf.use_udp6_rx_checksums = true;\n\t\tudp_conf.local_ip6 = in6addr_any;\n\t\tb->mtu = 1280;\n#endif\n\t} else {\n\t\terr = -EAFNOSUPPORT;\n\t\tgoto err;\n\t}\n\tudp_conf.local_udp_port = local.port;\n\terr = udp_sock_create(net, &udp_conf, &ub->ubsock);\n\tif (err)\n\t\tgoto err;\n\ttuncfg.sk_user_data = ub;\n\ttuncfg.encap_type = 1;\n\ttuncfg.encap_rcv = tipc_udp_recv;\n\ttuncfg.encap_destroy = NULL;\n\tsetup_udp_tunnel_sock(net, ub->ubsock, &tuncfg);\n\n\t/**\n\t * The bcast media address port is used for all peers and the ip\n\t * is used if it's a multicast address.\n\t */\n\tmemcpy(&b->bcast_addr.value, &remote, sizeof(remote));\n\tif (tipc_udp_is_mcast_addr(&remote))\n\t\terr = enable_mcast(ub, &remote);\n\telse\n\t\terr = tipc_udp_rcast_add(b, &remote);\n\tif (err)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tif (ub->ubsock)\n\t\tudp_tunnel_sock_release(ub->ubsock);\n\tkfree(ub);\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (tipc_mtu_bad(dev, sizeof(struct iphdr) +",
          "\t\t\t\t      sizeof(struct udphdr))) {",
          "\t\t\terr = -EINVAL;",
          "\t\t\tgoto err;",
          "\t\t}"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper validation of the relationship between the minimum fragment length and the maximum packet size.",
      "trigger_condition": "Local users with CAP_NET_ADMIN capability can exploit the vulnerability by manipulating the packet size to cause a heap-based buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the minimum fragment length against the maximum packet size, allowing for a potential heap-based buffer overflow if the packet size exceeds the available buffer space.",
      "id": 96,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1, struct tipc_bearer *VAR2,\nstruct nlattr *VAR3[])\n{\nint VAR4 = -VAR5;\nstruct udp_bearer *VAR6;\nstruct udp_media_addr VAR7 = {0};\nstruct udp_media_addr VAR8 = {0};\nstruct udp_port_cfg VAR9 = {0};\nstruct udp_tunnel_sock_cfg VAR10 = {NULL};\nstruct nlattr *VAR11[VAR12 + 1];\nVAR6 = FUN2(sizeof(*VAR6), VAR13);\nif (!VAR6)\nreturn -VAR14;\nFUN3(&VAR6->VAR15.VAR16);\nif (!VAR3[VAR17])\ngoto VAR4;\nif (FUN4(VAR11, VAR12,\nVAR3[VAR17],\nVAR18))\ngoto VAR4;\nif (!VAR11[VAR19] || !VAR11[VAR20]) {\nFUN5(\"STR\");\nVAR4 = -VAR5;\ngoto VAR4;\n}\nVAR4 = FUN6(VAR11[VAR19], &VAR8,\n&VAR6->VAR21);\nif (VAR4)\ngoto VAR4;\nVAR4 = FUN6(VAR11[VAR20], &VAR7, NULL);\nif (VAR4)\ngoto VAR4;\nVAR2->VAR22.VAR23 = VAR24;\nVAR2->VAR22.VAR25 = 1;\nFUN7(VAR2->VAR26, VAR6);\nFUN7(VAR6->VAR27, VAR2);\nFUN8(&VAR2->VAR28, &VAR8);\nif (VAR8.VAR29 == FUN9(VAR30)) {\nstruct net_device *VAR31;\nVAR31 = FUN10(VAR1, VAR8.VAR32.VAR33, false);\nif (!VAR31) {\nVAR4 = -VAR34;\ngoto VAR4;\n}\nVAR9.VAR35 = VAR36;\nVAR9.VAR37.VAR33 = FUN11(VAR38);\nVAR9.VAR39 = false;\nVAR6->VAR21 = VAR31->VAR21;\nif (FUN12(VAR31, sizeof(struct VAR40) +\nsizeof(struct VAR41))) {\nVAR4 = -VAR5;\ngoto VAR4;\n}\nVAR2->VAR42 = VAR31->VAR42 - sizeof(struct VAR40)\n- sizeof(struct VAR41);\n#if FUN13(VAR43)\n} else if (VAR8.VAR29 == FUN9(VAR44)) {\nVAR9.VAR35 = VAR45;\nVAR9.VAR46 = true;\nVAR9.VAR47 = true;\nVAR9.VAR48 = VAR49;\nVAR2->VAR42 = 1280;\n#VAR50\n} else {\nVAR4 = -VAR51;\ngoto VAR4;\n}\nVAR9.VAR52 = VAR8.VAR53;\nVAR4 = FUN14(VAR1, &VAR9, &VAR6->VAR54);\nif (VAR4)\ngoto VAR4;\nVAR10.VAR55 = VAR6;\nVAR10.VAR56 = 1;\nVAR10.VAR57 = VAR58;\nVAR10.VAR59 = NULL;\nFUN15(VAR1, VAR6->VAR54, &VAR10);\nFUN16(&VAR2->VAR22.VAR60, &VAR7, sizeof(VAR7));\nif (FUN17(&VAR7))\nVAR4 = FUN18(VAR6, &VAR7);\nelse\nVAR4 = FUN19(VAR2, &VAR7);\nif (VAR4)\ngoto VAR4;\nreturn 0;\nVAR4:\nif (VAR6->VAR54)\nFUN20(VAR6->VAR54);\nFUN21(VAR6);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1, struct tipc_bearer *VAR2,\nstruct nlattr *VAR3[])\n{\nint VAR4 = -VAR5;\nstruct udp_bearer *VAR6;\nstruct udp_media_addr VAR7 = {0};\nstruct udp_media_addr VAR8 = {0};\nstruct udp_port_cfg VAR9 = {0};\nstruct udp_tunnel_sock_cfg VAR10 = {NULL};\nstruct nlattr *VAR11[VAR12 + 1];\nVAR6 = FUN2(sizeof(*VAR6), VAR13);\nif (!VAR6)\nreturn -VAR14;\nFUN3(&VAR6->VAR15.VAR16);\nif (!VAR3[VAR17])\ngoto VAR4;\nif (FUN4(VAR11, VAR12,\nVAR3[VAR17],\nVAR18))\ngoto VAR4;\nif (!VAR11[VAR19] || !VAR11[VAR20]) {\nFUN5(\"STR\");\nVAR4 = -VAR5;\ngoto VAR4;\n}\nVAR4 = FUN6(VAR11[VAR19], &VAR8,\n&VAR6->VAR21);\nif (VAR4)\ngoto VAR4;\nVAR4 = FUN6(VAR11[VAR20], &VAR7, NULL);\nif (VAR4)\ngoto VAR4;\nVAR2->VAR22.VAR23 = VAR24;\nVAR2->VAR22.VAR25 = 1;\nFUN7(VAR2->VAR26, VAR6);\nFUN7(VAR6->VAR27, VAR2);\nFUN8(&VAR2->VAR28, &VAR8);\nif (VAR8.VAR29 == FUN9(VAR30)) {\nstruct net_device *VAR31;\nVAR31 = FUN10(VAR1, VAR8.VAR32.VAR33, false);\nif (!VAR31) {\nVAR4 = -VAR34;\ngoto VAR4;\n}\nVAR9.VAR35 = VAR36;\nVAR9.VAR37.VAR33 = FUN11(VAR38);\nVAR9.VAR39 = false;\nVAR6->VAR21 = VAR31->VAR21;\nVAR2->VAR40 = VAR31->VAR40 - sizeof(struct VAR41)\n- sizeof(struct VAR42);\n#if FUN12(VAR43)\n} else if (VAR8.VAR29 == FUN9(VAR44)) {\nVAR9.VAR35 = VAR45;\nVAR9.VAR46 = true;\nVAR9.VAR47 = true;\nVAR9.VAR48 = VAR49;\nVAR2->VAR40 = 1280;\n#VAR50\n} else {\nVAR4 = -VAR51;\ngoto VAR4;\n}\nVAR9.VAR52 = VAR8.VAR53;\nVAR4 = FUN13(VAR1, &VAR9, &VAR6->VAR54);\nif (VAR4)\ngoto VAR4;\nVAR10.VAR55 = VAR6;\nVAR10.VAR56 = 1;\nVAR10.VAR57 = VAR58;\nVAR10.VAR59 = NULL;\nFUN14(VAR1, VAR6->VAR54, &VAR10);\nFUN15(&VAR2->VAR22.VAR60, &VAR7, sizeof(VAR7));\nif (FUN16(&VAR7))\nVAR4 = FUN17(VAR6, &VAR7);\nelse\nVAR4 = FUN18(VAR2, &VAR7);\nif (VAR4)\ngoto VAR4;\nreturn 0;\nVAR4:\nif (VAR6->VAR54)\nFUN19(VAR6->VAR54);\nFUN20(VAR6);\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int tipc_udp_enable(struct net *net, struct tipc_bearer *b,\nstruct nlattr *attrs[])\n{\nint err = -EINVAL;\nstruct udp_bearer *ub;\nstruct udp_media_addr remote = {0};\nstruct udp_media_addr local = {0};\nstruct udp_port_cfg udp_conf = {0};\nstruct udp_tunnel_sock_cfg tuncfg = {NULL};\nstruct nlattr *opts[TIPC_NLA_UDP_MAX + 1];\nub = kzalloc(sizeof(*ub), GFP_ATOMIC);\nif (!ub)\nreturn -ENOMEM;\nINIT_LIST_HEAD(&ub->rcast.list);\nif (!attrs[TIPC_NLA_BEARER_UDP_OPTS])\ngoto err;\nif (nla_parse_nested(opts, TIPC_NLA_UDP_MAX,\nattrs[TIPC_NLA_BEARER_UDP_OPTS],\ntipc_nl_udp_policy))\ngoto err;\nif (!opts[TIPC_NLA_UDP_LOCAL] || !opts[TIPC_NLA_UDP_REMOTE]) {\npr_err(\"Invalid UDP bearer configuration\");\nerr = -EINVAL;\ngoto err;\n}\nerr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_LOCAL], &local,\n&ub->ifindex);\nif (err)\ngoto err;\nerr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_REMOTE], &remote, NULL);\nif (err)\ngoto err;\nb->bcast_addr.media_id = TIPC_MEDIA_TYPE_UDP;\nb->bcast_addr.broadcast = 1;\nrcu_assign_pointer(b->media_ptr, ub);\nrcu_assign_pointer(ub->bearer, b);\ntipc_udp_media_addr_set(&b->addr, &local);\nif (local.proto == htons(ETH_P_IP)) {\nstruct net_device *dev;\ndev = __ip_dev_find(net, local.ipv4.s_addr, false);\nif (!dev) {\nerr = -ENODEV;\ngoto err;\n}\nudp_conf.family = AF_INET;\nudp_conf.local_ip.s_addr = htonl(INADDR_ANY);\nudp_conf.use_udp_checksums = false;\nub->ifindex = dev->ifindex;\nif (tipc_mtu_bad(dev, sizeof(struct iphdr) +\nsizeof(struct udphdr))) {\nerr = -EINVAL;\ngoto err;\n}\nb->mtu = dev->mtu - sizeof(struct iphdr)\n- sizeof(struct udphdr);\n#if IS_ENABLED(CONFIG_IPV6)\n} else if (local.proto == htons(ETH_P_IPV6)) {\nudp_conf.family = AF_INET6;\nudp_conf.use_udp6_tx_checksums = true;\nudp_conf.use_udp6_rx_checksums = true;\nudp_conf.local_ip6 = in6addr_any;\nb->mtu = 1280;\n#endif\n} else {\nerr = -EAFNOSUPPORT;\ngoto err;\n}\nudp_conf.local_udp_port = local.port;\nerr = udp_sock_create(net, &udp_conf, &ub->ubsock);\nif (err)\ngoto err;\ntuncfg.sk_user_data = ub;\ntuncfg.encap_type = 1;\ntuncfg.encap_rcv = tipc_udp_recv;\ntuncfg.encap_destroy = NULL;\nsetup_udp_tunnel_sock(net, ub->ubsock, &tuncfg);\nmemcpy(&b->bcast_addr.value, &remote, sizeof(remote));\nif (tipc_udp_is_mcast_addr(&remote))\nerr = enable_mcast(ub, &remote);\nelse\nerr = tipc_udp_rcast_add(b, &remote);\nif (err)\ngoto err;\nreturn 0;\nerr:\nif (ub->ubsock)\nudp_tunnel_sock_release(ub->ubsock);\nkfree(ub);\nreturn err;\n}\n",
      "code_before_change_raw": "static int tipc_udp_enable(struct net *net, struct tipc_bearer *b,\nstruct nlattr *attrs[])\n{\nint err = -EINVAL;\nstruct udp_bearer *ub;\nstruct udp_media_addr remote = {0};\nstruct udp_media_addr local = {0};\nstruct udp_port_cfg udp_conf = {0};\nstruct udp_tunnel_sock_cfg tuncfg = {NULL};\nstruct nlattr *opts[TIPC_NLA_UDP_MAX + 1];\nub = kzalloc(sizeof(*ub), GFP_ATOMIC);\nif (!ub)\nreturn -ENOMEM;\nINIT_LIST_HEAD(&ub->rcast.list);\nif (!attrs[TIPC_NLA_BEARER_UDP_OPTS])\ngoto err;\nif (nla_parse_nested(opts, TIPC_NLA_UDP_MAX,\nattrs[TIPC_NLA_BEARER_UDP_OPTS],\ntipc_nl_udp_policy))\ngoto err;\nif (!opts[TIPC_NLA_UDP_LOCAL] || !opts[TIPC_NLA_UDP_REMOTE]) {\npr_err(\"Invalid UDP bearer configuration\");\nerr = -EINVAL;\ngoto err;\n}\nerr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_LOCAL], &local,\n&ub->ifindex);\nif (err)\ngoto err;\nerr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_REMOTE], &remote, NULL);\nif (err)\ngoto err;\nb->bcast_addr.media_id = TIPC_MEDIA_TYPE_UDP;\nb->bcast_addr.broadcast = 1;\nrcu_assign_pointer(b->media_ptr, ub);\nrcu_assign_pointer(ub->bearer, b);\ntipc_udp_media_addr_set(&b->addr, &local);\nif (local.proto == htons(ETH_P_IP)) {\nstruct net_device *dev;\ndev = __ip_dev_find(net, local.ipv4.s_addr, false);\nif (!dev) {\nerr = -ENODEV;\ngoto err;\n}\nudp_conf.family = AF_INET;\nudp_conf.local_ip.s_addr = htonl(INADDR_ANY);\nudp_conf.use_udp_checksums = false;\nub->ifindex = dev->ifindex;\nb->mtu = dev->mtu - sizeof(struct iphdr)\n- sizeof(struct udphdr);\n#if IS_ENABLED(CONFIG_IPV6)\n} else if (local.proto == htons(ETH_P_IPV6)) {\nudp_conf.family = AF_INET6;\nudp_conf.use_udp6_tx_checksums = true;\nudp_conf.use_udp6_rx_checksums = true;\nudp_conf.local_ip6 = in6addr_any;\nb->mtu = 1280;\n#endif\n} else {\nerr = -EAFNOSUPPORT;\ngoto err;\n}\nudp_conf.local_udp_port = local.port;\nerr = udp_sock_create(net, &udp_conf, &ub->ubsock);\nif (err)\ngoto err;\ntuncfg.sk_user_data = ub;\ntuncfg.encap_type = 1;\ntuncfg.encap_rcv = tipc_udp_recv;\ntuncfg.encap_destroy = NULL;\nsetup_udp_tunnel_sock(net, ub->ubsock, &tuncfg);\nmemcpy(&b->bcast_addr.value, &remote, sizeof(remote));\nif (tipc_udp_is_mcast_addr(&remote))\nerr = enable_mcast(ub, &remote);\nelse\nerr = tipc_udp_rcast_add(b, &remote);\nif (err)\ngoto err;\nreturn 0;\nerr:\nif (ub->ubsock)\nudp_tunnel_sock_release(ub->ubsock);\nkfree(ub);\nreturn err;\n}\n"
    }
  ],
  "CVE-2016-8633": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper input validation for incoming packet data length in a network packet processing function.",
        "trigger_condition": "Receiving crafted fragmented packets in certain hardware configurations can lead to buffer overflow and out-of-bounds access vulnerabilities.",
        "specific_code_behavior_causing_vulnerability": "The code does not check the length of incoming packet data before processing it, allowing potential buffer overflow and out-of-bounds access vulnerabilities to be exploited by remote attackers."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add checks to ensure that the length of incoming packet data is within expected bounds before processing it. Specifically, the code should verify that the length is greater than the size of the unfragmented header and the fragmented header, and ensure that the fragment offset and length do not exceed the datagram size. By adding these checks, the code can prevent buffer overflow and out-of-bounds access vulnerabilities from being exploited.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-8633, which allows remote attackers to execute arbitrary code via crafted fragmented packets in certain unusual hardware configurations. \n\nThe vulnerability arises from the lack of proper input validation in the original code snippet. By not checking the length of the incoming packet data before processing it, the code is susceptible to buffer overflow and out-of-bounds access vulnerabilities.\n\nThe modified code snippet adds checks to ensure that the length of the incoming packet data is within expected bounds before processing it. Specifically, it checks if the length is greater than the size of the unfragmented header and the fragmented header to prevent potential buffer overflow issues. Additionally, it verifies that the fragment offset and length do not exceed the datagram size to prevent out-of-bounds access.\n\nBy adding these checks, the modified code snippet helps prevent attackers from exploiting the vulnerability by sending crafted fragmented packets that could lead to arbitrary code execution.",
      "GPT_purpose": "Handle incoming FireWire network packets, either unfragmented or fragmented, and process them accordingly.",
      "GPT_function": "\n1. Process incoming packets on a FireWire network device.\n2. Handle unfragmented datagrams and build an skb around them.\n3. Handle fragmented datagrams and manage datagram fragments.",
      "CVE_id": "CVE-2016-8633",
      "code_before_change": "static int fwnet_incoming_packet(struct fwnet_device *dev, __be32 *buf, int len,\n\t\t\t\t int source_node_id, int generation,\n\t\t\t\t bool is_broadcast)\n{\n\tstruct sk_buff *skb;\n\tstruct net_device *net = dev->netdev;\n\tstruct rfc2734_header hdr;\n\tunsigned lf;\n\tunsigned long flags;\n\tstruct fwnet_peer *peer;\n\tstruct fwnet_partial_datagram *pd;\n\tint fg_off;\n\tint dg_size;\n\tu16 datagram_label;\n\tint retval;\n\tu16 ether_type;\n\n\thdr.w0 = be32_to_cpu(buf[0]);\n\tlf = fwnet_get_hdr_lf(&hdr);\n\tif (lf == RFC2374_HDR_UNFRAG) {\n\t\t/*\n\t\t * An unfragmented datagram has been received by the ieee1394\n\t\t * bus. Build an skbuff around it so we can pass it to the\n\t\t * high level network layer.\n\t\t */\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tbuf++;\n\t\tlen -= RFC2374_UNFRAG_HDR_SIZE;\n\n\t\tskb = dev_alloc_skb(len + LL_RESERVED_SPACE(net));\n\t\tif (unlikely(!skb)) {\n\t\t\tnet->stats.rx_dropped++;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tskb_reserve(skb, LL_RESERVED_SPACE(net));\n\t\tmemcpy(skb_put(skb, len), buf, len);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    is_broadcast, ether_type);\n\t}\n\t/* A datagram fragment has been received, now the fun begins. */\n\thdr.w1 = ntohl(buf[1]);\n\tbuf += 2;\n\tlen -= RFC2374_FRAG_HDR_SIZE;\n\tif (lf == RFC2374_HDR_FIRSTFRAG) {\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tfg_off = 0;\n\t} else {\n\t\tether_type = 0;\n\t\tfg_off = fwnet_get_hdr_fg_off(&hdr);\n\t}\n\tdatagram_label = fwnet_get_hdr_dgl(&hdr);\n\tdg_size = fwnet_get_hdr_dg_size(&hdr); /* ??? + 1 */\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\tpeer = fwnet_peer_find_by_node_id(dev, source_node_id, generation);\n\tif (!peer) {\n\t\tretval = -ENOENT;\n\t\tgoto fail;\n\t}\n\n\tpd = fwnet_pd_find(peer, datagram_label);\n\tif (pd == NULL) {\n\t\twhile (peer->pdg_size >= FWNET_MAX_FRAGMENTS) {\n\t\t\t/* remove the oldest */\n\t\t\tfwnet_pd_delete(list_first_entry(&peer->pd_list,\n\t\t\t\tstruct fwnet_partial_datagram, pd_link));\n\t\t\tpeer->pdg_size--;\n\t\t}\n\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t  dg_size, buf, fg_off, len);\n\t\tif (pd == NULL) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tpeer->pdg_size++;\n\t} else {\n\t\tif (fwnet_frag_overlap(pd, fg_off, len) ||\n\t\t    pd->datagram_size != dg_size) {\n\t\t\t/*\n\t\t\t * Differing datagram sizes or overlapping fragments,\n\t\t\t * discard old datagram and start a new one.\n\t\t\t */\n\t\t\tfwnet_pd_delete(pd);\n\t\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t\t  dg_size, buf, fg_off, len);\n\t\t\tif (pd == NULL) {\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!fwnet_pd_update(peer, pd, buf, fg_off, len)) {\n\t\t\t\t/*\n\t\t\t\t * Couldn't save off fragment anyway\n\t\t\t\t * so might as well obliterate the\n\t\t\t\t * datagram now.\n\t\t\t\t */\n\t\t\t\tfwnet_pd_delete(pd);\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t}\n\t} /* new datagram or add to existing one */\n\n\tif (lf == RFC2374_HDR_FIRSTFRAG)\n\t\tpd->ether_type = ether_type;\n\n\tif (fwnet_pd_is_complete(pd)) {\n\t\tether_type = pd->ether_type;\n\t\tpeer->pdg_size--;\n\t\tskb = skb_get(pd->skb);\n\t\tfwnet_pd_delete(pd);\n\n\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    false, ether_type);\n\t}\n\t/*\n\t * Datagram is not complete, we're done for the\n\t * moment.\n\t */\n\tretval = 0;\n fail:\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\treturn retval;\n}",
      "code_after_change": "static int fwnet_incoming_packet(struct fwnet_device *dev, __be32 *buf, int len,\n\t\t\t\t int source_node_id, int generation,\n\t\t\t\t bool is_broadcast)\n{\n\tstruct sk_buff *skb;\n\tstruct net_device *net = dev->netdev;\n\tstruct rfc2734_header hdr;\n\tunsigned lf;\n\tunsigned long flags;\n\tstruct fwnet_peer *peer;\n\tstruct fwnet_partial_datagram *pd;\n\tint fg_off;\n\tint dg_size;\n\tu16 datagram_label;\n\tint retval;\n\tu16 ether_type;\n\n\tif (len <= RFC2374_UNFRAG_HDR_SIZE)\n\t\treturn 0;\n\n\thdr.w0 = be32_to_cpu(buf[0]);\n\tlf = fwnet_get_hdr_lf(&hdr);\n\tif (lf == RFC2374_HDR_UNFRAG) {\n\t\t/*\n\t\t * An unfragmented datagram has been received by the ieee1394\n\t\t * bus. Build an skbuff around it so we can pass it to the\n\t\t * high level network layer.\n\t\t */\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tbuf++;\n\t\tlen -= RFC2374_UNFRAG_HDR_SIZE;\n\n\t\tskb = dev_alloc_skb(len + LL_RESERVED_SPACE(net));\n\t\tif (unlikely(!skb)) {\n\t\t\tnet->stats.rx_dropped++;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tskb_reserve(skb, LL_RESERVED_SPACE(net));\n\t\tmemcpy(skb_put(skb, len), buf, len);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    is_broadcast, ether_type);\n\t}\n\n\t/* A datagram fragment has been received, now the fun begins. */\n\n\tif (len <= RFC2374_FRAG_HDR_SIZE)\n\t\treturn 0;\n\n\thdr.w1 = ntohl(buf[1]);\n\tbuf += 2;\n\tlen -= RFC2374_FRAG_HDR_SIZE;\n\tif (lf == RFC2374_HDR_FIRSTFRAG) {\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tfg_off = 0;\n\t} else {\n\t\tether_type = 0;\n\t\tfg_off = fwnet_get_hdr_fg_off(&hdr);\n\t}\n\tdatagram_label = fwnet_get_hdr_dgl(&hdr);\n\tdg_size = fwnet_get_hdr_dg_size(&hdr); /* ??? + 1 */\n\n\tif (fg_off + len > dg_size)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\tpeer = fwnet_peer_find_by_node_id(dev, source_node_id, generation);\n\tif (!peer) {\n\t\tretval = -ENOENT;\n\t\tgoto fail;\n\t}\n\n\tpd = fwnet_pd_find(peer, datagram_label);\n\tif (pd == NULL) {\n\t\twhile (peer->pdg_size >= FWNET_MAX_FRAGMENTS) {\n\t\t\t/* remove the oldest */\n\t\t\tfwnet_pd_delete(list_first_entry(&peer->pd_list,\n\t\t\t\tstruct fwnet_partial_datagram, pd_link));\n\t\t\tpeer->pdg_size--;\n\t\t}\n\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t  dg_size, buf, fg_off, len);\n\t\tif (pd == NULL) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tpeer->pdg_size++;\n\t} else {\n\t\tif (fwnet_frag_overlap(pd, fg_off, len) ||\n\t\t    pd->datagram_size != dg_size) {\n\t\t\t/*\n\t\t\t * Differing datagram sizes or overlapping fragments,\n\t\t\t * discard old datagram and start a new one.\n\t\t\t */\n\t\t\tfwnet_pd_delete(pd);\n\t\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t\t  dg_size, buf, fg_off, len);\n\t\t\tif (pd == NULL) {\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!fwnet_pd_update(peer, pd, buf, fg_off, len)) {\n\t\t\t\t/*\n\t\t\t\t * Couldn't save off fragment anyway\n\t\t\t\t * so might as well obliterate the\n\t\t\t\t * datagram now.\n\t\t\t\t */\n\t\t\t\tfwnet_pd_delete(pd);\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t}\n\t} /* new datagram or add to existing one */\n\n\tif (lf == RFC2374_HDR_FIRSTFRAG)\n\t\tpd->ether_type = ether_type;\n\n\tif (fwnet_pd_is_complete(pd)) {\n\t\tether_type = pd->ether_type;\n\t\tpeer->pdg_size--;\n\t\tskb = skb_get(pd->skb);\n\t\tfwnet_pd_delete(pd);\n\n\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    false, ether_type);\n\t}\n\t/*\n\t * Datagram is not complete, we're done for the\n\t * moment.\n\t */\n\tretval = 0;\n fail:\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\treturn retval;\n}",
      "modified_lines": {
        "added": [
          "",
          "\tif (len <= RFC2374_UNFRAG_HDR_SIZE)",
          "\t\treturn 0;",
          "",
          "",
          "\tif (len <= RFC2374_FRAG_HDR_SIZE)",
          "\t\treturn 0;",
          "",
          "",
          "\tif (fg_off + len > dg_size)",
          "\t\treturn 0;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper input validation for incoming packet data length in a network packet processing function.",
      "trigger_condition": "Receiving crafted fragmented packets in certain hardware configurations can lead to buffer overflow and out-of-bounds access vulnerabilities.",
      "specific_code_behavior_causing_vulnerability": "The code does not check the length of incoming packet data before processing it, allowing potential buffer overflow and out-of-bounds access vulnerabilities to be exploited by remote attackers.",
      "id": 97,
      "code_after_change_normalized": "static int FUN1(struct fwnet_device *VAR1, __be32 *VAR2, int VAR3,\nint VAR4, int VAR5,\nbool VAR6)\n{\nstruct sk_buff *VAR7;\nstruct net_device *VAR8 = VAR1->VAR9;\nstruct rfc2734_header VAR10;\nunsigned VAR11;\nunsigned long VAR12;\nstruct fwnet_peer *VAR13;\nstruct fwnet_partial_datagram *VAR14;\nint VAR15;\nint VAR16;\nu16 VAR17;\nint VAR18;\nu16 VAR19;\nif (VAR3 <= VAR20)\nreturn 0;\nVAR10.VAR21 = FUN2(VAR2[0]);\nVAR11 = FUN3(&VAR10);\nif (VAR11 == VAR22) {\nVAR19 = FUN4(&VAR10);\nVAR2++;\nVAR3 -= VAR20;\nVAR7 = FUN5(VAR3 + FUN6(VAR8));\nif (FUN7(!VAR7)) {\nVAR8->VAR23.VAR24++;\nreturn -VAR25;\n}\nFUN8(VAR7, FUN6(VAR8));\nFUN9(FUN10(VAR7, VAR3), VAR2, VAR3);\nreturn FUN11(VAR8, VAR7, VAR4,\nVAR6, VAR19);\n}\nif (VAR3 <= VAR26)\nreturn 0;\nVAR10.VAR27 = FUN12(VAR2[1]);\nVAR2 += 2;\nVAR3 -= VAR26;\nif (VAR11 == VAR28) {\nVAR19 = FUN4(&VAR10);\nVAR15 = 0;\n} else {\nVAR19 = 0;\nVAR15 = FUN13(&VAR10);\n}\nVAR17 = FUN14(&VAR10);\nVAR16 = FUN15(&VAR10); \nif (VAR15 + VAR3 > VAR16)\nreturn 0;\nFUN16(&VAR1->VAR29, VAR12);\nVAR13 = FUN17(VAR1, VAR4, VAR5);\nif (!VAR13) {\nVAR18 = -VAR30;\ngoto VAR31;\n}\nVAR14 = FUN18(VAR13, VAR17);\nif (VAR14 == NULL) {\nwhile (VAR13->VAR32 >= VAR33) {\nFUN19(FUN20(&VAR13->VAR34,\nstruct VAR35, VAR36));\nVAR13->VAR32--;\n}\nVAR14 = FUN21(VAR8, VAR13, VAR17,\nVAR16, VAR2, VAR15, VAR3);\nif (VAR14 == NULL) {\nVAR18 = -VAR25;\ngoto VAR31;\n}\nVAR13->VAR32++;\n} else {\nif (FUN22(VAR14, VAR15, VAR3) ||\nVAR14->VAR37 != VAR16) {\nFUN19(VAR14);\nVAR14 = FUN21(VAR8, VAR13, VAR17,\nVAR16, VAR2, VAR15, VAR3);\nif (VAR14 == NULL) {\nVAR13->VAR32--;\nVAR18 = -VAR25;\ngoto VAR31;\n}\n} else {\nif (!FUN23(VAR13, VAR14, VAR2, VAR15, VAR3)) {\nFUN19(VAR14);\nVAR13->VAR32--;\nVAR18 = -VAR25;\ngoto VAR31;\n}\n}\n} \nif (VAR11 == VAR28)\nVAR14->VAR19 = VAR19;\nif (FUN24(VAR14)) {\nVAR19 = VAR14->VAR19;\nVAR13->VAR32--;\nVAR7 = FUN25(VAR14->VAR7);\nFUN19(VAR14);\nFUN26(&VAR1->VAR29, VAR12);\nreturn FUN11(VAR8, VAR7, VAR4,\nfalse, VAR19);\n}\nVAR18 = 0;\nVAR31:\nFUN26(&VAR1->VAR29, VAR12);\nreturn VAR18;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct fwnet_device *VAR1, __be32 *VAR2, int VAR3,\nint VAR4, int VAR5,\nbool VAR6)\n{\nstruct sk_buff *VAR7;\nstruct net_device *VAR8 = VAR1->VAR9;\nstruct rfc2734_header VAR10;\nunsigned VAR11;\nunsigned long VAR12;\nstruct fwnet_peer *VAR13;\nstruct fwnet_partial_datagram *VAR14;\nint VAR15;\nint VAR16;\nu16 VAR17;\nint VAR18;\nu16 VAR19;\nVAR10.VAR20 = FUN2(VAR2[0]);\nVAR11 = FUN3(&VAR10);\nif (VAR11 == VAR21) {\nVAR19 = FUN4(&VAR10);\nVAR2++;\nVAR3 -= VAR22;\nVAR7 = FUN5(VAR3 + FUN6(VAR8));\nif (FUN7(!VAR7)) {\nVAR8->VAR23.VAR24++;\nreturn -VAR25;\n}\nFUN8(VAR7, FUN6(VAR8));\nFUN9(FUN10(VAR7, VAR3), VAR2, VAR3);\nreturn FUN11(VAR8, VAR7, VAR4,\nVAR6, VAR19);\n}\nVAR10.VAR26 = FUN12(VAR2[1]);\nVAR2 += 2;\nVAR3 -= VAR27;\nif (VAR11 == VAR28) {\nVAR19 = FUN4(&VAR10);\nVAR15 = 0;\n} else {\nVAR19 = 0;\nVAR15 = FUN13(&VAR10);\n}\nVAR17 = FUN14(&VAR10);\nVAR16 = FUN15(&VAR10); \nFUN16(&VAR1->VAR29, VAR12);\nVAR13 = FUN17(VAR1, VAR4, VAR5);\nif (!VAR13) {\nVAR18 = -VAR30;\ngoto VAR31;\n}\nVAR14 = FUN18(VAR13, VAR17);\nif (VAR14 == NULL) {\nwhile (VAR13->VAR32 >= VAR33) {\nFUN19(FUN20(&VAR13->VAR34,\nstruct VAR35, VAR36));\nVAR13->VAR32--;\n}\nVAR14 = FUN21(VAR8, VAR13, VAR17,\nVAR16, VAR2, VAR15, VAR3);\nif (VAR14 == NULL) {\nVAR18 = -VAR25;\ngoto VAR31;\n}\nVAR13->VAR32++;\n} else {\nif (FUN22(VAR14, VAR15, VAR3) ||\nVAR14->VAR37 != VAR16) {\nFUN19(VAR14);\nVAR14 = FUN21(VAR8, VAR13, VAR17,\nVAR16, VAR2, VAR15, VAR3);\nif (VAR14 == NULL) {\nVAR13->VAR32--;\nVAR18 = -VAR25;\ngoto VAR31;\n}\n} else {\nif (!FUN23(VAR13, VAR14, VAR2, VAR15, VAR3)) {\nFUN19(VAR14);\nVAR13->VAR32--;\nVAR18 = -VAR25;\ngoto VAR31;\n}\n}\n} \nif (VAR11 == VAR28)\nVAR14->VAR19 = VAR19;\nif (FUN24(VAR14)) {\nVAR19 = VAR14->VAR19;\nVAR13->VAR32--;\nVAR7 = FUN25(VAR14->VAR7);\nFUN19(VAR14);\nFUN26(&VAR1->VAR29, VAR12);\nreturn FUN11(VAR8, VAR7, VAR4,\nfalse, VAR19);\n}\nVAR18 = 0;\nVAR31:\nFUN26(&VAR1->VAR29, VAR12);\nreturn VAR18;\n}\n",
      "code_after_change_raw": "static int fwnet_incoming_packet(struct fwnet_device *dev, __be32 *buf, int len,\nint source_node_id, int generation,\nbool is_broadcast)\n{\nstruct sk_buff *skb;\nstruct net_device *net = dev->netdev;\nstruct rfc2734_header hdr;\nunsigned lf;\nunsigned long flags;\nstruct fwnet_peer *peer;\nstruct fwnet_partial_datagram *pd;\nint fg_off;\nint dg_size;\nu16 datagram_label;\nint retval;\nu16 ether_type;\nif (len <= RFC2374_UNFRAG_HDR_SIZE)\nreturn 0;\nhdr.w0 = be32_to_cpu(buf[0]);\nlf = fwnet_get_hdr_lf(&hdr);\nif (lf == RFC2374_HDR_UNFRAG) {\nether_type = fwnet_get_hdr_ether_type(&hdr);\nbuf++;\nlen -= RFC2374_UNFRAG_HDR_SIZE;\nskb = dev_alloc_skb(len + LL_RESERVED_SPACE(net));\nif (unlikely(!skb)) {\nnet->stats.rx_dropped++;\nreturn -ENOMEM;\n}\nskb_reserve(skb, LL_RESERVED_SPACE(net));\nmemcpy(skb_put(skb, len), buf, len);\nreturn fwnet_finish_incoming_packet(net, skb, source_node_id,\nis_broadcast, ether_type);\n}\nif (len <= RFC2374_FRAG_HDR_SIZE)\nreturn 0;\nhdr.w1 = ntohl(buf[1]);\nbuf += 2;\nlen -= RFC2374_FRAG_HDR_SIZE;\nif (lf == RFC2374_HDR_FIRSTFRAG) {\nether_type = fwnet_get_hdr_ether_type(&hdr);\nfg_off = 0;\n} else {\nether_type = 0;\nfg_off = fwnet_get_hdr_fg_off(&hdr);\n}\ndatagram_label = fwnet_get_hdr_dgl(&hdr);\ndg_size = fwnet_get_hdr_dg_size(&hdr); \nif (fg_off + len > dg_size)\nreturn 0;\nspin_lock_irqsave(&dev->lock, flags);\npeer = fwnet_peer_find_by_node_id(dev, source_node_id, generation);\nif (!peer) {\nretval = -ENOENT;\ngoto fail;\n}\npd = fwnet_pd_find(peer, datagram_label);\nif (pd == NULL) {\nwhile (peer->pdg_size >= FWNET_MAX_FRAGMENTS) {\nfwnet_pd_delete(list_first_entry(&peer->pd_list,\nstruct fwnet_partial_datagram, pd_link));\npeer->pdg_size--;\n}\npd = fwnet_pd_new(net, peer, datagram_label,\ndg_size, buf, fg_off, len);\nif (pd == NULL) {\nretval = -ENOMEM;\ngoto fail;\n}\npeer->pdg_size++;\n} else {\nif (fwnet_frag_overlap(pd, fg_off, len) ||\npd->datagram_size != dg_size) {\nfwnet_pd_delete(pd);\npd = fwnet_pd_new(net, peer, datagram_label,\ndg_size, buf, fg_off, len);\nif (pd == NULL) {\npeer->pdg_size--;\nretval = -ENOMEM;\ngoto fail;\n}\n} else {\nif (!fwnet_pd_update(peer, pd, buf, fg_off, len)) {\nfwnet_pd_delete(pd);\npeer->pdg_size--;\nretval = -ENOMEM;\ngoto fail;\n}\n}\n} \nif (lf == RFC2374_HDR_FIRSTFRAG)\npd->ether_type = ether_type;\nif (fwnet_pd_is_complete(pd)) {\nether_type = pd->ether_type;\npeer->pdg_size--;\nskb = skb_get(pd->skb);\nfwnet_pd_delete(pd);\nspin_unlock_irqrestore(&dev->lock, flags);\nreturn fwnet_finish_incoming_packet(net, skb, source_node_id,\nfalse, ether_type);\n}\nretval = 0;\nfail:\nspin_unlock_irqrestore(&dev->lock, flags);\nreturn retval;\n}\n",
      "code_before_change_raw": "static int fwnet_incoming_packet(struct fwnet_device *dev, __be32 *buf, int len,\nint source_node_id, int generation,\nbool is_broadcast)\n{\nstruct sk_buff *skb;\nstruct net_device *net = dev->netdev;\nstruct rfc2734_header hdr;\nunsigned lf;\nunsigned long flags;\nstruct fwnet_peer *peer;\nstruct fwnet_partial_datagram *pd;\nint fg_off;\nint dg_size;\nu16 datagram_label;\nint retval;\nu16 ether_type;\nhdr.w0 = be32_to_cpu(buf[0]);\nlf = fwnet_get_hdr_lf(&hdr);\nif (lf == RFC2374_HDR_UNFRAG) {\nether_type = fwnet_get_hdr_ether_type(&hdr);\nbuf++;\nlen -= RFC2374_UNFRAG_HDR_SIZE;\nskb = dev_alloc_skb(len + LL_RESERVED_SPACE(net));\nif (unlikely(!skb)) {\nnet->stats.rx_dropped++;\nreturn -ENOMEM;\n}\nskb_reserve(skb, LL_RESERVED_SPACE(net));\nmemcpy(skb_put(skb, len), buf, len);\nreturn fwnet_finish_incoming_packet(net, skb, source_node_id,\nis_broadcast, ether_type);\n}\nhdr.w1 = ntohl(buf[1]);\nbuf += 2;\nlen -= RFC2374_FRAG_HDR_SIZE;\nif (lf == RFC2374_HDR_FIRSTFRAG) {\nether_type = fwnet_get_hdr_ether_type(&hdr);\nfg_off = 0;\n} else {\nether_type = 0;\nfg_off = fwnet_get_hdr_fg_off(&hdr);\n}\ndatagram_label = fwnet_get_hdr_dgl(&hdr);\ndg_size = fwnet_get_hdr_dg_size(&hdr); \nspin_lock_irqsave(&dev->lock, flags);\npeer = fwnet_peer_find_by_node_id(dev, source_node_id, generation);\nif (!peer) {\nretval = -ENOENT;\ngoto fail;\n}\npd = fwnet_pd_find(peer, datagram_label);\nif (pd == NULL) {\nwhile (peer->pdg_size >= FWNET_MAX_FRAGMENTS) {\nfwnet_pd_delete(list_first_entry(&peer->pd_list,\nstruct fwnet_partial_datagram, pd_link));\npeer->pdg_size--;\n}\npd = fwnet_pd_new(net, peer, datagram_label,\ndg_size, buf, fg_off, len);\nif (pd == NULL) {\nretval = -ENOMEM;\ngoto fail;\n}\npeer->pdg_size++;\n} else {\nif (fwnet_frag_overlap(pd, fg_off, len) ||\npd->datagram_size != dg_size) {\nfwnet_pd_delete(pd);\npd = fwnet_pd_new(net, peer, datagram_label,\ndg_size, buf, fg_off, len);\nif (pd == NULL) {\npeer->pdg_size--;\nretval = -ENOMEM;\ngoto fail;\n}\n} else {\nif (!fwnet_pd_update(peer, pd, buf, fg_off, len)) {\nfwnet_pd_delete(pd);\npeer->pdg_size--;\nretval = -ENOMEM;\ngoto fail;\n}\n}\n} \nif (lf == RFC2374_HDR_FIRSTFRAG)\npd->ether_type = ether_type;\nif (fwnet_pd_is_complete(pd)) {\nether_type = pd->ether_type;\npeer->pdg_size--;\nskb = skb_get(pd->skb);\nfwnet_pd_delete(pd);\nspin_unlock_irqrestore(&dev->lock, flags);\nreturn fwnet_finish_incoming_packet(net, skb, source_node_id,\nfalse, ether_type);\n}\nretval = 0;\nfail:\nspin_unlock_irqrestore(&dev->lock, flags);\nreturn retval;\n}\n"
    }
  ],
  "CVE-2016-8658": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of length validation for the SSID Information Element in a command to a Netlink socket.",
        "trigger_condition": "A local user provides a long SSID Information Element, causing a stack-based buffer overflow in the brcmf_cfg80211_start_ap function.",
        "specific_code_behavior_causing_vulnerability": "The code does not check the length of the SSID Information Element, allowing a potential buffer overflow if the SSID length exceeds the maximum allowed length."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a length validation check for the SSID Information Element to ensure it does not exceed the maximum allowed length. This prevents a stack-based buffer overflow and enhances the security of the code. In this case, the solution involves adding a check to verify the length of the SSID Information Element before processing it further.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-8658, which involves a stack-based buffer overflow in the `brcmf_cfg80211_start_ap` function. The vulnerability allows local users to cause a denial of service (system crash) or potentially have other unspecified impacts by providing a long SSID Information Element in a command to a Netlink socket.\n\nThe modification specifically adds a check to ensure that the length of the SSID Information Element does not exceed the maximum allowed length (`IEEE80211_MAX_SSID_LEN`). By adding this check, the code prevents a potential buffer overflow that could be exploited by an attacker to crash the system or execute arbitrary code.\n\nBy making this modification, the code becomes more secure and mitigates the risk associated with the vulnerability, thus protecting the system from potential exploitation.",
      "GPT_purpose": "Start an access point (AP) using the Broadcom wireless driver configuration for the Linux kernel.",
      "GPT_function": "\n1. Start an access point (AP) using the brcmf_cfg80211_start_ap function.\n2. Extract and process various information elements (IEs) from the AP settings.\n3. Configure WPA(2) security settings if WPA or RSN IEs are found.\n4. Set up AP-specific configurations based on the device role.\n5. Handle multiple-BSS configurations and ensure consistency in 11d settings.\n6. Configure the AP mode, set channel, bring the interface up, and handle WEP keys.\n7. Handle hidden SSID settings and complete AP mode configuration.\n8. Handle P2P GO mode configuration.\n9. Update VIF status and network carrier status.\n10. Handle error cases by reverting certain configurations if needed.",
      "CVE_id": "CVE-2016-8658",
      "code_before_change": "static s32\nbrcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,\n\t\t\tstruct cfg80211_ap_settings *settings)\n{\n\ts32 ie_offset;\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct brcmf_if *ifp = netdev_priv(ndev);\n\tconst struct brcmf_tlv *ssid_ie;\n\tconst struct brcmf_tlv *country_ie;\n\tstruct brcmf_ssid_le ssid_le;\n\ts32 err = -EPERM;\n\tconst struct brcmf_tlv *rsn_ie;\n\tconst struct brcmf_vs_tlv *wpa_ie;\n\tstruct brcmf_join_params join_params;\n\tenum nl80211_iftype dev_role;\n\tstruct brcmf_fil_bss_enable_le bss_enable;\n\tu16 chanspec = chandef_to_chanspec(&cfg->d11inf, &settings->chandef);\n\tbool mbss;\n\tint is_11d;\n\n\tbrcmf_dbg(TRACE, \"ctrlchn=%d, center=%d, bw=%d, beacon_interval=%d, dtim_period=%d,\\n\",\n\t\t  settings->chandef.chan->hw_value,\n\t\t  settings->chandef.center_freq1, settings->chandef.width,\n\t\t  settings->beacon_interval, settings->dtim_period);\n\tbrcmf_dbg(TRACE, \"ssid=%s(%zu), auth_type=%d, inactivity_timeout=%d\\n\",\n\t\t  settings->ssid, settings->ssid_len, settings->auth_type,\n\t\t  settings->inactivity_timeout);\n\tdev_role = ifp->vif->wdev.iftype;\n\tmbss = ifp->vif->mbss;\n\n\t/* store current 11d setting */\n\tbrcmf_fil_cmd_int_get(ifp, BRCMF_C_GET_REGULATORY, &ifp->vif->is_11d);\n\tcountry_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t      settings->beacon.tail_len,\n\t\t\t\t      WLAN_EID_COUNTRY);\n\tis_11d = country_ie ? 1 : 0;\n\n\tmemset(&ssid_le, 0, sizeof(ssid_le));\n\tif (settings->ssid == NULL || settings->ssid_len == 0) {\n\t\tie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN;\n\t\tssid_ie = brcmf_parse_tlvs(\n\t\t\t\t(u8 *)&settings->beacon.head[ie_offset],\n\t\t\t\tsettings->beacon.head_len - ie_offset,\n\t\t\t\tWLAN_EID_SSID);\n\t\tif (!ssid_ie)\n\t\t\treturn -EINVAL;\n\n\t\tmemcpy(ssid_le.SSID, ssid_ie->data, ssid_ie->len);\n\t\tssid_le.SSID_len = cpu_to_le32(ssid_ie->len);\n\t\tbrcmf_dbg(TRACE, \"SSID is (%s) in Head\\n\", ssid_le.SSID);\n\t} else {\n\t\tmemcpy(ssid_le.SSID, settings->ssid, settings->ssid_len);\n\t\tssid_le.SSID_len = cpu_to_le32((u32)settings->ssid_len);\n\t}\n\n\tif (!mbss) {\n\t\tbrcmf_set_mpc(ifp, 0);\n\t\tbrcmf_configure_arp_nd_offload(ifp, false);\n\t}\n\n\t/* find the RSN_IE */\n\trsn_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len, WLAN_EID_RSN);\n\n\t/* find the WPA_IE */\n\twpa_ie = brcmf_find_wpaie((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len);\n\n\tif ((wpa_ie != NULL || rsn_ie != NULL)) {\n\t\tbrcmf_dbg(TRACE, \"WPA(2) IE is found\\n\");\n\t\tif (wpa_ie != NULL) {\n\t\t\t/* WPA IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, wpa_ie, false);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t} else {\n\t\t\tstruct brcmf_vs_tlv *tmp_ie;\n\n\t\t\ttmp_ie = (struct brcmf_vs_tlv *)rsn_ie;\n\n\t\t\t/* RSN IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, tmp_ie, true);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t}\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"No WPA(2) IEs found\\n\");\n\t\tbrcmf_configure_opensecurity(ifp);\n\t}\n\n\tbrcmf_config_ap_mgmt_ie(ifp->vif, &settings->beacon);\n\n\t/* Parameters shared by all radio interfaces */\n\tif (!mbss) {\n\t\tif (is_11d != ifp->vif->is_11d) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_REGULATORY,\n\t\t\t\t\t\t    is_11d);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Regulatory Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->beacon_interval) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_BCNPRD,\n\t\t\t\t\t\t    settings->beacon_interval);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Beacon Interval Set Error, %d\\n\",\n\t\t\t\t\t  err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->dtim_period) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_DTIMPRD,\n\t\t\t\t\t\t    settings->dtim_period);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"DTIM Interval Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif ((dev_role == NL80211_IFTYPE_AP) &&\n\t\t    ((ifp->ifidx == 0) ||\n\t\t     !brcmf_feat_is_enabled(ifp, BRCMF_FEAT_RSDB))) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_DOWN, 1);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"BRCMF_C_DOWN error %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"apsta\", 0);\n\t\t}\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_INFRA, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET INFRA error %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t} else if (WARN_ON(is_11d != ifp->vif->is_11d)) {\n\t\t/* Multiple-BSS should use same 11d configuration */\n\t\terr = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\t/* Interface specific setup */\n\tif (dev_role == NL80211_IFTYPE_AP) {\n\t\tif ((brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MBSS)) && (!mbss))\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"mbss\", 1);\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_AP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting AP mode failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tif (!mbss) {\n\t\t\t/* Firmware 10.x requires setting channel after enabling\n\t\t\t * AP and before bringing interface up.\n\t\t\t */\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t\t  chanspec, err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_UP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"BRCMF_C_UP error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\t/* On DOWN the firmware removes the WEP keys, reconfigure\n\t\t * them if they were set.\n\t\t */\n\t\tbrcmf_cfg80211_reconfigure_wep(ifp);\n\n\t\tmemset(&join_params, 0, sizeof(join_params));\n\t\t/* join parameters starts with ssid */\n\t\tmemcpy(&join_params.ssid_le, &ssid_le, sizeof(ssid_le));\n\t\t/* create softap */\n\t\terr = brcmf_fil_cmd_data_set(ifp, BRCMF_C_SET_SSID,\n\t\t\t\t\t     &join_params, sizeof(join_params));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET SSID error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (settings->hidden_ssid) {\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"closednet\", 1);\n\t\t\tif (err) {\n\t\t\t\tbrcmf_err(\"closednet error (%d)\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"AP mode configuration complete\\n\");\n\t} else if (dev_role == NL80211_IFTYPE_P2P_GO) {\n\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t  chanspec, err);\n\t\t\tgoto exit;\n\t\t}\n\t\terr = brcmf_fil_bsscfg_data_set(ifp, \"ssid\", &ssid_le,\n\t\t\t\t\t\tsizeof(ssid_le));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting ssid failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tbss_enable.bsscfgidx = cpu_to_le32(ifp->bsscfgidx);\n\t\tbss_enable.enable = cpu_to_le32(1);\n\t\terr = brcmf_fil_iovar_data_set(ifp, \"bss\", &bss_enable,\n\t\t\t\t\t       sizeof(bss_enable));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"bss_enable config failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"GO mode configuration complete\\n\");\n\t} else {\n\t\tWARN_ON(1);\n\t}\n\n\tset_bit(BRCMF_VIF_STATUS_AP_CREATED, &ifp->vif->sme_state);\n\tbrcmf_net_setcarrier(ifp, true);\n\nexit:\n\tif ((err) && (!mbss)) {\n\t\tbrcmf_set_mpc(ifp, 1);\n\t\tbrcmf_configure_arp_nd_offload(ifp, true);\n\t}\n\treturn err;\n}",
      "code_after_change": "static s32\nbrcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,\n\t\t\tstruct cfg80211_ap_settings *settings)\n{\n\ts32 ie_offset;\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct brcmf_if *ifp = netdev_priv(ndev);\n\tconst struct brcmf_tlv *ssid_ie;\n\tconst struct brcmf_tlv *country_ie;\n\tstruct brcmf_ssid_le ssid_le;\n\ts32 err = -EPERM;\n\tconst struct brcmf_tlv *rsn_ie;\n\tconst struct brcmf_vs_tlv *wpa_ie;\n\tstruct brcmf_join_params join_params;\n\tenum nl80211_iftype dev_role;\n\tstruct brcmf_fil_bss_enable_le bss_enable;\n\tu16 chanspec = chandef_to_chanspec(&cfg->d11inf, &settings->chandef);\n\tbool mbss;\n\tint is_11d;\n\n\tbrcmf_dbg(TRACE, \"ctrlchn=%d, center=%d, bw=%d, beacon_interval=%d, dtim_period=%d,\\n\",\n\t\t  settings->chandef.chan->hw_value,\n\t\t  settings->chandef.center_freq1, settings->chandef.width,\n\t\t  settings->beacon_interval, settings->dtim_period);\n\tbrcmf_dbg(TRACE, \"ssid=%s(%zu), auth_type=%d, inactivity_timeout=%d\\n\",\n\t\t  settings->ssid, settings->ssid_len, settings->auth_type,\n\t\t  settings->inactivity_timeout);\n\tdev_role = ifp->vif->wdev.iftype;\n\tmbss = ifp->vif->mbss;\n\n\t/* store current 11d setting */\n\tbrcmf_fil_cmd_int_get(ifp, BRCMF_C_GET_REGULATORY, &ifp->vif->is_11d);\n\tcountry_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t      settings->beacon.tail_len,\n\t\t\t\t      WLAN_EID_COUNTRY);\n\tis_11d = country_ie ? 1 : 0;\n\n\tmemset(&ssid_le, 0, sizeof(ssid_le));\n\tif (settings->ssid == NULL || settings->ssid_len == 0) {\n\t\tie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN;\n\t\tssid_ie = brcmf_parse_tlvs(\n\t\t\t\t(u8 *)&settings->beacon.head[ie_offset],\n\t\t\t\tsettings->beacon.head_len - ie_offset,\n\t\t\t\tWLAN_EID_SSID);\n\t\tif (!ssid_ie || ssid_ie->len > IEEE80211_MAX_SSID_LEN)\n\t\t\treturn -EINVAL;\n\n\t\tmemcpy(ssid_le.SSID, ssid_ie->data, ssid_ie->len);\n\t\tssid_le.SSID_len = cpu_to_le32(ssid_ie->len);\n\t\tbrcmf_dbg(TRACE, \"SSID is (%s) in Head\\n\", ssid_le.SSID);\n\t} else {\n\t\tmemcpy(ssid_le.SSID, settings->ssid, settings->ssid_len);\n\t\tssid_le.SSID_len = cpu_to_le32((u32)settings->ssid_len);\n\t}\n\n\tif (!mbss) {\n\t\tbrcmf_set_mpc(ifp, 0);\n\t\tbrcmf_configure_arp_nd_offload(ifp, false);\n\t}\n\n\t/* find the RSN_IE */\n\trsn_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len, WLAN_EID_RSN);\n\n\t/* find the WPA_IE */\n\twpa_ie = brcmf_find_wpaie((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len);\n\n\tif ((wpa_ie != NULL || rsn_ie != NULL)) {\n\t\tbrcmf_dbg(TRACE, \"WPA(2) IE is found\\n\");\n\t\tif (wpa_ie != NULL) {\n\t\t\t/* WPA IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, wpa_ie, false);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t} else {\n\t\t\tstruct brcmf_vs_tlv *tmp_ie;\n\n\t\t\ttmp_ie = (struct brcmf_vs_tlv *)rsn_ie;\n\n\t\t\t/* RSN IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, tmp_ie, true);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t}\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"No WPA(2) IEs found\\n\");\n\t\tbrcmf_configure_opensecurity(ifp);\n\t}\n\n\tbrcmf_config_ap_mgmt_ie(ifp->vif, &settings->beacon);\n\n\t/* Parameters shared by all radio interfaces */\n\tif (!mbss) {\n\t\tif (is_11d != ifp->vif->is_11d) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_REGULATORY,\n\t\t\t\t\t\t    is_11d);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Regulatory Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->beacon_interval) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_BCNPRD,\n\t\t\t\t\t\t    settings->beacon_interval);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Beacon Interval Set Error, %d\\n\",\n\t\t\t\t\t  err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->dtim_period) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_DTIMPRD,\n\t\t\t\t\t\t    settings->dtim_period);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"DTIM Interval Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif ((dev_role == NL80211_IFTYPE_AP) &&\n\t\t    ((ifp->ifidx == 0) ||\n\t\t     !brcmf_feat_is_enabled(ifp, BRCMF_FEAT_RSDB))) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_DOWN, 1);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"BRCMF_C_DOWN error %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"apsta\", 0);\n\t\t}\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_INFRA, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET INFRA error %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t} else if (WARN_ON(is_11d != ifp->vif->is_11d)) {\n\t\t/* Multiple-BSS should use same 11d configuration */\n\t\terr = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\t/* Interface specific setup */\n\tif (dev_role == NL80211_IFTYPE_AP) {\n\t\tif ((brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MBSS)) && (!mbss))\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"mbss\", 1);\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_AP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting AP mode failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tif (!mbss) {\n\t\t\t/* Firmware 10.x requires setting channel after enabling\n\t\t\t * AP and before bringing interface up.\n\t\t\t */\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t\t  chanspec, err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_UP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"BRCMF_C_UP error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\t/* On DOWN the firmware removes the WEP keys, reconfigure\n\t\t * them if they were set.\n\t\t */\n\t\tbrcmf_cfg80211_reconfigure_wep(ifp);\n\n\t\tmemset(&join_params, 0, sizeof(join_params));\n\t\t/* join parameters starts with ssid */\n\t\tmemcpy(&join_params.ssid_le, &ssid_le, sizeof(ssid_le));\n\t\t/* create softap */\n\t\terr = brcmf_fil_cmd_data_set(ifp, BRCMF_C_SET_SSID,\n\t\t\t\t\t     &join_params, sizeof(join_params));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET SSID error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (settings->hidden_ssid) {\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"closednet\", 1);\n\t\t\tif (err) {\n\t\t\t\tbrcmf_err(\"closednet error (%d)\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"AP mode configuration complete\\n\");\n\t} else if (dev_role == NL80211_IFTYPE_P2P_GO) {\n\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t  chanspec, err);\n\t\t\tgoto exit;\n\t\t}\n\t\terr = brcmf_fil_bsscfg_data_set(ifp, \"ssid\", &ssid_le,\n\t\t\t\t\t\tsizeof(ssid_le));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting ssid failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tbss_enable.bsscfgidx = cpu_to_le32(ifp->bsscfgidx);\n\t\tbss_enable.enable = cpu_to_le32(1);\n\t\terr = brcmf_fil_iovar_data_set(ifp, \"bss\", &bss_enable,\n\t\t\t\t\t       sizeof(bss_enable));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"bss_enable config failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"GO mode configuration complete\\n\");\n\t} else {\n\t\tWARN_ON(1);\n\t}\n\n\tset_bit(BRCMF_VIF_STATUS_AP_CREATED, &ifp->vif->sme_state);\n\tbrcmf_net_setcarrier(ifp, true);\n\nexit:\n\tif ((err) && (!mbss)) {\n\t\tbrcmf_set_mpc(ifp, 1);\n\t\tbrcmf_configure_arp_nd_offload(ifp, true);\n\t}\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (!ssid_ie || ssid_ie->len > IEEE80211_MAX_SSID_LEN)"
        ],
        "deleted": [
          "\t\tif (!ssid_ie)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of length validation for the SSID Information Element in a command to a Netlink socket.",
      "trigger_condition": "A local user provides a long SSID Information Element, causing a stack-based buffer overflow in the brcmf_cfg80211_start_ap function.",
      "specific_code_behavior_causing_vulnerability": "The code does not check the length of the SSID Information Element, allowing a potential buffer overflow if the SSID length exceeds the maximum allowed length.",
      "id": 98,
      "code_after_change_normalized": "static VAR1\nFUN1(struct VAR2 *VAR2, struct net_device *VAR3,\nstruct cfg80211_ap_settings *VAR4)\n{\ns32 VAR5;\nstruct brcmf_cfg80211_info *VAR6 = FUN2(VAR2);\nstruct brcmf_if *VAR7 = FUN3(VAR3);\nconst struct brcmf_tlv *VAR8;\nconst struct brcmf_tlv *VAR9;\nstruct brcmf_ssid_le VAR10;\ns32 VAR11 = -VAR12;\nconst struct brcmf_tlv *VAR13;\nconst struct brcmf_vs_tlv *VAR14;\nstruct brcmf_join_params VAR15;\nenum nl80211_iftype VAR16;\nstruct brcmf_fil_bss_enable_le VAR17;\nu16 VAR18 = FUN4(&VAR6->VAR19, &VAR4->VAR20);\nbool VAR21;\nint VAR22;\nFUN5(VAR23, \"STR\",\nVAR4->VAR20.VAR24->VAR25,\nVAR4->VAR20.VAR26, VAR4->VAR20.VAR27,\nVAR4->VAR28, VAR4->VAR29);\nFUN5(VAR23, \"STR\",\nVAR4->VAR30, VAR4->VAR31, VAR4->VAR32,\nVAR4->VAR33);\nVAR16 = VAR7->VAR34->VAR35.VAR36;\nVAR21 = VAR7->VAR34->VAR21;\nFUN6(VAR7, VAR37, &VAR7->VAR34->VAR22);\nVAR9 = FUN7((VAR38 *)VAR4->VAR39.VAR40,\nVAR4->VAR39.VAR41,\nVAR42);\nVAR22 = VAR9 ? 1 : 0;\nFUN8(&VAR10, 0, sizeof(VAR10));\nif (VAR4->VAR30 == NULL || VAR4->VAR31 == 0) {\nVAR5 = VAR43 + VAR44;\nVAR8 = FUN7(\n(VAR38 *)&VAR4->VAR39.VAR45[VAR5],\nVAR4->VAR39.VAR46 - VAR5,\nVAR47);\nif (!VAR8 || VAR8->VAR48 > VAR49)\nreturn -VAR50;\nFUN9(VAR10.VAR51, VAR8->VAR52, VAR8->VAR48);\nVAR10.VAR53 = FUN10(VAR8->VAR48);\nFUN5(VAR23, \"STR\", VAR10.VAR51);\n} else {\nFUN9(VAR10.VAR51, VAR4->VAR30, VAR4->VAR31);\nVAR10.VAR53 = FUN10((VAR54)VAR4->VAR31);\n}\nif (!VAR21) {\nFUN11(VAR7, 0);\nFUN12(VAR7, false);\n}\nVAR13 = FUN7((VAR38 *)VAR4->VAR39.VAR40,\nVAR4->VAR39.VAR41, VAR55);\nVAR14 = FUN13((VAR38 *)VAR4->VAR39.VAR40,\nVAR4->VAR39.VAR41);\nif ((VAR14 != NULL || VAR13 != NULL)) {\nFUN5(VAR23, \"STR\");\nif (VAR14 != NULL) {\nVAR11 = FUN14(VAR7, VAR14, false);\nif (VAR11 < 0)\ngoto VAR56;\n} else {\nstruct brcmf_vs_tlv *VAR57;\nVAR57 = (struct VAR58 *)VAR13;\nVAR11 = FUN14(VAR7, VAR57, true);\nif (VAR11 < 0)\ngoto VAR56;\n}\n} else {\nFUN5(VAR23, \"STR\");\nFUN15(VAR7);\n}\nFUN16(VAR7->VAR34, &VAR4->VAR39);\nif (!VAR21) {\nif (VAR22 != VAR7->VAR34->VAR22) {\nVAR11 = FUN17(VAR7, VAR59,\nVAR22);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\n}\nif (VAR4->VAR28) {\nVAR11 = FUN17(VAR7, VAR60,\nVAR4->VAR28);\nif (VAR11 < 0) {\nFUN18(\"STR\",\nVAR11);\ngoto VAR56;\n}\n}\nif (VAR4->VAR29) {\nVAR11 = FUN17(VAR7, VAR61,\nVAR4->VAR29);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\n}\nif ((VAR16 == VAR62) &&\n((VAR7->VAR63 == 0) ||\n!FUN19(VAR7, VAR64))) {\nVAR11 = FUN17(VAR7, VAR65, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\nFUN20(VAR7, \"STR\", 0);\n}\nVAR11 = FUN17(VAR7, VAR66, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\n} else if (FUN21(VAR22 != VAR7->VAR34->VAR22)) {\nVAR11 = -VAR50;\ngoto VAR56;\n}\nif (VAR16 == VAR62) {\nif ((FUN19(VAR7, VAR67)) && (!VAR21))\nFUN20(VAR7, \"STR\", 1);\nVAR11 = FUN17(VAR7, VAR68, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\nif (!VAR21) {\nVAR11 = FUN20(VAR7, \"STR\", VAR18);\nif (VAR11 < 0) {\nFUN18(\"STR\",\nVAR18, VAR11);\ngoto VAR56;\n}\n}\nVAR11 = FUN17(VAR7, VAR69, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\nFUN22(VAR7);\nFUN8(&VAR15, 0, sizeof(VAR15));\nFUN9(&VAR15.VAR10, &VAR10, sizeof(VAR10));\nVAR11 = FUN23(VAR7, VAR70,\n&VAR15, sizeof(VAR15));\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\nif (VAR4->VAR71) {\nVAR11 = FUN20(VAR7, \"STR\", 1);\nif (VAR11) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\n}\nFUN5(VAR23, \"STR\");\n} else if (VAR16 == VAR72) {\nVAR11 = FUN20(VAR7, \"STR\", VAR18);\nif (VAR11 < 0) {\nFUN18(\"STR\",\nVAR18, VAR11);\ngoto VAR56;\n}\nVAR11 = FUN24(VAR7, \"STR\", &VAR10,\nsizeof(VAR10));\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\nVAR17.VAR73 = FUN10(VAR7->VAR73);\nVAR17.VAR74 = FUN10(1);\nVAR11 = FUN25(VAR7, \"STR\", &VAR17,\nsizeof(VAR17));\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR56;\n}\nFUN5(VAR23, \"STR\");\n} else {\nFUN21(1);\n}\nFUN26(VAR75, &VAR7->VAR34->VAR76);\nFUN27(VAR7, true);\nVAR56:\nif ((VAR11) && (!VAR21)) {\nFUN11(VAR7, 1);\nFUN12(VAR7, true);\n}\nreturn VAR11;\n}\n",
      "code_before_change_normalized": "static VAR1\nFUN1(struct VAR2 *VAR2, struct net_device *VAR3,\nstruct cfg80211_ap_settings *VAR4)\n{\ns32 VAR5;\nstruct brcmf_cfg80211_info *VAR6 = FUN2(VAR2);\nstruct brcmf_if *VAR7 = FUN3(VAR3);\nconst struct brcmf_tlv *VAR8;\nconst struct brcmf_tlv *VAR9;\nstruct brcmf_ssid_le VAR10;\ns32 VAR11 = -VAR12;\nconst struct brcmf_tlv *VAR13;\nconst struct brcmf_vs_tlv *VAR14;\nstruct brcmf_join_params VAR15;\nenum nl80211_iftype VAR16;\nstruct brcmf_fil_bss_enable_le VAR17;\nu16 VAR18 = FUN4(&VAR6->VAR19, &VAR4->VAR20);\nbool VAR21;\nint VAR22;\nFUN5(VAR23, \"STR\",\nVAR4->VAR20.VAR24->VAR25,\nVAR4->VAR20.VAR26, VAR4->VAR20.VAR27,\nVAR4->VAR28, VAR4->VAR29);\nFUN5(VAR23, \"STR\",\nVAR4->VAR30, VAR4->VAR31, VAR4->VAR32,\nVAR4->VAR33);\nVAR16 = VAR7->VAR34->VAR35.VAR36;\nVAR21 = VAR7->VAR34->VAR21;\nFUN6(VAR7, VAR37, &VAR7->VAR34->VAR22);\nVAR9 = FUN7((VAR38 *)VAR4->VAR39.VAR40,\nVAR4->VAR39.VAR41,\nVAR42);\nVAR22 = VAR9 ? 1 : 0;\nFUN8(&VAR10, 0, sizeof(VAR10));\nif (VAR4->VAR30 == NULL || VAR4->VAR31 == 0) {\nVAR5 = VAR43 + VAR44;\nVAR8 = FUN7(\n(VAR38 *)&VAR4->VAR39.VAR45[VAR5],\nVAR4->VAR39.VAR46 - VAR5,\nVAR47);\nif (!VAR8)\nreturn -VAR48;\nFUN9(VAR10.VAR49, VAR8->VAR50, VAR8->VAR51);\nVAR10.VAR52 = FUN10(VAR8->VAR51);\nFUN5(VAR23, \"STR\", VAR10.VAR49);\n} else {\nFUN9(VAR10.VAR49, VAR4->VAR30, VAR4->VAR31);\nVAR10.VAR52 = FUN10((VAR53)VAR4->VAR31);\n}\nif (!VAR21) {\nFUN11(VAR7, 0);\nFUN12(VAR7, false);\n}\nVAR13 = FUN7((VAR38 *)VAR4->VAR39.VAR40,\nVAR4->VAR39.VAR41, VAR54);\nVAR14 = FUN13((VAR38 *)VAR4->VAR39.VAR40,\nVAR4->VAR39.VAR41);\nif ((VAR14 != NULL || VAR13 != NULL)) {\nFUN5(VAR23, \"STR\");\nif (VAR14 != NULL) {\nVAR11 = FUN14(VAR7, VAR14, false);\nif (VAR11 < 0)\ngoto VAR55;\n} else {\nstruct brcmf_vs_tlv *VAR56;\nVAR56 = (struct VAR57 *)VAR13;\nVAR11 = FUN14(VAR7, VAR56, true);\nif (VAR11 < 0)\ngoto VAR55;\n}\n} else {\nFUN5(VAR23, \"STR\");\nFUN15(VAR7);\n}\nFUN16(VAR7->VAR34, &VAR4->VAR39);\nif (!VAR21) {\nif (VAR22 != VAR7->VAR34->VAR22) {\nVAR11 = FUN17(VAR7, VAR58,\nVAR22);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\n}\nif (VAR4->VAR28) {\nVAR11 = FUN17(VAR7, VAR59,\nVAR4->VAR28);\nif (VAR11 < 0) {\nFUN18(\"STR\",\nVAR11);\ngoto VAR55;\n}\n}\nif (VAR4->VAR29) {\nVAR11 = FUN17(VAR7, VAR60,\nVAR4->VAR29);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\n}\nif ((VAR16 == VAR61) &&\n((VAR7->VAR62 == 0) ||\n!FUN19(VAR7, VAR63))) {\nVAR11 = FUN17(VAR7, VAR64, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\nFUN20(VAR7, \"STR\", 0);\n}\nVAR11 = FUN17(VAR7, VAR65, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\n} else if (FUN21(VAR22 != VAR7->VAR34->VAR22)) {\nVAR11 = -VAR48;\ngoto VAR55;\n}\nif (VAR16 == VAR61) {\nif ((FUN19(VAR7, VAR66)) && (!VAR21))\nFUN20(VAR7, \"STR\", 1);\nVAR11 = FUN17(VAR7, VAR67, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\nif (!VAR21) {\nVAR11 = FUN20(VAR7, \"STR\", VAR18);\nif (VAR11 < 0) {\nFUN18(\"STR\",\nVAR18, VAR11);\ngoto VAR55;\n}\n}\nVAR11 = FUN17(VAR7, VAR68, 1);\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\nFUN22(VAR7);\nFUN8(&VAR15, 0, sizeof(VAR15));\nFUN9(&VAR15.VAR10, &VAR10, sizeof(VAR10));\nVAR11 = FUN23(VAR7, VAR69,\n&VAR15, sizeof(VAR15));\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\nif (VAR4->VAR70) {\nVAR11 = FUN20(VAR7, \"STR\", 1);\nif (VAR11) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\n}\nFUN5(VAR23, \"STR\");\n} else if (VAR16 == VAR71) {\nVAR11 = FUN20(VAR7, \"STR\", VAR18);\nif (VAR11 < 0) {\nFUN18(\"STR\",\nVAR18, VAR11);\ngoto VAR55;\n}\nVAR11 = FUN24(VAR7, \"STR\", &VAR10,\nsizeof(VAR10));\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\nVAR17.VAR72 = FUN10(VAR7->VAR72);\nVAR17.VAR73 = FUN10(1);\nVAR11 = FUN25(VAR7, \"STR\", &VAR17,\nsizeof(VAR17));\nif (VAR11 < 0) {\nFUN18(\"STR\", VAR11);\ngoto VAR55;\n}\nFUN5(VAR23, \"STR\");\n} else {\nFUN21(1);\n}\nFUN26(VAR74, &VAR7->VAR34->VAR75);\nFUN27(VAR7, true);\nVAR55:\nif ((VAR11) && (!VAR21)) {\nFUN11(VAR7, 1);\nFUN12(VAR7, true);\n}\nreturn VAR11;\n}\n",
      "code_after_change_raw": "static s32\nbrcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,\nstruct cfg80211_ap_settings *settings)\n{\ns32 ie_offset;\nstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\nstruct brcmf_if *ifp = netdev_priv(ndev);\nconst struct brcmf_tlv *ssid_ie;\nconst struct brcmf_tlv *country_ie;\nstruct brcmf_ssid_le ssid_le;\ns32 err = -EPERM;\nconst struct brcmf_tlv *rsn_ie;\nconst struct brcmf_vs_tlv *wpa_ie;\nstruct brcmf_join_params join_params;\nenum nl80211_iftype dev_role;\nstruct brcmf_fil_bss_enable_le bss_enable;\nu16 chanspec = chandef_to_chanspec(&cfg->d11inf, &settings->chandef);\nbool mbss;\nint is_11d;\nbrcmf_dbg(TRACE, \"ctrlchn=%d, center=%d, bw=%d, beacon_interval=%d, dtim_period=%d,\\n\",\nsettings->chandef.chan->hw_value,\nsettings->chandef.center_freq1, settings->chandef.width,\nsettings->beacon_interval, settings->dtim_period);\nbrcmf_dbg(TRACE, \"ssid=%s(%zu), auth_type=%d, inactivity_timeout=%d\\n\",\nsettings->ssid, settings->ssid_len, settings->auth_type,\nsettings->inactivity_timeout);\ndev_role = ifp->vif->wdev.iftype;\nmbss = ifp->vif->mbss;\nbrcmf_fil_cmd_int_get(ifp, BRCMF_C_GET_REGULATORY, &ifp->vif->is_11d);\ncountry_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\nsettings->beacon.tail_len,\nWLAN_EID_COUNTRY);\nis_11d = country_ie ? 1 : 0;\nmemset(&ssid_le, 0, sizeof(ssid_le));\nif (settings->ssid == NULL || settings->ssid_len == 0) {\nie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN;\nssid_ie = brcmf_parse_tlvs(\n(u8 *)&settings->beacon.head[ie_offset],\nsettings->beacon.head_len - ie_offset,\nWLAN_EID_SSID);\nif (!ssid_ie || ssid_ie->len > IEEE80211_MAX_SSID_LEN)\nreturn -EINVAL;\nmemcpy(ssid_le.SSID, ssid_ie->data, ssid_ie->len);\nssid_le.SSID_len = cpu_to_le32(ssid_ie->len);\nbrcmf_dbg(TRACE, \"SSID is (%s) in Head\\n\", ssid_le.SSID);\n} else {\nmemcpy(ssid_le.SSID, settings->ssid, settings->ssid_len);\nssid_le.SSID_len = cpu_to_le32((u32)settings->ssid_len);\n}\nif (!mbss) {\nbrcmf_set_mpc(ifp, 0);\nbrcmf_configure_arp_nd_offload(ifp, false);\n}\nrsn_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\nsettings->beacon.tail_len, WLAN_EID_RSN);\nwpa_ie = brcmf_find_wpaie((u8 *)settings->beacon.tail,\nsettings->beacon.tail_len);\nif ((wpa_ie != NULL || rsn_ie != NULL)) {\nbrcmf_dbg(TRACE, \"WPA(2) IE is found\\n\");\nif (wpa_ie != NULL) {\nerr = brcmf_configure_wpaie(ifp, wpa_ie, false);\nif (err < 0)\ngoto exit;\n} else {\nstruct brcmf_vs_tlv *tmp_ie;\ntmp_ie = (struct brcmf_vs_tlv *)rsn_ie;\nerr = brcmf_configure_wpaie(ifp, tmp_ie, true);\nif (err < 0)\ngoto exit;\n}\n} else {\nbrcmf_dbg(TRACE, \"No WPA(2) IEs found\\n\");\nbrcmf_configure_opensecurity(ifp);\n}\nbrcmf_config_ap_mgmt_ie(ifp->vif, &settings->beacon);\nif (!mbss) {\nif (is_11d != ifp->vif->is_11d) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_REGULATORY,\nis_11d);\nif (err < 0) {\nbrcmf_err(\"Regulatory Set Error, %d\\n\", err);\ngoto exit;\n}\n}\nif (settings->beacon_interval) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_BCNPRD,\nsettings->beacon_interval);\nif (err < 0) {\nbrcmf_err(\"Beacon Interval Set Error, %d\\n\",\nerr);\ngoto exit;\n}\n}\nif (settings->dtim_period) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_DTIMPRD,\nsettings->dtim_period);\nif (err < 0) {\nbrcmf_err(\"DTIM Interval Set Error, %d\\n\", err);\ngoto exit;\n}\n}\nif ((dev_role == NL80211_IFTYPE_AP) &&\n((ifp->ifidx == 0) ||\n!brcmf_feat_is_enabled(ifp, BRCMF_FEAT_RSDB))) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_DOWN, 1);\nif (err < 0) {\nbrcmf_err(\"BRCMF_C_DOWN error %d\\n\", err);\ngoto exit;\n}\nbrcmf_fil_iovar_int_set(ifp, \"apsta\", 0);\n}\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_INFRA, 1);\nif (err < 0) {\nbrcmf_err(\"SET INFRA error %d\\n\", err);\ngoto exit;\n}\n} else if (WARN_ON(is_11d != ifp->vif->is_11d)) {\nerr = -EINVAL;\ngoto exit;\n}\nif (dev_role == NL80211_IFTYPE_AP) {\nif ((brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MBSS)) && (!mbss))\nbrcmf_fil_iovar_int_set(ifp, \"mbss\", 1);\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_AP, 1);\nif (err < 0) {\nbrcmf_err(\"setting AP mode failed %d\\n\", err);\ngoto exit;\n}\nif (!mbss) {\nerr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\nif (err < 0) {\nbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\nchanspec, err);\ngoto exit;\n}\n}\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_UP, 1);\nif (err < 0) {\nbrcmf_err(\"BRCMF_C_UP error (%d)\\n\", err);\ngoto exit;\n}\nbrcmf_cfg80211_reconfigure_wep(ifp);\nmemset(&join_params, 0, sizeof(join_params));\nmemcpy(&join_params.ssid_le, &ssid_le, sizeof(ssid_le));\nerr = brcmf_fil_cmd_data_set(ifp, BRCMF_C_SET_SSID,\n&join_params, sizeof(join_params));\nif (err < 0) {\nbrcmf_err(\"SET SSID error (%d)\\n\", err);\ngoto exit;\n}\nif (settings->hidden_ssid) {\nerr = brcmf_fil_iovar_int_set(ifp, \"closednet\", 1);\nif (err) {\nbrcmf_err(\"closednet error (%d)\\n\", err);\ngoto exit;\n}\n}\nbrcmf_dbg(TRACE, \"AP mode configuration complete\\n\");\n} else if (dev_role == NL80211_IFTYPE_P2P_GO) {\nerr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\nif (err < 0) {\nbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\nchanspec, err);\ngoto exit;\n}\nerr = brcmf_fil_bsscfg_data_set(ifp, \"ssid\", &ssid_le,\nsizeof(ssid_le));\nif (err < 0) {\nbrcmf_err(\"setting ssid failed %d\\n\", err);\ngoto exit;\n}\nbss_enable.bsscfgidx = cpu_to_le32(ifp->bsscfgidx);\nbss_enable.enable = cpu_to_le32(1);\nerr = brcmf_fil_iovar_data_set(ifp, \"bss\", &bss_enable,\nsizeof(bss_enable));\nif (err < 0) {\nbrcmf_err(\"bss_enable config failed %d\\n\", err);\ngoto exit;\n}\nbrcmf_dbg(TRACE, \"GO mode configuration complete\\n\");\n} else {\nWARN_ON(1);\n}\nset_bit(BRCMF_VIF_STATUS_AP_CREATED, &ifp->vif->sme_state);\nbrcmf_net_setcarrier(ifp, true);\nexit:\nif ((err) && (!mbss)) {\nbrcmf_set_mpc(ifp, 1);\nbrcmf_configure_arp_nd_offload(ifp, true);\n}\nreturn err;\n}\n",
      "code_before_change_raw": "static s32\nbrcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,\nstruct cfg80211_ap_settings *settings)\n{\ns32 ie_offset;\nstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\nstruct brcmf_if *ifp = netdev_priv(ndev);\nconst struct brcmf_tlv *ssid_ie;\nconst struct brcmf_tlv *country_ie;\nstruct brcmf_ssid_le ssid_le;\ns32 err = -EPERM;\nconst struct brcmf_tlv *rsn_ie;\nconst struct brcmf_vs_tlv *wpa_ie;\nstruct brcmf_join_params join_params;\nenum nl80211_iftype dev_role;\nstruct brcmf_fil_bss_enable_le bss_enable;\nu16 chanspec = chandef_to_chanspec(&cfg->d11inf, &settings->chandef);\nbool mbss;\nint is_11d;\nbrcmf_dbg(TRACE, \"ctrlchn=%d, center=%d, bw=%d, beacon_interval=%d, dtim_period=%d,\\n\",\nsettings->chandef.chan->hw_value,\nsettings->chandef.center_freq1, settings->chandef.width,\nsettings->beacon_interval, settings->dtim_period);\nbrcmf_dbg(TRACE, \"ssid=%s(%zu), auth_type=%d, inactivity_timeout=%d\\n\",\nsettings->ssid, settings->ssid_len, settings->auth_type,\nsettings->inactivity_timeout);\ndev_role = ifp->vif->wdev.iftype;\nmbss = ifp->vif->mbss;\nbrcmf_fil_cmd_int_get(ifp, BRCMF_C_GET_REGULATORY, &ifp->vif->is_11d);\ncountry_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\nsettings->beacon.tail_len,\nWLAN_EID_COUNTRY);\nis_11d = country_ie ? 1 : 0;\nmemset(&ssid_le, 0, sizeof(ssid_le));\nif (settings->ssid == NULL || settings->ssid_len == 0) {\nie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN;\nssid_ie = brcmf_parse_tlvs(\n(u8 *)&settings->beacon.head[ie_offset],\nsettings->beacon.head_len - ie_offset,\nWLAN_EID_SSID);\nif (!ssid_ie)\nreturn -EINVAL;\nmemcpy(ssid_le.SSID, ssid_ie->data, ssid_ie->len);\nssid_le.SSID_len = cpu_to_le32(ssid_ie->len);\nbrcmf_dbg(TRACE, \"SSID is (%s) in Head\\n\", ssid_le.SSID);\n} else {\nmemcpy(ssid_le.SSID, settings->ssid, settings->ssid_len);\nssid_le.SSID_len = cpu_to_le32((u32)settings->ssid_len);\n}\nif (!mbss) {\nbrcmf_set_mpc(ifp, 0);\nbrcmf_configure_arp_nd_offload(ifp, false);\n}\nrsn_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\nsettings->beacon.tail_len, WLAN_EID_RSN);\nwpa_ie = brcmf_find_wpaie((u8 *)settings->beacon.tail,\nsettings->beacon.tail_len);\nif ((wpa_ie != NULL || rsn_ie != NULL)) {\nbrcmf_dbg(TRACE, \"WPA(2) IE is found\\n\");\nif (wpa_ie != NULL) {\nerr = brcmf_configure_wpaie(ifp, wpa_ie, false);\nif (err < 0)\ngoto exit;\n} else {\nstruct brcmf_vs_tlv *tmp_ie;\ntmp_ie = (struct brcmf_vs_tlv *)rsn_ie;\nerr = brcmf_configure_wpaie(ifp, tmp_ie, true);\nif (err < 0)\ngoto exit;\n}\n} else {\nbrcmf_dbg(TRACE, \"No WPA(2) IEs found\\n\");\nbrcmf_configure_opensecurity(ifp);\n}\nbrcmf_config_ap_mgmt_ie(ifp->vif, &settings->beacon);\nif (!mbss) {\nif (is_11d != ifp->vif->is_11d) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_REGULATORY,\nis_11d);\nif (err < 0) {\nbrcmf_err(\"Regulatory Set Error, %d\\n\", err);\ngoto exit;\n}\n}\nif (settings->beacon_interval) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_BCNPRD,\nsettings->beacon_interval);\nif (err < 0) {\nbrcmf_err(\"Beacon Interval Set Error, %d\\n\",\nerr);\ngoto exit;\n}\n}\nif (settings->dtim_period) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_DTIMPRD,\nsettings->dtim_period);\nif (err < 0) {\nbrcmf_err(\"DTIM Interval Set Error, %d\\n\", err);\ngoto exit;\n}\n}\nif ((dev_role == NL80211_IFTYPE_AP) &&\n((ifp->ifidx == 0) ||\n!brcmf_feat_is_enabled(ifp, BRCMF_FEAT_RSDB))) {\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_DOWN, 1);\nif (err < 0) {\nbrcmf_err(\"BRCMF_C_DOWN error %d\\n\", err);\ngoto exit;\n}\nbrcmf_fil_iovar_int_set(ifp, \"apsta\", 0);\n}\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_INFRA, 1);\nif (err < 0) {\nbrcmf_err(\"SET INFRA error %d\\n\", err);\ngoto exit;\n}\n} else if (WARN_ON(is_11d != ifp->vif->is_11d)) {\nerr = -EINVAL;\ngoto exit;\n}\nif (dev_role == NL80211_IFTYPE_AP) {\nif ((brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MBSS)) && (!mbss))\nbrcmf_fil_iovar_int_set(ifp, \"mbss\", 1);\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_AP, 1);\nif (err < 0) {\nbrcmf_err(\"setting AP mode failed %d\\n\", err);\ngoto exit;\n}\nif (!mbss) {\nerr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\nif (err < 0) {\nbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\nchanspec, err);\ngoto exit;\n}\n}\nerr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_UP, 1);\nif (err < 0) {\nbrcmf_err(\"BRCMF_C_UP error (%d)\\n\", err);\ngoto exit;\n}\nbrcmf_cfg80211_reconfigure_wep(ifp);\nmemset(&join_params, 0, sizeof(join_params));\nmemcpy(&join_params.ssid_le, &ssid_le, sizeof(ssid_le));\nerr = brcmf_fil_cmd_data_set(ifp, BRCMF_C_SET_SSID,\n&join_params, sizeof(join_params));\nif (err < 0) {\nbrcmf_err(\"SET SSID error (%d)\\n\", err);\ngoto exit;\n}\nif (settings->hidden_ssid) {\nerr = brcmf_fil_iovar_int_set(ifp, \"closednet\", 1);\nif (err) {\nbrcmf_err(\"closednet error (%d)\\n\", err);\ngoto exit;\n}\n}\nbrcmf_dbg(TRACE, \"AP mode configuration complete\\n\");\n} else if (dev_role == NL80211_IFTYPE_P2P_GO) {\nerr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\nif (err < 0) {\nbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\nchanspec, err);\ngoto exit;\n}\nerr = brcmf_fil_bsscfg_data_set(ifp, \"ssid\", &ssid_le,\nsizeof(ssid_le));\nif (err < 0) {\nbrcmf_err(\"setting ssid failed %d\\n\", err);\ngoto exit;\n}\nbss_enable.bsscfgidx = cpu_to_le32(ifp->bsscfgidx);\nbss_enable.enable = cpu_to_le32(1);\nerr = brcmf_fil_iovar_data_set(ifp, \"bss\", &bss_enable,\nsizeof(bss_enable));\nif (err < 0) {\nbrcmf_err(\"bss_enable config failed %d\\n\", err);\ngoto exit;\n}\nbrcmf_dbg(TRACE, \"GO mode configuration complete\\n\");\n} else {\nWARN_ON(1);\n}\nset_bit(BRCMF_VIF_STATUS_AP_CREATED, &ifp->vif->sme_state);\nbrcmf_net_setcarrier(ifp, true);\nexit:\nif ((err) && (!mbss)) {\nbrcmf_set_mpc(ifp, 1);\nbrcmf_configure_arp_nd_offload(ifp, true);\n}\nreturn err;\n}\n"
    }
  ],
  "CVE-2016-9083": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for input values and potential integer overflow scenarios in the VFIO_DEVICE_SET_IRQS ioctl call.",
        "trigger_condition": "An attacker leverages access to a vfio PCI device file to provide manipulated input values that can lead to integer overflow during the calculation of IRQ count.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check for potential integer overflow when calculating the count of IRQs in the VFIO_DEVICE_SET_IRQS ioctl call, allowing an attacker to bypass checks and potentially cause memory corruption or other unspecified impacts.",
        "solution": "To mitigate the vulnerability, it is necessary to add proper validation checks to ensure that the count calculation does not exceed the maximum value allowed and to handle the size calculation based on the data type specified in the flags. This prevents integer overflow scenarios and ensures correct handling of input values in the ioctl call."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2016-9083, which allows local users to bypass integer overflow checks and potentially cause memory corruption or other unspecified impacts by leveraging access to a vfio PCI device file for a VFIO_DEVICE_SET_IRQS ioctl call. \n\nThe vulnerability arises from improper handling of integer overflow in the calculation of the count of IRQs in the VFIO_DEVICE_SET_IRQS ioctl call. By not properly checking for potential overflow scenarios, an attacker could manipulate the input values to trigger unexpected behavior and potentially lead to memory corruption.\n\nThe modification adds a check to ensure that the count calculation does not exceed the maximum value allowed (U32_MAX) and properly handles the size calculation based on the data type specified in the flags. This helps prevent integer overflow and ensures the correct handling of input values, thereby mitigating the vulnerability and enhancing the security of the code.",
      "GPT_purpose": "Handle various ioctl commands for a VFIO PCI device, including getting device information, region information, IRQ information, setting IRQs, device reset, and PCI hot reset.",
      "GPT_function": "\n1. Handle VFIO_DEVICE_GET_INFO ioctl command.\n2. Handle VFIO_DEVICE_GET_REGION_INFO ioctl command.\n3. Handle VFIO_DEVICE_GET_IRQ_INFO ioctl command.\n4. Handle VFIO_DEVICE_SET_IRQS ioctl command.\n5. Handle VFIO_DEVICE_RESET ioctl command.\n6. Handle VFIO_DEVICE_GET_PCI_HOT_RESET_INFO ioctl command.\n7. Handle VFIO_DEVICE_PCI_HOT_RESET ioctl command.",
      "CVE_id": "CVE-2016-9083",
      "code_before_change": "static long vfio_pci_ioctl(void *device_data,\n\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\tstruct vfio_pci_device *vdev = device_data;\n\tunsigned long minsz;\n\n\tif (cmd == VFIO_DEVICE_GET_INFO) {\n\t\tstruct vfio_device_info info;\n\n\t\tminsz = offsetofend(struct vfio_device_info, num_irqs);\n\n\t\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (info.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tinfo.flags = VFIO_DEVICE_FLAGS_PCI;\n\n\t\tif (vdev->reset_works)\n\t\t\tinfo.flags |= VFIO_DEVICE_FLAGS_RESET;\n\n\t\tinfo.num_regions = VFIO_PCI_NUM_REGIONS + vdev->num_regions;\n\t\tinfo.num_irqs = VFIO_PCI_NUM_IRQS;\n\n\t\treturn copy_to_user((void __user *)arg, &info, minsz) ?\n\t\t\t-EFAULT : 0;\n\n\t} else if (cmd == VFIO_DEVICE_GET_REGION_INFO) {\n\t\tstruct pci_dev *pdev = vdev->pdev;\n\t\tstruct vfio_region_info info;\n\t\tstruct vfio_info_cap caps = { .buf = NULL, .size = 0 };\n\t\tint i, ret;\n\n\t\tminsz = offsetofend(struct vfio_region_info, offset);\n\n\t\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (info.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tswitch (info.index) {\n\t\tcase VFIO_PCI_CONFIG_REGION_INDEX:\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = pdev->cfg_size;\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ |\n\t\t\t\t     VFIO_REGION_INFO_FLAG_WRITE;\n\t\t\tbreak;\n\t\tcase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = pci_resource_len(pdev, info.index);\n\t\t\tif (!info.size) {\n\t\t\t\tinfo.flags = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ |\n\t\t\t\t     VFIO_REGION_INFO_FLAG_WRITE;\n\t\t\tif (vdev->bar_mmap_supported[info.index]) {\n\t\t\t\tinfo.flags |= VFIO_REGION_INFO_FLAG_MMAP;\n\t\t\t\tif (info.index == vdev->msix_bar) {\n\t\t\t\t\tret = msix_sparse_mmap_cap(vdev, &caps);\n\t\t\t\t\tif (ret)\n\t\t\t\t\t\treturn ret;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbreak;\n\t\tcase VFIO_PCI_ROM_REGION_INDEX:\n\t\t{\n\t\t\tvoid __iomem *io;\n\t\t\tsize_t size;\n\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.flags = 0;\n\n\t\t\t/* Report the BAR size, not the ROM size */\n\t\t\tinfo.size = pci_resource_len(pdev, info.index);\n\t\t\tif (!info.size) {\n\t\t\t\t/* Shadow ROMs appear as PCI option ROMs */\n\t\t\t\tif (pdev->resource[PCI_ROM_RESOURCE].flags &\n\t\t\t\t\t\t\tIORESOURCE_ROM_SHADOW)\n\t\t\t\t\tinfo.size = 0x20000;\n\t\t\t\telse\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Is it really there? */\n\t\t\tio = pci_map_rom(pdev, &size);\n\t\t\tif (!io || !size) {\n\t\t\t\tinfo.size = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpci_unmap_rom(pdev, io);\n\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ;\n\t\t\tbreak;\n\t\t}\n\t\tcase VFIO_PCI_VGA_REGION_INDEX:\n\t\t\tif (!vdev->has_vga)\n\t\t\t\treturn -EINVAL;\n\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = 0xc0000;\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ |\n\t\t\t\t     VFIO_REGION_INFO_FLAG_WRITE;\n\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (info.index >=\n\t\t\t    VFIO_PCI_NUM_REGIONS + vdev->num_regions)\n\t\t\t\treturn -EINVAL;\n\n\t\t\ti = info.index - VFIO_PCI_NUM_REGIONS;\n\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = vdev->region[i].size;\n\t\t\tinfo.flags = vdev->region[i].flags;\n\n\t\t\tret = region_type_cap(vdev, &caps,\n\t\t\t\t\t      vdev->region[i].type,\n\t\t\t\t\t      vdev->region[i].subtype);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tif (caps.size) {\n\t\t\tinfo.flags |= VFIO_REGION_INFO_FLAG_CAPS;\n\t\t\tif (info.argsz < sizeof(info) + caps.size) {\n\t\t\t\tinfo.argsz = sizeof(info) + caps.size;\n\t\t\t\tinfo.cap_offset = 0;\n\t\t\t} else {\n\t\t\t\tvfio_info_cap_shift(&caps, sizeof(info));\n\t\t\t\tif (copy_to_user((void __user *)arg +\n\t\t\t\t\t\t  sizeof(info), caps.buf,\n\t\t\t\t\t\t  caps.size)) {\n\t\t\t\t\tkfree(caps.buf);\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\t}\n\t\t\t\tinfo.cap_offset = sizeof(info);\n\t\t\t}\n\n\t\t\tkfree(caps.buf);\n\t\t}\n\n\t\treturn copy_to_user((void __user *)arg, &info, minsz) ?\n\t\t\t-EFAULT : 0;\n\n\t} else if (cmd == VFIO_DEVICE_GET_IRQ_INFO) {\n\t\tstruct vfio_irq_info info;\n\n\t\tminsz = offsetofend(struct vfio_irq_info, count);\n\n\t\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (info.argsz < minsz || info.index >= VFIO_PCI_NUM_IRQS)\n\t\t\treturn -EINVAL;\n\n\t\tswitch (info.index) {\n\t\tcase VFIO_PCI_INTX_IRQ_INDEX ... VFIO_PCI_MSIX_IRQ_INDEX:\n\t\tcase VFIO_PCI_REQ_IRQ_INDEX:\n\t\t\tbreak;\n\t\tcase VFIO_PCI_ERR_IRQ_INDEX:\n\t\t\tif (pci_is_pcie(vdev->pdev))\n\t\t\t\tbreak;\n\t\t/* pass thru to return error */\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tinfo.flags = VFIO_IRQ_INFO_EVENTFD;\n\n\t\tinfo.count = vfio_pci_get_irq_count(vdev, info.index);\n\n\t\tif (info.index == VFIO_PCI_INTX_IRQ_INDEX)\n\t\t\tinfo.flags |= (VFIO_IRQ_INFO_MASKABLE |\n\t\t\t\t       VFIO_IRQ_INFO_AUTOMASKED);\n\t\telse\n\t\t\tinfo.flags |= VFIO_IRQ_INFO_NORESIZE;\n\n\t\treturn copy_to_user((void __user *)arg, &info, minsz) ?\n\t\t\t-EFAULT : 0;\n\n\t} else if (cmd == VFIO_DEVICE_SET_IRQS) {\n\t\tstruct vfio_irq_set hdr;\n\t\tu8 *data = NULL;\n\t\tint ret = 0;\n\n\t\tminsz = offsetofend(struct vfio_irq_set, count);\n\n\t\tif (copy_from_user(&hdr, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (hdr.argsz < minsz || hdr.index >= VFIO_PCI_NUM_IRQS ||\n\t\t    hdr.flags & ~(VFIO_IRQ_SET_DATA_TYPE_MASK |\n\t\t\t\t  VFIO_IRQ_SET_ACTION_TYPE_MASK))\n\t\t\treturn -EINVAL;\n\n\t\tif (!(hdr.flags & VFIO_IRQ_SET_DATA_NONE)) {\n\t\t\tsize_t size;\n\t\t\tint max = vfio_pci_get_irq_count(vdev, hdr.index);\n\n\t\t\tif (hdr.flags & VFIO_IRQ_SET_DATA_BOOL)\n\t\t\t\tsize = sizeof(uint8_t);\n\t\t\telse if (hdr.flags & VFIO_IRQ_SET_DATA_EVENTFD)\n\t\t\t\tsize = sizeof(int32_t);\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\n\t\t\tif (hdr.argsz - minsz < hdr.count * size ||\n\t\t\t    hdr.start >= max || hdr.start + hdr.count > max)\n\t\t\t\treturn -EINVAL;\n\n\t\t\tdata = memdup_user((void __user *)(arg + minsz),\n\t\t\t\t\t   hdr.count * size);\n\t\t\tif (IS_ERR(data))\n\t\t\t\treturn PTR_ERR(data);\n\t\t}\n\n\t\tmutex_lock(&vdev->igate);\n\n\t\tret = vfio_pci_set_irqs_ioctl(vdev, hdr.flags, hdr.index,\n\t\t\t\t\t      hdr.start, hdr.count, data);\n\n\t\tmutex_unlock(&vdev->igate);\n\t\tkfree(data);\n\n\t\treturn ret;\n\n\t} else if (cmd == VFIO_DEVICE_RESET) {\n\t\treturn vdev->reset_works ?\n\t\t\tpci_try_reset_function(vdev->pdev) : -EINVAL;\n\n\t} else if (cmd == VFIO_DEVICE_GET_PCI_HOT_RESET_INFO) {\n\t\tstruct vfio_pci_hot_reset_info hdr;\n\t\tstruct vfio_pci_fill_info fill = { 0 };\n\t\tstruct vfio_pci_dependent_device *devices = NULL;\n\t\tbool slot = false;\n\t\tint ret = 0;\n\n\t\tminsz = offsetofend(struct vfio_pci_hot_reset_info, count);\n\n\t\tif (copy_from_user(&hdr, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (hdr.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\thdr.flags = 0;\n\n\t\t/* Can we do a slot or bus reset or neither? */\n\t\tif (!pci_probe_reset_slot(vdev->pdev->slot))\n\t\t\tslot = true;\n\t\telse if (pci_probe_reset_bus(vdev->pdev->bus))\n\t\t\treturn -ENODEV;\n\n\t\t/* How many devices are affected? */\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_count_devs,\n\t\t\t\t\t\t    &fill.max, slot);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tWARN_ON(!fill.max); /* Should always be at least one */\n\n\t\t/*\n\t\t * If there's enough space, fill it now, otherwise return\n\t\t * -ENOSPC and the number of devices affected.\n\t\t */\n\t\tif (hdr.argsz < sizeof(hdr) + (fill.max * sizeof(*devices))) {\n\t\t\tret = -ENOSPC;\n\t\t\thdr.count = fill.max;\n\t\t\tgoto reset_info_exit;\n\t\t}\n\n\t\tdevices = kcalloc(fill.max, sizeof(*devices), GFP_KERNEL);\n\t\tif (!devices)\n\t\t\treturn -ENOMEM;\n\n\t\tfill.devices = devices;\n\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_fill_devs,\n\t\t\t\t\t\t    &fill, slot);\n\n\t\t/*\n\t\t * If a device was removed between counting and filling,\n\t\t * we may come up short of fill.max.  If a device was\n\t\t * added, we'll have a return of -EAGAIN above.\n\t\t */\n\t\tif (!ret)\n\t\t\thdr.count = fill.cur;\n\nreset_info_exit:\n\t\tif (copy_to_user((void __user *)arg, &hdr, minsz))\n\t\t\tret = -EFAULT;\n\n\t\tif (!ret) {\n\t\t\tif (copy_to_user((void __user *)(arg + minsz), devices,\n\t\t\t\t\t hdr.count * sizeof(*devices)))\n\t\t\t\tret = -EFAULT;\n\t\t}\n\n\t\tkfree(devices);\n\t\treturn ret;\n\n\t} else if (cmd == VFIO_DEVICE_PCI_HOT_RESET) {\n\t\tstruct vfio_pci_hot_reset hdr;\n\t\tint32_t *group_fds;\n\t\tstruct vfio_pci_group_entry *groups;\n\t\tstruct vfio_pci_group_info info;\n\t\tbool slot = false;\n\t\tint i, count = 0, ret = 0;\n\n\t\tminsz = offsetofend(struct vfio_pci_hot_reset, count);\n\n\t\tif (copy_from_user(&hdr, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (hdr.argsz < minsz || hdr.flags)\n\t\t\treturn -EINVAL;\n\n\t\t/* Can we do a slot or bus reset or neither? */\n\t\tif (!pci_probe_reset_slot(vdev->pdev->slot))\n\t\t\tslot = true;\n\t\telse if (pci_probe_reset_bus(vdev->pdev->bus))\n\t\t\treturn -ENODEV;\n\n\t\t/*\n\t\t * We can't let userspace give us an arbitrarily large\n\t\t * buffer to copy, so verify how many we think there\n\t\t * could be.  Note groups can have multiple devices so\n\t\t * one group per device is the max.\n\t\t */\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_count_devs,\n\t\t\t\t\t\t    &count, slot);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t/* Somewhere between 1 and count is OK */\n\t\tif (!hdr.count || hdr.count > count)\n\t\t\treturn -EINVAL;\n\n\t\tgroup_fds = kcalloc(hdr.count, sizeof(*group_fds), GFP_KERNEL);\n\t\tgroups = kcalloc(hdr.count, sizeof(*groups), GFP_KERNEL);\n\t\tif (!group_fds || !groups) {\n\t\t\tkfree(group_fds);\n\t\t\tkfree(groups);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (copy_from_user(group_fds, (void __user *)(arg + minsz),\n\t\t\t\t   hdr.count * sizeof(*group_fds))) {\n\t\t\tkfree(group_fds);\n\t\t\tkfree(groups);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\t/*\n\t\t * For each group_fd, get the group through the vfio external\n\t\t * user interface and store the group and iommu ID.  This\n\t\t * ensures the group is held across the reset.\n\t\t */\n\t\tfor (i = 0; i < hdr.count; i++) {\n\t\t\tstruct vfio_group *group;\n\t\t\tstruct fd f = fdget(group_fds[i]);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgroup = vfio_group_get_external_user(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(group)) {\n\t\t\t\tret = PTR_ERR(group);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgroups[i].group = group;\n\t\t\tgroups[i].id = vfio_external_user_iommu_id(group);\n\t\t}\n\n\t\tkfree(group_fds);\n\n\t\t/* release reference to groups on error */\n\t\tif (ret)\n\t\t\tgoto hot_reset_release;\n\n\t\tinfo.count = hdr.count;\n\t\tinfo.groups = groups;\n\n\t\t/*\n\t\t * Test whether all the affected devices are contained\n\t\t * by the set of groups provided by the user.\n\t\t */\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_validate_devs,\n\t\t\t\t\t\t    &info, slot);\n\t\tif (!ret)\n\t\t\t/* User has access, do the reset */\n\t\t\tret = slot ? pci_try_reset_slot(vdev->pdev->slot) :\n\t\t\t\t     pci_try_reset_bus(vdev->pdev->bus);\n\nhot_reset_release:\n\t\tfor (i--; i >= 0; i--)\n\t\t\tvfio_group_put_external_user(groups[i].group);\n\n\t\tkfree(groups);\n\t\treturn ret;\n\t}\n\n\treturn -ENOTTY;\n}",
      "code_after_change": "static long vfio_pci_ioctl(void *device_data,\n\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\tstruct vfio_pci_device *vdev = device_data;\n\tunsigned long minsz;\n\n\tif (cmd == VFIO_DEVICE_GET_INFO) {\n\t\tstruct vfio_device_info info;\n\n\t\tminsz = offsetofend(struct vfio_device_info, num_irqs);\n\n\t\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (info.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tinfo.flags = VFIO_DEVICE_FLAGS_PCI;\n\n\t\tif (vdev->reset_works)\n\t\t\tinfo.flags |= VFIO_DEVICE_FLAGS_RESET;\n\n\t\tinfo.num_regions = VFIO_PCI_NUM_REGIONS + vdev->num_regions;\n\t\tinfo.num_irqs = VFIO_PCI_NUM_IRQS;\n\n\t\treturn copy_to_user((void __user *)arg, &info, minsz) ?\n\t\t\t-EFAULT : 0;\n\n\t} else if (cmd == VFIO_DEVICE_GET_REGION_INFO) {\n\t\tstruct pci_dev *pdev = vdev->pdev;\n\t\tstruct vfio_region_info info;\n\t\tstruct vfio_info_cap caps = { .buf = NULL, .size = 0 };\n\t\tint i, ret;\n\n\t\tminsz = offsetofend(struct vfio_region_info, offset);\n\n\t\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (info.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\tswitch (info.index) {\n\t\tcase VFIO_PCI_CONFIG_REGION_INDEX:\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = pdev->cfg_size;\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ |\n\t\t\t\t     VFIO_REGION_INFO_FLAG_WRITE;\n\t\t\tbreak;\n\t\tcase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = pci_resource_len(pdev, info.index);\n\t\t\tif (!info.size) {\n\t\t\t\tinfo.flags = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ |\n\t\t\t\t     VFIO_REGION_INFO_FLAG_WRITE;\n\t\t\tif (vdev->bar_mmap_supported[info.index]) {\n\t\t\t\tinfo.flags |= VFIO_REGION_INFO_FLAG_MMAP;\n\t\t\t\tif (info.index == vdev->msix_bar) {\n\t\t\t\t\tret = msix_sparse_mmap_cap(vdev, &caps);\n\t\t\t\t\tif (ret)\n\t\t\t\t\t\treturn ret;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbreak;\n\t\tcase VFIO_PCI_ROM_REGION_INDEX:\n\t\t{\n\t\t\tvoid __iomem *io;\n\t\t\tsize_t size;\n\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.flags = 0;\n\n\t\t\t/* Report the BAR size, not the ROM size */\n\t\t\tinfo.size = pci_resource_len(pdev, info.index);\n\t\t\tif (!info.size) {\n\t\t\t\t/* Shadow ROMs appear as PCI option ROMs */\n\t\t\t\tif (pdev->resource[PCI_ROM_RESOURCE].flags &\n\t\t\t\t\t\t\tIORESOURCE_ROM_SHADOW)\n\t\t\t\t\tinfo.size = 0x20000;\n\t\t\t\telse\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Is it really there? */\n\t\t\tio = pci_map_rom(pdev, &size);\n\t\t\tif (!io || !size) {\n\t\t\t\tinfo.size = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpci_unmap_rom(pdev, io);\n\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ;\n\t\t\tbreak;\n\t\t}\n\t\tcase VFIO_PCI_VGA_REGION_INDEX:\n\t\t\tif (!vdev->has_vga)\n\t\t\t\treturn -EINVAL;\n\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = 0xc0000;\n\t\t\tinfo.flags = VFIO_REGION_INFO_FLAG_READ |\n\t\t\t\t     VFIO_REGION_INFO_FLAG_WRITE;\n\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (info.index >=\n\t\t\t    VFIO_PCI_NUM_REGIONS + vdev->num_regions)\n\t\t\t\treturn -EINVAL;\n\n\t\t\ti = info.index - VFIO_PCI_NUM_REGIONS;\n\n\t\t\tinfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\n\t\t\tinfo.size = vdev->region[i].size;\n\t\t\tinfo.flags = vdev->region[i].flags;\n\n\t\t\tret = region_type_cap(vdev, &caps,\n\t\t\t\t\t      vdev->region[i].type,\n\t\t\t\t\t      vdev->region[i].subtype);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tif (caps.size) {\n\t\t\tinfo.flags |= VFIO_REGION_INFO_FLAG_CAPS;\n\t\t\tif (info.argsz < sizeof(info) + caps.size) {\n\t\t\t\tinfo.argsz = sizeof(info) + caps.size;\n\t\t\t\tinfo.cap_offset = 0;\n\t\t\t} else {\n\t\t\t\tvfio_info_cap_shift(&caps, sizeof(info));\n\t\t\t\tif (copy_to_user((void __user *)arg +\n\t\t\t\t\t\t  sizeof(info), caps.buf,\n\t\t\t\t\t\t  caps.size)) {\n\t\t\t\t\tkfree(caps.buf);\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\t}\n\t\t\t\tinfo.cap_offset = sizeof(info);\n\t\t\t}\n\n\t\t\tkfree(caps.buf);\n\t\t}\n\n\t\treturn copy_to_user((void __user *)arg, &info, minsz) ?\n\t\t\t-EFAULT : 0;\n\n\t} else if (cmd == VFIO_DEVICE_GET_IRQ_INFO) {\n\t\tstruct vfio_irq_info info;\n\n\t\tminsz = offsetofend(struct vfio_irq_info, count);\n\n\t\tif (copy_from_user(&info, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (info.argsz < minsz || info.index >= VFIO_PCI_NUM_IRQS)\n\t\t\treturn -EINVAL;\n\n\t\tswitch (info.index) {\n\t\tcase VFIO_PCI_INTX_IRQ_INDEX ... VFIO_PCI_MSIX_IRQ_INDEX:\n\t\tcase VFIO_PCI_REQ_IRQ_INDEX:\n\t\t\tbreak;\n\t\tcase VFIO_PCI_ERR_IRQ_INDEX:\n\t\t\tif (pci_is_pcie(vdev->pdev))\n\t\t\t\tbreak;\n\t\t/* pass thru to return error */\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tinfo.flags = VFIO_IRQ_INFO_EVENTFD;\n\n\t\tinfo.count = vfio_pci_get_irq_count(vdev, info.index);\n\n\t\tif (info.index == VFIO_PCI_INTX_IRQ_INDEX)\n\t\t\tinfo.flags |= (VFIO_IRQ_INFO_MASKABLE |\n\t\t\t\t       VFIO_IRQ_INFO_AUTOMASKED);\n\t\telse\n\t\t\tinfo.flags |= VFIO_IRQ_INFO_NORESIZE;\n\n\t\treturn copy_to_user((void __user *)arg, &info, minsz) ?\n\t\t\t-EFAULT : 0;\n\n\t} else if (cmd == VFIO_DEVICE_SET_IRQS) {\n\t\tstruct vfio_irq_set hdr;\n\t\tsize_t size;\n\t\tu8 *data = NULL;\n\t\tint max, ret = 0;\n\n\t\tminsz = offsetofend(struct vfio_irq_set, count);\n\n\t\tif (copy_from_user(&hdr, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (hdr.argsz < minsz || hdr.index >= VFIO_PCI_NUM_IRQS ||\n\t\t    hdr.count >= (U32_MAX - hdr.start) ||\n\t\t    hdr.flags & ~(VFIO_IRQ_SET_DATA_TYPE_MASK |\n\t\t\t\t  VFIO_IRQ_SET_ACTION_TYPE_MASK))\n\t\t\treturn -EINVAL;\n\n\t\tmax = vfio_pci_get_irq_count(vdev, hdr.index);\n\t\tif (hdr.start >= max || hdr.start + hdr.count > max)\n\t\t\treturn -EINVAL;\n\n\t\tswitch (hdr.flags & VFIO_IRQ_SET_DATA_TYPE_MASK) {\n\t\tcase VFIO_IRQ_SET_DATA_NONE:\n\t\t\tsize = 0;\n\t\t\tbreak;\n\t\tcase VFIO_IRQ_SET_DATA_BOOL:\n\t\t\tsize = sizeof(uint8_t);\n\t\t\tbreak;\n\t\tcase VFIO_IRQ_SET_DATA_EVENTFD:\n\t\t\tsize = sizeof(int32_t);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (size) {\n\t\t\tif (hdr.argsz - minsz < hdr.count * size)\n\t\t\t\treturn -EINVAL;\n\n\t\t\tdata = memdup_user((void __user *)(arg + minsz),\n\t\t\t\t\t   hdr.count * size);\n\t\t\tif (IS_ERR(data))\n\t\t\t\treturn PTR_ERR(data);\n\t\t}\n\n\t\tmutex_lock(&vdev->igate);\n\n\t\tret = vfio_pci_set_irqs_ioctl(vdev, hdr.flags, hdr.index,\n\t\t\t\t\t      hdr.start, hdr.count, data);\n\n\t\tmutex_unlock(&vdev->igate);\n\t\tkfree(data);\n\n\t\treturn ret;\n\n\t} else if (cmd == VFIO_DEVICE_RESET) {\n\t\treturn vdev->reset_works ?\n\t\t\tpci_try_reset_function(vdev->pdev) : -EINVAL;\n\n\t} else if (cmd == VFIO_DEVICE_GET_PCI_HOT_RESET_INFO) {\n\t\tstruct vfio_pci_hot_reset_info hdr;\n\t\tstruct vfio_pci_fill_info fill = { 0 };\n\t\tstruct vfio_pci_dependent_device *devices = NULL;\n\t\tbool slot = false;\n\t\tint ret = 0;\n\n\t\tminsz = offsetofend(struct vfio_pci_hot_reset_info, count);\n\n\t\tif (copy_from_user(&hdr, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (hdr.argsz < minsz)\n\t\t\treturn -EINVAL;\n\n\t\thdr.flags = 0;\n\n\t\t/* Can we do a slot or bus reset or neither? */\n\t\tif (!pci_probe_reset_slot(vdev->pdev->slot))\n\t\t\tslot = true;\n\t\telse if (pci_probe_reset_bus(vdev->pdev->bus))\n\t\t\treturn -ENODEV;\n\n\t\t/* How many devices are affected? */\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_count_devs,\n\t\t\t\t\t\t    &fill.max, slot);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tWARN_ON(!fill.max); /* Should always be at least one */\n\n\t\t/*\n\t\t * If there's enough space, fill it now, otherwise return\n\t\t * -ENOSPC and the number of devices affected.\n\t\t */\n\t\tif (hdr.argsz < sizeof(hdr) + (fill.max * sizeof(*devices))) {\n\t\t\tret = -ENOSPC;\n\t\t\thdr.count = fill.max;\n\t\t\tgoto reset_info_exit;\n\t\t}\n\n\t\tdevices = kcalloc(fill.max, sizeof(*devices), GFP_KERNEL);\n\t\tif (!devices)\n\t\t\treturn -ENOMEM;\n\n\t\tfill.devices = devices;\n\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_fill_devs,\n\t\t\t\t\t\t    &fill, slot);\n\n\t\t/*\n\t\t * If a device was removed between counting and filling,\n\t\t * we may come up short of fill.max.  If a device was\n\t\t * added, we'll have a return of -EAGAIN above.\n\t\t */\n\t\tif (!ret)\n\t\t\thdr.count = fill.cur;\n\nreset_info_exit:\n\t\tif (copy_to_user((void __user *)arg, &hdr, minsz))\n\t\t\tret = -EFAULT;\n\n\t\tif (!ret) {\n\t\t\tif (copy_to_user((void __user *)(arg + minsz), devices,\n\t\t\t\t\t hdr.count * sizeof(*devices)))\n\t\t\t\tret = -EFAULT;\n\t\t}\n\n\t\tkfree(devices);\n\t\treturn ret;\n\n\t} else if (cmd == VFIO_DEVICE_PCI_HOT_RESET) {\n\t\tstruct vfio_pci_hot_reset hdr;\n\t\tint32_t *group_fds;\n\t\tstruct vfio_pci_group_entry *groups;\n\t\tstruct vfio_pci_group_info info;\n\t\tbool slot = false;\n\t\tint i, count = 0, ret = 0;\n\n\t\tminsz = offsetofend(struct vfio_pci_hot_reset, count);\n\n\t\tif (copy_from_user(&hdr, (void __user *)arg, minsz))\n\t\t\treturn -EFAULT;\n\n\t\tif (hdr.argsz < minsz || hdr.flags)\n\t\t\treturn -EINVAL;\n\n\t\t/* Can we do a slot or bus reset or neither? */\n\t\tif (!pci_probe_reset_slot(vdev->pdev->slot))\n\t\t\tslot = true;\n\t\telse if (pci_probe_reset_bus(vdev->pdev->bus))\n\t\t\treturn -ENODEV;\n\n\t\t/*\n\t\t * We can't let userspace give us an arbitrarily large\n\t\t * buffer to copy, so verify how many we think there\n\t\t * could be.  Note groups can have multiple devices so\n\t\t * one group per device is the max.\n\t\t */\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_count_devs,\n\t\t\t\t\t\t    &count, slot);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t/* Somewhere between 1 and count is OK */\n\t\tif (!hdr.count || hdr.count > count)\n\t\t\treturn -EINVAL;\n\n\t\tgroup_fds = kcalloc(hdr.count, sizeof(*group_fds), GFP_KERNEL);\n\t\tgroups = kcalloc(hdr.count, sizeof(*groups), GFP_KERNEL);\n\t\tif (!group_fds || !groups) {\n\t\t\tkfree(group_fds);\n\t\t\tkfree(groups);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (copy_from_user(group_fds, (void __user *)(arg + minsz),\n\t\t\t\t   hdr.count * sizeof(*group_fds))) {\n\t\t\tkfree(group_fds);\n\t\t\tkfree(groups);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\t/*\n\t\t * For each group_fd, get the group through the vfio external\n\t\t * user interface and store the group and iommu ID.  This\n\t\t * ensures the group is held across the reset.\n\t\t */\n\t\tfor (i = 0; i < hdr.count; i++) {\n\t\t\tstruct vfio_group *group;\n\t\t\tstruct fd f = fdget(group_fds[i]);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgroup = vfio_group_get_external_user(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(group)) {\n\t\t\t\tret = PTR_ERR(group);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgroups[i].group = group;\n\t\t\tgroups[i].id = vfio_external_user_iommu_id(group);\n\t\t}\n\n\t\tkfree(group_fds);\n\n\t\t/* release reference to groups on error */\n\t\tif (ret)\n\t\t\tgoto hot_reset_release;\n\n\t\tinfo.count = hdr.count;\n\t\tinfo.groups = groups;\n\n\t\t/*\n\t\t * Test whether all the affected devices are contained\n\t\t * by the set of groups provided by the user.\n\t\t */\n\t\tret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\n\t\t\t\t\t\t    vfio_pci_validate_devs,\n\t\t\t\t\t\t    &info, slot);\n\t\tif (!ret)\n\t\t\t/* User has access, do the reset */\n\t\t\tret = slot ? pci_try_reset_slot(vdev->pdev->slot) :\n\t\t\t\t     pci_try_reset_bus(vdev->pdev->bus);\n\nhot_reset_release:\n\t\tfor (i--; i >= 0; i--)\n\t\t\tvfio_group_put_external_user(groups[i].group);\n\n\t\tkfree(groups);\n\t\treturn ret;\n\t}\n\n\treturn -ENOTTY;\n}",
      "modified_lines": {
        "added": [
          "\t\tsize_t size;",
          "\t\tint max, ret = 0;",
          "\t\t    hdr.count >= (U32_MAX - hdr.start) ||",
          "\t\tmax = vfio_pci_get_irq_count(vdev, hdr.index);",
          "\t\tif (hdr.start >= max || hdr.start + hdr.count > max)",
          "\t\t\treturn -EINVAL;",
          "",
          "\t\tswitch (hdr.flags & VFIO_IRQ_SET_DATA_TYPE_MASK) {",
          "\t\tcase VFIO_IRQ_SET_DATA_NONE:",
          "\t\t\tsize = 0;",
          "\t\t\tbreak;",
          "\t\tcase VFIO_IRQ_SET_DATA_BOOL:",
          "\t\t\tsize = sizeof(uint8_t);",
          "\t\t\tbreak;",
          "\t\tcase VFIO_IRQ_SET_DATA_EVENTFD:",
          "\t\t\tsize = sizeof(int32_t);",
          "\t\t\tbreak;",
          "\t\tdefault:",
          "\t\t\treturn -EINVAL;",
          "\t\t}",
          "",
          "\t\tif (size) {",
          "\t\t\tif (hdr.argsz - minsz < hdr.count * size)"
        ],
        "deleted": [
          "\t\tint ret = 0;",
          "\t\tif (!(hdr.flags & VFIO_IRQ_SET_DATA_NONE)) {",
          "\t\t\tsize_t size;",
          "\t\t\tint max = vfio_pci_get_irq_count(vdev, hdr.index);",
          "",
          "\t\t\tif (hdr.flags & VFIO_IRQ_SET_DATA_BOOL)",
          "\t\t\t\tsize = sizeof(uint8_t);",
          "\t\t\telse if (hdr.flags & VFIO_IRQ_SET_DATA_EVENTFD)",
          "\t\t\t\tsize = sizeof(int32_t);",
          "\t\t\telse",
          "\t\t\t\treturn -EINVAL;",
          "",
          "\t\t\tif (hdr.argsz - minsz < hdr.count * size ||",
          "\t\t\t    hdr.start >= max || hdr.start + hdr.count > max)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for input values and potential integer overflow scenarios in the VFIO_DEVICE_SET_IRQS ioctl call.",
      "trigger_condition": "An attacker leverages access to a vfio PCI device file to provide manipulated input values that can lead to integer overflow during the calculation of IRQ count.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check for potential integer overflow when calculating the count of IRQs in the VFIO_DEVICE_SET_IRQS ioctl call, allowing an attacker to bypass checks and potentially cause memory corruption or other unspecified impacts.",
      "solution": "To mitigate the vulnerability, it is necessary to add proper validation checks to ensure that the count calculation does not exceed the maximum value allowed and to handle the size calculation based on the data type specified in the flags. This prevents integer overflow scenarios and ensures correct handling of input values in the ioctl call.",
      "id": 99,
      "code_after_change_normalized": "static long FUN1(void *VAR1,\nunsigned int VAR2, unsigned long VAR3)\n{\nstruct vfio_pci_device *VAR4 = VAR1;\nunsigned long VAR5;\nif (VAR2 == VAR6) {\nstruct vfio_device_info VAR7;\nVAR5 = FUN2(struct VAR8, VAR9);\nif (FUN3(&VAR7, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR7.VAR12 < VAR5)\nreturn -VAR13;\nVAR7.VAR14 = VAR15;\nif (VAR4->VAR16)\nVAR7.VAR14 |= VAR17;\nVAR7.VAR18 = VAR19 + VAR4->VAR18;\nVAR7.VAR9 = VAR20;\nreturn FUN4((void VAR10 *)VAR3, &VAR7, VAR5) ?\n-VAR11 : 0;\n} else if (VAR2 == VAR21) {\nstruct pci_dev *VAR22 = VAR4->VAR22;\nstruct vfio_region_info VAR7;\nstruct vfio_info_cap VAR23 = { .VAR24 = NULL, .VAR25 = 0 };\nint VAR26, VAR27;\nVAR5 = FUN2(struct VAR28, VAR29);\nif (FUN3(&VAR7, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR7.VAR12 < VAR5)\nreturn -VAR13;\nswitch (VAR7.VAR30) {\ncase VAR31:\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = VAR22->VAR32;\nVAR7.VAR14 = VAR33 |\nVAR34;\nbreak;\ncase VAR35 ... VAR36:\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = FUN6(VAR22, VAR7.VAR30);\nif (!VAR7.VAR25) {\nVAR7.VAR14 = 0;\nbreak;\n}\nVAR7.VAR14 = VAR33 |\nVAR34;\nif (VAR4->VAR37[VAR7.VAR30]) {\nVAR7.VAR14 |= VAR38;\nif (VAR7.VAR30 == VAR4->VAR39) {\nVAR27 = FUN7(VAR4, &VAR23);\nif (VAR27)\nreturn VAR27;\n}\n}\nbreak;\ncase VAR40:\n{\nvoid __iomem *VAR41;\nsize_t VAR25;\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR14 = 0;\nVAR7.VAR25 = FUN6(VAR22, VAR7.VAR30);\nif (!VAR7.VAR25) {\nif (VAR22->VAR42[VAR43].VAR14 &\nVAR44)\nVAR7.VAR25 = VAR45;\nelse\nbreak;\n}\nVAR41 = FUN8(VAR22, &VAR25);\nif (!VAR41 || !VAR25) {\nVAR7.VAR25 = 0;\nbreak;\n}\nFUN9(VAR22, VAR41);\nVAR7.VAR14 = VAR33;\nbreak;\n}\ncase VAR46:\nif (!VAR4->VAR47)\nreturn -VAR13;\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = VAR45;\nVAR7.VAR14 = VAR33 |\nVAR34;\nbreak;\ndefault:\nif (VAR7.VAR30 >=\nVAR19 + VAR4->VAR18)\nreturn -VAR13;\nVAR26 = VAR7.VAR30 - VAR19;\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = VAR4->VAR48[VAR26].VAR25;\nVAR7.VAR14 = VAR4->VAR48[VAR26].VAR14;\nVAR27 = FUN10(VAR4, &VAR23,\nVAR4->VAR48[VAR26].VAR49,\nVAR4->VAR48[VAR26].VAR50);\nif (VAR27)\nreturn VAR27;\n}\nif (VAR23.VAR25) {\nVAR7.VAR14 |= VAR51;\nif (VAR7.VAR12 < sizeof(VAR7) + VAR23.VAR25) {\nVAR7.VAR12 = sizeof(VAR7) + VAR23.VAR25;\nVAR7.VAR52 = 0;\n} else {\nFUN11(&VAR23, sizeof(VAR7));\nif (FUN4((void VAR10 *)VAR3 +\nsizeof(VAR7), VAR23.VAR24,\nVAR23.VAR25)) {\nFUN12(VAR23.VAR24);\nreturn -VAR11;\n}\nVAR7.VAR52 = sizeof(VAR7);\n}\nFUN12(VAR23.VAR24);\n}\nreturn FUN4((void VAR10 *)VAR3, &VAR7, VAR5) ?\n-VAR11 : 0;\n} else if (VAR2 == VAR53) {\nstruct vfio_irq_info VAR7;\nVAR5 = FUN2(struct VAR54, VAR55);\nif (FUN3(&VAR7, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR7.VAR12 < VAR5 || VAR7.VAR30 >= VAR20)\nreturn -VAR13;\nswitch (VAR7.VAR30) {\ncase VAR56 ... VAR57:\ncase VAR58:\nbreak;\ncase VAR59:\nif (FUN13(VAR4->VAR22))\nbreak;\ndefault:\nreturn -VAR13;\n}\nVAR7.VAR14 = VAR60;\nVAR7.VAR55 = FUN14(VAR4, VAR7.VAR30);\nif (VAR7.VAR30 == VAR56)\nVAR7.VAR14 |= (VAR61 |\nVAR62);\nelse\nVAR7.VAR14 |= VAR63;\nreturn FUN4((void VAR10 *)VAR3, &VAR7, VAR5) ?\n-VAR11 : 0;\n} else if (VAR2 == VAR64) {\nstruct vfio_irq_set VAR65;\nsize_t VAR25;\nu8 *VAR66 = NULL;\nint VAR67, VAR27 = 0;\nVAR5 = FUN2(struct VAR68, VAR55);\nif (FUN3(&VAR65, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR65.VAR12 < VAR5 || VAR65.VAR30 >= VAR20 ||\nVAR65.VAR55 >= (VAR69 - VAR65.VAR70) ||\nVAR65.VAR14 & ~(VAR71 |\nVAR72))\nreturn -VAR13;\nVAR67 = FUN14(VAR4, VAR65.VAR30);\nif (VAR65.VAR70 >= VAR67 || VAR65.VAR70 + VAR65.VAR55 > VAR67)\nreturn -VAR13;\nswitch (VAR65.VAR14 & VAR71) {\ncase VAR73:\nVAR25 = 0;\nbreak;\ncase VAR74:\nVAR25 = sizeof(VAR75);\nbreak;\ncase VAR76:\nVAR25 = sizeof(VAR77);\nbreak;\ndefault:\nreturn -VAR13;\n}\nif (VAR25) {\nif (VAR65.VAR12 - VAR5 < VAR65.VAR55 * VAR25)\nreturn -VAR13;\nVAR66 = FUN15((void VAR10 *)(VAR3 + VAR5),\nVAR65.VAR55 * VAR25);\nif (FUN16(VAR66))\nreturn FUN17(VAR66);\n}\nFUN18(&VAR4->VAR78);\nVAR27 = FUN19(VAR4, VAR65.VAR14, VAR65.VAR30,\nVAR65.VAR70, VAR65.VAR55, VAR66);\nFUN20(&VAR4->VAR78);\nFUN12(VAR66);\nreturn VAR27;\n} else if (VAR2 == VAR79) {\nreturn VAR4->VAR16 ?\nFUN21(VAR4->VAR22) : -VAR13;\n} else if (VAR2 == VAR80) {\nstruct vfio_pci_hot_reset_info VAR65;\nstruct vfio_pci_fill_info VAR81 = { 0 };\nstruct vfio_pci_dependent_device *VAR82 = NULL;\nbool VAR83 = false;\nint VAR27 = 0;\nVAR5 = FUN2(struct VAR84, VAR55);\nif (FUN3(&VAR65, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR65.VAR12 < VAR5)\nreturn -VAR13;\nVAR65.VAR14 = 0;\nif (!FUN22(VAR4->VAR22->VAR83))\nVAR83 = true;\nelse if (FUN23(VAR4->VAR22->VAR85))\nreturn -VAR86;\nVAR27 = FUN24(VAR4->VAR22,\nVAR87,\n&VAR81.VAR67, VAR83);\nif (VAR27)\nreturn VAR27;\nFUN25(!VAR81.VAR67); \nif (VAR65.VAR12 < sizeof(VAR65) + (VAR81.VAR67 * sizeof(*VAR82))) {\nVAR27 = -VAR88;\nVAR65.VAR55 = VAR81.VAR67;\ngoto VAR89;\n}\nVAR82 = FUN26(VAR81.VAR67, sizeof(*VAR82), VAR90);\nif (!VAR82)\nreturn -VAR91;\nVAR81.VAR82 = VAR82;\nVAR27 = FUN24(VAR4->VAR22,\nVAR92,\n&VAR81, VAR83);\nif (!VAR27)\nVAR65.VAR55 = VAR81.VAR93;\nVAR89:\nif (FUN4((void VAR10 *)VAR3, &VAR65, VAR5))\nVAR27 = -VAR11;\nif (!VAR27) {\nif (FUN4((void VAR10 *)(VAR3 + VAR5), VAR82,\nVAR65.VAR55 * sizeof(*VAR82)))\nVAR27 = -VAR11;\n}\nFUN12(VAR82);\nreturn VAR27;\n} else if (VAR2 == VAR94) {\nstruct vfio_pci_hot_reset VAR65;\nint32_t *VAR95;\nstruct vfio_pci_group_entry *VAR96;\nstruct vfio_pci_group_info VAR7;\nbool VAR83 = false;\nint VAR26, VAR55 = 0, VAR27 = 0;\nVAR5 = FUN2(struct VAR97, VAR55);\nif (FUN3(&VAR65, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR65.VAR12 < VAR5 || VAR65.VAR14)\nreturn -VAR13;\nif (!FUN22(VAR4->VAR22->VAR83))\nVAR83 = true;\nelse if (FUN23(VAR4->VAR22->VAR85))\nreturn -VAR86;\nVAR27 = FUN24(VAR4->VAR22,\nVAR87,\n&VAR55, VAR83);\nif (VAR27)\nreturn VAR27;\nif (!VAR65.VAR55 || VAR65.VAR55 > VAR55)\nreturn -VAR13;\nVAR95 = FUN26(VAR65.VAR55, sizeof(*VAR95), VAR90);\nVAR96 = FUN26(VAR65.VAR55, sizeof(*VAR96), VAR90);\nif (!VAR95 || !VAR96) {\nFUN12(VAR95);\nFUN12(VAR96);\nreturn -VAR91;\n}\nif (FUN3(VAR95, (void VAR10 *)(VAR3 + VAR5),\nVAR65.VAR55 * sizeof(*VAR95))) {\nFUN12(VAR95);\nFUN12(VAR96);\nreturn -VAR11;\n}\nfor (VAR26 = 0; VAR26 < VAR65.VAR55; VAR26++) {\nstruct vfio_group *VAR98;\nstruct fd VAR99 = FUN27(VAR95[VAR26]);\nif (!VAR99.VAR100) {\nVAR27 = -VAR101;\nbreak;\n}\nVAR98 = FUN28(VAR99.VAR100);\nFUN29(VAR99);\nif (FUN16(VAR98)) {\nVAR27 = FUN17(VAR98);\nbreak;\n}\nVAR96[VAR26].VAR98 = VAR98;\nVAR96[VAR26].VAR102 = FUN30(VAR98);\n}\nFUN12(VAR95);\nif (VAR27)\ngoto VAR103;\nVAR7.VAR55 = VAR65.VAR55;\nVAR7.VAR96 = VAR96;\nVAR27 = FUN24(VAR4->VAR22,\nVAR104,\n&VAR7, VAR83);\nif (!VAR27)\nVAR27 = VAR83 ? FUN31(VAR4->VAR22->VAR83) :\nFUN32(VAR4->VAR22->VAR85);\nVAR103:\nfor (VAR26--; VAR26 >= 0; VAR26--)\nFUN33(VAR96[VAR26].VAR98);\nFUN12(VAR96);\nreturn VAR27;\n}\nreturn -VAR105;\n}\n",
      "code_before_change_normalized": "static long FUN1(void *VAR1,\nunsigned int VAR2, unsigned long VAR3)\n{\nstruct vfio_pci_device *VAR4 = VAR1;\nunsigned long VAR5;\nif (VAR2 == VAR6) {\nstruct vfio_device_info VAR7;\nVAR5 = FUN2(struct VAR8, VAR9);\nif (FUN3(&VAR7, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR7.VAR12 < VAR5)\nreturn -VAR13;\nVAR7.VAR14 = VAR15;\nif (VAR4->VAR16)\nVAR7.VAR14 |= VAR17;\nVAR7.VAR18 = VAR19 + VAR4->VAR18;\nVAR7.VAR9 = VAR20;\nreturn FUN4((void VAR10 *)VAR3, &VAR7, VAR5) ?\n-VAR11 : 0;\n} else if (VAR2 == VAR21) {\nstruct pci_dev *VAR22 = VAR4->VAR22;\nstruct vfio_region_info VAR7;\nstruct vfio_info_cap VAR23 = { .VAR24 = NULL, .VAR25 = 0 };\nint VAR26, VAR27;\nVAR5 = FUN2(struct VAR28, VAR29);\nif (FUN3(&VAR7, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR7.VAR12 < VAR5)\nreturn -VAR13;\nswitch (VAR7.VAR30) {\ncase VAR31:\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = VAR22->VAR32;\nVAR7.VAR14 = VAR33 |\nVAR34;\nbreak;\ncase VAR35 ... VAR36:\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = FUN6(VAR22, VAR7.VAR30);\nif (!VAR7.VAR25) {\nVAR7.VAR14 = 0;\nbreak;\n}\nVAR7.VAR14 = VAR33 |\nVAR34;\nif (VAR4->VAR37[VAR7.VAR30]) {\nVAR7.VAR14 |= VAR38;\nif (VAR7.VAR30 == VAR4->VAR39) {\nVAR27 = FUN7(VAR4, &VAR23);\nif (VAR27)\nreturn VAR27;\n}\n}\nbreak;\ncase VAR40:\n{\nvoid __iomem *VAR41;\nsize_t VAR25;\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR14 = 0;\nVAR7.VAR25 = FUN6(VAR22, VAR7.VAR30);\nif (!VAR7.VAR25) {\nif (VAR22->VAR42[VAR43].VAR14 &\nVAR44)\nVAR7.VAR25 = VAR45;\nelse\nbreak;\n}\nVAR41 = FUN8(VAR22, &VAR25);\nif (!VAR41 || !VAR25) {\nVAR7.VAR25 = 0;\nbreak;\n}\nFUN9(VAR22, VAR41);\nVAR7.VAR14 = VAR33;\nbreak;\n}\ncase VAR46:\nif (!VAR4->VAR47)\nreturn -VAR13;\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = VAR45;\nVAR7.VAR14 = VAR33 |\nVAR34;\nbreak;\ndefault:\nif (VAR7.VAR30 >=\nVAR19 + VAR4->VAR18)\nreturn -VAR13;\nVAR26 = VAR7.VAR30 - VAR19;\nVAR7.VAR29 = FUN5(VAR7.VAR30);\nVAR7.VAR25 = VAR4->VAR48[VAR26].VAR25;\nVAR7.VAR14 = VAR4->VAR48[VAR26].VAR14;\nVAR27 = FUN10(VAR4, &VAR23,\nVAR4->VAR48[VAR26].VAR49,\nVAR4->VAR48[VAR26].VAR50);\nif (VAR27)\nreturn VAR27;\n}\nif (VAR23.VAR25) {\nVAR7.VAR14 |= VAR51;\nif (VAR7.VAR12 < sizeof(VAR7) + VAR23.VAR25) {\nVAR7.VAR12 = sizeof(VAR7) + VAR23.VAR25;\nVAR7.VAR52 = 0;\n} else {\nFUN11(&VAR23, sizeof(VAR7));\nif (FUN4((void VAR10 *)VAR3 +\nsizeof(VAR7), VAR23.VAR24,\nVAR23.VAR25)) {\nFUN12(VAR23.VAR24);\nreturn -VAR11;\n}\nVAR7.VAR52 = sizeof(VAR7);\n}\nFUN12(VAR23.VAR24);\n}\nreturn FUN4((void VAR10 *)VAR3, &VAR7, VAR5) ?\n-VAR11 : 0;\n} else if (VAR2 == VAR53) {\nstruct vfio_irq_info VAR7;\nVAR5 = FUN2(struct VAR54, VAR55);\nif (FUN3(&VAR7, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR7.VAR12 < VAR5 || VAR7.VAR30 >= VAR20)\nreturn -VAR13;\nswitch (VAR7.VAR30) {\ncase VAR56 ... VAR57:\ncase VAR58:\nbreak;\ncase VAR59:\nif (FUN13(VAR4->VAR22))\nbreak;\ndefault:\nreturn -VAR13;\n}\nVAR7.VAR14 = VAR60;\nVAR7.VAR55 = FUN14(VAR4, VAR7.VAR30);\nif (VAR7.VAR30 == VAR56)\nVAR7.VAR14 |= (VAR61 |\nVAR62);\nelse\nVAR7.VAR14 |= VAR63;\nreturn FUN4((void VAR10 *)VAR3, &VAR7, VAR5) ?\n-VAR11 : 0;\n} else if (VAR2 == VAR64) {\nstruct vfio_irq_set VAR65;\nu8 *VAR66 = NULL;\nint VAR27 = 0;\nVAR5 = FUN2(struct VAR67, VAR55);\nif (FUN3(&VAR65, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR65.VAR12 < VAR5 || VAR65.VAR30 >= VAR20 ||\nVAR65.VAR14 & ~(VAR68 |\nVAR69))\nreturn -VAR13;\nif (!(VAR65.VAR14 & VAR70)) {\nsize_t VAR25;\nint VAR71 = FUN14(VAR4, VAR65.VAR30);\nif (VAR65.VAR14 & VAR72)\nVAR25 = sizeof(VAR73);\nelse if (VAR65.VAR14 & VAR74)\nVAR25 = sizeof(VAR75);\nelse\nreturn -VAR13;\nif (VAR65.VAR12 - VAR5 < VAR65.VAR55 * VAR25 ||\nVAR65.VAR76 >= VAR71 || VAR65.VAR76 + VAR65.VAR55 > VAR71)\nreturn -VAR13;\nVAR66 = FUN15((void VAR10 *)(VAR3 + VAR5),\nVAR65.VAR55 * VAR25);\nif (FUN16(VAR66))\nreturn FUN17(VAR66);\n}\nFUN18(&VAR4->VAR77);\nVAR27 = FUN19(VAR4, VAR65.VAR14, VAR65.VAR30,\nVAR65.VAR76, VAR65.VAR55, VAR66);\nFUN20(&VAR4->VAR77);\nFUN12(VAR66);\nreturn VAR27;\n} else if (VAR2 == VAR78) {\nreturn VAR4->VAR16 ?\nFUN21(VAR4->VAR22) : -VAR13;\n} else if (VAR2 == VAR79) {\nstruct vfio_pci_hot_reset_info VAR65;\nstruct vfio_pci_fill_info VAR80 = { 0 };\nstruct vfio_pci_dependent_device *VAR81 = NULL;\nbool VAR82 = false;\nint VAR27 = 0;\nVAR5 = FUN2(struct VAR83, VAR55);\nif (FUN3(&VAR65, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR65.VAR12 < VAR5)\nreturn -VAR13;\nVAR65.VAR14 = 0;\nif (!FUN22(VAR4->VAR22->VAR82))\nVAR82 = true;\nelse if (FUN23(VAR4->VAR22->VAR84))\nreturn -VAR85;\nVAR27 = FUN24(VAR4->VAR22,\nVAR86,\n&VAR80.VAR71, VAR82);\nif (VAR27)\nreturn VAR27;\nFUN25(!VAR80.VAR71); \nif (VAR65.VAR12 < sizeof(VAR65) + (VAR80.VAR71 * sizeof(*VAR81))) {\nVAR27 = -VAR87;\nVAR65.VAR55 = VAR80.VAR71;\ngoto VAR88;\n}\nVAR81 = FUN26(VAR80.VAR71, sizeof(*VAR81), VAR89);\nif (!VAR81)\nreturn -VAR90;\nVAR80.VAR81 = VAR81;\nVAR27 = FUN24(VAR4->VAR22,\nVAR91,\n&VAR80, VAR82);\nif (!VAR27)\nVAR65.VAR55 = VAR80.VAR92;\nVAR88:\nif (FUN4((void VAR10 *)VAR3, &VAR65, VAR5))\nVAR27 = -VAR11;\nif (!VAR27) {\nif (FUN4((void VAR10 *)(VAR3 + VAR5), VAR81,\nVAR65.VAR55 * sizeof(*VAR81)))\nVAR27 = -VAR11;\n}\nFUN12(VAR81);\nreturn VAR27;\n} else if (VAR2 == VAR93) {\nstruct vfio_pci_hot_reset VAR65;\nint32_t *VAR94;\nstruct vfio_pci_group_entry *VAR95;\nstruct vfio_pci_group_info VAR7;\nbool VAR82 = false;\nint VAR26, VAR55 = 0, VAR27 = 0;\nVAR5 = FUN2(struct VAR96, VAR55);\nif (FUN3(&VAR65, (void VAR10 *)VAR3, VAR5))\nreturn -VAR11;\nif (VAR65.VAR12 < VAR5 || VAR65.VAR14)\nreturn -VAR13;\nif (!FUN22(VAR4->VAR22->VAR82))\nVAR82 = true;\nelse if (FUN23(VAR4->VAR22->VAR84))\nreturn -VAR85;\nVAR27 = FUN24(VAR4->VAR22,\nVAR86,\n&VAR55, VAR82);\nif (VAR27)\nreturn VAR27;\nif (!VAR65.VAR55 || VAR65.VAR55 > VAR55)\nreturn -VAR13;\nVAR94 = FUN26(VAR65.VAR55, sizeof(*VAR94), VAR89);\nVAR95 = FUN26(VAR65.VAR55, sizeof(*VAR95), VAR89);\nif (!VAR94 || !VAR95) {\nFUN12(VAR94);\nFUN12(VAR95);\nreturn -VAR90;\n}\nif (FUN3(VAR94, (void VAR10 *)(VAR3 + VAR5),\nVAR65.VAR55 * sizeof(*VAR94))) {\nFUN12(VAR94);\nFUN12(VAR95);\nreturn -VAR11;\n}\nfor (VAR26 = 0; VAR26 < VAR65.VAR55; VAR26++) {\nstruct vfio_group *VAR97;\nstruct fd VAR98 = FUN27(VAR94[VAR26]);\nif (!VAR98.VAR99) {\nVAR27 = -VAR100;\nbreak;\n}\nVAR97 = FUN28(VAR98.VAR99);\nFUN29(VAR98);\nif (FUN16(VAR97)) {\nVAR27 = FUN17(VAR97);\nbreak;\n}\nVAR95[VAR26].VAR97 = VAR97;\nVAR95[VAR26].VAR101 = FUN30(VAR97);\n}\nFUN12(VAR94);\nif (VAR27)\ngoto VAR102;\nVAR7.VAR55 = VAR65.VAR55;\nVAR7.VAR95 = VAR95;\nVAR27 = FUN24(VAR4->VAR22,\nVAR103,\n&VAR7, VAR82);\nif (!VAR27)\nVAR27 = VAR82 ? FUN31(VAR4->VAR22->VAR82) :\nFUN32(VAR4->VAR22->VAR84);\nVAR102:\nfor (VAR26--; VAR26 >= 0; VAR26--)\nFUN33(VAR95[VAR26].VAR97);\nFUN12(VAR95);\nreturn VAR27;\n}\nreturn -VAR104;\n}\n",
      "code_after_change_raw": "static long vfio_pci_ioctl(void *device_data,\nunsigned int cmd, unsigned long arg)\n{\nstruct vfio_pci_device *vdev = device_data;\nunsigned long minsz;\nif (cmd == VFIO_DEVICE_GET_INFO) {\nstruct vfio_device_info info;\nminsz = offsetofend(struct vfio_device_info, num_irqs);\nif (copy_from_user(&info, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (info.argsz < minsz)\nreturn -EINVAL;\ninfo.flags = VFIO_DEVICE_FLAGS_PCI;\nif (vdev->reset_works)\ninfo.flags |= VFIO_DEVICE_FLAGS_RESET;\ninfo.num_regions = VFIO_PCI_NUM_REGIONS + vdev->num_regions;\ninfo.num_irqs = VFIO_PCI_NUM_IRQS;\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\n-EFAULT : 0;\n} else if (cmd == VFIO_DEVICE_GET_REGION_INFO) {\nstruct pci_dev *pdev = vdev->pdev;\nstruct vfio_region_info info;\nstruct vfio_info_cap caps = { .buf = NULL, .size = 0 };\nint i, ret;\nminsz = offsetofend(struct vfio_region_info, offset);\nif (copy_from_user(&info, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (info.argsz < minsz)\nreturn -EINVAL;\nswitch (info.index) {\ncase VFIO_PCI_CONFIG_REGION_INDEX:\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = pdev->cfg_size;\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\nVFIO_REGION_INFO_FLAG_WRITE;\nbreak;\ncase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = pci_resource_len(pdev, info.index);\nif (!info.size) {\ninfo.flags = 0;\nbreak;\n}\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\nVFIO_REGION_INFO_FLAG_WRITE;\nif (vdev->bar_mmap_supported[info.index]) {\ninfo.flags |= VFIO_REGION_INFO_FLAG_MMAP;\nif (info.index == vdev->msix_bar) {\nret = msix_sparse_mmap_cap(vdev, &caps);\nif (ret)\nreturn ret;\n}\n}\nbreak;\ncase VFIO_PCI_ROM_REGION_INDEX:\n{\nvoid __iomem *io;\nsize_t size;\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.flags = 0;\ninfo.size = pci_resource_len(pdev, info.index);\nif (!info.size) {\nif (pdev->resource[PCI_ROM_RESOURCE].flags &\nIORESOURCE_ROM_SHADOW)\ninfo.size = 0x20000;\nelse\nbreak;\n}\nio = pci_map_rom(pdev, &size);\nif (!io || !size) {\ninfo.size = 0;\nbreak;\n}\npci_unmap_rom(pdev, io);\ninfo.flags = VFIO_REGION_INFO_FLAG_READ;\nbreak;\n}\ncase VFIO_PCI_VGA_REGION_INDEX:\nif (!vdev->has_vga)\nreturn -EINVAL;\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = 0xc0000;\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\nVFIO_REGION_INFO_FLAG_WRITE;\nbreak;\ndefault:\nif (info.index >=\nVFIO_PCI_NUM_REGIONS + vdev->num_regions)\nreturn -EINVAL;\ni = info.index - VFIO_PCI_NUM_REGIONS;\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = vdev->region[i].size;\ninfo.flags = vdev->region[i].flags;\nret = region_type_cap(vdev, &caps,\nvdev->region[i].type,\nvdev->region[i].subtype);\nif (ret)\nreturn ret;\n}\nif (caps.size) {\ninfo.flags |= VFIO_REGION_INFO_FLAG_CAPS;\nif (info.argsz < sizeof(info) + caps.size) {\ninfo.argsz = sizeof(info) + caps.size;\ninfo.cap_offset = 0;\n} else {\nvfio_info_cap_shift(&caps, sizeof(info));\nif (copy_to_user((void __user *)arg +\nsizeof(info), caps.buf,\ncaps.size)) {\nkfree(caps.buf);\nreturn -EFAULT;\n}\ninfo.cap_offset = sizeof(info);\n}\nkfree(caps.buf);\n}\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\n-EFAULT : 0;\n} else if (cmd == VFIO_DEVICE_GET_IRQ_INFO) {\nstruct vfio_irq_info info;\nminsz = offsetofend(struct vfio_irq_info, count);\nif (copy_from_user(&info, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (info.argsz < minsz || info.index >= VFIO_PCI_NUM_IRQS)\nreturn -EINVAL;\nswitch (info.index) {\ncase VFIO_PCI_INTX_IRQ_INDEX ... VFIO_PCI_MSIX_IRQ_INDEX:\ncase VFIO_PCI_REQ_IRQ_INDEX:\nbreak;\ncase VFIO_PCI_ERR_IRQ_INDEX:\nif (pci_is_pcie(vdev->pdev))\nbreak;\ndefault:\nreturn -EINVAL;\n}\ninfo.flags = VFIO_IRQ_INFO_EVENTFD;\ninfo.count = vfio_pci_get_irq_count(vdev, info.index);\nif (info.index == VFIO_PCI_INTX_IRQ_INDEX)\ninfo.flags |= (VFIO_IRQ_INFO_MASKABLE |\nVFIO_IRQ_INFO_AUTOMASKED);\nelse\ninfo.flags |= VFIO_IRQ_INFO_NORESIZE;\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\n-EFAULT : 0;\n} else if (cmd == VFIO_DEVICE_SET_IRQS) {\nstruct vfio_irq_set hdr;\nsize_t size;\nu8 *data = NULL;\nint max, ret = 0;\nminsz = offsetofend(struct vfio_irq_set, count);\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (hdr.argsz < minsz || hdr.index >= VFIO_PCI_NUM_IRQS ||\nhdr.count >= (U32_MAX - hdr.start) ||\nhdr.flags & ~(VFIO_IRQ_SET_DATA_TYPE_MASK |\nVFIO_IRQ_SET_ACTION_TYPE_MASK))\nreturn -EINVAL;\nmax = vfio_pci_get_irq_count(vdev, hdr.index);\nif (hdr.start >= max || hdr.start + hdr.count > max)\nreturn -EINVAL;\nswitch (hdr.flags & VFIO_IRQ_SET_DATA_TYPE_MASK) {\ncase VFIO_IRQ_SET_DATA_NONE:\nsize = 0;\nbreak;\ncase VFIO_IRQ_SET_DATA_BOOL:\nsize = sizeof(uint8_t);\nbreak;\ncase VFIO_IRQ_SET_DATA_EVENTFD:\nsize = sizeof(int32_t);\nbreak;\ndefault:\nreturn -EINVAL;\n}\nif (size) {\nif (hdr.argsz - minsz < hdr.count * size)\nreturn -EINVAL;\ndata = memdup_user((void __user *)(arg + minsz),\nhdr.count * size);\nif (IS_ERR(data))\nreturn PTR_ERR(data);\n}\nmutex_lock(&vdev->igate);\nret = vfio_pci_set_irqs_ioctl(vdev, hdr.flags, hdr.index,\nhdr.start, hdr.count, data);\nmutex_unlock(&vdev->igate);\nkfree(data);\nreturn ret;\n} else if (cmd == VFIO_DEVICE_RESET) {\nreturn vdev->reset_works ?\npci_try_reset_function(vdev->pdev) : -EINVAL;\n} else if (cmd == VFIO_DEVICE_GET_PCI_HOT_RESET_INFO) {\nstruct vfio_pci_hot_reset_info hdr;\nstruct vfio_pci_fill_info fill = { 0 };\nstruct vfio_pci_dependent_device *devices = NULL;\nbool slot = false;\nint ret = 0;\nminsz = offsetofend(struct vfio_pci_hot_reset_info, count);\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (hdr.argsz < minsz)\nreturn -EINVAL;\nhdr.flags = 0;\nif (!pci_probe_reset_slot(vdev->pdev->slot))\nslot = true;\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\nreturn -ENODEV;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_count_devs,\n&fill.max, slot);\nif (ret)\nreturn ret;\nWARN_ON(!fill.max); \nif (hdr.argsz < sizeof(hdr) + (fill.max * sizeof(*devices))) {\nret = -ENOSPC;\nhdr.count = fill.max;\ngoto reset_info_exit;\n}\ndevices = kcalloc(fill.max, sizeof(*devices), GFP_KERNEL);\nif (!devices)\nreturn -ENOMEM;\nfill.devices = devices;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_fill_devs,\n&fill, slot);\nif (!ret)\nhdr.count = fill.cur;\nreset_info_exit:\nif (copy_to_user((void __user *)arg, &hdr, minsz))\nret = -EFAULT;\nif (!ret) {\nif (copy_to_user((void __user *)(arg + minsz), devices,\nhdr.count * sizeof(*devices)))\nret = -EFAULT;\n}\nkfree(devices);\nreturn ret;\n} else if (cmd == VFIO_DEVICE_PCI_HOT_RESET) {\nstruct vfio_pci_hot_reset hdr;\nint32_t *group_fds;\nstruct vfio_pci_group_entry *groups;\nstruct vfio_pci_group_info info;\nbool slot = false;\nint i, count = 0, ret = 0;\nminsz = offsetofend(struct vfio_pci_hot_reset, count);\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (hdr.argsz < minsz || hdr.flags)\nreturn -EINVAL;\nif (!pci_probe_reset_slot(vdev->pdev->slot))\nslot = true;\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\nreturn -ENODEV;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_count_devs,\n&count, slot);\nif (ret)\nreturn ret;\nif (!hdr.count || hdr.count > count)\nreturn -EINVAL;\ngroup_fds = kcalloc(hdr.count, sizeof(*group_fds), GFP_KERNEL);\ngroups = kcalloc(hdr.count, sizeof(*groups), GFP_KERNEL);\nif (!group_fds || !groups) {\nkfree(group_fds);\nkfree(groups);\nreturn -ENOMEM;\n}\nif (copy_from_user(group_fds, (void __user *)(arg + minsz),\nhdr.count * sizeof(*group_fds))) {\nkfree(group_fds);\nkfree(groups);\nreturn -EFAULT;\n}\nfor (i = 0; i < hdr.count; i++) {\nstruct vfio_group *group;\nstruct fd f = fdget(group_fds[i]);\nif (!f.file) {\nret = -EBADF;\nbreak;\n}\ngroup = vfio_group_get_external_user(f.file);\nfdput(f);\nif (IS_ERR(group)) {\nret = PTR_ERR(group);\nbreak;\n}\ngroups[i].group = group;\ngroups[i].id = vfio_external_user_iommu_id(group);\n}\nkfree(group_fds);\nif (ret)\ngoto hot_reset_release;\ninfo.count = hdr.count;\ninfo.groups = groups;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_validate_devs,\n&info, slot);\nif (!ret)\nret = slot ? pci_try_reset_slot(vdev->pdev->slot) :\npci_try_reset_bus(vdev->pdev->bus);\nhot_reset_release:\nfor (i--; i >= 0; i--)\nvfio_group_put_external_user(groups[i].group);\nkfree(groups);\nreturn ret;\n}\nreturn -ENOTTY;\n}\n",
      "code_before_change_raw": "static long vfio_pci_ioctl(void *device_data,\nunsigned int cmd, unsigned long arg)\n{\nstruct vfio_pci_device *vdev = device_data;\nunsigned long minsz;\nif (cmd == VFIO_DEVICE_GET_INFO) {\nstruct vfio_device_info info;\nminsz = offsetofend(struct vfio_device_info, num_irqs);\nif (copy_from_user(&info, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (info.argsz < minsz)\nreturn -EINVAL;\ninfo.flags = VFIO_DEVICE_FLAGS_PCI;\nif (vdev->reset_works)\ninfo.flags |= VFIO_DEVICE_FLAGS_RESET;\ninfo.num_regions = VFIO_PCI_NUM_REGIONS + vdev->num_regions;\ninfo.num_irqs = VFIO_PCI_NUM_IRQS;\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\n-EFAULT : 0;\n} else if (cmd == VFIO_DEVICE_GET_REGION_INFO) {\nstruct pci_dev *pdev = vdev->pdev;\nstruct vfio_region_info info;\nstruct vfio_info_cap caps = { .buf = NULL, .size = 0 };\nint i, ret;\nminsz = offsetofend(struct vfio_region_info, offset);\nif (copy_from_user(&info, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (info.argsz < minsz)\nreturn -EINVAL;\nswitch (info.index) {\ncase VFIO_PCI_CONFIG_REGION_INDEX:\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = pdev->cfg_size;\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\nVFIO_REGION_INFO_FLAG_WRITE;\nbreak;\ncase VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = pci_resource_len(pdev, info.index);\nif (!info.size) {\ninfo.flags = 0;\nbreak;\n}\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\nVFIO_REGION_INFO_FLAG_WRITE;\nif (vdev->bar_mmap_supported[info.index]) {\ninfo.flags |= VFIO_REGION_INFO_FLAG_MMAP;\nif (info.index == vdev->msix_bar) {\nret = msix_sparse_mmap_cap(vdev, &caps);\nif (ret)\nreturn ret;\n}\n}\nbreak;\ncase VFIO_PCI_ROM_REGION_INDEX:\n{\nvoid __iomem *io;\nsize_t size;\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.flags = 0;\ninfo.size = pci_resource_len(pdev, info.index);\nif (!info.size) {\nif (pdev->resource[PCI_ROM_RESOURCE].flags &\nIORESOURCE_ROM_SHADOW)\ninfo.size = 0x20000;\nelse\nbreak;\n}\nio = pci_map_rom(pdev, &size);\nif (!io || !size) {\ninfo.size = 0;\nbreak;\n}\npci_unmap_rom(pdev, io);\ninfo.flags = VFIO_REGION_INFO_FLAG_READ;\nbreak;\n}\ncase VFIO_PCI_VGA_REGION_INDEX:\nif (!vdev->has_vga)\nreturn -EINVAL;\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = 0xc0000;\ninfo.flags = VFIO_REGION_INFO_FLAG_READ |\nVFIO_REGION_INFO_FLAG_WRITE;\nbreak;\ndefault:\nif (info.index >=\nVFIO_PCI_NUM_REGIONS + vdev->num_regions)\nreturn -EINVAL;\ni = info.index - VFIO_PCI_NUM_REGIONS;\ninfo.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);\ninfo.size = vdev->region[i].size;\ninfo.flags = vdev->region[i].flags;\nret = region_type_cap(vdev, &caps,\nvdev->region[i].type,\nvdev->region[i].subtype);\nif (ret)\nreturn ret;\n}\nif (caps.size) {\ninfo.flags |= VFIO_REGION_INFO_FLAG_CAPS;\nif (info.argsz < sizeof(info) + caps.size) {\ninfo.argsz = sizeof(info) + caps.size;\ninfo.cap_offset = 0;\n} else {\nvfio_info_cap_shift(&caps, sizeof(info));\nif (copy_to_user((void __user *)arg +\nsizeof(info), caps.buf,\ncaps.size)) {\nkfree(caps.buf);\nreturn -EFAULT;\n}\ninfo.cap_offset = sizeof(info);\n}\nkfree(caps.buf);\n}\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\n-EFAULT : 0;\n} else if (cmd == VFIO_DEVICE_GET_IRQ_INFO) {\nstruct vfio_irq_info info;\nminsz = offsetofend(struct vfio_irq_info, count);\nif (copy_from_user(&info, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (info.argsz < minsz || info.index >= VFIO_PCI_NUM_IRQS)\nreturn -EINVAL;\nswitch (info.index) {\ncase VFIO_PCI_INTX_IRQ_INDEX ... VFIO_PCI_MSIX_IRQ_INDEX:\ncase VFIO_PCI_REQ_IRQ_INDEX:\nbreak;\ncase VFIO_PCI_ERR_IRQ_INDEX:\nif (pci_is_pcie(vdev->pdev))\nbreak;\ndefault:\nreturn -EINVAL;\n}\ninfo.flags = VFIO_IRQ_INFO_EVENTFD;\ninfo.count = vfio_pci_get_irq_count(vdev, info.index);\nif (info.index == VFIO_PCI_INTX_IRQ_INDEX)\ninfo.flags |= (VFIO_IRQ_INFO_MASKABLE |\nVFIO_IRQ_INFO_AUTOMASKED);\nelse\ninfo.flags |= VFIO_IRQ_INFO_NORESIZE;\nreturn copy_to_user((void __user *)arg, &info, minsz) ?\n-EFAULT : 0;\n} else if (cmd == VFIO_DEVICE_SET_IRQS) {\nstruct vfio_irq_set hdr;\nu8 *data = NULL;\nint ret = 0;\nminsz = offsetofend(struct vfio_irq_set, count);\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (hdr.argsz < minsz || hdr.index >= VFIO_PCI_NUM_IRQS ||\nhdr.flags & ~(VFIO_IRQ_SET_DATA_TYPE_MASK |\nVFIO_IRQ_SET_ACTION_TYPE_MASK))\nreturn -EINVAL;\nif (!(hdr.flags & VFIO_IRQ_SET_DATA_NONE)) {\nsize_t size;\nint max = vfio_pci_get_irq_count(vdev, hdr.index);\nif (hdr.flags & VFIO_IRQ_SET_DATA_BOOL)\nsize = sizeof(uint8_t);\nelse if (hdr.flags & VFIO_IRQ_SET_DATA_EVENTFD)\nsize = sizeof(int32_t);\nelse\nreturn -EINVAL;\nif (hdr.argsz - minsz < hdr.count * size ||\nhdr.start >= max || hdr.start + hdr.count > max)\nreturn -EINVAL;\ndata = memdup_user((void __user *)(arg + minsz),\nhdr.count * size);\nif (IS_ERR(data))\nreturn PTR_ERR(data);\n}\nmutex_lock(&vdev->igate);\nret = vfio_pci_set_irqs_ioctl(vdev, hdr.flags, hdr.index,\nhdr.start, hdr.count, data);\nmutex_unlock(&vdev->igate);\nkfree(data);\nreturn ret;\n} else if (cmd == VFIO_DEVICE_RESET) {\nreturn vdev->reset_works ?\npci_try_reset_function(vdev->pdev) : -EINVAL;\n} else if (cmd == VFIO_DEVICE_GET_PCI_HOT_RESET_INFO) {\nstruct vfio_pci_hot_reset_info hdr;\nstruct vfio_pci_fill_info fill = { 0 };\nstruct vfio_pci_dependent_device *devices = NULL;\nbool slot = false;\nint ret = 0;\nminsz = offsetofend(struct vfio_pci_hot_reset_info, count);\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (hdr.argsz < minsz)\nreturn -EINVAL;\nhdr.flags = 0;\nif (!pci_probe_reset_slot(vdev->pdev->slot))\nslot = true;\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\nreturn -ENODEV;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_count_devs,\n&fill.max, slot);\nif (ret)\nreturn ret;\nWARN_ON(!fill.max); \nif (hdr.argsz < sizeof(hdr) + (fill.max * sizeof(*devices))) {\nret = -ENOSPC;\nhdr.count = fill.max;\ngoto reset_info_exit;\n}\ndevices = kcalloc(fill.max, sizeof(*devices), GFP_KERNEL);\nif (!devices)\nreturn -ENOMEM;\nfill.devices = devices;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_fill_devs,\n&fill, slot);\nif (!ret)\nhdr.count = fill.cur;\nreset_info_exit:\nif (copy_to_user((void __user *)arg, &hdr, minsz))\nret = -EFAULT;\nif (!ret) {\nif (copy_to_user((void __user *)(arg + minsz), devices,\nhdr.count * sizeof(*devices)))\nret = -EFAULT;\n}\nkfree(devices);\nreturn ret;\n} else if (cmd == VFIO_DEVICE_PCI_HOT_RESET) {\nstruct vfio_pci_hot_reset hdr;\nint32_t *group_fds;\nstruct vfio_pci_group_entry *groups;\nstruct vfio_pci_group_info info;\nbool slot = false;\nint i, count = 0, ret = 0;\nminsz = offsetofend(struct vfio_pci_hot_reset, count);\nif (copy_from_user(&hdr, (void __user *)arg, minsz))\nreturn -EFAULT;\nif (hdr.argsz < minsz || hdr.flags)\nreturn -EINVAL;\nif (!pci_probe_reset_slot(vdev->pdev->slot))\nslot = true;\nelse if (pci_probe_reset_bus(vdev->pdev->bus))\nreturn -ENODEV;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_count_devs,\n&count, slot);\nif (ret)\nreturn ret;\nif (!hdr.count || hdr.count > count)\nreturn -EINVAL;\ngroup_fds = kcalloc(hdr.count, sizeof(*group_fds), GFP_KERNEL);\ngroups = kcalloc(hdr.count, sizeof(*groups), GFP_KERNEL);\nif (!group_fds || !groups) {\nkfree(group_fds);\nkfree(groups);\nreturn -ENOMEM;\n}\nif (copy_from_user(group_fds, (void __user *)(arg + minsz),\nhdr.count * sizeof(*group_fds))) {\nkfree(group_fds);\nkfree(groups);\nreturn -EFAULT;\n}\nfor (i = 0; i < hdr.count; i++) {\nstruct vfio_group *group;\nstruct fd f = fdget(group_fds[i]);\nif (!f.file) {\nret = -EBADF;\nbreak;\n}\ngroup = vfio_group_get_external_user(f.file);\nfdput(f);\nif (IS_ERR(group)) {\nret = PTR_ERR(group);\nbreak;\n}\ngroups[i].group = group;\ngroups[i].id = vfio_external_user_iommu_id(group);\n}\nkfree(group_fds);\nif (ret)\ngoto hot_reset_release;\ninfo.count = hdr.count;\ninfo.groups = groups;\nret = vfio_pci_for_each_slot_or_bus(vdev->pdev,\nvfio_pci_validate_devs,\n&info, slot);\nif (!ret)\nret = slot ? pci_try_reset_slot(vdev->pdev->slot) :\npci_try_reset_bus(vdev->pdev->bus);\nhot_reset_release:\nfor (i--; i >= 0; i--)\nvfio_group_put_external_user(groups[i].group);\nkfree(groups);\nreturn ret;\n}\nreturn -ENOTTY;\n}\n"
    }
  ],
  "CVE-2016-9793": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Mishandling of negative values for sk_sndbuf and sk_rcvbuf in the sock_setsockopt function.",
        "trigger_condition": "Local users leveraging the CAP_NET_ADMIN capability with a crafted setsockopt system call using the SO_SNDBUFFORCE or SO_RCVBUFFORCE option.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly handle negative values for sk_sndbuf and sk_rcvbuf, leading to memory corruption and system crash vulnerabilities when certain setsockopt options are used."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that sk_sndbuf and sk_rcvbuf cannot hold negative values. This can be achieved by changing the data type of these variables from int to unsigned int in the sock_setsockopt function. By making this modification, the code prevents mishandling of negative values and enhances system stability and security.",
      "GPT_analysis": "The modification is necessary to address a vulnerability (CVE-2016-9793) in the Linux kernel before version 4.8.14. The vulnerability arises from mishandling negative values of sk_sndbuf and sk_rcvbuf in the sock_setsockopt function. This vulnerability allows local users to cause a denial of service (memory corruption and system crash) or potentially have other unspecified impacts by exploiting the CAP_NET_ADMIN capability with a crafted setsockopt system call using the SO_SNDBUFFORCE or SO_RCVBUFFORCE option.\n\nThe modification involves changing the data type of the variables sk_sndbuf and sk_rcvbuf from int to unsigned int to prevent negative values from being mishandled. By ensuring that these variables cannot hold negative values, the vulnerability can be mitigated, and the system's stability and security can be improved.",
      "GPT_purpose": "Set socket options for a given socket.",
      "GPT_function": "\n1. Setting socket options based on the provided parameters.\n2. Handling various socket options such as SO_REUSEADDR, SO_REUSEPORT, SO_SNDBUF, SO_RCVBUF, SO_KEEPALIVE, SO_PRIORITY, SO_LINGER, and others.\n3. Checking for capabilities like CAP_NET_ADMIN before allowing certain socket options to be set.\n4. Handling different cases for setting socket options and returning appropriate error codes if needed.",
      "CVE_id": "CVE-2016-9793",
      "code_before_change": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_setbindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_REUSEPORT:\n\t\tsk->sk_reuseport = valbool;\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check_tx = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) ||\n\t\t    ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (val & SOF_TIMESTAMPING_OPT_ID &&\n\t\t    !(sk->sk_tsflags & SOF_TIMESTAMPING_OPT_ID)) {\n\t\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t\t    sk->sk_type == SOCK_STREAM) {\n\t\t\t\tif ((1 << sk->sk_state) &\n\t\t\t\t    (TCPF_CLOSE | TCPF_LISTEN)) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsk->sk_tskey = tcp_sk(sk)->snd_una;\n\t\t\t} else {\n\t\t\t\tsk->sk_tskey = 0;\n\t\t\t}\n\t\t}\n\t\tsk->sk_tsflags = val;\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_BPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_CBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_EBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_LOCK_FILTER:\n\t\tif (sock_flag(sk, SOCK_FILTER_LOCKED) && !valbool)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_FILTER_LOCKED, valbool);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tret = sock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tcase SO_SELECT_ERR_QUEUE:\n\t\tsock_valbool_flag(sk, SOCK_SELECT_ERR_QUEUE, valbool);\n\t\tbreak;\n\n#ifdef CONFIG_NET_RX_BUSY_POLL\n\tcase SO_BUSY_POLL:\n\t\t/* allow unprivileged users to decrease the value */\n\t\tif ((val > sk->sk_ll_usec) && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse {\n\t\t\tif (val < 0)\n\t\t\t\tret = -EINVAL;\n\t\t\telse\n\t\t\t\tsk->sk_ll_usec = val;\n\t\t}\n\t\tbreak;\n#endif\n\n\tcase SO_MAX_PACING_RATE:\n\t\tsk->sk_max_pacing_rate = val;\n\t\tsk->sk_pacing_rate = min(sk->sk_pacing_rate,\n\t\t\t\t\t sk->sk_max_pacing_rate);\n\t\tbreak;\n\n\tcase SO_INCOMING_CPU:\n\t\tsk->sk_incoming_cpu = val;\n\t\tbreak;\n\n\tcase SO_CNX_ADVICE:\n\t\tif (val == 1)\n\t\t\tdst_negative_advice(sk);\n\t\tbreak;\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
      "code_after_change": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_setbindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_REUSEPORT:\n\t\tsk->sk_reuseport = valbool;\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(int, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(int, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check_tx = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) ||\n\t\t    ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (val & SOF_TIMESTAMPING_OPT_ID &&\n\t\t    !(sk->sk_tsflags & SOF_TIMESTAMPING_OPT_ID)) {\n\t\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t\t    sk->sk_type == SOCK_STREAM) {\n\t\t\t\tif ((1 << sk->sk_state) &\n\t\t\t\t    (TCPF_CLOSE | TCPF_LISTEN)) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsk->sk_tskey = tcp_sk(sk)->snd_una;\n\t\t\t} else {\n\t\t\t\tsk->sk_tskey = 0;\n\t\t\t}\n\t\t}\n\t\tsk->sk_tsflags = val;\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_BPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_CBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_EBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_LOCK_FILTER:\n\t\tif (sock_flag(sk, SOCK_FILTER_LOCKED) && !valbool)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_FILTER_LOCKED, valbool);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tret = sock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tcase SO_SELECT_ERR_QUEUE:\n\t\tsock_valbool_flag(sk, SOCK_SELECT_ERR_QUEUE, valbool);\n\t\tbreak;\n\n#ifdef CONFIG_NET_RX_BUSY_POLL\n\tcase SO_BUSY_POLL:\n\t\t/* allow unprivileged users to decrease the value */\n\t\tif ((val > sk->sk_ll_usec) && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse {\n\t\t\tif (val < 0)\n\t\t\t\tret = -EINVAL;\n\t\t\telse\n\t\t\t\tsk->sk_ll_usec = val;\n\t\t}\n\t\tbreak;\n#endif\n\n\tcase SO_MAX_PACING_RATE:\n\t\tsk->sk_max_pacing_rate = val;\n\t\tsk->sk_pacing_rate = min(sk->sk_pacing_rate,\n\t\t\t\t\t sk->sk_max_pacing_rate);\n\t\tbreak;\n\n\tcase SO_INCOMING_CPU:\n\t\tsk->sk_incoming_cpu = val;\n\t\tbreak;\n\n\tcase SO_CNX_ADVICE:\n\t\tif (val == 1)\n\t\t\tdst_negative_advice(sk);\n\t\tbreak;\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\t\tsk->sk_sndbuf = max_t(int, val * 2, SOCK_MIN_SNDBUF);",
          "\t\tsk->sk_rcvbuf = max_t(int, val * 2, SOCK_MIN_RCVBUF);"
        ],
        "deleted": [
          "\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);",
          "\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);"
        ]
      },
      "preconditions_for_vulnerability": "Mishandling of negative values for sk_sndbuf and sk_rcvbuf in the sock_setsockopt function.",
      "trigger_condition": "Local users leveraging the CAP_NET_ADMIN capability with a crafted setsockopt system call using the SO_SNDBUFFORCE or SO_RCVBUFFORCE option.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly handle negative values for sk_sndbuf and sk_rcvbuf, leading to memory corruption and system crash vulnerabilities when certain setsockopt options are used.",
      "id": 100,
      "code_after_change_normalized": "int FUN1(struct socket *VAR1, int VAR2, int VAR3,\nchar __user *VAR4, unsigned int VAR5)\n{\nstruct VAR1 *VAR6 = VAR1->VAR6;\nint VAR7;\nint VAR8;\nstruct linger VAR9;\nint VAR10 = 0;\nif (VAR3 == VAR11)\nreturn FUN2(VAR6, VAR4, VAR5);\nif (VAR5 < sizeof(int))\nreturn -VAR12;\nif (FUN3(VAR7, (int VAR13 *)VAR4))\nreturn -VAR14;\nVAR8 = VAR7 ? 1 : 0;\nFUN4(VAR6);\nswitch (VAR3) {\ncase VAR15:\nif (VAR7 && !FUN5(VAR16))\nVAR10 = -VAR17;\nelse\nFUN6(VAR6, VAR18, VAR8);\nbreak;\ncase VAR19:\nVAR6->VAR20 = (VAR8 ? VAR21 : VAR22);\nbreak;\ncase VAR23:\nVAR6->VAR24 = VAR8;\nbreak;\ncase VAR25:\ncase VAR26:\ncase VAR27:\ncase VAR28:\nVAR10 = -VAR29;\nbreak;\ncase VAR30:\nFUN6(VAR6, VAR31, VAR8);\nbreak;\ncase VAR32:\nFUN6(VAR6, VAR33, VAR8);\nbreak;\ncase VAR34:\nVAR7 = FUN7(VAR35, VAR7, VAR36);\nVAR37:\nVAR6->VAR38 |= VAR39;\nVAR6->VAR40 = FUN8(int, VAR7 * 2, VAR41);\nVAR6->FUN9(VAR6);\nbreak;\ncase VAR42:\nif (!FUN5(VAR16)) {\nVAR10 = -VAR43;\nbreak;\n}\ngoto VAR37;\ncase VAR44:\nVAR7 = FUN7(VAR35, VAR7, VAR45);\nVAR46:\nVAR6->VAR38 |= VAR47;\nVAR6->VAR48 = FUN8(int, VAR7 * 2, VAR49);\nbreak;\ncase VAR50:\nif (!FUN5(VAR16)) {\nVAR10 = -VAR43;\nbreak;\n}\ngoto VAR46;\ncase VAR51:\n#ifdef VAR52\nif (VAR6->VAR53 == VAR54 &&\nVAR6->VAR55 == VAR56)\nFUN10(VAR6, VAR8);\n#VAR57\nFUN6(VAR6, VAR58, VAR8);\nbreak;\ncase VAR59:\nFUN6(VAR6, VAR60, VAR8);\nbreak;\ncase VAR61:\nVAR6->VAR62 = VAR8;\nbreak;\ncase VAR63:\nif ((VAR7 >= 0 && VAR7 <= 6) ||\nFUN11(FUN12(VAR6)->VAR64, VAR16))\nVAR6->VAR65 = VAR7;\nelse\nVAR10 = -VAR43;\nbreak;\ncase VAR66:\nif (VAR5 < sizeof(VAR9)) {\nVAR10 = -VAR12;\t\nbreak;\n}\nif (FUN13(&VAR9, VAR4, sizeof(VAR9))) {\nVAR10 = -VAR14;\nbreak;\n}\nif (!VAR9.VAR67)\nFUN14(VAR6, VAR68);\nelse {\n#if (VAR69 == 32)\nif ((unsigned int)VAR9.VAR70 >= VAR71/VAR72)\nVAR6->VAR73 = VAR71;\nelse\n#VAR57\nVAR6->VAR73 = (unsigned int)VAR9.VAR70 * VAR72;\nFUN15(VAR6, VAR68);\n}\nbreak;\ncase VAR74:\nFUN16(\"STR\");\nbreak;\ncase VAR75:\nif (VAR8)\nFUN17(VAR76, &VAR1->VAR77);\nelse\nFUN18(VAR76, &VAR1->VAR77);\nbreak;\ncase VAR78:\ncase VAR79:\nif (VAR8)  {\nif (VAR3 == VAR78)\nFUN14(VAR6, VAR80);\nelse\nFUN15(VAR6, VAR80);\nFUN15(VAR6, VAR81);\nFUN19(VAR6, VAR82);\n} else {\nFUN14(VAR6, VAR81);\nFUN14(VAR6, VAR80);\n}\nbreak;\ncase VAR83:\nif (VAR7 & ~VAR84) {\nVAR10 = -VAR12;\nbreak;\n}\nif (VAR7 & VAR85 &&\n!(VAR6->VAR86 & VAR85)) {\nif (VAR6->VAR53 == VAR54 &&\nVAR6->VAR55 == VAR56) {\nif ((1 << VAR6->VAR87) &\n(VAR88 | VAR89)) {\nVAR10 = -VAR12;\nbreak;\n}\nVAR6->VAR90 = FUN20(VAR6)->VAR91;\n} else {\nVAR6->VAR90 = 0;\n}\n}\nVAR6->VAR86 = VAR7;\nif (VAR7 & VAR92)\nFUN19(VAR6,\nVAR93);\nelse\nFUN21(VAR6,\n(1UL << VAR93));\nbreak;\ncase VAR94:\nif (VAR7 < 0)\nVAR7 = VAR95;\nVAR6->VAR96 = VAR7 ? : 1;\nbreak;\ncase VAR97:\nVAR10 = FUN22(&VAR6->VAR98, VAR4, VAR5);\nbreak;\ncase VAR99:\nVAR10 = FUN22(&VAR6->VAR100, VAR4, VAR5);\nbreak;\ncase VAR101:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(struct VAR102)) {\nstruct sock_fprog VAR103;\nVAR10 = -VAR14;\nif (FUN13(&VAR103, VAR4, sizeof(VAR103)))\nbreak;\nVAR10 = FUN23(&VAR103, VAR6);\n}\nbreak;\ncase VAR104:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(VAR35)) {\nu32 VAR105;\nVAR10 = -VAR14;\nif (FUN13(&VAR105, VAR4, sizeof(VAR105)))\nbreak;\nVAR10 = FUN24(VAR105, VAR6);\n}\nbreak;\ncase VAR106:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(struct VAR102)) {\nstruct sock_fprog VAR103;\nVAR10 = -VAR14;\nif (FUN13(&VAR103, VAR4, sizeof(VAR103)))\nbreak;\nVAR10 = FUN25(&VAR103, VAR6);\n}\nbreak;\ncase VAR107:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(VAR35)) {\nu32 VAR105;\nVAR10 = -VAR14;\nif (FUN13(&VAR105, VAR4, sizeof(VAR105)))\nbreak;\nVAR10 = FUN26(VAR105, VAR6);\n}\nbreak;\ncase VAR108:\nVAR10 = FUN27(VAR6);\nbreak;\ncase VAR109:\nif (FUN28(VAR6, VAR110) && !VAR8)\nVAR10 = -VAR43;\nelse\nFUN6(VAR6, VAR110, VAR8);\nbreak;\ncase VAR111:\nif (VAR8)\nFUN17(VAR112, &VAR1->VAR77);\nelse\nFUN18(VAR112, &VAR1->VAR77);\nbreak;\ncase VAR113:\nif (!FUN11(FUN12(VAR6)->VAR64, VAR16))\nVAR10 = -VAR43;\nelse\nVAR6->VAR114 = VAR7;\nbreak;\ncase VAR115:\nFUN6(VAR6, VAR116, VAR8);\nbreak;\ncase VAR117:\nFUN6(VAR6, VAR118, VAR8);\nbreak;\ncase VAR119:\nif (VAR1->VAR120->VAR121)\nVAR10 = VAR1->VAR120->FUN29(VAR6, VAR7);\nelse\nVAR10 = -VAR122;\nbreak;\ncase VAR123:\nFUN6(VAR6, VAR124, VAR8);\nbreak;\ncase VAR125:\nFUN6(VAR6, VAR126, VAR8);\nbreak;\n#ifdef VAR127\ncase VAR128:\nif ((VAR7 > VAR6->VAR129) && !FUN5(VAR16))\nVAR10 = -VAR43;\nelse {\nif (VAR7 < 0)\nVAR10 = -VAR12;\nelse\nVAR6->VAR129 = VAR7;\n}\nbreak;\n#VAR57\ncase VAR130:\nVAR6->VAR131 = VAR7;\nVAR6->VAR132 = FUN30(VAR6->VAR132,\nVAR6->VAR131);\nbreak;\ncase VAR133:\nVAR6->VAR134 = VAR7;\nbreak;\ncase VAR135:\nif (VAR7 == 1)\nFUN31(VAR6);\nbreak;\ndefault:\nVAR10 = -VAR29;\nbreak;\n}\nFUN32(VAR6);\nreturn VAR10;\n}\n",
      "code_before_change_normalized": "int FUN1(struct socket *VAR1, int VAR2, int VAR3,\nchar __user *VAR4, unsigned int VAR5)\n{\nstruct VAR1 *VAR6 = VAR1->VAR6;\nint VAR7;\nint VAR8;\nstruct linger VAR9;\nint VAR10 = 0;\nif (VAR3 == VAR11)\nreturn FUN2(VAR6, VAR4, VAR5);\nif (VAR5 < sizeof(int))\nreturn -VAR12;\nif (FUN3(VAR7, (int VAR13 *)VAR4))\nreturn -VAR14;\nVAR8 = VAR7 ? 1 : 0;\nFUN4(VAR6);\nswitch (VAR3) {\ncase VAR15:\nif (VAR7 && !FUN5(VAR16))\nVAR10 = -VAR17;\nelse\nFUN6(VAR6, VAR18, VAR8);\nbreak;\ncase VAR19:\nVAR6->VAR20 = (VAR8 ? VAR21 : VAR22);\nbreak;\ncase VAR23:\nVAR6->VAR24 = VAR8;\nbreak;\ncase VAR25:\ncase VAR26:\ncase VAR27:\ncase VAR28:\nVAR10 = -VAR29;\nbreak;\ncase VAR30:\nFUN6(VAR6, VAR31, VAR8);\nbreak;\ncase VAR32:\nFUN6(VAR6, VAR33, VAR8);\nbreak;\ncase VAR34:\nVAR7 = FUN7(VAR35, VAR7, VAR36);\nVAR37:\nVAR6->VAR38 |= VAR39;\nVAR6->VAR40 = FUN8(VAR35, VAR7 * 2, VAR41);\nVAR6->FUN9(VAR6);\nbreak;\ncase VAR42:\nif (!FUN5(VAR16)) {\nVAR10 = -VAR43;\nbreak;\n}\ngoto VAR37;\ncase VAR44:\nVAR7 = FUN7(VAR35, VAR7, VAR45);\nVAR46:\nVAR6->VAR38 |= VAR47;\nVAR6->VAR48 = FUN8(VAR35, VAR7 * 2, VAR49);\nbreak;\ncase VAR50:\nif (!FUN5(VAR16)) {\nVAR10 = -VAR43;\nbreak;\n}\ngoto VAR46;\ncase VAR51:\n#ifdef VAR52\nif (VAR6->VAR53 == VAR54 &&\nVAR6->VAR55 == VAR56)\nFUN10(VAR6, VAR8);\n#VAR57\nFUN6(VAR6, VAR58, VAR8);\nbreak;\ncase VAR59:\nFUN6(VAR6, VAR60, VAR8);\nbreak;\ncase VAR61:\nVAR6->VAR62 = VAR8;\nbreak;\ncase VAR63:\nif ((VAR7 >= 0 && VAR7 <= 6) ||\nFUN11(FUN12(VAR6)->VAR64, VAR16))\nVAR6->VAR65 = VAR7;\nelse\nVAR10 = -VAR43;\nbreak;\ncase VAR66:\nif (VAR5 < sizeof(VAR9)) {\nVAR10 = -VAR12;\t\nbreak;\n}\nif (FUN13(&VAR9, VAR4, sizeof(VAR9))) {\nVAR10 = -VAR14;\nbreak;\n}\nif (!VAR9.VAR67)\nFUN14(VAR6, VAR68);\nelse {\n#if (VAR69 == 32)\nif ((unsigned int)VAR9.VAR70 >= VAR71/VAR72)\nVAR6->VAR73 = VAR71;\nelse\n#VAR57\nVAR6->VAR73 = (unsigned int)VAR9.VAR70 * VAR72;\nFUN15(VAR6, VAR68);\n}\nbreak;\ncase VAR74:\nFUN16(\"STR\");\nbreak;\ncase VAR75:\nif (VAR8)\nFUN17(VAR76, &VAR1->VAR77);\nelse\nFUN18(VAR76, &VAR1->VAR77);\nbreak;\ncase VAR78:\ncase VAR79:\nif (VAR8)  {\nif (VAR3 == VAR78)\nFUN14(VAR6, VAR80);\nelse\nFUN15(VAR6, VAR80);\nFUN15(VAR6, VAR81);\nFUN19(VAR6, VAR82);\n} else {\nFUN14(VAR6, VAR81);\nFUN14(VAR6, VAR80);\n}\nbreak;\ncase VAR83:\nif (VAR7 & ~VAR84) {\nVAR10 = -VAR12;\nbreak;\n}\nif (VAR7 & VAR85 &&\n!(VAR6->VAR86 & VAR85)) {\nif (VAR6->VAR53 == VAR54 &&\nVAR6->VAR55 == VAR56) {\nif ((1 << VAR6->VAR87) &\n(VAR88 | VAR89)) {\nVAR10 = -VAR12;\nbreak;\n}\nVAR6->VAR90 = FUN20(VAR6)->VAR91;\n} else {\nVAR6->VAR90 = 0;\n}\n}\nVAR6->VAR86 = VAR7;\nif (VAR7 & VAR92)\nFUN19(VAR6,\nVAR93);\nelse\nFUN21(VAR6,\n(1UL << VAR93));\nbreak;\ncase VAR94:\nif (VAR7 < 0)\nVAR7 = VAR95;\nVAR6->VAR96 = VAR7 ? : 1;\nbreak;\ncase VAR97:\nVAR10 = FUN22(&VAR6->VAR98, VAR4, VAR5);\nbreak;\ncase VAR99:\nVAR10 = FUN22(&VAR6->VAR100, VAR4, VAR5);\nbreak;\ncase VAR101:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(struct VAR102)) {\nstruct sock_fprog VAR103;\nVAR10 = -VAR14;\nif (FUN13(&VAR103, VAR4, sizeof(VAR103)))\nbreak;\nVAR10 = FUN23(&VAR103, VAR6);\n}\nbreak;\ncase VAR104:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(VAR35)) {\nu32 VAR105;\nVAR10 = -VAR14;\nif (FUN13(&VAR105, VAR4, sizeof(VAR105)))\nbreak;\nVAR10 = FUN24(VAR105, VAR6);\n}\nbreak;\ncase VAR106:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(struct VAR102)) {\nstruct sock_fprog VAR103;\nVAR10 = -VAR14;\nif (FUN13(&VAR103, VAR4, sizeof(VAR103)))\nbreak;\nVAR10 = FUN25(&VAR103, VAR6);\n}\nbreak;\ncase VAR107:\nVAR10 = -VAR12;\nif (VAR5 == sizeof(VAR35)) {\nu32 VAR105;\nVAR10 = -VAR14;\nif (FUN13(&VAR105, VAR4, sizeof(VAR105)))\nbreak;\nVAR10 = FUN26(VAR105, VAR6);\n}\nbreak;\ncase VAR108:\nVAR10 = FUN27(VAR6);\nbreak;\ncase VAR109:\nif (FUN28(VAR6, VAR110) && !VAR8)\nVAR10 = -VAR43;\nelse\nFUN6(VAR6, VAR110, VAR8);\nbreak;\ncase VAR111:\nif (VAR8)\nFUN17(VAR112, &VAR1->VAR77);\nelse\nFUN18(VAR112, &VAR1->VAR77);\nbreak;\ncase VAR113:\nif (!FUN11(FUN12(VAR6)->VAR64, VAR16))\nVAR10 = -VAR43;\nelse\nVAR6->VAR114 = VAR7;\nbreak;\ncase VAR115:\nFUN6(VAR6, VAR116, VAR8);\nbreak;\ncase VAR117:\nFUN6(VAR6, VAR118, VAR8);\nbreak;\ncase VAR119:\nif (VAR1->VAR120->VAR121)\nVAR10 = VAR1->VAR120->FUN29(VAR6, VAR7);\nelse\nVAR10 = -VAR122;\nbreak;\ncase VAR123:\nFUN6(VAR6, VAR124, VAR8);\nbreak;\ncase VAR125:\nFUN6(VAR6, VAR126, VAR8);\nbreak;\n#ifdef VAR127\ncase VAR128:\nif ((VAR7 > VAR6->VAR129) && !FUN5(VAR16))\nVAR10 = -VAR43;\nelse {\nif (VAR7 < 0)\nVAR10 = -VAR12;\nelse\nVAR6->VAR129 = VAR7;\n}\nbreak;\n#VAR57\ncase VAR130:\nVAR6->VAR131 = VAR7;\nVAR6->VAR132 = FUN30(VAR6->VAR132,\nVAR6->VAR131);\nbreak;\ncase VAR133:\nVAR6->VAR134 = VAR7;\nbreak;\ncase VAR135:\nif (VAR7 == 1)\nFUN31(VAR6);\nbreak;\ndefault:\nVAR10 = -VAR29;\nbreak;\n}\nFUN32(VAR6);\nreturn VAR10;\n}\n",
      "code_after_change_raw": "int sock_setsockopt(struct socket *sock, int level, int optname,\nchar __user *optval, unsigned int optlen)\n{\nstruct sock *sk = sock->sk;\nint val;\nint valbool;\nstruct linger ling;\nint ret = 0;\nif (optname == SO_BINDTODEVICE)\nreturn sock_setbindtodevice(sk, optval, optlen);\nif (optlen < sizeof(int))\nreturn -EINVAL;\nif (get_user(val, (int __user *)optval))\nreturn -EFAULT;\nvalbool = val ? 1 : 0;\nlock_sock(sk);\nswitch (optname) {\ncase SO_DEBUG:\nif (val && !capable(CAP_NET_ADMIN))\nret = -EACCES;\nelse\nsock_valbool_flag(sk, SOCK_DBG, valbool);\nbreak;\ncase SO_REUSEADDR:\nsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\nbreak;\ncase SO_REUSEPORT:\nsk->sk_reuseport = valbool;\nbreak;\ncase SO_TYPE:\ncase SO_PROTOCOL:\ncase SO_DOMAIN:\ncase SO_ERROR:\nret = -ENOPROTOOPT;\nbreak;\ncase SO_DONTROUTE:\nsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\nbreak;\ncase SO_BROADCAST:\nsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\nbreak;\ncase SO_SNDBUF:\nval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\nsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\nsk->sk_sndbuf = max_t(int, val * 2, SOCK_MIN_SNDBUF);\nsk->sk_write_space(sk);\nbreak;\ncase SO_SNDBUFFORCE:\nif (!capable(CAP_NET_ADMIN)) {\nret = -EPERM;\nbreak;\n}\ngoto set_sndbuf;\ncase SO_RCVBUF:\nval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\nsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\nsk->sk_rcvbuf = max_t(int, val * 2, SOCK_MIN_RCVBUF);\nbreak;\ncase SO_RCVBUFFORCE:\nif (!capable(CAP_NET_ADMIN)) {\nret = -EPERM;\nbreak;\n}\ngoto set_rcvbuf;\ncase SO_KEEPALIVE:\n#ifdef CONFIG_INET\nif (sk->sk_protocol == IPPROTO_TCP &&\nsk->sk_type == SOCK_STREAM)\ntcp_set_keepalive(sk, valbool);\n#endif\nsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\nbreak;\ncase SO_OOBINLINE:\nsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\nbreak;\ncase SO_NO_CHECK:\nsk->sk_no_check_tx = valbool;\nbreak;\ncase SO_PRIORITY:\nif ((val >= 0 && val <= 6) ||\nns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\nsk->sk_priority = val;\nelse\nret = -EPERM;\nbreak;\ncase SO_LINGER:\nif (optlen < sizeof(ling)) {\nret = -EINVAL;\t\nbreak;\n}\nif (copy_from_user(&ling, optval, sizeof(ling))) {\nret = -EFAULT;\nbreak;\n}\nif (!ling.l_onoff)\nsock_reset_flag(sk, SOCK_LINGER);\nelse {\n#if (BITS_PER_LONG == 32)\nif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\nsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\nelse\n#endif\nsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\nsock_set_flag(sk, SOCK_LINGER);\n}\nbreak;\ncase SO_BSDCOMPAT:\nsock_warn_obsolete_bsdism(\"setsockopt\");\nbreak;\ncase SO_PASSCRED:\nif (valbool)\nset_bit(SOCK_PASSCRED, &sock->flags);\nelse\nclear_bit(SOCK_PASSCRED, &sock->flags);\nbreak;\ncase SO_TIMESTAMP:\ncase SO_TIMESTAMPNS:\nif (valbool)  {\nif (optname == SO_TIMESTAMP)\nsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\nelse\nsock_set_flag(sk, SOCK_RCVTSTAMPNS);\nsock_set_flag(sk, SOCK_RCVTSTAMP);\nsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n} else {\nsock_reset_flag(sk, SOCK_RCVTSTAMP);\nsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n}\nbreak;\ncase SO_TIMESTAMPING:\nif (val & ~SOF_TIMESTAMPING_MASK) {\nret = -EINVAL;\nbreak;\n}\nif (val & SOF_TIMESTAMPING_OPT_ID &&\n!(sk->sk_tsflags & SOF_TIMESTAMPING_OPT_ID)) {\nif (sk->sk_protocol == IPPROTO_TCP &&\nsk->sk_type == SOCK_STREAM) {\nif ((1 << sk->sk_state) &\n(TCPF_CLOSE | TCPF_LISTEN)) {\nret = -EINVAL;\nbreak;\n}\nsk->sk_tskey = tcp_sk(sk)->snd_una;\n} else {\nsk->sk_tskey = 0;\n}\n}\nsk->sk_tsflags = val;\nif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\nsock_enable_timestamp(sk,\nSOCK_TIMESTAMPING_RX_SOFTWARE);\nelse\nsock_disable_timestamp(sk,\n(1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\nbreak;\ncase SO_RCVLOWAT:\nif (val < 0)\nval = INT_MAX;\nsk->sk_rcvlowat = val ? : 1;\nbreak;\ncase SO_RCVTIMEO:\nret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\nbreak;\ncase SO_SNDTIMEO:\nret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\nbreak;\ncase SO_ATTACH_FILTER:\nret = -EINVAL;\nif (optlen == sizeof(struct sock_fprog)) {\nstruct sock_fprog fprog;\nret = -EFAULT;\nif (copy_from_user(&fprog, optval, sizeof(fprog)))\nbreak;\nret = sk_attach_filter(&fprog, sk);\n}\nbreak;\ncase SO_ATTACH_BPF:\nret = -EINVAL;\nif (optlen == sizeof(u32)) {\nu32 ufd;\nret = -EFAULT;\nif (copy_from_user(&ufd, optval, sizeof(ufd)))\nbreak;\nret = sk_attach_bpf(ufd, sk);\n}\nbreak;\ncase SO_ATTACH_REUSEPORT_CBPF:\nret = -EINVAL;\nif (optlen == sizeof(struct sock_fprog)) {\nstruct sock_fprog fprog;\nret = -EFAULT;\nif (copy_from_user(&fprog, optval, sizeof(fprog)))\nbreak;\nret = sk_reuseport_attach_filter(&fprog, sk);\n}\nbreak;\ncase SO_ATTACH_REUSEPORT_EBPF:\nret = -EINVAL;\nif (optlen == sizeof(u32)) {\nu32 ufd;\nret = -EFAULT;\nif (copy_from_user(&ufd, optval, sizeof(ufd)))\nbreak;\nret = sk_reuseport_attach_bpf(ufd, sk);\n}\nbreak;\ncase SO_DETACH_FILTER:\nret = sk_detach_filter(sk);\nbreak;\ncase SO_LOCK_FILTER:\nif (sock_flag(sk, SOCK_FILTER_LOCKED) && !valbool)\nret = -EPERM;\nelse\nsock_valbool_flag(sk, SOCK_FILTER_LOCKED, valbool);\nbreak;\ncase SO_PASSSEC:\nif (valbool)\nset_bit(SOCK_PASSSEC, &sock->flags);\nelse\nclear_bit(SOCK_PASSSEC, &sock->flags);\nbreak;\ncase SO_MARK:\nif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\nret = -EPERM;\nelse\nsk->sk_mark = val;\nbreak;\ncase SO_RXQ_OVFL:\nsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\nbreak;\ncase SO_WIFI_STATUS:\nsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\nbreak;\ncase SO_PEEK_OFF:\nif (sock->ops->set_peek_off)\nret = sock->ops->set_peek_off(sk, val);\nelse\nret = -EOPNOTSUPP;\nbreak;\ncase SO_NOFCS:\nsock_valbool_flag(sk, SOCK_NOFCS, valbool);\nbreak;\ncase SO_SELECT_ERR_QUEUE:\nsock_valbool_flag(sk, SOCK_SELECT_ERR_QUEUE, valbool);\nbreak;\n#ifdef CONFIG_NET_RX_BUSY_POLL\ncase SO_BUSY_POLL:\nif ((val > sk->sk_ll_usec) && !capable(CAP_NET_ADMIN))\nret = -EPERM;\nelse {\nif (val < 0)\nret = -EINVAL;\nelse\nsk->sk_ll_usec = val;\n}\nbreak;\n#endif\ncase SO_MAX_PACING_RATE:\nsk->sk_max_pacing_rate = val;\nsk->sk_pacing_rate = min(sk->sk_pacing_rate,\nsk->sk_max_pacing_rate);\nbreak;\ncase SO_INCOMING_CPU:\nsk->sk_incoming_cpu = val;\nbreak;\ncase SO_CNX_ADVICE:\nif (val == 1)\ndst_negative_advice(sk);\nbreak;\ndefault:\nret = -ENOPROTOOPT;\nbreak;\n}\nrelease_sock(sk);\nreturn ret;\n}\n",
      "code_before_change_raw": "int sock_setsockopt(struct socket *sock, int level, int optname,\nchar __user *optval, unsigned int optlen)\n{\nstruct sock *sk = sock->sk;\nint val;\nint valbool;\nstruct linger ling;\nint ret = 0;\nif (optname == SO_BINDTODEVICE)\nreturn sock_setbindtodevice(sk, optval, optlen);\nif (optlen < sizeof(int))\nreturn -EINVAL;\nif (get_user(val, (int __user *)optval))\nreturn -EFAULT;\nvalbool = val ? 1 : 0;\nlock_sock(sk);\nswitch (optname) {\ncase SO_DEBUG:\nif (val && !capable(CAP_NET_ADMIN))\nret = -EACCES;\nelse\nsock_valbool_flag(sk, SOCK_DBG, valbool);\nbreak;\ncase SO_REUSEADDR:\nsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\nbreak;\ncase SO_REUSEPORT:\nsk->sk_reuseport = valbool;\nbreak;\ncase SO_TYPE:\ncase SO_PROTOCOL:\ncase SO_DOMAIN:\ncase SO_ERROR:\nret = -ENOPROTOOPT;\nbreak;\ncase SO_DONTROUTE:\nsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\nbreak;\ncase SO_BROADCAST:\nsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\nbreak;\ncase SO_SNDBUF:\nval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\nsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\nsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\nsk->sk_write_space(sk);\nbreak;\ncase SO_SNDBUFFORCE:\nif (!capable(CAP_NET_ADMIN)) {\nret = -EPERM;\nbreak;\n}\ngoto set_sndbuf;\ncase SO_RCVBUF:\nval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\nsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\nsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\nbreak;\ncase SO_RCVBUFFORCE:\nif (!capable(CAP_NET_ADMIN)) {\nret = -EPERM;\nbreak;\n}\ngoto set_rcvbuf;\ncase SO_KEEPALIVE:\n#ifdef CONFIG_INET\nif (sk->sk_protocol == IPPROTO_TCP &&\nsk->sk_type == SOCK_STREAM)\ntcp_set_keepalive(sk, valbool);\n#endif\nsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\nbreak;\ncase SO_OOBINLINE:\nsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\nbreak;\ncase SO_NO_CHECK:\nsk->sk_no_check_tx = valbool;\nbreak;\ncase SO_PRIORITY:\nif ((val >= 0 && val <= 6) ||\nns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\nsk->sk_priority = val;\nelse\nret = -EPERM;\nbreak;\ncase SO_LINGER:\nif (optlen < sizeof(ling)) {\nret = -EINVAL;\t\nbreak;\n}\nif (copy_from_user(&ling, optval, sizeof(ling))) {\nret = -EFAULT;\nbreak;\n}\nif (!ling.l_onoff)\nsock_reset_flag(sk, SOCK_LINGER);\nelse {\n#if (BITS_PER_LONG == 32)\nif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\nsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\nelse\n#endif\nsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\nsock_set_flag(sk, SOCK_LINGER);\n}\nbreak;\ncase SO_BSDCOMPAT:\nsock_warn_obsolete_bsdism(\"setsockopt\");\nbreak;\ncase SO_PASSCRED:\nif (valbool)\nset_bit(SOCK_PASSCRED, &sock->flags);\nelse\nclear_bit(SOCK_PASSCRED, &sock->flags);\nbreak;\ncase SO_TIMESTAMP:\ncase SO_TIMESTAMPNS:\nif (valbool)  {\nif (optname == SO_TIMESTAMP)\nsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\nelse\nsock_set_flag(sk, SOCK_RCVTSTAMPNS);\nsock_set_flag(sk, SOCK_RCVTSTAMP);\nsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n} else {\nsock_reset_flag(sk, SOCK_RCVTSTAMP);\nsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n}\nbreak;\ncase SO_TIMESTAMPING:\nif (val & ~SOF_TIMESTAMPING_MASK) {\nret = -EINVAL;\nbreak;\n}\nif (val & SOF_TIMESTAMPING_OPT_ID &&\n!(sk->sk_tsflags & SOF_TIMESTAMPING_OPT_ID)) {\nif (sk->sk_protocol == IPPROTO_TCP &&\nsk->sk_type == SOCK_STREAM) {\nif ((1 << sk->sk_state) &\n(TCPF_CLOSE | TCPF_LISTEN)) {\nret = -EINVAL;\nbreak;\n}\nsk->sk_tskey = tcp_sk(sk)->snd_una;\n} else {\nsk->sk_tskey = 0;\n}\n}\nsk->sk_tsflags = val;\nif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\nsock_enable_timestamp(sk,\nSOCK_TIMESTAMPING_RX_SOFTWARE);\nelse\nsock_disable_timestamp(sk,\n(1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\nbreak;\ncase SO_RCVLOWAT:\nif (val < 0)\nval = INT_MAX;\nsk->sk_rcvlowat = val ? : 1;\nbreak;\ncase SO_RCVTIMEO:\nret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\nbreak;\ncase SO_SNDTIMEO:\nret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\nbreak;\ncase SO_ATTACH_FILTER:\nret = -EINVAL;\nif (optlen == sizeof(struct sock_fprog)) {\nstruct sock_fprog fprog;\nret = -EFAULT;\nif (copy_from_user(&fprog, optval, sizeof(fprog)))\nbreak;\nret = sk_attach_filter(&fprog, sk);\n}\nbreak;\ncase SO_ATTACH_BPF:\nret = -EINVAL;\nif (optlen == sizeof(u32)) {\nu32 ufd;\nret = -EFAULT;\nif (copy_from_user(&ufd, optval, sizeof(ufd)))\nbreak;\nret = sk_attach_bpf(ufd, sk);\n}\nbreak;\ncase SO_ATTACH_REUSEPORT_CBPF:\nret = -EINVAL;\nif (optlen == sizeof(struct sock_fprog)) {\nstruct sock_fprog fprog;\nret = -EFAULT;\nif (copy_from_user(&fprog, optval, sizeof(fprog)))\nbreak;\nret = sk_reuseport_attach_filter(&fprog, sk);\n}\nbreak;\ncase SO_ATTACH_REUSEPORT_EBPF:\nret = -EINVAL;\nif (optlen == sizeof(u32)) {\nu32 ufd;\nret = -EFAULT;\nif (copy_from_user(&ufd, optval, sizeof(ufd)))\nbreak;\nret = sk_reuseport_attach_bpf(ufd, sk);\n}\nbreak;\ncase SO_DETACH_FILTER:\nret = sk_detach_filter(sk);\nbreak;\ncase SO_LOCK_FILTER:\nif (sock_flag(sk, SOCK_FILTER_LOCKED) && !valbool)\nret = -EPERM;\nelse\nsock_valbool_flag(sk, SOCK_FILTER_LOCKED, valbool);\nbreak;\ncase SO_PASSSEC:\nif (valbool)\nset_bit(SOCK_PASSSEC, &sock->flags);\nelse\nclear_bit(SOCK_PASSSEC, &sock->flags);\nbreak;\ncase SO_MARK:\nif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\nret = -EPERM;\nelse\nsk->sk_mark = val;\nbreak;\ncase SO_RXQ_OVFL:\nsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\nbreak;\ncase SO_WIFI_STATUS:\nsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\nbreak;\ncase SO_PEEK_OFF:\nif (sock->ops->set_peek_off)\nret = sock->ops->set_peek_off(sk, val);\nelse\nret = -EOPNOTSUPP;\nbreak;\ncase SO_NOFCS:\nsock_valbool_flag(sk, SOCK_NOFCS, valbool);\nbreak;\ncase SO_SELECT_ERR_QUEUE:\nsock_valbool_flag(sk, SOCK_SELECT_ERR_QUEUE, valbool);\nbreak;\n#ifdef CONFIG_NET_RX_BUSY_POLL\ncase SO_BUSY_POLL:\nif ((val > sk->sk_ll_usec) && !capable(CAP_NET_ADMIN))\nret = -EPERM;\nelse {\nif (val < 0)\nret = -EINVAL;\nelse\nsk->sk_ll_usec = val;\n}\nbreak;\n#endif\ncase SO_MAX_PACING_RATE:\nsk->sk_max_pacing_rate = val;\nsk->sk_pacing_rate = min(sk->sk_pacing_rate,\nsk->sk_max_pacing_rate);\nbreak;\ncase SO_INCOMING_CPU:\nsk->sk_incoming_cpu = val;\nbreak;\ncase SO_CNX_ADVICE:\nif (val == 1)\ndst_negative_advice(sk);\nbreak;\ndefault:\nret = -ENOPROTOOPT;\nbreak;\n}\nrelease_sock(sk);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2017-1000253": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for memory mapping of Position Independent Executable (PIE) binaries in the Linux kernel.",
        "trigger_condition": "Loading a PIE binary with CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE enabled and a normal top-down address allocation strategy.",
        "specific_code_behavior_causing_vulnerability": "The code in load_elf_binary() does not account for the total size of the binary when mapping subsequent PT_LOAD segments, leading to overlapping mappings above mm->mmap_base.",
        "solution": "To fix the vulnerability, the code needs to calculate the total size of the binary and adjust the mapping of subsequent PT_LOAD segments to ensure they are placed below mm->mmap_base. This prevents overlapping mappings and ensures correct placement of the binary in memory."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to fix a vulnerability (CVE-2017-1000253) related to the way PIE (Position Independent Executable) binaries are loaded in the Linux kernel. The vulnerability occurs when loading a PIE binary with CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE enabled and a normal top-down address allocation strategy.\n\nThe original code did not properly account for the need to allocate sufficient space for the entire binary when mapping PIE binaries into memory. This resulted in subsequent PT_LOAD segments being mapped above mm->mmap_base, overlapping with the area that should be the \"gap\" between the stack and the binary.\n\nThe modification addresses this vulnerability by calculating the total size of the binary and ensuring that the subsequent PT_LOAD segments are mapped below mm->mmap_base as intended. By adjusting the mapping based on the total size of the binary, the code prevents overlapping mappings and ensures the correct placement of the binary in memory.\n\nTherefore, the modification is necessary to prevent potential security risks associated with incorrect memory mappings of PIE binaries in the Linux kernel.",
      "GPT_purpose": "Load an ELF binary into memory and set up the necessary memory mappings for execution.",
      "GPT_function": "\n1. Load an ELF binary into memory.\n2. Perform consistency checks on the ELF binary.\n3. Map the ELF binary into the correct location in memory.\n4. Handle program interpreter for shared libraries.\n5. Set up argument pages for the binary.\n6. Flush traces of the currently running executable.\n7. Set up additional pages for the ELF binary.\n8. Install execution credentials for the binary.\n9. Create ELF tables for the binary.\n10. Initialize registers and perform relocations for dynamically linked apps.",
      "CVE_id": "CVE-2017-1000253",
      "code_before_change": "static int load_elf_binary(struct linux_binprm *bprm)\n{\n\tstruct file *interpreter = NULL; /* to shut gcc up */\n \tunsigned long load_addr = 0, load_bias = 0;\n\tint load_addr_set = 0;\n\tchar * elf_interpreter = NULL;\n\tunsigned long error;\n\tstruct elf_phdr *elf_ppnt, *elf_phdata, *interp_elf_phdata = NULL;\n\tunsigned long elf_bss, elf_brk;\n\tint retval, i;\n\tunsigned long elf_entry;\n\tunsigned long interp_load_addr = 0;\n\tunsigned long start_code, end_code, start_data, end_data;\n\tunsigned long reloc_func_desc __maybe_unused = 0;\n\tint executable_stack = EXSTACK_DEFAULT;\n\tstruct pt_regs *regs = current_pt_regs();\n\tstruct {\n\t\tstruct elfhdr elf_ex;\n\t\tstruct elfhdr interp_elf_ex;\n\t} *loc;\n\tstruct arch_elf_state arch_state = INIT_ARCH_ELF_STATE;\n\n\tloc = kmalloc(sizeof(*loc), GFP_KERNEL);\n\tif (!loc) {\n\t\tretval = -ENOMEM;\n\t\tgoto out_ret;\n\t}\n\t\n\t/* Get the exec-header */\n\tloc->elf_ex = *((struct elfhdr *)bprm->buf);\n\n\tretval = -ENOEXEC;\n\t/* First of all, some simple consistency checks */\n\tif (memcmp(loc->elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\tgoto out;\n\n\tif (loc->elf_ex.e_type != ET_EXEC && loc->elf_ex.e_type != ET_DYN)\n\t\tgoto out;\n\tif (!elf_check_arch(&loc->elf_ex))\n\t\tgoto out;\n\tif (!bprm->file->f_op->mmap)\n\t\tgoto out;\n\n\telf_phdata = load_elf_phdrs(&loc->elf_ex, bprm->file);\n\tif (!elf_phdata)\n\t\tgoto out;\n\n\telf_ppnt = elf_phdata;\n\telf_bss = 0;\n\telf_brk = 0;\n\n\tstart_code = ~0UL;\n\tend_code = 0;\n\tstart_data = 0;\n\tend_data = 0;\n\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++) {\n\t\tif (elf_ppnt->p_type == PT_INTERP) {\n\t\t\t/* This is the program interpreter used for\n\t\t\t * shared libraries - for now assume that this\n\t\t\t * is an a.out format binary\n\t\t\t */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_ppnt->p_filesz > PATH_MAX || \n\t\t\t    elf_ppnt->p_filesz < 2)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = -ENOMEM;\n\t\t\telf_interpreter = kmalloc(elf_ppnt->p_filesz,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!elf_interpreter)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = kernel_read(bprm->file, elf_ppnt->p_offset,\n\t\t\t\t\t     elf_interpreter,\n\t\t\t\t\t     elf_ppnt->p_filesz);\n\t\t\tif (retval != elf_ppnt->p_filesz) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_interp;\n\t\t\t}\n\t\t\t/* make sure path is NULL terminated */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_interpreter[elf_ppnt->p_filesz - 1] != '\\0')\n\t\t\t\tgoto out_free_interp;\n\n\t\t\tinterpreter = open_exec(elf_interpreter);\n\t\t\tretval = PTR_ERR(interpreter);\n\t\t\tif (IS_ERR(interpreter))\n\t\t\t\tgoto out_free_interp;\n\n\t\t\t/*\n\t\t\t * If the binary is not readable then enforce\n\t\t\t * mm->dumpable = 0 regardless of the interpreter's\n\t\t\t * permissions.\n\t\t\t */\n\t\t\twould_dump(bprm, interpreter);\n\n\t\t\tretval = kernel_read(interpreter, 0, bprm->buf,\n\t\t\t\t\t     BINPRM_BUF_SIZE);\n\t\t\tif (retval != BINPRM_BUF_SIZE) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_dentry;\n\t\t\t}\n\n\t\t\t/* Get the exec headers */\n\t\t\tloc->interp_elf_ex = *((struct elfhdr *)bprm->buf);\n\t\t\tbreak;\n\t\t}\n\t\telf_ppnt++;\n\t}\n\n\telf_ppnt = elf_phdata;\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++)\n\t\tswitch (elf_ppnt->p_type) {\n\t\tcase PT_GNU_STACK:\n\t\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\t\texecutable_stack = EXSTACK_ENABLE_X;\n\t\t\telse\n\t\t\t\texecutable_stack = EXSTACK_DISABLE_X;\n\t\t\tbreak;\n\n\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\tretval = arch_elf_pt_proc(&loc->elf_ex, elf_ppnt,\n\t\t\t\t\t\t  bprm->file, false,\n\t\t\t\t\t\t  &arch_state);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tbreak;\n\t\t}\n\n\t/* Some simple consistency checks for the interpreter */\n\tif (elf_interpreter) {\n\t\tretval = -ELIBBAD;\n\t\t/* Not an ELF interpreter */\n\t\tif (memcmp(loc->interp_elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\t\tgoto out_free_dentry;\n\t\t/* Verify the interpreter has a valid arch */\n\t\tif (!elf_check_arch(&loc->interp_elf_ex))\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Load the interpreter program headers */\n\t\tinterp_elf_phdata = load_elf_phdrs(&loc->interp_elf_ex,\n\t\t\t\t\t\t   interpreter);\n\t\tif (!interp_elf_phdata)\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Pass PT_LOPROC..PT_HIPROC headers to arch code */\n\t\telf_ppnt = interp_elf_phdata;\n\t\tfor (i = 0; i < loc->interp_elf_ex.e_phnum; i++, elf_ppnt++)\n\t\t\tswitch (elf_ppnt->p_type) {\n\t\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\t\tretval = arch_elf_pt_proc(&loc->interp_elf_ex,\n\t\t\t\t\t\t\t  elf_ppnt, interpreter,\n\t\t\t\t\t\t\t  true, &arch_state);\n\t\t\t\tif (retval)\n\t\t\t\t\tgoto out_free_dentry;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/*\n\t * Allow arch code to reject the ELF at this point, whilst it's\n\t * still possible to return an error to the code that invoked\n\t * the exec syscall.\n\t */\n\tretval = arch_check_elf(&loc->elf_ex, !!interpreter, &arch_state);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Flush all traces of the currently running executable */\n\tretval = flush_old_exec(bprm);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Do this immediately, since STACK_TOP as used in setup_arg_pages\n\t   may depend on the personality.  */\n\tSET_PERSONALITY2(loc->elf_ex, &arch_state);\n\tif (elf_read_implies_exec(loc->elf_ex, executable_stack))\n\t\tcurrent->personality |= READ_IMPLIES_EXEC;\n\n\tif (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)\n\t\tcurrent->flags |= PF_RANDOMIZE;\n\n\tsetup_new_exec(bprm);\n\n\t/* Do this so that we can load the interpreter, if need be.  We will\n\t   change some of these later */\n\tretval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP),\n\t\t\t\t executable_stack);\n\tif (retval < 0)\n\t\tgoto out_free_dentry;\n\t\n\tcurrent->mm->start_stack = bprm->p;\n\n\t/* Now we do a little grungy work by mmapping the ELF image into\n\t   the correct location in memory. */\n\tfor(i = 0, elf_ppnt = elf_phdata;\n\t    i < loc->elf_ex.e_phnum; i++, elf_ppnt++) {\n\t\tint elf_prot = 0, elf_flags;\n\t\tunsigned long k, vaddr;\n\n\t\tif (elf_ppnt->p_type != PT_LOAD)\n\t\t\tcontinue;\n\n\t\tif (unlikely (elf_brk > elf_bss)) {\n\t\t\tunsigned long nbyte;\n\t            \n\t\t\t/* There was a PT_LOAD segment with p_memsz > p_filesz\n\t\t\t   before this one. Map anonymous pages, if needed,\n\t\t\t   and clear the area.  */\n\t\t\tretval = set_brk(elf_bss + load_bias,\n\t\t\t\t\t elf_brk + load_bias);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tnbyte = ELF_PAGEOFFSET(elf_bss);\n\t\t\tif (nbyte) {\n\t\t\t\tnbyte = ELF_MIN_ALIGN - nbyte;\n\t\t\t\tif (nbyte > elf_brk - elf_bss)\n\t\t\t\t\tnbyte = elf_brk - elf_bss;\n\t\t\t\tif (clear_user((void __user *)elf_bss +\n\t\t\t\t\t\t\tload_bias, nbyte)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * This bss-zeroing can fail if the ELF\n\t\t\t\t\t * file specifies odd protections. So\n\t\t\t\t\t * we don't check the return value\n\t\t\t\t\t */\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (elf_ppnt->p_flags & PF_R)\n\t\t\telf_prot |= PROT_READ;\n\t\tif (elf_ppnt->p_flags & PF_W)\n\t\t\telf_prot |= PROT_WRITE;\n\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\telf_prot |= PROT_EXEC;\n\n\t\telf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE;\n\n\t\tvaddr = elf_ppnt->p_vaddr;\n\t\tif (loc->elf_ex.e_type == ET_EXEC || load_addr_set) {\n\t\t\telf_flags |= MAP_FIXED;\n\t\t} else if (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t/* Try and get dynamic programs out of the way of the\n\t\t\t * default mmap base, as well as whatever program they\n\t\t\t * might try to exec.  This is because the brk will\n\t\t\t * follow the loader, and is not movable.  */\n#ifdef CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE\n\t\t\t/* Memory randomization might have been switched off\n\t\t\t * in runtime via sysctl or explicit setting of\n\t\t\t * personality flags.\n\t\t\t * If that is the case, retain the original non-zero\n\t\t\t * load_bias value in order to establish proper\n\t\t\t * non-randomized mappings.\n\t\t\t */\n\t\t\tif (current->flags & PF_RANDOMIZE)\n\t\t\t\tload_bias = 0;\n\t\t\telse\n\t\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#else\n\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#endif\n\t\t}\n\n\t\terror = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,\n\t\t\t\telf_prot, elf_flags, 0);\n\t\tif (BAD_ADDR(error)) {\n\t\t\tretval = IS_ERR((void *)error) ?\n\t\t\t\tPTR_ERR((void*)error) : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tif (!load_addr_set) {\n\t\t\tload_addr_set = 1;\n\t\t\tload_addr = (elf_ppnt->p_vaddr - elf_ppnt->p_offset);\n\t\t\tif (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t\tload_bias += error -\n\t\t\t\t             ELF_PAGESTART(load_bias + vaddr);\n\t\t\t\tload_addr += load_bias;\n\t\t\t\treloc_func_desc = load_bias;\n\t\t\t}\n\t\t}\n\t\tk = elf_ppnt->p_vaddr;\n\t\tif (k < start_code)\n\t\t\tstart_code = k;\n\t\tif (start_data < k)\n\t\t\tstart_data = k;\n\n\t\t/*\n\t\t * Check to see if the section's size will overflow the\n\t\t * allowed task size. Note that p_filesz must always be\n\t\t * <= p_memsz so it is only necessary to check p_memsz.\n\t\t */\n\t\tif (BAD_ADDR(k) || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||\n\t\t    elf_ppnt->p_memsz > TASK_SIZE ||\n\t\t    TASK_SIZE - elf_ppnt->p_memsz < k) {\n\t\t\t/* set_brk can never work. Avoid overflows. */\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_filesz;\n\n\t\tif (k > elf_bss)\n\t\t\telf_bss = k;\n\t\tif ((elf_ppnt->p_flags & PF_X) && end_code < k)\n\t\t\tend_code = k;\n\t\tif (end_data < k)\n\t\t\tend_data = k;\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_memsz;\n\t\tif (k > elf_brk)\n\t\t\telf_brk = k;\n\t}\n\n\tloc->elf_ex.e_entry += load_bias;\n\telf_bss += load_bias;\n\telf_brk += load_bias;\n\tstart_code += load_bias;\n\tend_code += load_bias;\n\tstart_data += load_bias;\n\tend_data += load_bias;\n\n\t/* Calling set_brk effectively mmaps the pages that we need\n\t * for the bss and break sections.  We must do this before\n\t * mapping in the interpreter, to make sure it doesn't wind\n\t * up getting placed where the bss needs to go.\n\t */\n\tretval = set_brk(elf_bss, elf_brk);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\tif (likely(elf_bss != elf_brk) && unlikely(padzero(elf_bss))) {\n\t\tretval = -EFAULT; /* Nobody gets to see this, but.. */\n\t\tgoto out_free_dentry;\n\t}\n\n\tif (elf_interpreter) {\n\t\tunsigned long interp_map_addr = 0;\n\n\t\telf_entry = load_elf_interp(&loc->interp_elf_ex,\n\t\t\t\t\t    interpreter,\n\t\t\t\t\t    &interp_map_addr,\n\t\t\t\t\t    load_bias, interp_elf_phdata);\n\t\tif (!IS_ERR((void *)elf_entry)) {\n\t\t\t/*\n\t\t\t * load_elf_interp() returns relocation\n\t\t\t * adjustment\n\t\t\t */\n\t\t\tinterp_load_addr = elf_entry;\n\t\t\telf_entry += loc->interp_elf_ex.e_entry;\n\t\t}\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = IS_ERR((void *)elf_entry) ?\n\t\t\t\t\t(int)elf_entry : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t\treloc_func_desc = interp_load_addr;\n\n\t\tallow_write_access(interpreter);\n\t\tfput(interpreter);\n\t\tkfree(elf_interpreter);\n\t} else {\n\t\telf_entry = loc->elf_ex.e_entry;\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t}\n\n\tkfree(interp_elf_phdata);\n\tkfree(elf_phdata);\n\n\tset_binfmt(&elf_format);\n\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\n\tretval = arch_setup_additional_pages(bprm, !!elf_interpreter);\n\tif (retval < 0)\n\t\tgoto out;\n#endif /* ARCH_HAS_SETUP_ADDITIONAL_PAGES */\n\n\tinstall_exec_creds(bprm);\n\tretval = create_elf_tables(bprm, &loc->elf_ex,\n\t\t\t  load_addr, interp_load_addr);\n\tif (retval < 0)\n\t\tgoto out;\n\t/* N.B. passed_fileno might not be initialized? */\n\tcurrent->mm->end_code = end_code;\n\tcurrent->mm->start_code = start_code;\n\tcurrent->mm->start_data = start_data;\n\tcurrent->mm->end_data = end_data;\n\tcurrent->mm->start_stack = bprm->p;\n\n#ifdef arch_randomize_brk\n\tif ((current->flags & PF_RANDOMIZE) && (randomize_va_space > 1)) {\n\t\tcurrent->mm->brk = current->mm->start_brk =\n\t\t\tarch_randomize_brk(current->mm);\n#ifdef CONFIG_COMPAT_BRK\n\t\tcurrent->brk_randomized = 1;\n#endif\n\t}\n#endif\n\n\tif (current->personality & MMAP_PAGE_ZERO) {\n\t\t/* Why this, you ask???  Well SVr4 maps page 0 as read-only,\n\t\t   and some applications \"depend\" upon this behavior.\n\t\t   Since we do not have the power to recompile these, we\n\t\t   emulate the SVr4 behavior. Sigh. */\n\t\terror = vm_mmap(NULL, 0, PAGE_SIZE, PROT_READ | PROT_EXEC,\n\t\t\t\tMAP_FIXED | MAP_PRIVATE, 0);\n\t}\n\n#ifdef ELF_PLAT_INIT\n\t/*\n\t * The ABI may specify that certain registers be set up in special\n\t * ways (on i386 %edx is the address of a DT_FINI function, for\n\t * example.  In addition, it may also specify (eg, PowerPC64 ELF)\n\t * that the e_entry field is the address of the function descriptor\n\t * for the startup routine, rather than the address of the startup\n\t * routine itself.  This macro performs whatever initialization to\n\t * the regs structure is required as well as any relocations to the\n\t * function descriptor entries when executing dynamically links apps.\n\t */\n\tELF_PLAT_INIT(regs, reloc_func_desc);\n#endif\n\n\tstart_thread(regs, elf_entry, bprm->p);\n\tretval = 0;\nout:\n\tkfree(loc);\nout_ret:\n\treturn retval;\n\n\t/* error cleanup */\nout_free_dentry:\n\tkfree(interp_elf_phdata);\n\tallow_write_access(interpreter);\n\tif (interpreter)\n\t\tfput(interpreter);\nout_free_interp:\n\tkfree(elf_interpreter);\nout_free_ph:\n\tkfree(elf_phdata);\n\tgoto out;\n}",
      "code_after_change": "static int load_elf_binary(struct linux_binprm *bprm)\n{\n\tstruct file *interpreter = NULL; /* to shut gcc up */\n \tunsigned long load_addr = 0, load_bias = 0;\n\tint load_addr_set = 0;\n\tchar * elf_interpreter = NULL;\n\tunsigned long error;\n\tstruct elf_phdr *elf_ppnt, *elf_phdata, *interp_elf_phdata = NULL;\n\tunsigned long elf_bss, elf_brk;\n\tint retval, i;\n\tunsigned long elf_entry;\n\tunsigned long interp_load_addr = 0;\n\tunsigned long start_code, end_code, start_data, end_data;\n\tunsigned long reloc_func_desc __maybe_unused = 0;\n\tint executable_stack = EXSTACK_DEFAULT;\n\tstruct pt_regs *regs = current_pt_regs();\n\tstruct {\n\t\tstruct elfhdr elf_ex;\n\t\tstruct elfhdr interp_elf_ex;\n\t} *loc;\n\tstruct arch_elf_state arch_state = INIT_ARCH_ELF_STATE;\n\n\tloc = kmalloc(sizeof(*loc), GFP_KERNEL);\n\tif (!loc) {\n\t\tretval = -ENOMEM;\n\t\tgoto out_ret;\n\t}\n\t\n\t/* Get the exec-header */\n\tloc->elf_ex = *((struct elfhdr *)bprm->buf);\n\n\tretval = -ENOEXEC;\n\t/* First of all, some simple consistency checks */\n\tif (memcmp(loc->elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\tgoto out;\n\n\tif (loc->elf_ex.e_type != ET_EXEC && loc->elf_ex.e_type != ET_DYN)\n\t\tgoto out;\n\tif (!elf_check_arch(&loc->elf_ex))\n\t\tgoto out;\n\tif (!bprm->file->f_op->mmap)\n\t\tgoto out;\n\n\telf_phdata = load_elf_phdrs(&loc->elf_ex, bprm->file);\n\tif (!elf_phdata)\n\t\tgoto out;\n\n\telf_ppnt = elf_phdata;\n\telf_bss = 0;\n\telf_brk = 0;\n\n\tstart_code = ~0UL;\n\tend_code = 0;\n\tstart_data = 0;\n\tend_data = 0;\n\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++) {\n\t\tif (elf_ppnt->p_type == PT_INTERP) {\n\t\t\t/* This is the program interpreter used for\n\t\t\t * shared libraries - for now assume that this\n\t\t\t * is an a.out format binary\n\t\t\t */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_ppnt->p_filesz > PATH_MAX || \n\t\t\t    elf_ppnt->p_filesz < 2)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = -ENOMEM;\n\t\t\telf_interpreter = kmalloc(elf_ppnt->p_filesz,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!elf_interpreter)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = kernel_read(bprm->file, elf_ppnt->p_offset,\n\t\t\t\t\t     elf_interpreter,\n\t\t\t\t\t     elf_ppnt->p_filesz);\n\t\t\tif (retval != elf_ppnt->p_filesz) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_interp;\n\t\t\t}\n\t\t\t/* make sure path is NULL terminated */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_interpreter[elf_ppnt->p_filesz - 1] != '\\0')\n\t\t\t\tgoto out_free_interp;\n\n\t\t\tinterpreter = open_exec(elf_interpreter);\n\t\t\tretval = PTR_ERR(interpreter);\n\t\t\tif (IS_ERR(interpreter))\n\t\t\t\tgoto out_free_interp;\n\n\t\t\t/*\n\t\t\t * If the binary is not readable then enforce\n\t\t\t * mm->dumpable = 0 regardless of the interpreter's\n\t\t\t * permissions.\n\t\t\t */\n\t\t\twould_dump(bprm, interpreter);\n\n\t\t\tretval = kernel_read(interpreter, 0, bprm->buf,\n\t\t\t\t\t     BINPRM_BUF_SIZE);\n\t\t\tif (retval != BINPRM_BUF_SIZE) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_dentry;\n\t\t\t}\n\n\t\t\t/* Get the exec headers */\n\t\t\tloc->interp_elf_ex = *((struct elfhdr *)bprm->buf);\n\t\t\tbreak;\n\t\t}\n\t\telf_ppnt++;\n\t}\n\n\telf_ppnt = elf_phdata;\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++)\n\t\tswitch (elf_ppnt->p_type) {\n\t\tcase PT_GNU_STACK:\n\t\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\t\texecutable_stack = EXSTACK_ENABLE_X;\n\t\t\telse\n\t\t\t\texecutable_stack = EXSTACK_DISABLE_X;\n\t\t\tbreak;\n\n\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\tretval = arch_elf_pt_proc(&loc->elf_ex, elf_ppnt,\n\t\t\t\t\t\t  bprm->file, false,\n\t\t\t\t\t\t  &arch_state);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tbreak;\n\t\t}\n\n\t/* Some simple consistency checks for the interpreter */\n\tif (elf_interpreter) {\n\t\tretval = -ELIBBAD;\n\t\t/* Not an ELF interpreter */\n\t\tif (memcmp(loc->interp_elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\t\tgoto out_free_dentry;\n\t\t/* Verify the interpreter has a valid arch */\n\t\tif (!elf_check_arch(&loc->interp_elf_ex))\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Load the interpreter program headers */\n\t\tinterp_elf_phdata = load_elf_phdrs(&loc->interp_elf_ex,\n\t\t\t\t\t\t   interpreter);\n\t\tif (!interp_elf_phdata)\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Pass PT_LOPROC..PT_HIPROC headers to arch code */\n\t\telf_ppnt = interp_elf_phdata;\n\t\tfor (i = 0; i < loc->interp_elf_ex.e_phnum; i++, elf_ppnt++)\n\t\t\tswitch (elf_ppnt->p_type) {\n\t\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\t\tretval = arch_elf_pt_proc(&loc->interp_elf_ex,\n\t\t\t\t\t\t\t  elf_ppnt, interpreter,\n\t\t\t\t\t\t\t  true, &arch_state);\n\t\t\t\tif (retval)\n\t\t\t\t\tgoto out_free_dentry;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/*\n\t * Allow arch code to reject the ELF at this point, whilst it's\n\t * still possible to return an error to the code that invoked\n\t * the exec syscall.\n\t */\n\tretval = arch_check_elf(&loc->elf_ex, !!interpreter, &arch_state);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Flush all traces of the currently running executable */\n\tretval = flush_old_exec(bprm);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Do this immediately, since STACK_TOP as used in setup_arg_pages\n\t   may depend on the personality.  */\n\tSET_PERSONALITY2(loc->elf_ex, &arch_state);\n\tif (elf_read_implies_exec(loc->elf_ex, executable_stack))\n\t\tcurrent->personality |= READ_IMPLIES_EXEC;\n\n\tif (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)\n\t\tcurrent->flags |= PF_RANDOMIZE;\n\n\tsetup_new_exec(bprm);\n\n\t/* Do this so that we can load the interpreter, if need be.  We will\n\t   change some of these later */\n\tretval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP),\n\t\t\t\t executable_stack);\n\tif (retval < 0)\n\t\tgoto out_free_dentry;\n\t\n\tcurrent->mm->start_stack = bprm->p;\n\n\t/* Now we do a little grungy work by mmapping the ELF image into\n\t   the correct location in memory. */\n\tfor(i = 0, elf_ppnt = elf_phdata;\n\t    i < loc->elf_ex.e_phnum; i++, elf_ppnt++) {\n\t\tint elf_prot = 0, elf_flags;\n\t\tunsigned long k, vaddr;\n\t\tunsigned long total_size = 0;\n\n\t\tif (elf_ppnt->p_type != PT_LOAD)\n\t\t\tcontinue;\n\n\t\tif (unlikely (elf_brk > elf_bss)) {\n\t\t\tunsigned long nbyte;\n\t            \n\t\t\t/* There was a PT_LOAD segment with p_memsz > p_filesz\n\t\t\t   before this one. Map anonymous pages, if needed,\n\t\t\t   and clear the area.  */\n\t\t\tretval = set_brk(elf_bss + load_bias,\n\t\t\t\t\t elf_brk + load_bias);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tnbyte = ELF_PAGEOFFSET(elf_bss);\n\t\t\tif (nbyte) {\n\t\t\t\tnbyte = ELF_MIN_ALIGN - nbyte;\n\t\t\t\tif (nbyte > elf_brk - elf_bss)\n\t\t\t\t\tnbyte = elf_brk - elf_bss;\n\t\t\t\tif (clear_user((void __user *)elf_bss +\n\t\t\t\t\t\t\tload_bias, nbyte)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * This bss-zeroing can fail if the ELF\n\t\t\t\t\t * file specifies odd protections. So\n\t\t\t\t\t * we don't check the return value\n\t\t\t\t\t */\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (elf_ppnt->p_flags & PF_R)\n\t\t\telf_prot |= PROT_READ;\n\t\tif (elf_ppnt->p_flags & PF_W)\n\t\t\telf_prot |= PROT_WRITE;\n\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\telf_prot |= PROT_EXEC;\n\n\t\telf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE;\n\n\t\tvaddr = elf_ppnt->p_vaddr;\n\t\tif (loc->elf_ex.e_type == ET_EXEC || load_addr_set) {\n\t\t\telf_flags |= MAP_FIXED;\n\t\t} else if (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t/* Try and get dynamic programs out of the way of the\n\t\t\t * default mmap base, as well as whatever program they\n\t\t\t * might try to exec.  This is because the brk will\n\t\t\t * follow the loader, and is not movable.  */\n#ifdef CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE\n\t\t\t/* Memory randomization might have been switched off\n\t\t\t * in runtime via sysctl or explicit setting of\n\t\t\t * personality flags.\n\t\t\t * If that is the case, retain the original non-zero\n\t\t\t * load_bias value in order to establish proper\n\t\t\t * non-randomized mappings.\n\t\t\t */\n\t\t\tif (current->flags & PF_RANDOMIZE)\n\t\t\t\tload_bias = 0;\n\t\t\telse\n\t\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#else\n\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#endif\n\t\t\ttotal_size = total_mapping_size(elf_phdata,\n\t\t\t\t\t\t\tloc->elf_ex.e_phnum);\n\t\t\tif (!total_size) {\n\t\t\t\terror = -EINVAL;\n\t\t\t\tgoto out_free_dentry;\n\t\t\t}\n\t\t}\n\n\t\terror = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,\n\t\t\t\telf_prot, elf_flags, total_size);\n\t\tif (BAD_ADDR(error)) {\n\t\t\tretval = IS_ERR((void *)error) ?\n\t\t\t\tPTR_ERR((void*)error) : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tif (!load_addr_set) {\n\t\t\tload_addr_set = 1;\n\t\t\tload_addr = (elf_ppnt->p_vaddr - elf_ppnt->p_offset);\n\t\t\tif (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t\tload_bias += error -\n\t\t\t\t             ELF_PAGESTART(load_bias + vaddr);\n\t\t\t\tload_addr += load_bias;\n\t\t\t\treloc_func_desc = load_bias;\n\t\t\t}\n\t\t}\n\t\tk = elf_ppnt->p_vaddr;\n\t\tif (k < start_code)\n\t\t\tstart_code = k;\n\t\tif (start_data < k)\n\t\t\tstart_data = k;\n\n\t\t/*\n\t\t * Check to see if the section's size will overflow the\n\t\t * allowed task size. Note that p_filesz must always be\n\t\t * <= p_memsz so it is only necessary to check p_memsz.\n\t\t */\n\t\tif (BAD_ADDR(k) || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||\n\t\t    elf_ppnt->p_memsz > TASK_SIZE ||\n\t\t    TASK_SIZE - elf_ppnt->p_memsz < k) {\n\t\t\t/* set_brk can never work. Avoid overflows. */\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_filesz;\n\n\t\tif (k > elf_bss)\n\t\t\telf_bss = k;\n\t\tif ((elf_ppnt->p_flags & PF_X) && end_code < k)\n\t\t\tend_code = k;\n\t\tif (end_data < k)\n\t\t\tend_data = k;\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_memsz;\n\t\tif (k > elf_brk)\n\t\t\telf_brk = k;\n\t}\n\n\tloc->elf_ex.e_entry += load_bias;\n\telf_bss += load_bias;\n\telf_brk += load_bias;\n\tstart_code += load_bias;\n\tend_code += load_bias;\n\tstart_data += load_bias;\n\tend_data += load_bias;\n\n\t/* Calling set_brk effectively mmaps the pages that we need\n\t * for the bss and break sections.  We must do this before\n\t * mapping in the interpreter, to make sure it doesn't wind\n\t * up getting placed where the bss needs to go.\n\t */\n\tretval = set_brk(elf_bss, elf_brk);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\tif (likely(elf_bss != elf_brk) && unlikely(padzero(elf_bss))) {\n\t\tretval = -EFAULT; /* Nobody gets to see this, but.. */\n\t\tgoto out_free_dentry;\n\t}\n\n\tif (elf_interpreter) {\n\t\tunsigned long interp_map_addr = 0;\n\n\t\telf_entry = load_elf_interp(&loc->interp_elf_ex,\n\t\t\t\t\t    interpreter,\n\t\t\t\t\t    &interp_map_addr,\n\t\t\t\t\t    load_bias, interp_elf_phdata);\n\t\tif (!IS_ERR((void *)elf_entry)) {\n\t\t\t/*\n\t\t\t * load_elf_interp() returns relocation\n\t\t\t * adjustment\n\t\t\t */\n\t\t\tinterp_load_addr = elf_entry;\n\t\t\telf_entry += loc->interp_elf_ex.e_entry;\n\t\t}\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = IS_ERR((void *)elf_entry) ?\n\t\t\t\t\t(int)elf_entry : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t\treloc_func_desc = interp_load_addr;\n\n\t\tallow_write_access(interpreter);\n\t\tfput(interpreter);\n\t\tkfree(elf_interpreter);\n\t} else {\n\t\telf_entry = loc->elf_ex.e_entry;\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t}\n\n\tkfree(interp_elf_phdata);\n\tkfree(elf_phdata);\n\n\tset_binfmt(&elf_format);\n\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\n\tretval = arch_setup_additional_pages(bprm, !!elf_interpreter);\n\tif (retval < 0)\n\t\tgoto out;\n#endif /* ARCH_HAS_SETUP_ADDITIONAL_PAGES */\n\n\tinstall_exec_creds(bprm);\n\tretval = create_elf_tables(bprm, &loc->elf_ex,\n\t\t\t  load_addr, interp_load_addr);\n\tif (retval < 0)\n\t\tgoto out;\n\t/* N.B. passed_fileno might not be initialized? */\n\tcurrent->mm->end_code = end_code;\n\tcurrent->mm->start_code = start_code;\n\tcurrent->mm->start_data = start_data;\n\tcurrent->mm->end_data = end_data;\n\tcurrent->mm->start_stack = bprm->p;\n\n#ifdef arch_randomize_brk\n\tif ((current->flags & PF_RANDOMIZE) && (randomize_va_space > 1)) {\n\t\tcurrent->mm->brk = current->mm->start_brk =\n\t\t\tarch_randomize_brk(current->mm);\n#ifdef CONFIG_COMPAT_BRK\n\t\tcurrent->brk_randomized = 1;\n#endif\n\t}\n#endif\n\n\tif (current->personality & MMAP_PAGE_ZERO) {\n\t\t/* Why this, you ask???  Well SVr4 maps page 0 as read-only,\n\t\t   and some applications \"depend\" upon this behavior.\n\t\t   Since we do not have the power to recompile these, we\n\t\t   emulate the SVr4 behavior. Sigh. */\n\t\terror = vm_mmap(NULL, 0, PAGE_SIZE, PROT_READ | PROT_EXEC,\n\t\t\t\tMAP_FIXED | MAP_PRIVATE, 0);\n\t}\n\n#ifdef ELF_PLAT_INIT\n\t/*\n\t * The ABI may specify that certain registers be set up in special\n\t * ways (on i386 %edx is the address of a DT_FINI function, for\n\t * example.  In addition, it may also specify (eg, PowerPC64 ELF)\n\t * that the e_entry field is the address of the function descriptor\n\t * for the startup routine, rather than the address of the startup\n\t * routine itself.  This macro performs whatever initialization to\n\t * the regs structure is required as well as any relocations to the\n\t * function descriptor entries when executing dynamically links apps.\n\t */\n\tELF_PLAT_INIT(regs, reloc_func_desc);\n#endif\n\n\tstart_thread(regs, elf_entry, bprm->p);\n\tretval = 0;\nout:\n\tkfree(loc);\nout_ret:\n\treturn retval;\n\n\t/* error cleanup */\nout_free_dentry:\n\tkfree(interp_elf_phdata);\n\tallow_write_access(interpreter);\n\tif (interpreter)\n\t\tfput(interpreter);\nout_free_interp:\n\tkfree(elf_interpreter);\nout_free_ph:\n\tkfree(elf_phdata);\n\tgoto out;\n}",
      "modified_lines": {
        "added": [
          "\t\tunsigned long total_size = 0;",
          "\t\t\ttotal_size = total_mapping_size(elf_phdata,",
          "\t\t\t\t\t\t\tloc->elf_ex.e_phnum);",
          "\t\t\tif (!total_size) {",
          "\t\t\t\terror = -EINVAL;",
          "\t\t\t\tgoto out_free_dentry;",
          "\t\t\t}",
          "\t\t\t\telf_prot, elf_flags, total_size);"
        ],
        "deleted": [
          "\t\t\t\telf_prot, elf_flags, 0);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for memory mapping of Position Independent Executable (PIE) binaries in the Linux kernel.",
      "trigger_condition": "Loading a PIE binary with CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE enabled and a normal top-down address allocation strategy.",
      "specific_code_behavior_causing_vulnerability": "The code in load_elf_binary() does not account for the total size of the binary when mapping subsequent PT_LOAD segments, leading to overlapping mappings above mm->mmap_base.",
      "solution": "To fix the vulnerability, the code needs to calculate the total size of the binary and adjust the mapping of subsequent PT_LOAD segments to ensure they are placed below mm->mmap_base. This prevents overlapping mappings and ensures correct placement of the binary in memory.",
      "id": 101,
      "code_after_change_normalized": "static int FUN1(struct linux_binprm *VAR1)\n{\nstruct file *VAR2 = NULL; \nunsigned long VAR3 = 0, VAR4 = 0;\nint VAR5 = 0;\nchar * VAR6 = NULL;\nunsigned long VAR7;\nstruct elf_phdr *VAR8, *VAR9, *VAR10 = NULL;\nunsigned long VAR11, VAR12;\nint VAR13, VAR14;\nunsigned long VAR15;\nunsigned long VAR16 = 0;\nunsigned long VAR17, VAR18, VAR19, VAR20;\nunsigned long reloc_func_desc VAR21 = 0;\nint VAR22 = VAR23;\nstruct pt_regs *VAR24 = FUN2();\nstruct {\nstruct elfhdr VAR25;\nstruct elfhdr VAR26;\n} *VAR27;\nstruct arch_elf_state VAR28 = VAR29;\nVAR27 = FUN3(sizeof(*VAR27), VAR30);\nif (!VAR27) {\nVAR13 = -VAR31;\ngoto VAR32;\n}\nVAR27->VAR25 = *((struct VAR33 *)VAR1->VAR34);\nVAR13 = -VAR35;\nif (FUN4(VAR27->VAR25.VAR36, VAR37, VAR38) != 0)\ngoto VAR39;\nif (VAR27->VAR25.VAR40 != VAR41 && VAR27->VAR25.VAR40 != VAR42)\ngoto VAR39;\nif (!FUN5(&VAR27->VAR25))\ngoto VAR39;\nif (!VAR1->VAR43->VAR44->VAR45)\ngoto VAR39;\nVAR9 = FUN6(&VAR27->VAR25, VAR1->VAR43);\nif (!VAR9)\ngoto VAR39;\nVAR8 = VAR9;\nVAR11 = 0;\nVAR12 = 0;\nVAR17 = ~0UL;\nVAR18 = 0;\nVAR19 = 0;\nVAR20 = 0;\nfor (VAR14 = 0; VAR14 < VAR27->VAR25.VAR46; VAR14++) {\nif (VAR8->VAR47 == VAR48) {\nVAR13 = -VAR35;\nif (VAR8->VAR49 > VAR50 ||\nVAR8->VAR49 < 2)\ngoto VAR51;\nVAR13 = -VAR31;\nVAR6 = FUN3(VAR8->VAR49,\nVAR30);\nif (!VAR6)\ngoto VAR51;\nVAR13 = FUN7(VAR1->VAR43, VAR8->VAR52,\nVAR6,\nVAR8->VAR49);\nif (VAR13 != VAR8->VAR49) {\nif (VAR13 >= 0)\nVAR13 = -VAR53;\ngoto VAR54;\n}\nVAR13 = -VAR35;\nif (VAR6[VAR8->VAR49 - 1] != )\ngoto VAR54;\nVAR2 = FUN8(VAR6);\nVAR13 = FUN9(VAR2);\nif (FUN10(VAR2))\ngoto VAR54;\nFUN11(VAR1, VAR2);\nVAR13 = FUN7(VAR2, 0, VAR1->VAR34,\nVAR55);\nif (VAR13 != VAR55) {\nif (VAR13 >= 0)\nVAR13 = -VAR53;\ngoto VAR56;\n}\nVAR27->VAR26 = *((struct VAR33 *)VAR1->VAR34);\nbreak;\n}\nVAR8++;\n}\nVAR8 = VAR9;\nfor (VAR14 = 0; VAR14 < VAR27->VAR25.VAR46; VAR14++, VAR8++)\nswitch (VAR8->VAR47) {\ncase VAR57:\nif (VAR8->VAR58 & VAR59)\nVAR22 = VAR60;\nelse\nVAR22 = VAR61;\nbreak;\ncase VAR62 ... VAR63:\nVAR13 = FUN12(&VAR27->VAR25, VAR8,\nVAR1->VAR43, false,\n&VAR28);\nif (VAR13)\ngoto VAR56;\nbreak;\n}\nif (VAR6) {\nVAR13 = -VAR64;\nif (FUN4(VAR27->VAR26.VAR36, VAR37, VAR38) != 0)\ngoto VAR56;\nif (!FUN5(&VAR27->VAR26))\ngoto VAR56;\nVAR10 = FUN6(&VAR27->VAR26,\nVAR2);\nif (!VAR10)\ngoto VAR56;\nVAR8 = VAR10;\nfor (VAR14 = 0; VAR14 < VAR27->VAR26.VAR46; VAR14++, VAR8++)\nswitch (VAR8->VAR47) {\ncase VAR62 ... VAR63:\nVAR13 = FUN12(&VAR27->VAR26,\nVAR8, VAR2,\ntrue, &VAR28);\nif (VAR13)\ngoto VAR56;\nbreak;\n}\n}\nVAR13 = FUN13(&VAR27->VAR25, !!VAR2, &VAR28);\nif (VAR13)\ngoto VAR56;\nVAR13 = FUN14(VAR1);\nif (VAR13)\ngoto VAR56;\nFUN15(VAR27->VAR25, &VAR28);\nif (FUN16(VAR27->VAR25, VAR22))\nVAR65->VAR66 |= VAR67;\nif (!(VAR65->VAR66 & VAR68) && VAR69)\nVAR65->VAR70 |= VAR71;\nFUN17(VAR1);\nVAR13 = FUN18(VAR1, FUN19(VAR72),\nVAR22);\nif (VAR13 < 0)\ngoto VAR56;\nVAR65->VAR73->VAR74 = VAR1->VAR75;\nfor(VAR14 = 0, VAR8 = VAR9;\nVAR14 < VAR27->VAR25.VAR46; VAR14++, VAR8++) {\nint VAR76 = 0, VAR77;\nunsigned long VAR78, VAR79;\nunsigned long VAR80 = 0;\nif (VAR8->VAR47 != VAR81)\ncontinue;\nif (FUN20 (VAR12 > VAR11)) {\nunsigned long VAR82;\nVAR13 = FUN21(VAR11 + VAR4,\nVAR12 + VAR4);\nif (VAR13)\ngoto VAR56;\nVAR82 = FUN22(VAR11);\nif (VAR82) {\nVAR82 = VAR83 - VAR82;\nif (VAR82 > VAR12 - VAR11)\nVAR82 = VAR12 - VAR11;\nif (FUN23((void VAR84 *)VAR11 +\nVAR4, VAR82)) {\n}\n}\n}\nif (VAR8->VAR58 & VAR85)\nVAR76 |= VAR86;\nif (VAR8->VAR58 & VAR87)\nVAR76 |= VAR88;\nif (VAR8->VAR58 & VAR59)\nVAR76 |= VAR89;\nVAR77 = VAR90 | VAR91 | VAR92;\nVAR79 = VAR8->VAR93;\nif (VAR27->VAR25.VAR40 == VAR41 || VAR5) {\nVAR77 |= VAR94;\n} else if (VAR27->VAR25.VAR40 == VAR42) {\n#ifdef VAR95\nif (VAR65->VAR70 & VAR71)\nVAR4 = 0;\nelse\nVAR4 = FUN24(VAR96 - VAR79);\n#else\nVAR4 = FUN24(VAR96 - VAR79);\n#VAR97\nVAR80 = FUN25(VAR9,\nVAR27->VAR25.VAR46);\nif (!VAR80) {\nVAR7 = -VAR98;\ngoto VAR56;\n}\n}\nVAR7 = FUN26(VAR1->VAR43, VAR4 + VAR79, VAR8,\nVAR76, VAR77, VAR80);\nif (FUN27(VAR7)) {\nVAR13 = FUN10((void *)VAR7) ?\nFUN9((void*)VAR7) : -VAR98;\ngoto VAR56;\n}\nif (!VAR5) {\nVAR5 = 1;\nVAR3 = (VAR8->VAR93 - VAR8->VAR52);\nif (VAR27->VAR25.VAR40 == VAR42) {\nVAR4 += VAR7 -\nFUN24(VAR4 + VAR79);\nVAR3 += VAR4;\nVAR99 = VAR4;\n}\n}\nVAR78 = VAR8->VAR93;\nif (VAR78 < VAR17)\nVAR17 = VAR78;\nif (VAR19 < VAR78)\nVAR19 = VAR78;\nif (FUN27(VAR78) || VAR8->VAR49 > VAR8->VAR100 ||\nVAR8->VAR100 > VAR101 ||\nVAR101 - VAR8->VAR100 < VAR78) {\nVAR13 = -VAR98;\ngoto VAR56;\n}\nVAR78 = VAR8->VAR93 + VAR8->VAR49;\nif (VAR78 > VAR11)\nVAR11 = VAR78;\nif ((VAR8->VAR58 & VAR59) && VAR18 < VAR78)\nVAR18 = VAR78;\nif (VAR20 < VAR78)\nVAR20 = VAR78;\nVAR78 = VAR8->VAR93 + VAR8->VAR100;\nif (VAR78 > VAR12)\nVAR12 = VAR78;\n}\nVAR27->VAR25.VAR102 += VAR4;\nVAR11 += VAR4;\nVAR12 += VAR4;\nVAR17 += VAR4;\nVAR18 += VAR4;\nVAR19 += VAR4;\nVAR20 += VAR4;\nVAR13 = FUN21(VAR11, VAR12);\nif (VAR13)\ngoto VAR56;\nif (FUN28(VAR11 != VAR12) && FUN20(FUN29(VAR11))) {\nVAR13 = -VAR103; \ngoto VAR56;\n}\nif (VAR6) {\nunsigned long VAR104 = 0;\nVAR15 = FUN30(&VAR27->VAR26,\nVAR2,\n&VAR104,\nVAR4, VAR10);\nif (!FUN10((void *)VAR15)) {\nVAR16 = VAR15;\nVAR15 += VAR27->VAR26.VAR102;\n}\nif (FUN27(VAR15)) {\nVAR13 = FUN10((void *)VAR15) ?\n(int)VAR15 : -VAR98;\ngoto VAR56;\n}\nVAR99 = VAR16;\nFUN31(VAR2);\nFUN32(VAR2);\nFUN33(VAR6);\n} else {\nVAR15 = VAR27->VAR25.VAR102;\nif (FUN27(VAR15)) {\nVAR13 = -VAR98;\ngoto VAR56;\n}\n}\nFUN33(VAR10);\nFUN33(VAR9);\nFUN34(&VAR105);\n#ifdef VAR106\nVAR13 = FUN35(VAR1, !!VAR6);\nif (VAR13 < 0)\ngoto VAR39;\n#VAR97 \nFUN36(VAR1);\nVAR13 = FUN37(VAR1, &VAR27->VAR25,\nVAR3, VAR16);\nif (VAR13 < 0)\ngoto VAR39;\nVAR65->VAR73->VAR18 = VAR18;\nVAR65->VAR73->VAR17 = VAR17;\nVAR65->VAR73->VAR19 = VAR19;\nVAR65->VAR73->VAR20 = VAR20;\nVAR65->VAR73->VAR74 = VAR1->VAR75;\n#ifdef VAR107\nif ((VAR65->VAR70 & VAR71) && (VAR69 > 1)) {\nVAR65->VAR73->VAR108 = VAR65->VAR73->VAR109 =\nFUN38(VAR65->VAR73);\n#ifdef VAR110\nVAR65->VAR111 = 1;\n#VAR97\n}\n#VAR97\nif (VAR65->VAR66 & VAR112) {\nVAR7 = FUN39(NULL, 0, VAR113, VAR86 | VAR89,\nVAR94 | VAR90, 0);\n}\n#ifdef VAR114\nFUN40(VAR24, VAR99);\n#VAR97\nFUN41(VAR24, VAR15, VAR1->VAR75);\nVAR13 = 0;\nVAR39:\nFUN33(VAR27);\nVAR32:\nreturn VAR13;\nVAR56:\nFUN33(VAR10);\nFUN31(VAR2);\nif (VAR2)\nFUN32(VAR2);\nVAR54:\nFUN33(VAR6);\nVAR51:\nFUN33(VAR9);\ngoto VAR39;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct linux_binprm *VAR1)\n{\nstruct file *VAR2 = NULL; \nunsigned long VAR3 = 0, VAR4 = 0;\nint VAR5 = 0;\nchar * VAR6 = NULL;\nunsigned long VAR7;\nstruct elf_phdr *VAR8, *VAR9, *VAR10 = NULL;\nunsigned long VAR11, VAR12;\nint VAR13, VAR14;\nunsigned long VAR15;\nunsigned long VAR16 = 0;\nunsigned long VAR17, VAR18, VAR19, VAR20;\nunsigned long reloc_func_desc VAR21 = 0;\nint VAR22 = VAR23;\nstruct pt_regs *VAR24 = FUN2();\nstruct {\nstruct elfhdr VAR25;\nstruct elfhdr VAR26;\n} *VAR27;\nstruct arch_elf_state VAR28 = VAR29;\nVAR27 = FUN3(sizeof(*VAR27), VAR30);\nif (!VAR27) {\nVAR13 = -VAR31;\ngoto VAR32;\n}\nVAR27->VAR25 = *((struct VAR33 *)VAR1->VAR34);\nVAR13 = -VAR35;\nif (FUN4(VAR27->VAR25.VAR36, VAR37, VAR38) != 0)\ngoto VAR39;\nif (VAR27->VAR25.VAR40 != VAR41 && VAR27->VAR25.VAR40 != VAR42)\ngoto VAR39;\nif (!FUN5(&VAR27->VAR25))\ngoto VAR39;\nif (!VAR1->VAR43->VAR44->VAR45)\ngoto VAR39;\nVAR9 = FUN6(&VAR27->VAR25, VAR1->VAR43);\nif (!VAR9)\ngoto VAR39;\nVAR8 = VAR9;\nVAR11 = 0;\nVAR12 = 0;\nVAR17 = ~0UL;\nVAR18 = 0;\nVAR19 = 0;\nVAR20 = 0;\nfor (VAR14 = 0; VAR14 < VAR27->VAR25.VAR46; VAR14++) {\nif (VAR8->VAR47 == VAR48) {\nVAR13 = -VAR35;\nif (VAR8->VAR49 > VAR50 ||\nVAR8->VAR49 < 2)\ngoto VAR51;\nVAR13 = -VAR31;\nVAR6 = FUN3(VAR8->VAR49,\nVAR30);\nif (!VAR6)\ngoto VAR51;\nVAR13 = FUN7(VAR1->VAR43, VAR8->VAR52,\nVAR6,\nVAR8->VAR49);\nif (VAR13 != VAR8->VAR49) {\nif (VAR13 >= 0)\nVAR13 = -VAR53;\ngoto VAR54;\n}\nVAR13 = -VAR35;\nif (VAR6[VAR8->VAR49 - 1] != )\ngoto VAR54;\nVAR2 = FUN8(VAR6);\nVAR13 = FUN9(VAR2);\nif (FUN10(VAR2))\ngoto VAR54;\nFUN11(VAR1, VAR2);\nVAR13 = FUN7(VAR2, 0, VAR1->VAR34,\nVAR55);\nif (VAR13 != VAR55) {\nif (VAR13 >= 0)\nVAR13 = -VAR53;\ngoto VAR56;\n}\nVAR27->VAR26 = *((struct VAR33 *)VAR1->VAR34);\nbreak;\n}\nVAR8++;\n}\nVAR8 = VAR9;\nfor (VAR14 = 0; VAR14 < VAR27->VAR25.VAR46; VAR14++, VAR8++)\nswitch (VAR8->VAR47) {\ncase VAR57:\nif (VAR8->VAR58 & VAR59)\nVAR22 = VAR60;\nelse\nVAR22 = VAR61;\nbreak;\ncase VAR62 ... VAR63:\nVAR13 = FUN12(&VAR27->VAR25, VAR8,\nVAR1->VAR43, false,\n&VAR28);\nif (VAR13)\ngoto VAR56;\nbreak;\n}\nif (VAR6) {\nVAR13 = -VAR64;\nif (FUN4(VAR27->VAR26.VAR36, VAR37, VAR38) != 0)\ngoto VAR56;\nif (!FUN5(&VAR27->VAR26))\ngoto VAR56;\nVAR10 = FUN6(&VAR27->VAR26,\nVAR2);\nif (!VAR10)\ngoto VAR56;\nVAR8 = VAR10;\nfor (VAR14 = 0; VAR14 < VAR27->VAR26.VAR46; VAR14++, VAR8++)\nswitch (VAR8->VAR47) {\ncase VAR62 ... VAR63:\nVAR13 = FUN12(&VAR27->VAR26,\nVAR8, VAR2,\ntrue, &VAR28);\nif (VAR13)\ngoto VAR56;\nbreak;\n}\n}\nVAR13 = FUN13(&VAR27->VAR25, !!VAR2, &VAR28);\nif (VAR13)\ngoto VAR56;\nVAR13 = FUN14(VAR1);\nif (VAR13)\ngoto VAR56;\nFUN15(VAR27->VAR25, &VAR28);\nif (FUN16(VAR27->VAR25, VAR22))\nVAR65->VAR66 |= VAR67;\nif (!(VAR65->VAR66 & VAR68) && VAR69)\nVAR65->VAR70 |= VAR71;\nFUN17(VAR1);\nVAR13 = FUN18(VAR1, FUN19(VAR72),\nVAR22);\nif (VAR13 < 0)\ngoto VAR56;\nVAR65->VAR73->VAR74 = VAR1->VAR75;\nfor(VAR14 = 0, VAR8 = VAR9;\nVAR14 < VAR27->VAR25.VAR46; VAR14++, VAR8++) {\nint VAR76 = 0, VAR77;\nunsigned long VAR78, VAR79;\nif (VAR8->VAR47 != VAR80)\ncontinue;\nif (FUN20 (VAR12 > VAR11)) {\nunsigned long VAR81;\nVAR13 = FUN21(VAR11 + VAR4,\nVAR12 + VAR4);\nif (VAR13)\ngoto VAR56;\nVAR81 = FUN22(VAR11);\nif (VAR81) {\nVAR81 = VAR82 - VAR81;\nif (VAR81 > VAR12 - VAR11)\nVAR81 = VAR12 - VAR11;\nif (FUN23((void VAR83 *)VAR11 +\nVAR4, VAR81)) {\n}\n}\n}\nif (VAR8->VAR58 & VAR84)\nVAR76 |= VAR85;\nif (VAR8->VAR58 & VAR86)\nVAR76 |= VAR87;\nif (VAR8->VAR58 & VAR59)\nVAR76 |= VAR88;\nVAR77 = VAR89 | VAR90 | VAR91;\nVAR79 = VAR8->VAR92;\nif (VAR27->VAR25.VAR40 == VAR41 || VAR5) {\nVAR77 |= VAR93;\n} else if (VAR27->VAR25.VAR40 == VAR42) {\n#ifdef VAR94\nif (VAR65->VAR70 & VAR71)\nVAR4 = 0;\nelse\nVAR4 = FUN24(VAR95 - VAR79);\n#else\nVAR4 = FUN24(VAR95 - VAR79);\n#VAR96\n}\nVAR7 = FUN25(VAR1->VAR43, VAR4 + VAR79, VAR8,\nVAR76, VAR77, 0);\nif (FUN26(VAR7)) {\nVAR13 = FUN10((void *)VAR7) ?\nFUN9((void*)VAR7) : -VAR97;\ngoto VAR56;\n}\nif (!VAR5) {\nVAR5 = 1;\nVAR3 = (VAR8->VAR92 - VAR8->VAR52);\nif (VAR27->VAR25.VAR40 == VAR42) {\nVAR4 += VAR7 -\nFUN24(VAR4 + VAR79);\nVAR3 += VAR4;\nVAR98 = VAR4;\n}\n}\nVAR78 = VAR8->VAR92;\nif (VAR78 < VAR17)\nVAR17 = VAR78;\nif (VAR19 < VAR78)\nVAR19 = VAR78;\nif (FUN26(VAR78) || VAR8->VAR49 > VAR8->VAR99 ||\nVAR8->VAR99 > VAR100 ||\nVAR100 - VAR8->VAR99 < VAR78) {\nVAR13 = -VAR97;\ngoto VAR56;\n}\nVAR78 = VAR8->VAR92 + VAR8->VAR49;\nif (VAR78 > VAR11)\nVAR11 = VAR78;\nif ((VAR8->VAR58 & VAR59) && VAR18 < VAR78)\nVAR18 = VAR78;\nif (VAR20 < VAR78)\nVAR20 = VAR78;\nVAR78 = VAR8->VAR92 + VAR8->VAR99;\nif (VAR78 > VAR12)\nVAR12 = VAR78;\n}\nVAR27->VAR25.VAR101 += VAR4;\nVAR11 += VAR4;\nVAR12 += VAR4;\nVAR17 += VAR4;\nVAR18 += VAR4;\nVAR19 += VAR4;\nVAR20 += VAR4;\nVAR13 = FUN21(VAR11, VAR12);\nif (VAR13)\ngoto VAR56;\nif (FUN27(VAR11 != VAR12) && FUN20(FUN28(VAR11))) {\nVAR13 = -VAR102; \ngoto VAR56;\n}\nif (VAR6) {\nunsigned long VAR103 = 0;\nVAR15 = FUN29(&VAR27->VAR26,\nVAR2,\n&VAR103,\nVAR4, VAR10);\nif (!FUN10((void *)VAR15)) {\nVAR16 = VAR15;\nVAR15 += VAR27->VAR26.VAR101;\n}\nif (FUN26(VAR15)) {\nVAR13 = FUN10((void *)VAR15) ?\n(int)VAR15 : -VAR97;\ngoto VAR56;\n}\nVAR98 = VAR16;\nFUN30(VAR2);\nFUN31(VAR2);\nFUN32(VAR6);\n} else {\nVAR15 = VAR27->VAR25.VAR101;\nif (FUN26(VAR15)) {\nVAR13 = -VAR97;\ngoto VAR56;\n}\n}\nFUN32(VAR10);\nFUN32(VAR9);\nFUN33(&VAR104);\n#ifdef VAR105\nVAR13 = FUN34(VAR1, !!VAR6);\nif (VAR13 < 0)\ngoto VAR39;\n#VAR96 \nFUN35(VAR1);\nVAR13 = FUN36(VAR1, &VAR27->VAR25,\nVAR3, VAR16);\nif (VAR13 < 0)\ngoto VAR39;\nVAR65->VAR73->VAR18 = VAR18;\nVAR65->VAR73->VAR17 = VAR17;\nVAR65->VAR73->VAR19 = VAR19;\nVAR65->VAR73->VAR20 = VAR20;\nVAR65->VAR73->VAR74 = VAR1->VAR75;\n#ifdef VAR106\nif ((VAR65->VAR70 & VAR71) && (VAR69 > 1)) {\nVAR65->VAR73->VAR107 = VAR65->VAR73->VAR108 =\nFUN37(VAR65->VAR73);\n#ifdef VAR109\nVAR65->VAR110 = 1;\n#VAR96\n}\n#VAR96\nif (VAR65->VAR66 & VAR111) {\nVAR7 = FUN38(NULL, 0, VAR112, VAR85 | VAR88,\nVAR93 | VAR89, 0);\n}\n#ifdef VAR113\nFUN39(VAR24, VAR98);\n#VAR96\nFUN40(VAR24, VAR15, VAR1->VAR75);\nVAR13 = 0;\nVAR39:\nFUN32(VAR27);\nVAR32:\nreturn VAR13;\nVAR56:\nFUN32(VAR10);\nFUN30(VAR2);\nif (VAR2)\nFUN31(VAR2);\nVAR54:\nFUN32(VAR6);\nVAR51:\nFUN32(VAR9);\ngoto VAR39;\n}\n",
      "code_after_change_raw": "static int load_elf_binary(struct linux_binprm *bprm)\n{\nstruct file *interpreter = NULL; \nunsigned long load_addr = 0, load_bias = 0;\nint load_addr_set = 0;\nchar * elf_interpreter = NULL;\nunsigned long error;\nstruct elf_phdr *elf_ppnt, *elf_phdata, *interp_elf_phdata = NULL;\nunsigned long elf_bss, elf_brk;\nint retval, i;\nunsigned long elf_entry;\nunsigned long interp_load_addr = 0;\nunsigned long start_code, end_code, start_data, end_data;\nunsigned long reloc_func_desc __maybe_unused = 0;\nint executable_stack = EXSTACK_DEFAULT;\nstruct pt_regs *regs = current_pt_regs();\nstruct {\nstruct elfhdr elf_ex;\nstruct elfhdr interp_elf_ex;\n} *loc;\nstruct arch_elf_state arch_state = INIT_ARCH_ELF_STATE;\nloc = kmalloc(sizeof(*loc), GFP_KERNEL);\nif (!loc) {\nretval = -ENOMEM;\ngoto out_ret;\n}\nloc->elf_ex = *((struct elfhdr *)bprm->buf);\nretval = -ENOEXEC;\nif (memcmp(loc->elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\ngoto out;\nif (loc->elf_ex.e_type != ET_EXEC && loc->elf_ex.e_type != ET_DYN)\ngoto out;\nif (!elf_check_arch(&loc->elf_ex))\ngoto out;\nif (!bprm->file->f_op->mmap)\ngoto out;\nelf_phdata = load_elf_phdrs(&loc->elf_ex, bprm->file);\nif (!elf_phdata)\ngoto out;\nelf_ppnt = elf_phdata;\nelf_bss = 0;\nelf_brk = 0;\nstart_code = ~0UL;\nend_code = 0;\nstart_data = 0;\nend_data = 0;\nfor (i = 0; i < loc->elf_ex.e_phnum; i++) {\nif (elf_ppnt->p_type == PT_INTERP) {\nretval = -ENOEXEC;\nif (elf_ppnt->p_filesz > PATH_MAX ||\nelf_ppnt->p_filesz < 2)\ngoto out_free_ph;\nretval = -ENOMEM;\nelf_interpreter = kmalloc(elf_ppnt->p_filesz,\nGFP_KERNEL);\nif (!elf_interpreter)\ngoto out_free_ph;\nretval = kernel_read(bprm->file, elf_ppnt->p_offset,\nelf_interpreter,\nelf_ppnt->p_filesz);\nif (retval != elf_ppnt->p_filesz) {\nif (retval >= 0)\nretval = -EIO;\ngoto out_free_interp;\n}\nretval = -ENOEXEC;\nif (elf_interpreter[elf_ppnt->p_filesz - 1] != '\\0')\ngoto out_free_interp;\ninterpreter = open_exec(elf_interpreter);\nretval = PTR_ERR(interpreter);\nif (IS_ERR(interpreter))\ngoto out_free_interp;\nwould_dump(bprm, interpreter);\nretval = kernel_read(interpreter, 0, bprm->buf,\nBINPRM_BUF_SIZE);\nif (retval != BINPRM_BUF_SIZE) {\nif (retval >= 0)\nretval = -EIO;\ngoto out_free_dentry;\n}\nloc->interp_elf_ex = *((struct elfhdr *)bprm->buf);\nbreak;\n}\nelf_ppnt++;\n}\nelf_ppnt = elf_phdata;\nfor (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++)\nswitch (elf_ppnt->p_type) {\ncase PT_GNU_STACK:\nif (elf_ppnt->p_flags & PF_X)\nexecutable_stack = EXSTACK_ENABLE_X;\nelse\nexecutable_stack = EXSTACK_DISABLE_X;\nbreak;\ncase PT_LOPROC ... PT_HIPROC:\nretval = arch_elf_pt_proc(&loc->elf_ex, elf_ppnt,\nbprm->file, false,\n&arch_state);\nif (retval)\ngoto out_free_dentry;\nbreak;\n}\nif (elf_interpreter) {\nretval = -ELIBBAD;\nif (memcmp(loc->interp_elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\ngoto out_free_dentry;\nif (!elf_check_arch(&loc->interp_elf_ex))\ngoto out_free_dentry;\ninterp_elf_phdata = load_elf_phdrs(&loc->interp_elf_ex,\ninterpreter);\nif (!interp_elf_phdata)\ngoto out_free_dentry;\nelf_ppnt = interp_elf_phdata;\nfor (i = 0; i < loc->interp_elf_ex.e_phnum; i++, elf_ppnt++)\nswitch (elf_ppnt->p_type) {\ncase PT_LOPROC ... PT_HIPROC:\nretval = arch_elf_pt_proc(&loc->interp_elf_ex,\nelf_ppnt, interpreter,\ntrue, &arch_state);\nif (retval)\ngoto out_free_dentry;\nbreak;\n}\n}\nretval = arch_check_elf(&loc->elf_ex, !!interpreter, &arch_state);\nif (retval)\ngoto out_free_dentry;\nretval = flush_old_exec(bprm);\nif (retval)\ngoto out_free_dentry;\nSET_PERSONALITY2(loc->elf_ex, &arch_state);\nif (elf_read_implies_exec(loc->elf_ex, executable_stack))\ncurrent->personality |= READ_IMPLIES_EXEC;\nif (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)\ncurrent->flags |= PF_RANDOMIZE;\nsetup_new_exec(bprm);\nretval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP),\nexecutable_stack);\nif (retval < 0)\ngoto out_free_dentry;\ncurrent->mm->start_stack = bprm->p;\nfor(i = 0, elf_ppnt = elf_phdata;\ni < loc->elf_ex.e_phnum; i++, elf_ppnt++) {\nint elf_prot = 0, elf_flags;\nunsigned long k, vaddr;\nunsigned long total_size = 0;\nif (elf_ppnt->p_type != PT_LOAD)\ncontinue;\nif (unlikely (elf_brk > elf_bss)) {\nunsigned long nbyte;\nretval = set_brk(elf_bss + load_bias,\nelf_brk + load_bias);\nif (retval)\ngoto out_free_dentry;\nnbyte = ELF_PAGEOFFSET(elf_bss);\nif (nbyte) {\nnbyte = ELF_MIN_ALIGN - nbyte;\nif (nbyte > elf_brk - elf_bss)\nnbyte = elf_brk - elf_bss;\nif (clear_user((void __user *)elf_bss +\nload_bias, nbyte)) {\n}\n}\n}\nif (elf_ppnt->p_flags & PF_R)\nelf_prot |= PROT_READ;\nif (elf_ppnt->p_flags & PF_W)\nelf_prot |= PROT_WRITE;\nif (elf_ppnt->p_flags & PF_X)\nelf_prot |= PROT_EXEC;\nelf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE;\nvaddr = elf_ppnt->p_vaddr;\nif (loc->elf_ex.e_type == ET_EXEC || load_addr_set) {\nelf_flags |= MAP_FIXED;\n} else if (loc->elf_ex.e_type == ET_DYN) {\n#ifdef CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE\nif (current->flags & PF_RANDOMIZE)\nload_bias = 0;\nelse\nload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#else\nload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#endif\ntotal_size = total_mapping_size(elf_phdata,\nloc->elf_ex.e_phnum);\nif (!total_size) {\nerror = -EINVAL;\ngoto out_free_dentry;\n}\n}\nerror = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,\nelf_prot, elf_flags, total_size);\nif (BAD_ADDR(error)) {\nretval = IS_ERR((void *)error) ?\nPTR_ERR((void*)error) : -EINVAL;\ngoto out_free_dentry;\n}\nif (!load_addr_set) {\nload_addr_set = 1;\nload_addr = (elf_ppnt->p_vaddr - elf_ppnt->p_offset);\nif (loc->elf_ex.e_type == ET_DYN) {\nload_bias += error -\nELF_PAGESTART(load_bias + vaddr);\nload_addr += load_bias;\nreloc_func_desc = load_bias;\n}\n}\nk = elf_ppnt->p_vaddr;\nif (k < start_code)\nstart_code = k;\nif (start_data < k)\nstart_data = k;\nif (BAD_ADDR(k) || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||\nelf_ppnt->p_memsz > TASK_SIZE ||\nTASK_SIZE - elf_ppnt->p_memsz < k) {\nretval = -EINVAL;\ngoto out_free_dentry;\n}\nk = elf_ppnt->p_vaddr + elf_ppnt->p_filesz;\nif (k > elf_bss)\nelf_bss = k;\nif ((elf_ppnt->p_flags & PF_X) && end_code < k)\nend_code = k;\nif (end_data < k)\nend_data = k;\nk = elf_ppnt->p_vaddr + elf_ppnt->p_memsz;\nif (k > elf_brk)\nelf_brk = k;\n}\nloc->elf_ex.e_entry += load_bias;\nelf_bss += load_bias;\nelf_brk += load_bias;\nstart_code += load_bias;\nend_code += load_bias;\nstart_data += load_bias;\nend_data += load_bias;\nretval = set_brk(elf_bss, elf_brk);\nif (retval)\ngoto out_free_dentry;\nif (likely(elf_bss != elf_brk) && unlikely(padzero(elf_bss))) {\nretval = -EFAULT; \ngoto out_free_dentry;\n}\nif (elf_interpreter) {\nunsigned long interp_map_addr = 0;\nelf_entry = load_elf_interp(&loc->interp_elf_ex,\ninterpreter,\n&interp_map_addr,\nload_bias, interp_elf_phdata);\nif (!IS_ERR((void *)elf_entry)) {\ninterp_load_addr = elf_entry;\nelf_entry += loc->interp_elf_ex.e_entry;\n}\nif (BAD_ADDR(elf_entry)) {\nretval = IS_ERR((void *)elf_entry) ?\n(int)elf_entry : -EINVAL;\ngoto out_free_dentry;\n}\nreloc_func_desc = interp_load_addr;\nallow_write_access(interpreter);\nfput(interpreter);\nkfree(elf_interpreter);\n} else {\nelf_entry = loc->elf_ex.e_entry;\nif (BAD_ADDR(elf_entry)) {\nretval = -EINVAL;\ngoto out_free_dentry;\n}\n}\nkfree(interp_elf_phdata);\nkfree(elf_phdata);\nset_binfmt(&elf_format);\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\nretval = arch_setup_additional_pages(bprm, !!elf_interpreter);\nif (retval < 0)\ngoto out;\n#endif \ninstall_exec_creds(bprm);\nretval = create_elf_tables(bprm, &loc->elf_ex,\nload_addr, interp_load_addr);\nif (retval < 0)\ngoto out;\ncurrent->mm->end_code = end_code;\ncurrent->mm->start_code = start_code;\ncurrent->mm->start_data = start_data;\ncurrent->mm->end_data = end_data;\ncurrent->mm->start_stack = bprm->p;\n#ifdef arch_randomize_brk\nif ((current->flags & PF_RANDOMIZE) && (randomize_va_space > 1)) {\ncurrent->mm->brk = current->mm->start_brk =\narch_randomize_brk(current->mm);\n#ifdef CONFIG_COMPAT_BRK\ncurrent->brk_randomized = 1;\n#endif\n}\n#endif\nif (current->personality & MMAP_PAGE_ZERO) {\nerror = vm_mmap(NULL, 0, PAGE_SIZE, PROT_READ | PROT_EXEC,\nMAP_FIXED | MAP_PRIVATE, 0);\n}\n#ifdef ELF_PLAT_INIT\nELF_PLAT_INIT(regs, reloc_func_desc);\n#endif\nstart_thread(regs, elf_entry, bprm->p);\nretval = 0;\nout:\nkfree(loc);\nout_ret:\nreturn retval;\nout_free_dentry:\nkfree(interp_elf_phdata);\nallow_write_access(interpreter);\nif (interpreter)\nfput(interpreter);\nout_free_interp:\nkfree(elf_interpreter);\nout_free_ph:\nkfree(elf_phdata);\ngoto out;\n}\n",
      "code_before_change_raw": "static int load_elf_binary(struct linux_binprm *bprm)\n{\nstruct file *interpreter = NULL; \nunsigned long load_addr = 0, load_bias = 0;\nint load_addr_set = 0;\nchar * elf_interpreter = NULL;\nunsigned long error;\nstruct elf_phdr *elf_ppnt, *elf_phdata, *interp_elf_phdata = NULL;\nunsigned long elf_bss, elf_brk;\nint retval, i;\nunsigned long elf_entry;\nunsigned long interp_load_addr = 0;\nunsigned long start_code, end_code, start_data, end_data;\nunsigned long reloc_func_desc __maybe_unused = 0;\nint executable_stack = EXSTACK_DEFAULT;\nstruct pt_regs *regs = current_pt_regs();\nstruct {\nstruct elfhdr elf_ex;\nstruct elfhdr interp_elf_ex;\n} *loc;\nstruct arch_elf_state arch_state = INIT_ARCH_ELF_STATE;\nloc = kmalloc(sizeof(*loc), GFP_KERNEL);\nif (!loc) {\nretval = -ENOMEM;\ngoto out_ret;\n}\nloc->elf_ex = *((struct elfhdr *)bprm->buf);\nretval = -ENOEXEC;\nif (memcmp(loc->elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\ngoto out;\nif (loc->elf_ex.e_type != ET_EXEC && loc->elf_ex.e_type != ET_DYN)\ngoto out;\nif (!elf_check_arch(&loc->elf_ex))\ngoto out;\nif (!bprm->file->f_op->mmap)\ngoto out;\nelf_phdata = load_elf_phdrs(&loc->elf_ex, bprm->file);\nif (!elf_phdata)\ngoto out;\nelf_ppnt = elf_phdata;\nelf_bss = 0;\nelf_brk = 0;\nstart_code = ~0UL;\nend_code = 0;\nstart_data = 0;\nend_data = 0;\nfor (i = 0; i < loc->elf_ex.e_phnum; i++) {\nif (elf_ppnt->p_type == PT_INTERP) {\nretval = -ENOEXEC;\nif (elf_ppnt->p_filesz > PATH_MAX ||\nelf_ppnt->p_filesz < 2)\ngoto out_free_ph;\nretval = -ENOMEM;\nelf_interpreter = kmalloc(elf_ppnt->p_filesz,\nGFP_KERNEL);\nif (!elf_interpreter)\ngoto out_free_ph;\nretval = kernel_read(bprm->file, elf_ppnt->p_offset,\nelf_interpreter,\nelf_ppnt->p_filesz);\nif (retval != elf_ppnt->p_filesz) {\nif (retval >= 0)\nretval = -EIO;\ngoto out_free_interp;\n}\nretval = -ENOEXEC;\nif (elf_interpreter[elf_ppnt->p_filesz - 1] != '\\0')\ngoto out_free_interp;\ninterpreter = open_exec(elf_interpreter);\nretval = PTR_ERR(interpreter);\nif (IS_ERR(interpreter))\ngoto out_free_interp;\nwould_dump(bprm, interpreter);\nretval = kernel_read(interpreter, 0, bprm->buf,\nBINPRM_BUF_SIZE);\nif (retval != BINPRM_BUF_SIZE) {\nif (retval >= 0)\nretval = -EIO;\ngoto out_free_dentry;\n}\nloc->interp_elf_ex = *((struct elfhdr *)bprm->buf);\nbreak;\n}\nelf_ppnt++;\n}\nelf_ppnt = elf_phdata;\nfor (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++)\nswitch (elf_ppnt->p_type) {\ncase PT_GNU_STACK:\nif (elf_ppnt->p_flags & PF_X)\nexecutable_stack = EXSTACK_ENABLE_X;\nelse\nexecutable_stack = EXSTACK_DISABLE_X;\nbreak;\ncase PT_LOPROC ... PT_HIPROC:\nretval = arch_elf_pt_proc(&loc->elf_ex, elf_ppnt,\nbprm->file, false,\n&arch_state);\nif (retval)\ngoto out_free_dentry;\nbreak;\n}\nif (elf_interpreter) {\nretval = -ELIBBAD;\nif (memcmp(loc->interp_elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\ngoto out_free_dentry;\nif (!elf_check_arch(&loc->interp_elf_ex))\ngoto out_free_dentry;\ninterp_elf_phdata = load_elf_phdrs(&loc->interp_elf_ex,\ninterpreter);\nif (!interp_elf_phdata)\ngoto out_free_dentry;\nelf_ppnt = interp_elf_phdata;\nfor (i = 0; i < loc->interp_elf_ex.e_phnum; i++, elf_ppnt++)\nswitch (elf_ppnt->p_type) {\ncase PT_LOPROC ... PT_HIPROC:\nretval = arch_elf_pt_proc(&loc->interp_elf_ex,\nelf_ppnt, interpreter,\ntrue, &arch_state);\nif (retval)\ngoto out_free_dentry;\nbreak;\n}\n}\nretval = arch_check_elf(&loc->elf_ex, !!interpreter, &arch_state);\nif (retval)\ngoto out_free_dentry;\nretval = flush_old_exec(bprm);\nif (retval)\ngoto out_free_dentry;\nSET_PERSONALITY2(loc->elf_ex, &arch_state);\nif (elf_read_implies_exec(loc->elf_ex, executable_stack))\ncurrent->personality |= READ_IMPLIES_EXEC;\nif (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)\ncurrent->flags |= PF_RANDOMIZE;\nsetup_new_exec(bprm);\nretval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP),\nexecutable_stack);\nif (retval < 0)\ngoto out_free_dentry;\ncurrent->mm->start_stack = bprm->p;\nfor(i = 0, elf_ppnt = elf_phdata;\ni < loc->elf_ex.e_phnum; i++, elf_ppnt++) {\nint elf_prot = 0, elf_flags;\nunsigned long k, vaddr;\nif (elf_ppnt->p_type != PT_LOAD)\ncontinue;\nif (unlikely (elf_brk > elf_bss)) {\nunsigned long nbyte;\nretval = set_brk(elf_bss + load_bias,\nelf_brk + load_bias);\nif (retval)\ngoto out_free_dentry;\nnbyte = ELF_PAGEOFFSET(elf_bss);\nif (nbyte) {\nnbyte = ELF_MIN_ALIGN - nbyte;\nif (nbyte > elf_brk - elf_bss)\nnbyte = elf_brk - elf_bss;\nif (clear_user((void __user *)elf_bss +\nload_bias, nbyte)) {\n}\n}\n}\nif (elf_ppnt->p_flags & PF_R)\nelf_prot |= PROT_READ;\nif (elf_ppnt->p_flags & PF_W)\nelf_prot |= PROT_WRITE;\nif (elf_ppnt->p_flags & PF_X)\nelf_prot |= PROT_EXEC;\nelf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE;\nvaddr = elf_ppnt->p_vaddr;\nif (loc->elf_ex.e_type == ET_EXEC || load_addr_set) {\nelf_flags |= MAP_FIXED;\n} else if (loc->elf_ex.e_type == ET_DYN) {\n#ifdef CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE\nif (current->flags & PF_RANDOMIZE)\nload_bias = 0;\nelse\nload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#else\nload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#endif\n}\nerror = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,\nelf_prot, elf_flags, 0);\nif (BAD_ADDR(error)) {\nretval = IS_ERR((void *)error) ?\nPTR_ERR((void*)error) : -EINVAL;\ngoto out_free_dentry;\n}\nif (!load_addr_set) {\nload_addr_set = 1;\nload_addr = (elf_ppnt->p_vaddr - elf_ppnt->p_offset);\nif (loc->elf_ex.e_type == ET_DYN) {\nload_bias += error -\nELF_PAGESTART(load_bias + vaddr);\nload_addr += load_bias;\nreloc_func_desc = load_bias;\n}\n}\nk = elf_ppnt->p_vaddr;\nif (k < start_code)\nstart_code = k;\nif (start_data < k)\nstart_data = k;\nif (BAD_ADDR(k) || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||\nelf_ppnt->p_memsz > TASK_SIZE ||\nTASK_SIZE - elf_ppnt->p_memsz < k) {\nretval = -EINVAL;\ngoto out_free_dentry;\n}\nk = elf_ppnt->p_vaddr + elf_ppnt->p_filesz;\nif (k > elf_bss)\nelf_bss = k;\nif ((elf_ppnt->p_flags & PF_X) && end_code < k)\nend_code = k;\nif (end_data < k)\nend_data = k;\nk = elf_ppnt->p_vaddr + elf_ppnt->p_memsz;\nif (k > elf_brk)\nelf_brk = k;\n}\nloc->elf_ex.e_entry += load_bias;\nelf_bss += load_bias;\nelf_brk += load_bias;\nstart_code += load_bias;\nend_code += load_bias;\nstart_data += load_bias;\nend_data += load_bias;\nretval = set_brk(elf_bss, elf_brk);\nif (retval)\ngoto out_free_dentry;\nif (likely(elf_bss != elf_brk) && unlikely(padzero(elf_bss))) {\nretval = -EFAULT; \ngoto out_free_dentry;\n}\nif (elf_interpreter) {\nunsigned long interp_map_addr = 0;\nelf_entry = load_elf_interp(&loc->interp_elf_ex,\ninterpreter,\n&interp_map_addr,\nload_bias, interp_elf_phdata);\nif (!IS_ERR((void *)elf_entry)) {\ninterp_load_addr = elf_entry;\nelf_entry += loc->interp_elf_ex.e_entry;\n}\nif (BAD_ADDR(elf_entry)) {\nretval = IS_ERR((void *)elf_entry) ?\n(int)elf_entry : -EINVAL;\ngoto out_free_dentry;\n}\nreloc_func_desc = interp_load_addr;\nallow_write_access(interpreter);\nfput(interpreter);\nkfree(elf_interpreter);\n} else {\nelf_entry = loc->elf_ex.e_entry;\nif (BAD_ADDR(elf_entry)) {\nretval = -EINVAL;\ngoto out_free_dentry;\n}\n}\nkfree(interp_elf_phdata);\nkfree(elf_phdata);\nset_binfmt(&elf_format);\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\nretval = arch_setup_additional_pages(bprm, !!elf_interpreter);\nif (retval < 0)\ngoto out;\n#endif \ninstall_exec_creds(bprm);\nretval = create_elf_tables(bprm, &loc->elf_ex,\nload_addr, interp_load_addr);\nif (retval < 0)\ngoto out;\ncurrent->mm->end_code = end_code;\ncurrent->mm->start_code = start_code;\ncurrent->mm->start_data = start_data;\ncurrent->mm->end_data = end_data;\ncurrent->mm->start_stack = bprm->p;\n#ifdef arch_randomize_brk\nif ((current->flags & PF_RANDOMIZE) && (randomize_va_space > 1)) {\ncurrent->mm->brk = current->mm->start_brk =\narch_randomize_brk(current->mm);\n#ifdef CONFIG_COMPAT_BRK\ncurrent->brk_randomized = 1;\n#endif\n}\n#endif\nif (current->personality & MMAP_PAGE_ZERO) {\nerror = vm_mmap(NULL, 0, PAGE_SIZE, PROT_READ | PROT_EXEC,\nMAP_FIXED | MAP_PRIVATE, 0);\n}\n#ifdef ELF_PLAT_INIT\nELF_PLAT_INIT(regs, reloc_func_desc);\n#endif\nstart_thread(regs, elf_entry, bprm->p);\nretval = 0;\nout:\nkfree(loc);\nout_ret:\nreturn retval;\nout_free_dentry:\nkfree(interp_elf_phdata);\nallow_write_access(interpreter);\nif (interpreter)\nfput(interpreter);\nout_free_interp:\nkfree(elf_interpreter);\nout_free_ph:\nkfree(elf_phdata);\ngoto out;\n}\n"
    }
  ],
  "CVE-2017-12762": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper bounds checking when copying user-controlled data into a fixed-size buffer.",
        "trigger_condition": "User-supplied data exceeding the buffer size during the copy operation, leading to a buffer overflow vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code uses strcpy to copy user-controlled data into a buffer without verifying the length of the input data, potentially allowing an attacker to overwrite adjacent memory locations.",
        "solution": "To mitigate the vulnerability, it is necessary to ensure that the buffer is null-terminated within its bounds after copying user-controlled data. This prevents buffer overflow by guaranteeing that the copied data does not exceed the buffer size."
      },
      "GPT_analysis": "The modification is necessary to address a buffer overflow vulnerability in the code snippet. Specifically, the vulnerability arises from the use of the `strcpy` function to copy user-controlled data into a buffer of constant size (`bname`) without performing any length check. This can lead to a situation where the user-supplied data exceeds the buffer size, causing a buffer overflow and potentially allowing an attacker to overwrite adjacent memory locations.\n\nBy adding the line `bname[sizeof(bname)-1] = 0;` after the `copy_from_user` call for the `bname` buffer, we ensure that the buffer is null-terminated within its bounds, preventing any potential buffer overflow. This modification helps to mitigate the vulnerability and improve the security of the code snippet.",
      "GPT_purpose": "Handle ISDN ioctl commands for various operations on ISDN network interfaces and devices.",
      "GPT_function": "\n1. Handle ISDN ioctl commands for various ISDN network operations.\n2. Manage configuration variables for network interfaces.\n3. Add, delete, and get phone numbers associated with network interfaces.\n4. Set and get configurable parameters for network interfaces.\n5. Force dialing and hangup of network interfaces.\n6. Set verbose level and global mode for ISDN.\n7. Set rejection bus flag for specific drivers.\n8. Manage modem profiles for ISDN channels.\n9. Set and get MSN->EAZ mapping for a driver.\n10. Handle debugging variables and driver control commands.",
      "CVE_id": "CVE-2017-12762",
      "code_before_change": "static int\nisdn_ioctl(struct file *file, uint cmd, ulong arg)\n{\n\tuint minor = iminor(file_inode(file));\n\tisdn_ctrl c;\n\tint drvidx;\n\tint ret;\n\tint i;\n\tchar __user *p;\n\tchar *s;\n\tunion iocpar {\n\t\tchar name[10];\n\t\tchar bname[22];\n\t\tisdn_ioctl_struct iocts;\n\t\tisdn_net_ioctl_phone phone;\n\t\tisdn_net_ioctl_cfg cfg;\n\t} iocpar;\n\tvoid __user *argp = (void __user *)arg;\n\n#define name  iocpar.name\n#define bname iocpar.bname\n#define iocts iocpar.iocts\n#define phone iocpar.phone\n#define cfg   iocpar.cfg\n\n\tif (minor == ISDN_MINOR_STATUS) {\n\t\tswitch (cmd) {\n\t\tcase IIOCGETDVR:\n\t\t\treturn (TTY_DV +\n\t\t\t\t(NET_DV << 8) +\n\t\t\t\t(INF_DV << 16));\n\t\tcase IIOCGETCPS:\n\t\t\tif (arg) {\n\t\t\t\tulong __user *p = argp;\n\t\t\t\tint i;\n\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\tput_user(dev->ibytes[i], p++);\n\t\t\t\t\tput_user(dev->obytes[i], p++);\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase IIOCNETGPN:\n\t\t\t/* Get peer phone number of a connected\n\t\t\t * isdn network interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_net_getpeer(&phone, argp);\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tif (!dev->drivers)\n\t\treturn -ENODEV;\n\tif (minor <= ISDN_MINOR_BMAX) {\n\t\tdrvidx = isdn_minor2drv(minor);\n\t\tif (drvidx < 0)\n\t\t\treturn -ENODEV;\n\t\tif (!(dev->drv[drvidx]->flags & DRV_FLAG_RUNNING))\n\t\t\treturn -ENODEV;\n\t\treturn 0;\n\t}\n\tif (minor <= ISDN_MINOR_CTRLMAX) {\n/*\n * isdn net devices manage lots of configuration variables as linked lists.\n * Those lists must only be manipulated from user space. Some of the ioctl's\n * service routines access user space and are not atomic. Therefore, ioctl's\n * manipulating the lists and ioctl's sleeping while accessing the lists\n * are serialized by means of a semaphore.\n */\n\t\tswitch (cmd) {\n\t\tcase IIOCNETDWRSET:\n\t\t\tprintk(KERN_INFO \"INFO: ISDN_DW_ABC_EXTENSION not enabled\\n\");\n\t\t\treturn (-EINVAL);\n\t\tcase IIOCNETLCR:\n\t\t\tprintk(KERN_INFO \"INFO: ISDN_ABC_LCR_SUPPORT not enabled\\n\");\n\t\t\treturn -ENODEV;\n\t\tcase IIOCNETAIF:\n\t\t\t/* Add a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\ts = name;\n\t\t\t} else {\n\t\t\t\ts = NULL;\n\t\t\t}\n\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\tif (ret) return ret;\n\t\t\tif ((s = isdn_net_new(s, NULL))) {\n\t\t\t\tif (copy_to_user(argp, s, strlen(s) + 1)) {\n\t\t\t\t\tret = -EFAULT;\n\t\t\t\t} else {\n\t\t\t\t\tret = 0;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tret = -ENODEV;\n\t\t\tmutex_unlock(&dev->mtx);\n\t\t\treturn ret;\n\t\tcase IIOCNETASL:\n\t\t\t/* Add a slave to a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(bname, argp, sizeof(bname) - 1))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\tif (ret) return ret;\n\t\t\tif ((s = isdn_net_newslave(bname))) {\n\t\t\t\tif (copy_to_user(argp, s, strlen(s) + 1)) {\n\t\t\t\t\tret = -EFAULT;\n\t\t\t\t} else {\n\t\t\t\t\tret = 0;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tret = -ENODEV;\n\t\t\tmutex_unlock(&dev->mtx);\n\t\t\treturn ret;\n\t\tcase IIOCNETDIF:\n\t\t\t/* Delete a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_rm(name);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETSCF:\n\t\t\t/* Set configurable parameters of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&cfg, argp, sizeof(cfg)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_net_setcfg(&cfg);\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETGCF:\n\t\t\t/* Get configurable parameters of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&cfg, argp, sizeof(cfg)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tif (!(ret = isdn_net_getcfg(&cfg))) {\n\t\t\t\t\tif (copy_to_user(argp, &cfg, sizeof(cfg)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t}\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETANM:\n\t\t\t/* Add a phone-number to a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_addphone(&phone);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETGNM:\n\t\t\t/* Get list of phone-numbers of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_getphones(&phone, argp);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETDNM:\n\t\t\t/* Delete a phone-number of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_delphone(&phone);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETDIL:\n\t\t\t/* Force dialing of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_net_force_dial(name);\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n#ifdef CONFIG_ISDN_PPP\n\t\tcase IIOCNETALN:\n\t\t\tif (!arg)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn isdn_ppp_dial_slave(name);\n\t\tcase IIOCNETDLN:\n\t\t\tif (!arg)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn isdn_ppp_hangup_slave(name);\n#endif\n\t\tcase IIOCNETHUP:\n\t\t\t/* Force hangup of a network-interface */\n\t\t\tif (!arg)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn isdn_net_force_hangup(name);\n\t\t\tbreak;\n\t\tcase IIOCSETVER:\n\t\t\tdev->net_verbose = arg;\n\t\t\tprintk(KERN_INFO \"isdn: Verbose-Level is %d\\n\", dev->net_verbose);\n\t\t\treturn 0;\n\t\tcase IIOCSETGST:\n\t\t\tif (arg)\n\t\t\t\tdev->global_flags |= ISDN_GLOBAL_STOPPED;\n\t\t\telse\n\t\t\t\tdev->global_flags &= ~ISDN_GLOBAL_STOPPED;\n\t\t\tprintk(KERN_INFO \"isdn: Global Mode %s\\n\",\n\t\t\t       (dev->global_flags & ISDN_GLOBAL_STOPPED) ? \"stopped\" : \"running\");\n\t\t\treturn 0;\n\t\tcase IIOCSETBRJ:\n\t\t\tdrvidx = -1;\n\t\t\tif (arg) {\n\t\t\t\tint i;\n\t\t\t\tchar *p;\n\t\t\t\tif (copy_from_user(&iocts, argp,\n\t\t\t\t\t\t   sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tiocts.drvid[sizeof(iocts.drvid) - 1] = 0;\n\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\tif ((p = strchr(iocts.drvid, ',')))\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (drvidx == -1)\n\t\t\t\treturn -ENODEV;\n\t\t\tif (iocts.arg)\n\t\t\t\tdev->drv[drvidx]->flags |= DRV_FLAG_REJBUS;\n\t\t\telse\n\t\t\t\tdev->drv[drvidx]->flags &= ~DRV_FLAG_REJBUS;\n\t\t\treturn 0;\n\t\tcase IIOCSIGPRF:\n\t\t\tdev->profd = current;\n\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase IIOCGETPRF:\n\t\t\t/* Get all Modem-Profiles */\n\t\t\tif (arg) {\n\t\t\t\tchar __user *p = argp;\n\t\t\t\tint i;\n\n\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.profile,\n\t\t\t\t\t\t\t ISDN_MODEM_NUMREG))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MODEM_NUMREG;\n\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.pmsn, ISDN_MSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MSNLEN;\n\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.plmsn, ISDN_LMSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_LMSNLEN;\n\t\t\t\t}\n\t\t\t\treturn (ISDN_MODEM_NUMREG + ISDN_MSNLEN + ISDN_LMSNLEN) * ISDN_MAX_CHANNELS;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase IIOCSETPRF:\n\t\t\t/* Set all Modem-Profiles */\n\t\t\tif (arg) {\n\t\t\t\tchar __user *p = argp;\n\t\t\t\tint i;\n\n\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.profile, p,\n\t\t\t\t\t\t\t   ISDN_MODEM_NUMREG))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MODEM_NUMREG;\n\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.plmsn, p, ISDN_LMSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_LMSNLEN;\n\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.pmsn, p, ISDN_MSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MSNLEN;\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase IIOCSETMAP:\n\t\tcase IIOCGETMAP:\n\t\t\t/* Set/Get MSN->EAZ-Mapping for a driver */\n\t\t\tif (arg) {\n\n\t\t\t\tif (copy_from_user(&iocts, argp,\n\t\t\t\t\t\t   sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tiocts.drvid[sizeof(iocts.drvid) - 1] = 0;\n\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t\tdrvidx = 0;\n\t\t\t\tif (drvidx == -1)\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\tif (cmd == IIOCSETMAP) {\n\t\t\t\t\tint loop = 1;\n\n\t\t\t\t\tp = (char __user *) iocts.arg;\n\t\t\t\t\ti = 0;\n\t\t\t\t\twhile (loop) {\n\t\t\t\t\t\tint j = 0;\n\n\t\t\t\t\t\twhile (1) {\n\t\t\t\t\t\t\tget_user(bname[j], p++);\n\t\t\t\t\t\t\tswitch (bname[j]) {\n\t\t\t\t\t\t\tcase '\\0':\n\t\t\t\t\t\t\t\tloop = 0;\n\t\t\t\t\t\t\t\t/* Fall through */\n\t\t\t\t\t\t\tcase ',':\n\t\t\t\t\t\t\t\tbname[j] = '\\0';\n\t\t\t\t\t\t\t\tstrcpy(dev->drv[drvidx]->msn2eaz[i], bname);\n\t\t\t\t\t\t\t\tj = ISDN_MSNLEN;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tj++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (j >= ISDN_MSNLEN)\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (++i > 9)\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tp = (char __user *) iocts.arg;\n\t\t\t\t\tfor (i = 0; i < 10; i++) {\n\t\t\t\t\t\tsnprintf(bname, sizeof(bname), \"%s%s\",\n\t\t\t\t\t\t\t strlen(dev->drv[drvidx]->msn2eaz[i]) ?\n\t\t\t\t\t\t\t dev->drv[drvidx]->msn2eaz[i] : \"_\",\n\t\t\t\t\t\t\t (i < 9) ? \",\" : \"\\0\");\n\t\t\t\t\t\tif (copy_to_user(p, bname, strlen(bname) + 1))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += strlen(bname);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCDBGVAR:\n\t\t\tif (arg) {\n\t\t\t\tif (copy_to_user(argp, &dev, sizeof(ulong)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif ((cmd & IIOCDRVCTL) == IIOCDRVCTL)\n\t\t\t\tcmd = ((cmd >> _IOC_NRSHIFT) & _IOC_NRMASK) & ISDN_DRVIOCTL_MASK;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t\tif (arg) {\n\t\t\t\tint i;\n\t\t\t\tchar *p;\n\t\t\t\tif (copy_from_user(&iocts, argp, sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tiocts.drvid[sizeof(iocts.drvid) - 1] = 0;\n\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\tif ((p = strchr(iocts.drvid, ',')))\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t\tdrvidx = 0;\n\t\t\t\tif (drvidx == -1)\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\tc.driver = drvidx;\n\t\t\t\tc.command = ISDN_CMD_IOCTL;\n\t\t\t\tc.arg = cmd;\n\t\t\t\tmemcpy(c.parm.num, &iocts.arg, sizeof(ulong));\n\t\t\t\tret = isdn_command(&c);\n\t\t\t\tmemcpy(&iocts.arg, c.parm.num, sizeof(ulong));\n\t\t\t\tif (copy_to_user(argp, &iocts, sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n#ifdef CONFIG_ISDN_PPP\n\tif (minor <= ISDN_MINOR_PPPMAX)\n\t\treturn (isdn_ppp_ioctl(minor - ISDN_MINOR_PPP, file, cmd, arg));\n#endif\n\treturn -ENODEV;\n\n#undef name\n#undef bname\n#undef iocts\n#undef phone\n#undef cfg\n}",
      "code_after_change": "static int\nisdn_ioctl(struct file *file, uint cmd, ulong arg)\n{\n\tuint minor = iminor(file_inode(file));\n\tisdn_ctrl c;\n\tint drvidx;\n\tint ret;\n\tint i;\n\tchar __user *p;\n\tchar *s;\n\tunion iocpar {\n\t\tchar name[10];\n\t\tchar bname[22];\n\t\tisdn_ioctl_struct iocts;\n\t\tisdn_net_ioctl_phone phone;\n\t\tisdn_net_ioctl_cfg cfg;\n\t} iocpar;\n\tvoid __user *argp = (void __user *)arg;\n\n#define name  iocpar.name\n#define bname iocpar.bname\n#define iocts iocpar.iocts\n#define phone iocpar.phone\n#define cfg   iocpar.cfg\n\n\tif (minor == ISDN_MINOR_STATUS) {\n\t\tswitch (cmd) {\n\t\tcase IIOCGETDVR:\n\t\t\treturn (TTY_DV +\n\t\t\t\t(NET_DV << 8) +\n\t\t\t\t(INF_DV << 16));\n\t\tcase IIOCGETCPS:\n\t\t\tif (arg) {\n\t\t\t\tulong __user *p = argp;\n\t\t\t\tint i;\n\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\tput_user(dev->ibytes[i], p++);\n\t\t\t\t\tput_user(dev->obytes[i], p++);\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase IIOCNETGPN:\n\t\t\t/* Get peer phone number of a connected\n\t\t\t * isdn network interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_net_getpeer(&phone, argp);\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tif (!dev->drivers)\n\t\treturn -ENODEV;\n\tif (minor <= ISDN_MINOR_BMAX) {\n\t\tdrvidx = isdn_minor2drv(minor);\n\t\tif (drvidx < 0)\n\t\t\treturn -ENODEV;\n\t\tif (!(dev->drv[drvidx]->flags & DRV_FLAG_RUNNING))\n\t\t\treturn -ENODEV;\n\t\treturn 0;\n\t}\n\tif (minor <= ISDN_MINOR_CTRLMAX) {\n/*\n * isdn net devices manage lots of configuration variables as linked lists.\n * Those lists must only be manipulated from user space. Some of the ioctl's\n * service routines access user space and are not atomic. Therefore, ioctl's\n * manipulating the lists and ioctl's sleeping while accessing the lists\n * are serialized by means of a semaphore.\n */\n\t\tswitch (cmd) {\n\t\tcase IIOCNETDWRSET:\n\t\t\tprintk(KERN_INFO \"INFO: ISDN_DW_ABC_EXTENSION not enabled\\n\");\n\t\t\treturn (-EINVAL);\n\t\tcase IIOCNETLCR:\n\t\t\tprintk(KERN_INFO \"INFO: ISDN_ABC_LCR_SUPPORT not enabled\\n\");\n\t\t\treturn -ENODEV;\n\t\tcase IIOCNETAIF:\n\t\t\t/* Add a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\ts = name;\n\t\t\t} else {\n\t\t\t\ts = NULL;\n\t\t\t}\n\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\tif (ret) return ret;\n\t\t\tif ((s = isdn_net_new(s, NULL))) {\n\t\t\t\tif (copy_to_user(argp, s, strlen(s) + 1)) {\n\t\t\t\t\tret = -EFAULT;\n\t\t\t\t} else {\n\t\t\t\t\tret = 0;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tret = -ENODEV;\n\t\t\tmutex_unlock(&dev->mtx);\n\t\t\treturn ret;\n\t\tcase IIOCNETASL:\n\t\t\t/* Add a slave to a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(bname, argp, sizeof(bname) - 1))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tbname[sizeof(bname)-1] = 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\tif (ret) return ret;\n\t\t\tif ((s = isdn_net_newslave(bname))) {\n\t\t\t\tif (copy_to_user(argp, s, strlen(s) + 1)) {\n\t\t\t\t\tret = -EFAULT;\n\t\t\t\t} else {\n\t\t\t\t\tret = 0;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\tret = -ENODEV;\n\t\t\tmutex_unlock(&dev->mtx);\n\t\t\treturn ret;\n\t\tcase IIOCNETDIF:\n\t\t\t/* Delete a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_rm(name);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETSCF:\n\t\t\t/* Set configurable parameters of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&cfg, argp, sizeof(cfg)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_net_setcfg(&cfg);\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETGCF:\n\t\t\t/* Get configurable parameters of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&cfg, argp, sizeof(cfg)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tif (!(ret = isdn_net_getcfg(&cfg))) {\n\t\t\t\t\tif (copy_to_user(argp, &cfg, sizeof(cfg)))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t}\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETANM:\n\t\t\t/* Add a phone-number to a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_addphone(&phone);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETGNM:\n\t\t\t/* Get list of phone-numbers of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_getphones(&phone, argp);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETDNM:\n\t\t\t/* Delete a phone-number of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(&phone, argp, sizeof(phone)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tret = mutex_lock_interruptible(&dev->mtx);\n\t\t\t\tif (ret) return ret;\n\t\t\t\tret = isdn_net_delphone(&phone);\n\t\t\t\tmutex_unlock(&dev->mtx);\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCNETDIL:\n\t\t\t/* Force dialing of a network-interface */\n\t\t\tif (arg) {\n\t\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn isdn_net_force_dial(name);\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n#ifdef CONFIG_ISDN_PPP\n\t\tcase IIOCNETALN:\n\t\t\tif (!arg)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn isdn_ppp_dial_slave(name);\n\t\tcase IIOCNETDLN:\n\t\t\tif (!arg)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn isdn_ppp_hangup_slave(name);\n#endif\n\t\tcase IIOCNETHUP:\n\t\t\t/* Force hangup of a network-interface */\n\t\t\tif (!arg)\n\t\t\t\treturn -EINVAL;\n\t\t\tif (copy_from_user(name, argp, sizeof(name)))\n\t\t\t\treturn -EFAULT;\n\t\t\treturn isdn_net_force_hangup(name);\n\t\t\tbreak;\n\t\tcase IIOCSETVER:\n\t\t\tdev->net_verbose = arg;\n\t\t\tprintk(KERN_INFO \"isdn: Verbose-Level is %d\\n\", dev->net_verbose);\n\t\t\treturn 0;\n\t\tcase IIOCSETGST:\n\t\t\tif (arg)\n\t\t\t\tdev->global_flags |= ISDN_GLOBAL_STOPPED;\n\t\t\telse\n\t\t\t\tdev->global_flags &= ~ISDN_GLOBAL_STOPPED;\n\t\t\tprintk(KERN_INFO \"isdn: Global Mode %s\\n\",\n\t\t\t       (dev->global_flags & ISDN_GLOBAL_STOPPED) ? \"stopped\" : \"running\");\n\t\t\treturn 0;\n\t\tcase IIOCSETBRJ:\n\t\t\tdrvidx = -1;\n\t\t\tif (arg) {\n\t\t\t\tint i;\n\t\t\t\tchar *p;\n\t\t\t\tif (copy_from_user(&iocts, argp,\n\t\t\t\t\t\t   sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tiocts.drvid[sizeof(iocts.drvid) - 1] = 0;\n\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\tif ((p = strchr(iocts.drvid, ',')))\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (drvidx == -1)\n\t\t\t\treturn -ENODEV;\n\t\t\tif (iocts.arg)\n\t\t\t\tdev->drv[drvidx]->flags |= DRV_FLAG_REJBUS;\n\t\t\telse\n\t\t\t\tdev->drv[drvidx]->flags &= ~DRV_FLAG_REJBUS;\n\t\t\treturn 0;\n\t\tcase IIOCSIGPRF:\n\t\t\tdev->profd = current;\n\t\t\treturn 0;\n\t\t\tbreak;\n\t\tcase IIOCGETPRF:\n\t\t\t/* Get all Modem-Profiles */\n\t\t\tif (arg) {\n\t\t\t\tchar __user *p = argp;\n\t\t\t\tint i;\n\n\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.profile,\n\t\t\t\t\t\t\t ISDN_MODEM_NUMREG))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MODEM_NUMREG;\n\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.pmsn, ISDN_MSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MSNLEN;\n\t\t\t\t\tif (copy_to_user(p, dev->mdm.info[i].emu.plmsn, ISDN_LMSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_LMSNLEN;\n\t\t\t\t}\n\t\t\t\treturn (ISDN_MODEM_NUMREG + ISDN_MSNLEN + ISDN_LMSNLEN) * ISDN_MAX_CHANNELS;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase IIOCSETPRF:\n\t\t\t/* Set all Modem-Profiles */\n\t\t\tif (arg) {\n\t\t\t\tchar __user *p = argp;\n\t\t\t\tint i;\n\n\t\t\t\tfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\n\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.profile, p,\n\t\t\t\t\t\t\t   ISDN_MODEM_NUMREG))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MODEM_NUMREG;\n\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.plmsn, p, ISDN_LMSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_LMSNLEN;\n\t\t\t\t\tif (copy_from_user(dev->mdm.info[i].emu.pmsn, p, ISDN_MSNLEN))\n\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\tp += ISDN_MSNLEN;\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tcase IIOCSETMAP:\n\t\tcase IIOCGETMAP:\n\t\t\t/* Set/Get MSN->EAZ-Mapping for a driver */\n\t\t\tif (arg) {\n\n\t\t\t\tif (copy_from_user(&iocts, argp,\n\t\t\t\t\t\t   sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tiocts.drvid[sizeof(iocts.drvid) - 1] = 0;\n\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t\tdrvidx = 0;\n\t\t\t\tif (drvidx == -1)\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\tif (cmd == IIOCSETMAP) {\n\t\t\t\t\tint loop = 1;\n\n\t\t\t\t\tp = (char __user *) iocts.arg;\n\t\t\t\t\ti = 0;\n\t\t\t\t\twhile (loop) {\n\t\t\t\t\t\tint j = 0;\n\n\t\t\t\t\t\twhile (1) {\n\t\t\t\t\t\t\tget_user(bname[j], p++);\n\t\t\t\t\t\t\tswitch (bname[j]) {\n\t\t\t\t\t\t\tcase '\\0':\n\t\t\t\t\t\t\t\tloop = 0;\n\t\t\t\t\t\t\t\t/* Fall through */\n\t\t\t\t\t\t\tcase ',':\n\t\t\t\t\t\t\t\tbname[j] = '\\0';\n\t\t\t\t\t\t\t\tstrcpy(dev->drv[drvidx]->msn2eaz[i], bname);\n\t\t\t\t\t\t\t\tj = ISDN_MSNLEN;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tj++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (j >= ISDN_MSNLEN)\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (++i > 9)\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tp = (char __user *) iocts.arg;\n\t\t\t\t\tfor (i = 0; i < 10; i++) {\n\t\t\t\t\t\tsnprintf(bname, sizeof(bname), \"%s%s\",\n\t\t\t\t\t\t\t strlen(dev->drv[drvidx]->msn2eaz[i]) ?\n\t\t\t\t\t\t\t dev->drv[drvidx]->msn2eaz[i] : \"_\",\n\t\t\t\t\t\t\t (i < 9) ? \",\" : \"\\0\");\n\t\t\t\t\t\tif (copy_to_user(p, bname, strlen(bname) + 1))\n\t\t\t\t\t\t\treturn -EFAULT;\n\t\t\t\t\t\tp += strlen(bname);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\tcase IIOCDBGVAR:\n\t\t\tif (arg) {\n\t\t\t\tif (copy_to_user(argp, &dev, sizeof(ulong)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn 0;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif ((cmd & IIOCDRVCTL) == IIOCDRVCTL)\n\t\t\t\tcmd = ((cmd >> _IOC_NRSHIFT) & _IOC_NRMASK) & ISDN_DRVIOCTL_MASK;\n\t\t\telse\n\t\t\t\treturn -EINVAL;\n\t\t\tif (arg) {\n\t\t\t\tint i;\n\t\t\t\tchar *p;\n\t\t\t\tif (copy_from_user(&iocts, argp, sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tiocts.drvid[sizeof(iocts.drvid) - 1] = 0;\n\t\t\t\tif (strlen(iocts.drvid)) {\n\t\t\t\t\tif ((p = strchr(iocts.drvid, ',')))\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\tdrvidx = -1;\n\t\t\t\t\tfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\n\t\t\t\t\t\tif (!(strcmp(dev->drvid[i], iocts.drvid))) {\n\t\t\t\t\t\t\tdrvidx = i;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t} else\n\t\t\t\t\tdrvidx = 0;\n\t\t\t\tif (drvidx == -1)\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\tc.driver = drvidx;\n\t\t\t\tc.command = ISDN_CMD_IOCTL;\n\t\t\t\tc.arg = cmd;\n\t\t\t\tmemcpy(c.parm.num, &iocts.arg, sizeof(ulong));\n\t\t\t\tret = isdn_command(&c);\n\t\t\t\tmemcpy(&iocts.arg, c.parm.num, sizeof(ulong));\n\t\t\t\tif (copy_to_user(argp, &iocts, sizeof(isdn_ioctl_struct)))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\treturn ret;\n\t\t\t} else\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n#ifdef CONFIG_ISDN_PPP\n\tif (minor <= ISDN_MINOR_PPPMAX)\n\t\treturn (isdn_ppp_ioctl(minor - ISDN_MINOR_PPP, file, cmd, arg));\n#endif\n\treturn -ENODEV;\n\n#undef name\n#undef bname\n#undef iocts\n#undef phone\n#undef cfg\n}",
      "modified_lines": {
        "added": [
          "\t\t\t\tbname[sizeof(bname)-1] = 0;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper bounds checking when copying user-controlled data into a fixed-size buffer.",
      "trigger_condition": "User-supplied data exceeding the buffer size during the copy operation, leading to a buffer overflow vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code uses strcpy to copy user-controlled data into a buffer without verifying the length of the input data, potentially allowing an attacker to overwrite adjacent memory locations.",
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the buffer is null-terminated within its bounds after copying user-controlled data. This prevents buffer overflow by guaranteeing that the copied data does not exceed the buffer size.",
      "id": 102,
      "code_after_change_normalized": "static int\nFUN1(struct VAR1 *VAR1, uint VAR2, ulong VAR3)\n{\nuint VAR4 = FUN2(FUN3(VAR1));\nisdn_ctrl VAR5;\nint VAR6;\nint VAR7;\nint VAR8;\nchar __user *VAR9;\nchar *VAR10;\nunion VAR11 {\nchar VAR12[10];\nchar VAR13[22];\nisdn_ioctl_struct VAR14;\nisdn_net_ioctl_phone VAR15;\nisdn_net_ioctl_cfg VAR16;\n} VAR11;\nvoid VAR18 *VAR17 = (void VAR18 *)VAR3;\n#define name  VAR11.VAR12\n#define bname VAR11.VAR13\n#define iocts VAR11.VAR14\n#define phone VAR11.VAR15\n#define cfg   VAR11.VAR16\nif (VAR4 == VAR19) {\nswitch (VAR2) {\ncase VAR20:\nreturn (VAR21 +\n(VAR22 << 8) +\n(VAR23 << 16));\ncase VAR24:\nif (VAR3) {\nulong __user *VAR9 = VAR17;\nint VAR8;\nfor (VAR8 = 0; VAR8 < VAR25; VAR8++) {\nFUN4(VAR26->VAR27[VAR8], VAR9++);\nFUN4(VAR26->VAR28[VAR8], VAR9++);\n}\nreturn 0;\n} else\nreturn -VAR29;\nbreak;\ncase VAR30:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nreturn FUN6(&VAR15, VAR17);\n} else\nreturn -VAR29;\ndefault:\nreturn -VAR29;\n}\n}\nif (!VAR26->VAR32)\nreturn -VAR33;\nif (VAR4 <= VAR34) {\nVAR6 = FUN7(VAR4);\nif (VAR6 < 0)\nreturn -VAR33;\nif (!(VAR26->VAR35[VAR6]->VAR36 & VAR37))\nreturn -VAR33;\nreturn 0;\n}\nif (VAR4 <= VAR38) {\nswitch (VAR2) {\ncase VAR39:\nFUN8(VAR40 \"STR\");\nreturn (-VAR29);\ncase VAR41:\nFUN8(VAR40 \"STR\");\nreturn -VAR33;\ncase VAR42:\nif (VAR3) {\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nVAR10 = VAR12;\n} else {\nVAR10 = NULL;\n}\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nif ((VAR10 = FUN10(VAR10, NULL))) {\nif (FUN11(VAR17, VAR10, FUN12(VAR10) + 1)) {\nVAR7 = -VAR31;\n} else {\nVAR7 = 0;\n}\n} else\nVAR7 = -VAR33;\nFUN13(&VAR26->VAR43);\nreturn VAR7;\ncase VAR44:\nif (VAR3) {\nif (FUN5(VAR13, VAR17, sizeof(VAR13) - 1))\nreturn -VAR31;\nVAR13[sizeof(VAR13)-1] = 0;\n} else\nreturn -VAR29;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nif ((VAR10 = FUN14(VAR13))) {\nif (FUN11(VAR17, VAR10, FUN12(VAR10) + 1)) {\nVAR7 = -VAR31;\n} else {\nVAR7 = 0;\n}\n} else\nVAR7 = -VAR33;\nFUN13(&VAR26->VAR43);\nreturn VAR7;\ncase VAR45:\nif (VAR3) {\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN15(VAR12);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR46:\nif (VAR3) {\nif (FUN5(&VAR16, VAR17, sizeof(VAR16)))\nreturn -VAR31;\nreturn FUN16(&VAR16);\n} else\nreturn -VAR29;\ncase VAR47:\nif (VAR3) {\nif (FUN5(&VAR16, VAR17, sizeof(VAR16)))\nreturn -VAR31;\nif (!(VAR7 = FUN17(&VAR16))) {\nif (FUN11(VAR17, &VAR16, sizeof(VAR16)))\nreturn -VAR31;\n}\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR48:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN18(&VAR15);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR49:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN19(&VAR15, VAR17);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR50:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN20(&VAR15);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR51:\nif (VAR3) {\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN21(VAR12);\n} else\nreturn -VAR29;\n#ifdef VAR52\ncase VAR53:\nif (!VAR3)\nreturn -VAR29;\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN22(VAR12);\ncase VAR54:\nif (!VAR3)\nreturn -VAR29;\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN23(VAR12);\n#VAR55\ncase VAR56:\nif (!VAR3)\nreturn -VAR29;\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN24(VAR12);\nbreak;\ncase VAR57:\nVAR26->VAR58 = VAR3;\nFUN8(VAR40 \"STR\", VAR26->VAR58);\nreturn 0;\ncase VAR59:\nif (VAR3)\nVAR26->VAR60 |= VAR61;\nelse\nVAR26->VAR60 &= ~VAR61;\nFUN8(VAR40 \"STR\",\n(VAR26->VAR60 & VAR61) ? \"STR\" : \"STR\");\nreturn 0;\ncase VAR62:\nVAR6 = -1;\nif (VAR3) {\nint VAR8;\nchar *VAR9;\nif (FUN5(&VAR14, VAR17,\nsizeof(VAR63)))\nreturn -VAR31;\nVAR14.VAR64[sizeof(VAR14.VAR64) - 1] = 0;\nif (FUN12(VAR14.VAR64)) {\nif ((VAR9 = FUN25(VAR14.VAR64, )))\n*VAR9 = 0;\nVAR6 = -1;\nfor (VAR8 = 0; VAR8 < VAR65; VAR8++)\nif (!(FUN26(VAR26->VAR64[VAR8], VAR14.VAR64))) {\nVAR6 = VAR8;\nbreak;\n}\n}\n}\nif (VAR6 == -1)\nreturn -VAR33;\nif (VAR14.VAR3)\nVAR26->VAR35[VAR6]->VAR36 |= VAR66;\nelse\nVAR26->VAR35[VAR6]->VAR36 &= ~VAR66;\nreturn 0;\ncase VAR67:\nVAR26->VAR68 = VAR69;\nreturn 0;\nbreak;\ncase VAR70:\nif (VAR3) {\nchar __user *VAR9 = VAR17;\nint VAR8;\nfor (VAR8 = 0; VAR8 < VAR25; VAR8++) {\nif (FUN11(VAR9, VAR26->VAR71.VAR72[VAR8].VAR73.VAR74,\nVAR75))\nreturn -VAR31;\nVAR9 += VAR75;\nif (FUN11(VAR9, VAR26->VAR71.VAR72[VAR8].VAR73.VAR76, VAR77))\nreturn -VAR31;\nVAR9 += VAR77;\nif (FUN11(VAR9, VAR26->VAR71.VAR72[VAR8].VAR73.VAR78, VAR79))\nreturn -VAR31;\nVAR9 += VAR79;\n}\nreturn (VAR75 + VAR77 + VAR79) * VAR25;\n} else\nreturn -VAR29;\nbreak;\ncase VAR80:\nif (VAR3) {\nchar __user *VAR9 = VAR17;\nint VAR8;\nfor (VAR8 = 0; VAR8 < VAR25; VAR8++) {\nif (FUN5(VAR26->VAR71.VAR72[VAR8].VAR73.VAR74, VAR9,\nVAR75))\nreturn -VAR31;\nVAR9 += VAR75;\nif (FUN5(VAR26->VAR71.VAR72[VAR8].VAR73.VAR78, VAR9, VAR79))\nreturn -VAR31;\nVAR9 += VAR79;\nif (FUN5(VAR26->VAR71.VAR72[VAR8].VAR73.VAR76, VAR9, VAR77))\nreturn -VAR31;\nVAR9 += VAR77;\n}\nreturn 0;\n} else\nreturn -VAR29;\nbreak;\ncase VAR81:\ncase VAR82:\nif (VAR3) {\nif (FUN5(&VAR14, VAR17,\nsizeof(VAR63)))\nreturn -VAR31;\nVAR14.VAR64[sizeof(VAR14.VAR64) - 1] = 0;\nif (FUN12(VAR14.VAR64)) {\nVAR6 = -1;\nfor (VAR8 = 0; VAR8 < VAR65; VAR8++)\nif (!(FUN26(VAR26->VAR64[VAR8], VAR14.VAR64))) {\nVAR6 = VAR8;\nbreak;\n}\n} else\nVAR6 = 0;\nif (VAR6 == -1)\nreturn -VAR33;\nif (VAR2 == VAR81) {\nint VAR83 = 1;\nVAR9 = (char VAR18 *) VAR14.VAR3;\nVAR8 = 0;\nwhile (VAR83) {\nint VAR84 = 0;\nwhile (1) {\nFUN27(VAR13[VAR84], VAR9++);\nswitch (VAR13[VAR84]) {\ncase :\nVAR83 = 0;\ncase :\nVAR13[VAR84] = ;\nFUN28(VAR26->VAR35[VAR6]->VAR85[VAR8], VAR13);\nVAR84 = VAR77;\nbreak;\ndefault:\nVAR84++;\n}\nif (VAR84 >= VAR77)\nbreak;\n}\nif (++VAR8 > 9)\nbreak;\n}\n} else {\nVAR9 = (char VAR18 *) VAR14.VAR3;\nfor (VAR8 = 0; VAR8 < 10; VAR8++) {\nFUN29(VAR13, sizeof(VAR13), \"STR\",\nFUN12(VAR26->VAR35[VAR6]->VAR85[VAR8]) ?\nVAR26->VAR35[VAR6]->VAR85[VAR8] : \"STR\",\n(VAR8 < 9) ? \"STR\" : \"STR\");\nif (FUN11(VAR9, VAR13, FUN12(VAR13) + 1))\nreturn -VAR31;\nVAR9 += FUN12(VAR13);\n}\n}\nreturn 0;\n} else\nreturn -VAR29;\ncase VAR86:\nif (VAR3) {\nif (FUN11(VAR17, &VAR26, sizeof(VAR87)))\nreturn -VAR31;\nreturn 0;\n} else\nreturn -VAR29;\nbreak;\ndefault:\nif ((VAR2 & VAR88) == VAR88)\nVAR2 = ((VAR2 >> VAR89) & VAR90) & VAR91;\nelse\nreturn -VAR29;\nif (VAR3) {\nint VAR8;\nchar *VAR9;\nif (FUN5(&VAR14, VAR17, sizeof(VAR63)))\nreturn -VAR31;\nVAR14.VAR64[sizeof(VAR14.VAR64) - 1] = 0;\nif (FUN12(VAR14.VAR64)) {\nif ((VAR9 = FUN25(VAR14.VAR64, )))\n*VAR9 = 0;\nVAR6 = -1;\nfor (VAR8 = 0; VAR8 < VAR65; VAR8++)\nif (!(FUN26(VAR26->VAR64[VAR8], VAR14.VAR64))) {\nVAR6 = VAR8;\nbreak;\n}\n} else\nVAR6 = 0;\nif (VAR6 == -1)\nreturn -VAR33;\nVAR5.VAR92 = VAR6;\nVAR5.VAR93 = VAR94;\nVAR5.VAR3 = VAR2;\nFUN30(VAR5.VAR95.VAR96, &VAR14.VAR3, sizeof(VAR87));\nVAR7 = FUN31(&VAR5);\nFUN30(&VAR14.VAR3, VAR5.VAR95.VAR96, sizeof(VAR87));\nif (FUN11(VAR17, &VAR14, sizeof(VAR63)))\nreturn -VAR31;\nreturn VAR7;\n} else\nreturn -VAR29;\n}\n}\n#ifdef VAR52\nif (VAR4 <= VAR97)\nreturn (FUN32(VAR4 - VAR98, VAR1, VAR2, VAR3));\n#VAR55\nreturn -VAR33;\n#undef VAR12\n#undef VAR13\n#undef VAR14\n#undef VAR15\n#undef VAR16\n}\n",
      "code_before_change_normalized": "static int\nFUN1(struct VAR1 *VAR1, uint VAR2, ulong VAR3)\n{\nuint VAR4 = FUN2(FUN3(VAR1));\nisdn_ctrl VAR5;\nint VAR6;\nint VAR7;\nint VAR8;\nchar __user *VAR9;\nchar *VAR10;\nunion VAR11 {\nchar VAR12[10];\nchar VAR13[22];\nisdn_ioctl_struct VAR14;\nisdn_net_ioctl_phone VAR15;\nisdn_net_ioctl_cfg VAR16;\n} VAR11;\nvoid VAR18 *VAR17 = (void VAR18 *)VAR3;\n#define name  VAR11.VAR12\n#define bname VAR11.VAR13\n#define iocts VAR11.VAR14\n#define phone VAR11.VAR15\n#define cfg   VAR11.VAR16\nif (VAR4 == VAR19) {\nswitch (VAR2) {\ncase VAR20:\nreturn (VAR21 +\n(VAR22 << 8) +\n(VAR23 << 16));\ncase VAR24:\nif (VAR3) {\nulong __user *VAR9 = VAR17;\nint VAR8;\nfor (VAR8 = 0; VAR8 < VAR25; VAR8++) {\nFUN4(VAR26->VAR27[VAR8], VAR9++);\nFUN4(VAR26->VAR28[VAR8], VAR9++);\n}\nreturn 0;\n} else\nreturn -VAR29;\nbreak;\ncase VAR30:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nreturn FUN6(&VAR15, VAR17);\n} else\nreturn -VAR29;\ndefault:\nreturn -VAR29;\n}\n}\nif (!VAR26->VAR32)\nreturn -VAR33;\nif (VAR4 <= VAR34) {\nVAR6 = FUN7(VAR4);\nif (VAR6 < 0)\nreturn -VAR33;\nif (!(VAR26->VAR35[VAR6]->VAR36 & VAR37))\nreturn -VAR33;\nreturn 0;\n}\nif (VAR4 <= VAR38) {\nswitch (VAR2) {\ncase VAR39:\nFUN8(VAR40 \"STR\");\nreturn (-VAR29);\ncase VAR41:\nFUN8(VAR40 \"STR\");\nreturn -VAR33;\ncase VAR42:\nif (VAR3) {\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nVAR10 = VAR12;\n} else {\nVAR10 = NULL;\n}\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nif ((VAR10 = FUN10(VAR10, NULL))) {\nif (FUN11(VAR17, VAR10, FUN12(VAR10) + 1)) {\nVAR7 = -VAR31;\n} else {\nVAR7 = 0;\n}\n} else\nVAR7 = -VAR33;\nFUN13(&VAR26->VAR43);\nreturn VAR7;\ncase VAR44:\nif (VAR3) {\nif (FUN5(VAR13, VAR17, sizeof(VAR13) - 1))\nreturn -VAR31;\n} else\nreturn -VAR29;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nif ((VAR10 = FUN14(VAR13))) {\nif (FUN11(VAR17, VAR10, FUN12(VAR10) + 1)) {\nVAR7 = -VAR31;\n} else {\nVAR7 = 0;\n}\n} else\nVAR7 = -VAR33;\nFUN13(&VAR26->VAR43);\nreturn VAR7;\ncase VAR45:\nif (VAR3) {\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN15(VAR12);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR46:\nif (VAR3) {\nif (FUN5(&VAR16, VAR17, sizeof(VAR16)))\nreturn -VAR31;\nreturn FUN16(&VAR16);\n} else\nreturn -VAR29;\ncase VAR47:\nif (VAR3) {\nif (FUN5(&VAR16, VAR17, sizeof(VAR16)))\nreturn -VAR31;\nif (!(VAR7 = FUN17(&VAR16))) {\nif (FUN11(VAR17, &VAR16, sizeof(VAR16)))\nreturn -VAR31;\n}\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR48:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN18(&VAR15);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR49:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN19(&VAR15, VAR17);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR50:\nif (VAR3) {\nif (FUN5(&VAR15, VAR17, sizeof(VAR15)))\nreturn -VAR31;\nVAR7 = FUN9(&VAR26->VAR43);\nif (VAR7) return VAR7;\nVAR7 = FUN20(&VAR15);\nFUN13(&VAR26->VAR43);\nreturn VAR7;\n} else\nreturn -VAR29;\ncase VAR51:\nif (VAR3) {\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN21(VAR12);\n} else\nreturn -VAR29;\n#ifdef VAR52\ncase VAR53:\nif (!VAR3)\nreturn -VAR29;\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN22(VAR12);\ncase VAR54:\nif (!VAR3)\nreturn -VAR29;\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN23(VAR12);\n#VAR55\ncase VAR56:\nif (!VAR3)\nreturn -VAR29;\nif (FUN5(VAR12, VAR17, sizeof(VAR12)))\nreturn -VAR31;\nreturn FUN24(VAR12);\nbreak;\ncase VAR57:\nVAR26->VAR58 = VAR3;\nFUN8(VAR40 \"STR\", VAR26->VAR58);\nreturn 0;\ncase VAR59:\nif (VAR3)\nVAR26->VAR60 |= VAR61;\nelse\nVAR26->VAR60 &= ~VAR61;\nFUN8(VAR40 \"STR\",\n(VAR26->VAR60 & VAR61) ? \"STR\" : \"STR\");\nreturn 0;\ncase VAR62:\nVAR6 = -1;\nif (VAR3) {\nint VAR8;\nchar *VAR9;\nif (FUN5(&VAR14, VAR17,\nsizeof(VAR63)))\nreturn -VAR31;\nVAR14.VAR64[sizeof(VAR14.VAR64) - 1] = 0;\nif (FUN12(VAR14.VAR64)) {\nif ((VAR9 = FUN25(VAR14.VAR64, )))\n*VAR9 = 0;\nVAR6 = -1;\nfor (VAR8 = 0; VAR8 < VAR65; VAR8++)\nif (!(FUN26(VAR26->VAR64[VAR8], VAR14.VAR64))) {\nVAR6 = VAR8;\nbreak;\n}\n}\n}\nif (VAR6 == -1)\nreturn -VAR33;\nif (VAR14.VAR3)\nVAR26->VAR35[VAR6]->VAR36 |= VAR66;\nelse\nVAR26->VAR35[VAR6]->VAR36 &= ~VAR66;\nreturn 0;\ncase VAR67:\nVAR26->VAR68 = VAR69;\nreturn 0;\nbreak;\ncase VAR70:\nif (VAR3) {\nchar __user *VAR9 = VAR17;\nint VAR8;\nfor (VAR8 = 0; VAR8 < VAR25; VAR8++) {\nif (FUN11(VAR9, VAR26->VAR71.VAR72[VAR8].VAR73.VAR74,\nVAR75))\nreturn -VAR31;\nVAR9 += VAR75;\nif (FUN11(VAR9, VAR26->VAR71.VAR72[VAR8].VAR73.VAR76, VAR77))\nreturn -VAR31;\nVAR9 += VAR77;\nif (FUN11(VAR9, VAR26->VAR71.VAR72[VAR8].VAR73.VAR78, VAR79))\nreturn -VAR31;\nVAR9 += VAR79;\n}\nreturn (VAR75 + VAR77 + VAR79) * VAR25;\n} else\nreturn -VAR29;\nbreak;\ncase VAR80:\nif (VAR3) {\nchar __user *VAR9 = VAR17;\nint VAR8;\nfor (VAR8 = 0; VAR8 < VAR25; VAR8++) {\nif (FUN5(VAR26->VAR71.VAR72[VAR8].VAR73.VAR74, VAR9,\nVAR75))\nreturn -VAR31;\nVAR9 += VAR75;\nif (FUN5(VAR26->VAR71.VAR72[VAR8].VAR73.VAR78, VAR9, VAR79))\nreturn -VAR31;\nVAR9 += VAR79;\nif (FUN5(VAR26->VAR71.VAR72[VAR8].VAR73.VAR76, VAR9, VAR77))\nreturn -VAR31;\nVAR9 += VAR77;\n}\nreturn 0;\n} else\nreturn -VAR29;\nbreak;\ncase VAR81:\ncase VAR82:\nif (VAR3) {\nif (FUN5(&VAR14, VAR17,\nsizeof(VAR63)))\nreturn -VAR31;\nVAR14.VAR64[sizeof(VAR14.VAR64) - 1] = 0;\nif (FUN12(VAR14.VAR64)) {\nVAR6 = -1;\nfor (VAR8 = 0; VAR8 < VAR65; VAR8++)\nif (!(FUN26(VAR26->VAR64[VAR8], VAR14.VAR64))) {\nVAR6 = VAR8;\nbreak;\n}\n} else\nVAR6 = 0;\nif (VAR6 == -1)\nreturn -VAR33;\nif (VAR2 == VAR81) {\nint VAR83 = 1;\nVAR9 = (char VAR18 *) VAR14.VAR3;\nVAR8 = 0;\nwhile (VAR83) {\nint VAR84 = 0;\nwhile (1) {\nFUN27(VAR13[VAR84], VAR9++);\nswitch (VAR13[VAR84]) {\ncase :\nVAR83 = 0;\ncase :\nVAR13[VAR84] = ;\nFUN28(VAR26->VAR35[VAR6]->VAR85[VAR8], VAR13);\nVAR84 = VAR77;\nbreak;\ndefault:\nVAR84++;\n}\nif (VAR84 >= VAR77)\nbreak;\n}\nif (++VAR8 > 9)\nbreak;\n}\n} else {\nVAR9 = (char VAR18 *) VAR14.VAR3;\nfor (VAR8 = 0; VAR8 < 10; VAR8++) {\nFUN29(VAR13, sizeof(VAR13), \"STR\",\nFUN12(VAR26->VAR35[VAR6]->VAR85[VAR8]) ?\nVAR26->VAR35[VAR6]->VAR85[VAR8] : \"STR\",\n(VAR8 < 9) ? \"STR\" : \"STR\");\nif (FUN11(VAR9, VAR13, FUN12(VAR13) + 1))\nreturn -VAR31;\nVAR9 += FUN12(VAR13);\n}\n}\nreturn 0;\n} else\nreturn -VAR29;\ncase VAR86:\nif (VAR3) {\nif (FUN11(VAR17, &VAR26, sizeof(VAR87)))\nreturn -VAR31;\nreturn 0;\n} else\nreturn -VAR29;\nbreak;\ndefault:\nif ((VAR2 & VAR88) == VAR88)\nVAR2 = ((VAR2 >> VAR89) & VAR90) & VAR91;\nelse\nreturn -VAR29;\nif (VAR3) {\nint VAR8;\nchar *VAR9;\nif (FUN5(&VAR14, VAR17, sizeof(VAR63)))\nreturn -VAR31;\nVAR14.VAR64[sizeof(VAR14.VAR64) - 1] = 0;\nif (FUN12(VAR14.VAR64)) {\nif ((VAR9 = FUN25(VAR14.VAR64, )))\n*VAR9 = 0;\nVAR6 = -1;\nfor (VAR8 = 0; VAR8 < VAR65; VAR8++)\nif (!(FUN26(VAR26->VAR64[VAR8], VAR14.VAR64))) {\nVAR6 = VAR8;\nbreak;\n}\n} else\nVAR6 = 0;\nif (VAR6 == -1)\nreturn -VAR33;\nVAR5.VAR92 = VAR6;\nVAR5.VAR93 = VAR94;\nVAR5.VAR3 = VAR2;\nFUN30(VAR5.VAR95.VAR96, &VAR14.VAR3, sizeof(VAR87));\nVAR7 = FUN31(&VAR5);\nFUN30(&VAR14.VAR3, VAR5.VAR95.VAR96, sizeof(VAR87));\nif (FUN11(VAR17, &VAR14, sizeof(VAR63)))\nreturn -VAR31;\nreturn VAR7;\n} else\nreturn -VAR29;\n}\n}\n#ifdef VAR52\nif (VAR4 <= VAR97)\nreturn (FUN32(VAR4 - VAR98, VAR1, VAR2, VAR3));\n#VAR55\nreturn -VAR33;\n#undef VAR12\n#undef VAR13\n#undef VAR14\n#undef VAR15\n#undef VAR16\n}\n",
      "code_after_change_raw": "static int\nisdn_ioctl(struct file *file, uint cmd, ulong arg)\n{\nuint minor = iminor(file_inode(file));\nisdn_ctrl c;\nint drvidx;\nint ret;\nint i;\nchar __user *p;\nchar *s;\nunion iocpar {\nchar name[10];\nchar bname[22];\nisdn_ioctl_struct iocts;\nisdn_net_ioctl_phone phone;\nisdn_net_ioctl_cfg cfg;\n} iocpar;\nvoid __user *argp = (void __user *)arg;\n#define name  iocpar.name\n#define bname iocpar.bname\n#define iocts iocpar.iocts\n#define phone iocpar.phone\n#define cfg   iocpar.cfg\nif (minor == ISDN_MINOR_STATUS) {\nswitch (cmd) {\ncase IIOCGETDVR:\nreturn (TTY_DV +\n(NET_DV << 8) +\n(INF_DV << 16));\ncase IIOCGETCPS:\nif (arg) {\nulong __user *p = argp;\nint i;\nfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\nput_user(dev->ibytes[i], p++);\nput_user(dev->obytes[i], p++);\n}\nreturn 0;\n} else\nreturn -EINVAL;\nbreak;\ncase IIOCNETGPN:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nreturn isdn_net_getpeer(&phone, argp);\n} else\nreturn -EINVAL;\ndefault:\nreturn -EINVAL;\n}\n}\nif (!dev->drivers)\nreturn -ENODEV;\nif (minor <= ISDN_MINOR_BMAX) {\ndrvidx = isdn_minor2drv(minor);\nif (drvidx < 0)\nreturn -ENODEV;\nif (!(dev->drv[drvidx]->flags & DRV_FLAG_RUNNING))\nreturn -ENODEV;\nreturn 0;\n}\nif (minor <= ISDN_MINOR_CTRLMAX) {\nswitch (cmd) {\ncase IIOCNETDWRSET:\nprintk(KERN_INFO \"INFO: ISDN_DW_ABC_EXTENSION not enabled\\n\");\nreturn (-EINVAL);\ncase IIOCNETLCR:\nprintk(KERN_INFO \"INFO: ISDN_ABC_LCR_SUPPORT not enabled\\n\");\nreturn -ENODEV;\ncase IIOCNETAIF:\nif (arg) {\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\ns = name;\n} else {\ns = NULL;\n}\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nif ((s = isdn_net_new(s, NULL))) {\nif (copy_to_user(argp, s, strlen(s) + 1)) {\nret = -EFAULT;\n} else {\nret = 0;\n}\n} else\nret = -ENODEV;\nmutex_unlock(&dev->mtx);\nreturn ret;\ncase IIOCNETASL:\nif (arg) {\nif (copy_from_user(bname, argp, sizeof(bname) - 1))\nreturn -EFAULT;\nbname[sizeof(bname)-1] = 0;\n} else\nreturn -EINVAL;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nif ((s = isdn_net_newslave(bname))) {\nif (copy_to_user(argp, s, strlen(s) + 1)) {\nret = -EFAULT;\n} else {\nret = 0;\n}\n} else\nret = -ENODEV;\nmutex_unlock(&dev->mtx);\nreturn ret;\ncase IIOCNETDIF:\nif (arg) {\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_rm(name);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETSCF:\nif (arg) {\nif (copy_from_user(&cfg, argp, sizeof(cfg)))\nreturn -EFAULT;\nreturn isdn_net_setcfg(&cfg);\n} else\nreturn -EINVAL;\ncase IIOCNETGCF:\nif (arg) {\nif (copy_from_user(&cfg, argp, sizeof(cfg)))\nreturn -EFAULT;\nif (!(ret = isdn_net_getcfg(&cfg))) {\nif (copy_to_user(argp, &cfg, sizeof(cfg)))\nreturn -EFAULT;\n}\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETANM:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_addphone(&phone);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETGNM:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_getphones(&phone, argp);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETDNM:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_delphone(&phone);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETDIL:\nif (arg) {\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_net_force_dial(name);\n} else\nreturn -EINVAL;\n#ifdef CONFIG_ISDN_PPP\ncase IIOCNETALN:\nif (!arg)\nreturn -EINVAL;\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_ppp_dial_slave(name);\ncase IIOCNETDLN:\nif (!arg)\nreturn -EINVAL;\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_ppp_hangup_slave(name);\n#endif\ncase IIOCNETHUP:\nif (!arg)\nreturn -EINVAL;\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_net_force_hangup(name);\nbreak;\ncase IIOCSETVER:\ndev->net_verbose = arg;\nprintk(KERN_INFO \"isdn: Verbose-Level is %d\\n\", dev->net_verbose);\nreturn 0;\ncase IIOCSETGST:\nif (arg)\ndev->global_flags |= ISDN_GLOBAL_STOPPED;\nelse\ndev->global_flags &= ~ISDN_GLOBAL_STOPPED;\nprintk(KERN_INFO \"isdn: Global Mode %s\\n\",\n(dev->global_flags & ISDN_GLOBAL_STOPPED) ? \"stopped\" : \"running\");\nreturn 0;\ncase IIOCSETBRJ:\ndrvidx = -1;\nif (arg) {\nint i;\nchar *p;\nif (copy_from_user(&iocts, argp,\nsizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\niocts.drvid[sizeof(iocts.drvid) - 1] = 0;\nif (strlen(iocts.drvid)) {\nif ((p = strchr(iocts.drvid, ',')))\n*p = 0;\ndrvidx = -1;\nfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\nif (!(strcmp(dev->drvid[i], iocts.drvid))) {\ndrvidx = i;\nbreak;\n}\n}\n}\nif (drvidx == -1)\nreturn -ENODEV;\nif (iocts.arg)\ndev->drv[drvidx]->flags |= DRV_FLAG_REJBUS;\nelse\ndev->drv[drvidx]->flags &= ~DRV_FLAG_REJBUS;\nreturn 0;\ncase IIOCSIGPRF:\ndev->profd = current;\nreturn 0;\nbreak;\ncase IIOCGETPRF:\nif (arg) {\nchar __user *p = argp;\nint i;\nfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\nif (copy_to_user(p, dev->mdm.info[i].emu.profile,\nISDN_MODEM_NUMREG))\nreturn -EFAULT;\np += ISDN_MODEM_NUMREG;\nif (copy_to_user(p, dev->mdm.info[i].emu.pmsn, ISDN_MSNLEN))\nreturn -EFAULT;\np += ISDN_MSNLEN;\nif (copy_to_user(p, dev->mdm.info[i].emu.plmsn, ISDN_LMSNLEN))\nreturn -EFAULT;\np += ISDN_LMSNLEN;\n}\nreturn (ISDN_MODEM_NUMREG + ISDN_MSNLEN + ISDN_LMSNLEN) * ISDN_MAX_CHANNELS;\n} else\nreturn -EINVAL;\nbreak;\ncase IIOCSETPRF:\nif (arg) {\nchar __user *p = argp;\nint i;\nfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\nif (copy_from_user(dev->mdm.info[i].emu.profile, p,\nISDN_MODEM_NUMREG))\nreturn -EFAULT;\np += ISDN_MODEM_NUMREG;\nif (copy_from_user(dev->mdm.info[i].emu.plmsn, p, ISDN_LMSNLEN))\nreturn -EFAULT;\np += ISDN_LMSNLEN;\nif (copy_from_user(dev->mdm.info[i].emu.pmsn, p, ISDN_MSNLEN))\nreturn -EFAULT;\np += ISDN_MSNLEN;\n}\nreturn 0;\n} else\nreturn -EINVAL;\nbreak;\ncase IIOCSETMAP:\ncase IIOCGETMAP:\nif (arg) {\nif (copy_from_user(&iocts, argp,\nsizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\niocts.drvid[sizeof(iocts.drvid) - 1] = 0;\nif (strlen(iocts.drvid)) {\ndrvidx = -1;\nfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\nif (!(strcmp(dev->drvid[i], iocts.drvid))) {\ndrvidx = i;\nbreak;\n}\n} else\ndrvidx = 0;\nif (drvidx == -1)\nreturn -ENODEV;\nif (cmd == IIOCSETMAP) {\nint loop = 1;\np = (char __user *) iocts.arg;\ni = 0;\nwhile (loop) {\nint j = 0;\nwhile (1) {\nget_user(bname[j], p++);\nswitch (bname[j]) {\ncase '\\0':\nloop = 0;\ncase ',':\nbname[j] = '\\0';\nstrcpy(dev->drv[drvidx]->msn2eaz[i], bname);\nj = ISDN_MSNLEN;\nbreak;\ndefault:\nj++;\n}\nif (j >= ISDN_MSNLEN)\nbreak;\n}\nif (++i > 9)\nbreak;\n}\n} else {\np = (char __user *) iocts.arg;\nfor (i = 0; i < 10; i++) {\nsnprintf(bname, sizeof(bname), \"%s%s\",\nstrlen(dev->drv[drvidx]->msn2eaz[i]) ?\ndev->drv[drvidx]->msn2eaz[i] : \"_\",\n(i < 9) ? \",\" : \"\\0\");\nif (copy_to_user(p, bname, strlen(bname) + 1))\nreturn -EFAULT;\np += strlen(bname);\n}\n}\nreturn 0;\n} else\nreturn -EINVAL;\ncase IIOCDBGVAR:\nif (arg) {\nif (copy_to_user(argp, &dev, sizeof(ulong)))\nreturn -EFAULT;\nreturn 0;\n} else\nreturn -EINVAL;\nbreak;\ndefault:\nif ((cmd & IIOCDRVCTL) == IIOCDRVCTL)\ncmd = ((cmd >> _IOC_NRSHIFT) & _IOC_NRMASK) & ISDN_DRVIOCTL_MASK;\nelse\nreturn -EINVAL;\nif (arg) {\nint i;\nchar *p;\nif (copy_from_user(&iocts, argp, sizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\niocts.drvid[sizeof(iocts.drvid) - 1] = 0;\nif (strlen(iocts.drvid)) {\nif ((p = strchr(iocts.drvid, ',')))\n*p = 0;\ndrvidx = -1;\nfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\nif (!(strcmp(dev->drvid[i], iocts.drvid))) {\ndrvidx = i;\nbreak;\n}\n} else\ndrvidx = 0;\nif (drvidx == -1)\nreturn -ENODEV;\nc.driver = drvidx;\nc.command = ISDN_CMD_IOCTL;\nc.arg = cmd;\nmemcpy(c.parm.num, &iocts.arg, sizeof(ulong));\nret = isdn_command(&c);\nmemcpy(&iocts.arg, c.parm.num, sizeof(ulong));\nif (copy_to_user(argp, &iocts, sizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\nreturn ret;\n} else\nreturn -EINVAL;\n}\n}\n#ifdef CONFIG_ISDN_PPP\nif (minor <= ISDN_MINOR_PPPMAX)\nreturn (isdn_ppp_ioctl(minor - ISDN_MINOR_PPP, file, cmd, arg));\n#endif\nreturn -ENODEV;\n#undef name\n#undef bname\n#undef iocts\n#undef phone\n#undef cfg\n}\n",
      "code_before_change_raw": "static int\nisdn_ioctl(struct file *file, uint cmd, ulong arg)\n{\nuint minor = iminor(file_inode(file));\nisdn_ctrl c;\nint drvidx;\nint ret;\nint i;\nchar __user *p;\nchar *s;\nunion iocpar {\nchar name[10];\nchar bname[22];\nisdn_ioctl_struct iocts;\nisdn_net_ioctl_phone phone;\nisdn_net_ioctl_cfg cfg;\n} iocpar;\nvoid __user *argp = (void __user *)arg;\n#define name  iocpar.name\n#define bname iocpar.bname\n#define iocts iocpar.iocts\n#define phone iocpar.phone\n#define cfg   iocpar.cfg\nif (minor == ISDN_MINOR_STATUS) {\nswitch (cmd) {\ncase IIOCGETDVR:\nreturn (TTY_DV +\n(NET_DV << 8) +\n(INF_DV << 16));\ncase IIOCGETCPS:\nif (arg) {\nulong __user *p = argp;\nint i;\nfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\nput_user(dev->ibytes[i], p++);\nput_user(dev->obytes[i], p++);\n}\nreturn 0;\n} else\nreturn -EINVAL;\nbreak;\ncase IIOCNETGPN:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nreturn isdn_net_getpeer(&phone, argp);\n} else\nreturn -EINVAL;\ndefault:\nreturn -EINVAL;\n}\n}\nif (!dev->drivers)\nreturn -ENODEV;\nif (minor <= ISDN_MINOR_BMAX) {\ndrvidx = isdn_minor2drv(minor);\nif (drvidx < 0)\nreturn -ENODEV;\nif (!(dev->drv[drvidx]->flags & DRV_FLAG_RUNNING))\nreturn -ENODEV;\nreturn 0;\n}\nif (minor <= ISDN_MINOR_CTRLMAX) {\nswitch (cmd) {\ncase IIOCNETDWRSET:\nprintk(KERN_INFO \"INFO: ISDN_DW_ABC_EXTENSION not enabled\\n\");\nreturn (-EINVAL);\ncase IIOCNETLCR:\nprintk(KERN_INFO \"INFO: ISDN_ABC_LCR_SUPPORT not enabled\\n\");\nreturn -ENODEV;\ncase IIOCNETAIF:\nif (arg) {\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\ns = name;\n} else {\ns = NULL;\n}\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nif ((s = isdn_net_new(s, NULL))) {\nif (copy_to_user(argp, s, strlen(s) + 1)) {\nret = -EFAULT;\n} else {\nret = 0;\n}\n} else\nret = -ENODEV;\nmutex_unlock(&dev->mtx);\nreturn ret;\ncase IIOCNETASL:\nif (arg) {\nif (copy_from_user(bname, argp, sizeof(bname) - 1))\nreturn -EFAULT;\n} else\nreturn -EINVAL;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nif ((s = isdn_net_newslave(bname))) {\nif (copy_to_user(argp, s, strlen(s) + 1)) {\nret = -EFAULT;\n} else {\nret = 0;\n}\n} else\nret = -ENODEV;\nmutex_unlock(&dev->mtx);\nreturn ret;\ncase IIOCNETDIF:\nif (arg) {\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_rm(name);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETSCF:\nif (arg) {\nif (copy_from_user(&cfg, argp, sizeof(cfg)))\nreturn -EFAULT;\nreturn isdn_net_setcfg(&cfg);\n} else\nreturn -EINVAL;\ncase IIOCNETGCF:\nif (arg) {\nif (copy_from_user(&cfg, argp, sizeof(cfg)))\nreturn -EFAULT;\nif (!(ret = isdn_net_getcfg(&cfg))) {\nif (copy_to_user(argp, &cfg, sizeof(cfg)))\nreturn -EFAULT;\n}\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETANM:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_addphone(&phone);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETGNM:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_getphones(&phone, argp);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETDNM:\nif (arg) {\nif (copy_from_user(&phone, argp, sizeof(phone)))\nreturn -EFAULT;\nret = mutex_lock_interruptible(&dev->mtx);\nif (ret) return ret;\nret = isdn_net_delphone(&phone);\nmutex_unlock(&dev->mtx);\nreturn ret;\n} else\nreturn -EINVAL;\ncase IIOCNETDIL:\nif (arg) {\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_net_force_dial(name);\n} else\nreturn -EINVAL;\n#ifdef CONFIG_ISDN_PPP\ncase IIOCNETALN:\nif (!arg)\nreturn -EINVAL;\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_ppp_dial_slave(name);\ncase IIOCNETDLN:\nif (!arg)\nreturn -EINVAL;\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_ppp_hangup_slave(name);\n#endif\ncase IIOCNETHUP:\nif (!arg)\nreturn -EINVAL;\nif (copy_from_user(name, argp, sizeof(name)))\nreturn -EFAULT;\nreturn isdn_net_force_hangup(name);\nbreak;\ncase IIOCSETVER:\ndev->net_verbose = arg;\nprintk(KERN_INFO \"isdn: Verbose-Level is %d\\n\", dev->net_verbose);\nreturn 0;\ncase IIOCSETGST:\nif (arg)\ndev->global_flags |= ISDN_GLOBAL_STOPPED;\nelse\ndev->global_flags &= ~ISDN_GLOBAL_STOPPED;\nprintk(KERN_INFO \"isdn: Global Mode %s\\n\",\n(dev->global_flags & ISDN_GLOBAL_STOPPED) ? \"stopped\" : \"running\");\nreturn 0;\ncase IIOCSETBRJ:\ndrvidx = -1;\nif (arg) {\nint i;\nchar *p;\nif (copy_from_user(&iocts, argp,\nsizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\niocts.drvid[sizeof(iocts.drvid) - 1] = 0;\nif (strlen(iocts.drvid)) {\nif ((p = strchr(iocts.drvid, ',')))\n*p = 0;\ndrvidx = -1;\nfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\nif (!(strcmp(dev->drvid[i], iocts.drvid))) {\ndrvidx = i;\nbreak;\n}\n}\n}\nif (drvidx == -1)\nreturn -ENODEV;\nif (iocts.arg)\ndev->drv[drvidx]->flags |= DRV_FLAG_REJBUS;\nelse\ndev->drv[drvidx]->flags &= ~DRV_FLAG_REJBUS;\nreturn 0;\ncase IIOCSIGPRF:\ndev->profd = current;\nreturn 0;\nbreak;\ncase IIOCGETPRF:\nif (arg) {\nchar __user *p = argp;\nint i;\nfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\nif (copy_to_user(p, dev->mdm.info[i].emu.profile,\nISDN_MODEM_NUMREG))\nreturn -EFAULT;\np += ISDN_MODEM_NUMREG;\nif (copy_to_user(p, dev->mdm.info[i].emu.pmsn, ISDN_MSNLEN))\nreturn -EFAULT;\np += ISDN_MSNLEN;\nif (copy_to_user(p, dev->mdm.info[i].emu.plmsn, ISDN_LMSNLEN))\nreturn -EFAULT;\np += ISDN_LMSNLEN;\n}\nreturn (ISDN_MODEM_NUMREG + ISDN_MSNLEN + ISDN_LMSNLEN) * ISDN_MAX_CHANNELS;\n} else\nreturn -EINVAL;\nbreak;\ncase IIOCSETPRF:\nif (arg) {\nchar __user *p = argp;\nint i;\nfor (i = 0; i < ISDN_MAX_CHANNELS; i++) {\nif (copy_from_user(dev->mdm.info[i].emu.profile, p,\nISDN_MODEM_NUMREG))\nreturn -EFAULT;\np += ISDN_MODEM_NUMREG;\nif (copy_from_user(dev->mdm.info[i].emu.plmsn, p, ISDN_LMSNLEN))\nreturn -EFAULT;\np += ISDN_LMSNLEN;\nif (copy_from_user(dev->mdm.info[i].emu.pmsn, p, ISDN_MSNLEN))\nreturn -EFAULT;\np += ISDN_MSNLEN;\n}\nreturn 0;\n} else\nreturn -EINVAL;\nbreak;\ncase IIOCSETMAP:\ncase IIOCGETMAP:\nif (arg) {\nif (copy_from_user(&iocts, argp,\nsizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\niocts.drvid[sizeof(iocts.drvid) - 1] = 0;\nif (strlen(iocts.drvid)) {\ndrvidx = -1;\nfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\nif (!(strcmp(dev->drvid[i], iocts.drvid))) {\ndrvidx = i;\nbreak;\n}\n} else\ndrvidx = 0;\nif (drvidx == -1)\nreturn -ENODEV;\nif (cmd == IIOCSETMAP) {\nint loop = 1;\np = (char __user *) iocts.arg;\ni = 0;\nwhile (loop) {\nint j = 0;\nwhile (1) {\nget_user(bname[j], p++);\nswitch (bname[j]) {\ncase '\\0':\nloop = 0;\ncase ',':\nbname[j] = '\\0';\nstrcpy(dev->drv[drvidx]->msn2eaz[i], bname);\nj = ISDN_MSNLEN;\nbreak;\ndefault:\nj++;\n}\nif (j >= ISDN_MSNLEN)\nbreak;\n}\nif (++i > 9)\nbreak;\n}\n} else {\np = (char __user *) iocts.arg;\nfor (i = 0; i < 10; i++) {\nsnprintf(bname, sizeof(bname), \"%s%s\",\nstrlen(dev->drv[drvidx]->msn2eaz[i]) ?\ndev->drv[drvidx]->msn2eaz[i] : \"_\",\n(i < 9) ? \",\" : \"\\0\");\nif (copy_to_user(p, bname, strlen(bname) + 1))\nreturn -EFAULT;\np += strlen(bname);\n}\n}\nreturn 0;\n} else\nreturn -EINVAL;\ncase IIOCDBGVAR:\nif (arg) {\nif (copy_to_user(argp, &dev, sizeof(ulong)))\nreturn -EFAULT;\nreturn 0;\n} else\nreturn -EINVAL;\nbreak;\ndefault:\nif ((cmd & IIOCDRVCTL) == IIOCDRVCTL)\ncmd = ((cmd >> _IOC_NRSHIFT) & _IOC_NRMASK) & ISDN_DRVIOCTL_MASK;\nelse\nreturn -EINVAL;\nif (arg) {\nint i;\nchar *p;\nif (copy_from_user(&iocts, argp, sizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\niocts.drvid[sizeof(iocts.drvid) - 1] = 0;\nif (strlen(iocts.drvid)) {\nif ((p = strchr(iocts.drvid, ',')))\n*p = 0;\ndrvidx = -1;\nfor (i = 0; i < ISDN_MAX_DRIVERS; i++)\nif (!(strcmp(dev->drvid[i], iocts.drvid))) {\ndrvidx = i;\nbreak;\n}\n} else\ndrvidx = 0;\nif (drvidx == -1)\nreturn -ENODEV;\nc.driver = drvidx;\nc.command = ISDN_CMD_IOCTL;\nc.arg = cmd;\nmemcpy(c.parm.num, &iocts.arg, sizeof(ulong));\nret = isdn_command(&c);\nmemcpy(&iocts.arg, c.parm.num, sizeof(ulong));\nif (copy_to_user(argp, &iocts, sizeof(isdn_ioctl_struct)))\nreturn -EFAULT;\nreturn ret;\n} else\nreturn -EINVAL;\n}\n}\n#ifdef CONFIG_ISDN_PPP\nif (minor <= ISDN_MINOR_PPPMAX)\nreturn (isdn_ppp_ioctl(minor - ISDN_MINOR_PPP, file, cmd, arg));\n#endif\nreturn -ENODEV;\n#undef name\n#undef bname\n#undef iocts\n#undef phone\n#undef cfg\n}\n"
    }
  ],
  "CVE-2017-14497": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of vnet headers in the tpacket_rcv function.",
        "trigger_condition": "Crafted system calls that manipulate vnet headers trigger a buffer overflow, disk corruption, and memory corruption vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code mishandles vnet headers, potentially allowing local users to cause a denial of service by triggering a buffer overflow, disk corruption, and memory corruption through crafted system calls.",
        "specific_solution": "To mitigate the vulnerability, it is necessary to properly handle vnet headers in the tpacket_rcv function. This involves adding a 'do_vnet' flag to track the presence of vnet headers and adjusting the behavior accordingly. By setting the flag to true when dealing with vnet headers, the code ensures that the necessary checks and actions are taken to prevent buffer overflow, disk corruption, and memory corruption caused by crafted system calls."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-14497, which involves mishandling vnet headers in the tpacket_rcv function. By adding the 'do_vnet' flag and setting it to true when dealing with vnet headers, the code ensures that the necessary checks and actions are taken to prevent buffer overflow, disk corruption, and memory corruption that could be caused by crafted system calls. By properly handling vnet headers and adjusting the behavior based on the 'do_vnet' flag, the code mitigates the vulnerability and improves the overall security of the function.",
      "GPT_purpose": "Receiving and processing packets in the AF_PACKET socket implementation in the Linux kernel.",
      "GPT_function": "\n1. Receiving packets and processing them in the tpacket_rcv function.\n2. Handling packet filtering and checksum validation.\n3. Managing packet data length and offsets for different packet types.\n4. Dealing with packet size constraints and potential buffer overflows.\n5. Setting packet metadata and network headers.\n6. Handling timestamp information for packets.\n7. Populating packet headers based on the TPACKET version.\n8. Setting socket and packet status for different TPACKET versions.\n9. Handling packet drops and memory management.\n10. Returning 0 after processing the packet.",
      "CVE_id": "CVE-2017-14497",
      "code_before_change": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t       struct packet_type *pt, struct net_device *orig_dev)\n{\n\tstruct sock *sk;\n\tstruct packet_sock *po;\n\tstruct sockaddr_ll *sll;\n\tunion tpacket_uhdr h;\n\tu8 *skb_head = skb->data;\n\tint skb_len = skb->len;\n\tunsigned int snaplen, res;\n\tunsigned long status = TP_STATUS_USER;\n\tunsigned short macoff, netoff, hdrlen;\n\tstruct sk_buff *copy_skb = NULL;\n\tstruct timespec ts;\n\t__u32 ts_status;\n\tbool is_drop_n_account = false;\n\n\t/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.\n\t * We may add members to them until current aligned size without forcing\n\t * userspace to call getsockopt(..., PACKET_HDRLEN, ...).\n\t */\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\n\n\tif (skb->pkt_type == PACKET_LOOPBACK)\n\t\tgoto drop;\n\n\tsk = pt->af_packet_priv;\n\tpo = pkt_sk(sk);\n\n\tif (!net_eq(dev_net(dev), sock_net(sk)))\n\t\tgoto drop;\n\n\tif (dev->header_ops) {\n\t\tif (sk->sk_type != SOCK_DGRAM)\n\t\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\t\telse if (skb->pkt_type == PACKET_OUTGOING) {\n\t\t\t/* Special case: outgoing packets have ll header at head */\n\t\t\tskb_pull(skb, skb_network_offset(skb));\n\t\t}\n\t}\n\n\tsnaplen = skb->len;\n\n\tres = run_filter(skb, sk, snaplen);\n\tif (!res)\n\t\tgoto drop_n_restore;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tstatus |= TP_STATUS_CSUMNOTREADY;\n\telse if (skb->pkt_type != PACKET_OUTGOING &&\n\t\t (skb->ip_summed == CHECKSUM_COMPLETE ||\n\t\t  skb_csum_unnecessary(skb)))\n\t\tstatus |= TP_STATUS_CSUM_VALID;\n\n\tif (snaplen > res)\n\t\tsnaplen = res;\n\n\tif (sk->sk_type == SOCK_DGRAM) {\n\t\tmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\n\t\t\t\t  po->tp_reserve;\n\t} else {\n\t\tunsigned int maclen = skb_network_offset(skb);\n\t\tnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n\t\t\t\t       (maclen < 16 ? 16 : maclen)) +\n\t\t\t\t       po->tp_reserve;\n\t\tif (po->has_vnet_hdr)\n\t\t\tnetoff += sizeof(struct virtio_net_hdr);\n\t\tmacoff = netoff - maclen;\n\t}\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tif (macoff + snaplen > po->rx_ring.frame_size) {\n\t\t\tif (po->copy_thresh &&\n\t\t\t    atomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\n\t\t\t\tif (skb_shared(skb)) {\n\t\t\t\t\tcopy_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\t} else {\n\t\t\t\t\tcopy_skb = skb_get(skb);\n\t\t\t\t\tskb_head = skb->data;\n\t\t\t\t}\n\t\t\t\tif (copy_skb)\n\t\t\t\t\tskb_set_owner_r(copy_skb, sk);\n\t\t\t}\n\t\t\tsnaplen = po->rx_ring.frame_size - macoff;\n\t\t\tif ((int)snaplen < 0)\n\t\t\t\tsnaplen = 0;\n\t\t}\n\t} else if (unlikely(macoff + snaplen >\n\t\t\t    GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\n\t\tu32 nval;\n\n\t\tnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\n\t\tpr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\n\t\t\t    snaplen, nval, macoff);\n\t\tsnaplen = nval;\n\t\tif (unlikely((int)snaplen < 0)) {\n\t\t\tsnaplen = 0;\n\t\t\tmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n\t\t}\n\t}\n\tspin_lock(&sk->sk_receive_queue.lock);\n\th.raw = packet_current_rx_frame(po, skb,\n\t\t\t\t\tTP_STATUS_KERNEL, (macoff+snaplen));\n\tif (!h.raw)\n\t\tgoto drop_n_account;\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tpacket_increment_rx_head(po, &po->rx_ring);\n\t/*\n\t * LOSING will be reported till you read the stats,\n\t * because it's COR - Clear On Read.\n\t * Anyways, moving it for V1/V2 only as V3 doesn't need this\n\t * at packet level.\n\t */\n\t\tif (po->stats.stats1.tp_drops)\n\t\t\tstatus |= TP_STATUS_LOSING;\n\t}\n\tpo->stats.stats1.tp_packets++;\n\tif (copy_skb) {\n\t\tstatus |= TP_STATUS_COPY;\n\t\t__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tif (po->has_vnet_hdr) {\n\t\tif (virtio_net_hdr_from_skb(skb, h.raw + macoff -\n\t\t\t\t\t    sizeof(struct virtio_net_hdr),\n\t\t\t\t\t    vio_le(), true)) {\n\t\t\tspin_lock(&sk->sk_receive_queue.lock);\n\t\t\tgoto drop_n_account;\n\t\t}\n\t}\n\n\tskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\n\n\tif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\n\t\tgetnstimeofday(&ts);\n\n\tstatus |= ts_status;\n\n\tswitch (po->tp_version) {\n\tcase TPACKET_V1:\n\t\th.h1->tp_len = skb->len;\n\t\th.h1->tp_snaplen = snaplen;\n\t\th.h1->tp_mac = macoff;\n\t\th.h1->tp_net = netoff;\n\t\th.h1->tp_sec = ts.tv_sec;\n\t\th.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\n\t\thdrlen = sizeof(*h.h1);\n\t\tbreak;\n\tcase TPACKET_V2:\n\t\th.h2->tp_len = skb->len;\n\t\th.h2->tp_snaplen = snaplen;\n\t\th.h2->tp_mac = macoff;\n\t\th.h2->tp_net = netoff;\n\t\th.h2->tp_sec = ts.tv_sec;\n\t\th.h2->tp_nsec = ts.tv_nsec;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\th.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\n\t\t\th.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\n\t\t\tstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n\t\t} else {\n\t\t\th.h2->tp_vlan_tci = 0;\n\t\t\th.h2->tp_vlan_tpid = 0;\n\t\t}\n\t\tmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\n\t\thdrlen = sizeof(*h.h2);\n\t\tbreak;\n\tcase TPACKET_V3:\n\t\t/* tp_nxt_offset,vlan are already populated above.\n\t\t * So DONT clear those fields here\n\t\t */\n\t\th.h3->tp_status |= status;\n\t\th.h3->tp_len = skb->len;\n\t\th.h3->tp_snaplen = snaplen;\n\t\th.h3->tp_mac = macoff;\n\t\th.h3->tp_net = netoff;\n\t\th.h3->tp_sec  = ts.tv_sec;\n\t\th.h3->tp_nsec = ts.tv_nsec;\n\t\tmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\n\t\thdrlen = sizeof(*h.h3);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tsll = h.raw + TPACKET_ALIGN(hdrlen);\n\tsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\n\tsll->sll_family = AF_PACKET;\n\tsll->sll_hatype = dev->type;\n\tsll->sll_protocol = skb->protocol;\n\tsll->sll_pkttype = skb->pkt_type;\n\tif (unlikely(po->origdev))\n\t\tsll->sll_ifindex = orig_dev->ifindex;\n\telse\n\t\tsll->sll_ifindex = dev->ifindex;\n\n\tsmp_mb();\n\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tu8 *start, *end;\n\n\t\tend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\n\t\t\t\t\tmacoff + snaplen);\n\n\t\tfor (start = h.raw; start < end; start += PAGE_SIZE)\n\t\t\tflush_dcache_page(pgv_to_page(start));\n\t}\n\tsmp_wmb();\n#endif\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\t__packet_set_status(po, h.raw, status);\n\t\tsk->sk_data_ready(sk);\n\t} else {\n\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t}\n\ndrop_n_restore:\n\tif (skb_head != skb->data && skb_shared(skb)) {\n\t\tskb->data = skb_head;\n\t\tskb->len = skb_len;\n\t}\ndrop:\n\tif (!is_drop_n_account)\n\t\tconsume_skb(skb);\n\telse\n\t\tkfree_skb(skb);\n\treturn 0;\n\ndrop_n_account:\n\tis_drop_n_account = true;\n\tpo->stats.stats1.tp_drops++;\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tsk->sk_data_ready(sk);\n\tkfree_skb(copy_skb);\n\tgoto drop_n_restore;\n}",
      "code_after_change": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t       struct packet_type *pt, struct net_device *orig_dev)\n{\n\tstruct sock *sk;\n\tstruct packet_sock *po;\n\tstruct sockaddr_ll *sll;\n\tunion tpacket_uhdr h;\n\tu8 *skb_head = skb->data;\n\tint skb_len = skb->len;\n\tunsigned int snaplen, res;\n\tunsigned long status = TP_STATUS_USER;\n\tunsigned short macoff, netoff, hdrlen;\n\tstruct sk_buff *copy_skb = NULL;\n\tstruct timespec ts;\n\t__u32 ts_status;\n\tbool is_drop_n_account = false;\n\tbool do_vnet = false;\n\n\t/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.\n\t * We may add members to them until current aligned size without forcing\n\t * userspace to call getsockopt(..., PACKET_HDRLEN, ...).\n\t */\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\n\n\tif (skb->pkt_type == PACKET_LOOPBACK)\n\t\tgoto drop;\n\n\tsk = pt->af_packet_priv;\n\tpo = pkt_sk(sk);\n\n\tif (!net_eq(dev_net(dev), sock_net(sk)))\n\t\tgoto drop;\n\n\tif (dev->header_ops) {\n\t\tif (sk->sk_type != SOCK_DGRAM)\n\t\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\t\telse if (skb->pkt_type == PACKET_OUTGOING) {\n\t\t\t/* Special case: outgoing packets have ll header at head */\n\t\t\tskb_pull(skb, skb_network_offset(skb));\n\t\t}\n\t}\n\n\tsnaplen = skb->len;\n\n\tres = run_filter(skb, sk, snaplen);\n\tif (!res)\n\t\tgoto drop_n_restore;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tstatus |= TP_STATUS_CSUMNOTREADY;\n\telse if (skb->pkt_type != PACKET_OUTGOING &&\n\t\t (skb->ip_summed == CHECKSUM_COMPLETE ||\n\t\t  skb_csum_unnecessary(skb)))\n\t\tstatus |= TP_STATUS_CSUM_VALID;\n\n\tif (snaplen > res)\n\t\tsnaplen = res;\n\n\tif (sk->sk_type == SOCK_DGRAM) {\n\t\tmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\n\t\t\t\t  po->tp_reserve;\n\t} else {\n\t\tunsigned int maclen = skb_network_offset(skb);\n\t\tnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n\t\t\t\t       (maclen < 16 ? 16 : maclen)) +\n\t\t\t\t       po->tp_reserve;\n\t\tif (po->has_vnet_hdr) {\n\t\t\tnetoff += sizeof(struct virtio_net_hdr);\n\t\t\tdo_vnet = true;\n\t\t}\n\t\tmacoff = netoff - maclen;\n\t}\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tif (macoff + snaplen > po->rx_ring.frame_size) {\n\t\t\tif (po->copy_thresh &&\n\t\t\t    atomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\n\t\t\t\tif (skb_shared(skb)) {\n\t\t\t\t\tcopy_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\t} else {\n\t\t\t\t\tcopy_skb = skb_get(skb);\n\t\t\t\t\tskb_head = skb->data;\n\t\t\t\t}\n\t\t\t\tif (copy_skb)\n\t\t\t\t\tskb_set_owner_r(copy_skb, sk);\n\t\t\t}\n\t\t\tsnaplen = po->rx_ring.frame_size - macoff;\n\t\t\tif ((int)snaplen < 0) {\n\t\t\t\tsnaplen = 0;\n\t\t\t\tdo_vnet = false;\n\t\t\t}\n\t\t}\n\t} else if (unlikely(macoff + snaplen >\n\t\t\t    GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\n\t\tu32 nval;\n\n\t\tnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\n\t\tpr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\n\t\t\t    snaplen, nval, macoff);\n\t\tsnaplen = nval;\n\t\tif (unlikely((int)snaplen < 0)) {\n\t\t\tsnaplen = 0;\n\t\t\tmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n\t\t\tdo_vnet = false;\n\t\t}\n\t}\n\tspin_lock(&sk->sk_receive_queue.lock);\n\th.raw = packet_current_rx_frame(po, skb,\n\t\t\t\t\tTP_STATUS_KERNEL, (macoff+snaplen));\n\tif (!h.raw)\n\t\tgoto drop_n_account;\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tpacket_increment_rx_head(po, &po->rx_ring);\n\t/*\n\t * LOSING will be reported till you read the stats,\n\t * because it's COR - Clear On Read.\n\t * Anyways, moving it for V1/V2 only as V3 doesn't need this\n\t * at packet level.\n\t */\n\t\tif (po->stats.stats1.tp_drops)\n\t\t\tstatus |= TP_STATUS_LOSING;\n\t}\n\tpo->stats.stats1.tp_packets++;\n\tif (copy_skb) {\n\t\tstatus |= TP_STATUS_COPY;\n\t\t__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tif (do_vnet) {\n\t\tif (virtio_net_hdr_from_skb(skb, h.raw + macoff -\n\t\t\t\t\t    sizeof(struct virtio_net_hdr),\n\t\t\t\t\t    vio_le(), true)) {\n\t\t\tspin_lock(&sk->sk_receive_queue.lock);\n\t\t\tgoto drop_n_account;\n\t\t}\n\t}\n\n\tskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\n\n\tif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\n\t\tgetnstimeofday(&ts);\n\n\tstatus |= ts_status;\n\n\tswitch (po->tp_version) {\n\tcase TPACKET_V1:\n\t\th.h1->tp_len = skb->len;\n\t\th.h1->tp_snaplen = snaplen;\n\t\th.h1->tp_mac = macoff;\n\t\th.h1->tp_net = netoff;\n\t\th.h1->tp_sec = ts.tv_sec;\n\t\th.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\n\t\thdrlen = sizeof(*h.h1);\n\t\tbreak;\n\tcase TPACKET_V2:\n\t\th.h2->tp_len = skb->len;\n\t\th.h2->tp_snaplen = snaplen;\n\t\th.h2->tp_mac = macoff;\n\t\th.h2->tp_net = netoff;\n\t\th.h2->tp_sec = ts.tv_sec;\n\t\th.h2->tp_nsec = ts.tv_nsec;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\th.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\n\t\t\th.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\n\t\t\tstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n\t\t} else {\n\t\t\th.h2->tp_vlan_tci = 0;\n\t\t\th.h2->tp_vlan_tpid = 0;\n\t\t}\n\t\tmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\n\t\thdrlen = sizeof(*h.h2);\n\t\tbreak;\n\tcase TPACKET_V3:\n\t\t/* tp_nxt_offset,vlan are already populated above.\n\t\t * So DONT clear those fields here\n\t\t */\n\t\th.h3->tp_status |= status;\n\t\th.h3->tp_len = skb->len;\n\t\th.h3->tp_snaplen = snaplen;\n\t\th.h3->tp_mac = macoff;\n\t\th.h3->tp_net = netoff;\n\t\th.h3->tp_sec  = ts.tv_sec;\n\t\th.h3->tp_nsec = ts.tv_nsec;\n\t\tmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\n\t\thdrlen = sizeof(*h.h3);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tsll = h.raw + TPACKET_ALIGN(hdrlen);\n\tsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\n\tsll->sll_family = AF_PACKET;\n\tsll->sll_hatype = dev->type;\n\tsll->sll_protocol = skb->protocol;\n\tsll->sll_pkttype = skb->pkt_type;\n\tif (unlikely(po->origdev))\n\t\tsll->sll_ifindex = orig_dev->ifindex;\n\telse\n\t\tsll->sll_ifindex = dev->ifindex;\n\n\tsmp_mb();\n\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tu8 *start, *end;\n\n\t\tend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\n\t\t\t\t\tmacoff + snaplen);\n\n\t\tfor (start = h.raw; start < end; start += PAGE_SIZE)\n\t\t\tflush_dcache_page(pgv_to_page(start));\n\t}\n\tsmp_wmb();\n#endif\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\t__packet_set_status(po, h.raw, status);\n\t\tsk->sk_data_ready(sk);\n\t} else {\n\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t}\n\ndrop_n_restore:\n\tif (skb_head != skb->data && skb_shared(skb)) {\n\t\tskb->data = skb_head;\n\t\tskb->len = skb_len;\n\t}\ndrop:\n\tif (!is_drop_n_account)\n\t\tconsume_skb(skb);\n\telse\n\t\tkfree_skb(skb);\n\treturn 0;\n\ndrop_n_account:\n\tis_drop_n_account = true;\n\tpo->stats.stats1.tp_drops++;\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tsk->sk_data_ready(sk);\n\tkfree_skb(copy_skb);\n\tgoto drop_n_restore;\n}",
      "modified_lines": {
        "added": [
          "\tbool do_vnet = false;",
          "\t\tif (po->has_vnet_hdr) {",
          "\t\t\tdo_vnet = true;",
          "\t\t}",
          "\t\t\tif ((int)snaplen < 0) {",
          "\t\t\t\tdo_vnet = false;",
          "\t\t\t}",
          "\t\t\tdo_vnet = false;",
          "\tif (do_vnet) {"
        ],
        "deleted": [
          "\t\tif (po->has_vnet_hdr)",
          "\t\t\tif ((int)snaplen < 0)",
          "\tif (po->has_vnet_hdr) {"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of vnet headers in the tpacket_rcv function.",
      "trigger_condition": "Crafted system calls that manipulate vnet headers trigger a buffer overflow, disk corruption, and memory corruption vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code mishandles vnet headers, potentially allowing local users to cause a denial of service by triggering a buffer overflow, disk corruption, and memory corruption through crafted system calls.",
      "id": 103,
      "code_after_change_normalized": "static int FUN1(struct sk_buff *VAR1, struct net_device *VAR2,\nstruct packet_type *VAR3, struct net_device *VAR4)\n{\nstruct sock *VAR5;\nstruct packet_sock *VAR6;\nstruct sockaddr_ll *VAR7;\nunion tpacket_uhdr VAR8;\nu8 *VAR9 = VAR1->VAR10;\nint VAR11 = VAR1->VAR12;\nunsigned int VAR13, VAR14;\nunsigned long VAR15 = VAR16;\nunsigned short VAR17, VAR18, VAR19;\nstruct sk_buff *VAR20 = NULL;\nstruct timespec VAR21;\n__u32 VAR22;\nbool VAR23 = false;\nbool VAR24 = false;\nFUN2(FUN3(sizeof(*VAR8.VAR25)) != 32);\nFUN2(FUN3(sizeof(*VAR8.VAR26)) != 48);\nif (VAR1->VAR27 == VAR28)\ngoto VAR29;\nVAR5 = VAR3->VAR30;\nVAR6 = FUN4(VAR5);\nif (!FUN5(FUN6(VAR2), FUN7(VAR5)))\ngoto VAR29;\nif (VAR2->VAR31) {\nif (VAR5->VAR32 != VAR33)\nFUN8(VAR1, VAR1->VAR10 - FUN9(VAR1));\nelse if (VAR1->VAR27 == VAR34) {\nFUN10(VAR1, FUN11(VAR1));\n}\n}\nVAR13 = VAR1->VAR12;\nVAR14 = FUN12(VAR1, VAR5, VAR13);\nif (!VAR14)\ngoto VAR35;\nif (VAR1->VAR36 == VAR37)\nVAR15 |= VAR38;\nelse if (VAR1->VAR27 != VAR34 &&\n(VAR1->VAR36 == VAR39 ||\nFUN13(VAR1)))\nVAR15 |= VAR40;\nif (VAR13 > VAR14)\nVAR13 = VAR14;\nif (VAR5->VAR32 == VAR33) {\nVAR17 = VAR18 = FUN3(VAR6->VAR41) + 16 +\nVAR6->VAR42;\n} else {\nunsigned int VAR43 = FUN11(VAR1);\nVAR18 = FUN3(VAR6->VAR41 +\n(VAR43 < 16 ? 16 : VAR43)) +\nVAR6->VAR42;\nif (VAR6->VAR44) {\nVAR18 += sizeof(struct VAR45);\nVAR24 = true;\n}\nVAR17 = VAR18 - VAR43;\n}\nif (VAR6->VAR46 <= VAR47) {\nif (VAR17 + VAR13 > VAR6->VAR48.VAR49) {\nif (VAR6->VAR50 &&\nFUN14(&VAR5->VAR51) < VAR5->VAR52) {\nif (FUN15(VAR1)) {\nVAR20 = FUN16(VAR1, VAR53);\n} else {\nVAR20 = FUN17(VAR1);\nVAR9 = VAR1->VAR10;\n}\nif (VAR20)\nFUN18(VAR20, VAR5);\n}\nVAR13 = VAR6->VAR48.VAR49 - VAR17;\nif ((int)VAR13 < 0) {\nVAR13 = 0;\nVAR24 = false;\n}\n}\n} else if (FUN19(VAR17 + VAR13 >\nFUN20(&VAR6->VAR48)->VAR54)) {\nu32 VAR55;\nVAR55 = FUN20(&VAR6->VAR48)->VAR54 - VAR17;\nFUN21(\"STR\",\nVAR13, VAR55, VAR17);\nVAR13 = VAR55;\nif (FUN19((int)VAR13 < 0)) {\nVAR13 = 0;\nVAR17 = FUN20(&VAR6->VAR48)->VAR54;\nVAR24 = false;\n}\n}\nFUN22(&VAR5->VAR56.VAR57);\nVAR8.VAR58 = FUN23(VAR6, VAR1,\nVAR59, (VAR17+VAR13));\nif (!VAR8.VAR58)\ngoto VAR60;\nif (VAR6->VAR46 <= VAR47) {\nFUN24(VAR6, &VAR6->VAR48);\nif (VAR6->VAR61.VAR62.VAR63)\nVAR15 |= VAR64;\n}\nVAR6->VAR61.VAR62.VAR65++;\nif (VAR20) {\nVAR15 |= VAR66;\nFUN25(&VAR5->VAR56, VAR20);\n}\nFUN26(&VAR5->VAR56.VAR57);\nif (VAR24) {\nif (FUN27(VAR1, VAR8.VAR58 + VAR17 -\nsizeof(struct VAR45),\nFUN28(), true)) {\nFUN22(&VAR5->VAR56.VAR57);\ngoto VAR60;\n}\n}\nFUN29(VAR1, 0, VAR8.VAR58 + VAR17, VAR13);\nif (!(VAR22 = FUN30(VAR1, &VAR21, VAR6->VAR67)))\nFUN31(&VAR21);\nVAR15 |= VAR22;\nswitch (VAR6->VAR46) {\ncase VAR68:\nVAR8.VAR69->VAR70 = VAR1->VAR12;\nVAR8.VAR69->VAR71 = VAR13;\nVAR8.VAR69->VAR72 = VAR17;\nVAR8.VAR69->VAR73 = VAR18;\nVAR8.VAR69->VAR74 = VAR21.VAR75;\nVAR8.VAR69->VAR76 = VAR21.VAR77 / VAR78;\nVAR19 = sizeof(*VAR8.VAR69);\nbreak;\ncase VAR47:\nVAR8.VAR25->VAR70 = VAR1->VAR12;\nVAR8.VAR25->VAR71 = VAR13;\nVAR8.VAR25->VAR72 = VAR17;\nVAR8.VAR25->VAR73 = VAR18;\nVAR8.VAR25->VAR74 = VAR21.VAR75;\nVAR8.VAR25->VAR79 = VAR21.VAR77;\nif (FUN32(VAR1)) {\nVAR8.VAR25->VAR80 = FUN33(VAR1);\nVAR8.VAR25->VAR81 = FUN34(VAR1->VAR82);\nVAR15 |= VAR83 | VAR84;\n} else {\nVAR8.VAR25->VAR80 = 0;\nVAR8.VAR25->VAR81 = 0;\n}\nFUN35(VAR8.VAR25->VAR85, 0, sizeof(VAR8.VAR25->VAR85));\nVAR19 = sizeof(*VAR8.VAR25);\nbreak;\ncase VAR86:\nVAR8.VAR26->VAR87 |= VAR15;\nVAR8.VAR26->VAR70 = VAR1->VAR12;\nVAR8.VAR26->VAR71 = VAR13;\nVAR8.VAR26->VAR72 = VAR17;\nVAR8.VAR26->VAR73 = VAR18;\nVAR8.VAR26->VAR74  = VAR21.VAR75;\nVAR8.VAR26->VAR79 = VAR21.VAR77;\nFUN35(VAR8.VAR26->VAR85, 0, sizeof(VAR8.VAR26->VAR85));\nVAR19 = sizeof(*VAR8.VAR26);\nbreak;\ndefault:\nFUN36();\n}\nVAR7 = VAR8.VAR58 + FUN3(VAR19);\nVAR7->VAR88 = FUN37(VAR1, VAR7->VAR89);\nVAR7->VAR90 = VAR91;\nVAR7->VAR92 = VAR2->VAR93;\nVAR7->VAR94 = VAR1->VAR95;\nVAR7->VAR96 = VAR1->VAR27;\nif (FUN19(VAR6->VAR97))\nVAR7->VAR98 = VAR4->VAR99;\nelse\nVAR7->VAR98 = VAR2->VAR99;\nFUN38();\n#if VAR100 == 1\nif (VAR6->VAR46 <= VAR47) {\nu8 *VAR101, *VAR102;\nVAR102 = (VAR103 *) FUN39((unsigned long) VAR8.VAR58 +\nVAR17 + VAR13);\nfor (VAR101 = VAR8.VAR58; VAR101 < VAR102; VAR101 += VAR104)\nFUN40(FUN41(VAR101));\n}\nFUN42();\n#VAR105\nif (VAR6->VAR46 <= VAR47) {\nFUN43(VAR6, VAR8.VAR58, VAR15);\nVAR5->FUN44(VAR5);\n} else {\nFUN45(&VAR6->VAR48);\n}\nVAR35:\nif (VAR9 != VAR1->VAR10 && FUN15(VAR1)) {\nVAR1->VAR10 = VAR9;\nVAR1->VAR12 = VAR11;\n}\nVAR29:\nif (!VAR23)\nFUN46(VAR1);\nelse\nFUN47(VAR1);\nreturn 0;\nVAR60:\nVAR23 = true;\nVAR6->VAR61.VAR62.VAR63++;\nFUN26(&VAR5->VAR56.VAR57);\nVAR5->FUN44(VAR5);\nFUN47(VAR20);\ngoto VAR35;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct sk_buff *VAR1, struct net_device *VAR2,\nstruct packet_type *VAR3, struct net_device *VAR4)\n{\nstruct sock *VAR5;\nstruct packet_sock *VAR6;\nstruct sockaddr_ll *VAR7;\nunion tpacket_uhdr VAR8;\nu8 *VAR9 = VAR1->VAR10;\nint VAR11 = VAR1->VAR12;\nunsigned int VAR13, VAR14;\nunsigned long VAR15 = VAR16;\nunsigned short VAR17, VAR18, VAR19;\nstruct sk_buff *VAR20 = NULL;\nstruct timespec VAR21;\n__u32 VAR22;\nbool VAR23 = false;\nFUN2(FUN3(sizeof(*VAR8.VAR24)) != 32);\nFUN2(FUN3(sizeof(*VAR8.VAR25)) != 48);\nif (VAR1->VAR26 == VAR27)\ngoto VAR28;\nVAR5 = VAR3->VAR29;\nVAR6 = FUN4(VAR5);\nif (!FUN5(FUN6(VAR2), FUN7(VAR5)))\ngoto VAR28;\nif (VAR2->VAR30) {\nif (VAR5->VAR31 != VAR32)\nFUN8(VAR1, VAR1->VAR10 - FUN9(VAR1));\nelse if (VAR1->VAR26 == VAR33) {\nFUN10(VAR1, FUN11(VAR1));\n}\n}\nVAR13 = VAR1->VAR12;\nVAR14 = FUN12(VAR1, VAR5, VAR13);\nif (!VAR14)\ngoto VAR34;\nif (VAR1->VAR35 == VAR36)\nVAR15 |= VAR37;\nelse if (VAR1->VAR26 != VAR33 &&\n(VAR1->VAR35 == VAR38 ||\nFUN13(VAR1)))\nVAR15 |= VAR39;\nif (VAR13 > VAR14)\nVAR13 = VAR14;\nif (VAR5->VAR31 == VAR32) {\nVAR17 = VAR18 = FUN3(VAR6->VAR40) + 16 +\nVAR6->VAR41;\n} else {\nunsigned int VAR42 = FUN11(VAR1);\nVAR18 = FUN3(VAR6->VAR40 +\n(VAR42 < 16 ? 16 : VAR42)) +\nVAR6->VAR41;\nif (VAR6->VAR43)\nVAR18 += sizeof(struct VAR44);\nVAR17 = VAR18 - VAR42;\n}\nif (VAR6->VAR45 <= VAR46) {\nif (VAR17 + VAR13 > VAR6->VAR47.VAR48) {\nif (VAR6->VAR49 &&\nFUN14(&VAR5->VAR50) < VAR5->VAR51) {\nif (FUN15(VAR1)) {\nVAR20 = FUN16(VAR1, VAR52);\n} else {\nVAR20 = FUN17(VAR1);\nVAR9 = VAR1->VAR10;\n}\nif (VAR20)\nFUN18(VAR20, VAR5);\n}\nVAR13 = VAR6->VAR47.VAR48 - VAR17;\nif ((int)VAR13 < 0)\nVAR13 = 0;\n}\n} else if (FUN19(VAR17 + VAR13 >\nFUN20(&VAR6->VAR47)->VAR53)) {\nu32 VAR54;\nVAR54 = FUN20(&VAR6->VAR47)->VAR53 - VAR17;\nFUN21(\"STR\",\nVAR13, VAR54, VAR17);\nVAR13 = VAR54;\nif (FUN19((int)VAR13 < 0)) {\nVAR13 = 0;\nVAR17 = FUN20(&VAR6->VAR47)->VAR53;\n}\n}\nFUN22(&VAR5->VAR55.VAR56);\nVAR8.VAR57 = FUN23(VAR6, VAR1,\nVAR58, (VAR17+VAR13));\nif (!VAR8.VAR57)\ngoto VAR59;\nif (VAR6->VAR45 <= VAR46) {\nFUN24(VAR6, &VAR6->VAR47);\nif (VAR6->VAR60.VAR61.VAR62)\nVAR15 |= VAR63;\n}\nVAR6->VAR60.VAR61.VAR64++;\nif (VAR20) {\nVAR15 |= VAR65;\nFUN25(&VAR5->VAR55, VAR20);\n}\nFUN26(&VAR5->VAR55.VAR56);\nif (VAR6->VAR43) {\nif (FUN27(VAR1, VAR8.VAR57 + VAR17 -\nsizeof(struct VAR44),\nFUN28(), true)) {\nFUN22(&VAR5->VAR55.VAR56);\ngoto VAR59;\n}\n}\nFUN29(VAR1, 0, VAR8.VAR57 + VAR17, VAR13);\nif (!(VAR22 = FUN30(VAR1, &VAR21, VAR6->VAR66)))\nFUN31(&VAR21);\nVAR15 |= VAR22;\nswitch (VAR6->VAR45) {\ncase VAR67:\nVAR8.VAR68->VAR69 = VAR1->VAR12;\nVAR8.VAR68->VAR70 = VAR13;\nVAR8.VAR68->VAR71 = VAR17;\nVAR8.VAR68->VAR72 = VAR18;\nVAR8.VAR68->VAR73 = VAR21.VAR74;\nVAR8.VAR68->VAR75 = VAR21.VAR76 / VAR77;\nVAR19 = sizeof(*VAR8.VAR68);\nbreak;\ncase VAR46:\nVAR8.VAR24->VAR69 = VAR1->VAR12;\nVAR8.VAR24->VAR70 = VAR13;\nVAR8.VAR24->VAR71 = VAR17;\nVAR8.VAR24->VAR72 = VAR18;\nVAR8.VAR24->VAR73 = VAR21.VAR74;\nVAR8.VAR24->VAR78 = VAR21.VAR76;\nif (FUN32(VAR1)) {\nVAR8.VAR24->VAR79 = FUN33(VAR1);\nVAR8.VAR24->VAR80 = FUN34(VAR1->VAR81);\nVAR15 |= VAR82 | VAR83;\n} else {\nVAR8.VAR24->VAR79 = 0;\nVAR8.VAR24->VAR80 = 0;\n}\nFUN35(VAR8.VAR24->VAR84, 0, sizeof(VAR8.VAR24->VAR84));\nVAR19 = sizeof(*VAR8.VAR24);\nbreak;\ncase VAR85:\nVAR8.VAR25->VAR86 |= VAR15;\nVAR8.VAR25->VAR69 = VAR1->VAR12;\nVAR8.VAR25->VAR70 = VAR13;\nVAR8.VAR25->VAR71 = VAR17;\nVAR8.VAR25->VAR72 = VAR18;\nVAR8.VAR25->VAR73  = VAR21.VAR74;\nVAR8.VAR25->VAR78 = VAR21.VAR76;\nFUN35(VAR8.VAR25->VAR84, 0, sizeof(VAR8.VAR25->VAR84));\nVAR19 = sizeof(*VAR8.VAR25);\nbreak;\ndefault:\nFUN36();\n}\nVAR7 = VAR8.VAR57 + FUN3(VAR19);\nVAR7->VAR87 = FUN37(VAR1, VAR7->VAR88);\nVAR7->VAR89 = VAR90;\nVAR7->VAR91 = VAR2->VAR92;\nVAR7->VAR93 = VAR1->VAR94;\nVAR7->VAR95 = VAR1->VAR26;\nif (FUN19(VAR6->VAR96))\nVAR7->VAR97 = VAR4->VAR98;\nelse\nVAR7->VAR97 = VAR2->VAR98;\nFUN38();\n#if VAR99 == 1\nif (VAR6->VAR45 <= VAR46) {\nu8 *VAR100, *VAR101;\nVAR101 = (VAR102 *) FUN39((unsigned long) VAR8.VAR57 +\nVAR17 + VAR13);\nfor (VAR100 = VAR8.VAR57; VAR100 < VAR101; VAR100 += VAR103)\nFUN40(FUN41(VAR100));\n}\nFUN42();\n#VAR104\nif (VAR6->VAR45 <= VAR46) {\nFUN43(VAR6, VAR8.VAR57, VAR15);\nVAR5->FUN44(VAR5);\n} else {\nFUN45(&VAR6->VAR47);\n}\nVAR34:\nif (VAR9 != VAR1->VAR10 && FUN15(VAR1)) {\nVAR1->VAR10 = VAR9;\nVAR1->VAR12 = VAR11;\n}\nVAR28:\nif (!VAR23)\nFUN46(VAR1);\nelse\nFUN47(VAR1);\nreturn 0;\nVAR59:\nVAR23 = true;\nVAR6->VAR60.VAR61.VAR62++;\nFUN26(&VAR5->VAR55.VAR56);\nVAR5->FUN44(VAR5);\nFUN47(VAR20);\ngoto VAR34;\n}\n",
      "code_after_change_raw": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\nstruct packet_type *pt, struct net_device *orig_dev)\n{\nstruct sock *sk;\nstruct packet_sock *po;\nstruct sockaddr_ll *sll;\nunion tpacket_uhdr h;\nu8 *skb_head = skb->data;\nint skb_len = skb->len;\nunsigned int snaplen, res;\nunsigned long status = TP_STATUS_USER;\nunsigned short macoff, netoff, hdrlen;\nstruct sk_buff *copy_skb = NULL;\nstruct timespec ts;\n__u32 ts_status;\nbool is_drop_n_account = false;\nbool do_vnet = false;\nBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\nBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\nif (skb->pkt_type == PACKET_LOOPBACK)\ngoto drop;\nsk = pt->af_packet_priv;\npo = pkt_sk(sk);\nif (!net_eq(dev_net(dev), sock_net(sk)))\ngoto drop;\nif (dev->header_ops) {\nif (sk->sk_type != SOCK_DGRAM)\nskb_push(skb, skb->data - skb_mac_header(skb));\nelse if (skb->pkt_type == PACKET_OUTGOING) {\nskb_pull(skb, skb_network_offset(skb));\n}\n}\nsnaplen = skb->len;\nres = run_filter(skb, sk, snaplen);\nif (!res)\ngoto drop_n_restore;\nif (skb->ip_summed == CHECKSUM_PARTIAL)\nstatus |= TP_STATUS_CSUMNOTREADY;\nelse if (skb->pkt_type != PACKET_OUTGOING &&\n(skb->ip_summed == CHECKSUM_COMPLETE ||\nskb_csum_unnecessary(skb)))\nstatus |= TP_STATUS_CSUM_VALID;\nif (snaplen > res)\nsnaplen = res;\nif (sk->sk_type == SOCK_DGRAM) {\nmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\npo->tp_reserve;\n} else {\nunsigned int maclen = skb_network_offset(skb);\nnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n(maclen < 16 ? 16 : maclen)) +\npo->tp_reserve;\nif (po->has_vnet_hdr) {\nnetoff += sizeof(struct virtio_net_hdr);\ndo_vnet = true;\n}\nmacoff = netoff - maclen;\n}\nif (po->tp_version <= TPACKET_V2) {\nif (macoff + snaplen > po->rx_ring.frame_size) {\nif (po->copy_thresh &&\natomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\nif (skb_shared(skb)) {\ncopy_skb = skb_clone(skb, GFP_ATOMIC);\n} else {\ncopy_skb = skb_get(skb);\nskb_head = skb->data;\n}\nif (copy_skb)\nskb_set_owner_r(copy_skb, sk);\n}\nsnaplen = po->rx_ring.frame_size - macoff;\nif ((int)snaplen < 0) {\nsnaplen = 0;\ndo_vnet = false;\n}\n}\n} else if (unlikely(macoff + snaplen >\nGET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\nu32 nval;\nnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\npr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\nsnaplen, nval, macoff);\nsnaplen = nval;\nif (unlikely((int)snaplen < 0)) {\nsnaplen = 0;\nmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\ndo_vnet = false;\n}\n}\nspin_lock(&sk->sk_receive_queue.lock);\nh.raw = packet_current_rx_frame(po, skb,\nTP_STATUS_KERNEL, (macoff+snaplen));\nif (!h.raw)\ngoto drop_n_account;\nif (po->tp_version <= TPACKET_V2) {\npacket_increment_rx_head(po, &po->rx_ring);\nif (po->stats.stats1.tp_drops)\nstatus |= TP_STATUS_LOSING;\n}\npo->stats.stats1.tp_packets++;\nif (copy_skb) {\nstatus |= TP_STATUS_COPY;\n__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n}\nspin_unlock(&sk->sk_receive_queue.lock);\nif (do_vnet) {\nif (virtio_net_hdr_from_skb(skb, h.raw + macoff -\nsizeof(struct virtio_net_hdr),\nvio_le(), true)) {\nspin_lock(&sk->sk_receive_queue.lock);\ngoto drop_n_account;\n}\n}\nskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\nif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\ngetnstimeofday(&ts);\nstatus |= ts_status;\nswitch (po->tp_version) {\ncase TPACKET_V1:\nh.h1->tp_len = skb->len;\nh.h1->tp_snaplen = snaplen;\nh.h1->tp_mac = macoff;\nh.h1->tp_net = netoff;\nh.h1->tp_sec = ts.tv_sec;\nh.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\nhdrlen = sizeof(*h.h1);\nbreak;\ncase TPACKET_V2:\nh.h2->tp_len = skb->len;\nh.h2->tp_snaplen = snaplen;\nh.h2->tp_mac = macoff;\nh.h2->tp_net = netoff;\nh.h2->tp_sec = ts.tv_sec;\nh.h2->tp_nsec = ts.tv_nsec;\nif (skb_vlan_tag_present(skb)) {\nh.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\nh.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\nstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n} else {\nh.h2->tp_vlan_tci = 0;\nh.h2->tp_vlan_tpid = 0;\n}\nmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\nhdrlen = sizeof(*h.h2);\nbreak;\ncase TPACKET_V3:\nh.h3->tp_status |= status;\nh.h3->tp_len = skb->len;\nh.h3->tp_snaplen = snaplen;\nh.h3->tp_mac = macoff;\nh.h3->tp_net = netoff;\nh.h3->tp_sec  = ts.tv_sec;\nh.h3->tp_nsec = ts.tv_nsec;\nmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\nhdrlen = sizeof(*h.h3);\nbreak;\ndefault:\nBUG();\n}\nsll = h.raw + TPACKET_ALIGN(hdrlen);\nsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\nsll->sll_family = AF_PACKET;\nsll->sll_hatype = dev->type;\nsll->sll_protocol = skb->protocol;\nsll->sll_pkttype = skb->pkt_type;\nif (unlikely(po->origdev))\nsll->sll_ifindex = orig_dev->ifindex;\nelse\nsll->sll_ifindex = dev->ifindex;\nsmp_mb();\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\nif (po->tp_version <= TPACKET_V2) {\nu8 *start, *end;\nend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\nmacoff + snaplen);\nfor (start = h.raw; start < end; start += PAGE_SIZE)\nflush_dcache_page(pgv_to_page(start));\n}\nsmp_wmb();\n#endif\nif (po->tp_version <= TPACKET_V2) {\n__packet_set_status(po, h.raw, status);\nsk->sk_data_ready(sk);\n} else {\nprb_clear_blk_fill_status(&po->rx_ring);\n}\ndrop_n_restore:\nif (skb_head != skb->data && skb_shared(skb)) {\nskb->data = skb_head;\nskb->len = skb_len;\n}\ndrop:\nif (!is_drop_n_account)\nconsume_skb(skb);\nelse\nkfree_skb(skb);\nreturn 0;\ndrop_n_account:\nis_drop_n_account = true;\npo->stats.stats1.tp_drops++;\nspin_unlock(&sk->sk_receive_queue.lock);\nsk->sk_data_ready(sk);\nkfree_skb(copy_skb);\ngoto drop_n_restore;\n}\n",
      "code_before_change_raw": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\nstruct packet_type *pt, struct net_device *orig_dev)\n{\nstruct sock *sk;\nstruct packet_sock *po;\nstruct sockaddr_ll *sll;\nunion tpacket_uhdr h;\nu8 *skb_head = skb->data;\nint skb_len = skb->len;\nunsigned int snaplen, res;\nunsigned long status = TP_STATUS_USER;\nunsigned short macoff, netoff, hdrlen;\nstruct sk_buff *copy_skb = NULL;\nstruct timespec ts;\n__u32 ts_status;\nbool is_drop_n_account = false;\nBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\nBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\nif (skb->pkt_type == PACKET_LOOPBACK)\ngoto drop;\nsk = pt->af_packet_priv;\npo = pkt_sk(sk);\nif (!net_eq(dev_net(dev), sock_net(sk)))\ngoto drop;\nif (dev->header_ops) {\nif (sk->sk_type != SOCK_DGRAM)\nskb_push(skb, skb->data - skb_mac_header(skb));\nelse if (skb->pkt_type == PACKET_OUTGOING) {\nskb_pull(skb, skb_network_offset(skb));\n}\n}\nsnaplen = skb->len;\nres = run_filter(skb, sk, snaplen);\nif (!res)\ngoto drop_n_restore;\nif (skb->ip_summed == CHECKSUM_PARTIAL)\nstatus |= TP_STATUS_CSUMNOTREADY;\nelse if (skb->pkt_type != PACKET_OUTGOING &&\n(skb->ip_summed == CHECKSUM_COMPLETE ||\nskb_csum_unnecessary(skb)))\nstatus |= TP_STATUS_CSUM_VALID;\nif (snaplen > res)\nsnaplen = res;\nif (sk->sk_type == SOCK_DGRAM) {\nmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\npo->tp_reserve;\n} else {\nunsigned int maclen = skb_network_offset(skb);\nnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n(maclen < 16 ? 16 : maclen)) +\npo->tp_reserve;\nif (po->has_vnet_hdr)\nnetoff += sizeof(struct virtio_net_hdr);\nmacoff = netoff - maclen;\n}\nif (po->tp_version <= TPACKET_V2) {\nif (macoff + snaplen > po->rx_ring.frame_size) {\nif (po->copy_thresh &&\natomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\nif (skb_shared(skb)) {\ncopy_skb = skb_clone(skb, GFP_ATOMIC);\n} else {\ncopy_skb = skb_get(skb);\nskb_head = skb->data;\n}\nif (copy_skb)\nskb_set_owner_r(copy_skb, sk);\n}\nsnaplen = po->rx_ring.frame_size - macoff;\nif ((int)snaplen < 0)\nsnaplen = 0;\n}\n} else if (unlikely(macoff + snaplen >\nGET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\nu32 nval;\nnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\npr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\nsnaplen, nval, macoff);\nsnaplen = nval;\nif (unlikely((int)snaplen < 0)) {\nsnaplen = 0;\nmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n}\n}\nspin_lock(&sk->sk_receive_queue.lock);\nh.raw = packet_current_rx_frame(po, skb,\nTP_STATUS_KERNEL, (macoff+snaplen));\nif (!h.raw)\ngoto drop_n_account;\nif (po->tp_version <= TPACKET_V2) {\npacket_increment_rx_head(po, &po->rx_ring);\nif (po->stats.stats1.tp_drops)\nstatus |= TP_STATUS_LOSING;\n}\npo->stats.stats1.tp_packets++;\nif (copy_skb) {\nstatus |= TP_STATUS_COPY;\n__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n}\nspin_unlock(&sk->sk_receive_queue.lock);\nif (po->has_vnet_hdr) {\nif (virtio_net_hdr_from_skb(skb, h.raw + macoff -\nsizeof(struct virtio_net_hdr),\nvio_le(), true)) {\nspin_lock(&sk->sk_receive_queue.lock);\ngoto drop_n_account;\n}\n}\nskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\nif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\ngetnstimeofday(&ts);\nstatus |= ts_status;\nswitch (po->tp_version) {\ncase TPACKET_V1:\nh.h1->tp_len = skb->len;\nh.h1->tp_snaplen = snaplen;\nh.h1->tp_mac = macoff;\nh.h1->tp_net = netoff;\nh.h1->tp_sec = ts.tv_sec;\nh.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\nhdrlen = sizeof(*h.h1);\nbreak;\ncase TPACKET_V2:\nh.h2->tp_len = skb->len;\nh.h2->tp_snaplen = snaplen;\nh.h2->tp_mac = macoff;\nh.h2->tp_net = netoff;\nh.h2->tp_sec = ts.tv_sec;\nh.h2->tp_nsec = ts.tv_nsec;\nif (skb_vlan_tag_present(skb)) {\nh.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\nh.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\nstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n} else {\nh.h2->tp_vlan_tci = 0;\nh.h2->tp_vlan_tpid = 0;\n}\nmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\nhdrlen = sizeof(*h.h2);\nbreak;\ncase TPACKET_V3:\nh.h3->tp_status |= status;\nh.h3->tp_len = skb->len;\nh.h3->tp_snaplen = snaplen;\nh.h3->tp_mac = macoff;\nh.h3->tp_net = netoff;\nh.h3->tp_sec  = ts.tv_sec;\nh.h3->tp_nsec = ts.tv_nsec;\nmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\nhdrlen = sizeof(*h.h3);\nbreak;\ndefault:\nBUG();\n}\nsll = h.raw + TPACKET_ALIGN(hdrlen);\nsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\nsll->sll_family = AF_PACKET;\nsll->sll_hatype = dev->type;\nsll->sll_protocol = skb->protocol;\nsll->sll_pkttype = skb->pkt_type;\nif (unlikely(po->origdev))\nsll->sll_ifindex = orig_dev->ifindex;\nelse\nsll->sll_ifindex = dev->ifindex;\nsmp_mb();\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\nif (po->tp_version <= TPACKET_V2) {\nu8 *start, *end;\nend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\nmacoff + snaplen);\nfor (start = h.raw; start < end; start += PAGE_SIZE)\nflush_dcache_page(pgv_to_page(start));\n}\nsmp_wmb();\n#endif\nif (po->tp_version <= TPACKET_V2) {\n__packet_set_status(po, h.raw, status);\nsk->sk_data_ready(sk);\n} else {\nprb_clear_blk_fill_status(&po->rx_ring);\n}\ndrop_n_restore:\nif (skb_head != skb->data && skb_shared(skb)) {\nskb->data = skb_head;\nskb->len = skb_len;\n}\ndrop:\nif (!is_drop_n_account)\nconsume_skb(skb);\nelse\nkfree_skb(skb);\nreturn 0;\ndrop_n_account:\nis_drop_n_account = true;\npo->stats.stats1.tp_drops++;\nspin_unlock(&sk->sk_receive_queue.lock);\nsk->sk_data_ready(sk);\nkfree_skb(copy_skb);\ngoto drop_n_restore;\n}\n"
    }
  ],
  "CVE-2017-15126": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for wait queue entry removal in the event of a fork failure during userfaultfd event processing.",
        "trigger_condition": "A fork failure occurs while processing userfaultfd events, leading to the removal of a wait queue entry that has already been freed, resulting in a use-after-free vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code removes the wait queue entry after accessing it in the case of a fork event, potentially leading to a use-after-free scenario if the entry has already been freed. This behavior can result in accessing memory that has been released, causing memory corruption and security risks."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the wait queue entry is removed before accessing it in the case of a fork event. By moving the wait queue entry removal before accessing it, the code prevents the use-after-free scenario and maintains the integrity of the event handling process. This solution helps in handling the wait queue entry properly and avoids potential memory corruption issues.",
      "GPT_analysis": "The modification is necessary to address the use-after-free vulnerability in the code snippet. Specifically, the modification ensures that the wait queue entry (&ewq->wq) is properly removed from the event wait queue before accessing it in the case of a fork event. \n\nIn the vulnerable code, the wait queue entry removal (__remove_wait_queue) is done after accessing the event message for a fork event. This could lead to a situation where the wait queue entry is accessed after it has been removed, potentially resulting in a use-after-free scenario.\n\nBy moving the wait queue entry removal before accessing it in the case of a fork event, the modified code ensures that the entry is properly handled and prevents the use-after-free vulnerability from occurring. This modification helps maintain the integrity of the event handling process and prevents potential memory corruption issues.",
      "GPT_purpose": "Wait for userfaultfd event completion and handle fork events.",
      "GPT_function": "\n1. Wait for userfaultfd event completion.\n2. Handle event messages related to fork failure.\n3. Remove a fork event from the list of events.",
      "CVE_id": "CVE-2017-15126",
      "code_before_change": "static void userfaultfd_event_wait_completion(struct userfaultfd_ctx *ctx,\n\t\t\t\t\t      struct userfaultfd_wait_queue *ewq)\n{\n\tif (WARN_ON_ONCE(current->flags & PF_EXITING))\n\t\tgoto out;\n\n\tewq->ctx = ctx;\n\tinit_waitqueue_entry(&ewq->wq, current);\n\n\tspin_lock(&ctx->event_wqh.lock);\n\t/*\n\t * After the __add_wait_queue the uwq is visible to userland\n\t * through poll/read().\n\t */\n\t__add_wait_queue(&ctx->event_wqh, &ewq->wq);\n\tfor (;;) {\n\t\tset_current_state(TASK_KILLABLE);\n\t\tif (ewq->msg.event == 0)\n\t\t\tbreak;\n\t\tif (ACCESS_ONCE(ctx->released) ||\n\t\t    fatal_signal_pending(current)) {\n\t\t\t__remove_wait_queue(&ctx->event_wqh, &ewq->wq);\n\t\t\tif (ewq->msg.event == UFFD_EVENT_FORK) {\n\t\t\t\tstruct userfaultfd_ctx *new;\n\n\t\t\t\tnew = (struct userfaultfd_ctx *)\n\t\t\t\t\t(unsigned long)\n\t\t\t\t\tewq->msg.arg.reserved.reserved1;\n\n\t\t\t\tuserfaultfd_ctx_put(new);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock(&ctx->event_wqh.lock);\n\n\t\twake_up_poll(&ctx->fd_wqh, POLLIN);\n\t\tschedule();\n\n\t\tspin_lock(&ctx->event_wqh.lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\tspin_unlock(&ctx->event_wqh.lock);\n\n\t/*\n\t * ctx may go away after this if the userfault pseudo fd is\n\t * already released.\n\t */\nout:\n\tuserfaultfd_ctx_put(ctx);\n}",
      "code_after_change": "static void userfaultfd_event_wait_completion(struct userfaultfd_ctx *ctx,\n\t\t\t\t\t      struct userfaultfd_wait_queue *ewq)\n{\n\tif (WARN_ON_ONCE(current->flags & PF_EXITING))\n\t\tgoto out;\n\n\tewq->ctx = ctx;\n\tinit_waitqueue_entry(&ewq->wq, current);\n\n\tspin_lock(&ctx->event_wqh.lock);\n\t/*\n\t * After the __add_wait_queue the uwq is visible to userland\n\t * through poll/read().\n\t */\n\t__add_wait_queue(&ctx->event_wqh, &ewq->wq);\n\tfor (;;) {\n\t\tset_current_state(TASK_KILLABLE);\n\t\tif (ewq->msg.event == 0)\n\t\t\tbreak;\n\t\tif (ACCESS_ONCE(ctx->released) ||\n\t\t    fatal_signal_pending(current)) {\n\t\t\t/*\n\t\t\t * &ewq->wq may be queued in fork_event, but\n\t\t\t * __remove_wait_queue ignores the head\n\t\t\t * parameter. It would be a problem if it\n\t\t\t * didn't.\n\t\t\t */\n\t\t\t__remove_wait_queue(&ctx->event_wqh, &ewq->wq);\n\t\t\tif (ewq->msg.event == UFFD_EVENT_FORK) {\n\t\t\t\tstruct userfaultfd_ctx *new;\n\n\t\t\t\tnew = (struct userfaultfd_ctx *)\n\t\t\t\t\t(unsigned long)\n\t\t\t\t\tewq->msg.arg.reserved.reserved1;\n\n\t\t\t\tuserfaultfd_ctx_put(new);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock(&ctx->event_wqh.lock);\n\n\t\twake_up_poll(&ctx->fd_wqh, POLLIN);\n\t\tschedule();\n\n\t\tspin_lock(&ctx->event_wqh.lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\tspin_unlock(&ctx->event_wqh.lock);\n\n\t/*\n\t * ctx may go away after this if the userfault pseudo fd is\n\t * already released.\n\t */\nout:\n\tuserfaultfd_ctx_put(ctx);\n}",
      "modified_lines": {
        "added": [
          "\t\t\t/*",
          "\t\t\t * &ewq->wq may be queued in fork_event, but",
          "\t\t\t * __remove_wait_queue ignores the head",
          "\t\t\t * parameter. It would be a problem if it",
          "\t\t\t * didn't.",
          "\t\t\t */"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper handling for wait queue entry removal in the event of a fork failure during userfaultfd event processing.",
      "trigger_condition": "A fork failure occurs while processing userfaultfd events, leading to the removal of a wait queue entry that has already been freed, resulting in a use-after-free vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code removes the wait queue entry after accessing it in the case of a fork event, potentially leading to a use-after-free scenario if the entry has already been freed. This behavior can result in accessing memory that has been released, causing memory corruption and security risks.",
      "id": 104,
      "code_after_change_normalized": "static void FUN1(struct userfaultfd_ctx *VAR1,\nstruct userfaultfd_wait_queue *VAR2)\n{\nif (FUN2(VAR3->VAR4 & VAR5))\ngoto VAR6;\nVAR2->VAR1 = VAR1;\nFUN3(&VAR2->VAR7, VAR3);\nFUN4(&VAR1->VAR8.VAR9);\nFUN5(&VAR1->VAR8, &VAR2->VAR7);\nfor (;;) {\nFUN6(VAR10);\nif (VAR2->VAR11.VAR12 == 0)\nbreak;\nif (FUN7(VAR1->VAR13) ||\nFUN8(VAR3)) {\nFUN9(&VAR1->VAR8, &VAR2->VAR7);\nif (VAR2->VAR11.VAR12 == VAR14) {\nstruct userfaultfd_ctx *new;\nnew = (struct VAR15 *)\n(unsigned long)\nVAR2->VAR11.VAR16.VAR17.VAR18;\nFUN10(new);\n}\nbreak;\n}\nFUN11(&VAR1->VAR8.VAR9);\nFUN12(&VAR1->VAR19, VAR20);\nFUN13();\nFUN4(&VAR1->VAR8.VAR9);\n}\nFUN14(VAR21);\nFUN11(&VAR1->VAR8.VAR9);\nVAR6:\nFUN10(VAR1);\n}\n",
      "code_before_change_normalized": "static void FUN1(struct userfaultfd_ctx *VAR1,\nstruct userfaultfd_wait_queue *VAR2)\n{\nif (FUN2(VAR3->VAR4 & VAR5))\ngoto VAR6;\nVAR2->VAR1 = VAR1;\nFUN3(&VAR2->VAR7, VAR3);\nFUN4(&VAR1->VAR8.VAR9);\nFUN5(&VAR1->VAR8, &VAR2->VAR7);\nfor (;;) {\nFUN6(VAR10);\nif (VAR2->VAR11.VAR12 == 0)\nbreak;\nif (FUN7(VAR1->VAR13) ||\nFUN8(VAR3)) {\nFUN9(&VAR1->VAR8, &VAR2->VAR7);\nif (VAR2->VAR11.VAR12 == VAR14) {\nstruct userfaultfd_ctx *new;\nnew = (struct VAR15 *)\n(unsigned long)\nVAR2->VAR11.VAR16.VAR17.VAR18;\nFUN10(new);\n}\nbreak;\n}\nFUN11(&VAR1->VAR8.VAR9);\nFUN12(&VAR1->VAR19, VAR20);\nFUN13();\nFUN4(&VAR1->VAR8.VAR9);\n}\nFUN14(VAR21);\nFUN11(&VAR1->VAR8.VAR9);\nVAR6:\nFUN10(VAR1);\n}\n",
      "code_after_change_raw": "static void userfaultfd_event_wait_completion(struct userfaultfd_ctx *ctx,\nstruct userfaultfd_wait_queue *ewq)\n{\nif (WARN_ON_ONCE(current->flags & PF_EXITING))\ngoto out;\newq->ctx = ctx;\ninit_waitqueue_entry(&ewq->wq, current);\nspin_lock(&ctx->event_wqh.lock);\n__add_wait_queue(&ctx->event_wqh, &ewq->wq);\nfor (;;) {\nset_current_state(TASK_KILLABLE);\nif (ewq->msg.event == 0)\nbreak;\nif (ACCESS_ONCE(ctx->released) ||\nfatal_signal_pending(current)) {\n__remove_wait_queue(&ctx->event_wqh, &ewq->wq);\nif (ewq->msg.event == UFFD_EVENT_FORK) {\nstruct userfaultfd_ctx *new;\nnew = (struct userfaultfd_ctx *)\n(unsigned long)\newq->msg.arg.reserved.reserved1;\nuserfaultfd_ctx_put(new);\n}\nbreak;\n}\nspin_unlock(&ctx->event_wqh.lock);\nwake_up_poll(&ctx->fd_wqh, POLLIN);\nschedule();\nspin_lock(&ctx->event_wqh.lock);\n}\n__set_current_state(TASK_RUNNING);\nspin_unlock(&ctx->event_wqh.lock);\nout:\nuserfaultfd_ctx_put(ctx);\n}\n",
      "code_before_change_raw": "static void userfaultfd_event_wait_completion(struct userfaultfd_ctx *ctx,\nstruct userfaultfd_wait_queue *ewq)\n{\nif (WARN_ON_ONCE(current->flags & PF_EXITING))\ngoto out;\newq->ctx = ctx;\ninit_waitqueue_entry(&ewq->wq, current);\nspin_lock(&ctx->event_wqh.lock);\n__add_wait_queue(&ctx->event_wqh, &ewq->wq);\nfor (;;) {\nset_current_state(TASK_KILLABLE);\nif (ewq->msg.event == 0)\nbreak;\nif (ACCESS_ONCE(ctx->released) ||\nfatal_signal_pending(current)) {\n__remove_wait_queue(&ctx->event_wqh, &ewq->wq);\nif (ewq->msg.event == UFFD_EVENT_FORK) {\nstruct userfaultfd_ctx *new;\nnew = (struct userfaultfd_ctx *)\n(unsigned long)\newq->msg.arg.reserved.reserved1;\nuserfaultfd_ctx_put(new);\n}\nbreak;\n}\nspin_unlock(&ctx->event_wqh.lock);\nwake_up_poll(&ctx->fd_wqh, POLLIN);\nschedule();\nspin_lock(&ctx->event_wqh.lock);\n}\n__set_current_state(TASK_RUNNING);\nspin_unlock(&ctx->event_wqh.lock);\nout:\nuserfaultfd_ctx_put(ctx);\n}\n"
    }
  ],
  "CVE-2017-16526": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper error handling for the return value of a function that creates a kernel thread.",
        "trigger_condition": "The function creating the kernel thread fails and returns NULL, leading to a situation where subsequent code tries to access a member of a NULL pointer.",
        "specific_code_behavior_causing_vulnerability": "The original code does not check the return value of the function creating the kernel thread, leading to a potential NULL pointer dereference if the function fails.",
        "impact": "The vulnerability can result in a denial of service (general protection fault and system crash) or other unspecified impacts.",
        "exploitation": "A local user can exploit this vulnerability by crafting a specific USB device to trigger the faulty code path.",
        "affected_versions": "Linux kernel versions before 4.13.6"
      },
      "solution": {
        "description": "To mitigate the vulnerability, it is necessary to properly handle the return value of the function that creates the kernel thread.",
        "specific_steps": "Check the return value of the function using IS_ERR macro and handle the failure case by setting the related pointer to NULL and logging an error message.",
        "code_modification": "Replace the direct assignment of the kernel thread creation function's return value to the pointer with a conditional assignment based on the return value check."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2017-16526. The vulnerability arises from the fact that the original code does not properly handle the return value of the kthread_run function. In the original code, if kthread_run fails and returns NULL, the code still tries to access rc->uwbd.task->pid, which can lead to a general protection fault and system crash.\n\nBy making the modification as shown in the corrected code snippet, the return value of kthread_run is properly checked using the IS_ERR macro. If kthread_run fails, the code sets rc->uwbd.task to NULL and logs an error message. This prevents accessing rc->uwbd.task->pid when it is not valid, thus avoiding the vulnerability and potential system crash.\n\nTherefore, the modification ensures proper error handling and prevents the vulnerability from being exploited.",
      "GPT_purpose": "Start a management daemon for UWB (Ultra-Wideband) communication on a UWB radio controller.",
      "GPT_function": "\n1. Start the uwbd task for a given uwb_rc.\n2. Check if the task was successfully started.\n3. Assign the process ID of the task to the uwb_rc structure.",
      "CVE_id": "CVE-2017-16526",
      "code_before_change": "void uwbd_start(struct uwb_rc *rc)\n{\n\trc->uwbd.task = kthread_run(uwbd, rc, \"uwbd\");\n\tif (rc->uwbd.task == NULL)\n\t\tprintk(KERN_ERR \"UWB: Cannot start management daemon; \"\n\t\t       \"UWB won't work\\n\");\n\telse\n\t\trc->uwbd.pid = rc->uwbd.task->pid;\n}",
      "code_after_change": "void uwbd_start(struct uwb_rc *rc)\n{\n\tstruct task_struct *task = kthread_run(uwbd, rc, \"uwbd\");\n\tif (IS_ERR(task)) {\n\t\trc->uwbd.task = NULL;\n\t\tprintk(KERN_ERR \"UWB: Cannot start management daemon; \"\n\t\t       \"UWB won't work\\n\");\n\t} else {\n\t\trc->uwbd.task = task;\n\t\trc->uwbd.pid = rc->uwbd.task->pid;\n\t}\n}",
      "modified_lines": {
        "added": [
          "\tstruct task_struct *task = kthread_run(uwbd, rc, \"uwbd\");",
          "\tif (IS_ERR(task)) {",
          "\t\trc->uwbd.task = NULL;",
          "\t} else {",
          "\t\trc->uwbd.task = task;",
          "\t}"
        ],
        "deleted": [
          "\trc->uwbd.task = kthread_run(uwbd, rc, \"uwbd\");",
          "\tif (rc->uwbd.task == NULL)",
          "\telse"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper error handling for the return value of a function that creates a kernel thread.",
      "trigger_condition": "The function creating the kernel thread fails and returns NULL, leading to a situation where subsequent code tries to access a member of a NULL pointer.",
      "specific_code_behavior_causing_vulnerability": "The original code does not check the return value of the function creating the kernel thread, leading to a potential NULL pointer dereference if the function fails.",
      "id": 105,
      "code_after_change_normalized": "void FUN1(struct uwb_rc *VAR1)\n{\nstruct task_struct *VAR2 = FUN2(VAR3, VAR1, \"STR\");\nif (FUN3(VAR2)) {\nVAR1->VAR3.VAR2 = NULL;\nFUN4(VAR4 \"STR\"\n\"STR\");\n} else {\nVAR1->VAR3.VAR2 = VAR2;\nVAR1->VAR3.VAR5 = VAR1->VAR3.VAR2->VAR5;\n}\n}\n",
      "code_before_change_normalized": "void FUN1(struct uwb_rc *VAR1)\n{\nVAR1->VAR2.VAR3 = FUN2(VAR2, VAR1, \"STR\");\nif (VAR1->VAR2.VAR3 == NULL)\nFUN3(VAR4 \"STR\"\n\"STR\");\nelse\nVAR1->VAR2.VAR5 = VAR1->VAR2.VAR3->VAR5;\n}\n",
      "code_after_change_raw": "void uwbd_start(struct uwb_rc *rc)\n{\nstruct task_struct *task = kthread_run(uwbd, rc, \"uwbd\");\nif (IS_ERR(task)) {\nrc->uwbd.task = NULL;\nprintk(KERN_ERR \"UWB: Cannot start management daemon; \"\n\"UWB won't work\\n\");\n} else {\nrc->uwbd.task = task;\nrc->uwbd.pid = rc->uwbd.task->pid;\n}\n}\n",
      "code_before_change_raw": "void uwbd_start(struct uwb_rc *rc)\n{\nrc->uwbd.task = kthread_run(uwbd, rc, \"uwbd\");\nif (rc->uwbd.task == NULL)\nprintk(KERN_ERR \"UWB: Cannot start management daemon; \"\n\"UWB won't work\\n\");\nelse\nrc->uwbd.pid = rc->uwbd.task->pid;\n}\n"
    }
  ],
  "CVE-2017-16534": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation of the descriptor buffer length before processing each descriptor.",
        "trigger_condition": "A crafted USB device with a malicious descriptor buffer is connected, leading to out-of-bounds read and system crash.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the descriptor buffer length is valid before processing each descriptor, allowing for potential out-of-bounds reads and system crashes.",
        "specific_solution_to_fix_vulnerability": "To mitigate the vulnerability, it is necessary to add a check for the descriptor buffer length to ensure it is valid before processing each descriptor. This prevents out-of-bounds reads and system crashes caused by malformed USB devices. In this case, the solution involves adding a check for (buflen < elength) || (elength < 3) before processing each descriptor."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-16534, which allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have other unspecified impacts via a crafted USB device.\n\nThe vulnerability arises from the lack of proper validation of the descriptor buffer length in the original code. By adding the check `(buflen < elength) || (elength < 3)` before processing each descriptor, we ensure that the buffer length is valid and prevent potential out-of-bounds reads that could lead to a system crash or other security issues.\n\nThis modification helps to enhance the security and stability of the code by preventing malicious or malformed USB devices from causing unexpected behavior or crashes in the system.",
      "GPT_purpose": "Parse and extract various CDC (Communication Device Class) descriptors from a USB device buffer.",
      "GPT_function": "\n1. Parse USB CDC descriptors from a buffer.\n2. Handle different types of USB CDC descriptors.\n3. Check for specific descriptor types and their lengths.\n4. Store parsed descriptor information in a struct.\n5. Prevent duplicates of certain descriptors.\n6. Handle errors and skip over unrecognized descriptors.\n7. Update the parsed header struct with the descriptor information.\n8. Return the count of descriptors parsed.",
      "CVE_id": "CVE-2017-16534",
      "code_before_change": "int cdc_parse_cdc_header(struct usb_cdc_parsed_header *hdr,\n\t\t\t\tstruct usb_interface *intf,\n\t\t\t\tu8 *buffer,\n\t\t\t\tint buflen)\n{\n\t/* duplicates are ignored */\n\tstruct usb_cdc_union_desc *union_header = NULL;\n\n\t/* duplicates are not tolerated */\n\tstruct usb_cdc_header_desc *header = NULL;\n\tstruct usb_cdc_ether_desc *ether = NULL;\n\tstruct usb_cdc_mdlm_detail_desc *detail = NULL;\n\tstruct usb_cdc_mdlm_desc *desc = NULL;\n\n\tunsigned int elength;\n\tint cnt = 0;\n\n\tmemset(hdr, 0x00, sizeof(struct usb_cdc_parsed_header));\n\thdr->phonet_magic_present = false;\n\twhile (buflen > 0) {\n\t\telength = buffer[0];\n\t\tif (!elength) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage byte\\n\");\n\t\t\telength = 1;\n\t\t\tgoto next_desc;\n\t\t}\n\t\tif (buffer[1] != USB_DT_CS_INTERFACE) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage\\n\");\n\t\t\tgoto next_desc;\n\t\t}\n\n\t\tswitch (buffer[2]) {\n\t\tcase USB_CDC_UNION_TYPE: /* we've found it */\n\t\t\tif (elength < sizeof(struct usb_cdc_union_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (union_header) {\n\t\t\t\tdev_err(&intf->dev, \"More than one union descriptor, skipping ...\\n\");\n\t\t\t\tgoto next_desc;\n\t\t\t}\n\t\t\tunion_header = (struct usb_cdc_union_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_COUNTRY_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_country_functional_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_country_functional_desc =\n\t\t\t\t(struct usb_cdc_country_functional_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_HEADER_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_header_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (header)\n\t\t\t\treturn -EINVAL;\n\t\t\theader = (struct usb_cdc_header_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ACM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_acm_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_acm_descriptor =\n\t\t\t\t(struct usb_cdc_acm_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ETHERNET_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_ether_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (ether)\n\t\t\t\treturn -EINVAL;\n\t\t\tether = (struct usb_cdc_ether_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_CALL_MANAGEMENT_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_call_mgmt_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_call_mgmt_descriptor =\n\t\t\t\t(struct usb_cdc_call_mgmt_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_DMM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_dmm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_dmm_desc =\n\t\t\t\t(struct usb_cdc_dmm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (desc)\n\t\t\t\treturn -EINVAL;\n\t\t\tdesc = (struct usb_cdc_mdlm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_DETAIL_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_detail_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (detail)\n\t\t\t\treturn -EINVAL;\n\t\t\tdetail = (struct usb_cdc_mdlm_detail_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_NCM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_ncm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_ncm_desc = (struct usb_cdc_ncm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_desc))\n\t\t\t\tgoto next_desc;\n\n\t\t\thdr->usb_cdc_mbim_desc = (struct usb_cdc_mbim_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_EXTENDED_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_extended_desc))\n\t\t\t\tbreak;\n\t\t\thdr->usb_cdc_mbim_extended_desc =\n\t\t\t\t(struct usb_cdc_mbim_extended_desc *)buffer;\n\t\t\tbreak;\n\t\tcase CDC_PHONET_MAGIC_NUMBER:\n\t\t\thdr->phonet_magic_present = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/*\n\t\t\t * there are LOTS more CDC descriptors that\n\t\t\t * could legitimately be found here.\n\t\t\t */\n\t\t\tdev_dbg(&intf->dev, \"Ignoring descriptor: type %02x, length %ud\\n\",\n\t\t\t\t\tbuffer[2], elength);\n\t\t\tgoto next_desc;\n\t\t}\n\t\tcnt++;\nnext_desc:\n\t\tbuflen -= elength;\n\t\tbuffer += elength;\n\t}\n\thdr->usb_cdc_union_desc = union_header;\n\thdr->usb_cdc_header_desc = header;\n\thdr->usb_cdc_mdlm_detail_desc = detail;\n\thdr->usb_cdc_mdlm_desc = desc;\n\thdr->usb_cdc_ether_desc = ether;\n\treturn cnt;\n}",
      "code_after_change": "int cdc_parse_cdc_header(struct usb_cdc_parsed_header *hdr,\n\t\t\t\tstruct usb_interface *intf,\n\t\t\t\tu8 *buffer,\n\t\t\t\tint buflen)\n{\n\t/* duplicates are ignored */\n\tstruct usb_cdc_union_desc *union_header = NULL;\n\n\t/* duplicates are not tolerated */\n\tstruct usb_cdc_header_desc *header = NULL;\n\tstruct usb_cdc_ether_desc *ether = NULL;\n\tstruct usb_cdc_mdlm_detail_desc *detail = NULL;\n\tstruct usb_cdc_mdlm_desc *desc = NULL;\n\n\tunsigned int elength;\n\tint cnt = 0;\n\n\tmemset(hdr, 0x00, sizeof(struct usb_cdc_parsed_header));\n\thdr->phonet_magic_present = false;\n\twhile (buflen > 0) {\n\t\telength = buffer[0];\n\t\tif (!elength) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage byte\\n\");\n\t\t\telength = 1;\n\t\t\tgoto next_desc;\n\t\t}\n\t\tif ((buflen < elength) || (elength < 3)) {\n\t\t\tdev_err(&intf->dev, \"invalid descriptor buffer length\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tif (buffer[1] != USB_DT_CS_INTERFACE) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage\\n\");\n\t\t\tgoto next_desc;\n\t\t}\n\n\t\tswitch (buffer[2]) {\n\t\tcase USB_CDC_UNION_TYPE: /* we've found it */\n\t\t\tif (elength < sizeof(struct usb_cdc_union_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (union_header) {\n\t\t\t\tdev_err(&intf->dev, \"More than one union descriptor, skipping ...\\n\");\n\t\t\t\tgoto next_desc;\n\t\t\t}\n\t\t\tunion_header = (struct usb_cdc_union_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_COUNTRY_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_country_functional_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_country_functional_desc =\n\t\t\t\t(struct usb_cdc_country_functional_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_HEADER_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_header_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (header)\n\t\t\t\treturn -EINVAL;\n\t\t\theader = (struct usb_cdc_header_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ACM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_acm_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_acm_descriptor =\n\t\t\t\t(struct usb_cdc_acm_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ETHERNET_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_ether_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (ether)\n\t\t\t\treturn -EINVAL;\n\t\t\tether = (struct usb_cdc_ether_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_CALL_MANAGEMENT_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_call_mgmt_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_call_mgmt_descriptor =\n\t\t\t\t(struct usb_cdc_call_mgmt_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_DMM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_dmm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_dmm_desc =\n\t\t\t\t(struct usb_cdc_dmm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (desc)\n\t\t\t\treturn -EINVAL;\n\t\t\tdesc = (struct usb_cdc_mdlm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_DETAIL_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_detail_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (detail)\n\t\t\t\treturn -EINVAL;\n\t\t\tdetail = (struct usb_cdc_mdlm_detail_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_NCM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_ncm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_ncm_desc = (struct usb_cdc_ncm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_desc))\n\t\t\t\tgoto next_desc;\n\n\t\t\thdr->usb_cdc_mbim_desc = (struct usb_cdc_mbim_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_EXTENDED_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_extended_desc))\n\t\t\t\tbreak;\n\t\t\thdr->usb_cdc_mbim_extended_desc =\n\t\t\t\t(struct usb_cdc_mbim_extended_desc *)buffer;\n\t\t\tbreak;\n\t\tcase CDC_PHONET_MAGIC_NUMBER:\n\t\t\thdr->phonet_magic_present = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/*\n\t\t\t * there are LOTS more CDC descriptors that\n\t\t\t * could legitimately be found here.\n\t\t\t */\n\t\t\tdev_dbg(&intf->dev, \"Ignoring descriptor: type %02x, length %ud\\n\",\n\t\t\t\t\tbuffer[2], elength);\n\t\t\tgoto next_desc;\n\t\t}\n\t\tcnt++;\nnext_desc:\n\t\tbuflen -= elength;\n\t\tbuffer += elength;\n\t}\n\thdr->usb_cdc_union_desc = union_header;\n\thdr->usb_cdc_header_desc = header;\n\thdr->usb_cdc_mdlm_detail_desc = detail;\n\thdr->usb_cdc_mdlm_desc = desc;\n\thdr->usb_cdc_ether_desc = ether;\n\treturn cnt;\n}",
      "modified_lines": {
        "added": [
          "\t\t}",
          "\t\tif ((buflen < elength) || (elength < 3)) {",
          "\t\t\tdev_err(&intf->dev, \"invalid descriptor buffer length\\n\");",
          "\t\t\tbreak;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper validation of the descriptor buffer length before processing each descriptor.",
      "trigger_condition": "A crafted USB device with a malicious descriptor buffer is connected, leading to out-of-bounds read and system crash.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the descriptor buffer length is valid before processing each descriptor, allowing for potential out-of-bounds reads and system crashes.",
      "id": 106,
      "code_after_change_normalized": "int FUN1(struct usb_cdc_parsed_header *VAR1,\nstruct usb_interface *VAR2,\nu8 *VAR3,\nint VAR4)\n{\nstruct usb_cdc_union_desc *VAR5 = NULL;\nstruct usb_cdc_header_desc *VAR6 = NULL;\nstruct usb_cdc_ether_desc *VAR7 = NULL;\nstruct usb_cdc_mdlm_detail_desc *VAR8 = NULL;\nstruct usb_cdc_mdlm_desc *VAR9 = NULL;\nunsigned int VAR10;\nint VAR11 = 0;\nFUN2(VAR1, VAR12, sizeof(struct VAR13));\nVAR1->VAR14 = false;\nwhile (VAR4 > 0) {\nVAR10 = VAR3[0];\nif (!VAR10) {\nFUN3(&VAR2->VAR15, \"STR\");\nVAR10 = 1;\ngoto VAR16;\n}\nif ((VAR4 < VAR10) || (VAR10 < 3)) {\nFUN3(&VAR2->VAR15, \"STR\");\nbreak;\n}\nif (VAR3[1] != VAR17) {\nFUN3(&VAR2->VAR15, \"STR\");\ngoto VAR16;\n}\nswitch (VAR3[2]) {\ncase VAR18: \nif (VAR10 < sizeof(struct VAR19))\ngoto VAR16;\nif (VAR5) {\nFUN3(&VAR2->VAR15, \"STR\");\ngoto VAR16;\n}\nVAR5 = (struct VAR19 *)VAR3;\nbreak;\ncase VAR20:\nif (VAR10 < sizeof(struct VAR21))\ngoto VAR16;\nVAR1->VAR21 =\n(struct VAR21 *)VAR3;\nbreak;\ncase VAR22:\nif (VAR10 != sizeof(struct VAR23))\ngoto VAR16;\nif (VAR6)\nreturn -VAR24;\nVAR6 = (struct VAR23 *)VAR3;\nbreak;\ncase VAR25:\nif (VAR10 < sizeof(struct VAR26))\ngoto VAR16;\nVAR1->VAR26 =\n(struct VAR26 *)VAR3;\nbreak;\ncase VAR27:\nif (VAR10 != sizeof(struct VAR28))\ngoto VAR16;\nif (VAR7)\nreturn -VAR24;\nVAR7 = (struct VAR28 *)VAR3;\nbreak;\ncase VAR29:\nif (VAR10 < sizeof(struct VAR30))\ngoto VAR16;\nVAR1->VAR30 =\n(struct VAR30 *)VAR3;\nbreak;\ncase VAR31:\nif (VAR10 < sizeof(struct VAR32))\ngoto VAR16;\nVAR1->VAR32 =\n(struct VAR32 *)VAR3;\nbreak;\ncase VAR33:\nif (VAR10 < sizeof(struct VAR34 *))\ngoto VAR16;\nif (VAR9)\nreturn -VAR24;\nVAR9 = (struct VAR34 *)VAR3;\nbreak;\ncase VAR35:\nif (VAR10 < sizeof(struct VAR36 *))\ngoto VAR16;\nif (VAR8)\nreturn -VAR24;\nVAR8 = (struct VAR36 *)VAR3;\nbreak;\ncase VAR37:\nif (VAR10 < sizeof(struct VAR38))\ngoto VAR16;\nVAR1->VAR38 = (struct VAR38 *)VAR3;\nbreak;\ncase VAR39:\nif (VAR10 < sizeof(struct VAR40))\ngoto VAR16;\nVAR1->VAR40 = (struct VAR40 *)VAR3;\nbreak;\ncase VAR41:\nif (VAR10 < sizeof(struct VAR42))\nbreak;\nVAR1->VAR42 =\n(struct VAR42 *)VAR3;\nbreak;\ncase VAR43:\nVAR1->VAR14 = true;\nbreak;\ndefault:\nFUN4(&VAR2->VAR15, \"STR\",\nVAR3[2], VAR10);\ngoto VAR16;\n}\nVAR11++;\nVAR16:\nVAR4 -= VAR10;\nVAR3 += VAR10;\n}\nVAR1->VAR19 = VAR5;\nVAR1->VAR23 = VAR6;\nVAR1->VAR36 = VAR8;\nVAR1->VAR34 = VAR9;\nVAR1->VAR28 = VAR7;\nreturn VAR11;\n}\n",
      "code_before_change_normalized": "int FUN1(struct usb_cdc_parsed_header *VAR1,\nstruct usb_interface *VAR2,\nu8 *VAR3,\nint VAR4)\n{\nstruct usb_cdc_union_desc *VAR5 = NULL;\nstruct usb_cdc_header_desc *VAR6 = NULL;\nstruct usb_cdc_ether_desc *VAR7 = NULL;\nstruct usb_cdc_mdlm_detail_desc *VAR8 = NULL;\nstruct usb_cdc_mdlm_desc *VAR9 = NULL;\nunsigned int VAR10;\nint VAR11 = 0;\nFUN2(VAR1, VAR12, sizeof(struct VAR13));\nVAR1->VAR14 = false;\nwhile (VAR4 > 0) {\nVAR10 = VAR3[0];\nif (!VAR10) {\nFUN3(&VAR2->VAR15, \"STR\");\nVAR10 = 1;\ngoto VAR16;\n}\nif (VAR3[1] != VAR17) {\nFUN3(&VAR2->VAR15, \"STR\");\ngoto VAR16;\n}\nswitch (VAR3[2]) {\ncase VAR18: \nif (VAR10 < sizeof(struct VAR19))\ngoto VAR16;\nif (VAR5) {\nFUN3(&VAR2->VAR15, \"STR\");\ngoto VAR16;\n}\nVAR5 = (struct VAR19 *)VAR3;\nbreak;\ncase VAR20:\nif (VAR10 < sizeof(struct VAR21))\ngoto VAR16;\nVAR1->VAR21 =\n(struct VAR21 *)VAR3;\nbreak;\ncase VAR22:\nif (VAR10 != sizeof(struct VAR23))\ngoto VAR16;\nif (VAR6)\nreturn -VAR24;\nVAR6 = (struct VAR23 *)VAR3;\nbreak;\ncase VAR25:\nif (VAR10 < sizeof(struct VAR26))\ngoto VAR16;\nVAR1->VAR26 =\n(struct VAR26 *)VAR3;\nbreak;\ncase VAR27:\nif (VAR10 != sizeof(struct VAR28))\ngoto VAR16;\nif (VAR7)\nreturn -VAR24;\nVAR7 = (struct VAR28 *)VAR3;\nbreak;\ncase VAR29:\nif (VAR10 < sizeof(struct VAR30))\ngoto VAR16;\nVAR1->VAR30 =\n(struct VAR30 *)VAR3;\nbreak;\ncase VAR31:\nif (VAR10 < sizeof(struct VAR32))\ngoto VAR16;\nVAR1->VAR32 =\n(struct VAR32 *)VAR3;\nbreak;\ncase VAR33:\nif (VAR10 < sizeof(struct VAR34 *))\ngoto VAR16;\nif (VAR9)\nreturn -VAR24;\nVAR9 = (struct VAR34 *)VAR3;\nbreak;\ncase VAR35:\nif (VAR10 < sizeof(struct VAR36 *))\ngoto VAR16;\nif (VAR8)\nreturn -VAR24;\nVAR8 = (struct VAR36 *)VAR3;\nbreak;\ncase VAR37:\nif (VAR10 < sizeof(struct VAR38))\ngoto VAR16;\nVAR1->VAR38 = (struct VAR38 *)VAR3;\nbreak;\ncase VAR39:\nif (VAR10 < sizeof(struct VAR40))\ngoto VAR16;\nVAR1->VAR40 = (struct VAR40 *)VAR3;\nbreak;\ncase VAR41:\nif (VAR10 < sizeof(struct VAR42))\nbreak;\nVAR1->VAR42 =\n(struct VAR42 *)VAR3;\nbreak;\ncase VAR43:\nVAR1->VAR14 = true;\nbreak;\ndefault:\nFUN4(&VAR2->VAR15, \"STR\",\nVAR3[2], VAR10);\ngoto VAR16;\n}\nVAR11++;\nVAR16:\nVAR4 -= VAR10;\nVAR3 += VAR10;\n}\nVAR1->VAR19 = VAR5;\nVAR1->VAR23 = VAR6;\nVAR1->VAR36 = VAR8;\nVAR1->VAR34 = VAR9;\nVAR1->VAR28 = VAR7;\nreturn VAR11;\n}\n",
      "code_after_change_raw": "int cdc_parse_cdc_header(struct usb_cdc_parsed_header *hdr,\nstruct usb_interface *intf,\nu8 *buffer,\nint buflen)\n{\nstruct usb_cdc_union_desc *union_header = NULL;\nstruct usb_cdc_header_desc *header = NULL;\nstruct usb_cdc_ether_desc *ether = NULL;\nstruct usb_cdc_mdlm_detail_desc *detail = NULL;\nstruct usb_cdc_mdlm_desc *desc = NULL;\nunsigned int elength;\nint cnt = 0;\nmemset(hdr, 0x00, sizeof(struct usb_cdc_parsed_header));\nhdr->phonet_magic_present = false;\nwhile (buflen > 0) {\nelength = buffer[0];\nif (!elength) {\ndev_err(&intf->dev, \"skipping garbage byte\\n\");\nelength = 1;\ngoto next_desc;\n}\nif ((buflen < elength) || (elength < 3)) {\ndev_err(&intf->dev, \"invalid descriptor buffer length\\n\");\nbreak;\n}\nif (buffer[1] != USB_DT_CS_INTERFACE) {\ndev_err(&intf->dev, \"skipping garbage\\n\");\ngoto next_desc;\n}\nswitch (buffer[2]) {\ncase USB_CDC_UNION_TYPE: \nif (elength < sizeof(struct usb_cdc_union_desc))\ngoto next_desc;\nif (union_header) {\ndev_err(&intf->dev, \"More than one union descriptor, skipping ...\\n\");\ngoto next_desc;\n}\nunion_header = (struct usb_cdc_union_desc *)buffer;\nbreak;\ncase USB_CDC_COUNTRY_TYPE:\nif (elength < sizeof(struct usb_cdc_country_functional_desc))\ngoto next_desc;\nhdr->usb_cdc_country_functional_desc =\n(struct usb_cdc_country_functional_desc *)buffer;\nbreak;\ncase USB_CDC_HEADER_TYPE:\nif (elength != sizeof(struct usb_cdc_header_desc))\ngoto next_desc;\nif (header)\nreturn -EINVAL;\nheader = (struct usb_cdc_header_desc *)buffer;\nbreak;\ncase USB_CDC_ACM_TYPE:\nif (elength < sizeof(struct usb_cdc_acm_descriptor))\ngoto next_desc;\nhdr->usb_cdc_acm_descriptor =\n(struct usb_cdc_acm_descriptor *)buffer;\nbreak;\ncase USB_CDC_ETHERNET_TYPE:\nif (elength != sizeof(struct usb_cdc_ether_desc))\ngoto next_desc;\nif (ether)\nreturn -EINVAL;\nether = (struct usb_cdc_ether_desc *)buffer;\nbreak;\ncase USB_CDC_CALL_MANAGEMENT_TYPE:\nif (elength < sizeof(struct usb_cdc_call_mgmt_descriptor))\ngoto next_desc;\nhdr->usb_cdc_call_mgmt_descriptor =\n(struct usb_cdc_call_mgmt_descriptor *)buffer;\nbreak;\ncase USB_CDC_DMM_TYPE:\nif (elength < sizeof(struct usb_cdc_dmm_desc))\ngoto next_desc;\nhdr->usb_cdc_dmm_desc =\n(struct usb_cdc_dmm_desc *)buffer;\nbreak;\ncase USB_CDC_MDLM_TYPE:\nif (elength < sizeof(struct usb_cdc_mdlm_desc *))\ngoto next_desc;\nif (desc)\nreturn -EINVAL;\ndesc = (struct usb_cdc_mdlm_desc *)buffer;\nbreak;\ncase USB_CDC_MDLM_DETAIL_TYPE:\nif (elength < sizeof(struct usb_cdc_mdlm_detail_desc *))\ngoto next_desc;\nif (detail)\nreturn -EINVAL;\ndetail = (struct usb_cdc_mdlm_detail_desc *)buffer;\nbreak;\ncase USB_CDC_NCM_TYPE:\nif (elength < sizeof(struct usb_cdc_ncm_desc))\ngoto next_desc;\nhdr->usb_cdc_ncm_desc = (struct usb_cdc_ncm_desc *)buffer;\nbreak;\ncase USB_CDC_MBIM_TYPE:\nif (elength < sizeof(struct usb_cdc_mbim_desc))\ngoto next_desc;\nhdr->usb_cdc_mbim_desc = (struct usb_cdc_mbim_desc *)buffer;\nbreak;\ncase USB_CDC_MBIM_EXTENDED_TYPE:\nif (elength < sizeof(struct usb_cdc_mbim_extended_desc))\nbreak;\nhdr->usb_cdc_mbim_extended_desc =\n(struct usb_cdc_mbim_extended_desc *)buffer;\nbreak;\ncase CDC_PHONET_MAGIC_NUMBER:\nhdr->phonet_magic_present = true;\nbreak;\ndefault:\ndev_dbg(&intf->dev, \"Ignoring descriptor: type %02x, length %ud\\n\",\nbuffer[2], elength);\ngoto next_desc;\n}\ncnt++;\nnext_desc:\nbuflen -= elength;\nbuffer += elength;\n}\nhdr->usb_cdc_union_desc = union_header;\nhdr->usb_cdc_header_desc = header;\nhdr->usb_cdc_mdlm_detail_desc = detail;\nhdr->usb_cdc_mdlm_desc = desc;\nhdr->usb_cdc_ether_desc = ether;\nreturn cnt;\n}\n",
      "code_before_change_raw": "int cdc_parse_cdc_header(struct usb_cdc_parsed_header *hdr,\nstruct usb_interface *intf,\nu8 *buffer,\nint buflen)\n{\nstruct usb_cdc_union_desc *union_header = NULL;\nstruct usb_cdc_header_desc *header = NULL;\nstruct usb_cdc_ether_desc *ether = NULL;\nstruct usb_cdc_mdlm_detail_desc *detail = NULL;\nstruct usb_cdc_mdlm_desc *desc = NULL;\nunsigned int elength;\nint cnt = 0;\nmemset(hdr, 0x00, sizeof(struct usb_cdc_parsed_header));\nhdr->phonet_magic_present = false;\nwhile (buflen > 0) {\nelength = buffer[0];\nif (!elength) {\ndev_err(&intf->dev, \"skipping garbage byte\\n\");\nelength = 1;\ngoto next_desc;\n}\nif (buffer[1] != USB_DT_CS_INTERFACE) {\ndev_err(&intf->dev, \"skipping garbage\\n\");\ngoto next_desc;\n}\nswitch (buffer[2]) {\ncase USB_CDC_UNION_TYPE: \nif (elength < sizeof(struct usb_cdc_union_desc))\ngoto next_desc;\nif (union_header) {\ndev_err(&intf->dev, \"More than one union descriptor, skipping ...\\n\");\ngoto next_desc;\n}\nunion_header = (struct usb_cdc_union_desc *)buffer;\nbreak;\ncase USB_CDC_COUNTRY_TYPE:\nif (elength < sizeof(struct usb_cdc_country_functional_desc))\ngoto next_desc;\nhdr->usb_cdc_country_functional_desc =\n(struct usb_cdc_country_functional_desc *)buffer;\nbreak;\ncase USB_CDC_HEADER_TYPE:\nif (elength != sizeof(struct usb_cdc_header_desc))\ngoto next_desc;\nif (header)\nreturn -EINVAL;\nheader = (struct usb_cdc_header_desc *)buffer;\nbreak;\ncase USB_CDC_ACM_TYPE:\nif (elength < sizeof(struct usb_cdc_acm_descriptor))\ngoto next_desc;\nhdr->usb_cdc_acm_descriptor =\n(struct usb_cdc_acm_descriptor *)buffer;\nbreak;\ncase USB_CDC_ETHERNET_TYPE:\nif (elength != sizeof(struct usb_cdc_ether_desc))\ngoto next_desc;\nif (ether)\nreturn -EINVAL;\nether = (struct usb_cdc_ether_desc *)buffer;\nbreak;\ncase USB_CDC_CALL_MANAGEMENT_TYPE:\nif (elength < sizeof(struct usb_cdc_call_mgmt_descriptor))\ngoto next_desc;\nhdr->usb_cdc_call_mgmt_descriptor =\n(struct usb_cdc_call_mgmt_descriptor *)buffer;\nbreak;\ncase USB_CDC_DMM_TYPE:\nif (elength < sizeof(struct usb_cdc_dmm_desc))\ngoto next_desc;\nhdr->usb_cdc_dmm_desc =\n(struct usb_cdc_dmm_desc *)buffer;\nbreak;\ncase USB_CDC_MDLM_TYPE:\nif (elength < sizeof(struct usb_cdc_mdlm_desc *))\ngoto next_desc;\nif (desc)\nreturn -EINVAL;\ndesc = (struct usb_cdc_mdlm_desc *)buffer;\nbreak;\ncase USB_CDC_MDLM_DETAIL_TYPE:\nif (elength < sizeof(struct usb_cdc_mdlm_detail_desc *))\ngoto next_desc;\nif (detail)\nreturn -EINVAL;\ndetail = (struct usb_cdc_mdlm_detail_desc *)buffer;\nbreak;\ncase USB_CDC_NCM_TYPE:\nif (elength < sizeof(struct usb_cdc_ncm_desc))\ngoto next_desc;\nhdr->usb_cdc_ncm_desc = (struct usb_cdc_ncm_desc *)buffer;\nbreak;\ncase USB_CDC_MBIM_TYPE:\nif (elength < sizeof(struct usb_cdc_mbim_desc))\ngoto next_desc;\nhdr->usb_cdc_mbim_desc = (struct usb_cdc_mbim_desc *)buffer;\nbreak;\ncase USB_CDC_MBIM_EXTENDED_TYPE:\nif (elength < sizeof(struct usb_cdc_mbim_extended_desc))\nbreak;\nhdr->usb_cdc_mbim_extended_desc =\n(struct usb_cdc_mbim_extended_desc *)buffer;\nbreak;\ncase CDC_PHONET_MAGIC_NUMBER:\nhdr->phonet_magic_present = true;\nbreak;\ndefault:\ndev_dbg(&intf->dev, \"Ignoring descriptor: type %02x, length %ud\\n\",\nbuffer[2], elength);\ngoto next_desc;\n}\ncnt++;\nnext_desc:\nbuflen -= elength;\nbuffer += elength;\n}\nhdr->usb_cdc_union_desc = union_header;\nhdr->usb_cdc_header_desc = header;\nhdr->usb_cdc_mdlm_detail_desc = detail;\nhdr->usb_cdc_mdlm_desc = desc;\nhdr->usb_cdc_ether_desc = ether;\nreturn cnt;\n}\n"
    }
  ],
  "CVE-2017-16913": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for the transfer buffer length specified in CMD_SUBMIT packets, allowing for arbitrary memory allocation.",
        "trigger_condition": "An attacker sends a specially crafted USB over IP packet with a large transfer buffer length, exploiting the lack of validation and causing a denial of service due to excessive memory allocation.",
        "specific_code_behavior_causing_vulnerability": "The code allocates memory for the transfer buffer without verifying that the transfer buffer length is within a valid range, leading to potential arbitrary memory allocation and denial of service vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the transfer buffer length specified in CMD_SUBMIT packets is greater than 0 and less than or equal to INT_MAX. This validation step prevents excessive memory allocation and helps protect against denial of service attacks. By validating the transfer buffer length before allocating memory, the code can prevent the exploitation of this vulnerability.",
      "GPT_analysis": "The modification made to the code snippet is necessary to address the vulnerability CVE-2017-16913. The vulnerability in the original code lies in the handling of the transfer buffer length in the CMD_SUBMIT packets. An attacker could exploit this vulnerability to cause a denial of service (arbitrary memory allocation) by sending a specially crafted USB over IP packet with a large transfer buffer length.\n\nThe modification adds a check to ensure that the transfer buffer length specified in the CMD_SUBMIT packet is within a valid range (greater than 0 and less than or equal to INT_MAX). By adding this check, the code prevents the allocation of excessive memory that could lead to a denial of service attack.\n\nTherefore, by validating the transfer buffer length before allocating memory for the transfer buffer, the modified code effectively mitigates the vulnerability and enhances the security of the system.",
      "GPT_purpose": "Receive and process USB over IP packets for submitting USB requests in the Linux Kernel.",
      "GPT_function": "\n1. Receive a USBIP packet and process it.\n2. Allocate memory for a USB Request Block (URB) based on the packet information.\n3. Copy setup packet data from the USBIP packet to the URB.\n4. Set up URB members such as context, device, pipe, and completion function.\n5. Pack the URB into a USBIP packet and receive transfer buffer data.\n6. Handle special requests and adjust URB flags.\n7. Submit the URB for processing and handle the submission result.",
      "CVE_id": "CVE-2017-16913",
      "code_before_change": "static void stub_recv_cmd_submit(struct stub_device *sdev,\n\t\t\t\t struct usbip_header *pdu)\n{\n\tint ret;\n\tstruct stub_priv *priv;\n\tstruct usbip_device *ud = &sdev->ud;\n\tstruct usb_device *udev = sdev->udev;\n\tint pipe = get_pipe(sdev, pdu->base.ep, pdu->base.direction);\n\n\tif (pipe == -1)\n\t\treturn;\n\n\tpriv = stub_priv_alloc(sdev, pdu);\n\tif (!priv)\n\t\treturn;\n\n\t/* setup a urb */\n\tif (usb_pipeisoc(pipe))\n\t\tpriv->urb = usb_alloc_urb(pdu->u.cmd_submit.number_of_packets,\n\t\t\t\t\t  GFP_KERNEL);\n\telse\n\t\tpriv->urb = usb_alloc_urb(0, GFP_KERNEL);\n\n\tif (!priv->urb) {\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* allocate urb transfer buffer, if needed */\n\tif (pdu->u.cmd_submit.transfer_buffer_length > 0) {\n\t\tpriv->urb->transfer_buffer =\n\t\t\tkzalloc(pdu->u.cmd_submit.transfer_buffer_length,\n\t\t\t\tGFP_KERNEL);\n\t\tif (!priv->urb->transfer_buffer) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* copy urb setup packet */\n\tpriv->urb->setup_packet = kmemdup(&pdu->u.cmd_submit.setup, 8,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!priv->urb->setup_packet) {\n\t\tdev_err(&udev->dev, \"allocate setup_packet\\n\");\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* set other members from the base header of pdu */\n\tpriv->urb->context                = (void *) priv;\n\tpriv->urb->dev                    = udev;\n\tpriv->urb->pipe                   = pipe;\n\tpriv->urb->complete               = stub_complete;\n\n\tusbip_pack_pdu(pdu, priv->urb, USBIP_CMD_SUBMIT, 0);\n\n\n\tif (usbip_recv_xbuff(ud, priv->urb) < 0)\n\t\treturn;\n\n\tif (usbip_recv_iso(ud, priv->urb) < 0)\n\t\treturn;\n\n\t/* no need to submit an intercepted request, but harmless? */\n\ttweak_special_requests(priv->urb);\n\n\tmasking_bogus_flags(priv->urb);\n\t/* urb is now ready to submit */\n\tret = usb_submit_urb(priv->urb, GFP_KERNEL);\n\n\tif (ret == 0)\n\t\tusbip_dbg_stub_rx(\"submit urb ok, seqnum %u\\n\",\n\t\t\t\t  pdu->base.seqnum);\n\telse {\n\t\tdev_err(&udev->dev, \"submit_urb error, %d\\n\", ret);\n\t\tusbip_dump_header(pdu);\n\t\tusbip_dump_urb(priv->urb);\n\n\t\t/*\n\t\t * Pessimistic.\n\t\t * This connection will be discarded.\n\t\t */\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_SUBMIT);\n\t}\n\n\tusbip_dbg_stub_rx(\"Leave\\n\");\n}",
      "code_after_change": "static void stub_recv_cmd_submit(struct stub_device *sdev,\n\t\t\t\t struct usbip_header *pdu)\n{\n\tint ret;\n\tstruct stub_priv *priv;\n\tstruct usbip_device *ud = &sdev->ud;\n\tstruct usb_device *udev = sdev->udev;\n\tint pipe = get_pipe(sdev, pdu);\n\n\tif (pipe == -1)\n\t\treturn;\n\n\tpriv = stub_priv_alloc(sdev, pdu);\n\tif (!priv)\n\t\treturn;\n\n\t/* setup a urb */\n\tif (usb_pipeisoc(pipe))\n\t\tpriv->urb = usb_alloc_urb(pdu->u.cmd_submit.number_of_packets,\n\t\t\t\t\t  GFP_KERNEL);\n\telse\n\t\tpriv->urb = usb_alloc_urb(0, GFP_KERNEL);\n\n\tif (!priv->urb) {\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* allocate urb transfer buffer, if needed */\n\tif (pdu->u.cmd_submit.transfer_buffer_length > 0 &&\n\t    pdu->u.cmd_submit.transfer_buffer_length <= INT_MAX) {\n\t\tpriv->urb->transfer_buffer =\n\t\t\tkzalloc(pdu->u.cmd_submit.transfer_buffer_length,\n\t\t\t\tGFP_KERNEL);\n\t\tif (!priv->urb->transfer_buffer) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* copy urb setup packet */\n\tpriv->urb->setup_packet = kmemdup(&pdu->u.cmd_submit.setup, 8,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!priv->urb->setup_packet) {\n\t\tdev_err(&udev->dev, \"allocate setup_packet\\n\");\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* set other members from the base header of pdu */\n\tpriv->urb->context                = (void *) priv;\n\tpriv->urb->dev                    = udev;\n\tpriv->urb->pipe                   = pipe;\n\tpriv->urb->complete               = stub_complete;\n\n\tusbip_pack_pdu(pdu, priv->urb, USBIP_CMD_SUBMIT, 0);\n\n\n\tif (usbip_recv_xbuff(ud, priv->urb) < 0)\n\t\treturn;\n\n\tif (usbip_recv_iso(ud, priv->urb) < 0)\n\t\treturn;\n\n\t/* no need to submit an intercepted request, but harmless? */\n\ttweak_special_requests(priv->urb);\n\n\tmasking_bogus_flags(priv->urb);\n\t/* urb is now ready to submit */\n\tret = usb_submit_urb(priv->urb, GFP_KERNEL);\n\n\tif (ret == 0)\n\t\tusbip_dbg_stub_rx(\"submit urb ok, seqnum %u\\n\",\n\t\t\t\t  pdu->base.seqnum);\n\telse {\n\t\tdev_err(&udev->dev, \"submit_urb error, %d\\n\", ret);\n\t\tusbip_dump_header(pdu);\n\t\tusbip_dump_urb(priv->urb);\n\n\t\t/*\n\t\t * Pessimistic.\n\t\t * This connection will be discarded.\n\t\t */\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_SUBMIT);\n\t}\n\n\tusbip_dbg_stub_rx(\"Leave\\n\");\n}",
      "modified_lines": {
        "added": [
          "\tint pipe = get_pipe(sdev, pdu);",
          "\tif (pdu->u.cmd_submit.transfer_buffer_length > 0 &&",
          "\t    pdu->u.cmd_submit.transfer_buffer_length <= INT_MAX) {"
        ],
        "deleted": [
          "\tint pipe = get_pipe(sdev, pdu->base.ep, pdu->base.direction);",
          "\tif (pdu->u.cmd_submit.transfer_buffer_length > 0) {"
        ]
      },
      "preconditions_for_vulnerability": "Lack of validation for the transfer buffer length specified in CMD_SUBMIT packets, allowing for arbitrary memory allocation.",
      "trigger_condition": "An attacker sends a specially crafted USB over IP packet with a large transfer buffer length, exploiting the lack of validation and causing a denial of service due to excessive memory allocation.",
      "specific_code_behavior_causing_vulnerability": "The code allocates memory for the transfer buffer without verifying that the transfer buffer length is within a valid range, leading to potential arbitrary memory allocation and denial of service vulnerability.",
      "id": 107,
      "code_after_change_normalized": "static void FUN1(struct stub_device *VAR1,\nstruct usbip_header *VAR2)\n{\nint VAR3;\nstruct stub_priv *VAR4;\nstruct usbip_device *VAR5 = &VAR1->VAR5;\nstruct usb_device *VAR6 = VAR1->VAR6;\nint VAR7 = FUN2(VAR1, VAR2);\nif (VAR7 == -1)\nreturn;\nVAR4 = FUN3(VAR1, VAR2);\nif (!VAR4)\nreturn;\nif (FUN4(VAR7))\nVAR4->VAR8 = FUN5(VAR2->VAR9.VAR10.VAR11,\nVAR12);\nelse\nVAR4->VAR8 = FUN5(0, VAR12);\nif (!VAR4->VAR8) {\nFUN6(VAR5, VAR13);\nreturn;\n}\nif (VAR2->VAR9.VAR10.VAR14 > 0 &&\nVAR2->VAR9.VAR10.VAR14 <= VAR15) {\nVAR4->VAR8->VAR16 =\nFUN7(VAR2->VAR9.VAR10.VAR14,\nVAR12);\nif (!VAR4->VAR8->VAR16) {\nFUN6(VAR5, VAR13);\nreturn;\n}\n}\nVAR4->VAR8->VAR17 = FUN8(&VAR2->VAR9.VAR10.VAR18, 8,\nVAR12);\nif (!VAR4->VAR8->VAR17) {\nFUN9(&VAR6->VAR19, \"STR\");\nFUN6(VAR5, VAR13);\nreturn;\n}\nVAR4->VAR8->VAR20                = (void *) VAR4;\nVAR4->VAR8->VAR19                    = VAR6;\nVAR4->VAR8->VAR7                   = VAR7;\nVAR4->VAR8->VAR21               = VAR22;\nFUN10(VAR2, VAR4->VAR8, VAR23, 0);\nif (FUN11(VAR5, VAR4->VAR8) < 0)\nreturn;\nif (FUN12(VAR5, VAR4->VAR8) < 0)\nreturn;\nFUN13(VAR4->VAR8);\nFUN14(VAR4->VAR8);\nVAR3 = FUN15(VAR4->VAR8, VAR12);\nif (VAR3 == 0)\nFUN16(\"STR\",\nVAR2->VAR24.VAR25);\nelse {\nFUN9(&VAR6->VAR19, \"STR\", VAR3);\nFUN17(VAR2);\nFUN18(VAR4->VAR8);\nFUN6(VAR5, VAR26);\n}\nFUN16(\"STR\");\n}\n",
      "code_before_change_normalized": "static void FUN1(struct stub_device *VAR1,\nstruct usbip_header *VAR2)\n{\nint VAR3;\nstruct stub_priv *VAR4;\nstruct usbip_device *VAR5 = &VAR1->VAR5;\nstruct usb_device *VAR6 = VAR1->VAR6;\nint VAR7 = FUN2(VAR1, VAR2->VAR8.VAR9, VAR2->VAR8.VAR10);\nif (VAR7 == -1)\nreturn;\nVAR4 = FUN3(VAR1, VAR2);\nif (!VAR4)\nreturn;\nif (FUN4(VAR7))\nVAR4->VAR11 = FUN5(VAR2->VAR12.VAR13.VAR14,\nVAR15);\nelse\nVAR4->VAR11 = FUN5(0, VAR15);\nif (!VAR4->VAR11) {\nFUN6(VAR5, VAR16);\nreturn;\n}\nif (VAR2->VAR12.VAR13.VAR17 > 0) {\nVAR4->VAR11->VAR18 =\nFUN7(VAR2->VAR12.VAR13.VAR17,\nVAR15);\nif (!VAR4->VAR11->VAR18) {\nFUN6(VAR5, VAR16);\nreturn;\n}\n}\nVAR4->VAR11->VAR19 = FUN8(&VAR2->VAR12.VAR13.VAR20, 8,\nVAR15);\nif (!VAR4->VAR11->VAR19) {\nFUN9(&VAR6->VAR21, \"STR\");\nFUN6(VAR5, VAR16);\nreturn;\n}\nVAR4->VAR11->VAR22                = (void *) VAR4;\nVAR4->VAR11->VAR21                    = VAR6;\nVAR4->VAR11->VAR7                   = VAR7;\nVAR4->VAR11->VAR23               = VAR24;\nFUN10(VAR2, VAR4->VAR11, VAR25, 0);\nif (FUN11(VAR5, VAR4->VAR11) < 0)\nreturn;\nif (FUN12(VAR5, VAR4->VAR11) < 0)\nreturn;\nFUN13(VAR4->VAR11);\nFUN14(VAR4->VAR11);\nVAR3 = FUN15(VAR4->VAR11, VAR15);\nif (VAR3 == 0)\nFUN16(\"STR\",\nVAR2->VAR8.VAR26);\nelse {\nFUN9(&VAR6->VAR21, \"STR\", VAR3);\nFUN17(VAR2);\nFUN18(VAR4->VAR11);\nFUN6(VAR5, VAR27);\n}\nFUN16(\"STR\");\n}\n",
      "code_after_change_raw": "static void stub_recv_cmd_submit(struct stub_device *sdev,\nstruct usbip_header *pdu)\n{\nint ret;\nstruct stub_priv *priv;\nstruct usbip_device *ud = &sdev->ud;\nstruct usb_device *udev = sdev->udev;\nint pipe = get_pipe(sdev, pdu);\nif (pipe == -1)\nreturn;\npriv = stub_priv_alloc(sdev, pdu);\nif (!priv)\nreturn;\nif (usb_pipeisoc(pipe))\npriv->urb = usb_alloc_urb(pdu->u.cmd_submit.number_of_packets,\nGFP_KERNEL);\nelse\npriv->urb = usb_alloc_urb(0, GFP_KERNEL);\nif (!priv->urb) {\nusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\nreturn;\n}\nif (pdu->u.cmd_submit.transfer_buffer_length > 0 &&\npdu->u.cmd_submit.transfer_buffer_length <= INT_MAX) {\npriv->urb->transfer_buffer =\nkzalloc(pdu->u.cmd_submit.transfer_buffer_length,\nGFP_KERNEL);\nif (!priv->urb->transfer_buffer) {\nusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\nreturn;\n}\n}\npriv->urb->setup_packet = kmemdup(&pdu->u.cmd_submit.setup, 8,\nGFP_KERNEL);\nif (!priv->urb->setup_packet) {\ndev_err(&udev->dev, \"allocate setup_packet\\n\");\nusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\nreturn;\n}\npriv->urb->context                = (void *) priv;\npriv->urb->dev                    = udev;\npriv->urb->pipe                   = pipe;\npriv->urb->complete               = stub_complete;\nusbip_pack_pdu(pdu, priv->urb, USBIP_CMD_SUBMIT, 0);\nif (usbip_recv_xbuff(ud, priv->urb) < 0)\nreturn;\nif (usbip_recv_iso(ud, priv->urb) < 0)\nreturn;\ntweak_special_requests(priv->urb);\nmasking_bogus_flags(priv->urb);\nret = usb_submit_urb(priv->urb, GFP_KERNEL);\nif (ret == 0)\nusbip_dbg_stub_rx(\"submit urb ok, seqnum %u\\n\",\npdu->base.seqnum);\nelse {\ndev_err(&udev->dev, \"submit_urb error, %d\\n\", ret);\nusbip_dump_header(pdu);\nusbip_dump_urb(priv->urb);\nusbip_event_add(ud, SDEV_EVENT_ERROR_SUBMIT);\n}\nusbip_dbg_stub_rx(\"Leave\\n\");\n}\n",
      "code_before_change_raw": "static void stub_recv_cmd_submit(struct stub_device *sdev,\nstruct usbip_header *pdu)\n{\nint ret;\nstruct stub_priv *priv;\nstruct usbip_device *ud = &sdev->ud;\nstruct usb_device *udev = sdev->udev;\nint pipe = get_pipe(sdev, pdu->base.ep, pdu->base.direction);\nif (pipe == -1)\nreturn;\npriv = stub_priv_alloc(sdev, pdu);\nif (!priv)\nreturn;\nif (usb_pipeisoc(pipe))\npriv->urb = usb_alloc_urb(pdu->u.cmd_submit.number_of_packets,\nGFP_KERNEL);\nelse\npriv->urb = usb_alloc_urb(0, GFP_KERNEL);\nif (!priv->urb) {\nusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\nreturn;\n}\nif (pdu->u.cmd_submit.transfer_buffer_length > 0) {\npriv->urb->transfer_buffer =\nkzalloc(pdu->u.cmd_submit.transfer_buffer_length,\nGFP_KERNEL);\nif (!priv->urb->transfer_buffer) {\nusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\nreturn;\n}\n}\npriv->urb->setup_packet = kmemdup(&pdu->u.cmd_submit.setup, 8,\nGFP_KERNEL);\nif (!priv->urb->setup_packet) {\ndev_err(&udev->dev, \"allocate setup_packet\\n\");\nusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\nreturn;\n}\npriv->urb->context                = (void *) priv;\npriv->urb->dev                    = udev;\npriv->urb->pipe                   = pipe;\npriv->urb->complete               = stub_complete;\nusbip_pack_pdu(pdu, priv->urb, USBIP_CMD_SUBMIT, 0);\nif (usbip_recv_xbuff(ud, priv->urb) < 0)\nreturn;\nif (usbip_recv_iso(ud, priv->urb) < 0)\nreturn;\ntweak_special_requests(priv->urb);\nmasking_bogus_flags(priv->urb);\nret = usb_submit_urb(priv->urb, GFP_KERNEL);\nif (ret == 0)\nusbip_dbg_stub_rx(\"submit urb ok, seqnum %u\\n\",\npdu->base.seqnum);\nelse {\ndev_err(&udev->dev, \"submit_urb error, %d\\n\", ret);\nusbip_dump_header(pdu);\nusbip_dump_urb(priv->urb);\nusbip_event_add(ud, SDEV_EVENT_ERROR_SUBMIT);\n}\nusbip_dbg_stub_rx(\"Leave\\n\");\n}\n"
    }
  ],
  "CVE-2017-16996": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for register truncation in the BPF verifier code.",
        "trigger_condition": "Local users can exploit the mishandling of register truncation to cause memory corruption or other unspecified impacts.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly handle register truncation in certain BPF instructions, potentially leading to memory corruption when manipulating register values."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that register sizes are properly coerced to prevent truncation issues. Specifically, in the BPF_MOV case where the source operand is a register (BPF_X), adding a function call to coerce the register to a size of 4 bytes helps prevent register truncation and enhances the security of the BPF verifier.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-16996, which involves register truncation mishandling in the Linux kernel's BPF verifier. The vulnerability allows local users to cause a denial of service (memory corruption) or potentially have other unspecified impacts.\n\nThe specific change made in the code snippet is the addition of the function `coerce_reg_to_size(&regs[insn->dst_reg], 4);` in the `BPF_MOV` case where the source operand is a register (`BPF_X`). This function call ensures that the register is coerced to a size of 4 bytes, which helps prevent register truncation issues that could lead to memory corruption or other security vulnerabilities.\n\nBy adding this coercion step, the modified code snippet mitigates the register truncation mishandling vulnerability and improves the security of the BPF verifier in the Linux kernel.",
      "GPT_purpose": "Verify and check the validity of ALU operations in a BPF program.",
      "GPT_function": "\n1. Check ALU operation for BPF_END and BPF_NEG opcodes.\n2. Check ALU operation for BPF_MOV opcode.\n3. Check ALU operation for other ALU ops (and, sub, xor, add, etc.).",
      "CVE_id": "CVE-2017-16996",
      "code_before_change": "static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tint err;\n\n\tif (opcode == BPF_END || opcode == BPF_NEG) {\n\t\tif (opcode == BPF_NEG) {\n\t\t\tif (BPF_SRC(insn->code) != 0 ||\n\t\t\t    insn->src_reg != BPF_REG_0 ||\n\t\t\t    insn->off != 0 || insn->imm != 0) {\n\t\t\t\tverbose(env, \"BPF_NEG uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0 ||\n\t\t\t    (insn->imm != 16 && insn->imm != 32 && insn->imm != 64) ||\n\t\t\t    BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\tverbose(env, \"BPF_END uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (is_pointer_value(env, insn->dst_reg)) {\n\t\t\tverbose(env, \"R%d pointer arithmetic prohibited\\n\",\n\t\t\t\tinsn->dst_reg);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t} else if (opcode == BPF_MOV) {\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t/* check src operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t/* case: R1 = R2\n\t\t\t\t * copy register state to dest reg\n\t\t\t\t */\n\t\t\t\tregs[insn->dst_reg] = regs[insn->src_reg];\n\t\t\t\tregs[insn->dst_reg].live |= REG_LIVE_WRITTEN;\n\t\t\t} else {\n\t\t\t\t/* R1 = (u32) R2 */\n\t\t\t\tif (is_pointer_value(env, insn->src_reg)) {\n\t\t\t\t\tverbose(env,\n\t\t\t\t\t\t\"R%d partial copy of pointer\\n\",\n\t\t\t\t\t\tinsn->src_reg);\n\t\t\t\t\treturn -EACCES;\n\t\t\t\t}\n\t\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\t\t/* high 32 bits are known zero. */\n\t\t\t\tregs[insn->dst_reg].var_off = tnum_cast(\n\t\t\t\t\t\tregs[insn->dst_reg].var_off, 4);\n\t\t\t\t__update_reg_bounds(&regs[insn->dst_reg]);\n\t\t\t}\n\t\t} else {\n\t\t\t/* case: R = imm\n\t\t\t * remember the value we stored into this reg\n\t\t\t */\n\t\t\tregs[insn->dst_reg].type = SCALAR_VALUE;\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t insn->imm);\n\t\t\t} else {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t (u32)insn->imm);\n\t\t\t}\n\t\t}\n\n\t} else if (opcode > BPF_END) {\n\t\tverbose(env, \"invalid BPF_ALU opcode %x\\n\", opcode);\n\t\treturn -EINVAL;\n\n\t} else {\t/* all other ALU ops: and, sub, xor, add, ... */\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t/* check src1 operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src2 operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif ((opcode == BPF_MOD || opcode == BPF_DIV) &&\n\t\t    BPF_SRC(insn->code) == BPF_K && insn->imm == 0) {\n\t\t\tverbose(env, \"div by zero\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif ((opcode == BPF_LSH || opcode == BPF_RSH ||\n\t\t     opcode == BPF_ARSH) && BPF_SRC(insn->code) == BPF_K) {\n\t\t\tint size = BPF_CLASS(insn->code) == BPF_ALU64 ? 64 : 32;\n\n\t\t\tif (insn->imm < 0 || insn->imm >= size) {\n\t\t\t\tverbose(env, \"invalid shift %d\\n\", insn->imm);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\treturn adjust_reg_min_max_vals(env, insn);\n\t}\n\n\treturn 0;\n}",
      "code_after_change": "static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tint err;\n\n\tif (opcode == BPF_END || opcode == BPF_NEG) {\n\t\tif (opcode == BPF_NEG) {\n\t\t\tif (BPF_SRC(insn->code) != 0 ||\n\t\t\t    insn->src_reg != BPF_REG_0 ||\n\t\t\t    insn->off != 0 || insn->imm != 0) {\n\t\t\t\tverbose(env, \"BPF_NEG uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0 ||\n\t\t\t    (insn->imm != 16 && insn->imm != 32 && insn->imm != 64) ||\n\t\t\t    BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\tverbose(env, \"BPF_END uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (is_pointer_value(env, insn->dst_reg)) {\n\t\t\tverbose(env, \"R%d pointer arithmetic prohibited\\n\",\n\t\t\t\tinsn->dst_reg);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t} else if (opcode == BPF_MOV) {\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t/* check src operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t/* case: R1 = R2\n\t\t\t\t * copy register state to dest reg\n\t\t\t\t */\n\t\t\t\tregs[insn->dst_reg] = regs[insn->src_reg];\n\t\t\t\tregs[insn->dst_reg].live |= REG_LIVE_WRITTEN;\n\t\t\t} else {\n\t\t\t\t/* R1 = (u32) R2 */\n\t\t\t\tif (is_pointer_value(env, insn->src_reg)) {\n\t\t\t\t\tverbose(env,\n\t\t\t\t\t\t\"R%d partial copy of pointer\\n\",\n\t\t\t\t\t\tinsn->src_reg);\n\t\t\t\t\treturn -EACCES;\n\t\t\t\t}\n\t\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\t\tcoerce_reg_to_size(&regs[insn->dst_reg], 4);\n\t\t\t}\n\t\t} else {\n\t\t\t/* case: R = imm\n\t\t\t * remember the value we stored into this reg\n\t\t\t */\n\t\t\tregs[insn->dst_reg].type = SCALAR_VALUE;\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t insn->imm);\n\t\t\t} else {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t (u32)insn->imm);\n\t\t\t}\n\t\t}\n\n\t} else if (opcode > BPF_END) {\n\t\tverbose(env, \"invalid BPF_ALU opcode %x\\n\", opcode);\n\t\treturn -EINVAL;\n\n\t} else {\t/* all other ALU ops: and, sub, xor, add, ... */\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t/* check src1 operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src2 operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif ((opcode == BPF_MOD || opcode == BPF_DIV) &&\n\t\t    BPF_SRC(insn->code) == BPF_K && insn->imm == 0) {\n\t\t\tverbose(env, \"div by zero\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif ((opcode == BPF_LSH || opcode == BPF_RSH ||\n\t\t     opcode == BPF_ARSH) && BPF_SRC(insn->code) == BPF_K) {\n\t\t\tint size = BPF_CLASS(insn->code) == BPF_ALU64 ? 64 : 32;\n\n\t\t\tif (insn->imm < 0 || insn->imm >= size) {\n\t\t\t\tverbose(env, \"invalid shift %d\\n\", insn->imm);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\treturn adjust_reg_min_max_vals(env, insn);\n\t}\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\t\t\tcoerce_reg_to_size(&regs[insn->dst_reg], 4);"
        ],
        "deleted": [
          "\t\t\t\t/* high 32 bits are known zero. */",
          "\t\t\t\tregs[insn->dst_reg].var_off = tnum_cast(",
          "\t\t\t\t\t\tregs[insn->dst_reg].var_off, 4);",
          "\t\t\t\t__update_reg_bounds(&regs[insn->dst_reg]);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for register truncation in the BPF verifier code.",
      "trigger_condition": "Local users can exploit the mishandling of register truncation to cause memory corruption or other unspecified impacts.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly handle register truncation in certain BPF instructions, potentially leading to memory corruption when manipulating register values.",
      "id": 108,
      "code_after_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1, struct bpf_insn *VAR2)\n{\nstruct bpf_reg_state *VAR3 = FUN2(VAR1);\nu8 VAR4 = FUN3(VAR2->VAR5);\nint VAR6;\nif (VAR4 == VAR7 || VAR4 == VAR8) {\nif (VAR4 == VAR8) {\nif (FUN4(VAR2->VAR5) != 0 ||\nVAR2->VAR9 != VAR10 ||\nVAR2->VAR11 != 0 || VAR2->VAR12 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n} else {\nif (VAR2->VAR9 != VAR10 || VAR2->VAR11 != 0 ||\n(VAR2->VAR12 != 16 && VAR2->VAR12 != 32 && VAR2->VAR12 != 64) ||\nFUN6(VAR2->VAR5) == VAR14) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR16);\nif (VAR6)\nreturn VAR6;\nif (FUN8(VAR1, VAR2->VAR15)) {\nFUN5(VAR1, \"STR\",\nVAR2->VAR15);\nreturn -VAR17;\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR18);\nif (VAR6)\nreturn VAR6;\n} else if (VAR4 == VAR19) {\nif (FUN4(VAR2->VAR5) == VAR20) {\nif (VAR2->VAR12 != 0 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\nVAR6 = FUN7(VAR1, VAR2->VAR9, VAR16);\nif (VAR6)\nreturn VAR6;\n} else {\nif (VAR2->VAR9 != VAR10 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR18);\nif (VAR6)\nreturn VAR6;\nif (FUN4(VAR2->VAR5) == VAR20) {\nif (FUN6(VAR2->VAR5) == VAR14) {\nVAR3[VAR2->VAR15] = VAR3[VAR2->VAR9];\nVAR3[VAR2->VAR15].VAR21 |= VAR22;\n} else {\nif (FUN8(VAR1, VAR2->VAR9)) {\nFUN5(VAR1,\n\"STR\",\nVAR2->VAR9);\nreturn -VAR17;\n}\nFUN9(VAR1, VAR3, VAR2->VAR15);\nFUN10(&VAR3[VAR2->VAR15], 4);\n}\n} else {\nVAR3[VAR2->VAR15].VAR23 = VAR24;\nif (FUN6(VAR2->VAR5) == VAR14) {\nFUN11(VAR3 + VAR2->VAR15,\nVAR2->VAR12);\n} else {\nFUN11(VAR3 + VAR2->VAR15,\n(VAR25)VAR2->VAR12);\n}\n}\n} else if (VAR4 > VAR7) {\nFUN5(VAR1, \"STR\", VAR4);\nreturn -VAR13;\n} else {\t\nif (FUN4(VAR2->VAR5) == VAR20) {\nif (VAR2->VAR12 != 0 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\nVAR6 = FUN7(VAR1, VAR2->VAR9, VAR16);\nif (VAR6)\nreturn VAR6;\n} else {\nif (VAR2->VAR9 != VAR10 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR16);\nif (VAR6)\nreturn VAR6;\nif ((VAR4 == VAR26 || VAR4 == VAR27) &&\nFUN4(VAR2->VAR5) == VAR28 && VAR2->VAR12 == 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\nif ((VAR4 == VAR29 || VAR4 == VAR30 ||\nVAR4 == VAR31) && FUN4(VAR2->VAR5) == VAR28) {\nint VAR32 = FUN6(VAR2->VAR5) == VAR14 ? 64 : 32;\nif (VAR2->VAR12 < 0 || VAR2->VAR12 >= VAR32) {\nFUN5(VAR1, \"STR\", VAR2->VAR12);\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR33);\nif (VAR6)\nreturn VAR6;\nreturn FUN12(VAR1, VAR2);\n}\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1, struct bpf_insn *VAR2)\n{\nstruct bpf_reg_state *VAR3 = FUN2(VAR1);\nu8 VAR4 = FUN3(VAR2->VAR5);\nint VAR6;\nif (VAR4 == VAR7 || VAR4 == VAR8) {\nif (VAR4 == VAR8) {\nif (FUN4(VAR2->VAR5) != 0 ||\nVAR2->VAR9 != VAR10 ||\nVAR2->VAR11 != 0 || VAR2->VAR12 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n} else {\nif (VAR2->VAR9 != VAR10 || VAR2->VAR11 != 0 ||\n(VAR2->VAR12 != 16 && VAR2->VAR12 != 32 && VAR2->VAR12 != 64) ||\nFUN6(VAR2->VAR5) == VAR14) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR16);\nif (VAR6)\nreturn VAR6;\nif (FUN8(VAR1, VAR2->VAR15)) {\nFUN5(VAR1, \"STR\",\nVAR2->VAR15);\nreturn -VAR17;\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR18);\nif (VAR6)\nreturn VAR6;\n} else if (VAR4 == VAR19) {\nif (FUN4(VAR2->VAR5) == VAR20) {\nif (VAR2->VAR12 != 0 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\nVAR6 = FUN7(VAR1, VAR2->VAR9, VAR16);\nif (VAR6)\nreturn VAR6;\n} else {\nif (VAR2->VAR9 != VAR10 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR18);\nif (VAR6)\nreturn VAR6;\nif (FUN4(VAR2->VAR5) == VAR20) {\nif (FUN6(VAR2->VAR5) == VAR14) {\nVAR3[VAR2->VAR15] = VAR3[VAR2->VAR9];\nVAR3[VAR2->VAR15].VAR21 |= VAR22;\n} else {\nif (FUN8(VAR1, VAR2->VAR9)) {\nFUN5(VAR1,\n\"STR\",\nVAR2->VAR9);\nreturn -VAR17;\n}\nFUN9(VAR1, VAR3, VAR2->VAR15);\nVAR3[VAR2->VAR15].VAR23 = FUN10(\nVAR3[VAR2->VAR15].VAR23, 4);\nFUN11(&VAR3[VAR2->VAR15]);\n}\n} else {\nVAR3[VAR2->VAR15].VAR24 = VAR25;\nif (FUN6(VAR2->VAR5) == VAR14) {\nFUN12(VAR3 + VAR2->VAR15,\nVAR2->VAR12);\n} else {\nFUN12(VAR3 + VAR2->VAR15,\n(VAR26)VAR2->VAR12);\n}\n}\n} else if (VAR4 > VAR7) {\nFUN5(VAR1, \"STR\", VAR4);\nreturn -VAR13;\n} else {\t\nif (FUN4(VAR2->VAR5) == VAR20) {\nif (VAR2->VAR12 != 0 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\nVAR6 = FUN7(VAR1, VAR2->VAR9, VAR16);\nif (VAR6)\nreturn VAR6;\n} else {\nif (VAR2->VAR9 != VAR10 || VAR2->VAR11 != 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR16);\nif (VAR6)\nreturn VAR6;\nif ((VAR4 == VAR27 || VAR4 == VAR28) &&\nFUN4(VAR2->VAR5) == VAR29 && VAR2->VAR12 == 0) {\nFUN5(VAR1, \"STR\");\nreturn -VAR13;\n}\nif ((VAR4 == VAR30 || VAR4 == VAR31 ||\nVAR4 == VAR32) && FUN4(VAR2->VAR5) == VAR29) {\nint VAR33 = FUN6(VAR2->VAR5) == VAR14 ? 64 : 32;\nif (VAR2->VAR12 < 0 || VAR2->VAR12 >= VAR33) {\nFUN5(VAR1, \"STR\", VAR2->VAR12);\nreturn -VAR13;\n}\n}\nVAR6 = FUN7(VAR1, VAR2->VAR15, VAR34);\nif (VAR6)\nreturn VAR6;\nreturn FUN13(VAR1, VAR2);\n}\nreturn 0;\n}\n",
      "code_after_change_raw": "static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\nstruct bpf_reg_state *regs = cur_regs(env);\nu8 opcode = BPF_OP(insn->code);\nint err;\nif (opcode == BPF_END || opcode == BPF_NEG) {\nif (opcode == BPF_NEG) {\nif (BPF_SRC(insn->code) != 0 ||\ninsn->src_reg != BPF_REG_0 ||\ninsn->off != 0 || insn->imm != 0) {\nverbose(env, \"BPF_NEG uses reserved fields\\n\");\nreturn -EINVAL;\n}\n} else {\nif (insn->src_reg != BPF_REG_0 || insn->off != 0 ||\n(insn->imm != 16 && insn->imm != 32 && insn->imm != 64) ||\nBPF_CLASS(insn->code) == BPF_ALU64) {\nverbose(env, \"BPF_END uses reserved fields\\n\");\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, SRC_OP);\nif (err)\nreturn err;\nif (is_pointer_value(env, insn->dst_reg)) {\nverbose(env, \"R%d pointer arithmetic prohibited\\n\",\ninsn->dst_reg);\nreturn -EACCES;\n}\nerr = check_reg_arg(env, insn->dst_reg, DST_OP);\nif (err)\nreturn err;\n} else if (opcode == BPF_MOV) {\nif (BPF_SRC(insn->code) == BPF_X) {\nif (insn->imm != 0 || insn->off != 0) {\nverbose(env, \"BPF_MOV uses reserved fields\\n\");\nreturn -EINVAL;\n}\nerr = check_reg_arg(env, insn->src_reg, SRC_OP);\nif (err)\nreturn err;\n} else {\nif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\nverbose(env, \"BPF_MOV uses reserved fields\\n\");\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, DST_OP);\nif (err)\nreturn err;\nif (BPF_SRC(insn->code) == BPF_X) {\nif (BPF_CLASS(insn->code) == BPF_ALU64) {\nregs[insn->dst_reg] = regs[insn->src_reg];\nregs[insn->dst_reg].live |= REG_LIVE_WRITTEN;\n} else {\nif (is_pointer_value(env, insn->src_reg)) {\nverbose(env,\n\"R%d partial copy of pointer\\n\",\ninsn->src_reg);\nreturn -EACCES;\n}\nmark_reg_unknown(env, regs, insn->dst_reg);\ncoerce_reg_to_size(&regs[insn->dst_reg], 4);\n}\n} else {\nregs[insn->dst_reg].type = SCALAR_VALUE;\nif (BPF_CLASS(insn->code) == BPF_ALU64) {\n__mark_reg_known(regs + insn->dst_reg,\ninsn->imm);\n} else {\n__mark_reg_known(regs + insn->dst_reg,\n(u32)insn->imm);\n}\n}\n} else if (opcode > BPF_END) {\nverbose(env, \"invalid BPF_ALU opcode %x\\n\", opcode);\nreturn -EINVAL;\n} else {\t\nif (BPF_SRC(insn->code) == BPF_X) {\nif (insn->imm != 0 || insn->off != 0) {\nverbose(env, \"BPF_ALU uses reserved fields\\n\");\nreturn -EINVAL;\n}\nerr = check_reg_arg(env, insn->src_reg, SRC_OP);\nif (err)\nreturn err;\n} else {\nif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\nverbose(env, \"BPF_ALU uses reserved fields\\n\");\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, SRC_OP);\nif (err)\nreturn err;\nif ((opcode == BPF_MOD || opcode == BPF_DIV) &&\nBPF_SRC(insn->code) == BPF_K && insn->imm == 0) {\nverbose(env, \"div by zero\\n\");\nreturn -EINVAL;\n}\nif ((opcode == BPF_LSH || opcode == BPF_RSH ||\nopcode == BPF_ARSH) && BPF_SRC(insn->code) == BPF_K) {\nint size = BPF_CLASS(insn->code) == BPF_ALU64 ? 64 : 32;\nif (insn->imm < 0 || insn->imm >= size) {\nverbose(env, \"invalid shift %d\\n\", insn->imm);\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\nif (err)\nreturn err;\nreturn adjust_reg_min_max_vals(env, insn);\n}\nreturn 0;\n}\n",
      "code_before_change_raw": "static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\nstruct bpf_reg_state *regs = cur_regs(env);\nu8 opcode = BPF_OP(insn->code);\nint err;\nif (opcode == BPF_END || opcode == BPF_NEG) {\nif (opcode == BPF_NEG) {\nif (BPF_SRC(insn->code) != 0 ||\ninsn->src_reg != BPF_REG_0 ||\ninsn->off != 0 || insn->imm != 0) {\nverbose(env, \"BPF_NEG uses reserved fields\\n\");\nreturn -EINVAL;\n}\n} else {\nif (insn->src_reg != BPF_REG_0 || insn->off != 0 ||\n(insn->imm != 16 && insn->imm != 32 && insn->imm != 64) ||\nBPF_CLASS(insn->code) == BPF_ALU64) {\nverbose(env, \"BPF_END uses reserved fields\\n\");\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, SRC_OP);\nif (err)\nreturn err;\nif (is_pointer_value(env, insn->dst_reg)) {\nverbose(env, \"R%d pointer arithmetic prohibited\\n\",\ninsn->dst_reg);\nreturn -EACCES;\n}\nerr = check_reg_arg(env, insn->dst_reg, DST_OP);\nif (err)\nreturn err;\n} else if (opcode == BPF_MOV) {\nif (BPF_SRC(insn->code) == BPF_X) {\nif (insn->imm != 0 || insn->off != 0) {\nverbose(env, \"BPF_MOV uses reserved fields\\n\");\nreturn -EINVAL;\n}\nerr = check_reg_arg(env, insn->src_reg, SRC_OP);\nif (err)\nreturn err;\n} else {\nif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\nverbose(env, \"BPF_MOV uses reserved fields\\n\");\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, DST_OP);\nif (err)\nreturn err;\nif (BPF_SRC(insn->code) == BPF_X) {\nif (BPF_CLASS(insn->code) == BPF_ALU64) {\nregs[insn->dst_reg] = regs[insn->src_reg];\nregs[insn->dst_reg].live |= REG_LIVE_WRITTEN;\n} else {\nif (is_pointer_value(env, insn->src_reg)) {\nverbose(env,\n\"R%d partial copy of pointer\\n\",\ninsn->src_reg);\nreturn -EACCES;\n}\nmark_reg_unknown(env, regs, insn->dst_reg);\nregs[insn->dst_reg].var_off = tnum_cast(\nregs[insn->dst_reg].var_off, 4);\n__update_reg_bounds(&regs[insn->dst_reg]);\n}\n} else {\nregs[insn->dst_reg].type = SCALAR_VALUE;\nif (BPF_CLASS(insn->code) == BPF_ALU64) {\n__mark_reg_known(regs + insn->dst_reg,\ninsn->imm);\n} else {\n__mark_reg_known(regs + insn->dst_reg,\n(u32)insn->imm);\n}\n}\n} else if (opcode > BPF_END) {\nverbose(env, \"invalid BPF_ALU opcode %x\\n\", opcode);\nreturn -EINVAL;\n} else {\t\nif (BPF_SRC(insn->code) == BPF_X) {\nif (insn->imm != 0 || insn->off != 0) {\nverbose(env, \"BPF_ALU uses reserved fields\\n\");\nreturn -EINVAL;\n}\nerr = check_reg_arg(env, insn->src_reg, SRC_OP);\nif (err)\nreturn err;\n} else {\nif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\nverbose(env, \"BPF_ALU uses reserved fields\\n\");\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, SRC_OP);\nif (err)\nreturn err;\nif ((opcode == BPF_MOD || opcode == BPF_DIV) &&\nBPF_SRC(insn->code) == BPF_K && insn->imm == 0) {\nverbose(env, \"div by zero\\n\");\nreturn -EINVAL;\n}\nif ((opcode == BPF_LSH || opcode == BPF_RSH ||\nopcode == BPF_ARSH) && BPF_SRC(insn->code) == BPF_K) {\nint size = BPF_CLASS(insn->code) == BPF_ALU64 ? 64 : 32;\nif (insn->imm < 0 || insn->imm >= size) {\nverbose(env, \"invalid shift %d\\n\", insn->imm);\nreturn -EINVAL;\n}\n}\nerr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\nif (err)\nreturn err;\nreturn adjust_reg_min_max_vals(env, insn);\n}\nreturn 0;\n}\n"
    }
  ],
  "CVE-2017-17856": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of stack-pointer alignment enforcement in the code.",
        "trigger_condition": "Local users exploit the lack of stack-pointer alignment enforcement to cause memory corruption or other unspecified impacts.",
        "specific_code_behavior_causing_vulnerability": "The code does not enforce stack-pointer alignment for certain pointer types, leading to a vulnerability where local users can exploit this lack of alignment enforcement to cause memory corruption or other impacts.",
        "specific_solution": "To mitigate the vulnerability, it is necessary to enforce strict alignment for stack pointers in the code. By ensuring that stack accesses are properly aligned, the code prevents potential memory corruption and other issues that could arise from unaligned stack accesses. The solution involves adding a case for stack pointers in the switch statement and setting the 'strict' flag to true to enforce alignment for stack accesses."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-17856, which allows local users to cause a denial of service (memory corruption) or possibly have other unspecified impacts due to the lack of stack-pointer alignment enforcement.\n\nBy adding the following lines to the code snippet:\n```c\ncase PTR_TO_STACK:\n    pointer_desc = \"stack \";\n    /* The stack spill tracking logic in check_stack_write()\n     * and check_stack_read() relies on stack accesses being\n     * aligned.\n     */\n    strict = true;\n    break;\n```\nWe enforce strict alignment for stack pointers, ensuring that stack accesses are properly aligned. This modification helps prevent memory corruption and other potential issues that could arise from unaligned stack accesses.",
      "GPT_purpose": "Check pointer alignment for different types of pointers in the BPF verifier environment.",
      "GPT_function": "\n1. Check pointer alignment based on the type of pointer.\n2. Handle special cases for packet pointers.\n3. Determine the type of pointer and set the pointer description accordingly.\n4. Return the result of checking pointer alignment based on the pointer type.",
      "CVE_id": "CVE-2017-17856",
      "code_before_change": "static int check_ptr_alignment(struct bpf_verifier_env *env,\n\t\t\t       const struct bpf_reg_state *reg,\n\t\t\t       int off, int size)\n{\n\tbool strict = env->strict_alignment;\n\tconst char *pointer_desc = \"\";\n\n\tswitch (reg->type) {\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\t\t/* Special case, because of NET_IP_ALIGN. Given metadata sits\n\t\t * right in front, treat it the very same way.\n\t\t */\n\t\treturn check_pkt_ptr_alignment(env, reg, off, size, strict);\n\tcase PTR_TO_MAP_VALUE:\n\t\tpointer_desc = \"value \";\n\t\tbreak;\n\tcase PTR_TO_CTX:\n\t\tpointer_desc = \"context \";\n\t\tbreak;\n\tcase PTR_TO_STACK:\n\t\tpointer_desc = \"stack \";\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn check_generic_ptr_alignment(env, reg, pointer_desc, off, size,\n\t\t\t\t\t   strict);\n}",
      "code_after_change": "static int check_ptr_alignment(struct bpf_verifier_env *env,\n\t\t\t       const struct bpf_reg_state *reg,\n\t\t\t       int off, int size)\n{\n\tbool strict = env->strict_alignment;\n\tconst char *pointer_desc = \"\";\n\n\tswitch (reg->type) {\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\t\t/* Special case, because of NET_IP_ALIGN. Given metadata sits\n\t\t * right in front, treat it the very same way.\n\t\t */\n\t\treturn check_pkt_ptr_alignment(env, reg, off, size, strict);\n\tcase PTR_TO_MAP_VALUE:\n\t\tpointer_desc = \"value \";\n\t\tbreak;\n\tcase PTR_TO_CTX:\n\t\tpointer_desc = \"context \";\n\t\tbreak;\n\tcase PTR_TO_STACK:\n\t\tpointer_desc = \"stack \";\n\t\t/* The stack spill tracking logic in check_stack_write()\n\t\t * and check_stack_read() relies on stack accesses being\n\t\t * aligned.\n\t\t */\n\t\tstrict = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn check_generic_ptr_alignment(env, reg, pointer_desc, off, size,\n\t\t\t\t\t   strict);\n}",
      "modified_lines": {
        "added": [
          "\t\t/* The stack spill tracking logic in check_stack_write()",
          "\t\t * and check_stack_read() relies on stack accesses being",
          "\t\t * aligned.",
          "\t\t */",
          "\t\tstrict = true;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of stack-pointer alignment enforcement in the code.",
      "trigger_condition": "Local users exploit the lack of stack-pointer alignment enforcement to cause memory corruption or other unspecified impacts.",
      "specific_code_behavior_causing_vulnerability": "The code does not enforce stack-pointer alignment for certain pointer types, leading to a vulnerability where local users can exploit this lack of alignment enforcement to cause memory corruption or other impacts.",
      "id": 109,
      "code_after_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1,\nconst struct bpf_reg_state *VAR2,\nint VAR3, int VAR4)\n{\nbool VAR5 = VAR1->VAR6;\nconst char *VAR7 = \"STR\";\nswitch (VAR2->VAR8) {\ncase VAR9:\ncase VAR10:\nreturn FUN2(VAR1, VAR2, VAR3, VAR4, VAR5);\ncase VAR11:\nVAR7 = \"STR\";\nbreak;\ncase VAR12:\nVAR7 = \"STR\";\nbreak;\ncase VAR13:\nVAR7 = \"STR\";\nVAR5 = true;\nbreak;\ndefault:\nbreak;\n}\nreturn FUN3(VAR1, VAR2, VAR7, VAR3, VAR4,\nVAR5);\n}\n",
      "code_before_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1,\nconst struct bpf_reg_state *VAR2,\nint VAR3, int VAR4)\n{\nbool VAR5 = VAR1->VAR6;\nconst char *VAR7 = \"STR\";\nswitch (VAR2->VAR8) {\ncase VAR9:\ncase VAR10:\nreturn FUN2(VAR1, VAR2, VAR3, VAR4, VAR5);\ncase VAR11:\nVAR7 = \"STR\";\nbreak;\ncase VAR12:\nVAR7 = \"STR\";\nbreak;\ncase VAR13:\nVAR7 = \"STR\";\nbreak;\ndefault:\nbreak;\n}\nreturn FUN3(VAR1, VAR2, VAR7, VAR3, VAR4,\nVAR5);\n}\n",
      "code_after_change_raw": "static int check_ptr_alignment(struct bpf_verifier_env *env,\nconst struct bpf_reg_state *reg,\nint off, int size)\n{\nbool strict = env->strict_alignment;\nconst char *pointer_desc = \"\";\nswitch (reg->type) {\ncase PTR_TO_PACKET:\ncase PTR_TO_PACKET_META:\nreturn check_pkt_ptr_alignment(env, reg, off, size, strict);\ncase PTR_TO_MAP_VALUE:\npointer_desc = \"value \";\nbreak;\ncase PTR_TO_CTX:\npointer_desc = \"context \";\nbreak;\ncase PTR_TO_STACK:\npointer_desc = \"stack \";\nstrict = true;\nbreak;\ndefault:\nbreak;\n}\nreturn check_generic_ptr_alignment(env, reg, pointer_desc, off, size,\nstrict);\n}\n",
      "code_before_change_raw": "static int check_ptr_alignment(struct bpf_verifier_env *env,\nconst struct bpf_reg_state *reg,\nint off, int size)\n{\nbool strict = env->strict_alignment;\nconst char *pointer_desc = \"\";\nswitch (reg->type) {\ncase PTR_TO_PACKET:\ncase PTR_TO_PACKET_META:\nreturn check_pkt_ptr_alignment(env, reg, off, size, strict);\ncase PTR_TO_MAP_VALUE:\npointer_desc = \"value \";\nbreak;\ncase PTR_TO_CTX:\npointer_desc = \"context \";\nbreak;\ncase PTR_TO_STACK:\npointer_desc = \"stack \";\nbreak;\ndefault:\nbreak;\n}\nreturn check_generic_ptr_alignment(env, reg, pointer_desc, off, size,\nstrict);\n}\n"
    }
  ],
  "CVE-2017-18193": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper synchronization in handling extent trees in a multi-threaded environment.",
        "trigger_condition": "Multiple threads concurrently access and modify the extent tree data structures without adequate protection, leading to a denial of service bug.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly handle concurrent access to the extent tree data structures, allowing multiple threads to manipulate the tree simultaneously without proper synchronization. This can result in a denial of service bug due to race conditions and inconsistent tree state.",
        "solution": "To mitigate the vulnerability, it is necessary to ensure proper synchronization mechanisms are in place to protect the extent tree data structures from concurrent access. This involves introducing synchronization primitives such as locks to control access to the extent tree and prevent race conditions. Additionally, modifying the code to handle extent tree initialization and manipulation in a thread-safe manner is crucial to prevent the denial of service bug. The solution provided involves introducing a new function to handle extent tree initialization and setting an inode flag to indicate the tree's status."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-18193 by ensuring that the extent tree initialization is handled correctly and consistently. By introducing the `__f2fs_init_extent_tree` function and checking the return value to set the appropriate inode flag, the code is made more robust and less prone to the denial of service issue caused by mishandling extent trees in a multi-threaded environment.\n\nAdditionally, setting the `FI_NO_EXTENT` flag when the extent tree is not initialized properly helps to prevent potential issues that may arise from accessing uninitialized or corrupted extent tree data structures. This modification improves the overall reliability and security of the code.",
      "GPT_purpose": "Initialize and manage an extent tree for a given inode in the F2FS filesystem.",
      "GPT_function": "\n1. Initialize the extent tree for a given inode.\n2. Check if the inode may have an extent tree.\n3. Handle dropping the largest extent if it exists.\n4. Grab the extent tree for the inode.\n5. Check if the given extent information is valid.\n6. Get extent information from the provided extent.\n7. Write lock the extent tree.\n8. Check if there are existing nodes in the extent tree.\n9. Initialize a new extent node with the provided extent information.\n10. Add the new extent node to the extent list.\n11. Unlock the extent tree.\n12. Return false.",
      "CVE_id": "CVE-2017-18193",
      "code_before_change": "bool f2fs_init_extent_tree(struct inode *inode, struct f2fs_extent *i_ext)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct extent_tree *et;\n\tstruct extent_node *en;\n\tstruct extent_info ei;\n\n\tif (!f2fs_may_extent_tree(inode)) {\n\t\t/* drop largest extent */\n\t\tif (i_ext && i_ext->len) {\n\t\t\ti_ext->len = 0;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\n\tet = __grab_extent_tree(inode);\n\n\tif (!i_ext || !i_ext->len)\n\t\treturn false;\n\n\tget_extent_info(&ei, i_ext);\n\n\twrite_lock(&et->lock);\n\tif (atomic_read(&et->node_cnt))\n\t\tgoto out;\n\n\ten = __init_extent_tree(sbi, et, &ei);\n\tif (en) {\n\t\tspin_lock(&sbi->extent_lock);\n\t\tlist_add_tail(&en->list, &sbi->extent_list);\n\t\tspin_unlock(&sbi->extent_lock);\n\t}\nout:\n\twrite_unlock(&et->lock);\n\treturn false;\n}",
      "code_after_change": "bool f2fs_init_extent_tree(struct inode *inode, struct f2fs_extent *i_ext)\n{\n\tbool ret =  __f2fs_init_extent_tree(inode, i_ext);\n\n\tif (!F2FS_I(inode)->extent_tree)\n\t\tset_inode_flag(inode, FI_NO_EXTENT);\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tbool ret =  __f2fs_init_extent_tree(inode, i_ext);",
          "\tif (!F2FS_I(inode)->extent_tree)",
          "\t\tset_inode_flag(inode, FI_NO_EXTENT);",
          "\treturn ret;"
        ],
        "deleted": [
          "\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);",
          "\tstruct extent_tree *et;",
          "\tstruct extent_node *en;",
          "\tstruct extent_info ei;",
          "\tif (!f2fs_may_extent_tree(inode)) {",
          "\t\t/* drop largest extent */",
          "\t\tif (i_ext && i_ext->len) {",
          "\t\t\ti_ext->len = 0;",
          "\t\t\treturn true;",
          "\t\t}",
          "\t\treturn false;",
          "\t}",
          "\tet = __grab_extent_tree(inode);",
          "",
          "\tif (!i_ext || !i_ext->len)",
          "\t\treturn false;",
          "",
          "\tget_extent_info(&ei, i_ext);",
          "",
          "\twrite_lock(&et->lock);",
          "\tif (atomic_read(&et->node_cnt))",
          "\t\tgoto out;",
          "",
          "\ten = __init_extent_tree(sbi, et, &ei);",
          "\tif (en) {",
          "\t\tspin_lock(&sbi->extent_lock);",
          "\t\tlist_add_tail(&en->list, &sbi->extent_list);",
          "\t\tspin_unlock(&sbi->extent_lock);",
          "\t}",
          "out:",
          "\twrite_unlock(&et->lock);",
          "\treturn false;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper synchronization in handling extent trees in a multi-threaded environment.",
      "trigger_condition": "Multiple threads concurrently access and modify the extent tree data structures without adequate protection, leading to a denial of service bug.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly handle concurrent access to the extent tree data structures, allowing multiple threads to manipulate the tree simultaneously without proper synchronization. This can result in a denial of service bug due to race conditions and inconsistent tree state.",
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper synchronization mechanisms are in place to protect the extent tree data structures from concurrent access. This involves introducing synchronization primitives such as locks to control access to the extent tree and prevent race conditions. Additionally, modifying the code to handle extent tree initialization and manipulation in a thread-safe manner is crucial to prevent the denial of service bug. The solution provided involves introducing a new function to handle extent tree initialization and setting an inode flag to indicate the tree's status.",
      "id": 110,
      "code_after_change_normalized": "bool FUN1(struct VAR1 *VAR1, struct f2fs_extent *VAR2)\n{\nbool VAR3 =  FUN2(VAR1, VAR2);\nif (!FUN3(VAR1)->VAR4)\nFUN4(VAR1, VAR5);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "bool FUN1(struct VAR1 *VAR1, struct f2fs_extent *VAR2)\n{\nstruct f2fs_sb_info *VAR3 = FUN2(VAR1);\nstruct extent_tree *VAR4;\nstruct extent_node *VAR5;\nstruct extent_info VAR6;\nif (!FUN3(VAR1)) {\nif (VAR2 && VAR2->VAR7) {\nVAR2->VAR7 = 0;\nreturn true;\n}\nreturn false;\n}\nVAR4 = FUN4(VAR1);\nif (!VAR2 || !VAR2->VAR7)\nreturn false;\nFUN5(&VAR6, VAR2);\nFUN6(&VAR4->VAR8);\nif (FUN7(&VAR4->VAR9))\ngoto VAR10;\nVAR5 = FUN8(VAR3, VAR4, &VAR6);\nif (VAR5) {\nFUN9(&VAR3->VAR11);\nFUN10(&VAR5->VAR12, &VAR3->VAR13);\nFUN11(&VAR3->VAR11);\n}\nVAR10:\nFUN12(&VAR4->VAR8);\nreturn false;\n}\n",
      "code_after_change_raw": "bool f2fs_init_extent_tree(struct inode *inode, struct f2fs_extent *i_ext)\n{\nbool ret =  __f2fs_init_extent_tree(inode, i_ext);\nif (!F2FS_I(inode)->extent_tree)\nset_inode_flag(inode, FI_NO_EXTENT);\nreturn ret;\n}\n",
      "code_before_change_raw": "bool f2fs_init_extent_tree(struct inode *inode, struct f2fs_extent *i_ext)\n{\nstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\nstruct extent_tree *et;\nstruct extent_node *en;\nstruct extent_info ei;\nif (!f2fs_may_extent_tree(inode)) {\nif (i_ext && i_ext->len) {\ni_ext->len = 0;\nreturn true;\n}\nreturn false;\n}\net = __grab_extent_tree(inode);\nif (!i_ext || !i_ext->len)\nreturn false;\nget_extent_info(&ei, i_ext);\nwrite_lock(&et->lock);\nif (atomic_read(&et->node_cnt))\ngoto out;\nen = __init_extent_tree(sbi, et, &ei);\nif (en) {\nspin_lock(&sbi->extent_lock);\nlist_add_tail(&en->list, &sbi->extent_list);\nspin_unlock(&sbi->extent_lock);\n}\nout:\nwrite_unlock(&et->lock);\nreturn false;\n}\n"
    }
  ],
  "CVE-2017-18222": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of consideration for a specific case when retrieving sset_count data in the network subsystem.",
        "trigger_condition": "The network subsystem does not properly handle the case when a specific type of data set count is requested, leading to incompatibility issues and potential vulnerabilities.",
        "specific_code_behavior_causing_vulnerability": "The code only considers one specific type of data set count and returns 0 for any other value, which can result in denial of service, buffer overflow, memory corruption, or other unspecified impacts when incompatible requests are made.",
        "specific_solution_to_fix_vulnerability": "To mitigate the vulnerability, it is necessary to update the code to handle the specific case when a different type of data set count is requested. By adding a condition to check for the additional type and returning the correct count of elements in the array, the code can prevent incompatibility issues and potential vulnerabilities. In this case, the solution involves modifying the code to include the condition 'stringset == ETH_SS_PRIV_FLAGS' in the function to properly handle the requested data set count."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability described in CVE-2017-18222. By adding the condition `stringset == ETH_SS_PRIV_FLAGS` in the `hns_gmac_get_sset_count` function, the code now properly handles the case when `ETH_SS_PRIV_FLAGS` is passed as the `stringset` parameter. This ensures that the function correctly returns the count of elements in the `g_gmac_stats_string` array when either `ETH_SS_STATS` or `ETH_SS_PRIV_FLAGS` is requested.\n\nWithout this modification, the function only considers the `ETH_SS_STATS` case and returns 0 for any other value of `stringset`, which can lead to incompatibility issues between `hns_get_sset_count` and `ethtool_get_strings`. This vulnerability could potentially be exploited by local users to cause a denial of service, buffer overflow, memory corruption, or other unspecified impacts.",
      "GPT_purpose": "Retrieve the count of supported string sets for the Hisilicon Network Subsystem (HNS) based on the input string set type.",
      "GPT_function": "\n1. Check if the stringset is ETH_SS_STATS.\n2. Return the size of the g_gmac_stats_string array if the stringset is ETH_SS_STATS.\n3. Return 0 if the stringset is not ETH_SS_STATS.",
      "CVE_id": "CVE-2017-18222",
      "code_before_change": "static int hns_gmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn ARRAY_SIZE(g_gmac_stats_string);\n\n\treturn 0;\n}",
      "code_after_change": "static int hns_gmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n\t\treturn ARRAY_SIZE(g_gmac_stats_string);\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)"
        ],
        "deleted": [
          "\tif (stringset == ETH_SS_STATS)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of consideration for a specific case when retrieving sset_count data in the network subsystem.",
      "trigger_condition": "The network subsystem does not properly handle the case when a specific type of data set count is requested, leading to incompatibility issues and potential vulnerabilities.",
      "specific_code_behavior_causing_vulnerability": "The code only considers one specific type of data set count and returns 0 for any other value, which can result in denial of service, buffer overflow, memory corruption, or other unspecified impacts when incompatible requests are made.",
      "id": 111,
      "code_after_change_normalized": "static int FUN1(int VAR1)\n{\nif (VAR1 == VAR2 || VAR1 == VAR3)\nreturn FUN2(VAR4);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(int VAR1)\n{\nif (VAR1 == VAR2)\nreturn FUN2(VAR3);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int hns_gmac_get_sset_count(int stringset)\n{\nif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\nreturn ARRAY_SIZE(g_gmac_stats_string);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int hns_gmac_get_sset_count(int stringset)\n{\nif (stringset == ETH_SS_STATS)\nreturn ARRAY_SIZE(g_gmac_stats_string);\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of consideration for a specific case when retrieving sset_count data in the network subsystem.",
        "trigger_condition": "The code does not handle the ETH_SS_PRIV_FLAGS case when retrieving sset_count data, leading to a vulnerability that can be exploited by local users.",
        "specific_code_behavior_causing_vulnerability": "The code in the network subsystem function does not include the necessary condition to handle the ETH_SS_PRIV_FLAGS case, which can result in a denial of service, buffer overflow, memory corruption, or other unspecified impacts."
      },
      "solution": "To mitigate the vulnerability, it is essential to add the condition to handle the ETH_SS_PRIV_FLAGS case when retrieving sset_count data. This ensures that the function correctly considers all possible cases, preventing the vulnerability from being exploited. In this case, the solution involves modifying the code to include the missing condition for ETH_SS_PRIV_FLAGS in the if statement.",
      "GPT_analysis": "The modification is necessary to address the vulnerability described in CVE-2017-18222. By adding the condition `stringset == ETH_SS_PRIV_FLAGS` in the if statement, the code now properly handles the case when `stringset` is `ETH_SS_PRIV_FLAGS`. This ensures that the function `hns_rcb_get_ring_sset_count` correctly considers all possible cases when retrieving sset_count data, preventing the vulnerability that could lead to a denial of service, buffer overflow, memory corruption, or other unspecified impacts.",
      "GPT_purpose": "Return the number of static registers in a Hisilicon Network Subsystem (HNS) ring based on the provided stringset.",
      "GPT_function": "\n1. Check if the input stringset is ETH_SS_STATS.\n2. Return HNS_RING_STATIC_REG_NUM if the input stringset is ETH_SS_STATS.\n3. Return 0 if the input stringset is not ETH_SS_STATS.",
      "CVE_id": "CVE-2017-18222",
      "code_before_change": "int hns_rcb_get_ring_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn HNS_RING_STATIC_REG_NUM;\n\n\treturn 0;\n}",
      "code_after_change": "int hns_rcb_get_ring_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n\t\treturn HNS_RING_STATIC_REG_NUM;\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)"
        ],
        "deleted": [
          "\tif (stringset == ETH_SS_STATS)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of consideration for a specific case when retrieving sset_count data in the network subsystem.",
      "trigger_condition": "The code does not handle the ETH_SS_PRIV_FLAGS case when retrieving sset_count data, leading to a vulnerability that can be exploited by local users.",
      "specific_code_behavior_causing_vulnerability": "The code in the network subsystem function does not include the necessary condition to handle the ETH_SS_PRIV_FLAGS case, which can result in a denial of service, buffer overflow, memory corruption, or other unspecified impacts.",
      "id": 112,
      "code_after_change_normalized": "int FUN1(int VAR1)\n{\nif (VAR1 == VAR2 || VAR1 == VAR3)\nreturn VAR4;\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(int VAR1)\n{\nif (VAR1 == VAR2)\nreturn VAR3;\nreturn 0;\n}\n",
      "code_after_change_raw": "int hns_rcb_get_ring_sset_count(int stringset)\n{\nif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\nreturn HNS_RING_STATIC_REG_NUM;\nreturn 0;\n}\n",
      "code_before_change_raw": "int hns_rcb_get_ring_sset_count(int stringset)\n{\nif (stringset == ETH_SS_STATS)\nreturn HNS_RING_STATIC_REG_NUM;\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of consideration for the ETH_SS_PRIV_FLAGS case when retrieving sset_count data in the Hisilicon Network Subsystem (HNS).",
        "trigger_condition": "Requesting sset_count data with the ETH_SS_PRIV_FLAGS string set, which is not properly handled in the code.",
        "specific_code_behavior_causing_vulnerability": "The code in the hns_xgmac_get_sset_count function does not include a check for the ETH_SS_PRIV_FLAGS case, leading to incompatibility between hns_get_sset_count and ethtool_get_strings. This can result in a denial of service (buffer overflow and memory corruption) or other unspecified impacts.",
        "solution": "To mitigate the vulnerability, it is necessary to add a condition in the hns_xgmac_get_sset_count function to handle the ETH_SS_PRIV_FLAGS case when retrieving sset_count data. By including the condition 'stringset == ETH_SS_PRIV_FLAGS', the code now properly considers this case and prevents the denial of service and memory corruption issues. This modification ensures that the function behaves correctly and securely when dealing with different string sets."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-18222 by ensuring that the Hisilicon Network Subsystem (HNS) considers the ETH_SS_PRIV_FLAGS case when retrieving sset_count data. By adding the condition `stringset == ETH_SS_PRIV_FLAGS` in the `hns_xgmac_get_sset_count` function, the code now properly handles the case where `ETH_SS_PRIV_FLAGS` is requested, preventing a denial of service (buffer overflow and memory corruption) or any other unspecified impact that could occur due to the incompatibility between `hns_get_sset_count` and `ethtool_get_strings`. This modification ensures that the function behaves correctly and securely when dealing with different string sets, thereby mitigating the vulnerability.",
      "GPT_purpose": "Retrieve the count of string sets for a specific type in the Hisilicon Network Subsystem (HNS) XGMAC driver.",
      "GPT_function": "\n1. Checks if the input stringset is ETH_SS_STATS.\n2. Returns the size of the g_xgmac_stats_string array if the input is ETH_SS_STATS.\n3. Otherwise, returns 0.",
      "CVE_id": "CVE-2017-18222",
      "code_before_change": "static int hns_xgmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn ARRAY_SIZE(g_xgmac_stats_string);\n\n\treturn 0;\n}",
      "code_after_change": "static int hns_xgmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n\t\treturn ARRAY_SIZE(g_xgmac_stats_string);\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)"
        ],
        "deleted": [
          "\tif (stringset == ETH_SS_STATS)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of consideration for the ETH_SS_PRIV_FLAGS case when retrieving sset_count data in the Hisilicon Network Subsystem (HNS).",
      "trigger_condition": "Requesting sset_count data with the ETH_SS_PRIV_FLAGS string set, which is not properly handled in the code.",
      "specific_code_behavior_causing_vulnerability": "The code in the hns_xgmac_get_sset_count function does not include a check for the ETH_SS_PRIV_FLAGS case, leading to incompatibility between hns_get_sset_count and ethtool_get_strings. This can result in a denial of service (buffer overflow and memory corruption) or other unspecified impacts.",
      "solution": "To mitigate the vulnerability, it is necessary to add a condition in the hns_xgmac_get_sset_count function to handle the ETH_SS_PRIV_FLAGS case when retrieving sset_count data. By including the condition 'stringset == ETH_SS_PRIV_FLAGS', the code now properly considers this case and prevents the denial of service and memory corruption issues. This modification ensures that the function behaves correctly and securely when dealing with different string sets.",
      "id": 113,
      "code_after_change_normalized": "static int FUN1(int VAR1)\n{\nif (VAR1 == VAR2 || VAR1 == VAR3)\nreturn FUN2(VAR4);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(int VAR1)\n{\nif (VAR1 == VAR2)\nreturn FUN2(VAR3);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int hns_xgmac_get_sset_count(int stringset)\n{\nif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\nreturn ARRAY_SIZE(g_xgmac_stats_string);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int hns_xgmac_get_sset_count(int stringset)\n{\nif (stringset == ETH_SS_STATS)\nreturn ARRAY_SIZE(g_xgmac_stats_string);\nreturn 0;\n}\n"
    }
  ],
  "CVE-2017-18379": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of bounds checking for an index used to access an array, leading to a potential out-of-bounds memory access.",
        "trigger_condition": "The index value exceeds the maximum allowed index of the array, causing the code to access memory outside the bounds of the array.",
        "specific_code_behavior_causing_vulnerability": "The code uses an index variable without verifying that it is within the valid range of the array, which can result in accessing memory locations beyond the allocated array size."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a bounds check to ensure that the index used to access the array is within the valid range. By verifying the index before accessing the array, the code can prevent out-of-bounds memory access and enhance security. In this case, the solution involves checking if the index value exceeds the maximum allowed index and returning early with a NULL value to prevent accessing memory outside the array bounds.",
      "GPT_analysis": "The modification is necessary to prevent an out-of-bounds access vulnerability in the code. In the original code snippet, the variable `qid` is used to index into the `assoc->queues` array without any bounds checking. If the value of `qid` exceeds the maximum allowed index (NVMET_NR_QUEUES), it could lead to accessing memory outside the bounds of the array, resulting in undefined behavior and potential security risks.\n\nBy adding the check `if (qid > NVMET_NR_QUEUES) return NULL;`, the modified code ensures that the index `qid` is within the valid range of the `assoc->queues` array before attempting to access it. This helps prevent out-of-bounds memory access and improves the overall security and stability of the code.",
      "GPT_purpose": "Find a target queue associated with a given connection ID in the NVMe over Fabrics target driver.",
      "GPT_function": "\n1. `nvmet_fc_find_target_queue`: Finds a target queue associated with a given target port and connection ID.\n2. `nvmet_fc_getassociationid`: Retrieves the association ID from a given connection ID.\n3. `nvmet_fc_getqueueid`: Retrieves the queue ID from a given connection ID.",
      "CVE_id": "CVE-2017-18379",
      "code_before_change": "static struct nvmet_fc_tgt_queue *\nnvmet_fc_find_target_queue(struct nvmet_fc_tgtport *tgtport,\n\t\t\t\tu64 connection_id)\n{\n\tstruct nvmet_fc_tgt_assoc *assoc;\n\tstruct nvmet_fc_tgt_queue *queue;\n\tu64 association_id = nvmet_fc_getassociationid(connection_id);\n\tu16 qid = nvmet_fc_getqueueid(connection_id);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tgtport->lock, flags);\n\tlist_for_each_entry(assoc, &tgtport->assoc_list, a_list) {\n\t\tif (association_id == assoc->association_id) {\n\t\t\tqueue = assoc->queues[qid];\n\t\t\tif (queue &&\n\t\t\t    (!atomic_read(&queue->connected) ||\n\t\t\t     !nvmet_fc_tgt_q_get(queue)))\n\t\t\t\tqueue = NULL;\n\t\t\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\t\t\treturn queue;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\treturn NULL;\n}",
      "code_after_change": "static struct nvmet_fc_tgt_queue *\nnvmet_fc_find_target_queue(struct nvmet_fc_tgtport *tgtport,\n\t\t\t\tu64 connection_id)\n{\n\tstruct nvmet_fc_tgt_assoc *assoc;\n\tstruct nvmet_fc_tgt_queue *queue;\n\tu64 association_id = nvmet_fc_getassociationid(connection_id);\n\tu16 qid = nvmet_fc_getqueueid(connection_id);\n\tunsigned long flags;\n\n\tif (qid > NVMET_NR_QUEUES)\n\t\treturn NULL;\n\n\tspin_lock_irqsave(&tgtport->lock, flags);\n\tlist_for_each_entry(assoc, &tgtport->assoc_list, a_list) {\n\t\tif (association_id == assoc->association_id) {\n\t\t\tqueue = assoc->queues[qid];\n\t\t\tif (queue &&\n\t\t\t    (!atomic_read(&queue->connected) ||\n\t\t\t     !nvmet_fc_tgt_q_get(queue)))\n\t\t\t\tqueue = NULL;\n\t\t\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\t\t\treturn queue;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\treturn NULL;\n}",
      "modified_lines": {
        "added": [
          "",
          "\tif (qid > NVMET_NR_QUEUES)",
          "\t\treturn NULL;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of bounds checking for an index used to access an array, leading to a potential out-of-bounds memory access.",
      "trigger_condition": "The index value exceeds the maximum allowed index of the array, causing the code to access memory outside the bounds of the array.",
      "specific_code_behavior_causing_vulnerability": "The code uses an index variable without verifying that it is within the valid range of the array, which can result in accessing memory locations beyond the allocated array size.",
      "id": 114,
      "code_after_change_normalized": "static struct VAR1 *\nFUN1(struct nvmet_fc_tgtport *VAR2,\nu64 VAR3)\n{\nstruct nvmet_fc_tgt_assoc *VAR4;\nstruct nvmet_fc_tgt_queue *VAR5;\nu64 VAR6 = FUN2(VAR3);\nu16 VAR7 = FUN3(VAR3);\nunsigned long VAR8;\nif (VAR7 > VAR9)\nreturn NULL;\nFUN4(&VAR2->VAR10, VAR8);\nFUN5(VAR4, &VAR2->VAR11, VAR12) {\nif (VAR6 == VAR4->VAR6) {\nVAR5 = VAR4->VAR13[VAR7];\nif (VAR5 &&\n(!FUN6(&VAR5->VAR14) ||\n!FUN7(VAR5)))\nVAR5 = NULL;\nFUN8(&VAR2->VAR10, VAR8);\nreturn VAR5;\n}\n}\nFUN8(&VAR2->VAR10, VAR8);\nreturn NULL;\n}\n",
      "code_before_change_normalized": "static struct VAR1 *\nFUN1(struct nvmet_fc_tgtport *VAR2,\nu64 VAR3)\n{\nstruct nvmet_fc_tgt_assoc *VAR4;\nstruct nvmet_fc_tgt_queue *VAR5;\nu64 VAR6 = FUN2(VAR3);\nu16 VAR7 = FUN3(VAR3);\nunsigned long VAR8;\nFUN4(&VAR2->VAR9, VAR8);\nFUN5(VAR4, &VAR2->VAR10, VAR11) {\nif (VAR6 == VAR4->VAR6) {\nVAR5 = VAR4->VAR12[VAR7];\nif (VAR5 &&\n(!FUN6(&VAR5->VAR13) ||\n!FUN7(VAR5)))\nVAR5 = NULL;\nFUN8(&VAR2->VAR9, VAR8);\nreturn VAR5;\n}\n}\nFUN8(&VAR2->VAR9, VAR8);\nreturn NULL;\n}\n",
      "code_after_change_raw": "static struct nvmet_fc_tgt_queue *\nnvmet_fc_find_target_queue(struct nvmet_fc_tgtport *tgtport,\nu64 connection_id)\n{\nstruct nvmet_fc_tgt_assoc *assoc;\nstruct nvmet_fc_tgt_queue *queue;\nu64 association_id = nvmet_fc_getassociationid(connection_id);\nu16 qid = nvmet_fc_getqueueid(connection_id);\nunsigned long flags;\nif (qid > NVMET_NR_QUEUES)\nreturn NULL;\nspin_lock_irqsave(&tgtport->lock, flags);\nlist_for_each_entry(assoc, &tgtport->assoc_list, a_list) {\nif (association_id == assoc->association_id) {\nqueue = assoc->queues[qid];\nif (queue &&\n(!atomic_read(&queue->connected) ||\n!nvmet_fc_tgt_q_get(queue)))\nqueue = NULL;\nspin_unlock_irqrestore(&tgtport->lock, flags);\nreturn queue;\n}\n}\nspin_unlock_irqrestore(&tgtport->lock, flags);\nreturn NULL;\n}\n",
      "code_before_change_raw": "static struct nvmet_fc_tgt_queue *\nnvmet_fc_find_target_queue(struct nvmet_fc_tgtport *tgtport,\nu64 connection_id)\n{\nstruct nvmet_fc_tgt_assoc *assoc;\nstruct nvmet_fc_tgt_queue *queue;\nu64 association_id = nvmet_fc_getassociationid(connection_id);\nu16 qid = nvmet_fc_getqueueid(connection_id);\nunsigned long flags;\nspin_lock_irqsave(&tgtport->lock, flags);\nlist_for_each_entry(assoc, &tgtport->assoc_list, a_list) {\nif (association_id == assoc->association_id) {\nqueue = assoc->queues[qid];\nif (queue &&\n(!atomic_read(&queue->connected) ||\n!nvmet_fc_tgt_q_get(queue)))\nqueue = NULL;\nspin_unlock_irqrestore(&tgtport->lock, flags);\nreturn queue;\n}\n}\nspin_unlock_irqrestore(&tgtport->lock, flags);\nreturn NULL;\n}\n"
    }
  ],
  "CVE-2017-5547": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper memory management leading to potential memory corruption or denial of service.",
        "trigger_condition": "Interaction with a specific kernel configuration option that allows the use of more than one virtual page for a DMA scatterlist.",
        "specific_code_behavior_causing_vulnerability": "The code snippet uses a fixed-size array for data storage without proper memory allocation and deallocation mechanisms. This can lead to memory corruption or denial of service when interacting with the mentioned kernel configuration option.",
        "solution": "To mitigate the vulnerability, the code needs to dynamically allocate memory for data storage using kmalloc, check for successful memory allocation, free the allocated memory using kfree before returning from the function, and use a pointer to the allocated memory instead of a fixed-size array. These changes ensure proper memory management and prevent memory corruption or denial of service issues when interacting with the kernel configuration option."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2017-5547 related to the incorrect interaction with the CONFIG_VMAP_STACK option. The vulnerability allows local users to cause a denial of service or memory corruption by leveraging the use of more than one virtual page for a DMA scatterlist.\n\nThe key changes made in the modified code snippet are:\n1. Dynamically allocating memory for the 'data' buffer using kmalloc to ensure that the buffer is within the kernel space and prevent potential memory corruption issues.\n2. Checking if the memory allocation was successful and returning -ENOMEM if it fails to handle out-of-memory scenarios.\n3. Freeing the allocated memory using kfree before returning from the function to prevent memory leaks.\n4. Using 'data' as a pointer to the allocated memory instead of a fixed-size array to ensure that the buffer size can be adjusted as needed.\n\nBy making these modifications, the code snippet addresses the vulnerability by correctly managing memory allocation and deallocation, thereby mitigating the risk of memory corruption and potential denial of service issues.",
      "GPT_purpose": "Retrieve the macro mode of a Corsair K90 keyboard connected via USB.",
      "GPT_function": "\n1. Show the macro mode of a K90 device.\n2. Retrieve the macro mode from the USB device.\n3. Handle different macro modes (hardware or software) and return the corresponding mode.",
      "CVE_id": "CVE-2017-5547",
      "code_before_change": "static ssize_t k90_show_macro_mode(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tint ret;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tconst char *macro_mode;\n\tchar data[8];\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_GET_MODE,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 2,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial mode (error %d).\\n\",\n\t\t\t ret);\n\t\treturn -EIO;\n\t}\n\n\tswitch (data[0]) {\n\tcase K90_MACRO_MODE_HW:\n\t\tmacro_mode = \"HW\";\n\t\tbreak;\n\n\tcase K90_MACRO_MODE_SW:\n\t\tmacro_mode = \"SW\";\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(dev, \"K90 in unknown mode: %02hhx.\\n\",\n\t\t\t data[0]);\n\t\treturn -EIO;\n\t}\n\n\treturn snprintf(buf, PAGE_SIZE, \"%s\\n\", macro_mode);\n}",
      "code_after_change": "static ssize_t k90_show_macro_mode(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tint ret;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tconst char *macro_mode;\n\tchar *data;\n\n\tdata = kmalloc(2, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_GET_MODE,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 2,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial mode (error %d).\\n\",\n\t\t\t ret);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tswitch (data[0]) {\n\tcase K90_MACRO_MODE_HW:\n\t\tmacro_mode = \"HW\";\n\t\tbreak;\n\n\tcase K90_MACRO_MODE_SW:\n\t\tmacro_mode = \"SW\";\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(dev, \"K90 in unknown mode: %02hhx.\\n\",\n\t\t\t data[0]);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tret = snprintf(buf, PAGE_SIZE, \"%s\\n\", macro_mode);\nout:\n\tkfree(data);\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tchar *data;",
          "",
          "\tdata = kmalloc(2, GFP_KERNEL);",
          "\tif (!data)",
          "\t\treturn -ENOMEM;",
          "\t\tret = -EIO;",
          "\t\tgoto out;",
          "\t\tret = -EIO;",
          "\t\tgoto out;",
          "\tret = snprintf(buf, PAGE_SIZE, \"%s\\n\", macro_mode);",
          "out:",
          "\tkfree(data);",
          "",
          "\treturn ret;"
        ],
        "deleted": [
          "\tchar data[8];",
          "\t\treturn -EIO;",
          "\t\treturn -EIO;",
          "\treturn snprintf(buf, PAGE_SIZE, \"%s\\n\", macro_mode);"
        ]
      },
      "preconditions_for_vulnerability": "Improper memory management leading to potential memory corruption or denial of service.",
      "trigger_condition": "Interaction with a specific kernel configuration option that allows the use of more than one virtual page for a DMA scatterlist.",
      "specific_code_behavior_causing_vulnerability": "The code snippet uses a fixed-size array for data storage without proper memory allocation and deallocation mechanisms. This can lead to memory corruption or denial of service when interacting with the mentioned kernel configuration option.",
      "solution": "To mitigate the vulnerability, the code needs to dynamically allocate memory for data storage using kmalloc, check for successful memory allocation, free the allocated memory using kfree before returning from the function, and use a pointer to the allocated memory instead of a fixed-size array. These changes ensure proper memory management and prevent memory corruption or denial of service issues when interacting with the kernel configuration option.",
      "id": 115,
      "code_after_change_normalized": "static ssize_t FUN1(struct device *VAR1,\nstruct device_attribute *VAR2, char *VAR3)\n{\nint VAR4;\nstruct usb_interface *VAR5 = FUN2(VAR1->VAR6);\nstruct usb_device *VAR7 = FUN3(VAR5);\nconst char *VAR8;\nchar *VAR9;\nVAR9 = FUN4(2, VAR10);\nif (!VAR9)\nreturn -VAR11;\nVAR4 = FUN5(VAR7, FUN6(VAR7, 0),\nVAR12,\nVAR13 | VAR14 |\nVAR15, 0, 0, VAR9, 2,\nVAR16);\nif (VAR4 < 0) {\nFUN7(VAR1, \"STR\",\nVAR4);\nVAR4 = -VAR17;\ngoto VAR18;\n}\nswitch (VAR9[0]) {\ncase VAR19:\nVAR8 = \"STR\";\nbreak;\ncase VAR20:\nVAR8 = \"STR\";\nbreak;\ndefault:\nFUN7(VAR1, \"STR\",\nVAR9[0]);\nVAR4 = -VAR17;\ngoto VAR18;\n}\nVAR4 = FUN8(VAR3, VAR21, \"STR\", VAR8);\nVAR18:\nFUN9(VAR9);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct device *VAR1,\nstruct device_attribute *VAR2, char *VAR3)\n{\nint VAR4;\nstruct usb_interface *VAR5 = FUN2(VAR1->VAR6);\nstruct usb_device *VAR7 = FUN3(VAR5);\nconst char *VAR8;\nchar VAR9[8];\nVAR4 = FUN4(VAR7, FUN5(VAR7, 0),\nVAR10,\nVAR11 | VAR12 |\nVAR13, 0, 0, VAR9, 2,\nVAR14);\nif (VAR4 < 0) {\nFUN6(VAR1, \"STR\",\nVAR4);\nreturn -VAR15;\n}\nswitch (VAR9[0]) {\ncase VAR16:\nVAR8 = \"STR\";\nbreak;\ncase VAR17:\nVAR8 = \"STR\";\nbreak;\ndefault:\nFUN6(VAR1, \"STR\",\nVAR9[0]);\nreturn -VAR15;\n}\nreturn FUN7(VAR3, VAR18, \"STR\", VAR8);\n}\n",
      "code_after_change_raw": "static ssize_t k90_show_macro_mode(struct device *dev,\nstruct device_attribute *attr, char *buf)\n{\nint ret;\nstruct usb_interface *usbif = to_usb_interface(dev->parent);\nstruct usb_device *usbdev = interface_to_usbdev(usbif);\nconst char *macro_mode;\nchar *data;\ndata = kmalloc(2, GFP_KERNEL);\nif (!data)\nreturn -ENOMEM;\nret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\nK90_REQUEST_GET_MODE,\nUSB_DIR_IN | USB_TYPE_VENDOR |\nUSB_RECIP_DEVICE, 0, 0, data, 2,\nUSB_CTRL_SET_TIMEOUT);\nif (ret < 0) {\ndev_warn(dev, \"Failed to get K90 initial mode (error %d).\\n\",\nret);\nret = -EIO;\ngoto out;\n}\nswitch (data[0]) {\ncase K90_MACRO_MODE_HW:\nmacro_mode = \"HW\";\nbreak;\ncase K90_MACRO_MODE_SW:\nmacro_mode = \"SW\";\nbreak;\ndefault:\ndev_warn(dev, \"K90 in unknown mode: %02hhx.\\n\",\ndata[0]);\nret = -EIO;\ngoto out;\n}\nret = snprintf(buf, PAGE_SIZE, \"%s\\n\", macro_mode);\nout:\nkfree(data);\nreturn ret;\n}\n",
      "code_before_change_raw": "static ssize_t k90_show_macro_mode(struct device *dev,\nstruct device_attribute *attr, char *buf)\n{\nint ret;\nstruct usb_interface *usbif = to_usb_interface(dev->parent);\nstruct usb_device *usbdev = interface_to_usbdev(usbif);\nconst char *macro_mode;\nchar data[8];\nret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\nK90_REQUEST_GET_MODE,\nUSB_DIR_IN | USB_TYPE_VENDOR |\nUSB_RECIP_DEVICE, 0, 0, data, 2,\nUSB_CTRL_SET_TIMEOUT);\nif (ret < 0) {\ndev_warn(dev, \"Failed to get K90 initial mode (error %d).\\n\",\nret);\nreturn -EIO;\n}\nswitch (data[0]) {\ncase K90_MACRO_MODE_HW:\nmacro_mode = \"HW\";\nbreak;\ncase K90_MACRO_MODE_SW:\nmacro_mode = \"SW\";\nbreak;\ndefault:\ndev_warn(dev, \"K90 in unknown mode: %02hhx.\\n\",\ndata[0]);\nreturn -EIO;\n}\nreturn snprintf(buf, PAGE_SIZE, \"%s\\n\", macro_mode);\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Usage of a fixed-size stack buffer to store data received from a USB control message.",
        "trigger_condition": "Receiving data larger than the size of the fixed-size stack buffer, leading to a buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code uses a fixed-size stack buffer to store data received from a USB control message without checking the size of the received data. This can result in a buffer overflow if the received data exceeds the size of the buffer."
      },
      "solution": "To mitigate the vulnerability, it is necessary to dynamically allocate memory for the data buffer using kmalloc to ensure that enough memory is available to store the received data without risking a buffer overflow. Additionally, proper error handling should be implemented using goto statements to free the allocated memory in case of errors and ensure correct error reporting.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-5547 in the code snippet. The vulnerability arises due to the use of a fixed-size stack buffer `char data[8];` to store data received from a USB control message. This can lead to a buffer overflow if the received data exceeds the size of the buffer.\n\nTo fix this vulnerability, the modification replaces the fixed-size stack buffer with a dynamically allocated buffer using `kmalloc`. By dynamically allocating memory for the data buffer, the code ensures that enough memory is available to store the received data without risking a buffer overflow.\n\nAdditionally, the modification also includes proper error handling using `goto` statements to free the allocated memory in case of errors and to ensure that the function returns the correct error code. This helps prevent memory leaks and ensures that the function behaves correctly in case of errors during the USB control message handling.",
      "GPT_purpose": "Retrieve the current profile of a Corsair K90 keyboard connected via USB.",
      "GPT_function": "\n1. Show the current profile of a K90 device connected via USB.\n2. Retrieve the current profile data from the USB device.\n3. Check if the current profile is within a valid range (1 to 3).\n4. Display the current profile information in the output buffer.",
      "CVE_id": "CVE-2017-5547",
      "code_before_change": "static ssize_t k90_show_current_profile(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tint ret;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tint current_profile;\n\tchar data[8];\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_STATUS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 8,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n\t\t\t ret);\n\t\treturn -EIO;\n\t}\n\tcurrent_profile = data[7];\n\tif (current_profile < 1 || current_profile > 3) {\n\t\tdev_warn(dev, \"Read invalid current profile: %02hhx.\\n\",\n\t\t\t data[7]);\n\t\treturn -EIO;\n\t}\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\n}",
      "code_after_change": "static ssize_t k90_show_current_profile(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tint ret;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tint current_profile;\n\tchar *data;\n\n\tdata = kmalloc(8, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_STATUS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 8,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n\t\t\t ret);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tcurrent_profile = data[7];\n\tif (current_profile < 1 || current_profile > 3) {\n\t\tdev_warn(dev, \"Read invalid current profile: %02hhx.\\n\",\n\t\t\t data[7]);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tret = snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\nout:\n\tkfree(data);\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tchar *data;",
          "",
          "\tdata = kmalloc(8, GFP_KERNEL);",
          "\tif (!data)",
          "\t\treturn -ENOMEM;",
          "\t\tret = -EIO;",
          "\t\tgoto out;",
          "\t\tret = -EIO;",
          "\t\tgoto out;",
          "\tret = snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);",
          "out:",
          "\tkfree(data);",
          "",
          "\treturn ret;"
        ],
        "deleted": [
          "\tchar data[8];",
          "\t\treturn -EIO;",
          "\t\treturn -EIO;",
          "\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);"
        ]
      },
      "preconditions_for_vulnerability": "Usage of a fixed-size stack buffer to store data received from a USB control message.",
      "trigger_condition": "Receiving data larger than the size of the fixed-size stack buffer, leading to a buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code uses a fixed-size stack buffer to store data received from a USB control message without checking the size of the received data. This can result in a buffer overflow if the received data exceeds the size of the buffer.",
      "id": 116,
      "code_after_change_normalized": "static ssize_t FUN1(struct device *VAR1,\nstruct device_attribute *VAR2,\nchar *VAR3)\n{\nint VAR4;\nstruct usb_interface *VAR5 = FUN2(VAR1->VAR6);\nstruct usb_device *VAR7 = FUN3(VAR5);\nint VAR8;\nchar *VAR9;\nVAR9 = FUN4(8, VAR10);\nif (!VAR9)\nreturn -VAR11;\nVAR4 = FUN5(VAR7, FUN6(VAR7, 0),\nVAR12,\nVAR13 | VAR14 |\nVAR15, 0, 0, VAR9, 8,\nVAR16);\nif (VAR4 < 0) {\nFUN7(VAR1, \"STR\",\nVAR4);\nVAR4 = -VAR17;\ngoto VAR18;\n}\nVAR8 = VAR9[7];\nif (VAR8 < 1 || VAR8 > 3) {\nFUN7(VAR1, \"STR\",\nVAR9[7]);\nVAR4 = -VAR17;\ngoto VAR18;\n}\nVAR4 = FUN8(VAR3, VAR19, \"STR\", VAR8);\nVAR18:\nFUN9(VAR9);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct device *VAR1,\nstruct device_attribute *VAR2,\nchar *VAR3)\n{\nint VAR4;\nstruct usb_interface *VAR5 = FUN2(VAR1->VAR6);\nstruct usb_device *VAR7 = FUN3(VAR5);\nint VAR8;\nchar VAR9[8];\nVAR4 = FUN4(VAR7, FUN5(VAR7, 0),\nVAR10,\nVAR11 | VAR12 |\nVAR13, 0, 0, VAR9, 8,\nVAR14);\nif (VAR4 < 0) {\nFUN6(VAR1, \"STR\",\nVAR4);\nreturn -VAR15;\n}\nVAR8 = VAR9[7];\nif (VAR8 < 1 || VAR8 > 3) {\nFUN6(VAR1, \"STR\",\nVAR9[7]);\nreturn -VAR15;\n}\nreturn FUN7(VAR3, VAR16, \"STR\", VAR8);\n}\n",
      "code_after_change_raw": "static ssize_t k90_show_current_profile(struct device *dev,\nstruct device_attribute *attr,\nchar *buf)\n{\nint ret;\nstruct usb_interface *usbif = to_usb_interface(dev->parent);\nstruct usb_device *usbdev = interface_to_usbdev(usbif);\nint current_profile;\nchar *data;\ndata = kmalloc(8, GFP_KERNEL);\nif (!data)\nreturn -ENOMEM;\nret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\nK90_REQUEST_STATUS,\nUSB_DIR_IN | USB_TYPE_VENDOR |\nUSB_RECIP_DEVICE, 0, 0, data, 8,\nUSB_CTRL_SET_TIMEOUT);\nif (ret < 0) {\ndev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\nret);\nret = -EIO;\ngoto out;\n}\ncurrent_profile = data[7];\nif (current_profile < 1 || current_profile > 3) {\ndev_warn(dev, \"Read invalid current profile: %02hhx.\\n\",\ndata[7]);\nret = -EIO;\ngoto out;\n}\nret = snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\nout:\nkfree(data);\nreturn ret;\n}\n",
      "code_before_change_raw": "static ssize_t k90_show_current_profile(struct device *dev,\nstruct device_attribute *attr,\nchar *buf)\n{\nint ret;\nstruct usb_interface *usbif = to_usb_interface(dev->parent);\nstruct usb_device *usbdev = interface_to_usbdev(usbif);\nint current_profile;\nchar data[8];\nret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\nK90_REQUEST_STATUS,\nUSB_DIR_IN | USB_TYPE_VENDOR |\nUSB_RECIP_DEVICE, 0, 0, data, 8,\nUSB_CTRL_SET_TIMEOUT);\nif (ret < 0) {\ndev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\nret);\nreturn -EIO;\n}\ncurrent_profile = data[7];\nif (current_profile < 1 || current_profile > 3) {\ndev_warn(dev, \"Read invalid current profile: %02hhx.\\n\",\ndata[7]);\nreturn -EIO;\n}\nreturn snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\n}\n"
    }
  ],
  "CVE-2017-5548": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Interaction issue with CONFIG_VMAP_STACK option, leading to a denial of service or memory corruption due to improper handling of DMA scatterlists.",
        "trigger_condition": "Use of more than one virtual page for a DMA scatterlist by local users.",
        "specific_code_behavior_causing_vulnerability": "The original code snippet declares a fixed-size array on the stack for buffer, which can lead to memory corruption or system crash when interacting with DMA scatterlists and CONFIG_VMAP_STACK."
      },
      "solution": "To mitigate the vulnerability, it is necessary to dynamically allocate memory for the buffer using kmalloc and free it using kfree. This ensures proper memory management and avoids potential issues with DMA scatterlists. By dynamically allocating memory, the code ensures that the buffer is located in a safe memory region and can be properly handled by DMA operations, reducing the risk of denial of service or memory corruption.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2017-5548 related to the incorrect interaction with the CONFIG_VMAP_STACK option. By allocating memory dynamically using kmalloc and freeing it using kfree, the code ensures that the buffer is properly managed and avoids potential issues with DMA scatterlists that could lead to a denial of service or memory corruption.\n\nIn the original code snippet, the buffer was declared as a fixed-size array on the stack, which could be problematic when interacting with DMA scatterlists and CONFIG_VMAP_STACK. By dynamically allocating memory for the buffer using kmalloc, the code ensures that the buffer is located in a safe memory region and can be properly handled by the DMA scatterlist operations.\n\nTherefore, the modification is necessary to mitigate the vulnerability and improve the overall security and stability of the code when dealing with DMA operations and potential memory corruption issues.",
      "GPT_purpose": "Retrieve and display firmware revision information for an ATUSB device.",
      "GPT_function": "\n1. Get and display the ATMega Firmware values from a USB device.\n2. Check if the firmware version predates a specific release and provide a message if so.\n3. Return the result of the operation.",
      "CVE_id": "CVE-2017-5548",
      "code_before_change": "static int atusb_get_and_show_revision(struct atusb *atusb)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tunsigned char buffer[3];\n\tint ret;\n\n\t/* Get a couple of the ATMega Firmware values */\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_ID, ATUSB_REQ_FROM_DEV, 0, 0,\n\t\t\t\tbuffer, 3, 1000);\n\tif (ret >= 0) {\n\t\tatusb->fw_ver_maj = buffer[0];\n\t\tatusb->fw_ver_min = buffer[1];\n\t\tatusb->fw_hw_type = buffer[2];\n\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware: major: %u, minor: %u, hardware type: %u\\n\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min, atusb->fw_hw_type);\n\t}\n\tif (atusb->fw_ver_maj == 0 && atusb->fw_ver_min < 2) {\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware version (%u.%u) predates our first public release.\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min);\n\t\tdev_info(&usb_dev->dev, \"Please update to version 0.2 or newer\");\n\t}\n\n\treturn ret;\n}",
      "code_after_change": "static int atusb_get_and_show_revision(struct atusb *atusb)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tunsigned char *buffer;\n\tint ret;\n\n\tbuffer = kmalloc(3, GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\t/* Get a couple of the ATMega Firmware values */\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_ID, ATUSB_REQ_FROM_DEV, 0, 0,\n\t\t\t\tbuffer, 3, 1000);\n\tif (ret >= 0) {\n\t\tatusb->fw_ver_maj = buffer[0];\n\t\tatusb->fw_ver_min = buffer[1];\n\t\tatusb->fw_hw_type = buffer[2];\n\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware: major: %u, minor: %u, hardware type: %u\\n\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min, atusb->fw_hw_type);\n\t}\n\tif (atusb->fw_ver_maj == 0 && atusb->fw_ver_min < 2) {\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware version (%u.%u) predates our first public release.\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min);\n\t\tdev_info(&usb_dev->dev, \"Please update to version 0.2 or newer\");\n\t}\n\n\tkfree(buffer);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tunsigned char *buffer;",
          "",
          "\tbuffer = kmalloc(3, GFP_KERNEL);",
          "\tif (!buffer)",
          "\t\treturn -ENOMEM;",
          "\tkfree(buffer);"
        ],
        "deleted": [
          "\tunsigned char buffer[3];"
        ]
      },
      "preconditions_for_vulnerability": "Interaction issue with CONFIG_VMAP_STACK option, leading to a denial of service or memory corruption due to improper handling of DMA scatterlists.",
      "trigger_condition": "Use of more than one virtual page for a DMA scatterlist by local users.",
      "specific_code_behavior_causing_vulnerability": "The original code snippet declares a fixed-size array on the stack for buffer, which can lead to memory corruption or system crash when interacting with DMA scatterlists and CONFIG_VMAP_STACK.",
      "id": 117,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1)\n{\nstruct usb_device *VAR2 = VAR1->VAR2;\nunsigned char *VAR3;\nint VAR4;\nVAR3 = FUN2(3, VAR5);\nif (!VAR3)\nreturn -VAR6;\nVAR4 = FUN3(VAR1, FUN4(VAR2, 0),\nVAR7, VAR8, 0, 0,\nVAR3, 3, 1000);\nif (VAR4 >= 0) {\nVAR1->VAR9 = VAR3[0];\nVAR1->VAR10 = VAR3[1];\nVAR1->VAR11 = VAR3[2];\nFUN5(&VAR2->VAR12,\n\"STR\",\nVAR1->VAR9, VAR1->VAR10, VAR1->VAR11);\n}\nif (VAR1->VAR9 == 0 && VAR1->VAR10 < 2) {\nFUN5(&VAR2->VAR12,\n\"STR\",\nVAR1->VAR9, VAR1->VAR10);\nFUN5(&VAR2->VAR12, \"STR\");\n}\nFUN6(VAR3);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1)\n{\nstruct usb_device *VAR2 = VAR1->VAR2;\nunsigned char VAR3[3];\nint VAR4;\nVAR4 = FUN2(VAR1, FUN3(VAR2, 0),\nVAR5, VAR6, 0, 0,\nVAR3, 3, 1000);\nif (VAR4 >= 0) {\nVAR1->VAR7 = VAR3[0];\nVAR1->VAR8 = VAR3[1];\nVAR1->VAR9 = VAR3[2];\nFUN4(&VAR2->VAR10,\n\"STR\",\nVAR1->VAR7, VAR1->VAR8, VAR1->VAR9);\n}\nif (VAR1->VAR7 == 0 && VAR1->VAR8 < 2) {\nFUN4(&VAR2->VAR10,\n\"STR\",\nVAR1->VAR7, VAR1->VAR8);\nFUN4(&VAR2->VAR10, \"STR\");\n}\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int atusb_get_and_show_revision(struct atusb *atusb)\n{\nstruct usb_device *usb_dev = atusb->usb_dev;\nunsigned char *buffer;\nint ret;\nbuffer = kmalloc(3, GFP_KERNEL);\nif (!buffer)\nreturn -ENOMEM;\nret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\nATUSB_ID, ATUSB_REQ_FROM_DEV, 0, 0,\nbuffer, 3, 1000);\nif (ret >= 0) {\natusb->fw_ver_maj = buffer[0];\natusb->fw_ver_min = buffer[1];\natusb->fw_hw_type = buffer[2];\ndev_info(&usb_dev->dev,\n\"Firmware: major: %u, minor: %u, hardware type: %u\\n\",\natusb->fw_ver_maj, atusb->fw_ver_min, atusb->fw_hw_type);\n}\nif (atusb->fw_ver_maj == 0 && atusb->fw_ver_min < 2) {\ndev_info(&usb_dev->dev,\n\"Firmware version (%u.%u) predates our first public release.\",\natusb->fw_ver_maj, atusb->fw_ver_min);\ndev_info(&usb_dev->dev, \"Please update to version 0.2 or newer\");\n}\nkfree(buffer);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int atusb_get_and_show_revision(struct atusb *atusb)\n{\nstruct usb_device *usb_dev = atusb->usb_dev;\nunsigned char buffer[3];\nint ret;\nret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\nATUSB_ID, ATUSB_REQ_FROM_DEV, 0, 0,\nbuffer, 3, 1000);\nif (ret >= 0) {\natusb->fw_ver_maj = buffer[0];\natusb->fw_ver_min = buffer[1];\natusb->fw_hw_type = buffer[2];\ndev_info(&usb_dev->dev,\n\"Firmware: major: %u, minor: %u, hardware type: %u\\n\",\natusb->fw_ver_maj, atusb->fw_ver_min, atusb->fw_hw_type);\n}\nif (atusb->fw_ver_maj == 0 && atusb->fw_ver_min < 2) {\ndev_info(&usb_dev->dev,\n\"Firmware version (%u.%u) predates our first public release.\",\natusb->fw_ver_maj, atusb->fw_ver_min);\ndev_info(&usb_dev->dev, \"Please update to version 0.2 or newer\");\n}\nreturn ret;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect interaction with a specific kernel configuration option leads to improper handling of DMA scatterlists, causing a denial of service or memory corruption.",
        "trigger_condition": "Use of more than one virtual page for a DMA scatterlist by local users.",
        "specific_code_behavior_causing_vulnerability": "The original code snippet allocates a single byte variable to store the value read from the USB device, but the atusb_control_msg function writes directly to this variable, potentially causing memory corruption if more than one byte is written. This vulnerability arises due to improper memory handling and potential overflow issues.",
        "solution": "To mitigate the vulnerability, the code needs to allocate a buffer of appropriate size to store the value read from the USB device. By using kmalloc to allocate memory for the buffer, the code ensures that the atusb_control_msg function writes the value to a safe memory location. After reading the value, the code properly accesses it from the buffer and then frees the allocated memory using kfree. This solution prevents memory corruption issues and ensures safe memory access."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-5548 by fixing the way memory is allocated and accessed in the code snippet. \n\nIn the original code snippet, the variable `value` is a single uint8_t variable used to store the value read from the USB device. However, the atusb_control_msg function writes the value directly to this variable, which can lead to memory corruption if the function writes more than one byte to it.\n\nThe modified code snippet addresses this issue by allocating a buffer of size 1 using kmalloc to store the value read from the USB device. This ensures that the function atusb_control_msg writes the value to a safe memory location. After reading the value, the code properly accesses it from the buffer and then frees the allocated memory using kfree.\n\nBy making these changes, the modified code snippet prevents potential memory corruption issues and ensures safe memory access, thereby fixing the vulnerability.",
      "GPT_purpose": "Read a register value from an ATUSB device using USB communication.",
      "GPT_function": "\n1. Read a register from the ATUSB device.\n2. Log the register value being read.\n3. Perform a control message to read the register value from the device.",
      "CVE_id": "CVE-2017-5548",
      "code_before_change": "static int atusb_read_reg(struct atusb *atusb, uint8_t reg)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tint ret;\n\tuint8_t value;\n\n\tdev_dbg(&usb_dev->dev, \"atusb: reg = 0x%x\\n\", reg);\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_REG_READ, ATUSB_REQ_FROM_DEV,\n\t\t\t\t0, reg, &value, 1, 1000);\n\treturn ret >= 0 ? value : ret;\n}",
      "code_after_change": "static int atusb_read_reg(struct atusb *atusb, uint8_t reg)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tint ret;\n\tuint8_t *buffer;\n\tuint8_t value;\n\n\tbuffer = kmalloc(1, GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\tdev_dbg(&usb_dev->dev, \"atusb: reg = 0x%x\\n\", reg);\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_REG_READ, ATUSB_REQ_FROM_DEV,\n\t\t\t\t0, reg, buffer, 1, 1000);\n\n\tif (ret >= 0) {\n\t\tvalue = buffer[0];\n\t\tkfree(buffer);\n\t\treturn value;\n\t} else {\n\t\tkfree(buffer);\n\t\treturn ret;\n\t}\n}",
      "modified_lines": {
        "added": [
          "\tuint8_t *buffer;",
          "",
          "\tbuffer = kmalloc(1, GFP_KERNEL);",
          "\tif (!buffer)",
          "\t\treturn -ENOMEM;",
          "\t\t\t\t0, reg, buffer, 1, 1000);",
          "",
          "\tif (ret >= 0) {",
          "\t\tvalue = buffer[0];",
          "\t\tkfree(buffer);",
          "\t\treturn value;",
          "\t} else {",
          "\t\tkfree(buffer);",
          "\t\treturn ret;",
          "\t}"
        ],
        "deleted": [
          "\t\t\t\t0, reg, &value, 1, 1000);",
          "\treturn ret >= 0 ? value : ret;"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect interaction with a specific kernel configuration option leads to improper handling of DMA scatterlists, causing a denial of service or memory corruption.",
      "trigger_condition": "Use of more than one virtual page for a DMA scatterlist by local users.",
      "specific_code_behavior_causing_vulnerability": "The original code snippet allocates a single byte variable to store the value read from the USB device, but the atusb_control_msg function writes directly to this variable, potentially causing memory corruption if more than one byte is written. This vulnerability arises due to improper memory handling and potential overflow issues.",
      "solution": "To mitigate the vulnerability, the code needs to allocate a buffer of appropriate size to store the value read from the USB device. By using kmalloc to allocate memory for the buffer, the code ensures that the atusb_control_msg function writes the value to a safe memory location. After reading the value, the code properly accesses it from the buffer and then frees the allocated memory using kfree. This solution prevents memory corruption issues and ensures safe memory access.",
      "id": 118,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1, uint8_t VAR2)\n{\nstruct usb_device *VAR3 = VAR1->VAR3;\nint VAR4;\nuint8_t *VAR5;\nuint8_t VAR6;\nVAR5 = FUN2(1, VAR7);\nif (!VAR5)\nreturn -VAR8;\nFUN3(&VAR3->VAR9, \"STR\", VAR2);\nVAR4 = FUN4(VAR1, FUN5(VAR3, 0),\nVAR10, VAR11,\n0, VAR2, VAR5, 1, 1000);\nif (VAR4 >= 0) {\nVAR6 = VAR5[0];\nFUN6(VAR5);\nreturn VAR6;\n} else {\nFUN6(VAR5);\nreturn VAR4;\n}\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1, uint8_t VAR2)\n{\nstruct usb_device *VAR3 = VAR1->VAR3;\nint VAR4;\nuint8_t VAR5;\nFUN2(&VAR3->VAR6, \"STR\", VAR2);\nVAR4 = FUN3(VAR1, FUN4(VAR3, 0),\nVAR7, VAR8,\n0, VAR2, &VAR5, 1, 1000);\nreturn VAR4 >= 0 ? VAR5 : VAR4;\n}\n",
      "code_after_change_raw": "static int atusb_read_reg(struct atusb *atusb, uint8_t reg)\n{\nstruct usb_device *usb_dev = atusb->usb_dev;\nint ret;\nuint8_t *buffer;\nuint8_t value;\nbuffer = kmalloc(1, GFP_KERNEL);\nif (!buffer)\nreturn -ENOMEM;\ndev_dbg(&usb_dev->dev, \"atusb: reg = 0x%x\\n\", reg);\nret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\nATUSB_REG_READ, ATUSB_REQ_FROM_DEV,\n0, reg, buffer, 1, 1000);\nif (ret >= 0) {\nvalue = buffer[0];\nkfree(buffer);\nreturn value;\n} else {\nkfree(buffer);\nreturn ret;\n}\n}\n",
      "code_before_change_raw": "static int atusb_read_reg(struct atusb *atusb, uint8_t reg)\n{\nstruct usb_device *usb_dev = atusb->usb_dev;\nint ret;\nuint8_t value;\ndev_dbg(&usb_dev->dev, \"atusb: reg = 0x%x\\n\", reg);\nret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\nATUSB_REG_READ, ATUSB_REQ_FROM_DEV,\n0, reg, &value, 1, 1000);\nreturn ret >= 0 ? value : ret;\n}\n"
    }
  ],
  "CVE-2017-7187": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for the command size input in the SG_NEXT_CMD_LEN ioctl call.",
        "trigger_condition": "An attacker provides a large command size input in the SG_NEXT_CMD_LEN ioctl call, leading to a stack-based buffer overflow in the sg_write function.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the command size input exceeds a predefined maximum value, allowing a potential buffer overflow during the sg_write operation."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the command size input in the SG_NEXT_CMD_LEN ioctl call does not exceed a safe maximum value. By limiting the command size to a predefined maximum, the code prevents the stack-based buffer overflow in the sg_write function. In this case, the solution involves adding a line to check if the command size input is within the safe limits before proceeding with the sg_write operation.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-7187, which involves a stack-based buffer overflow in the sg_ioctl function. By adding the check `if (val > SG_MAX_CDB_SIZE)` in the `SG_NEXT_CMD_LEN` case, we ensure that the command size `val` does not exceed a predefined maximum size `SG_MAX_CDB_SIZE`. This check prevents a potential buffer overflow that could occur if a large command size is provided, leading to out-of-bounds write access in the sg_write function.\n\nBy limiting the command size to a safe maximum value, we mitigate the risk of a denial of service or other unspecified impacts caused by the vulnerability. This modification helps to enhance the security and stability of the sg_ioctl function in the Linux kernel.",
      "GPT_purpose": "Handle various ioctl commands for the SCSI generic (sg) driver in the Linux kernel.",
      "GPT_function": "\n1. Handle various SCSI ioctl commands such as SG_IO, SG_SET_TIMEOUT, SG_GET_TIMEOUT, SG_SET_FORCE_LOW_DMA, SG_GET_LOW_DMA, SG_GET_SCSI_ID, SG_SET_FORCE_PACK_ID, SG_GET_PACK_ID, SG_GET_NUM_WAITING, SG_GET_SG_TABLESIZE, SG_SET_RESERVED_SIZE, SG_GET_RESERVED_SIZE, SG_SET_COMMAND_Q, SG_GET_COMMAND_Q, SG_SET_KEEP_ORPHAN, SG_GET_KEEP_ORPHAN, SG_NEXT_CMD_LEN, SG_GET_VERSION_NUM, SG_GET_ACCESS_COUNT, SG_GET_REQUEST_TABLE, SG_EMULATED_HOST, SCSI_IOCTL_SEND_COMMAND, SG_SET_DEBUG, BLKSECTGET, BLKTRACESETUP, BLKTRACESTART, BLKTRACESTOP, BLKTRACETEARDOWN, SCSI_IOCTL_GET_IDLUN, SCSI_IOCTL_GET_BUS_NUMBER, SCSI_IOCTL_PROBE_HOST, SG_GET_TRANSFORM, SG_SCSI_RESET.\n2. Check for detaching status and block access if detaching.\n3. Handle specific ioctl commands with user input validation and processing.",
      "CVE_id": "CVE-2017-7187",
      "code_before_change": "static long\nsg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\n\tvoid __user *p = (void __user *)arg;\n\tint __user *ip = p;\n\tint result, val, read_only;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tSg_request *srp;\n\tunsigned long iflags;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t   \"sg_ioctl: cmd=0x%x\\n\", (int) cmd_in));\n\tread_only = (O_RDWR != (filp->f_flags & O_ACCMODE));\n\n\tswitch (cmd_in) {\n\tcase SG_IO:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (!scsi_block_when_processing_errors(sdp->device))\n\t\t\treturn -ENXIO;\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_IO_HDR))\n\t\t\treturn -EFAULT;\n\t\tresult = sg_new_write(sfp, filp, p, SZ_SG_IO_HDR,\n\t\t\t\t 1, read_only, 1, &srp);\n\t\tif (result < 0)\n\t\t\treturn result;\n\t\tresult = wait_event_interruptible(sfp->read_wait,\n\t\t\t(srp_done(sfp, srp) || atomic_read(&sdp->detaching)));\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\twrite_lock_irq(&sfp->rq_list_lock);\n\t\tif (srp->done) {\n\t\t\tsrp->done = 2;\n\t\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\t\tresult = sg_new_read(sfp, p, SZ_SG_IO_HDR, srp);\n\t\t\treturn (result < 0) ? result : 0;\n\t\t}\n\t\tsrp->orphan = 1;\n\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\treturn result;\t/* -ERESTARTSYS because signal hit process */\n\tcase SG_SET_TIMEOUT:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val < 0)\n\t\t\treturn -EIO;\n\t\tif (val >= mult_frac((s64)INT_MAX, USER_HZ, HZ))\n\t\t\tval = min_t(s64, mult_frac((s64)INT_MAX, USER_HZ, HZ),\n\t\t\t\t    INT_MAX);\n\t\tsfp->timeout_user = val;\n\t\tsfp->timeout = mult_frac(val, HZ, USER_HZ);\n\n\t\treturn 0;\n\tcase SG_GET_TIMEOUT:\t/* N.B. User receives timeout as return value */\n\t\t\t\t/* strange ..., for backward compatibility */\n\t\treturn sfp->timeout_user;\n\tcase SG_SET_FORCE_LOW_DMA:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val) {\n\t\t\tsfp->low_dma = 1;\n\t\t\tif ((0 == sfp->low_dma) && (0 == sg_res_in_use(sfp))) {\n\t\t\t\tval = (int) sfp->reserve.bufflen;\n\t\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\t\tsg_build_reserve(sfp, val);\n\t\t\t}\n\t\t} else {\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\tsfp->low_dma = sdp->device->host->unchecked_isa_dma;\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_LOW_DMA:\n\t\treturn put_user((int) sfp->low_dma, ip);\n\tcase SG_GET_SCSI_ID:\n\t\tif (!access_ok(VERIFY_WRITE, p, sizeof (sg_scsi_id_t)))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_scsi_id_t __user *sg_idp = p;\n\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\t__put_user((int) sdp->device->host->host_no,\n\t\t\t\t   &sg_idp->host_no);\n\t\t\t__put_user((int) sdp->device->channel,\n\t\t\t\t   &sg_idp->channel);\n\t\t\t__put_user((int) sdp->device->id, &sg_idp->scsi_id);\n\t\t\t__put_user((int) sdp->device->lun, &sg_idp->lun);\n\t\t\t__put_user((int) sdp->device->type, &sg_idp->scsi_type);\n\t\t\t__put_user((short) sdp->device->host->cmd_per_lun,\n\t\t\t\t   &sg_idp->h_cmd_per_lun);\n\t\t\t__put_user((short) sdp->device->queue_depth,\n\t\t\t\t   &sg_idp->d_queue_depth);\n\t\t\t__put_user(0, &sg_idp->unused[0]);\n\t\t\t__put_user(0, &sg_idp->unused[1]);\n\t\t\treturn 0;\n\t\t}\n\tcase SG_SET_FORCE_PACK_ID:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->force_packid = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_PACK_ID:\n\t\tif (!access_ok(VERIFY_WRITE, ip, sizeof (int)))\n\t\t\treturn -EFAULT;\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned)) {\n\t\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock,\n\t\t\t\t\t\t       iflags);\n\t\t\t\t__put_user(srp->header.pack_id, ip);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t__put_user(-1, ip);\n\t\treturn 0;\n\tcase SG_GET_NUM_WAITING:\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (val = 0, srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned))\n\t\t\t\t++val;\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_SG_TABLESIZE:\n\t\treturn put_user(sdp->sg_tablesize, ip);\n\tcase SG_SET_RESERVED_SIZE:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n                if (val < 0)\n                        return -EINVAL;\n\t\tval = min_t(int, val,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\tif (val != sfp->reserve.bufflen) {\n\t\t\tif (sg_res_in_use(sfp) || sfp->mmap_called)\n\t\t\t\treturn -EBUSY;\n\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\tsg_build_reserve(sfp, val);\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_RESERVED_SIZE:\n\t\tval = min_t(int, sfp->reserve.bufflen,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\treturn put_user(val, ip);\n\tcase SG_SET_COMMAND_Q:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->cmd_q = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_COMMAND_Q:\n\t\treturn put_user((int) sfp->cmd_q, ip);\n\tcase SG_SET_KEEP_ORPHAN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->keep_orphan = val;\n\t\treturn 0;\n\tcase SG_GET_KEEP_ORPHAN:\n\t\treturn put_user((int) sfp->keep_orphan, ip);\n\tcase SG_NEXT_CMD_LEN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->next_cmd_len = (val > 0) ? val : 0;\n\t\treturn 0;\n\tcase SG_GET_VERSION_NUM:\n\t\treturn put_user(sg_version_num, ip);\n\tcase SG_GET_ACCESS_COUNT:\n\t\t/* faked - we don't have a real access count anymore */\n\t\tval = (sdp->device ? 1 : 0);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_REQUEST_TABLE:\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_REQ_INFO * SG_MAX_QUEUE))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_req_info_t *rinfo;\n\t\t\tunsigned int ms;\n\n\t\t\trinfo = kmalloc(SZ_SG_REQ_INFO * SG_MAX_QUEUE,\n\t\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!rinfo)\n\t\t\t\treturn -ENOMEM;\n\t\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\t\tfor (srp = sfp->headrp, val = 0; val < SG_MAX_QUEUE;\n\t\t\t     ++val, srp = srp ? srp->nextrp : srp) {\n\t\t\t\tmemset(&rinfo[val], 0, SZ_SG_REQ_INFO);\n\t\t\t\tif (srp) {\n\t\t\t\t\trinfo[val].req_state = srp->done + 1;\n\t\t\t\t\trinfo[val].problem =\n\t\t\t\t\t    srp->header.masked_status & \n\t\t\t\t\t    srp->header.host_status & \n\t\t\t\t\t    srp->header.driver_status;\n\t\t\t\t\tif (srp->done)\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t\tsrp->header.duration;\n\t\t\t\t\telse {\n\t\t\t\t\t\tms = jiffies_to_msecs(jiffies);\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t    (ms > srp->header.duration) ?\n\t\t\t\t\t\t    (ms - srp->header.duration) : 0;\n\t\t\t\t\t}\n\t\t\t\t\trinfo[val].orphan = srp->orphan;\n\t\t\t\t\trinfo[val].sg_io_owned =\n\t\t\t\t\t\t\tsrp->sg_io_owned;\n\t\t\t\t\trinfo[val].pack_id =\n\t\t\t\t\t\t\tsrp->header.pack_id;\n\t\t\t\t\trinfo[val].usr_ptr =\n\t\t\t\t\t\t\tsrp->header.usr_ptr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t\tresult = __copy_to_user(p, rinfo, \n\t\t\t\t\t\tSZ_SG_REQ_INFO * SG_MAX_QUEUE);\n\t\t\tresult = result ? -EFAULT : 0;\n\t\t\tkfree(rinfo);\n\t\t\treturn result;\n\t\t}\n\tcase SG_EMULATED_HOST:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\treturn put_user(sdp->device->host->hostt->emulated, ip);\n\tcase SCSI_IOCTL_SEND_COMMAND:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (read_only) {\n\t\t\tunsigned char opcode = WRITE_6;\n\t\t\tScsi_Ioctl_Command __user *siocp = p;\n\n\t\t\tif (copy_from_user(&opcode, siocp->data, 1))\n\t\t\t\treturn -EFAULT;\n\t\t\tif (sg_allow_access(filp, &opcode))\n\t\t\t\treturn -EPERM;\n\t\t}\n\t\treturn sg_scsi_ioctl(sdp->device->request_queue, NULL, filp->f_mode, p);\n\tcase SG_SET_DEBUG:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsdp->sgdebug = (char) val;\n\t\treturn 0;\n\tcase BLKSECTGET:\n\t\treturn put_user(max_sectors_bytes(sdp->device->request_queue),\n\t\t\t\tip);\n\tcase BLKTRACESETUP:\n\t\treturn blk_trace_setup(sdp->device->request_queue,\n\t\t\t\t       sdp->disk->disk_name,\n\t\t\t\t       MKDEV(SCSI_GENERIC_MAJOR, sdp->index),\n\t\t\t\t       NULL,\n\t\t\t\t       (char *)arg);\n\tcase BLKTRACESTART:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 1);\n\tcase BLKTRACESTOP:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 0);\n\tcase BLKTRACETEARDOWN:\n\t\treturn blk_trace_remove(sdp->device->request_queue);\n\tcase SCSI_IOCTL_GET_IDLUN:\n\tcase SCSI_IOCTL_GET_BUS_NUMBER:\n\tcase SCSI_IOCTL_PROBE_HOST:\n\tcase SG_GET_TRANSFORM:\n\tcase SG_SCSI_RESET:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tdefault:\n\t\tif (read_only)\n\t\t\treturn -EPERM;\t/* don't know so take safe approach */\n\t\tbreak;\n\t}\n\n\tresult = scsi_ioctl_block_when_processing_errors(sdp->device,\n\t\t\tcmd_in, filp->f_flags & O_NDELAY);\n\tif (result)\n\t\treturn result;\n\treturn scsi_ioctl(sdp->device, cmd_in, p);\n}",
      "code_after_change": "static long\nsg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\n\tvoid __user *p = (void __user *)arg;\n\tint __user *ip = p;\n\tint result, val, read_only;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tSg_request *srp;\n\tunsigned long iflags;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t   \"sg_ioctl: cmd=0x%x\\n\", (int) cmd_in));\n\tread_only = (O_RDWR != (filp->f_flags & O_ACCMODE));\n\n\tswitch (cmd_in) {\n\tcase SG_IO:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (!scsi_block_when_processing_errors(sdp->device))\n\t\t\treturn -ENXIO;\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_IO_HDR))\n\t\t\treturn -EFAULT;\n\t\tresult = sg_new_write(sfp, filp, p, SZ_SG_IO_HDR,\n\t\t\t\t 1, read_only, 1, &srp);\n\t\tif (result < 0)\n\t\t\treturn result;\n\t\tresult = wait_event_interruptible(sfp->read_wait,\n\t\t\t(srp_done(sfp, srp) || atomic_read(&sdp->detaching)));\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\twrite_lock_irq(&sfp->rq_list_lock);\n\t\tif (srp->done) {\n\t\t\tsrp->done = 2;\n\t\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\t\tresult = sg_new_read(sfp, p, SZ_SG_IO_HDR, srp);\n\t\t\treturn (result < 0) ? result : 0;\n\t\t}\n\t\tsrp->orphan = 1;\n\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\treturn result;\t/* -ERESTARTSYS because signal hit process */\n\tcase SG_SET_TIMEOUT:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val < 0)\n\t\t\treturn -EIO;\n\t\tif (val >= mult_frac((s64)INT_MAX, USER_HZ, HZ))\n\t\t\tval = min_t(s64, mult_frac((s64)INT_MAX, USER_HZ, HZ),\n\t\t\t\t    INT_MAX);\n\t\tsfp->timeout_user = val;\n\t\tsfp->timeout = mult_frac(val, HZ, USER_HZ);\n\n\t\treturn 0;\n\tcase SG_GET_TIMEOUT:\t/* N.B. User receives timeout as return value */\n\t\t\t\t/* strange ..., for backward compatibility */\n\t\treturn sfp->timeout_user;\n\tcase SG_SET_FORCE_LOW_DMA:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val) {\n\t\t\tsfp->low_dma = 1;\n\t\t\tif ((0 == sfp->low_dma) && (0 == sg_res_in_use(sfp))) {\n\t\t\t\tval = (int) sfp->reserve.bufflen;\n\t\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\t\tsg_build_reserve(sfp, val);\n\t\t\t}\n\t\t} else {\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\tsfp->low_dma = sdp->device->host->unchecked_isa_dma;\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_LOW_DMA:\n\t\treturn put_user((int) sfp->low_dma, ip);\n\tcase SG_GET_SCSI_ID:\n\t\tif (!access_ok(VERIFY_WRITE, p, sizeof (sg_scsi_id_t)))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_scsi_id_t __user *sg_idp = p;\n\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\t__put_user((int) sdp->device->host->host_no,\n\t\t\t\t   &sg_idp->host_no);\n\t\t\t__put_user((int) sdp->device->channel,\n\t\t\t\t   &sg_idp->channel);\n\t\t\t__put_user((int) sdp->device->id, &sg_idp->scsi_id);\n\t\t\t__put_user((int) sdp->device->lun, &sg_idp->lun);\n\t\t\t__put_user((int) sdp->device->type, &sg_idp->scsi_type);\n\t\t\t__put_user((short) sdp->device->host->cmd_per_lun,\n\t\t\t\t   &sg_idp->h_cmd_per_lun);\n\t\t\t__put_user((short) sdp->device->queue_depth,\n\t\t\t\t   &sg_idp->d_queue_depth);\n\t\t\t__put_user(0, &sg_idp->unused[0]);\n\t\t\t__put_user(0, &sg_idp->unused[1]);\n\t\t\treturn 0;\n\t\t}\n\tcase SG_SET_FORCE_PACK_ID:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->force_packid = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_PACK_ID:\n\t\tif (!access_ok(VERIFY_WRITE, ip, sizeof (int)))\n\t\t\treturn -EFAULT;\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned)) {\n\t\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock,\n\t\t\t\t\t\t       iflags);\n\t\t\t\t__put_user(srp->header.pack_id, ip);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t__put_user(-1, ip);\n\t\treturn 0;\n\tcase SG_GET_NUM_WAITING:\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (val = 0, srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned))\n\t\t\t\t++val;\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_SG_TABLESIZE:\n\t\treturn put_user(sdp->sg_tablesize, ip);\n\tcase SG_SET_RESERVED_SIZE:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n                if (val < 0)\n                        return -EINVAL;\n\t\tval = min_t(int, val,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\tif (val != sfp->reserve.bufflen) {\n\t\t\tif (sg_res_in_use(sfp) || sfp->mmap_called)\n\t\t\t\treturn -EBUSY;\n\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\tsg_build_reserve(sfp, val);\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_RESERVED_SIZE:\n\t\tval = min_t(int, sfp->reserve.bufflen,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\treturn put_user(val, ip);\n\tcase SG_SET_COMMAND_Q:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->cmd_q = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_COMMAND_Q:\n\t\treturn put_user((int) sfp->cmd_q, ip);\n\tcase SG_SET_KEEP_ORPHAN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->keep_orphan = val;\n\t\treturn 0;\n\tcase SG_GET_KEEP_ORPHAN:\n\t\treturn put_user((int) sfp->keep_orphan, ip);\n\tcase SG_NEXT_CMD_LEN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val > SG_MAX_CDB_SIZE)\n\t\t\treturn -ENOMEM;\n\t\tsfp->next_cmd_len = (val > 0) ? val : 0;\n\t\treturn 0;\n\tcase SG_GET_VERSION_NUM:\n\t\treturn put_user(sg_version_num, ip);\n\tcase SG_GET_ACCESS_COUNT:\n\t\t/* faked - we don't have a real access count anymore */\n\t\tval = (sdp->device ? 1 : 0);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_REQUEST_TABLE:\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_REQ_INFO * SG_MAX_QUEUE))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_req_info_t *rinfo;\n\t\t\tunsigned int ms;\n\n\t\t\trinfo = kmalloc(SZ_SG_REQ_INFO * SG_MAX_QUEUE,\n\t\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!rinfo)\n\t\t\t\treturn -ENOMEM;\n\t\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\t\tfor (srp = sfp->headrp, val = 0; val < SG_MAX_QUEUE;\n\t\t\t     ++val, srp = srp ? srp->nextrp : srp) {\n\t\t\t\tmemset(&rinfo[val], 0, SZ_SG_REQ_INFO);\n\t\t\t\tif (srp) {\n\t\t\t\t\trinfo[val].req_state = srp->done + 1;\n\t\t\t\t\trinfo[val].problem =\n\t\t\t\t\t    srp->header.masked_status & \n\t\t\t\t\t    srp->header.host_status & \n\t\t\t\t\t    srp->header.driver_status;\n\t\t\t\t\tif (srp->done)\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t\tsrp->header.duration;\n\t\t\t\t\telse {\n\t\t\t\t\t\tms = jiffies_to_msecs(jiffies);\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t    (ms > srp->header.duration) ?\n\t\t\t\t\t\t    (ms - srp->header.duration) : 0;\n\t\t\t\t\t}\n\t\t\t\t\trinfo[val].orphan = srp->orphan;\n\t\t\t\t\trinfo[val].sg_io_owned =\n\t\t\t\t\t\t\tsrp->sg_io_owned;\n\t\t\t\t\trinfo[val].pack_id =\n\t\t\t\t\t\t\tsrp->header.pack_id;\n\t\t\t\t\trinfo[val].usr_ptr =\n\t\t\t\t\t\t\tsrp->header.usr_ptr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t\tresult = __copy_to_user(p, rinfo, \n\t\t\t\t\t\tSZ_SG_REQ_INFO * SG_MAX_QUEUE);\n\t\t\tresult = result ? -EFAULT : 0;\n\t\t\tkfree(rinfo);\n\t\t\treturn result;\n\t\t}\n\tcase SG_EMULATED_HOST:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\treturn put_user(sdp->device->host->hostt->emulated, ip);\n\tcase SCSI_IOCTL_SEND_COMMAND:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (read_only) {\n\t\t\tunsigned char opcode = WRITE_6;\n\t\t\tScsi_Ioctl_Command __user *siocp = p;\n\n\t\t\tif (copy_from_user(&opcode, siocp->data, 1))\n\t\t\t\treturn -EFAULT;\n\t\t\tif (sg_allow_access(filp, &opcode))\n\t\t\t\treturn -EPERM;\n\t\t}\n\t\treturn sg_scsi_ioctl(sdp->device->request_queue, NULL, filp->f_mode, p);\n\tcase SG_SET_DEBUG:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsdp->sgdebug = (char) val;\n\t\treturn 0;\n\tcase BLKSECTGET:\n\t\treturn put_user(max_sectors_bytes(sdp->device->request_queue),\n\t\t\t\tip);\n\tcase BLKTRACESETUP:\n\t\treturn blk_trace_setup(sdp->device->request_queue,\n\t\t\t\t       sdp->disk->disk_name,\n\t\t\t\t       MKDEV(SCSI_GENERIC_MAJOR, sdp->index),\n\t\t\t\t       NULL,\n\t\t\t\t       (char *)arg);\n\tcase BLKTRACESTART:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 1);\n\tcase BLKTRACESTOP:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 0);\n\tcase BLKTRACETEARDOWN:\n\t\treturn blk_trace_remove(sdp->device->request_queue);\n\tcase SCSI_IOCTL_GET_IDLUN:\n\tcase SCSI_IOCTL_GET_BUS_NUMBER:\n\tcase SCSI_IOCTL_PROBE_HOST:\n\tcase SG_GET_TRANSFORM:\n\tcase SG_SCSI_RESET:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tdefault:\n\t\tif (read_only)\n\t\t\treturn -EPERM;\t/* don't know so take safe approach */\n\t\tbreak;\n\t}\n\n\tresult = scsi_ioctl_block_when_processing_errors(sdp->device,\n\t\t\tcmd_in, filp->f_flags & O_NDELAY);\n\tif (result)\n\t\treturn result;\n\treturn scsi_ioctl(sdp->device, cmd_in, p);\n}",
      "modified_lines": {
        "added": [
          "\t\tif (val > SG_MAX_CDB_SIZE)",
          "\t\t\treturn -ENOMEM;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation for the command size input in the SG_NEXT_CMD_LEN ioctl call.",
      "trigger_condition": "An attacker provides a large command size input in the SG_NEXT_CMD_LEN ioctl call, leading to a stack-based buffer overflow in the sg_write function.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the command size input exceeds a predefined maximum value, allowing a potential buffer overflow during the sg_write operation.",
      "id": 119,
      "code_after_change_normalized": "static long\nFUN1(struct file *VAR1, unsigned int VAR2, unsigned long VAR3)\n{\nvoid VAR5 *VAR4 = (void VAR5 *)VAR3;\nint __user *VAR6 = VAR4;\nint VAR7, VAR8, VAR9;\nSg_device *VAR10;\nSg_fd *VAR11;\nSg_request *VAR12;\nunsigned long VAR13;\nif ((!(VAR11 = (VAR14 *) VAR1->VAR15)) || (!(VAR10 = VAR11->VAR16)))\nreturn -VAR17;\nFUN2(3, FUN3(VAR18, VAR10,\n\"STR\", (int) VAR2));\nVAR9 = (VAR19 != (VAR1->VAR20 & VAR21));\nswitch (VAR2) {\ncase VAR22:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nif (!FUN5(VAR10->VAR25))\nreturn -VAR17;\nif (!FUN6(VAR26, VAR4, VAR27))\nreturn -VAR28;\nVAR7 = FUN7(VAR11, VAR1, VAR4, VAR27,\n1, VAR9, 1, &VAR12);\nif (VAR7 < 0)\nreturn VAR7;\nVAR7 = FUN8(VAR11->VAR29,\n(FUN9(VAR11, VAR12) || FUN4(&VAR10->VAR23)));\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nFUN10(&VAR11->VAR30);\nif (VAR12->VAR31) {\nVAR12->VAR31 = 2;\nFUN11(&VAR11->VAR30);\nVAR7 = FUN12(VAR11, VAR4, VAR27, VAR12);\nreturn (VAR7 < 0) ? VAR7 : 0;\n}\nVAR12->VAR32 = 1;\nFUN11(&VAR11->VAR30);\nreturn VAR7;\t\ncase VAR33:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nif (VAR8 < 0)\nreturn -VAR34;\nif (VAR8 >= FUN14((VAR35)VAR36, VAR37, VAR38))\nVAR8 = FUN15(VAR35, FUN14((VAR35)VAR36, VAR37, VAR38),\nVAR36);\nVAR11->VAR39 = VAR8;\nVAR11->VAR40 = FUN14(VAR8, VAR38, VAR37);\nreturn 0;\ncase VAR41:\t\nreturn VAR11->VAR39;\ncase VAR42:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nif (VAR8) {\nVAR11->VAR43 = 1;\nif ((0 == VAR11->VAR43) && (0 == FUN16(VAR11))) {\nVAR8 = (int) VAR11->VAR44.VAR45;\nFUN17(VAR11, &VAR11->VAR44);\nFUN18(VAR11, VAR8);\n}\n} else {\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nVAR11->VAR43 = VAR10->VAR25->VAR46->VAR47;\n}\nreturn 0;\ncase VAR48:\nreturn FUN19((int) VAR11->VAR43, VAR6);\ncase VAR49:\nif (!FUN6(VAR26, VAR4, sizeof (VAR50)))\nreturn -VAR28;\nelse {\nsg_scsi_id_t __user *VAR51 = VAR4;\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nFUN20((int) VAR10->VAR25->VAR46->VAR52,\n&VAR51->VAR52);\nFUN20((int) VAR10->VAR25->VAR53,\n&VAR51->VAR53);\nFUN20((int) VAR10->VAR25->VAR54, &VAR51->VAR55);\nFUN20((int) VAR10->VAR25->VAR56, &VAR51->VAR56);\nFUN20((int) VAR10->VAR25->VAR57, &VAR51->VAR58);\nFUN20((short) VAR10->VAR25->VAR46->VAR59,\n&VAR51->VAR60);\nFUN20((short) VAR10->VAR25->VAR61,\n&VAR51->VAR62);\nFUN20(0, &VAR51->VAR63[0]);\nFUN20(0, &VAR51->VAR63[1]);\nreturn 0;\n}\ncase VAR64:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR11->VAR65 = VAR8 ? 1 : 0;\nreturn 0;\ncase VAR66:\nif (!FUN6(VAR26, VAR6, sizeof (int)))\nreturn -VAR28;\nFUN21(&VAR11->VAR30, VAR13);\nfor (VAR12 = VAR11->VAR67; VAR12; VAR12 = VAR12->VAR68) {\nif ((1 == VAR12->VAR31) && (!VAR12->VAR69)) {\nFUN22(&VAR11->VAR30,\nVAR13);\nFUN20(VAR12->VAR70.VAR71, VAR6);\nreturn 0;\n}\n}\nFUN22(&VAR11->VAR30, VAR13);\nFUN20(-1, VAR6);\nreturn 0;\ncase VAR72:\nFUN21(&VAR11->VAR30, VAR13);\nfor (VAR8 = 0, VAR12 = VAR11->VAR67; VAR12; VAR12 = VAR12->VAR68) {\nif ((1 == VAR12->VAR31) && (!VAR12->VAR69))\n++VAR8;\n}\nFUN22(&VAR11->VAR30, VAR13);\nreturn FUN19(VAR8, VAR6);\ncase VAR73:\nreturn FUN19(VAR10->VAR74, VAR6);\ncase VAR75:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nif (VAR8 < 0)\nreturn -VAR76;\nVAR8 = FUN15(int, VAR8,\nFUN23(VAR10->VAR25->VAR77));\nif (VAR8 != VAR11->VAR44.VAR45) {\nif (FUN16(VAR11) || VAR11->VAR78)\nreturn -VAR79;\nFUN17(VAR11, &VAR11->VAR44);\nFUN18(VAR11, VAR8);\n}\nreturn 0;\ncase VAR80:\nVAR8 = FUN15(int, VAR11->VAR44.VAR45,\nFUN23(VAR10->VAR25->VAR77));\nreturn FUN19(VAR8, VAR6);\ncase VAR81:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR11->VAR82 = VAR8 ? 1 : 0;\nreturn 0;\ncase VAR83:\nreturn FUN19((int) VAR11->VAR82, VAR6);\ncase VAR84:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR11->VAR85 = VAR8;\nreturn 0;\ncase VAR86:\nreturn FUN19((int) VAR11->VAR85, VAR6);\ncase VAR87:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nif (VAR8 > VAR88)\nreturn -VAR89;\nVAR11->VAR90 = (VAR8 > 0) ? VAR8 : 0;\nreturn 0;\ncase VAR91:\nreturn FUN19(VAR92, VAR6);\ncase VAR93:\nVAR8 = (VAR10->VAR25 ? 1 : 0);\nreturn FUN19(VAR8, VAR6);\ncase VAR94:\nif (!FUN6(VAR26, VAR4, VAR95 * VAR96))\nreturn -VAR28;\nelse {\nsg_req_info_t *VAR97;\nunsigned int VAR98;\nVAR97 = FUN24(VAR95 * VAR96,\nVAR99);\nif (!VAR97)\nreturn -VAR89;\nFUN21(&VAR11->VAR30, VAR13);\nfor (VAR12 = VAR11->VAR67, VAR8 = 0; VAR8 < VAR96;\n++VAR8, VAR12 = VAR12 ? VAR12->VAR68 : VAR12) {\nFUN25(&VAR97[VAR8], 0, VAR95);\nif (VAR12) {\nVAR97[VAR8].VAR100 = VAR12->VAR31 + 1;\nVAR97[VAR8].VAR101 =\nVAR12->VAR70.VAR102 &\nVAR12->VAR70.VAR103 &\nVAR12->VAR70.VAR104;\nif (VAR12->VAR31)\nVAR97[VAR8].VAR105 =\nVAR12->VAR70.VAR105;\nelse {\nVAR98 = FUN26(VAR106);\nVAR97[VAR8].VAR105 =\n(VAR98 > VAR12->VAR70.VAR105) ?\n(VAR98 - VAR12->VAR70.VAR105) : 0;\n}\nVAR97[VAR8].VAR32 = VAR12->VAR32;\nVAR97[VAR8].VAR69 =\nVAR12->VAR69;\nVAR97[VAR8].VAR71 =\nVAR12->VAR70.VAR71;\nVAR97[VAR8].VAR107 =\nVAR12->VAR70.VAR107;\n}\n}\nFUN22(&VAR11->VAR30, VAR13);\nVAR7 = FUN27(VAR4, VAR97,\nVAR95 * VAR96);\nVAR7 = VAR7 ? -VAR28 : 0;\nFUN28(VAR97);\nreturn VAR7;\n}\ncase VAR108:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nreturn FUN19(VAR10->VAR25->VAR46->VAR109->VAR110, VAR6);\ncase VAR111:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nif (VAR9) {\nunsigned char VAR112 = VAR113;\nScsi_Ioctl_Command __user *VAR114 = VAR4;\nif (FUN29(&VAR112, VAR114->VAR115, 1))\nreturn -VAR28;\nif (FUN30(VAR1, &VAR112))\nreturn -VAR116;\n}\nreturn FUN31(VAR10->VAR25->VAR77, NULL, VAR1->VAR117, VAR4);\ncase VAR118:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR10->VAR119 = (char) VAR8;\nreturn 0;\ncase VAR120:\nreturn FUN19(FUN23(VAR10->VAR25->VAR77),\nVAR6);\ncase VAR121:\nreturn FUN32(VAR10->VAR25->VAR77,\nVAR10->VAR122->VAR123,\nFUN33(VAR124, VAR10->VAR125),\nNULL,\n(char *)VAR3);\ncase VAR126:\nreturn FUN34(VAR10->VAR25->VAR77, 1);\ncase VAR127:\nreturn FUN34(VAR10->VAR25->VAR77, 0);\ncase VAR128:\nreturn FUN35(VAR10->VAR25->VAR77);\ncase VAR129:\ncase VAR130:\ncase VAR131:\ncase VAR132:\ncase VAR133:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nbreak;\ndefault:\nif (VAR9)\nreturn -VAR116;\t\nbreak;\n}\nVAR7 = FUN36(VAR10->VAR25,\nVAR2, VAR1->VAR20 & VAR134);\nif (VAR7)\nreturn VAR7;\nreturn FUN37(VAR10->VAR25, VAR2, VAR4);\n}\n",
      "code_before_change_normalized": "static long\nFUN1(struct file *VAR1, unsigned int VAR2, unsigned long VAR3)\n{\nvoid VAR5 *VAR4 = (void VAR5 *)VAR3;\nint __user *VAR6 = VAR4;\nint VAR7, VAR8, VAR9;\nSg_device *VAR10;\nSg_fd *VAR11;\nSg_request *VAR12;\nunsigned long VAR13;\nif ((!(VAR11 = (VAR14 *) VAR1->VAR15)) || (!(VAR10 = VAR11->VAR16)))\nreturn -VAR17;\nFUN2(3, FUN3(VAR18, VAR10,\n\"STR\", (int) VAR2));\nVAR9 = (VAR19 != (VAR1->VAR20 & VAR21));\nswitch (VAR2) {\ncase VAR22:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nif (!FUN5(VAR10->VAR25))\nreturn -VAR17;\nif (!FUN6(VAR26, VAR4, VAR27))\nreturn -VAR28;\nVAR7 = FUN7(VAR11, VAR1, VAR4, VAR27,\n1, VAR9, 1, &VAR12);\nif (VAR7 < 0)\nreturn VAR7;\nVAR7 = FUN8(VAR11->VAR29,\n(FUN9(VAR11, VAR12) || FUN4(&VAR10->VAR23)));\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nFUN10(&VAR11->VAR30);\nif (VAR12->VAR31) {\nVAR12->VAR31 = 2;\nFUN11(&VAR11->VAR30);\nVAR7 = FUN12(VAR11, VAR4, VAR27, VAR12);\nreturn (VAR7 < 0) ? VAR7 : 0;\n}\nVAR12->VAR32 = 1;\nFUN11(&VAR11->VAR30);\nreturn VAR7;\t\ncase VAR33:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nif (VAR8 < 0)\nreturn -VAR34;\nif (VAR8 >= FUN14((VAR35)VAR36, VAR37, VAR38))\nVAR8 = FUN15(VAR35, FUN14((VAR35)VAR36, VAR37, VAR38),\nVAR36);\nVAR11->VAR39 = VAR8;\nVAR11->VAR40 = FUN14(VAR8, VAR38, VAR37);\nreturn 0;\ncase VAR41:\t\nreturn VAR11->VAR39;\ncase VAR42:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nif (VAR8) {\nVAR11->VAR43 = 1;\nif ((0 == VAR11->VAR43) && (0 == FUN16(VAR11))) {\nVAR8 = (int) VAR11->VAR44.VAR45;\nFUN17(VAR11, &VAR11->VAR44);\nFUN18(VAR11, VAR8);\n}\n} else {\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nVAR11->VAR43 = VAR10->VAR25->VAR46->VAR47;\n}\nreturn 0;\ncase VAR48:\nreturn FUN19((int) VAR11->VAR43, VAR6);\ncase VAR49:\nif (!FUN6(VAR26, VAR4, sizeof (VAR50)))\nreturn -VAR28;\nelse {\nsg_scsi_id_t __user *VAR51 = VAR4;\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nFUN20((int) VAR10->VAR25->VAR46->VAR52,\n&VAR51->VAR52);\nFUN20((int) VAR10->VAR25->VAR53,\n&VAR51->VAR53);\nFUN20((int) VAR10->VAR25->VAR54, &VAR51->VAR55);\nFUN20((int) VAR10->VAR25->VAR56, &VAR51->VAR56);\nFUN20((int) VAR10->VAR25->VAR57, &VAR51->VAR58);\nFUN20((short) VAR10->VAR25->VAR46->VAR59,\n&VAR51->VAR60);\nFUN20((short) VAR10->VAR25->VAR61,\n&VAR51->VAR62);\nFUN20(0, &VAR51->VAR63[0]);\nFUN20(0, &VAR51->VAR63[1]);\nreturn 0;\n}\ncase VAR64:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR11->VAR65 = VAR8 ? 1 : 0;\nreturn 0;\ncase VAR66:\nif (!FUN6(VAR26, VAR6, sizeof (int)))\nreturn -VAR28;\nFUN21(&VAR11->VAR30, VAR13);\nfor (VAR12 = VAR11->VAR67; VAR12; VAR12 = VAR12->VAR68) {\nif ((1 == VAR12->VAR31) && (!VAR12->VAR69)) {\nFUN22(&VAR11->VAR30,\nVAR13);\nFUN20(VAR12->VAR70.VAR71, VAR6);\nreturn 0;\n}\n}\nFUN22(&VAR11->VAR30, VAR13);\nFUN20(-1, VAR6);\nreturn 0;\ncase VAR72:\nFUN21(&VAR11->VAR30, VAR13);\nfor (VAR8 = 0, VAR12 = VAR11->VAR67; VAR12; VAR12 = VAR12->VAR68) {\nif ((1 == VAR12->VAR31) && (!VAR12->VAR69))\n++VAR8;\n}\nFUN22(&VAR11->VAR30, VAR13);\nreturn FUN19(VAR8, VAR6);\ncase VAR73:\nreturn FUN19(VAR10->VAR74, VAR6);\ncase VAR75:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nif (VAR8 < 0)\nreturn -VAR76;\nVAR8 = FUN15(int, VAR8,\nFUN23(VAR10->VAR25->VAR77));\nif (VAR8 != VAR11->VAR44.VAR45) {\nif (FUN16(VAR11) || VAR11->VAR78)\nreturn -VAR79;\nFUN17(VAR11, &VAR11->VAR44);\nFUN18(VAR11, VAR8);\n}\nreturn 0;\ncase VAR80:\nVAR8 = FUN15(int, VAR11->VAR44.VAR45,\nFUN23(VAR10->VAR25->VAR77));\nreturn FUN19(VAR8, VAR6);\ncase VAR81:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR11->VAR82 = VAR8 ? 1 : 0;\nreturn 0;\ncase VAR83:\nreturn FUN19((int) VAR11->VAR82, VAR6);\ncase VAR84:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR11->VAR85 = VAR8;\nreturn 0;\ncase VAR86:\nreturn FUN19((int) VAR11->VAR85, VAR6);\ncase VAR87:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR11->VAR88 = (VAR8 > 0) ? VAR8 : 0;\nreturn 0;\ncase VAR89:\nreturn FUN19(VAR90, VAR6);\ncase VAR91:\nVAR8 = (VAR10->VAR25 ? 1 : 0);\nreturn FUN19(VAR8, VAR6);\ncase VAR92:\nif (!FUN6(VAR26, VAR4, VAR93 * VAR94))\nreturn -VAR28;\nelse {\nsg_req_info_t *VAR95;\nunsigned int VAR96;\nVAR95 = FUN24(VAR93 * VAR94,\nVAR97);\nif (!VAR95)\nreturn -VAR98;\nFUN21(&VAR11->VAR30, VAR13);\nfor (VAR12 = VAR11->VAR67, VAR8 = 0; VAR8 < VAR94;\n++VAR8, VAR12 = VAR12 ? VAR12->VAR68 : VAR12) {\nFUN25(&VAR95[VAR8], 0, VAR93);\nif (VAR12) {\nVAR95[VAR8].VAR99 = VAR12->VAR31 + 1;\nVAR95[VAR8].VAR100 =\nVAR12->VAR70.VAR101 &\nVAR12->VAR70.VAR102 &\nVAR12->VAR70.VAR103;\nif (VAR12->VAR31)\nVAR95[VAR8].VAR104 =\nVAR12->VAR70.VAR104;\nelse {\nVAR96 = FUN26(VAR105);\nVAR95[VAR8].VAR104 =\n(VAR96 > VAR12->VAR70.VAR104) ?\n(VAR96 - VAR12->VAR70.VAR104) : 0;\n}\nVAR95[VAR8].VAR32 = VAR12->VAR32;\nVAR95[VAR8].VAR69 =\nVAR12->VAR69;\nVAR95[VAR8].VAR71 =\nVAR12->VAR70.VAR71;\nVAR95[VAR8].VAR106 =\nVAR12->VAR70.VAR106;\n}\n}\nFUN22(&VAR11->VAR30, VAR13);\nVAR7 = FUN27(VAR4, VAR95,\nVAR93 * VAR94);\nVAR7 = VAR7 ? -VAR28 : 0;\nFUN28(VAR95);\nreturn VAR7;\n}\ncase VAR107:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nreturn FUN19(VAR10->VAR25->VAR46->VAR108->VAR109, VAR6);\ncase VAR110:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nif (VAR9) {\nunsigned char VAR111 = VAR112;\nScsi_Ioctl_Command __user *VAR113 = VAR4;\nif (FUN29(&VAR111, VAR113->VAR114, 1))\nreturn -VAR28;\nif (FUN30(VAR1, &VAR111))\nreturn -VAR115;\n}\nreturn FUN31(VAR10->VAR25->VAR77, NULL, VAR1->VAR116, VAR4);\ncase VAR117:\nVAR7 = FUN13(VAR8, VAR6);\nif (VAR7)\nreturn VAR7;\nVAR10->VAR118 = (char) VAR8;\nreturn 0;\ncase VAR119:\nreturn FUN19(FUN23(VAR10->VAR25->VAR77),\nVAR6);\ncase VAR120:\nreturn FUN32(VAR10->VAR25->VAR77,\nVAR10->VAR121->VAR122,\nFUN33(VAR123, VAR10->VAR124),\nNULL,\n(char *)VAR3);\ncase VAR125:\nreturn FUN34(VAR10->VAR25->VAR77, 1);\ncase VAR126:\nreturn FUN34(VAR10->VAR25->VAR77, 0);\ncase VAR127:\nreturn FUN35(VAR10->VAR25->VAR77);\ncase VAR128:\ncase VAR129:\ncase VAR130:\ncase VAR131:\ncase VAR132:\nif (FUN4(&VAR10->VAR23))\nreturn -VAR24;\nbreak;\ndefault:\nif (VAR9)\nreturn -VAR115;\t\nbreak;\n}\nVAR7 = FUN36(VAR10->VAR25,\nVAR2, VAR1->VAR20 & VAR133);\nif (VAR7)\nreturn VAR7;\nreturn FUN37(VAR10->VAR25, VAR2, VAR4);\n}\n",
      "code_after_change_raw": "static long\nsg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\nvoid __user *p = (void __user *)arg;\nint __user *ip = p;\nint result, val, read_only;\nSg_device *sdp;\nSg_fd *sfp;\nSg_request *srp;\nunsigned long iflags;\nif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\nreturn -ENXIO;\nSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\"sg_ioctl: cmd=0x%x\\n\", (int) cmd_in));\nread_only = (O_RDWR != (filp->f_flags & O_ACCMODE));\nswitch (cmd_in) {\ncase SG_IO:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nif (!scsi_block_when_processing_errors(sdp->device))\nreturn -ENXIO;\nif (!access_ok(VERIFY_WRITE, p, SZ_SG_IO_HDR))\nreturn -EFAULT;\nresult = sg_new_write(sfp, filp, p, SZ_SG_IO_HDR,\n1, read_only, 1, &srp);\nif (result < 0)\nreturn result;\nresult = wait_event_interruptible(sfp->read_wait,\n(srp_done(sfp, srp) || atomic_read(&sdp->detaching)));\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nwrite_lock_irq(&sfp->rq_list_lock);\nif (srp->done) {\nsrp->done = 2;\nwrite_unlock_irq(&sfp->rq_list_lock);\nresult = sg_new_read(sfp, p, SZ_SG_IO_HDR, srp);\nreturn (result < 0) ? result : 0;\n}\nsrp->orphan = 1;\nwrite_unlock_irq(&sfp->rq_list_lock);\nreturn result;\t\ncase SG_SET_TIMEOUT:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nif (val < 0)\nreturn -EIO;\nif (val >= mult_frac((s64)INT_MAX, USER_HZ, HZ))\nval = min_t(s64, mult_frac((s64)INT_MAX, USER_HZ, HZ),\nINT_MAX);\nsfp->timeout_user = val;\nsfp->timeout = mult_frac(val, HZ, USER_HZ);\nreturn 0;\ncase SG_GET_TIMEOUT:\t\nreturn sfp->timeout_user;\ncase SG_SET_FORCE_LOW_DMA:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nif (val) {\nsfp->low_dma = 1;\nif ((0 == sfp->low_dma) && (0 == sg_res_in_use(sfp))) {\nval = (int) sfp->reserve.bufflen;\nsg_remove_scat(sfp, &sfp->reserve);\nsg_build_reserve(sfp, val);\n}\n} else {\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nsfp->low_dma = sdp->device->host->unchecked_isa_dma;\n}\nreturn 0;\ncase SG_GET_LOW_DMA:\nreturn put_user((int) sfp->low_dma, ip);\ncase SG_GET_SCSI_ID:\nif (!access_ok(VERIFY_WRITE, p, sizeof (sg_scsi_id_t)))\nreturn -EFAULT;\nelse {\nsg_scsi_id_t __user *sg_idp = p;\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\n__put_user((int) sdp->device->host->host_no,\n&sg_idp->host_no);\n__put_user((int) sdp->device->channel,\n&sg_idp->channel);\n__put_user((int) sdp->device->id, &sg_idp->scsi_id);\n__put_user((int) sdp->device->lun, &sg_idp->lun);\n__put_user((int) sdp->device->type, &sg_idp->scsi_type);\n__put_user((short) sdp->device->host->cmd_per_lun,\n&sg_idp->h_cmd_per_lun);\n__put_user((short) sdp->device->queue_depth,\n&sg_idp->d_queue_depth);\n__put_user(0, &sg_idp->unused[0]);\n__put_user(0, &sg_idp->unused[1]);\nreturn 0;\n}\ncase SG_SET_FORCE_PACK_ID:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsfp->force_packid = val ? 1 : 0;\nreturn 0;\ncase SG_GET_PACK_ID:\nif (!access_ok(VERIFY_WRITE, ip, sizeof (int)))\nreturn -EFAULT;\nread_lock_irqsave(&sfp->rq_list_lock, iflags);\nfor (srp = sfp->headrp; srp; srp = srp->nextrp) {\nif ((1 == srp->done) && (!srp->sg_io_owned)) {\nread_unlock_irqrestore(&sfp->rq_list_lock,\niflags);\n__put_user(srp->header.pack_id, ip);\nreturn 0;\n}\n}\nread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n__put_user(-1, ip);\nreturn 0;\ncase SG_GET_NUM_WAITING:\nread_lock_irqsave(&sfp->rq_list_lock, iflags);\nfor (val = 0, srp = sfp->headrp; srp; srp = srp->nextrp) {\nif ((1 == srp->done) && (!srp->sg_io_owned))\n++val;\n}\nread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\nreturn put_user(val, ip);\ncase SG_GET_SG_TABLESIZE:\nreturn put_user(sdp->sg_tablesize, ip);\ncase SG_SET_RESERVED_SIZE:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nif (val < 0)\nreturn -EINVAL;\nval = min_t(int, val,\nmax_sectors_bytes(sdp->device->request_queue));\nif (val != sfp->reserve.bufflen) {\nif (sg_res_in_use(sfp) || sfp->mmap_called)\nreturn -EBUSY;\nsg_remove_scat(sfp, &sfp->reserve);\nsg_build_reserve(sfp, val);\n}\nreturn 0;\ncase SG_GET_RESERVED_SIZE:\nval = min_t(int, sfp->reserve.bufflen,\nmax_sectors_bytes(sdp->device->request_queue));\nreturn put_user(val, ip);\ncase SG_SET_COMMAND_Q:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsfp->cmd_q = val ? 1 : 0;\nreturn 0;\ncase SG_GET_COMMAND_Q:\nreturn put_user((int) sfp->cmd_q, ip);\ncase SG_SET_KEEP_ORPHAN:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsfp->keep_orphan = val;\nreturn 0;\ncase SG_GET_KEEP_ORPHAN:\nreturn put_user((int) sfp->keep_orphan, ip);\ncase SG_NEXT_CMD_LEN:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nif (val > SG_MAX_CDB_SIZE)\nreturn -ENOMEM;\nsfp->next_cmd_len = (val > 0) ? val : 0;\nreturn 0;\ncase SG_GET_VERSION_NUM:\nreturn put_user(sg_version_num, ip);\ncase SG_GET_ACCESS_COUNT:\nval = (sdp->device ? 1 : 0);\nreturn put_user(val, ip);\ncase SG_GET_REQUEST_TABLE:\nif (!access_ok(VERIFY_WRITE, p, SZ_SG_REQ_INFO * SG_MAX_QUEUE))\nreturn -EFAULT;\nelse {\nsg_req_info_t *rinfo;\nunsigned int ms;\nrinfo = kmalloc(SZ_SG_REQ_INFO * SG_MAX_QUEUE,\nGFP_KERNEL);\nif (!rinfo)\nreturn -ENOMEM;\nread_lock_irqsave(&sfp->rq_list_lock, iflags);\nfor (srp = sfp->headrp, val = 0; val < SG_MAX_QUEUE;\n++val, srp = srp ? srp->nextrp : srp) {\nmemset(&rinfo[val], 0, SZ_SG_REQ_INFO);\nif (srp) {\nrinfo[val].req_state = srp->done + 1;\nrinfo[val].problem =\nsrp->header.masked_status &\nsrp->header.host_status &\nsrp->header.driver_status;\nif (srp->done)\nrinfo[val].duration =\nsrp->header.duration;\nelse {\nms = jiffies_to_msecs(jiffies);\nrinfo[val].duration =\n(ms > srp->header.duration) ?\n(ms - srp->header.duration) : 0;\n}\nrinfo[val].orphan = srp->orphan;\nrinfo[val].sg_io_owned =\nsrp->sg_io_owned;\nrinfo[val].pack_id =\nsrp->header.pack_id;\nrinfo[val].usr_ptr =\nsrp->header.usr_ptr;\n}\n}\nread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\nresult = __copy_to_user(p, rinfo,\nSZ_SG_REQ_INFO * SG_MAX_QUEUE);\nresult = result ? -EFAULT : 0;\nkfree(rinfo);\nreturn result;\n}\ncase SG_EMULATED_HOST:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nreturn put_user(sdp->device->host->hostt->emulated, ip);\ncase SCSI_IOCTL_SEND_COMMAND:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nif (read_only) {\nunsigned char opcode = WRITE_6;\nScsi_Ioctl_Command __user *siocp = p;\nif (copy_from_user(&opcode, siocp->data, 1))\nreturn -EFAULT;\nif (sg_allow_access(filp, &opcode))\nreturn -EPERM;\n}\nreturn sg_scsi_ioctl(sdp->device->request_queue, NULL, filp->f_mode, p);\ncase SG_SET_DEBUG:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsdp->sgdebug = (char) val;\nreturn 0;\ncase BLKSECTGET:\nreturn put_user(max_sectors_bytes(sdp->device->request_queue),\nip);\ncase BLKTRACESETUP:\nreturn blk_trace_setup(sdp->device->request_queue,\nsdp->disk->disk_name,\nMKDEV(SCSI_GENERIC_MAJOR, sdp->index),\nNULL,\n(char *)arg);\ncase BLKTRACESTART:\nreturn blk_trace_startstop(sdp->device->request_queue, 1);\ncase BLKTRACESTOP:\nreturn blk_trace_startstop(sdp->device->request_queue, 0);\ncase BLKTRACETEARDOWN:\nreturn blk_trace_remove(sdp->device->request_queue);\ncase SCSI_IOCTL_GET_IDLUN:\ncase SCSI_IOCTL_GET_BUS_NUMBER:\ncase SCSI_IOCTL_PROBE_HOST:\ncase SG_GET_TRANSFORM:\ncase SG_SCSI_RESET:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nbreak;\ndefault:\nif (read_only)\nreturn -EPERM;\t\nbreak;\n}\nresult = scsi_ioctl_block_when_processing_errors(sdp->device,\ncmd_in, filp->f_flags & O_NDELAY);\nif (result)\nreturn result;\nreturn scsi_ioctl(sdp->device, cmd_in, p);\n}\n",
      "code_before_change_raw": "static long\nsg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\nvoid __user *p = (void __user *)arg;\nint __user *ip = p;\nint result, val, read_only;\nSg_device *sdp;\nSg_fd *sfp;\nSg_request *srp;\nunsigned long iflags;\nif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\nreturn -ENXIO;\nSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\"sg_ioctl: cmd=0x%x\\n\", (int) cmd_in));\nread_only = (O_RDWR != (filp->f_flags & O_ACCMODE));\nswitch (cmd_in) {\ncase SG_IO:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nif (!scsi_block_when_processing_errors(sdp->device))\nreturn -ENXIO;\nif (!access_ok(VERIFY_WRITE, p, SZ_SG_IO_HDR))\nreturn -EFAULT;\nresult = sg_new_write(sfp, filp, p, SZ_SG_IO_HDR,\n1, read_only, 1, &srp);\nif (result < 0)\nreturn result;\nresult = wait_event_interruptible(sfp->read_wait,\n(srp_done(sfp, srp) || atomic_read(&sdp->detaching)));\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nwrite_lock_irq(&sfp->rq_list_lock);\nif (srp->done) {\nsrp->done = 2;\nwrite_unlock_irq(&sfp->rq_list_lock);\nresult = sg_new_read(sfp, p, SZ_SG_IO_HDR, srp);\nreturn (result < 0) ? result : 0;\n}\nsrp->orphan = 1;\nwrite_unlock_irq(&sfp->rq_list_lock);\nreturn result;\t\ncase SG_SET_TIMEOUT:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nif (val < 0)\nreturn -EIO;\nif (val >= mult_frac((s64)INT_MAX, USER_HZ, HZ))\nval = min_t(s64, mult_frac((s64)INT_MAX, USER_HZ, HZ),\nINT_MAX);\nsfp->timeout_user = val;\nsfp->timeout = mult_frac(val, HZ, USER_HZ);\nreturn 0;\ncase SG_GET_TIMEOUT:\t\nreturn sfp->timeout_user;\ncase SG_SET_FORCE_LOW_DMA:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nif (val) {\nsfp->low_dma = 1;\nif ((0 == sfp->low_dma) && (0 == sg_res_in_use(sfp))) {\nval = (int) sfp->reserve.bufflen;\nsg_remove_scat(sfp, &sfp->reserve);\nsg_build_reserve(sfp, val);\n}\n} else {\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nsfp->low_dma = sdp->device->host->unchecked_isa_dma;\n}\nreturn 0;\ncase SG_GET_LOW_DMA:\nreturn put_user((int) sfp->low_dma, ip);\ncase SG_GET_SCSI_ID:\nif (!access_ok(VERIFY_WRITE, p, sizeof (sg_scsi_id_t)))\nreturn -EFAULT;\nelse {\nsg_scsi_id_t __user *sg_idp = p;\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\n__put_user((int) sdp->device->host->host_no,\n&sg_idp->host_no);\n__put_user((int) sdp->device->channel,\n&sg_idp->channel);\n__put_user((int) sdp->device->id, &sg_idp->scsi_id);\n__put_user((int) sdp->device->lun, &sg_idp->lun);\n__put_user((int) sdp->device->type, &sg_idp->scsi_type);\n__put_user((short) sdp->device->host->cmd_per_lun,\n&sg_idp->h_cmd_per_lun);\n__put_user((short) sdp->device->queue_depth,\n&sg_idp->d_queue_depth);\n__put_user(0, &sg_idp->unused[0]);\n__put_user(0, &sg_idp->unused[1]);\nreturn 0;\n}\ncase SG_SET_FORCE_PACK_ID:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsfp->force_packid = val ? 1 : 0;\nreturn 0;\ncase SG_GET_PACK_ID:\nif (!access_ok(VERIFY_WRITE, ip, sizeof (int)))\nreturn -EFAULT;\nread_lock_irqsave(&sfp->rq_list_lock, iflags);\nfor (srp = sfp->headrp; srp; srp = srp->nextrp) {\nif ((1 == srp->done) && (!srp->sg_io_owned)) {\nread_unlock_irqrestore(&sfp->rq_list_lock,\niflags);\n__put_user(srp->header.pack_id, ip);\nreturn 0;\n}\n}\nread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n__put_user(-1, ip);\nreturn 0;\ncase SG_GET_NUM_WAITING:\nread_lock_irqsave(&sfp->rq_list_lock, iflags);\nfor (val = 0, srp = sfp->headrp; srp; srp = srp->nextrp) {\nif ((1 == srp->done) && (!srp->sg_io_owned))\n++val;\n}\nread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\nreturn put_user(val, ip);\ncase SG_GET_SG_TABLESIZE:\nreturn put_user(sdp->sg_tablesize, ip);\ncase SG_SET_RESERVED_SIZE:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nif (val < 0)\nreturn -EINVAL;\nval = min_t(int, val,\nmax_sectors_bytes(sdp->device->request_queue));\nif (val != sfp->reserve.bufflen) {\nif (sg_res_in_use(sfp) || sfp->mmap_called)\nreturn -EBUSY;\nsg_remove_scat(sfp, &sfp->reserve);\nsg_build_reserve(sfp, val);\n}\nreturn 0;\ncase SG_GET_RESERVED_SIZE:\nval = min_t(int, sfp->reserve.bufflen,\nmax_sectors_bytes(sdp->device->request_queue));\nreturn put_user(val, ip);\ncase SG_SET_COMMAND_Q:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsfp->cmd_q = val ? 1 : 0;\nreturn 0;\ncase SG_GET_COMMAND_Q:\nreturn put_user((int) sfp->cmd_q, ip);\ncase SG_SET_KEEP_ORPHAN:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsfp->keep_orphan = val;\nreturn 0;\ncase SG_GET_KEEP_ORPHAN:\nreturn put_user((int) sfp->keep_orphan, ip);\ncase SG_NEXT_CMD_LEN:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsfp->next_cmd_len = (val > 0) ? val : 0;\nreturn 0;\ncase SG_GET_VERSION_NUM:\nreturn put_user(sg_version_num, ip);\ncase SG_GET_ACCESS_COUNT:\nval = (sdp->device ? 1 : 0);\nreturn put_user(val, ip);\ncase SG_GET_REQUEST_TABLE:\nif (!access_ok(VERIFY_WRITE, p, SZ_SG_REQ_INFO * SG_MAX_QUEUE))\nreturn -EFAULT;\nelse {\nsg_req_info_t *rinfo;\nunsigned int ms;\nrinfo = kmalloc(SZ_SG_REQ_INFO * SG_MAX_QUEUE,\nGFP_KERNEL);\nif (!rinfo)\nreturn -ENOMEM;\nread_lock_irqsave(&sfp->rq_list_lock, iflags);\nfor (srp = sfp->headrp, val = 0; val < SG_MAX_QUEUE;\n++val, srp = srp ? srp->nextrp : srp) {\nmemset(&rinfo[val], 0, SZ_SG_REQ_INFO);\nif (srp) {\nrinfo[val].req_state = srp->done + 1;\nrinfo[val].problem =\nsrp->header.masked_status &\nsrp->header.host_status &\nsrp->header.driver_status;\nif (srp->done)\nrinfo[val].duration =\nsrp->header.duration;\nelse {\nms = jiffies_to_msecs(jiffies);\nrinfo[val].duration =\n(ms > srp->header.duration) ?\n(ms - srp->header.duration) : 0;\n}\nrinfo[val].orphan = srp->orphan;\nrinfo[val].sg_io_owned =\nsrp->sg_io_owned;\nrinfo[val].pack_id =\nsrp->header.pack_id;\nrinfo[val].usr_ptr =\nsrp->header.usr_ptr;\n}\n}\nread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\nresult = __copy_to_user(p, rinfo,\nSZ_SG_REQ_INFO * SG_MAX_QUEUE);\nresult = result ? -EFAULT : 0;\nkfree(rinfo);\nreturn result;\n}\ncase SG_EMULATED_HOST:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nreturn put_user(sdp->device->host->hostt->emulated, ip);\ncase SCSI_IOCTL_SEND_COMMAND:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nif (read_only) {\nunsigned char opcode = WRITE_6;\nScsi_Ioctl_Command __user *siocp = p;\nif (copy_from_user(&opcode, siocp->data, 1))\nreturn -EFAULT;\nif (sg_allow_access(filp, &opcode))\nreturn -EPERM;\n}\nreturn sg_scsi_ioctl(sdp->device->request_queue, NULL, filp->f_mode, p);\ncase SG_SET_DEBUG:\nresult = get_user(val, ip);\nif (result)\nreturn result;\nsdp->sgdebug = (char) val;\nreturn 0;\ncase BLKSECTGET:\nreturn put_user(max_sectors_bytes(sdp->device->request_queue),\nip);\ncase BLKTRACESETUP:\nreturn blk_trace_setup(sdp->device->request_queue,\nsdp->disk->disk_name,\nMKDEV(SCSI_GENERIC_MAJOR, sdp->index),\nNULL,\n(char *)arg);\ncase BLKTRACESTART:\nreturn blk_trace_startstop(sdp->device->request_queue, 1);\ncase BLKTRACESTOP:\nreturn blk_trace_startstop(sdp->device->request_queue, 0);\ncase BLKTRACETEARDOWN:\nreturn blk_trace_remove(sdp->device->request_queue);\ncase SCSI_IOCTL_GET_IDLUN:\ncase SCSI_IOCTL_GET_BUS_NUMBER:\ncase SCSI_IOCTL_PROBE_HOST:\ncase SG_GET_TRANSFORM:\ncase SG_SCSI_RESET:\nif (atomic_read(&sdp->detaching))\nreturn -ENODEV;\nbreak;\ndefault:\nif (read_only)\nreturn -EPERM;\t\nbreak;\n}\nresult = scsi_ioctl_block_when_processing_errors(sdp->device,\ncmd_in, filp->f_flags & O_NDELAY);\nif (result)\nreturn result;\nreturn scsi_ioctl(sdp->device, cmd_in, p);\n}\n"
    }
  ],
  "CVE-2017-7541": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for the length of the action frame in the brcmf_cfg80211_mgmt_tx function.",
        "trigger_condition": "Receiving a crafted NL80211_CMD_FRAME Netlink packet with a maliciously large length for the action frame.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the length of the action frame exceeds the maximum allowed size, leading to a potential buffer overflow and system crash."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the length of the action frame does not exceed the maximum allowed size before processing it. By validating the length, the code prevents buffer overflow and system crash vulnerabilities. In this case, the solution involves adding a check 'if (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN)' before handling the action frame.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-7541, which allows local users to cause a denial of service (buffer overflow and system crash) or possibly gain privileges via a crafted NL80211_CMD_FRAME Netlink packet.\n\nThe vulnerability arises from the lack of validation for the length of the action frame in the function brcmf_cfg80211_mgmt_tx. By adding the check `if (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN)` before processing the action frame, the code ensures that the length of the frame does not exceed the maximum allowed size. If the length is invalid, the function returns an error (-EINVAL) and prevents a potential buffer overflow.\n\nThis modification helps to prevent the exploitation of the vulnerability by enforcing proper bounds checking on the length of the action frame, thereby enhancing the security and stability of the system.",
      "GPT_purpose": "Transmit management frames in a Broadcom Wi-Fi driver.",
      "GPT_function": "\n1. Transmit management frames in the brcmf driver.\n2. Handle probe response packets for P2P functionality.\n3. Handle action frames for P2P functionality.\n4. Check and handle other types of management frames.",
      "CVE_id": "CVE-2017-7541",
      "code_before_change": "static int\nbrcmf_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,\n\t\t       struct cfg80211_mgmt_tx_params *params, u64 *cookie)\n{\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct ieee80211_channel *chan = params->chan;\n\tconst u8 *buf = params->buf;\n\tsize_t len = params->len;\n\tconst struct ieee80211_mgmt *mgmt;\n\tstruct brcmf_cfg80211_vif *vif;\n\ts32 err = 0;\n\ts32 ie_offset;\n\ts32 ie_len;\n\tstruct brcmf_fil_action_frame_le *action_frame;\n\tstruct brcmf_fil_af_params_le *af_params;\n\tbool ack;\n\ts32 chan_nr;\n\tu32 freq;\n\n\tbrcmf_dbg(TRACE, \"Enter\\n\");\n\n\t*cookie = 0;\n\n\tmgmt = (const struct ieee80211_mgmt *)buf;\n\n\tif (!ieee80211_is_mgmt(mgmt->frame_control)) {\n\t\tbrcmf_err(\"Driver only allows MGMT packet type\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tvif = container_of(wdev, struct brcmf_cfg80211_vif, wdev);\n\n\tif (ieee80211_is_probe_resp(mgmt->frame_control)) {\n\t\t/* Right now the only reason to get a probe response */\n\t\t/* is for p2p listen response or for p2p GO from     */\n\t\t/* wpa_supplicant. Unfortunately the probe is send   */\n\t\t/* on primary ndev, while dongle wants it on the p2p */\n\t\t/* vif. Since this is only reason for a probe        */\n\t\t/* response to be sent, the vif is taken from cfg.   */\n\t\t/* If ever desired to send proberesp for non p2p     */\n\t\t/* response then data should be checked for          */\n\t\t/* \"DIRECT-\". Note in future supplicant will take    */\n\t\t/* dedicated p2p wdev to do this and then this 'hack'*/\n\t\t/* is not needed anymore.                            */\n\t\tie_offset =  DOT11_MGMT_HDR_LEN +\n\t\t\t     DOT11_BCN_PRB_FIXED_LEN;\n\t\tie_len = len - ie_offset;\n\t\tif (vif == cfg->p2p.bss_idx[P2PAPI_BSSCFG_PRIMARY].vif)\n\t\t\tvif = cfg->p2p.bss_idx[P2PAPI_BSSCFG_DEVICE].vif;\n\t\terr = brcmf_vif_set_mgmt_ie(vif,\n\t\t\t\t\t    BRCMF_VNDR_IE_PRBRSP_FLAG,\n\t\t\t\t\t    &buf[ie_offset],\n\t\t\t\t\t    ie_len);\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, true,\n\t\t\t\t\tGFP_KERNEL);\n\t} else if (ieee80211_is_action(mgmt->frame_control)) {\n\t\taf_params = kzalloc(sizeof(*af_params), GFP_KERNEL);\n\t\tif (af_params == NULL) {\n\t\t\tbrcmf_err(\"unable to allocate frame\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto exit;\n\t\t}\n\t\taction_frame = &af_params->action_frame;\n\t\t/* Add the packet Id */\n\t\taction_frame->packet_id = cpu_to_le32(*cookie);\n\t\t/* Add BSSID */\n\t\tmemcpy(&action_frame->da[0], &mgmt->da[0], ETH_ALEN);\n\t\tmemcpy(&af_params->bssid[0], &mgmt->bssid[0], ETH_ALEN);\n\t\t/* Add the length exepted for 802.11 header  */\n\t\taction_frame->len = cpu_to_le16(len - DOT11_MGMT_HDR_LEN);\n\t\t/* Add the channel. Use the one specified as parameter if any or\n\t\t * the current one (got from the firmware) otherwise\n\t\t */\n\t\tif (chan)\n\t\t\tfreq = chan->center_freq;\n\t\telse\n\t\t\tbrcmf_fil_cmd_int_get(vif->ifp, BRCMF_C_GET_CHANNEL,\n\t\t\t\t\t      &freq);\n\t\tchan_nr = ieee80211_frequency_to_channel(freq);\n\t\taf_params->channel = cpu_to_le32(chan_nr);\n\n\t\tmemcpy(action_frame->data, &buf[DOT11_MGMT_HDR_LEN],\n\t\t       le16_to_cpu(action_frame->len));\n\n\t\tbrcmf_dbg(TRACE, \"Action frame, cookie=%lld, len=%d, freq=%d\\n\",\n\t\t\t  *cookie, le16_to_cpu(action_frame->len), freq);\n\n\t\tack = brcmf_p2p_send_action_frame(cfg, cfg_to_ndev(cfg),\n\t\t\t\t\t\t  af_params);\n\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, ack,\n\t\t\t\t\tGFP_KERNEL);\n\t\tkfree(af_params);\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"Unhandled, fc=%04x!!\\n\", mgmt->frame_control);\n\t\tbrcmf_dbg_hex_dump(true, buf, len, \"payload, len=%zu\\n\", len);\n\t}\n\nexit:\n\treturn err;\n}",
      "code_after_change": "static int\nbrcmf_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,\n\t\t       struct cfg80211_mgmt_tx_params *params, u64 *cookie)\n{\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct ieee80211_channel *chan = params->chan;\n\tconst u8 *buf = params->buf;\n\tsize_t len = params->len;\n\tconst struct ieee80211_mgmt *mgmt;\n\tstruct brcmf_cfg80211_vif *vif;\n\ts32 err = 0;\n\ts32 ie_offset;\n\ts32 ie_len;\n\tstruct brcmf_fil_action_frame_le *action_frame;\n\tstruct brcmf_fil_af_params_le *af_params;\n\tbool ack;\n\ts32 chan_nr;\n\tu32 freq;\n\n\tbrcmf_dbg(TRACE, \"Enter\\n\");\n\n\t*cookie = 0;\n\n\tmgmt = (const struct ieee80211_mgmt *)buf;\n\n\tif (!ieee80211_is_mgmt(mgmt->frame_control)) {\n\t\tbrcmf_err(\"Driver only allows MGMT packet type\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tvif = container_of(wdev, struct brcmf_cfg80211_vif, wdev);\n\n\tif (ieee80211_is_probe_resp(mgmt->frame_control)) {\n\t\t/* Right now the only reason to get a probe response */\n\t\t/* is for p2p listen response or for p2p GO from     */\n\t\t/* wpa_supplicant. Unfortunately the probe is send   */\n\t\t/* on primary ndev, while dongle wants it on the p2p */\n\t\t/* vif. Since this is only reason for a probe        */\n\t\t/* response to be sent, the vif is taken from cfg.   */\n\t\t/* If ever desired to send proberesp for non p2p     */\n\t\t/* response then data should be checked for          */\n\t\t/* \"DIRECT-\". Note in future supplicant will take    */\n\t\t/* dedicated p2p wdev to do this and then this 'hack'*/\n\t\t/* is not needed anymore.                            */\n\t\tie_offset =  DOT11_MGMT_HDR_LEN +\n\t\t\t     DOT11_BCN_PRB_FIXED_LEN;\n\t\tie_len = len - ie_offset;\n\t\tif (vif == cfg->p2p.bss_idx[P2PAPI_BSSCFG_PRIMARY].vif)\n\t\t\tvif = cfg->p2p.bss_idx[P2PAPI_BSSCFG_DEVICE].vif;\n\t\terr = brcmf_vif_set_mgmt_ie(vif,\n\t\t\t\t\t    BRCMF_VNDR_IE_PRBRSP_FLAG,\n\t\t\t\t\t    &buf[ie_offset],\n\t\t\t\t\t    ie_len);\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, true,\n\t\t\t\t\tGFP_KERNEL);\n\t} else if (ieee80211_is_action(mgmt->frame_control)) {\n\t\tif (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN) {\n\t\t\tbrcmf_err(\"invalid action frame length\\n\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto exit;\n\t\t}\n\t\taf_params = kzalloc(sizeof(*af_params), GFP_KERNEL);\n\t\tif (af_params == NULL) {\n\t\t\tbrcmf_err(\"unable to allocate frame\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto exit;\n\t\t}\n\t\taction_frame = &af_params->action_frame;\n\t\t/* Add the packet Id */\n\t\taction_frame->packet_id = cpu_to_le32(*cookie);\n\t\t/* Add BSSID */\n\t\tmemcpy(&action_frame->da[0], &mgmt->da[0], ETH_ALEN);\n\t\tmemcpy(&af_params->bssid[0], &mgmt->bssid[0], ETH_ALEN);\n\t\t/* Add the length exepted for 802.11 header  */\n\t\taction_frame->len = cpu_to_le16(len - DOT11_MGMT_HDR_LEN);\n\t\t/* Add the channel. Use the one specified as parameter if any or\n\t\t * the current one (got from the firmware) otherwise\n\t\t */\n\t\tif (chan)\n\t\t\tfreq = chan->center_freq;\n\t\telse\n\t\t\tbrcmf_fil_cmd_int_get(vif->ifp, BRCMF_C_GET_CHANNEL,\n\t\t\t\t\t      &freq);\n\t\tchan_nr = ieee80211_frequency_to_channel(freq);\n\t\taf_params->channel = cpu_to_le32(chan_nr);\n\n\t\tmemcpy(action_frame->data, &buf[DOT11_MGMT_HDR_LEN],\n\t\t       le16_to_cpu(action_frame->len));\n\n\t\tbrcmf_dbg(TRACE, \"Action frame, cookie=%lld, len=%d, freq=%d\\n\",\n\t\t\t  *cookie, le16_to_cpu(action_frame->len), freq);\n\n\t\tack = brcmf_p2p_send_action_frame(cfg, cfg_to_ndev(cfg),\n\t\t\t\t\t\t  af_params);\n\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, ack,\n\t\t\t\t\tGFP_KERNEL);\n\t\tkfree(af_params);\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"Unhandled, fc=%04x!!\\n\", mgmt->frame_control);\n\t\tbrcmf_dbg_hex_dump(true, buf, len, \"payload, len=%zu\\n\", len);\n\t}\n\nexit:\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN) {",
          "\t\t\tbrcmf_err(\"invalid action frame length\\n\");",
          "\t\t\terr = -EINVAL;",
          "\t\t\tgoto exit;",
          "\t\t}"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation for the length of the action frame in the brcmf_cfg80211_mgmt_tx function.",
      "trigger_condition": "Receiving a crafted NL80211_CMD_FRAME Netlink packet with a maliciously large length for the action frame.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the length of the action frame exceeds the maximum allowed size, leading to a potential buffer overflow and system crash.",
      "id": 120,
      "code_after_change_normalized": "static int\nFUN1(struct VAR1 *VAR1, struct wireless_dev *VAR2,\nstruct cfg80211_mgmt_tx_params *VAR3, u64 *VAR4)\n{\nstruct brcmf_cfg80211_info *VAR5 = FUN2(VAR1);\nstruct ieee80211_channel *VAR6 = VAR3->VAR6;\nconst u8 *VAR7 = VAR3->VAR7;\nsize_t VAR8 = VAR3->VAR8;\nconst struct ieee80211_mgmt *VAR9;\nstruct brcmf_cfg80211_vif *VAR10;\ns32 VAR11 = 0;\ns32 VAR12;\ns32 VAR13;\nstruct brcmf_fil_action_frame_le *VAR14;\nstruct brcmf_fil_af_params_le *VAR15;\nbool VAR16;\ns32 VAR17;\nu32 VAR18;\nFUN3(VAR19, \"STR\");\n*VAR4 = 0;\nVAR9 = (const struct VAR20 *)VAR7;\nif (!FUN4(VAR9->VAR21)) {\nFUN5(\"STR\");\nreturn -VAR22;\n}\nVAR10 = FUN6(VAR2, struct VAR23, VAR2);\nif (FUN7(VAR9->VAR21)) {\nVAR12 =  VAR24 +\nVAR25;\nVAR13 = VAR8 - VAR12;\nif (VAR10 == VAR5->VAR26.VAR27[VAR28].VAR10)\nVAR10 = VAR5->VAR26.VAR27[VAR29].VAR10;\nVAR11 = FUN8(VAR10,\nVAR30,\n&VAR7[VAR12],\nVAR13);\nFUN9(VAR2, *VAR4, VAR7, VAR8, true,\nVAR31);\n} else if (FUN10(VAR9->VAR21)) {\nif (VAR8 > VAR32 + VAR24) {\nFUN5(\"STR\");\nVAR11 = -VAR33;\ngoto VAR34;\n}\nVAR15 = FUN11(sizeof(*VAR15), VAR31);\nif (VAR15 == NULL) {\nFUN5(\"STR\");\nVAR11 = -VAR35;\ngoto VAR34;\n}\nVAR14 = &VAR15->VAR14;\nVAR14->VAR36 = FUN12(*VAR4);\nFUN13(&VAR14->VAR37[0], &VAR9->VAR37[0], VAR38);\nFUN13(&VAR15->VAR39[0], &VAR9->VAR39[0], VAR38);\nVAR14->VAR8 = FUN14(VAR8 - VAR24);\nif (VAR6)\nVAR18 = VAR6->VAR40;\nelse\nFUN15(VAR10->VAR41, VAR42,\n&VAR18);\nVAR17 = FUN16(VAR18);\nVAR15->VAR43 = FUN12(VAR17);\nFUN13(VAR14->VAR44, &VAR7[VAR24],\nFUN17(VAR14->VAR8));\nFUN3(VAR19, \"STR\",\n*VAR4, FUN17(VAR14->VAR8), VAR18);\nVAR16 = FUN18(VAR5, FUN19(VAR5),\nVAR15);\nFUN9(VAR2, *VAR4, VAR7, VAR8, VAR16,\nVAR31);\nFUN20(VAR15);\n} else {\nFUN3(VAR19, \"STR\", VAR9->VAR21);\nFUN21(true, VAR7, VAR8, \"STR\", VAR8);\n}\nVAR34:\nreturn VAR11;\n}\n",
      "code_before_change_normalized": "static int\nFUN1(struct VAR1 *VAR1, struct wireless_dev *VAR2,\nstruct cfg80211_mgmt_tx_params *VAR3, u64 *VAR4)\n{\nstruct brcmf_cfg80211_info *VAR5 = FUN2(VAR1);\nstruct ieee80211_channel *VAR6 = VAR3->VAR6;\nconst u8 *VAR7 = VAR3->VAR7;\nsize_t VAR8 = VAR3->VAR8;\nconst struct ieee80211_mgmt *VAR9;\nstruct brcmf_cfg80211_vif *VAR10;\ns32 VAR11 = 0;\ns32 VAR12;\ns32 VAR13;\nstruct brcmf_fil_action_frame_le *VAR14;\nstruct brcmf_fil_af_params_le *VAR15;\nbool VAR16;\ns32 VAR17;\nu32 VAR18;\nFUN3(VAR19, \"STR\");\n*VAR4 = 0;\nVAR9 = (const struct VAR20 *)VAR7;\nif (!FUN4(VAR9->VAR21)) {\nFUN5(\"STR\");\nreturn -VAR22;\n}\nVAR10 = FUN6(VAR2, struct VAR23, VAR2);\nif (FUN7(VAR9->VAR21)) {\nVAR12 =  VAR24 +\nVAR25;\nVAR13 = VAR8 - VAR12;\nif (VAR10 == VAR5->VAR26.VAR27[VAR28].VAR10)\nVAR10 = VAR5->VAR26.VAR27[VAR29].VAR10;\nVAR11 = FUN8(VAR10,\nVAR30,\n&VAR7[VAR12],\nVAR13);\nFUN9(VAR2, *VAR4, VAR7, VAR8, true,\nVAR31);\n} else if (FUN10(VAR9->VAR21)) {\nVAR15 = FUN11(sizeof(*VAR15), VAR31);\nif (VAR15 == NULL) {\nFUN5(\"STR\");\nVAR11 = -VAR32;\ngoto VAR33;\n}\nVAR14 = &VAR15->VAR14;\nVAR14->VAR34 = FUN12(*VAR4);\nFUN13(&VAR14->VAR35[0], &VAR9->VAR35[0], VAR36);\nFUN13(&VAR15->VAR37[0], &VAR9->VAR37[0], VAR36);\nVAR14->VAR8 = FUN14(VAR8 - VAR24);\nif (VAR6)\nVAR18 = VAR6->VAR38;\nelse\nFUN15(VAR10->VAR39, VAR40,\n&VAR18);\nVAR17 = FUN16(VAR18);\nVAR15->VAR41 = FUN12(VAR17);\nFUN13(VAR14->VAR42, &VAR7[VAR24],\nFUN17(VAR14->VAR8));\nFUN3(VAR19, \"STR\",\n*VAR4, FUN17(VAR14->VAR8), VAR18);\nVAR16 = FUN18(VAR5, FUN19(VAR5),\nVAR15);\nFUN9(VAR2, *VAR4, VAR7, VAR8, VAR16,\nVAR31);\nFUN20(VAR15);\n} else {\nFUN3(VAR19, \"STR\", VAR9->VAR21);\nFUN21(true, VAR7, VAR8, \"STR\", VAR8);\n}\nVAR33:\nreturn VAR11;\n}\n",
      "code_after_change_raw": "static int\nbrcmf_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,\nstruct cfg80211_mgmt_tx_params *params, u64 *cookie)\n{\nstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\nstruct ieee80211_channel *chan = params->chan;\nconst u8 *buf = params->buf;\nsize_t len = params->len;\nconst struct ieee80211_mgmt *mgmt;\nstruct brcmf_cfg80211_vif *vif;\ns32 err = 0;\ns32 ie_offset;\ns32 ie_len;\nstruct brcmf_fil_action_frame_le *action_frame;\nstruct brcmf_fil_af_params_le *af_params;\nbool ack;\ns32 chan_nr;\nu32 freq;\nbrcmf_dbg(TRACE, \"Enter\\n\");\n*cookie = 0;\nmgmt = (const struct ieee80211_mgmt *)buf;\nif (!ieee80211_is_mgmt(mgmt->frame_control)) {\nbrcmf_err(\"Driver only allows MGMT packet type\\n\");\nreturn -EPERM;\n}\nvif = container_of(wdev, struct brcmf_cfg80211_vif, wdev);\nif (ieee80211_is_probe_resp(mgmt->frame_control)) {\nie_offset =  DOT11_MGMT_HDR_LEN +\nDOT11_BCN_PRB_FIXED_LEN;\nie_len = len - ie_offset;\nif (vif == cfg->p2p.bss_idx[P2PAPI_BSSCFG_PRIMARY].vif)\nvif = cfg->p2p.bss_idx[P2PAPI_BSSCFG_DEVICE].vif;\nerr = brcmf_vif_set_mgmt_ie(vif,\nBRCMF_VNDR_IE_PRBRSP_FLAG,\n&buf[ie_offset],\nie_len);\ncfg80211_mgmt_tx_status(wdev, *cookie, buf, len, true,\nGFP_KERNEL);\n} else if (ieee80211_is_action(mgmt->frame_control)) {\nif (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN) {\nbrcmf_err(\"invalid action frame length\\n\");\nerr = -EINVAL;\ngoto exit;\n}\naf_params = kzalloc(sizeof(*af_params), GFP_KERNEL);\nif (af_params == NULL) {\nbrcmf_err(\"unable to allocate frame\\n\");\nerr = -ENOMEM;\ngoto exit;\n}\naction_frame = &af_params->action_frame;\naction_frame->packet_id = cpu_to_le32(*cookie);\nmemcpy(&action_frame->da[0], &mgmt->da[0], ETH_ALEN);\nmemcpy(&af_params->bssid[0], &mgmt->bssid[0], ETH_ALEN);\naction_frame->len = cpu_to_le16(len - DOT11_MGMT_HDR_LEN);\nif (chan)\nfreq = chan->center_freq;\nelse\nbrcmf_fil_cmd_int_get(vif->ifp, BRCMF_C_GET_CHANNEL,\n&freq);\nchan_nr = ieee80211_frequency_to_channel(freq);\naf_params->channel = cpu_to_le32(chan_nr);\nmemcpy(action_frame->data, &buf[DOT11_MGMT_HDR_LEN],\nle16_to_cpu(action_frame->len));\nbrcmf_dbg(TRACE, \"Action frame, cookie=%lld, len=%d, freq=%d\\n\",\n*cookie, le16_to_cpu(action_frame->len), freq);\nack = brcmf_p2p_send_action_frame(cfg, cfg_to_ndev(cfg),\naf_params);\ncfg80211_mgmt_tx_status(wdev, *cookie, buf, len, ack,\nGFP_KERNEL);\nkfree(af_params);\n} else {\nbrcmf_dbg(TRACE, \"Unhandled, fc=%04x!!\\n\", mgmt->frame_control);\nbrcmf_dbg_hex_dump(true, buf, len, \"payload, len=%zu\\n\", len);\n}\nexit:\nreturn err;\n}\n",
      "code_before_change_raw": "static int\nbrcmf_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,\nstruct cfg80211_mgmt_tx_params *params, u64 *cookie)\n{\nstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\nstruct ieee80211_channel *chan = params->chan;\nconst u8 *buf = params->buf;\nsize_t len = params->len;\nconst struct ieee80211_mgmt *mgmt;\nstruct brcmf_cfg80211_vif *vif;\ns32 err = 0;\ns32 ie_offset;\ns32 ie_len;\nstruct brcmf_fil_action_frame_le *action_frame;\nstruct brcmf_fil_af_params_le *af_params;\nbool ack;\ns32 chan_nr;\nu32 freq;\nbrcmf_dbg(TRACE, \"Enter\\n\");\n*cookie = 0;\nmgmt = (const struct ieee80211_mgmt *)buf;\nif (!ieee80211_is_mgmt(mgmt->frame_control)) {\nbrcmf_err(\"Driver only allows MGMT packet type\\n\");\nreturn -EPERM;\n}\nvif = container_of(wdev, struct brcmf_cfg80211_vif, wdev);\nif (ieee80211_is_probe_resp(mgmt->frame_control)) {\nie_offset =  DOT11_MGMT_HDR_LEN +\nDOT11_BCN_PRB_FIXED_LEN;\nie_len = len - ie_offset;\nif (vif == cfg->p2p.bss_idx[P2PAPI_BSSCFG_PRIMARY].vif)\nvif = cfg->p2p.bss_idx[P2PAPI_BSSCFG_DEVICE].vif;\nerr = brcmf_vif_set_mgmt_ie(vif,\nBRCMF_VNDR_IE_PRBRSP_FLAG,\n&buf[ie_offset],\nie_len);\ncfg80211_mgmt_tx_status(wdev, *cookie, buf, len, true,\nGFP_KERNEL);\n} else if (ieee80211_is_action(mgmt->frame_control)) {\naf_params = kzalloc(sizeof(*af_params), GFP_KERNEL);\nif (af_params == NULL) {\nbrcmf_err(\"unable to allocate frame\\n\");\nerr = -ENOMEM;\ngoto exit;\n}\naction_frame = &af_params->action_frame;\naction_frame->packet_id = cpu_to_le32(*cookie);\nmemcpy(&action_frame->da[0], &mgmt->da[0], ETH_ALEN);\nmemcpy(&af_params->bssid[0], &mgmt->bssid[0], ETH_ALEN);\naction_frame->len = cpu_to_le16(len - DOT11_MGMT_HDR_LEN);\nif (chan)\nfreq = chan->center_freq;\nelse\nbrcmf_fil_cmd_int_get(vif->ifp, BRCMF_C_GET_CHANNEL,\n&freq);\nchan_nr = ieee80211_frequency_to_channel(freq);\naf_params->channel = cpu_to_le32(chan_nr);\nmemcpy(action_frame->data, &buf[DOT11_MGMT_HDR_LEN],\nle16_to_cpu(action_frame->len));\nbrcmf_dbg(TRACE, \"Action frame, cookie=%lld, len=%d, freq=%d\\n\",\n*cookie, le16_to_cpu(action_frame->len), freq);\nack = brcmf_p2p_send_action_frame(cfg, cfg_to_ndev(cfg),\naf_params);\ncfg80211_mgmt_tx_status(wdev, *cookie, buf, len, ack,\nGFP_KERNEL);\nkfree(af_params);\n} else {\nbrcmf_dbg(TRACE, \"Unhandled, fc=%04x!!\\n\", mgmt->frame_control);\nbrcmf_dbg_hex_dump(true, buf, len, \"payload, len=%zu\\n\", len);\n}\nexit:\nreturn err;\n}\n"
    }
  ],
  "CVE-2017-7895": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of boundary checks for the end of a buffer in the NFSv2 and NFSv3 server implementations.",
        "trigger_condition": "Remote attackers send crafted requests that can trigger pointer-arithmetic errors due to the absence of proper buffer boundary checks.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the pointer arithmetic when accessing buffers, potentially leading to buffer overflows or out-of-bounds access."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a boundary check to ensure that the pointer does not exceed the bounds of the buffer before accessing it. This check helps prevent buffer overflows and out-of-bounds access that could be exploited by remote attackers. In this case, the solution involves adding a specific boundary check before accessing the buffer to prevent pointer-arithmetic errors.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2017-7895, which involves a lack of certain checks for the end of a buffer in the NFSv2 and NFSv3 server implementations in the Linux kernel. By adding the check `(void *)old > vec->iov_base + vec->iov_len` before accessing the buffer in the code snippet, we ensure that pointer-arithmetic errors are avoided. This check helps prevent potential buffer overflows or out-of-bounds access that could be exploited by remote attackers through crafted requests.\n\nIn summary, the modification adds a boundary check to ensure that the pointer `old` does not exceed the bounds of the buffer specified by `vec->iov_base` and `vec->iov_len`, thereby enhancing the security of the code and mitigating the vulnerability.",
      "GPT_purpose": "Decode symlink arguments for NFSv3 service requests.",
      "GPT_function": "\n1. Decode file handle and filename.\n2. Decode file attributes.\n3. Decode and copy a pathname into a new page, checking for buffer overflows.",
      "CVE_id": "CVE-2017-7895",
      "code_before_change": "int\nnfs3svc_decode_symlinkargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_symlinkargs *args)\n{\n\tunsigned int len, avail;\n\tchar *old, *new;\n\tstruct kvec *vec;\n\n\tif (!(p = decode_fh(p, &args->ffh)) ||\n\t    !(p = decode_filename(p, &args->fname, &args->flen))\n\t\t)\n\t\treturn 0;\n\tp = decode_sattr3(p, &args->attrs);\n\n\t/* now decode the pathname, which might be larger than the first page.\n\t * As we have to check for nul's anyway, we copy it into a new page\n\t * This page appears in the rq_res.pages list, but as pages_len is always\n\t * 0, it won't get in the way\n\t */\n\tlen = ntohl(*p++);\n\tif (len == 0 || len > NFS3_MAXPATHLEN || len >= PAGE_SIZE)\n\t\treturn 0;\n\targs->tname = new = page_address(*(rqstp->rq_next_page++));\n\targs->tlen = len;\n\t/* first copy and check from the first page */\n\told = (char*)p;\n\tvec = &rqstp->rq_arg.head[0];\n\tavail = vec->iov_len - (old - (char*)vec->iov_base);\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t/* now copy next page if there is one */\n\tif (len && !avail && rqstp->rq_arg.page_len) {\n\t\tavail = min_t(unsigned int, rqstp->rq_arg.page_len, PAGE_SIZE);\n\t\told = page_address(rqstp->rq_arg.pages[0]);\n\t}\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t*new = '\\0';\n\tif (len)\n\t\treturn 0;\n\n\treturn 1;\n}",
      "code_after_change": "int\nnfs3svc_decode_symlinkargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_symlinkargs *args)\n{\n\tunsigned int len, avail;\n\tchar *old, *new;\n\tstruct kvec *vec;\n\n\tif (!(p = decode_fh(p, &args->ffh)) ||\n\t    !(p = decode_filename(p, &args->fname, &args->flen))\n\t\t)\n\t\treturn 0;\n\tp = decode_sattr3(p, &args->attrs);\n\n\t/* now decode the pathname, which might be larger than the first page.\n\t * As we have to check for nul's anyway, we copy it into a new page\n\t * This page appears in the rq_res.pages list, but as pages_len is always\n\t * 0, it won't get in the way\n\t */\n\tlen = ntohl(*p++);\n\tif (len == 0 || len > NFS3_MAXPATHLEN || len >= PAGE_SIZE)\n\t\treturn 0;\n\targs->tname = new = page_address(*(rqstp->rq_next_page++));\n\targs->tlen = len;\n\t/* first copy and check from the first page */\n\told = (char*)p;\n\tvec = &rqstp->rq_arg.head[0];\n\tif ((void *)old > vec->iov_base + vec->iov_len)\n\t\treturn 0;\n\tavail = vec->iov_len - (old - (char*)vec->iov_base);\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t/* now copy next page if there is one */\n\tif (len && !avail && rqstp->rq_arg.page_len) {\n\t\tavail = min_t(unsigned int, rqstp->rq_arg.page_len, PAGE_SIZE);\n\t\told = page_address(rqstp->rq_arg.pages[0]);\n\t}\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t*new = '\\0';\n\tif (len)\n\t\treturn 0;\n\n\treturn 1;\n}",
      "modified_lines": {
        "added": [
          "\tif ((void *)old > vec->iov_base + vec->iov_len)",
          "\t\treturn 0;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of boundary checks for the end of a buffer in the NFSv2 and NFSv3 server implementations.",
      "trigger_condition": "Remote attackers send crafted requests that can trigger pointer-arithmetic errors due to the absence of proper buffer boundary checks.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the pointer arithmetic when accessing buffers, potentially leading to buffer overflows or out-of-bounds access.",
      "id": 121,
      "code_after_change_normalized": "int\nFUN1(struct svc_rqst *VAR1, __be32 *VAR2,\nstruct nfsd3_symlinkargs *VAR3)\n{\nunsigned int VAR4, VAR5;\nchar *VAR6, *new;\nstruct kvec *VAR7;\nif (!(VAR2 = FUN2(VAR2, &VAR3->VAR8)) ||\n!(VAR2 = FUN3(VAR2, &VAR3->VAR9, &VAR3->VAR10))\n)\nreturn 0;\nVAR2 = FUN4(VAR2, &VAR3->VAR11);\nVAR4 = FUN5(*VAR2++);\nif (VAR4 == 0 || VAR4 > VAR12 || VAR4 >= VAR13)\nreturn 0;\nVAR3->VAR14 = new = FUN6(*(VAR1->VAR15++));\nVAR3->VAR16 = VAR4;\nVAR6 = (char*)VAR2;\nVAR7 = &VAR1->VAR17.VAR18[0];\nif ((void *)VAR6 > VAR7->VAR19 + VAR7->VAR20)\nreturn 0;\nVAR5 = VAR7->VAR20 - (VAR6 - (char*)VAR7->VAR19);\nwhile (VAR4 && VAR5 && *VAR6) {\n*new++ = *VAR6++;\nVAR4--;\nVAR5--;\n}\nif (VAR4 && !VAR5 && VAR1->VAR17.VAR21) {\nVAR5 = FUN7(unsigned int, VAR1->VAR17.VAR21, VAR13);\nVAR6 = FUN6(VAR1->VAR17.VAR22[0]);\n}\nwhile (VAR4 && VAR5 && *VAR6) {\n*new++ = *VAR6++;\nVAR4--;\nVAR5--;\n}\n*new = ;\nif (VAR4)\nreturn 0;\nreturn 1;\n}\n",
      "code_before_change_normalized": "int\nFUN1(struct svc_rqst *VAR1, __be32 *VAR2,\nstruct nfsd3_symlinkargs *VAR3)\n{\nunsigned int VAR4, VAR5;\nchar *VAR6, *new;\nstruct kvec *VAR7;\nif (!(VAR2 = FUN2(VAR2, &VAR3->VAR8)) ||\n!(VAR2 = FUN3(VAR2, &VAR3->VAR9, &VAR3->VAR10))\n)\nreturn 0;\nVAR2 = FUN4(VAR2, &VAR3->VAR11);\nVAR4 = FUN5(*VAR2++);\nif (VAR4 == 0 || VAR4 > VAR12 || VAR4 >= VAR13)\nreturn 0;\nVAR3->VAR14 = new = FUN6(*(VAR1->VAR15++));\nVAR3->VAR16 = VAR4;\nVAR6 = (char*)VAR2;\nVAR7 = &VAR1->VAR17.VAR18[0];\nVAR5 = VAR7->VAR19 - (VAR6 - (char*)VAR7->VAR20);\nwhile (VAR4 && VAR5 && *VAR6) {\n*new++ = *VAR6++;\nVAR4--;\nVAR5--;\n}\nif (VAR4 && !VAR5 && VAR1->VAR17.VAR21) {\nVAR5 = FUN7(unsigned int, VAR1->VAR17.VAR21, VAR13);\nVAR6 = FUN6(VAR1->VAR17.VAR22[0]);\n}\nwhile (VAR4 && VAR5 && *VAR6) {\n*new++ = *VAR6++;\nVAR4--;\nVAR5--;\n}\n*new = ;\nif (VAR4)\nreturn 0;\nreturn 1;\n}\n",
      "code_after_change_raw": "int\nnfs3svc_decode_symlinkargs(struct svc_rqst *rqstp, __be32 *p,\nstruct nfsd3_symlinkargs *args)\n{\nunsigned int len, avail;\nchar *old, *new;\nstruct kvec *vec;\nif (!(p = decode_fh(p, &args->ffh)) ||\n!(p = decode_filename(p, &args->fname, &args->flen))\n)\nreturn 0;\np = decode_sattr3(p, &args->attrs);\nlen = ntohl(*p++);\nif (len == 0 || len > NFS3_MAXPATHLEN || len >= PAGE_SIZE)\nreturn 0;\nargs->tname = new = page_address(*(rqstp->rq_next_page++));\nargs->tlen = len;\nold = (char*)p;\nvec = &rqstp->rq_arg.head[0];\nif ((void *)old > vec->iov_base + vec->iov_len)\nreturn 0;\navail = vec->iov_len - (old - (char*)vec->iov_base);\nwhile (len && avail && *old) {\n*new++ = *old++;\nlen--;\navail--;\n}\nif (len && !avail && rqstp->rq_arg.page_len) {\navail = min_t(unsigned int, rqstp->rq_arg.page_len, PAGE_SIZE);\nold = page_address(rqstp->rq_arg.pages[0]);\n}\nwhile (len && avail && *old) {\n*new++ = *old++;\nlen--;\navail--;\n}\n*new = '\\0';\nif (len)\nreturn 0;\nreturn 1;\n}\n",
      "code_before_change_raw": "int\nnfs3svc_decode_symlinkargs(struct svc_rqst *rqstp, __be32 *p,\nstruct nfsd3_symlinkargs *args)\n{\nunsigned int len, avail;\nchar *old, *new;\nstruct kvec *vec;\nif (!(p = decode_fh(p, &args->ffh)) ||\n!(p = decode_filename(p, &args->fname, &args->flen))\n)\nreturn 0;\np = decode_sattr3(p, &args->attrs);\nlen = ntohl(*p++);\nif (len == 0 || len > NFS3_MAXPATHLEN || len >= PAGE_SIZE)\nreturn 0;\nargs->tname = new = page_address(*(rqstp->rq_next_page++));\nargs->tlen = len;\nold = (char*)p;\nvec = &rqstp->rq_arg.head[0];\navail = vec->iov_len - (old - (char*)vec->iov_base);\nwhile (len && avail && *old) {\n*new++ = *old++;\nlen--;\navail--;\n}\nif (len && !avail && rqstp->rq_arg.page_len) {\navail = min_t(unsigned int, rqstp->rq_arg.page_len, PAGE_SIZE);\nold = page_address(rqstp->rq_arg.pages[0]);\n}\nwhile (len && avail && *old) {\n*new++ = *old++;\nlen--;\navail--;\n}\n*new = '\\0';\nif (len)\nreturn 0;\nreturn 1;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of certain checks for the end of a buffer in the NFSv2 and NFSv3 server implementations.",
        "trigger_condition": "Remote attackers send crafted requests that exploit the lack of buffer end checks, leading to pointer-arithmetic errors or other unspecified impacts.",
        "specific_code_behavior_causing_vulnerability": "The code performs pointer arithmetic without verifying the end of the buffer, potentially allowing it to go beyond the buffer boundaries and resulting in errors or unspecified impacts."
      },
      "solution": "To mitigate the vulnerability, a boundary check is added to ensure that the calculated header length does not exceed the length of the buffer. This check prevents potential pointer-arithmetic errors by verifying that the pointer does not go beyond the buffer boundaries.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-7895 in the code snippet. The vulnerability arises due to the lack of certain checks for the end of a buffer in the NFSv2 and NFSv3 server implementations in the Linux kernel. Specifically, the vulnerability allows remote attackers to trigger pointer-arithmetic errors or have other unspecified impacts via crafted requests.\n\nBy adding the check `if (hdr > head->iov_len)` in the modified code, we ensure that the pointer arithmetic does not go beyond the end of the buffer. This check verifies that the calculated header length does not exceed the length of the buffer, preventing potential pointer-arithmetic errors and enhancing the security of the code against the vulnerability.\n\nTherefore, the modification is necessary to mitigate the vulnerability by adding a boundary check to prevent buffer overflows and pointer-arithmetic errors.",
      "GPT_purpose": "Decode write arguments for NFS server requests.",
      "GPT_function": "\n1. Decode NFS write arguments.\n2. Check for maximum data length.\n3. Verify the received data length against the specified length.",
      "CVE_id": "CVE-2017-7895",
      "code_before_change": "int\nnfssvc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd_writeargs *args)\n{\n\tunsigned int len, hdr, dlen;\n\tstruct kvec *head = rqstp->rq_arg.head;\n\tint v;\n\n\tp = decode_fh(p, &args->fh);\n\tif (!p)\n\t\treturn 0;\n\n\tp++;\t\t\t\t/* beginoffset */\n\targs->offset = ntohl(*p++);\t/* offset */\n\tp++;\t\t\t\t/* totalcount */\n\tlen = args->len = ntohl(*p++);\n\t/*\n\t * The protocol specifies a maximum of 8192 bytes.\n\t */\n\tif (len > NFSSVC_MAXBLKSIZE_V2)\n\t\treturn 0;\n\n\t/*\n\t * Check to make sure that we got the right number of\n\t * bytes.\n\t */\n\thdr = (void*)p - head->iov_base;\n\tdlen = head->iov_len + rqstp->rq_arg.page_len - hdr;\n\n\t/*\n\t * Round the length of the data which was specified up to\n\t * the next multiple of XDR units and then compare that\n\t * against the length which was actually received.\n\t * Note that when RPCSEC/GSS (for example) is used, the\n\t * data buffer can be padded so dlen might be larger\n\t * than required.  It must never be smaller.\n\t */\n\tif (dlen < XDR_QUADLEN(len)*4)\n\t\treturn 0;\n\n\trqstp->rq_vec[0].iov_base = (void*)p;\n\trqstp->rq_vec[0].iov_len = head->iov_len - hdr;\n\tv = 0;\n\twhile (len > rqstp->rq_vec[v].iov_len) {\n\t\tlen -= rqstp->rq_vec[v].iov_len;\n\t\tv++;\n\t\trqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\n\t\trqstp->rq_vec[v].iov_len = PAGE_SIZE;\n\t}\n\trqstp->rq_vec[v].iov_len = len;\n\targs->vlen = v + 1;\n\treturn 1;\n}",
      "code_after_change": "int\nnfssvc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd_writeargs *args)\n{\n\tunsigned int len, hdr, dlen;\n\tstruct kvec *head = rqstp->rq_arg.head;\n\tint v;\n\n\tp = decode_fh(p, &args->fh);\n\tif (!p)\n\t\treturn 0;\n\n\tp++;\t\t\t\t/* beginoffset */\n\targs->offset = ntohl(*p++);\t/* offset */\n\tp++;\t\t\t\t/* totalcount */\n\tlen = args->len = ntohl(*p++);\n\t/*\n\t * The protocol specifies a maximum of 8192 bytes.\n\t */\n\tif (len > NFSSVC_MAXBLKSIZE_V2)\n\t\treturn 0;\n\n\t/*\n\t * Check to make sure that we got the right number of\n\t * bytes.\n\t */\n\thdr = (void*)p - head->iov_base;\n\tif (hdr > head->iov_len)\n\t\treturn 0;\n\tdlen = head->iov_len + rqstp->rq_arg.page_len - hdr;\n\n\t/*\n\t * Round the length of the data which was specified up to\n\t * the next multiple of XDR units and then compare that\n\t * against the length which was actually received.\n\t * Note that when RPCSEC/GSS (for example) is used, the\n\t * data buffer can be padded so dlen might be larger\n\t * than required.  It must never be smaller.\n\t */\n\tif (dlen < XDR_QUADLEN(len)*4)\n\t\treturn 0;\n\n\trqstp->rq_vec[0].iov_base = (void*)p;\n\trqstp->rq_vec[0].iov_len = head->iov_len - hdr;\n\tv = 0;\n\twhile (len > rqstp->rq_vec[v].iov_len) {\n\t\tlen -= rqstp->rq_vec[v].iov_len;\n\t\tv++;\n\t\trqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\n\t\trqstp->rq_vec[v].iov_len = PAGE_SIZE;\n\t}\n\trqstp->rq_vec[v].iov_len = len;\n\targs->vlen = v + 1;\n\treturn 1;\n}",
      "modified_lines": {
        "added": [
          "\tif (hdr > head->iov_len)",
          "\t\treturn 0;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of certain checks for the end of a buffer in the NFSv2 and NFSv3 server implementations.",
      "trigger_condition": "Remote attackers send crafted requests that exploit the lack of buffer end checks, leading to pointer-arithmetic errors or other unspecified impacts.",
      "specific_code_behavior_causing_vulnerability": "The code performs pointer arithmetic without verifying the end of the buffer, potentially allowing it to go beyond the buffer boundaries and resulting in errors or unspecified impacts.",
      "id": 122,
      "code_after_change_normalized": "int\nFUN1(struct svc_rqst *VAR1, __be32 *VAR2,\nstruct nfsd_writeargs *VAR3)\n{\nunsigned int VAR4, VAR5, VAR6;\nstruct kvec *VAR7 = VAR1->VAR8.VAR7;\nint VAR9;\nVAR2 = FUN2(VAR2, &VAR3->VAR10);\nif (!VAR2)\nreturn 0;\nVAR2++;\t\t\t\t\nVAR3->VAR11 = FUN3(*VAR2++);\t\nVAR2++;\t\t\t\t\nVAR4 = VAR3->VAR4 = FUN3(*VAR2++);\nif (VAR4 > VAR12)\nreturn 0;\nVAR5 = (void*)VAR2 - VAR7->VAR13;\nif (VAR5 > VAR7->VAR14)\nreturn 0;\nVAR6 = VAR7->VAR14 + VAR1->VAR8.VAR15 - VAR5;\nif (VAR6 < FUN4(VAR4)*4)\nreturn 0;\nVAR1->VAR16[0].VAR13 = (void*)VAR2;\nVAR1->VAR16[0].VAR14 = VAR7->VAR14 - VAR5;\nVAR9 = 0;\nwhile (VAR4 > VAR1->VAR16[VAR9].VAR14) {\nVAR4 -= VAR1->VAR16[VAR9].VAR14;\nVAR9++;\nVAR1->VAR16[VAR9].VAR13 = FUN5(VAR1->VAR17[VAR9]);\nVAR1->VAR16[VAR9].VAR14 = VAR18;\n}\nVAR1->VAR16[VAR9].VAR14 = VAR4;\nVAR3->VAR19 = VAR9 + 1;\nreturn 1;\n}\n",
      "code_before_change_normalized": "int\nFUN1(struct svc_rqst *VAR1, __be32 *VAR2,\nstruct nfsd_writeargs *VAR3)\n{\nunsigned int VAR4, VAR5, VAR6;\nstruct kvec *VAR7 = VAR1->VAR8.VAR7;\nint VAR9;\nVAR2 = FUN2(VAR2, &VAR3->VAR10);\nif (!VAR2)\nreturn 0;\nVAR2++;\t\t\t\t\nVAR3->VAR11 = FUN3(*VAR2++);\t\nVAR2++;\t\t\t\t\nVAR4 = VAR3->VAR4 = FUN3(*VAR2++);\nif (VAR4 > VAR12)\nreturn 0;\nVAR5 = (void*)VAR2 - VAR7->VAR13;\nVAR6 = VAR7->VAR14 + VAR1->VAR8.VAR15 - VAR5;\nif (VAR6 < FUN4(VAR4)*4)\nreturn 0;\nVAR1->VAR16[0].VAR13 = (void*)VAR2;\nVAR1->VAR16[0].VAR14 = VAR7->VAR14 - VAR5;\nVAR9 = 0;\nwhile (VAR4 > VAR1->VAR16[VAR9].VAR14) {\nVAR4 -= VAR1->VAR16[VAR9].VAR14;\nVAR9++;\nVAR1->VAR16[VAR9].VAR13 = FUN5(VAR1->VAR17[VAR9]);\nVAR1->VAR16[VAR9].VAR14 = VAR18;\n}\nVAR1->VAR16[VAR9].VAR14 = VAR4;\nVAR3->VAR19 = VAR9 + 1;\nreturn 1;\n}\n",
      "code_after_change_raw": "int\nnfssvc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\nstruct nfsd_writeargs *args)\n{\nunsigned int len, hdr, dlen;\nstruct kvec *head = rqstp->rq_arg.head;\nint v;\np = decode_fh(p, &args->fh);\nif (!p)\nreturn 0;\np++;\t\t\t\t\nargs->offset = ntohl(*p++);\t\np++;\t\t\t\t\nlen = args->len = ntohl(*p++);\nif (len > NFSSVC_MAXBLKSIZE_V2)\nreturn 0;\nhdr = (void*)p - head->iov_base;\nif (hdr > head->iov_len)\nreturn 0;\ndlen = head->iov_len + rqstp->rq_arg.page_len - hdr;\nif (dlen < XDR_QUADLEN(len)*4)\nreturn 0;\nrqstp->rq_vec[0].iov_base = (void*)p;\nrqstp->rq_vec[0].iov_len = head->iov_len - hdr;\nv = 0;\nwhile (len > rqstp->rq_vec[v].iov_len) {\nlen -= rqstp->rq_vec[v].iov_len;\nv++;\nrqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\nrqstp->rq_vec[v].iov_len = PAGE_SIZE;\n}\nrqstp->rq_vec[v].iov_len = len;\nargs->vlen = v + 1;\nreturn 1;\n}\n",
      "code_before_change_raw": "int\nnfssvc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\nstruct nfsd_writeargs *args)\n{\nunsigned int len, hdr, dlen;\nstruct kvec *head = rqstp->rq_arg.head;\nint v;\np = decode_fh(p, &args->fh);\nif (!p)\nreturn 0;\np++;\t\t\t\t\nargs->offset = ntohl(*p++);\t\np++;\t\t\t\t\nlen = args->len = ntohl(*p++);\nif (len > NFSSVC_MAXBLKSIZE_V2)\nreturn 0;\nhdr = (void*)p - head->iov_base;\ndlen = head->iov_len + rqstp->rq_arg.page_len - hdr;\nif (dlen < XDR_QUADLEN(len)*4)\nreturn 0;\nrqstp->rq_vec[0].iov_base = (void*)p;\nrqstp->rq_vec[0].iov_len = head->iov_len - hdr;\nv = 0;\nwhile (len > rqstp->rq_vec[v].iov_len) {\nlen -= rqstp->rq_vec[v].iov_len;\nv++;\nrqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\nrqstp->rq_vec[v].iov_len = PAGE_SIZE;\n}\nrqstp->rq_vec[v].iov_len = len;\nargs->vlen = v + 1;\nreturn 1;\n}\n"
    }
  ],
  "CVE-2017-8061": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper memory allocation and access in the code, specifically related to DMA operations and scatterlists.",
        "trigger_condition": "Interaction with the CONFIG_VMAP_STACK option while using more than one virtual page for a DMA scatterlist.",
        "specific_code_behavior_causing_vulnerability": "The original code snippet allocates memory for the hexline struct using kmalloc, which may not align memory properly for DMA operations. Additionally, the way the reset value is handled can lead to memory corruption.",
        "solution": "To mitigate the vulnerability, the code needs to ensure proper memory alignment and access, especially for DMA operations and scatterlists. This involves modifying the code to allocate memory for a buffer of the appropriate size and then casting it to the hexline struct. Furthermore, the code should directly use the buffer for handling the reset value to improve memory access and alignment."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-8061 by fixing the way memory is allocated and accessed in the code snippet. The vulnerability arises due to incorrect interaction with the CONFIG_VMAP_STACK option, which can lead to a denial of service or memory corruption when using more than one virtual page for a DMA scatterlist.\n\nIn the original code snippet, the memory allocation for the `hx` struct is done using `kmalloc(sizeof(*hx), GFP_KERNEL)`. This allocation may not align the memory properly, especially when dealing with DMA operations and scatterlists. By modifying the code to allocate memory for a buffer `buf` of the appropriate size and then casting it to `hx`, we ensure that the memory is correctly aligned and accessed.\n\nAdditionally, the modification changes the way the `reset` value is handled by using the `buf` array directly instead of a separate variable. This helps in ensuring proper memory access and alignment, reducing the risk of memory corruption.\n\nOverall, the modification improves memory handling and alignment in the code, addressing the vulnerability related to DMA scatterlists and CONFIG_VMAP_STACK interaction.",
      "GPT_purpose": "Load firmware onto a USB device using Cypress chipset.",
      "GPT_function": "\n1. Load firmware onto a USB device.\n2. Stop the CPU of the USB controller.\n3. Write firmware data to specific memory addresses.\n4. Handle errors during firmware transfer.\n5. Restart the CPU of the USB controller.",
      "CVE_id": "CVE-2017-8061",
      "code_before_change": "int usb_cypress_load_firmware(struct usb_device *udev, const struct firmware *fw, int type)\n{\n\tstruct hexline *hx;\n\tu8 reset;\n\tint ret,pos=0;\n\n\thx = kmalloc(sizeof(*hx), GFP_KERNEL);\n\tif (!hx)\n\t\treturn -ENOMEM;\n\n\t/* stop the CPU */\n\treset = 1;\n\tif ((ret = usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1)) != 1)\n\t\terr(\"could not stop the USB controller CPU.\");\n\n\twhile ((ret = dvb_usb_get_hexline(fw, hx, &pos)) > 0) {\n\t\tdeb_fw(\"writing to address 0x%04x (buffer: 0x%02x %02x)\\n\", hx->addr, hx->len, hx->chk);\n\t\tret = usb_cypress_writemem(udev, hx->addr, hx->data, hx->len);\n\n\t\tif (ret != hx->len) {\n\t\t\terr(\"error while transferring firmware (transferred size: %d, block size: %d)\",\n\t\t\t\tret, hx->len);\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (ret < 0) {\n\t\terr(\"firmware download failed at %d with %d\",pos,ret);\n\t\tkfree(hx);\n\t\treturn ret;\n\t}\n\n\tif (ret == 0) {\n\t\t/* restart the CPU */\n\t\treset = 0;\n\t\tif (ret || usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1) != 1) {\n\t\t\terr(\"could not restart the USB controller CPU.\");\n\t\t\tret = -EINVAL;\n\t\t}\n\t} else\n\t\tret = -EIO;\n\n\tkfree(hx);\n\n\treturn ret;\n}",
      "code_after_change": "int usb_cypress_load_firmware(struct usb_device *udev, const struct firmware *fw, int type)\n{\n\tstruct hexline *hx;\n\tu8 *buf;\n\tint ret, pos = 0;\n\tu16 cpu_cs_register = cypress[type].cpu_cs_register;\n\n\tbuf = kmalloc(sizeof(*hx), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\thx = (struct hexline *)buf;\n\n\t/* stop the CPU */\n\tbuf[0] = 1;\n\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1)\n\t\terr(\"could not stop the USB controller CPU.\");\n\n\twhile ((ret = dvb_usb_get_hexline(fw, hx, &pos)) > 0) {\n\t\tdeb_fw(\"writing to address 0x%04x (buffer: 0x%02x %02x)\\n\", hx->addr, hx->len, hx->chk);\n\t\tret = usb_cypress_writemem(udev, hx->addr, hx->data, hx->len);\n\n\t\tif (ret != hx->len) {\n\t\t\terr(\"error while transferring firmware (transferred size: %d, block size: %d)\",\n\t\t\t\tret, hx->len);\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (ret < 0) {\n\t\terr(\"firmware download failed at %d with %d\",pos,ret);\n\t\tkfree(buf);\n\t\treturn ret;\n\t}\n\n\tif (ret == 0) {\n\t\t/* restart the CPU */\n\t\tbuf[0] = 0;\n\t\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1) {\n\t\t\terr(\"could not restart the USB controller CPU.\");\n\t\t\tret = -EINVAL;\n\t\t}\n\t} else\n\t\tret = -EIO;\n\n\tkfree(buf);\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tu8 *buf;",
          "\tint ret, pos = 0;",
          "\tu16 cpu_cs_register = cypress[type].cpu_cs_register;",
          "\tbuf = kmalloc(sizeof(*hx), GFP_KERNEL);",
          "\tif (!buf)",
          "\thx = (struct hexline *)buf;",
          "\tbuf[0] = 1;",
          "\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1)",
          "\t\tkfree(buf);",
          "\t\tbuf[0] = 0;",
          "\t\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1) {",
          "\tkfree(buf);"
        ],
        "deleted": [
          "\tu8 reset;",
          "\tint ret,pos=0;",
          "\thx = kmalloc(sizeof(*hx), GFP_KERNEL);",
          "\tif (!hx)",
          "\treset = 1;",
          "\tif ((ret = usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1)) != 1)",
          "\t\tkfree(hx);",
          "\t\treset = 0;",
          "\t\tif (ret || usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1) != 1) {",
          "\tkfree(hx);"
        ]
      },
      "preconditions_for_vulnerability": "Improper memory allocation and access in the code, specifically related to DMA operations and scatterlists.",
      "trigger_condition": "Interaction with the CONFIG_VMAP_STACK option while using more than one virtual page for a DMA scatterlist.",
      "specific_code_behavior_causing_vulnerability": "The original code snippet allocates memory for the hexline struct using kmalloc, which may not align memory properly for DMA operations. Additionally, the way the reset value is handled can lead to memory corruption.",
      "solution": "To mitigate the vulnerability, the code needs to ensure proper memory alignment and access, especially for DMA operations and scatterlists. This involves modifying the code to allocate memory for a buffer of the appropriate size and then casting it to the hexline struct. Furthermore, the code should directly use the buffer for handling the reset value to improve memory access and alignment.",
      "id": 123,
      "code_after_change_normalized": "int FUN1(struct usb_device *VAR1, const struct firmware *VAR2, int VAR3)\n{\nstruct hexline *VAR4;\nu8 *VAR5;\nint VAR6, VAR7 = 0;\nu16 VAR8 = VAR9[VAR3].VAR8;\nVAR5 = FUN2(sizeof(*VAR4), VAR10);\nif (!VAR5)\nreturn -VAR11;\nVAR4 = (struct VAR12 *)VAR5;\nVAR5[0] = 1;\nif (FUN3(VAR1, VAR8, VAR5, 1) != 1)\nFUN4(\"STR\");\nwhile ((VAR6 = FUN5(VAR2, VAR4, &VAR7)) > 0) {\nFUN6(\"STR\", VAR4->VAR13, VAR4->VAR14, VAR4->VAR15);\nVAR6 = FUN3(VAR1, VAR4->VAR13, VAR4->VAR16, VAR4->VAR14);\nif (VAR6 != VAR4->VAR14) {\nFUN4(\"STR\",\nVAR6, VAR4->VAR14);\nVAR6 = -VAR17;\nbreak;\n}\n}\nif (VAR6 < 0) {\nFUN4(\"STR\",VAR7,VAR6);\nFUN7(VAR5);\nreturn VAR6;\n}\nif (VAR6 == 0) {\nVAR5[0] = 0;\nif (FUN3(VAR1, VAR8, VAR5, 1) != 1) {\nFUN4(\"STR\");\nVAR6 = -VAR17;\n}\n} else\nVAR6 = -VAR18;\nFUN7(VAR5);\nreturn VAR6;\n}\n",
      "code_before_change_normalized": "int FUN1(struct usb_device *VAR1, const struct firmware *VAR2, int VAR3)\n{\nstruct hexline *VAR4;\nu8 VAR5;\nint VAR6,VAR7=0;\nVAR4 = FUN2(sizeof(*VAR4), VAR8);\nif (!VAR4)\nreturn -VAR9;\nVAR5 = 1;\nif ((VAR6 = FUN3(VAR1,VAR10[VAR3].VAR11,&VAR5,1)) != 1)\nFUN4(\"STR\");\nwhile ((VAR6 = FUN5(VAR2, VAR4, &VAR7)) > 0) {\nFUN6(\"STR\", VAR4->VAR12, VAR4->VAR13, VAR4->VAR14);\nVAR6 = FUN3(VAR1, VAR4->VAR12, VAR4->VAR15, VAR4->VAR13);\nif (VAR6 != VAR4->VAR13) {\nFUN4(\"STR\",\nVAR6, VAR4->VAR13);\nVAR6 = -VAR16;\nbreak;\n}\n}\nif (VAR6 < 0) {\nFUN4(\"STR\",VAR7,VAR6);\nFUN7(VAR4);\nreturn VAR6;\n}\nif (VAR6 == 0) {\nVAR5 = 0;\nif (VAR6 || FUN3(VAR1,VAR10[VAR3].VAR11,&VAR5,1) != 1) {\nFUN4(\"STR\");\nVAR6 = -VAR16;\n}\n} else\nVAR6 = -VAR17;\nFUN7(VAR4);\nreturn VAR6;\n}\n",
      "code_after_change_raw": "int usb_cypress_load_firmware(struct usb_device *udev, const struct firmware *fw, int type)\n{\nstruct hexline *hx;\nu8 *buf;\nint ret, pos = 0;\nu16 cpu_cs_register = cypress[type].cpu_cs_register;\nbuf = kmalloc(sizeof(*hx), GFP_KERNEL);\nif (!buf)\nreturn -ENOMEM;\nhx = (struct hexline *)buf;\nbuf[0] = 1;\nif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1)\nerr(\"could not stop the USB controller CPU.\");\nwhile ((ret = dvb_usb_get_hexline(fw, hx, &pos)) > 0) {\ndeb_fw(\"writing to address 0x%04x (buffer: 0x%02x %02x)\\n\", hx->addr, hx->len, hx->chk);\nret = usb_cypress_writemem(udev, hx->addr, hx->data, hx->len);\nif (ret != hx->len) {\nerr(\"error while transferring firmware (transferred size: %d, block size: %d)\",\nret, hx->len);\nret = -EINVAL;\nbreak;\n}\n}\nif (ret < 0) {\nerr(\"firmware download failed at %d with %d\",pos,ret);\nkfree(buf);\nreturn ret;\n}\nif (ret == 0) {\nbuf[0] = 0;\nif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1) {\nerr(\"could not restart the USB controller CPU.\");\nret = -EINVAL;\n}\n} else\nret = -EIO;\nkfree(buf);\nreturn ret;\n}\n",
      "code_before_change_raw": "int usb_cypress_load_firmware(struct usb_device *udev, const struct firmware *fw, int type)\n{\nstruct hexline *hx;\nu8 reset;\nint ret,pos=0;\nhx = kmalloc(sizeof(*hx), GFP_KERNEL);\nif (!hx)\nreturn -ENOMEM;\nreset = 1;\nif ((ret = usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1)) != 1)\nerr(\"could not stop the USB controller CPU.\");\nwhile ((ret = dvb_usb_get_hexline(fw, hx, &pos)) > 0) {\ndeb_fw(\"writing to address 0x%04x (buffer: 0x%02x %02x)\\n\", hx->addr, hx->len, hx->chk);\nret = usb_cypress_writemem(udev, hx->addr, hx->data, hx->len);\nif (ret != hx->len) {\nerr(\"error while transferring firmware (transferred size: %d, block size: %d)\",\nret, hx->len);\nret = -EINVAL;\nbreak;\n}\n}\nif (ret < 0) {\nerr(\"firmware download failed at %d with %d\",pos,ret);\nkfree(hx);\nreturn ret;\n}\nif (ret == 0) {\nreset = 0;\nif (ret || usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1) != 1) {\nerr(\"could not restart the USB controller CPU.\");\nret = -EINVAL;\n}\n} else\nret = -EIO;\nkfree(hx);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2017-8062": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel.",
        "trigger_condition": "Use of more than one virtual page for a DMA scatterlist.",
        "specific_code_behavior_causing_vulnerability": "Direct manipulation of data arrays without proper structuring and management, leading to potential memory corruption or system crash."
      },
      "solution": "To mitigate the vulnerability, it is necessary to introduce a struct variable to properly store and manage the data being manipulated in the function. This ensures that the data is accessed and modified in a controlled manner, reducing the risk of memory corruption or system crashes. Additionally, proper locking mechanisms should be implemented to ensure thread safety when accessing and modifying the data.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-8062 in the code snippet. The vulnerability arises from the incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel, which can lead to a denial of service or memory corruption when using more than one virtual page for a DMA scatterlist.\n\nThe modification introduces a new `struct dw2102_state *state` variable to store the data being manipulated in the `su3000_i2c_transfer` function. This ensures that the data is properly managed and accessed within the function, reducing the risk of memory corruption or system crashes caused by incorrect handling of the data.\n\nBy using the `state` variable to store and manipulate the data instead of directly accessing arrays like `obuf` and `ibuf`, the code becomes more robust and less prone to vulnerabilities related to DMA scatterlists and virtual memory management. Additionally, the modification includes proper locking mechanisms with `data_mutex` to ensure thread safety when accessing and modifying the data, further enhancing the code's security and stability.",
      "GPT_purpose": "Perform I2C transfers for a specific DVB USB device, handling different cases for single and multiple messages.",
      "GPT_function": "\n1. Perform I2C transfer operations for a given adapter and message array.\n2. Handle different cases based on the number of I2C messages provided.\n3. Execute specific actions based on the I2C message address and content.\n4. Manage read and write operations for I2C communication.\n5. Provide error handling for failed I2C transfers.\n6. Ensure mutual exclusion using a mutex during I2C operations.",
      "CVE_id": "CVE-2017-8062",
      "code_before_change": "static int su3000_i2c_transfer(struct i2c_adapter *adap, struct i2c_msg msg[],\n\t\t\t\t\t\t\t\tint num)\n{\n\tstruct dvb_usb_device *d = i2c_get_adapdata(adap);\n\tu8 obuf[0x40], ibuf[0x40];\n\n\tif (!d)\n\t\treturn -ENODEV;\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\n\t\treturn -EAGAIN;\n\n\tswitch (num) {\n\tcase 1:\n\t\tswitch (msg[0].addr) {\n\t\tcase SU3000_STREAM_CTRL:\n\t\t\tobuf[0] = msg[0].buf[0] + 0x36;\n\t\t\tobuf[1] = 3;\n\t\t\tobuf[2] = 0;\n\t\t\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 0, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tbreak;\n\t\tcase DW2102_RC_QUERY:\n\t\t\tobuf[0] = 0x10;\n\t\t\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 2, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tmsg[0].buf[1] = ibuf[0];\n\t\t\tmsg[0].buf[0] = ibuf[1];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* always i2c write*/\n\t\t\tobuf[0] = 0x08;\n\t\t\tobuf[1] = msg[0].addr;\n\t\t\tobuf[2] = msg[0].len;\n\n\t\t\tmemcpy(&obuf[3], msg[0].buf, msg[0].len);\n\n\t\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 3,\n\t\t\t\t\t\tibuf, 1, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\n\t\t}\n\t\tbreak;\n\tcase 2:\n\t\t/* always i2c read */\n\t\tobuf[0] = 0x09;\n\t\tobuf[1] = msg[0].len;\n\t\tobuf[2] = msg[1].len;\n\t\tobuf[3] = msg[0].addr;\n\t\tmemcpy(&obuf[4], msg[0].buf, msg[0].len);\n\n\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 4,\n\t\t\t\t\tibuf, msg[1].len + 1, 0) < 0)\n\t\t\terr(\"i2c transfer failed.\");\n\n\t\tmemcpy(msg[1].buf, &ibuf[1], msg[1].len);\n\t\tbreak;\n\tdefault:\n\t\twarn(\"more than 2 i2c messages at a time is not handled yet.\");\n\t\tbreak;\n\t}\n\tmutex_unlock(&d->i2c_mutex);\n\treturn num;\n}",
      "code_after_change": "static int su3000_i2c_transfer(struct i2c_adapter *adap, struct i2c_msg msg[],\n\t\t\t\t\t\t\t\tint num)\n{\n\tstruct dvb_usb_device *d = i2c_get_adapdata(adap);\n\tstruct dw2102_state *state;\n\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tstate = d->priv;\n\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\n\t\treturn -EAGAIN;\n\tif (mutex_lock_interruptible(&d->data_mutex) < 0) {\n\t\tmutex_unlock(&d->i2c_mutex);\n\t\treturn -EAGAIN;\n\t}\n\n\tswitch (num) {\n\tcase 1:\n\t\tswitch (msg[0].addr) {\n\t\tcase SU3000_STREAM_CTRL:\n\t\t\tstate->data[0] = msg[0].buf[0] + 0x36;\n\t\t\tstate->data[1] = 3;\n\t\t\tstate->data[2] = 0;\n\t\t\tif (dvb_usb_generic_rw(d, state->data, 3,\n\t\t\t\t\tstate->data, 0, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tbreak;\n\t\tcase DW2102_RC_QUERY:\n\t\t\tstate->data[0] = 0x10;\n\t\t\tif (dvb_usb_generic_rw(d, state->data, 1,\n\t\t\t\t\tstate->data, 2, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tmsg[0].buf[1] = state->data[0];\n\t\t\tmsg[0].buf[0] = state->data[1];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* always i2c write*/\n\t\t\tstate->data[0] = 0x08;\n\t\t\tstate->data[1] = msg[0].addr;\n\t\t\tstate->data[2] = msg[0].len;\n\n\t\t\tmemcpy(&state->data[3], msg[0].buf, msg[0].len);\n\n\t\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 3,\n\t\t\t\t\t\tstate->data, 1, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\n\t\t}\n\t\tbreak;\n\tcase 2:\n\t\t/* always i2c read */\n\t\tstate->data[0] = 0x09;\n\t\tstate->data[1] = msg[0].len;\n\t\tstate->data[2] = msg[1].len;\n\t\tstate->data[3] = msg[0].addr;\n\t\tmemcpy(&state->data[4], msg[0].buf, msg[0].len);\n\n\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 4,\n\t\t\t\t\tstate->data, msg[1].len + 1, 0) < 0)\n\t\t\terr(\"i2c transfer failed.\");\n\n\t\tmemcpy(msg[1].buf, &state->data[1], msg[1].len);\n\t\tbreak;\n\tdefault:\n\t\twarn(\"more than 2 i2c messages at a time is not handled yet.\");\n\t\tbreak;\n\t}\n\tmutex_unlock(&d->data_mutex);\n\tmutex_unlock(&d->i2c_mutex);\n\treturn num;\n}",
      "modified_lines": {
        "added": [
          "\tstruct dw2102_state *state;",
          "",
          "\tstate = d->priv;",
          "",
          "\tif (mutex_lock_interruptible(&d->data_mutex) < 0) {",
          "\t\tmutex_unlock(&d->i2c_mutex);",
          "\t\treturn -EAGAIN;",
          "\t}",
          "\t\t\tstate->data[0] = msg[0].buf[0] + 0x36;",
          "\t\t\tstate->data[1] = 3;",
          "\t\t\tstate->data[2] = 0;",
          "\t\t\tif (dvb_usb_generic_rw(d, state->data, 3,",
          "\t\t\t\t\tstate->data, 0, 0) < 0)",
          "\t\t\tstate->data[0] = 0x10;",
          "\t\t\tif (dvb_usb_generic_rw(d, state->data, 1,",
          "\t\t\t\t\tstate->data, 2, 0) < 0)",
          "\t\t\tmsg[0].buf[1] = state->data[0];",
          "\t\t\tmsg[0].buf[0] = state->data[1];",
          "\t\t\tstate->data[0] = 0x08;",
          "\t\t\tstate->data[1] = msg[0].addr;",
          "\t\t\tstate->data[2] = msg[0].len;",
          "\t\t\tmemcpy(&state->data[3], msg[0].buf, msg[0].len);",
          "\t\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 3,",
          "\t\t\t\t\t\tstate->data, 1, 0) < 0)",
          "\t\tstate->data[0] = 0x09;",
          "\t\tstate->data[1] = msg[0].len;",
          "\t\tstate->data[2] = msg[1].len;",
          "\t\tstate->data[3] = msg[0].addr;",
          "\t\tmemcpy(&state->data[4], msg[0].buf, msg[0].len);",
          "\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 4,",
          "\t\t\t\t\tstate->data, msg[1].len + 1, 0) < 0)",
          "\t\tmemcpy(msg[1].buf, &state->data[1], msg[1].len);",
          "\tmutex_unlock(&d->data_mutex);"
        ],
        "deleted": [
          "\tu8 obuf[0x40], ibuf[0x40];",
          "\t\t\tobuf[0] = msg[0].buf[0] + 0x36;",
          "\t\t\tobuf[1] = 3;",
          "\t\t\tobuf[2] = 0;",
          "\t\t\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 0, 0) < 0)",
          "\t\t\tobuf[0] = 0x10;",
          "\t\t\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 2, 0) < 0)",
          "\t\t\tmsg[0].buf[1] = ibuf[0];",
          "\t\t\tmsg[0].buf[0] = ibuf[1];",
          "\t\t\tobuf[0] = 0x08;",
          "\t\t\tobuf[1] = msg[0].addr;",
          "\t\t\tobuf[2] = msg[0].len;",
          "\t\t\tmemcpy(&obuf[3], msg[0].buf, msg[0].len);",
          "\t\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 3,",
          "\t\t\t\t\t\tibuf, 1, 0) < 0)",
          "\t\tobuf[0] = 0x09;",
          "\t\tobuf[1] = msg[0].len;",
          "\t\tobuf[2] = msg[1].len;",
          "\t\tobuf[3] = msg[0].addr;",
          "\t\tmemcpy(&obuf[4], msg[0].buf, msg[0].len);",
          "\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 4,",
          "\t\t\t\t\tibuf, msg[1].len + 1, 0) < 0)",
          "\t\tmemcpy(msg[1].buf, &ibuf[1], msg[1].len);"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel.",
      "trigger_condition": "Use of more than one virtual page for a DMA scatterlist.",
      "specific_code_behavior_causing_vulnerability": "Direct manipulation of data arrays without proper structuring and management, leading to potential memory corruption or system crash.",
      "id": 124,
      "code_after_change_normalized": "static int FUN1(struct i2c_adapter *VAR1, struct i2c_msg VAR2[],\nint VAR3)\n{\nstruct dvb_usb_device *VAR4 = FUN2(VAR1);\nstruct dw2102_state *VAR5;\nif (!VAR4)\nreturn -VAR6;\nVAR5 = VAR4->VAR7;\nif (FUN3(&VAR4->VAR8) < 0)\nreturn -VAR9;\nif (FUN3(&VAR4->VAR10) < 0) {\nFUN4(&VAR4->VAR8);\nreturn -VAR9;\n}\nswitch (VAR3) {\ncase 1:\nswitch (VAR2[0].VAR11) {\ncase VAR12:\nVAR5->VAR13[0] = VAR2[0].VAR14[0] + VAR15;\nVAR5->VAR13[1] = 3;\nVAR5->VAR13[2] = 0;\nif (FUN5(VAR4, VAR5->VAR13, 3,\nVAR5->VAR13, 0, 0) < 0)\nFUN6(\"STR\");\nbreak;\ncase VAR16:\nVAR5->VAR13[0] = VAR15;\nif (FUN5(VAR4, VAR5->VAR13, 1,\nVAR5->VAR13, 2, 0) < 0)\nFUN6(\"STR\");\nVAR2[0].VAR14[1] = VAR5->VAR13[0];\nVAR2[0].VAR14[0] = VAR5->VAR13[1];\nbreak;\ndefault:\nVAR5->VAR13[0] = VAR15;\nVAR5->VAR13[1] = VAR2[0].VAR11;\nVAR5->VAR13[2] = VAR2[0].VAR17;\nFUN7(&VAR5->VAR13[3], VAR2[0].VAR14, VAR2[0].VAR17);\nif (FUN5(VAR4, VAR5->VAR13, VAR2[0].VAR17 + 3,\nVAR5->VAR13, 1, 0) < 0)\nFUN6(\"STR\");\n}\nbreak;\ncase 2:\nVAR5->VAR13[0] = VAR15;\nVAR5->VAR13[1] = VAR2[0].VAR17;\nVAR5->VAR13[2] = VAR2[1].VAR17;\nVAR5->VAR13[3] = VAR2[0].VAR11;\nFUN7(&VAR5->VAR13[4], VAR2[0].VAR14, VAR2[0].VAR17);\nif (FUN5(VAR4, VAR5->VAR13, VAR2[0].VAR17 + 4,\nVAR5->VAR13, VAR2[1].VAR17 + 1, 0) < 0)\nFUN6(\"STR\");\nFUN7(VAR2[1].VAR14, &VAR5->VAR13[1], VAR2[1].VAR17);\nbreak;\ndefault:\nFUN8(\"STR\");\nbreak;\n}\nFUN4(&VAR4->VAR10);\nFUN4(&VAR4->VAR8);\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct i2c_adapter *VAR1, struct i2c_msg VAR2[],\nint VAR3)\n{\nstruct dvb_usb_device *VAR4 = FUN2(VAR1);\nu8 VAR5[VAR6], VAR7[VAR6];\nif (!VAR4)\nreturn -VAR8;\nif (FUN3(&VAR4->VAR9) < 0)\nreturn -VAR10;\nswitch (VAR3) {\ncase 1:\nswitch (VAR2[0].VAR11) {\ncase VAR12:\nVAR5[0] = VAR2[0].VAR13[0] + VAR6;\nVAR5[1] = 3;\nVAR5[2] = 0;\nif (FUN4(VAR4, VAR5, 3, VAR7, 0, 0) < 0)\nFUN5(\"STR\");\nbreak;\ncase VAR14:\nVAR5[0] = VAR6;\nif (FUN4(VAR4, VAR5, 1, VAR7, 2, 0) < 0)\nFUN5(\"STR\");\nVAR2[0].VAR13[1] = VAR7[0];\nVAR2[0].VAR13[0] = VAR7[1];\nbreak;\ndefault:\nVAR5[0] = VAR6;\nVAR5[1] = VAR2[0].VAR11;\nVAR5[2] = VAR2[0].VAR15;\nFUN6(&VAR5[3], VAR2[0].VAR13, VAR2[0].VAR15);\nif (FUN4(VAR4, VAR5, VAR2[0].VAR15 + 3,\nVAR7, 1, 0) < 0)\nFUN5(\"STR\");\n}\nbreak;\ncase 2:\nVAR5[0] = VAR6;\nVAR5[1] = VAR2[0].VAR15;\nVAR5[2] = VAR2[1].VAR15;\nVAR5[3] = VAR2[0].VAR11;\nFUN6(&VAR5[4], VAR2[0].VAR13, VAR2[0].VAR15);\nif (FUN4(VAR4, VAR5, VAR2[0].VAR15 + 4,\nVAR7, VAR2[1].VAR15 + 1, 0) < 0)\nFUN5(\"STR\");\nFUN6(VAR2[1].VAR13, &VAR7[1], VAR2[1].VAR15);\nbreak;\ndefault:\nFUN7(\"STR\");\nbreak;\n}\nFUN8(&VAR4->VAR9);\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static int su3000_i2c_transfer(struct i2c_adapter *adap, struct i2c_msg msg[],\nint num)\n{\nstruct dvb_usb_device *d = i2c_get_adapdata(adap);\nstruct dw2102_state *state;\nif (!d)\nreturn -ENODEV;\nstate = d->priv;\nif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\nreturn -EAGAIN;\nif (mutex_lock_interruptible(&d->data_mutex) < 0) {\nmutex_unlock(&d->i2c_mutex);\nreturn -EAGAIN;\n}\nswitch (num) {\ncase 1:\nswitch (msg[0].addr) {\ncase SU3000_STREAM_CTRL:\nstate->data[0] = msg[0].buf[0] + 0x36;\nstate->data[1] = 3;\nstate->data[2] = 0;\nif (dvb_usb_generic_rw(d, state->data, 3,\nstate->data, 0, 0) < 0)\nerr(\"i2c transfer failed.\");\nbreak;\ncase DW2102_RC_QUERY:\nstate->data[0] = 0x10;\nif (dvb_usb_generic_rw(d, state->data, 1,\nstate->data, 2, 0) < 0)\nerr(\"i2c transfer failed.\");\nmsg[0].buf[1] = state->data[0];\nmsg[0].buf[0] = state->data[1];\nbreak;\ndefault:\nstate->data[0] = 0x08;\nstate->data[1] = msg[0].addr;\nstate->data[2] = msg[0].len;\nmemcpy(&state->data[3], msg[0].buf, msg[0].len);\nif (dvb_usb_generic_rw(d, state->data, msg[0].len + 3,\nstate->data, 1, 0) < 0)\nerr(\"i2c transfer failed.\");\n}\nbreak;\ncase 2:\nstate->data[0] = 0x09;\nstate->data[1] = msg[0].len;\nstate->data[2] = msg[1].len;\nstate->data[3] = msg[0].addr;\nmemcpy(&state->data[4], msg[0].buf, msg[0].len);\nif (dvb_usb_generic_rw(d, state->data, msg[0].len + 4,\nstate->data, msg[1].len + 1, 0) < 0)\nerr(\"i2c transfer failed.\");\nmemcpy(msg[1].buf, &state->data[1], msg[1].len);\nbreak;\ndefault:\nwarn(\"more than 2 i2c messages at a time is not handled yet.\");\nbreak;\n}\nmutex_unlock(&d->data_mutex);\nmutex_unlock(&d->i2c_mutex);\nreturn num;\n}\n",
      "code_before_change_raw": "static int su3000_i2c_transfer(struct i2c_adapter *adap, struct i2c_msg msg[],\nint num)\n{\nstruct dvb_usb_device *d = i2c_get_adapdata(adap);\nu8 obuf[0x40], ibuf[0x40];\nif (!d)\nreturn -ENODEV;\nif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\nreturn -EAGAIN;\nswitch (num) {\ncase 1:\nswitch (msg[0].addr) {\ncase SU3000_STREAM_CTRL:\nobuf[0] = msg[0].buf[0] + 0x36;\nobuf[1] = 3;\nobuf[2] = 0;\nif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 0, 0) < 0)\nerr(\"i2c transfer failed.\");\nbreak;\ncase DW2102_RC_QUERY:\nobuf[0] = 0x10;\nif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 2, 0) < 0)\nerr(\"i2c transfer failed.\");\nmsg[0].buf[1] = ibuf[0];\nmsg[0].buf[0] = ibuf[1];\nbreak;\ndefault:\nobuf[0] = 0x08;\nobuf[1] = msg[0].addr;\nobuf[2] = msg[0].len;\nmemcpy(&obuf[3], msg[0].buf, msg[0].len);\nif (dvb_usb_generic_rw(d, obuf, msg[0].len + 3,\nibuf, 1, 0) < 0)\nerr(\"i2c transfer failed.\");\n}\nbreak;\ncase 2:\nobuf[0] = 0x09;\nobuf[1] = msg[0].len;\nobuf[2] = msg[1].len;\nobuf[3] = msg[0].addr;\nmemcpy(&obuf[4], msg[0].buf, msg[0].len);\nif (dvb_usb_generic_rw(d, obuf, msg[0].len + 4,\nibuf, msg[1].len + 1, 0) < 0)\nerr(\"i2c transfer failed.\");\nmemcpy(msg[1].buf, &ibuf[1], msg[1].len);\nbreak;\ndefault:\nwarn(\"more than 2 i2c messages at a time is not handled yet.\");\nbreak;\n}\nmutex_unlock(&d->i2c_mutex);\nreturn num;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel versions 4.9.x and 4.10.x before 4.10.4.",
        "trigger_condition": "Use of more than one virtual page for a DMA scatterlist, leading to a denial of service (system crash or memory corruption) or other unspecified impacts.",
        "specific_code_behavior_causing_vulnerability": "The code does not provide proper synchronization when accessing and manipulating shared data, potentially allowing multiple threads to concurrently access the data and leading to memory corruption or system crashes."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add mutex locks around critical sections of code where shared data is accessed and manipulated. This ensures that only one thread can access the data at a time, preventing race conditions and maintaining data integrity. By using mutex locks, the code enforces proper synchronization and reduces the risk of exploitation by multiple threads. In this case, the solution involves adding mutex locks before and after accessing shared data to prevent concurrent access and address the vulnerability related to the CONFIG_VMAP_STACK option.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-8062 in the code snippet. The vulnerability arises from the incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel versions 4.9.x and 4.10.x before 4.10.4. This vulnerability can allow local users to cause a denial of service (system crash or memory corruption) or potentially have other unspecified impacts by leveraging the use of more than one virtual page for a DMA scatterlist.\n\nThe modification involves adding mutex locks and unlocks around the critical sections of code where data is being accessed and manipulated. By using mutex locks, we ensure that only one thread can access the shared data at a time, preventing potential race conditions and ensuring data integrity. This helps to mitigate the risk of the vulnerability being exploited by multiple threads concurrently accessing the same data structures, which could lead to memory corruption or system crashes.\n\nTherefore, the addition of mutex locks in the modified code snippet helps to prevent the exploitation of the vulnerability by providing proper synchronization and control over data access, thereby enhancing the security and stability of the code.",
      "GPT_purpose": "Attaching the frontend and tuner devices for a DVB USB adapter using specific configurations and modules.",
      "GPT_function": "\n1. Attach the frontend device\n2. Attach the demodulator\n3. Attach the tuner",
      "CVE_id": "CVE-2017-8062",
      "code_before_change": "static int tt_s2_4600_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dvb_usb_device *d = adap->dev;\n\tstruct dw2102_state *state = d->priv;\n\tu8 obuf[3] = { 0xe, 0x80, 0 };\n\tu8 ibuf[] = { 0 };\n\tstruct i2c_adapter *i2c_adapter;\n\tstruct i2c_client *client;\n\tstruct i2c_board_info board_info;\n\tstruct m88ds3103_platform_data m88ds3103_pdata = {};\n\tstruct ts2020_config ts2020_config = {};\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tobuf[0] = 0xe;\n\tobuf[1] = 0x02;\n\tobuf[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\tmsleep(300);\n\n\tobuf[0] = 0xe;\n\tobuf[1] = 0x83;\n\tobuf[2] = 0;\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tobuf[0] = 0xe;\n\tobuf[1] = 0x83;\n\tobuf[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tobuf[0] = 0x51;\n\n\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x51 transfer failed.\");\n\n\t/* attach demod */\n\tm88ds3103_pdata.clk = 27000000;\n\tm88ds3103_pdata.i2c_wr_max = 33;\n\tm88ds3103_pdata.ts_mode = M88DS3103_TS_CI;\n\tm88ds3103_pdata.ts_clk = 16000;\n\tm88ds3103_pdata.ts_clk_pol = 0;\n\tm88ds3103_pdata.spec_inv = 0;\n\tm88ds3103_pdata.agc = 0x99;\n\tm88ds3103_pdata.agc_inv = 0;\n\tm88ds3103_pdata.clk_out = M88DS3103_CLOCK_OUT_ENABLED;\n\tm88ds3103_pdata.envelope_mode = 0;\n\tm88ds3103_pdata.lnb_hv_pol = 1;\n\tm88ds3103_pdata.lnb_en_pol = 0;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"m88ds3103\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x68;\n\tboard_info.platform_data = &m88ds3103_pdata;\n\trequest_module(\"m88ds3103\");\n\tclient = i2c_new_device(&d->i2c_adap, &board_info);\n\tif (client == NULL || client->dev.driver == NULL)\n\t\treturn -ENODEV;\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = m88ds3103_pdata.get_dvb_frontend(client);\n\ti2c_adapter = m88ds3103_pdata.get_i2c_adapter(client);\n\n\tstate->i2c_client_demod = client;\n\n\t/* attach tuner */\n\tts2020_config.fe = adap->fe_adap[0].fe;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"ts2022\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x60;\n\tboard_info.platform_data = &ts2020_config;\n\trequest_module(\"ts2020\");\n\tclient = i2c_new_device(i2c_adapter, &board_info);\n\n\tif (client == NULL || client->dev.driver == NULL) {\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\t/* delegate signal strength measurement to tuner */\n\tadap->fe_adap[0].fe->ops.read_signal_strength =\n\t\t\tadap->fe_adap[0].fe->ops.tuner_ops.get_rf_strength;\n\n\tstate->i2c_client_tuner = client;\n\n\t/* hook fe: need to resync the slave fifo when signal locks */\n\tstate->fe_read_status = adap->fe_adap[0].fe->ops.read_status;\n\tadap->fe_adap[0].fe->ops.read_status = tt_s2_4600_read_status;\n\n\tstate->last_lock = 0;\n\n\treturn 0;\n}",
      "code_after_change": "static int tt_s2_4600_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dvb_usb_device *d = adap->dev;\n\tstruct dw2102_state *state = d->priv;\n\tstruct i2c_adapter *i2c_adapter;\n\tstruct i2c_client *client;\n\tstruct i2c_board_info board_info;\n\tstruct m88ds3103_platform_data m88ds3103_pdata = {};\n\tstruct ts2020_config ts2020_config = {};\n\n\tmutex_lock(&d->data_mutex);\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x80;\n\tstate->data[2] = 0x0;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x02;\n\tstate->data[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\tmsleep(300);\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x83;\n\tstate->data[2] = 0;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x83;\n\tstate->data[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tstate->data[0] = 0x51;\n\n\tif (dvb_usb_generic_rw(d, state->data, 1, state->data, 1, 0) < 0)\n\t\terr(\"command 0x51 transfer failed.\");\n\n\tmutex_unlock(&d->data_mutex);\n\n\t/* attach demod */\n\tm88ds3103_pdata.clk = 27000000;\n\tm88ds3103_pdata.i2c_wr_max = 33;\n\tm88ds3103_pdata.ts_mode = M88DS3103_TS_CI;\n\tm88ds3103_pdata.ts_clk = 16000;\n\tm88ds3103_pdata.ts_clk_pol = 0;\n\tm88ds3103_pdata.spec_inv = 0;\n\tm88ds3103_pdata.agc = 0x99;\n\tm88ds3103_pdata.agc_inv = 0;\n\tm88ds3103_pdata.clk_out = M88DS3103_CLOCK_OUT_ENABLED;\n\tm88ds3103_pdata.envelope_mode = 0;\n\tm88ds3103_pdata.lnb_hv_pol = 1;\n\tm88ds3103_pdata.lnb_en_pol = 0;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"m88ds3103\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x68;\n\tboard_info.platform_data = &m88ds3103_pdata;\n\trequest_module(\"m88ds3103\");\n\tclient = i2c_new_device(&d->i2c_adap, &board_info);\n\tif (client == NULL || client->dev.driver == NULL)\n\t\treturn -ENODEV;\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = m88ds3103_pdata.get_dvb_frontend(client);\n\ti2c_adapter = m88ds3103_pdata.get_i2c_adapter(client);\n\n\tstate->i2c_client_demod = client;\n\n\t/* attach tuner */\n\tts2020_config.fe = adap->fe_adap[0].fe;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"ts2022\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x60;\n\tboard_info.platform_data = &ts2020_config;\n\trequest_module(\"ts2020\");\n\tclient = i2c_new_device(i2c_adapter, &board_info);\n\n\tif (client == NULL || client->dev.driver == NULL) {\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\t/* delegate signal strength measurement to tuner */\n\tadap->fe_adap[0].fe->ops.read_signal_strength =\n\t\t\tadap->fe_adap[0].fe->ops.tuner_ops.get_rf_strength;\n\n\tstate->i2c_client_tuner = client;\n\n\t/* hook fe: need to resync the slave fifo when signal locks */\n\tstate->fe_read_status = adap->fe_adap[0].fe->ops.read_status;\n\tadap->fe_adap[0].fe->ops.read_status = tt_s2_4600_read_status;\n\n\tstate->last_lock = 0;\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tmutex_lock(&d->data_mutex);",
          "",
          "\tstate->data[0] = 0xe;",
          "\tstate->data[1] = 0x80;",
          "\tstate->data[2] = 0x0;",
          "",
          "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
          "\tstate->data[0] = 0xe;",
          "\tstate->data[1] = 0x02;",
          "\tstate->data[2] = 1;",
          "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
          "\tstate->data[0] = 0xe;",
          "\tstate->data[1] = 0x83;",
          "\tstate->data[2] = 0;",
          "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
          "\tstate->data[0] = 0xe;",
          "\tstate->data[1] = 0x83;",
          "\tstate->data[2] = 1;",
          "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
          "\tstate->data[0] = 0x51;",
          "\tif (dvb_usb_generic_rw(d, state->data, 1, state->data, 1, 0) < 0)",
          "",
          "\tmutex_unlock(&d->data_mutex);"
        ],
        "deleted": [
          "\tu8 obuf[3] = { 0xe, 0x80, 0 };",
          "\tu8 ibuf[] = { 0 };",
          "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
          "\tobuf[0] = 0xe;",
          "\tobuf[1] = 0x02;",
          "\tobuf[2] = 1;",
          "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
          "\tobuf[0] = 0xe;",
          "\tobuf[1] = 0x83;",
          "\tobuf[2] = 0;",
          "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
          "\tobuf[0] = 0xe;",
          "\tobuf[1] = 0x83;",
          "\tobuf[2] = 1;",
          "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
          "\tobuf[0] = 0x51;",
          "\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 1, 0) < 0)"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel versions 4.9.x and 4.10.x before 4.10.4.",
      "trigger_condition": "Use of more than one virtual page for a DMA scatterlist, leading to a denial of service (system crash or memory corruption) or other unspecified impacts.",
      "specific_code_behavior_causing_vulnerability": "The code does not provide proper synchronization when accessing and manipulating shared data, potentially allowing multiple threads to concurrently access the data and leading to memory corruption or system crashes.",
      "id": 125,
      "code_after_change_normalized": "static int FUN1(struct dvb_usb_adapter *VAR1)\n{\nstruct dvb_usb_device *VAR2 = VAR1->VAR3;\nstruct dw2102_state *VAR4 = VAR2->VAR5;\nstruct VAR6 *VAR6;\nstruct i2c_client *VAR7;\nstruct i2c_board_info VAR8;\nstruct m88ds3103_platform_data VAR9 = {};\nstruct ts2020_config VAR10 = {};\nFUN2(&VAR2->VAR11);\nVAR4->VAR12[0] = VAR13;\nVAR4->VAR12[1] = VAR13;\nVAR4->VAR12[2] = VAR13;\nif (FUN3(VAR2, VAR4->VAR12, 3, VAR4->VAR12, 1, 0) < 0)\nFUN4(\"STR\");\nVAR4->VAR12[0] = VAR13;\nVAR4->VAR12[1] = VAR13;\nVAR4->VAR12[2] = 1;\nif (FUN3(VAR2, VAR4->VAR12, 3, VAR4->VAR12, 1, 0) < 0)\nFUN4(\"STR\");\nFUN5(300);\nVAR4->VAR12[0] = VAR13;\nVAR4->VAR12[1] = VAR13;\nVAR4->VAR12[2] = 0;\nif (FUN3(VAR2, VAR4->VAR12, 3, VAR4->VAR12, 1, 0) < 0)\nFUN4(\"STR\");\nVAR4->VAR12[0] = VAR13;\nVAR4->VAR12[1] = VAR13;\nVAR4->VAR12[2] = 1;\nif (FUN3(VAR2, VAR4->VAR12, 3, VAR4->VAR12, 1, 0) < 0)\nFUN4(\"STR\");\nVAR4->VAR12[0] = VAR13;\nif (FUN3(VAR2, VAR4->VAR12, 1, VAR4->VAR12, 1, 0) < 0)\nFUN4(\"STR\");\nFUN6(&VAR2->VAR11);\nVAR9.VAR14 = 27000000;\nVAR9.VAR15 = 33;\nVAR9.VAR16 = VAR17;\nVAR9.VAR18 = 16000;\nVAR9.VAR19 = 0;\nVAR9.VAR20 = 0;\nVAR9.VAR21 = VAR13;\nVAR9.VAR22 = 0;\nVAR9.VAR23 = VAR24;\nVAR9.VAR25 = 0;\nVAR9.VAR26 = 1;\nVAR9.VAR27 = 0;\nFUN7(&VAR8, 0, sizeof(VAR8));\nFUN8(VAR8.VAR28, \"STR\", VAR29);\nVAR8.VAR30 = VAR13;\nVAR8.VAR31 = &VAR9;\nFUN9(\"STR\");\nVAR7 = FUN10(&VAR2->VAR32, &VAR8);\nif (VAR7 == NULL || VAR7->VAR3.VAR33 == NULL)\nreturn -VAR34;\nif (!FUN11(VAR7->VAR3.VAR33->VAR35)) {\nFUN12(VAR7);\nreturn -VAR34;\n}\nVAR1->VAR36[0].VAR37 = VAR9.FUN13(VAR7);\nVAR6 = VAR9.FUN14(VAR7);\nVAR4->VAR38 = VAR7;\nVAR10.VAR37 = VAR1->VAR36[0].VAR37;\nFUN7(&VAR8, 0, sizeof(VAR8));\nFUN8(VAR8.VAR28, \"STR\", VAR29);\nVAR8.VAR30 = VAR13;\nVAR8.VAR31 = &VAR10;\nFUN9(\"STR\");\nVAR7 = FUN10(VAR6, &VAR8);\nif (VAR7 == NULL || VAR7->VAR3.VAR33 == NULL) {\nFUN15(VAR1->VAR36[0].VAR37);\nreturn -VAR34;\n}\nif (!FUN11(VAR7->VAR3.VAR33->VAR35)) {\nFUN12(VAR7);\nFUN15(VAR1->VAR36[0].VAR37);\nreturn -VAR34;\n}\nVAR1->VAR36[0].VAR37->VAR39.VAR40 =\nVAR1->VAR36[0].VAR37->VAR39.VAR41.VAR42;\nVAR4->VAR43 = VAR7;\nVAR4->VAR44 = VAR1->VAR36[0].VAR37->VAR39.VAR45;\nVAR1->VAR36[0].VAR37->VAR39.VAR45 = VAR46;\nVAR4->VAR47 = 0;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct dvb_usb_adapter *VAR1)\n{\nstruct dvb_usb_device *VAR2 = VAR1->VAR3;\nstruct dw2102_state *VAR4 = VAR2->VAR5;\nu8 VAR6[3] = { VAR7, VAR7, 0 };\nu8 VAR8[] = { 0 };\nstruct VAR9 *VAR9;\nstruct i2c_client *VAR10;\nstruct i2c_board_info VAR11;\nstruct m88ds3103_platform_data VAR12 = {};\nstruct ts2020_config VAR13 = {};\nif (FUN2(VAR2, VAR6, 3, VAR8, 1, 0) < 0)\nFUN3(\"STR\");\nVAR6[0] = VAR7;\nVAR6[1] = VAR7;\nVAR6[2] = 1;\nif (FUN2(VAR2, VAR6, 3, VAR8, 1, 0) < 0)\nFUN3(\"STR\");\nFUN4(300);\nVAR6[0] = VAR7;\nVAR6[1] = VAR7;\nVAR6[2] = 0;\nif (FUN2(VAR2, VAR6, 3, VAR8, 1, 0) < 0)\nFUN3(\"STR\");\nVAR6[0] = VAR7;\nVAR6[1] = VAR7;\nVAR6[2] = 1;\nif (FUN2(VAR2, VAR6, 3, VAR8, 1, 0) < 0)\nFUN3(\"STR\");\nVAR6[0] = VAR7;\nif (FUN2(VAR2, VAR6, 1, VAR8, 1, 0) < 0)\nFUN3(\"STR\");\nVAR12.VAR14 = 27000000;\nVAR12.VAR15 = 33;\nVAR12.VAR16 = VAR17;\nVAR12.VAR18 = 16000;\nVAR12.VAR19 = 0;\nVAR12.VAR20 = 0;\nVAR12.VAR21 = VAR7;\nVAR12.VAR22 = 0;\nVAR12.VAR23 = VAR24;\nVAR12.VAR25 = 0;\nVAR12.VAR26 = 1;\nVAR12.VAR27 = 0;\nFUN5(&VAR11, 0, sizeof(VAR11));\nFUN6(VAR11.VAR28, \"STR\", VAR29);\nVAR11.VAR30 = VAR7;\nVAR11.VAR31 = &VAR12;\nFUN7(\"STR\");\nVAR10 = FUN8(&VAR2->VAR32, &VAR11);\nif (VAR10 == NULL || VAR10->VAR3.VAR33 == NULL)\nreturn -VAR34;\nif (!FUN9(VAR10->VAR3.VAR33->VAR35)) {\nFUN10(VAR10);\nreturn -VAR34;\n}\nVAR1->VAR36[0].VAR37 = VAR12.FUN11(VAR10);\nVAR9 = VAR12.FUN12(VAR10);\nVAR4->VAR38 = VAR10;\nVAR13.VAR37 = VAR1->VAR36[0].VAR37;\nFUN5(&VAR11, 0, sizeof(VAR11));\nFUN6(VAR11.VAR28, \"STR\", VAR29);\nVAR11.VAR30 = VAR7;\nVAR11.VAR31 = &VAR13;\nFUN7(\"STR\");\nVAR10 = FUN8(VAR9, &VAR11);\nif (VAR10 == NULL || VAR10->VAR3.VAR33 == NULL) {\nFUN13(VAR1->VAR36[0].VAR37);\nreturn -VAR34;\n}\nif (!FUN9(VAR10->VAR3.VAR33->VAR35)) {\nFUN10(VAR10);\nFUN13(VAR1->VAR36[0].VAR37);\nreturn -VAR34;\n}\nVAR1->VAR36[0].VAR37->VAR39.VAR40 =\nVAR1->VAR36[0].VAR37->VAR39.VAR41.VAR42;\nVAR4->VAR43 = VAR10;\nVAR4->VAR44 = VAR1->VAR36[0].VAR37->VAR39.VAR45;\nVAR1->VAR36[0].VAR37->VAR39.VAR45 = VAR46;\nVAR4->VAR47 = 0;\nreturn 0;\n}\n",
      "code_after_change_raw": "static int tt_s2_4600_frontend_attach(struct dvb_usb_adapter *adap)\n{\nstruct dvb_usb_device *d = adap->dev;\nstruct dw2102_state *state = d->priv;\nstruct i2c_adapter *i2c_adapter;\nstruct i2c_client *client;\nstruct i2c_board_info board_info;\nstruct m88ds3103_platform_data m88ds3103_pdata = {};\nstruct ts2020_config ts2020_config = {};\nmutex_lock(&d->data_mutex);\nstate->data[0] = 0xe;\nstate->data[1] = 0x80;\nstate->data[2] = 0x0;\nif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nstate->data[0] = 0xe;\nstate->data[1] = 0x02;\nstate->data[2] = 1;\nif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nmsleep(300);\nstate->data[0] = 0xe;\nstate->data[1] = 0x83;\nstate->data[2] = 0;\nif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nstate->data[0] = 0xe;\nstate->data[1] = 0x83;\nstate->data[2] = 1;\nif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nstate->data[0] = 0x51;\nif (dvb_usb_generic_rw(d, state->data, 1, state->data, 1, 0) < 0)\nerr(\"command 0x51 transfer failed.\");\nmutex_unlock(&d->data_mutex);\nm88ds3103_pdata.clk = 27000000;\nm88ds3103_pdata.i2c_wr_max = 33;\nm88ds3103_pdata.ts_mode = M88DS3103_TS_CI;\nm88ds3103_pdata.ts_clk = 16000;\nm88ds3103_pdata.ts_clk_pol = 0;\nm88ds3103_pdata.spec_inv = 0;\nm88ds3103_pdata.agc = 0x99;\nm88ds3103_pdata.agc_inv = 0;\nm88ds3103_pdata.clk_out = M88DS3103_CLOCK_OUT_ENABLED;\nm88ds3103_pdata.envelope_mode = 0;\nm88ds3103_pdata.lnb_hv_pol = 1;\nm88ds3103_pdata.lnb_en_pol = 0;\nmemset(&board_info, 0, sizeof(board_info));\nstrlcpy(board_info.type, \"m88ds3103\", I2C_NAME_SIZE);\nboard_info.addr = 0x68;\nboard_info.platform_data = &m88ds3103_pdata;\nrequest_module(\"m88ds3103\");\nclient = i2c_new_device(&d->i2c_adap, &board_info);\nif (client == NULL || client->dev.driver == NULL)\nreturn -ENODEV;\nif (!try_module_get(client->dev.driver->owner)) {\ni2c_unregister_device(client);\nreturn -ENODEV;\n}\nadap->fe_adap[0].fe = m88ds3103_pdata.get_dvb_frontend(client);\ni2c_adapter = m88ds3103_pdata.get_i2c_adapter(client);\nstate->i2c_client_demod = client;\nts2020_config.fe = adap->fe_adap[0].fe;\nmemset(&board_info, 0, sizeof(board_info));\nstrlcpy(board_info.type, \"ts2022\", I2C_NAME_SIZE);\nboard_info.addr = 0x60;\nboard_info.platform_data = &ts2020_config;\nrequest_module(\"ts2020\");\nclient = i2c_new_device(i2c_adapter, &board_info);\nif (client == NULL || client->dev.driver == NULL) {\ndvb_frontend_detach(adap->fe_adap[0].fe);\nreturn -ENODEV;\n}\nif (!try_module_get(client->dev.driver->owner)) {\ni2c_unregister_device(client);\ndvb_frontend_detach(adap->fe_adap[0].fe);\nreturn -ENODEV;\n}\nadap->fe_adap[0].fe->ops.read_signal_strength =\nadap->fe_adap[0].fe->ops.tuner_ops.get_rf_strength;\nstate->i2c_client_tuner = client;\nstate->fe_read_status = adap->fe_adap[0].fe->ops.read_status;\nadap->fe_adap[0].fe->ops.read_status = tt_s2_4600_read_status;\nstate->last_lock = 0;\nreturn 0;\n}\n",
      "code_before_change_raw": "static int tt_s2_4600_frontend_attach(struct dvb_usb_adapter *adap)\n{\nstruct dvb_usb_device *d = adap->dev;\nstruct dw2102_state *state = d->priv;\nu8 obuf[3] = { 0xe, 0x80, 0 };\nu8 ibuf[] = { 0 };\nstruct i2c_adapter *i2c_adapter;\nstruct i2c_client *client;\nstruct i2c_board_info board_info;\nstruct m88ds3103_platform_data m88ds3103_pdata = {};\nstruct ts2020_config ts2020_config = {};\nif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nobuf[0] = 0xe;\nobuf[1] = 0x02;\nobuf[2] = 1;\nif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nmsleep(300);\nobuf[0] = 0xe;\nobuf[1] = 0x83;\nobuf[2] = 0;\nif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nobuf[0] = 0xe;\nobuf[1] = 0x83;\nobuf[2] = 1;\nif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\nerr(\"command 0x0e transfer failed.\");\nobuf[0] = 0x51;\nif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 1, 0) < 0)\nerr(\"command 0x51 transfer failed.\");\nm88ds3103_pdata.clk = 27000000;\nm88ds3103_pdata.i2c_wr_max = 33;\nm88ds3103_pdata.ts_mode = M88DS3103_TS_CI;\nm88ds3103_pdata.ts_clk = 16000;\nm88ds3103_pdata.ts_clk_pol = 0;\nm88ds3103_pdata.spec_inv = 0;\nm88ds3103_pdata.agc = 0x99;\nm88ds3103_pdata.agc_inv = 0;\nm88ds3103_pdata.clk_out = M88DS3103_CLOCK_OUT_ENABLED;\nm88ds3103_pdata.envelope_mode = 0;\nm88ds3103_pdata.lnb_hv_pol = 1;\nm88ds3103_pdata.lnb_en_pol = 0;\nmemset(&board_info, 0, sizeof(board_info));\nstrlcpy(board_info.type, \"m88ds3103\", I2C_NAME_SIZE);\nboard_info.addr = 0x68;\nboard_info.platform_data = &m88ds3103_pdata;\nrequest_module(\"m88ds3103\");\nclient = i2c_new_device(&d->i2c_adap, &board_info);\nif (client == NULL || client->dev.driver == NULL)\nreturn -ENODEV;\nif (!try_module_get(client->dev.driver->owner)) {\ni2c_unregister_device(client);\nreturn -ENODEV;\n}\nadap->fe_adap[0].fe = m88ds3103_pdata.get_dvb_frontend(client);\ni2c_adapter = m88ds3103_pdata.get_i2c_adapter(client);\nstate->i2c_client_demod = client;\nts2020_config.fe = adap->fe_adap[0].fe;\nmemset(&board_info, 0, sizeof(board_info));\nstrlcpy(board_info.type, \"ts2022\", I2C_NAME_SIZE);\nboard_info.addr = 0x60;\nboard_info.platform_data = &ts2020_config;\nrequest_module(\"ts2020\");\nclient = i2c_new_device(i2c_adapter, &board_info);\nif (client == NULL || client->dev.driver == NULL) {\ndvb_frontend_detach(adap->fe_adap[0].fe);\nreturn -ENODEV;\n}\nif (!try_module_get(client->dev.driver->owner)) {\ni2c_unregister_device(client);\ndvb_frontend_detach(adap->fe_adap[0].fe);\nreturn -ENODEV;\n}\nadap->fe_adap[0].fe->ops.read_signal_strength =\nadap->fe_adap[0].fe->ops.tuner_ops.get_rf_strength;\nstate->i2c_client_tuner = client;\nstate->fe_read_status = adap->fe_adap[0].fe->ops.read_status;\nadap->fe_adap[0].fe->ops.read_status = tt_s2_4600_read_status;\nstate->last_lock = 0;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2017-8063": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Interaction with CONFIG_VMAP_STACK option leads to improper handling of DMA scatterlists.",
        "trigger_condition": "Use of more than one virtual page for a DMA scatterlist.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check the length of the read buffer (rlen) against MAX_XFER_SIZE, potentially allowing for issues related to DMA scatterlists. This can lead to a denial of service or other unspecified impacts due to the incorrect interaction with the CONFIG_VMAP_STACK option."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the length of the read buffer (rlen) does not exceed MAX_XFER_SIZE. Additionally, the code should handle the read operation securely by using dvb_usb_generic_rw to read data into the buffer and then copying the data to the output buffer if necessary. This solution addresses the vulnerability by properly checking and handling the read operation, making the code more secure and less susceptible to potential exploits.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-8063 in the code snippet. The vulnerability arises from the incorrect interaction with the CONFIG_VMAP_STACK option, which can lead to a denial of service or other unspecified impacts due to the improper handling of DMA scatterlists.\n\nThe modification addresses this vulnerability by ensuring that the length of the read buffer (rlen) is checked against MAX_XFER_SIZE to prevent potential issues related to DMA scatterlists. By adding the check for rlen against MAX_XFER_SIZE and handling the read operation appropriately, the code becomes more secure and less susceptible to the vulnerability.\n\nAdditionally, the modification also includes proper handling of the read operation by using dvb_usb_generic_rw to read data into the st->data buffer and then copying the data to the output buffer (rbuf) if necessary. This ensures that the read operation is performed correctly and securely.\n\nOverall, the modification improves the code's security by addressing the vulnerability and ensuring proper handling of read operations, making the code more robust and less prone to potential exploits.",
      "GPT_purpose": "Perform control message handling for a cxusb device by sending and receiving data packets.",
      "GPT_function": "\n1. Handles control messages for a cxusb device.\n2. Checks if the length of the message is within the maximum transfer size.\n3. Determines if the message is write-only.\n4. Locks the data mutex.\n5. Copies the command and data to the device state.\n6. Writes data to the device or performs read/write operation based on the parameters.\n7. Unlocks the data mutex.\n8. Returns the result of the operation.",
      "CVE_id": "CVE-2017-8063",
      "code_before_change": "static int cxusb_ctrl_msg(struct dvb_usb_device *d,\n\t\t\t  u8 cmd, u8 *wbuf, int wlen, u8 *rbuf, int rlen)\n{\n\tstruct cxusb_state *st = d->priv;\n\tint ret, wo;\n\n\tif (1 + wlen > MAX_XFER_SIZE) {\n\t\twarn(\"i2c wr: len=%d is too big!\\n\", wlen);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\two = (rbuf == NULL || rlen == 0); /* write-only */\n\n\tmutex_lock(&d->data_mutex);\n\tst->data[0] = cmd;\n\tmemcpy(&st->data[1], wbuf, wlen);\n\tif (wo)\n\t\tret = dvb_usb_generic_write(d, st->data, 1 + wlen);\n\telse\n\t\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen,\n\t\t\t\t\t rbuf, rlen, 0);\n\n\tmutex_unlock(&d->data_mutex);\n\treturn ret;\n}",
      "code_after_change": "static int cxusb_ctrl_msg(struct dvb_usb_device *d,\n\t\t\t  u8 cmd, u8 *wbuf, int wlen, u8 *rbuf, int rlen)\n{\n\tstruct cxusb_state *st = d->priv;\n\tint ret;\n\n\tif (1 + wlen > MAX_XFER_SIZE) {\n\t\twarn(\"i2c wr: len=%d is too big!\\n\", wlen);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (rlen > MAX_XFER_SIZE) {\n\t\twarn(\"i2c rd: len=%d is too big!\\n\", rlen);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmutex_lock(&d->data_mutex);\n\tst->data[0] = cmd;\n\tmemcpy(&st->data[1], wbuf, wlen);\n\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen, st->data, rlen, 0);\n\tif (!ret && rbuf && rlen)\n\t\tmemcpy(rbuf, st->data, rlen);\n\n\tmutex_unlock(&d->data_mutex);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tint ret;",
          "\tif (rlen > MAX_XFER_SIZE) {",
          "\t\twarn(\"i2c rd: len=%d is too big!\\n\", rlen);",
          "\t\treturn -EOPNOTSUPP;",
          "\t}",
          "\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen, st->data, rlen, 0);",
          "\tif (!ret && rbuf && rlen)",
          "\t\tmemcpy(rbuf, st->data, rlen);"
        ],
        "deleted": [
          "\tint ret, wo;",
          "\two = (rbuf == NULL || rlen == 0); /* write-only */",
          "\tif (wo)",
          "\t\tret = dvb_usb_generic_write(d, st->data, 1 + wlen);",
          "\telse",
          "\t\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen,",
          "\t\t\t\t\t rbuf, rlen, 0);"
        ]
      },
      "preconditions_for_vulnerability": "Interaction with CONFIG_VMAP_STACK option leads to improper handling of DMA scatterlists.",
      "trigger_condition": "Use of more than one virtual page for a DMA scatterlist.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check the length of the read buffer (rlen) against MAX_XFER_SIZE, potentially allowing for issues related to DMA scatterlists. This can lead to a denial of service or other unspecified impacts due to the incorrect interaction with the CONFIG_VMAP_STACK option.",
      "id": 126,
      "code_after_change_normalized": "static int FUN1(struct dvb_usb_device *VAR1,\nu8 VAR2, u8 *VAR3, int VAR4, u8 *VAR5, int VAR6)\n{\nstruct cxusb_state *VAR7 = VAR1->VAR8;\nint VAR9;\nif (1 + VAR4 > VAR10) {\nFUN2(\"STR\", VAR4);\nreturn -VAR11;\n}\nif (VAR6 > VAR10) {\nFUN2(\"STR\", VAR6);\nreturn -VAR11;\n}\nFUN3(&VAR1->VAR12);\nVAR7->VAR13[0] = VAR2;\nFUN4(&VAR7->VAR13[1], VAR3, VAR4);\nVAR9 = FUN5(VAR1, VAR7->VAR13, 1 + VAR4, VAR7->VAR13, VAR6, 0);\nif (!VAR9 && VAR5 && VAR6)\nFUN4(VAR5, VAR7->VAR13, VAR6);\nFUN6(&VAR1->VAR12);\nreturn VAR9;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct dvb_usb_device *VAR1,\nu8 VAR2, u8 *VAR3, int VAR4, u8 *VAR5, int VAR6)\n{\nstruct cxusb_state *VAR7 = VAR1->VAR8;\nint VAR9, VAR10;\nif (1 + VAR4 > VAR11) {\nFUN2(\"STR\", VAR4);\nreturn -VAR12;\n}\nVAR10 = (VAR5 == NULL || VAR6 == 0); \nFUN3(&VAR1->VAR13);\nVAR7->VAR14[0] = VAR2;\nFUN4(&VAR7->VAR14[1], VAR3, VAR4);\nif (VAR10)\nVAR9 = FUN5(VAR1, VAR7->VAR14, 1 + VAR4);\nelse\nVAR9 = FUN6(VAR1, VAR7->VAR14, 1 + VAR4,\nVAR5, VAR6, 0);\nFUN7(&VAR1->VAR13);\nreturn VAR9;\n}\n",
      "code_after_change_raw": "static int cxusb_ctrl_msg(struct dvb_usb_device *d,\nu8 cmd, u8 *wbuf, int wlen, u8 *rbuf, int rlen)\n{\nstruct cxusb_state *st = d->priv;\nint ret;\nif (1 + wlen > MAX_XFER_SIZE) {\nwarn(\"i2c wr: len=%d is too big!\\n\", wlen);\nreturn -EOPNOTSUPP;\n}\nif (rlen > MAX_XFER_SIZE) {\nwarn(\"i2c rd: len=%d is too big!\\n\", rlen);\nreturn -EOPNOTSUPP;\n}\nmutex_lock(&d->data_mutex);\nst->data[0] = cmd;\nmemcpy(&st->data[1], wbuf, wlen);\nret = dvb_usb_generic_rw(d, st->data, 1 + wlen, st->data, rlen, 0);\nif (!ret && rbuf && rlen)\nmemcpy(rbuf, st->data, rlen);\nmutex_unlock(&d->data_mutex);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int cxusb_ctrl_msg(struct dvb_usb_device *d,\nu8 cmd, u8 *wbuf, int wlen, u8 *rbuf, int rlen)\n{\nstruct cxusb_state *st = d->priv;\nint ret, wo;\nif (1 + wlen > MAX_XFER_SIZE) {\nwarn(\"i2c wr: len=%d is too big!\\n\", wlen);\nreturn -EOPNOTSUPP;\n}\nwo = (rbuf == NULL || rlen == 0); \nmutex_lock(&d->data_mutex);\nst->data[0] = cmd;\nmemcpy(&st->data[1], wbuf, wlen);\nif (wo)\nret = dvb_usb_generic_write(d, st->data, 1 + wlen);\nelse\nret = dvb_usb_generic_rw(d, st->data, 1 + wlen,\nrbuf, rlen, 0);\nmutex_unlock(&d->data_mutex);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2017-8066": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel.",
        "trigger_condition": "Using more than one virtual page for a DMA scatterlist while interacting incorrectly with the CONFIG_VMAP_STACK option.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly handle memory allocation and deallocation for data structures, leading to potential memory corruption or system crash when interacting with the CONFIG_VMAP_STACK option."
      },
      "solution": "To mitigate the vulnerability, it is necessary to dynamically allocate memory for data structures using kmalloc, send data using the allocated memory, and free the memory after its use. This ensures proper handling of data within the allocated memory space and prevents memory corruption issues when interacting with the CONFIG_VMAP_STACK option. The solution involves modifying the code to allocate and free memory for the data structures appropriately.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2017-8066 in the gs_usb_probe function. The vulnerability arises due to incorrect interaction with the CONFIG_VMAP_STACK option, which can lead to a denial of service (system crash or memory corruption) or other unspecified impacts when using more than one virtual page for a DMA scatterlist.\n\nThe modification involves dynamically allocating memory for the gs_host_config and gs_device_config structures using kmalloc, sending the data using the allocated memory, and then freeing the memory after its use. This ensures that the data is properly handled within the allocated memory space and avoids potential memory corruption issues that could arise from interacting incorrectly with the CONFIG_VMAP_STACK option.\n\nBy dynamically allocating memory for the structures and properly managing the memory allocation and deallocation, the code modification helps mitigate the vulnerability and ensures safe handling of data structures in the USB driver code.",
      "GPT_purpose": "Initialize a GS USB device by sending host configuration and reading device configuration, then configuring for a specific number of interfaces and creating corresponding CAN devices.",
      "GPT_function": "\n1. Probing a USB device\n2. Sending host configuration data to the USB device\n3. Reading device configuration data from the USB device\n4. Configuring for a specific number of interfaces based on device configuration\n5. Handling errors and returning appropriate error codes\n6. Allocating memory for device structures\n7. Setting interface data and USB device for the device\n8. Creating CAN devices based on device configuration\n9. Handling errors during CAN device creation and cleanup if needed",
      "CVE_id": "CVE-2017-8066",
      "code_before_change": "static int gs_usb_probe(struct usb_interface *intf,\n\t\t\tconst struct usb_device_id *id)\n{\n\tstruct gs_usb *dev;\n\tint rc = -ENOMEM;\n\tunsigned int icount, i;\n\tstruct gs_host_config hconf = {\n\t\t.byte_order = 0x0000beef,\n\t};\n\tstruct gs_device_config dconf;\n\n\t/* send host config */\n\trc = usb_control_msg(interface_to_usbdev(intf),\n\t\t\t     usb_sndctrlpipe(interface_to_usbdev(intf), 0),\n\t\t\t     GS_USB_BREQ_HOST_FORMAT,\n\t\t\t     USB_DIR_OUT|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n\t\t\t     1,\n\t\t\t     intf->altsetting[0].desc.bInterfaceNumber,\n\t\t\t     &hconf,\n\t\t\t     sizeof(hconf),\n\t\t\t     1000);\n\n\tif (rc < 0) {\n\t\tdev_err(&intf->dev, \"Couldn't send data format (err=%d)\\n\",\n\t\t\trc);\n\t\treturn rc;\n\t}\n\n\t/* read device config */\n\trc = usb_control_msg(interface_to_usbdev(intf),\n\t\t\t     usb_rcvctrlpipe(interface_to_usbdev(intf), 0),\n\t\t\t     GS_USB_BREQ_DEVICE_CONFIG,\n\t\t\t     USB_DIR_IN|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n\t\t\t     1,\n\t\t\t     intf->altsetting[0].desc.bInterfaceNumber,\n\t\t\t     &dconf,\n\t\t\t     sizeof(dconf),\n\t\t\t     1000);\n\tif (rc < 0) {\n\t\tdev_err(&intf->dev, \"Couldn't get device config: (err=%d)\\n\",\n\t\t\trc);\n\t\treturn rc;\n\t}\n\n\ticount = dconf.icount + 1;\n\tdev_info(&intf->dev, \"Configuring for %d interfaces\\n\", icount);\n\n\tif (icount > GS_MAX_INTF) {\n\t\tdev_err(&intf->dev,\n\t\t\t\"Driver cannot handle more that %d CAN interfaces\\n\",\n\t\t\tGS_MAX_INTF);\n\t\treturn -EINVAL;\n\t}\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\tinit_usb_anchor(&dev->rx_submitted);\n\n\tatomic_set(&dev->active_channels, 0);\n\n\tusb_set_intfdata(intf, dev);\n\tdev->udev = interface_to_usbdev(intf);\n\n\tfor (i = 0; i < icount; i++) {\n\t\tdev->canch[i] = gs_make_candev(i, intf, &dconf);\n\t\tif (IS_ERR_OR_NULL(dev->canch[i])) {\n\t\t\t/* save error code to return later */\n\t\t\trc = PTR_ERR(dev->canch[i]);\n\n\t\t\t/* on failure destroy previously created candevs */\n\t\t\ticount = i;\n\t\t\tfor (i = 0; i < icount; i++)\n\t\t\t\tgs_destroy_candev(dev->canch[i]);\n\n\t\t\tusb_kill_anchored_urbs(&dev->rx_submitted);\n\t\t\tkfree(dev);\n\t\t\treturn rc;\n\t\t}\n\t\tdev->canch[i]->parent = dev;\n\t}\n\n\treturn 0;\n}",
      "code_after_change": "static int gs_usb_probe(struct usb_interface *intf,\n\t\t\tconst struct usb_device_id *id)\n{\n\tstruct gs_usb *dev;\n\tint rc = -ENOMEM;\n\tunsigned int icount, i;\n\tstruct gs_host_config *hconf;\n\tstruct gs_device_config *dconf;\n\n\thconf = kmalloc(sizeof(*hconf), GFP_KERNEL);\n\tif (!hconf)\n\t\treturn -ENOMEM;\n\n\thconf->byte_order = 0x0000beef;\n\n\t/* send host config */\n\trc = usb_control_msg(interface_to_usbdev(intf),\n\t\t\t     usb_sndctrlpipe(interface_to_usbdev(intf), 0),\n\t\t\t     GS_USB_BREQ_HOST_FORMAT,\n\t\t\t     USB_DIR_OUT|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n\t\t\t     1,\n\t\t\t     intf->altsetting[0].desc.bInterfaceNumber,\n\t\t\t     hconf,\n\t\t\t     sizeof(*hconf),\n\t\t\t     1000);\n\n\tkfree(hconf);\n\n\tif (rc < 0) {\n\t\tdev_err(&intf->dev, \"Couldn't send data format (err=%d)\\n\",\n\t\t\trc);\n\t\treturn rc;\n\t}\n\n\tdconf = kmalloc(sizeof(*dconf), GFP_KERNEL);\n\tif (!dconf)\n\t\treturn -ENOMEM;\n\n\t/* read device config */\n\trc = usb_control_msg(interface_to_usbdev(intf),\n\t\t\t     usb_rcvctrlpipe(interface_to_usbdev(intf), 0),\n\t\t\t     GS_USB_BREQ_DEVICE_CONFIG,\n\t\t\t     USB_DIR_IN|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n\t\t\t     1,\n\t\t\t     intf->altsetting[0].desc.bInterfaceNumber,\n\t\t\t     dconf,\n\t\t\t     sizeof(*dconf),\n\t\t\t     1000);\n\tif (rc < 0) {\n\t\tdev_err(&intf->dev, \"Couldn't get device config: (err=%d)\\n\",\n\t\t\trc);\n\t\tkfree(dconf);\n\t\treturn rc;\n\t}\n\n\ticount = dconf->icount + 1;\n\tdev_info(&intf->dev, \"Configuring for %d interfaces\\n\", icount);\n\n\tif (icount > GS_MAX_INTF) {\n\t\tdev_err(&intf->dev,\n\t\t\t\"Driver cannot handle more that %d CAN interfaces\\n\",\n\t\t\tGS_MAX_INTF);\n\t\tkfree(dconf);\n\t\treturn -EINVAL;\n\t}\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev) {\n\t\tkfree(dconf);\n\t\treturn -ENOMEM;\n\t}\n\n\tinit_usb_anchor(&dev->rx_submitted);\n\n\tatomic_set(&dev->active_channels, 0);\n\n\tusb_set_intfdata(intf, dev);\n\tdev->udev = interface_to_usbdev(intf);\n\n\tfor (i = 0; i < icount; i++) {\n\t\tdev->canch[i] = gs_make_candev(i, intf, dconf);\n\t\tif (IS_ERR_OR_NULL(dev->canch[i])) {\n\t\t\t/* save error code to return later */\n\t\t\trc = PTR_ERR(dev->canch[i]);\n\n\t\t\t/* on failure destroy previously created candevs */\n\t\t\ticount = i;\n\t\t\tfor (i = 0; i < icount; i++)\n\t\t\t\tgs_destroy_candev(dev->canch[i]);\n\n\t\t\tusb_kill_anchored_urbs(&dev->rx_submitted);\n\t\t\tkfree(dconf);\n\t\t\tkfree(dev);\n\t\t\treturn rc;\n\t\t}\n\t\tdev->canch[i]->parent = dev;\n\t}\n\n\tkfree(dconf);\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tstruct gs_host_config *hconf;",
          "\tstruct gs_device_config *dconf;",
          "",
          "\thconf = kmalloc(sizeof(*hconf), GFP_KERNEL);",
          "\tif (!hconf)",
          "\t\treturn -ENOMEM;",
          "",
          "\thconf->byte_order = 0x0000beef;",
          "\t\t\t     hconf,",
          "\t\t\t     sizeof(*hconf),",
          "",
          "\tkfree(hconf);",
          "",
          "\tdconf = kmalloc(sizeof(*dconf), GFP_KERNEL);",
          "\tif (!dconf)",
          "\t\treturn -ENOMEM;",
          "\t\t\t     dconf,",
          "\t\t\t     sizeof(*dconf),",
          "\t\tkfree(dconf);",
          "\ticount = dconf->icount + 1;",
          "\t\tkfree(dconf);",
          "\tif (!dev) {",
          "\t\tkfree(dconf);",
          "\t}",
          "",
          "\t\tdev->canch[i] = gs_make_candev(i, intf, dconf);",
          "\t\t\tkfree(dconf);",
          "\tkfree(dconf);",
          ""
        ],
        "deleted": [
          "\tstruct gs_host_config hconf = {",
          "\t\t.byte_order = 0x0000beef,",
          "\t};",
          "\tstruct gs_device_config dconf;",
          "\t\t\t     &hconf,",
          "\t\t\t     sizeof(hconf),",
          "\t\t\t     &dconf,",
          "\t\t\t     sizeof(dconf),",
          "\ticount = dconf.icount + 1;",
          "\tif (!dev)",
          "\t\tdev->canch[i] = gs_make_candev(i, intf, &dconf);"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect interaction with the CONFIG_VMAP_STACK option in the Linux kernel.",
      "trigger_condition": "Using more than one virtual page for a DMA scatterlist while interacting incorrectly with the CONFIG_VMAP_STACK option.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly handle memory allocation and deallocation for data structures, leading to potential memory corruption or system crash when interacting with the CONFIG_VMAP_STACK option.",
      "id": 127,
      "code_after_change_normalized": "static int FUN1(struct usb_interface *VAR1,\nconst struct usb_device_id *VAR2)\n{\nstruct gs_usb *VAR3;\nint VAR4 = -VAR5;\nunsigned int VAR6, VAR7;\nstruct gs_host_config *VAR8;\nstruct gs_device_config *VAR9;\nVAR8 = FUN2(sizeof(*VAR8), VAR10);\nif (!VAR8)\nreturn -VAR5;\nVAR8->VAR11 = VAR12;\nVAR4 = FUN3(FUN4(VAR1),\nFUN5(FUN4(VAR1), 0),\nVAR13,\nVAR14|VAR15|VAR16,\n1,\nVAR1->VAR17[0].VAR18.VAR19,\nVAR8,\nsizeof(*VAR8),\n1000);\nFUN6(VAR8);\nif (VAR4 < 0) {\nFUN7(&VAR1->VAR3, \"STR\",\nVAR4);\nreturn VAR4;\n}\nVAR9 = FUN2(sizeof(*VAR9), VAR10);\nif (!VAR9)\nreturn -VAR5;\nVAR4 = FUN3(FUN4(VAR1),\nFUN8(FUN4(VAR1), 0),\nVAR20,\nVAR21|VAR15|VAR16,\n1,\nVAR1->VAR17[0].VAR18.VAR19,\nVAR9,\nsizeof(*VAR9),\n1000);\nif (VAR4 < 0) {\nFUN7(&VAR1->VAR3, \"STR\",\nVAR4);\nFUN6(VAR9);\nreturn VAR4;\n}\nVAR6 = VAR9->VAR6 + 1;\nFUN9(&VAR1->VAR3, \"STR\", VAR6);\nif (VAR6 > VAR22) {\nFUN7(&VAR1->VAR3,\n\"STR\",\nVAR22);\nFUN6(VAR9);\nreturn -VAR23;\n}\nVAR3 = FUN10(sizeof(*VAR3), VAR10);\nif (!VAR3) {\nFUN6(VAR9);\nreturn -VAR5;\n}\nFUN11(&VAR3->VAR24);\nFUN12(&VAR3->VAR25, 0);\nFUN13(VAR1, VAR3);\nVAR3->VAR26 = FUN4(VAR1);\nfor (VAR7 = 0; VAR7 < VAR6; VAR7++) {\nVAR3->VAR27[VAR7] = FUN14(VAR7, VAR1, VAR9);\nif (FUN15(VAR3->VAR27[VAR7])) {\nVAR4 = FUN16(VAR3->VAR27[VAR7]);\nVAR6 = VAR7;\nfor (VAR7 = 0; VAR7 < VAR6; VAR7++)\nFUN17(VAR3->VAR27[VAR7]);\nFUN18(&VAR3->VAR24);\nFUN6(VAR9);\nFUN6(VAR3);\nreturn VAR4;\n}\nVAR3->VAR27[VAR7]->VAR28 = VAR3;\n}\nFUN6(VAR9);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct usb_interface *VAR1,\nconst struct usb_device_id *VAR2)\n{\nstruct gs_usb *VAR3;\nint VAR4 = -VAR5;\nunsigned int VAR6, VAR7;\nstruct gs_host_config VAR8 = {\n.VAR9 = VAR10,\n};\nstruct gs_device_config VAR11;\nVAR4 = FUN2(FUN3(VAR1),\nFUN4(FUN3(VAR1), 0),\nVAR12,\nVAR13|VAR14|VAR15,\n1,\nVAR1->VAR16[0].VAR17.VAR18,\n&VAR8,\nsizeof(VAR8),\n1000);\nif (VAR4 < 0) {\nFUN5(&VAR1->VAR3, \"STR\",\nVAR4);\nreturn VAR4;\n}\nVAR4 = FUN2(FUN3(VAR1),\nFUN6(FUN3(VAR1), 0),\nVAR19,\nVAR20|VAR14|VAR15,\n1,\nVAR1->VAR16[0].VAR17.VAR18,\n&VAR11,\nsizeof(VAR11),\n1000);\nif (VAR4 < 0) {\nFUN5(&VAR1->VAR3, \"STR\",\nVAR4);\nreturn VAR4;\n}\nVAR6 = VAR11.VAR6 + 1;\nFUN7(&VAR1->VAR3, \"STR\", VAR6);\nif (VAR6 > VAR21) {\nFUN5(&VAR1->VAR3,\n\"STR\",\nVAR21);\nreturn -VAR22;\n}\nVAR3 = FUN8(sizeof(*VAR3), VAR23);\nif (!VAR3)\nreturn -VAR5;\nFUN9(&VAR3->VAR24);\nFUN10(&VAR3->VAR25, 0);\nFUN11(VAR1, VAR3);\nVAR3->VAR26 = FUN3(VAR1);\nfor (VAR7 = 0; VAR7 < VAR6; VAR7++) {\nVAR3->VAR27[VAR7] = FUN12(VAR7, VAR1, &VAR11);\nif (FUN13(VAR3->VAR27[VAR7])) {\nVAR4 = FUN14(VAR3->VAR27[VAR7]);\nVAR6 = VAR7;\nfor (VAR7 = 0; VAR7 < VAR6; VAR7++)\nFUN15(VAR3->VAR27[VAR7]);\nFUN16(&VAR3->VAR24);\nFUN17(VAR3);\nreturn VAR4;\n}\nVAR3->VAR27[VAR7]->VAR28 = VAR3;\n}\nreturn 0;\n}\n",
      "code_after_change_raw": "static int gs_usb_probe(struct usb_interface *intf,\nconst struct usb_device_id *id)\n{\nstruct gs_usb *dev;\nint rc = -ENOMEM;\nunsigned int icount, i;\nstruct gs_host_config *hconf;\nstruct gs_device_config *dconf;\nhconf = kmalloc(sizeof(*hconf), GFP_KERNEL);\nif (!hconf)\nreturn -ENOMEM;\nhconf->byte_order = 0x0000beef;\nrc = usb_control_msg(interface_to_usbdev(intf),\nusb_sndctrlpipe(interface_to_usbdev(intf), 0),\nGS_USB_BREQ_HOST_FORMAT,\nUSB_DIR_OUT|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n1,\nintf->altsetting[0].desc.bInterfaceNumber,\nhconf,\nsizeof(*hconf),\n1000);\nkfree(hconf);\nif (rc < 0) {\ndev_err(&intf->dev, \"Couldn't send data format (err=%d)\\n\",\nrc);\nreturn rc;\n}\ndconf = kmalloc(sizeof(*dconf), GFP_KERNEL);\nif (!dconf)\nreturn -ENOMEM;\nrc = usb_control_msg(interface_to_usbdev(intf),\nusb_rcvctrlpipe(interface_to_usbdev(intf), 0),\nGS_USB_BREQ_DEVICE_CONFIG,\nUSB_DIR_IN|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n1,\nintf->altsetting[0].desc.bInterfaceNumber,\ndconf,\nsizeof(*dconf),\n1000);\nif (rc < 0) {\ndev_err(&intf->dev, \"Couldn't get device config: (err=%d)\\n\",\nrc);\nkfree(dconf);\nreturn rc;\n}\nicount = dconf->icount + 1;\ndev_info(&intf->dev, \"Configuring for %d interfaces\\n\", icount);\nif (icount > GS_MAX_INTF) {\ndev_err(&intf->dev,\n\"Driver cannot handle more that %d CAN interfaces\\n\",\nGS_MAX_INTF);\nkfree(dconf);\nreturn -EINVAL;\n}\ndev = kzalloc(sizeof(*dev), GFP_KERNEL);\nif (!dev) {\nkfree(dconf);\nreturn -ENOMEM;\n}\ninit_usb_anchor(&dev->rx_submitted);\natomic_set(&dev->active_channels, 0);\nusb_set_intfdata(intf, dev);\ndev->udev = interface_to_usbdev(intf);\nfor (i = 0; i < icount; i++) {\ndev->canch[i] = gs_make_candev(i, intf, dconf);\nif (IS_ERR_OR_NULL(dev->canch[i])) {\nrc = PTR_ERR(dev->canch[i]);\nicount = i;\nfor (i = 0; i < icount; i++)\ngs_destroy_candev(dev->canch[i]);\nusb_kill_anchored_urbs(&dev->rx_submitted);\nkfree(dconf);\nkfree(dev);\nreturn rc;\n}\ndev->canch[i]->parent = dev;\n}\nkfree(dconf);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int gs_usb_probe(struct usb_interface *intf,\nconst struct usb_device_id *id)\n{\nstruct gs_usb *dev;\nint rc = -ENOMEM;\nunsigned int icount, i;\nstruct gs_host_config hconf = {\n.byte_order = 0x0000beef,\n};\nstruct gs_device_config dconf;\nrc = usb_control_msg(interface_to_usbdev(intf),\nusb_sndctrlpipe(interface_to_usbdev(intf), 0),\nGS_USB_BREQ_HOST_FORMAT,\nUSB_DIR_OUT|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n1,\nintf->altsetting[0].desc.bInterfaceNumber,\n&hconf,\nsizeof(hconf),\n1000);\nif (rc < 0) {\ndev_err(&intf->dev, \"Couldn't send data format (err=%d)\\n\",\nrc);\nreturn rc;\n}\nrc = usb_control_msg(interface_to_usbdev(intf),\nusb_rcvctrlpipe(interface_to_usbdev(intf), 0),\nGS_USB_BREQ_DEVICE_CONFIG,\nUSB_DIR_IN|USB_TYPE_VENDOR|USB_RECIP_INTERFACE,\n1,\nintf->altsetting[0].desc.bInterfaceNumber,\n&dconf,\nsizeof(dconf),\n1000);\nif (rc < 0) {\ndev_err(&intf->dev, \"Couldn't get device config: (err=%d)\\n\",\nrc);\nreturn rc;\n}\nicount = dconf.icount + 1;\ndev_info(&intf->dev, \"Configuring for %d interfaces\\n\", icount);\nif (icount > GS_MAX_INTF) {\ndev_err(&intf->dev,\n\"Driver cannot handle more that %d CAN interfaces\\n\",\nGS_MAX_INTF);\nreturn -EINVAL;\n}\ndev = kzalloc(sizeof(*dev), GFP_KERNEL);\nif (!dev)\nreturn -ENOMEM;\ninit_usb_anchor(&dev->rx_submitted);\natomic_set(&dev->active_channels, 0);\nusb_set_intfdata(intf, dev);\ndev->udev = interface_to_usbdev(intf);\nfor (i = 0; i < icount; i++) {\ndev->canch[i] = gs_make_candev(i, intf, &dconf);\nif (IS_ERR_OR_NULL(dev->canch[i])) {\nrc = PTR_ERR(dev->canch[i]);\nicount = i;\nfor (i = 0; i < icount; i++)\ngs_destroy_candev(dev->canch[i]);\nusb_kill_anchored_urbs(&dev->rx_submitted);\nkfree(dev);\nreturn rc;\n}\ndev->canch[i]->parent = dev;\n}\nreturn 0;\n}\n"
    }
  ],
  "CVE-2017-8068": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Interacting incorrectly with the CONFIG_VMAP_STACK option in the Linux kernel, leading to a denial of service or memory corruption vulnerability.",
        "trigger_condition": "Using more than one virtual page for a DMA scatterlist, causing memory corruption or system crash.",
        "specific_code_behavior_causing_vulnerability": "The code directly uses a pointer to data without proper memory allocation, which can lead to memory corruption when interacting with the CONFIG_VMAP_STACK option."
      },
      "solution": "To mitigate the vulnerability, it is necessary to allocate memory for the buffer in a safe way that is compatible with the kernel's memory management mechanisms. This involves using kmemdup to allocate memory for the buffer instead of directly using the data pointer. Additionally, the allocated memory should be properly freed using kfree at the end of the function to prevent memory leaks. By ensuring safe memory allocation and management practices, the code can address the vulnerability and prevent memory corruption or system crashes when using more than one virtual page for a DMA scatterlist.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2017-8068, which involves interacting incorrectly with the CONFIG_VMAP_STACK option in the Linux kernel. By using kmemdup to allocate memory for the buffer 'buf' instead of directly using the 'data' pointer, the modified code ensures that the buffer is allocated in a safe way that is compatible with the kernel's memory management mechanisms.\n\nThe vulnerability arises from potential memory corruption when using more than one virtual page for a DMA scatterlist. By allocating memory for 'buf' using kmemdup, the modified code ensures that the buffer is properly managed and avoids the possibility of memory corruption or other impacts that could lead to a denial of service or system crash.\n\nAdditionally, the modified code properly frees the allocated memory using kfree at the end of the function, ensuring that memory is released appropriately and preventing memory leaks.\n\nIn summary, the modification in the code snippet is necessary to address the vulnerability by ensuring safe memory allocation and management practices in the context of the Linux kernel's memory handling mechanisms.",
      "GPT_purpose": "Set a register value in a Pegasus USB device.",
      "GPT_function": "\n1. Set a register using USB control message.\n2. Handle the return value of the USB control message function.\n3. Print a debug message if the USB control message function returns an error.",
      "CVE_id": "CVE-2017-8068",
      "code_before_change": "static int set_register(pegasus_t *pegasus, __u16 indx, __u8 data)\n{\n\tint ret;\n\n\tret = usb_control_msg(pegasus->usb, usb_sndctrlpipe(pegasus->usb, 0),\n\t\t\t      PEGASUS_REQ_SET_REG, PEGASUS_REQT_WRITE, data,\n\t\t\t      indx, &data, 1, 1000);\n\tif (ret < 0)\n\t\tnetif_dbg(pegasus, drv, pegasus->net,\n\t\t\t  \"%s returned %d\\n\", __func__, ret);\n\treturn ret;\n}",
      "code_after_change": "static int set_register(pegasus_t *pegasus, __u16 indx, __u8 data)\n{\n\tu8 *buf;\n\tint ret;\n\n\tbuf = kmemdup(&data, 1, GFP_NOIO);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(pegasus->usb, usb_sndctrlpipe(pegasus->usb, 0),\n\t\t\t      PEGASUS_REQ_SET_REG, PEGASUS_REQT_WRITE, data,\n\t\t\t      indx, buf, 1, 1000);\n\tif (ret < 0)\n\t\tnetif_dbg(pegasus, drv, pegasus->net,\n\t\t\t  \"%s returned %d\\n\", __func__, ret);\n\tkfree(buf);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tu8 *buf;",
          "",
          "\tbuf = kmemdup(&data, 1, GFP_NOIO);",
          "\tif (!buf)",
          "\t\treturn -ENOMEM;",
          "\t\t\t      indx, buf, 1, 1000);",
          "\tkfree(buf);"
        ],
        "deleted": [
          "\t\t\t      indx, &data, 1, 1000);"
        ]
      },
      "preconditions_for_vulnerability": "Interacting incorrectly with the CONFIG_VMAP_STACK option in the Linux kernel, leading to a denial of service or memory corruption vulnerability.",
      "trigger_condition": "Using more than one virtual page for a DMA scatterlist, causing memory corruption or system crash.",
      "specific_code_behavior_causing_vulnerability": "The code directly uses a pointer to data without proper memory allocation, which can lead to memory corruption when interacting with the CONFIG_VMAP_STACK option.",
      "id": 128,
      "code_after_change_normalized": "static int FUN1(pegasus_t *VAR1, __u16 VAR2, __u8 VAR3)\n{\nu8 *VAR4;\nint VAR5;\nVAR4 = FUN2(&VAR3, 1, VAR6);\nif (!VAR4)\nreturn -VAR7;\nVAR5 = FUN3(VAR1->VAR8, FUN4(VAR1->VAR8, 0),\nVAR9, VAR10, VAR3,\nVAR2, VAR4, 1, 1000);\nif (VAR5 < 0)\nFUN5(VAR1, VAR11, VAR1->VAR12,\n\"STR\", VAR13, VAR5);\nFUN6(VAR4);\nreturn VAR5;\n}\n",
      "code_before_change_normalized": "static int FUN1(pegasus_t *VAR1, __u16 VAR2, __u8 VAR3)\n{\nint VAR4;\nVAR4 = FUN2(VAR1->VAR5, FUN3(VAR1->VAR5, 0),\nVAR6, VAR7, VAR3,\nVAR2, &VAR3, 1, 1000);\nif (VAR4 < 0)\nFUN4(VAR1, VAR8, VAR1->VAR9,\n\"STR\", VAR10, VAR4);\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int set_register(pegasus_t *pegasus, __u16 indx, __u8 data)\n{\nu8 *buf;\nint ret;\nbuf = kmemdup(&data, 1, GFP_NOIO);\nif (!buf)\nreturn -ENOMEM;\nret = usb_control_msg(pegasus->usb, usb_sndctrlpipe(pegasus->usb, 0),\nPEGASUS_REQ_SET_REG, PEGASUS_REQT_WRITE, data,\nindx, buf, 1, 1000);\nif (ret < 0)\nnetif_dbg(pegasus, drv, pegasus->net,\n\"%s returned %d\\n\", __func__, ret);\nkfree(buf);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int set_register(pegasus_t *pegasus, __u16 indx, __u8 data)\n{\nint ret;\nret = usb_control_msg(pegasus->usb, usb_sndctrlpipe(pegasus->usb, 0),\nPEGASUS_REQ_SET_REG, PEGASUS_REQT_WRITE, data,\nindx, &data, 1, 1000);\nif (ret < 0)\nnetif_dbg(pegasus, drv, pegasus->net,\n\"%s returned %d\\n\", __func__, ret);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2017-8069": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect interaction with a specific kernel configuration option leads to improper handling of DMA scatterlists.",
        "trigger_condition": "Use of more than one virtual page for a DMA scatterlist while interacting with the kernel configuration option.",
        "specific_code_behavior_causing_vulnerability": "The code directly uses the 'data' pointer without proper memory allocation, leading to potential memory corruption or system crashes when interacting with DMA scatterlists."
      },
      "solution": "To mitigate the vulnerability, it is necessary to dynamically allocate memory for the data buffer using kmalloc, ensuring proper memory management. Additionally, error handling should be implemented to check for successful memory allocation and free the allocated memory before returning from the function. This prevents memory leaks and reduces the risk of memory corruption or system crashes caused by incorrect DMA scatterlist usage.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2017-8069 in the code snippet. The vulnerability arises from the incorrect interaction with the CONFIG_VMAP_STACK option, which can lead to a denial of service or memory corruption due to the misuse of DMA scatterlists.\n\nBy adding the modification, the code snippet now dynamically allocates memory using kmalloc to create a buffer for the data instead of directly using the 'data' pointer. This ensures that the buffer is properly allocated and managed, reducing the risk of memory corruption or system crashes caused by incorrect DMA scatterlist usage.\n\nAdditionally, the modification includes proper error handling by checking if the memory allocation was successful and freeing the allocated memory using kfree before returning from the function. This helps prevent memory leaks and ensures proper resource management.\n\nOverall, the modification improves the code's robustness and security by addressing the vulnerability and implementing safer memory handling practices.",
      "GPT_purpose": "Retrieve registers from an RTL8150 USB device.",
      "GPT_function": "\n1. Send a USB control message to retrieve registers from an RTL8150 device.\n2. Interact with the USB device to read registers based on the provided index and size.\n3. Utilize a USB control message to communicate with the USB device for register retrieval.",
      "CVE_id": "CVE-2017-8069",
      "code_before_change": "static int get_registers(rtl8150_t * dev, u16 indx, u16 size, void *data)\n{\n\treturn usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t       RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\n\t\t\t       indx, 0, data, size, 500);\n}",
      "code_after_change": "static int get_registers(rtl8150_t * dev, u16 indx, u16 size, void *data)\n{\n\tvoid *buf;\n\tint ret;\n\n\tbuf = kmalloc(size, GFP_NOIO);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t      RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\n\t\t\t      indx, 0, buf, size, 500);\n\tif (ret > 0 && ret <= size)\n\t\tmemcpy(data, buf, ret);\n\tkfree(buf);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tvoid *buf;",
          "\tint ret;",
          "",
          "\tbuf = kmalloc(size, GFP_NOIO);",
          "\tif (!buf)",
          "\t\treturn -ENOMEM;",
          "",
          "\tret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),",
          "\t\t\t      RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,",
          "\t\t\t      indx, 0, buf, size, 500);",
          "\tif (ret > 0 && ret <= size)",
          "\t\tmemcpy(data, buf, ret);",
          "\tkfree(buf);",
          "\treturn ret;"
        ],
        "deleted": [
          "\treturn usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),",
          "\t\t\t       RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,",
          "\t\t\t       indx, 0, data, size, 500);"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect interaction with a specific kernel configuration option leads to improper handling of DMA scatterlists.",
      "trigger_condition": "Use of more than one virtual page for a DMA scatterlist while interacting with the kernel configuration option.",
      "specific_code_behavior_causing_vulnerability": "The code directly uses the 'data' pointer without proper memory allocation, leading to potential memory corruption or system crashes when interacting with DMA scatterlists.",
      "id": 129,
      "code_after_change_normalized": "static int FUN1(VAR1 * VAR2, u16 VAR3, u16 VAR4, void *VAR5)\n{\nvoid *VAR6;\nint VAR7;\nVAR6 = FUN2(VAR4, VAR8);\nif (!VAR6)\nreturn -VAR9;\nVAR7 = FUN3(VAR2->VAR10, FUN4(VAR2->VAR10, 0),\nVAR11, VAR12,\nVAR3, 0, VAR6, VAR4, 500);\nif (VAR7 > 0 && VAR7 <= VAR4)\nFUN5(VAR5, VAR6, VAR7);\nFUN6(VAR6);\nreturn VAR7;\n}\n",
      "code_before_change_normalized": "static int FUN1(VAR1 * VAR2, u16 VAR3, u16 VAR4, void *VAR5)\n{\nreturn FUN2(VAR2->VAR6, FUN3(VAR2->VAR6, 0),\nVAR7, VAR8,\nVAR3, 0, VAR5, VAR4, 500);\n}\n",
      "code_after_change_raw": "static int get_registers(rtl8150_t * dev, u16 indx, u16 size, void *data)\n{\nvoid *buf;\nint ret;\nbuf = kmalloc(size, GFP_NOIO);\nif (!buf)\nreturn -ENOMEM;\nret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\nRTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\nindx, 0, buf, size, 500);\nif (ret > 0 && ret <= size)\nmemcpy(data, buf, ret);\nkfree(buf);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int get_registers(rtl8150_t * dev, u16 indx, u16 size, void *data)\n{\nreturn usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\nRTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\nindx, 0, data, size, 500);\n}\n"
    }
  ],
  "CVE-2018-1000199": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Invocation of modify_user_hw_breakpoint with IRQs disabled, leading to the inability to raise IPIs invoking __perf_event_disable.",
        "trigger_condition": "The code does not properly handle breakpoint modifications when IRQs are disabled, potentially resulting in a crash and memory corruption.",
        "specific_code_behavior_causing_vulnerability": "Improper handling of breakpoint modifications when IRQs are disabled, leading to potential memory corruption and crashes. The code does not correctly enable/disable breakpoints based on the disabled flag, and it lacks proper error handling for breakpoint validation failures."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper handling of breakpoint modifications when IRQs are disabled. The solution involves setting bp->attr.disabled to 1 at the beginning of the function, correctly enabling/disabling breakpoints based on the attr->disabled flag, and simplifying the error handling logic. By following these steps, the code can prevent potential crashes and memory corruption issues related to breakpoint modifications.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2018-1000199 in the `modify_user_hw_breakpoint` function. The vulnerability allowed for a potential crash and memory corruption due to improper handling of breakpoints. \n\nThe fix involves setting `bp->attr.disabled` to 1 at the beginning of the function and then properly enabling/disabling the breakpoint based on the `attr->disabled` flag. This ensures that the breakpoint is correctly handled and avoids potential issues that could lead to crashes or memory corruption.\n\nAdditionally, the modification simplifies the code logic by removing unnecessary code related to reverting changes if an error occurs during breakpoint validation. Instead, it directly returns the error if validation fails, improving code readability and maintainability.",
      "GPT_purpose": "Modify hardware breakpoint settings for a given perf_event.",
      "GPT_function": "\n1. Modify user hardware breakpoint attributes.\n2. Disable and enable hardware breakpoints.\n3. Validate hardware breakpoints.\n4. Handle a vulnerability related to hardware breakpoints.",
      "CVE_id": "CVE-2018-1000199",
      "code_before_change": "int modify_user_hw_breakpoint(struct perf_event *bp, struct perf_event_attr *attr)\n{\n\tu64 old_addr = bp->attr.bp_addr;\n\tu64 old_len = bp->attr.bp_len;\n\tint old_type = bp->attr.bp_type;\n\tint err = 0;\n\n\t/*\n\t * modify_user_hw_breakpoint can be invoked with IRQs disabled and hence it\n\t * will not be possible to raise IPIs that invoke __perf_event_disable.\n\t * So call the function directly after making sure we are targeting the\n\t * current task.\n\t */\n\tif (irqs_disabled() && bp->ctx && bp->ctx->task == current)\n\t\tperf_event_disable_local(bp);\n\telse\n\t\tperf_event_disable(bp);\n\n\tbp->attr.bp_addr = attr->bp_addr;\n\tbp->attr.bp_type = attr->bp_type;\n\tbp->attr.bp_len = attr->bp_len;\n\n\tif (attr->disabled)\n\t\tgoto end;\n\n\terr = validate_hw_breakpoint(bp);\n\tif (!err)\n\t\tperf_event_enable(bp);\n\n\tif (err) {\n\t\tbp->attr.bp_addr = old_addr;\n\t\tbp->attr.bp_type = old_type;\n\t\tbp->attr.bp_len = old_len;\n\t\tif (!bp->attr.disabled)\n\t\t\tperf_event_enable(bp);\n\n\t\treturn err;\n\t}\n\nend:\n\tbp->attr.disabled = attr->disabled;\n\n\treturn 0;\n}",
      "code_after_change": "int modify_user_hw_breakpoint(struct perf_event *bp, struct perf_event_attr *attr)\n{\n\t/*\n\t * modify_user_hw_breakpoint can be invoked with IRQs disabled and hence it\n\t * will not be possible to raise IPIs that invoke __perf_event_disable.\n\t * So call the function directly after making sure we are targeting the\n\t * current task.\n\t */\n\tif (irqs_disabled() && bp->ctx && bp->ctx->task == current)\n\t\tperf_event_disable_local(bp);\n\telse\n\t\tperf_event_disable(bp);\n\n\tbp->attr.bp_addr = attr->bp_addr;\n\tbp->attr.bp_type = attr->bp_type;\n\tbp->attr.bp_len = attr->bp_len;\n\tbp->attr.disabled = 1;\n\n\tif (!attr->disabled) {\n\t\tint err = validate_hw_breakpoint(bp);\n\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tperf_event_enable(bp);\n\t\tbp->attr.disabled = 0;\n\t}\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tbp->attr.disabled = 1;",
          "\tif (!attr->disabled) {",
          "\t\tint err = validate_hw_breakpoint(bp);",
          "\t\tif (err)",
          "\t\t\treturn err;",
          "",
          "\t\tbp->attr.disabled = 0;"
        ],
        "deleted": [
          "\tu64 old_addr = bp->attr.bp_addr;",
          "\tu64 old_len = bp->attr.bp_len;",
          "\tint old_type = bp->attr.bp_type;",
          "\tint err = 0;",
          "",
          "\tif (attr->disabled)",
          "\t\tgoto end;",
          "\terr = validate_hw_breakpoint(bp);",
          "\tif (!err)",
          "",
          "\tif (err) {",
          "\t\tbp->attr.bp_addr = old_addr;",
          "\t\tbp->attr.bp_type = old_type;",
          "\t\tbp->attr.bp_len = old_len;",
          "\t\tif (!bp->attr.disabled)",
          "\t\t\tperf_event_enable(bp);",
          "",
          "\t\treturn err;",
          "",
          "end:",
          "\tbp->attr.disabled = attr->disabled;"
        ]
      },
      "preconditions_for_vulnerability": "Invocation of modify_user_hw_breakpoint with IRQs disabled, leading to the inability to raise IPIs invoking __perf_event_disable.",
      "trigger_condition": "The code does not properly handle breakpoint modifications when IRQs are disabled, potentially resulting in a crash and memory corruption.",
      "specific_code_behavior_causing_vulnerability": "Improper handling of breakpoint modifications when IRQs are disabled, leading to potential memory corruption and crashes. The code does not correctly enable/disable breakpoints based on the disabled flag, and it lacks proper error handling for breakpoint validation failures.",
      "id": 130,
      "code_after_change_normalized": "int FUN1(struct perf_event *VAR1, struct perf_event_attr *VAR2)\n{\nif (FUN2() && VAR1->VAR3 && VAR1->VAR3->VAR4 == VAR5)\nFUN3(VAR1);\nelse\nFUN4(VAR1);\nVAR1->VAR2.VAR6 = VAR2->VAR6;\nVAR1->VAR2.VAR7 = VAR2->VAR7;\nVAR1->VAR2.VAR8 = VAR2->VAR8;\nVAR1->VAR2.VAR9 = 1;\nif (!VAR2->VAR9) {\nint VAR10 = FUN5(VAR1);\nif (VAR10)\nreturn VAR10;\nFUN6(VAR1);\nVAR1->VAR2.VAR9 = 0;\n}\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(struct perf_event *VAR1, struct perf_event_attr *VAR2)\n{\nu64 VAR3 = VAR1->VAR2.VAR4;\nu64 VAR5 = VAR1->VAR2.VAR6;\nint VAR7 = VAR1->VAR2.VAR8;\nint VAR9 = 0;\nif (FUN2() && VAR1->VAR10 && VAR1->VAR10->VAR11 == VAR12)\nFUN3(VAR1);\nelse\nFUN4(VAR1);\nVAR1->VAR2.VAR4 = VAR2->VAR4;\nVAR1->VAR2.VAR8 = VAR2->VAR8;\nVAR1->VAR2.VAR6 = VAR2->VAR6;\nif (VAR2->VAR13)\ngoto VAR14;\nVAR9 = FUN5(VAR1);\nif (!VAR9)\nFUN6(VAR1);\nif (VAR9) {\nVAR1->VAR2.VAR4 = VAR3;\nVAR1->VAR2.VAR8 = VAR7;\nVAR1->VAR2.VAR6 = VAR5;\nif (!VAR1->VAR2.VAR13)\nFUN6(VAR1);\nreturn VAR9;\n}\nVAR14:\nVAR1->VAR2.VAR13 = VAR2->VAR13;\nreturn 0;\n}\n",
      "code_after_change_raw": "int modify_user_hw_breakpoint(struct perf_event *bp, struct perf_event_attr *attr)\n{\nif (irqs_disabled() && bp->ctx && bp->ctx->task == current)\nperf_event_disable_local(bp);\nelse\nperf_event_disable(bp);\nbp->attr.bp_addr = attr->bp_addr;\nbp->attr.bp_type = attr->bp_type;\nbp->attr.bp_len = attr->bp_len;\nbp->attr.disabled = 1;\nif (!attr->disabled) {\nint err = validate_hw_breakpoint(bp);\nif (err)\nreturn err;\nperf_event_enable(bp);\nbp->attr.disabled = 0;\n}\nreturn 0;\n}\n",
      "code_before_change_raw": "int modify_user_hw_breakpoint(struct perf_event *bp, struct perf_event_attr *attr)\n{\nu64 old_addr = bp->attr.bp_addr;\nu64 old_len = bp->attr.bp_len;\nint old_type = bp->attr.bp_type;\nint err = 0;\nif (irqs_disabled() && bp->ctx && bp->ctx->task == current)\nperf_event_disable_local(bp);\nelse\nperf_event_disable(bp);\nbp->attr.bp_addr = attr->bp_addr;\nbp->attr.bp_type = attr->bp_type;\nbp->attr.bp_len = attr->bp_len;\nif (attr->disabled)\ngoto end;\nerr = validate_hw_breakpoint(bp);\nif (!err)\nperf_event_enable(bp);\nif (err) {\nbp->attr.bp_addr = old_addr;\nbp->attr.bp_type = old_type;\nbp->attr.bp_len = old_len;\nif (!bp->attr.disabled)\nperf_event_enable(bp);\nreturn err;\n}\nend:\nbp->attr.disabled = attr->disabled;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2018-10124": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for INT_MIN argument in the kill_something_info function.",
        "trigger_condition": "Calling the kill_something_info function with an INT_MIN argument, leading to undefined behavior.",
        "specific_code_behavior_causing_vulnerability": "The code does not check for the specific case where the pid argument is equal to INT_MIN, which can result in undefined behavior and a denial of service vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check for the condition where pid is equal to INT_MIN within the kill_something_info function. By explicitly handling this edge case and returning an appropriate error code (-ESRCH in this case), the code can prevent the undefined behavior and potential denial of service caused by passing INT_MIN as an argument.",
      "GPT_analysis": "The modification is necessary to address the vulnerability described in CVE-2018-10124. The vulnerability arises when the function `kill_something_info` is called with an `INT_MIN` argument, which can lead to undefined behavior. In this case, the modification specifically checks for the condition where `pid` is equal to `INT_MIN` and returns `-ESRCH` to avoid the undefined behavior and prevent a denial of service caused by the vulnerability.\n\nBy adding the check for `pid == INT_MIN`, the code ensures that the function handles this edge case properly and prevents any potential issues that may arise from passing `INT_MIN` as an argument. This modification helps to make the code more robust and secure, addressing the vulnerability and improving the overall reliability of the function.",
      "GPT_purpose": "Kill a process or a process group based on the provided signal and process ID.",
      "GPT_function": "\n1. `kill_something_info` function that takes a signal, siginfo structure, and process ID as arguments.\n2. Checks if the process ID is greater than 0 and calls `kill_pid_info` function.\n3. If the process ID is not greater than 0, it iterates through all processes and sends a signal to each process group except the current one.",
      "CVE_id": "CVE-2018-10124",
      "code_before_change": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\n\tint ret;\n\n\tif (pid > 0) {\n\t\trcu_read_lock();\n\t\tret = kill_pid_info(sig, info, find_vpid(pid));\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\n\tread_lock(&tasklist_lock);\n\tif (pid != -1) {\n\t\tret = __kill_pgrp_info(sig, info,\n\t\t\t\tpid ? find_vpid(-pid) : task_pgrp(current));\n\t} else {\n\t\tint retval = 0, count = 0;\n\t\tstruct task_struct * p;\n\n\t\tfor_each_process(p) {\n\t\t\tif (task_pid_vnr(p) > 1 &&\n\t\t\t\t\t!same_thread_group(p, current)) {\n\t\t\t\tint err = group_send_sig_info(sig, info, p);\n\t\t\t\t++count;\n\t\t\t\tif (err != -EPERM)\n\t\t\t\t\tretval = err;\n\t\t\t}\n\t\t}\n\t\tret = count ? retval : -ESRCH;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}",
      "code_after_change": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\n\tint ret;\n\n\tif (pid > 0) {\n\t\trcu_read_lock();\n\t\tret = kill_pid_info(sig, info, find_vpid(pid));\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\n\t/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */\n\tif (pid == INT_MIN)\n\t\treturn -ESRCH;\n\n\tread_lock(&tasklist_lock);\n\tif (pid != -1) {\n\t\tret = __kill_pgrp_info(sig, info,\n\t\t\t\tpid ? find_vpid(-pid) : task_pgrp(current));\n\t} else {\n\t\tint retval = 0, count = 0;\n\t\tstruct task_struct * p;\n\n\t\tfor_each_process(p) {\n\t\t\tif (task_pid_vnr(p) > 1 &&\n\t\t\t\t\t!same_thread_group(p, current)) {\n\t\t\t\tint err = group_send_sig_info(sig, info, p);\n\t\t\t\t++count;\n\t\t\t\tif (err != -EPERM)\n\t\t\t\t\tretval = err;\n\t\t\t}\n\t\t}\n\t\tret = count ? retval : -ESRCH;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "",
          "\t/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */",
          "\tif (pid == INT_MIN)",
          "\t\treturn -ESRCH;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper handling for INT_MIN argument in the kill_something_info function.",
      "trigger_condition": "Calling the kill_something_info function with an INT_MIN argument, leading to undefined behavior.",
      "specific_code_behavior_causing_vulnerability": "The code does not check for the specific case where the pid argument is equal to INT_MIN, which can result in undefined behavior and a denial of service vulnerability.",
      "id": 131,
      "code_after_change_normalized": "static int FUN1(int VAR1, struct siginfo *VAR2, pid_t VAR3)\n{\nint VAR4;\nif (VAR3 > 0) {\nFUN2();\nVAR4 = FUN3(VAR1, VAR2, FUN4(VAR3));\nFUN5();\nreturn VAR4;\n}\nif (VAR3 == VAR5)\nreturn -VAR6;\nFUN6(&VAR7);\nif (VAR3 != -1) {\nVAR4 = FUN7(VAR1, VAR2,\nVAR3 ? FUN4(-VAR3) : FUN8(VAR8));\n} else {\nint VAR9 = 0, VAR10 = 0;\nstruct VAR11 * VAR12;\nFUN9(VAR12) {\nif (FUN10(VAR12) > 1 &&\n!FUN11(VAR12, VAR8)) {\nint VAR13 = FUN12(VAR1, VAR2, VAR12);\n++VAR10;\nif (VAR13 != -VAR14)\nVAR9 = VAR13;\n}\n}\nVAR4 = VAR10 ? VAR9 : -VAR6;\n}\nFUN13(&VAR7);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static int FUN1(int VAR1, struct siginfo *VAR2, pid_t VAR3)\n{\nint VAR4;\nif (VAR3 > 0) {\nFUN2();\nVAR4 = FUN3(VAR1, VAR2, FUN4(VAR3));\nFUN5();\nreturn VAR4;\n}\nFUN6(&VAR5);\nif (VAR3 != -1) {\nVAR4 = FUN7(VAR1, VAR2,\nVAR3 ? FUN4(-VAR3) : FUN8(VAR6));\n} else {\nint VAR7 = 0, VAR8 = 0;\nstruct VAR9 * VAR10;\nFUN9(VAR10) {\nif (FUN10(VAR10) > 1 &&\n!FUN11(VAR10, VAR6)) {\nint VAR11 = FUN12(VAR1, VAR2, VAR10);\n++VAR8;\nif (VAR11 != -VAR12)\nVAR7 = VAR11;\n}\n}\nVAR4 = VAR8 ? VAR7 : -VAR13;\n}\nFUN13(&VAR5);\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\nint ret;\nif (pid > 0) {\nrcu_read_lock();\nret = kill_pid_info(sig, info, find_vpid(pid));\nrcu_read_unlock();\nreturn ret;\n}\nif (pid == INT_MIN)\nreturn -ESRCH;\nread_lock(&tasklist_lock);\nif (pid != -1) {\nret = __kill_pgrp_info(sig, info,\npid ? find_vpid(-pid) : task_pgrp(current));\n} else {\nint retval = 0, count = 0;\nstruct task_struct * p;\nfor_each_process(p) {\nif (task_pid_vnr(p) > 1 &&\n!same_thread_group(p, current)) {\nint err = group_send_sig_info(sig, info, p);\n++count;\nif (err != -EPERM)\nretval = err;\n}\n}\nret = count ? retval : -ESRCH;\n}\nread_unlock(&tasklist_lock);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\nint ret;\nif (pid > 0) {\nrcu_read_lock();\nret = kill_pid_info(sig, info, find_vpid(pid));\nrcu_read_unlock();\nreturn ret;\n}\nread_lock(&tasklist_lock);\nif (pid != -1) {\nret = __kill_pgrp_info(sig, info,\npid ? find_vpid(-pid) : task_pgrp(current));\n} else {\nint retval = 0, count = 0;\nstruct task_struct * p;\nfor_each_process(p) {\nif (task_pid_vnr(p) > 1 &&\n!same_thread_group(p, current)) {\nint err = group_send_sig_info(sig, info, p);\n++count;\nif (err != -EPERM)\nretval = err;\n}\n}\nret = count ? retval : -ESRCH;\n}\nread_unlock(&tasklist_lock);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2018-10940": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper bounds checking for user-supplied input in the CDROM driver ioctl function.",
        "trigger_condition": "An attacker provides a malicious or out-of-bounds value as an argument to the CDROM_MEDIA_CHANGED ioctl, leading to an incorrect bounds check and potential out-of-bounds read access.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the user-supplied argument against the capacity value, allowing for a potential out-of-bounds read access if the argument exceeds the capacity.",
        "solution": "To mitigate the vulnerability, it is necessary to ensure proper bounds checking for user-supplied input in the CDROM driver ioctl function. Specifically, the code should validate the argument against the capacity value to prevent out-of-bounds access. In this case, the solution involves modifying the bounds check condition to compare the argument directly with the capacity value."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2018-10940, which involves an incorrect bounds check in the CDROM driver CDROM_MEDIA_CHANGED ioctl that could allow local attackers to read out kernel memory. \n\nIn the original code snippet, the vulnerability lies in the line:\n```c\nif ((unsigned int)arg >= cdi->capacity)\n```\nThis line does not properly check the bounds of the 'arg' parameter, which could lead to an out-of-bounds read access if 'arg' is larger than the 'capacity' value. This can potentially expose sensitive kernel memory to attackers.\n\nThe correct way to fix this vulnerability is to modify the line to:\n```c\nif (arg >= cdi->capacity)\n```\nBy making this change, we ensure that the 'arg' parameter is properly checked against the 'capacity' value, preventing any out-of-bounds access and enhancing the security of the code.",
      "GPT_purpose": "Check for media change in a CD-ROM device and handle disc selection.",
      "GPT_function": "\n1. Check if the CDROM driver supports the CDC_MEDIA_CHANGED ioctl command.\n2. Handle cases where disc selection is not allowed or the current disc is selected.\n3. Perform a bounds check on the argument passed to the ioctl command.\n4. Allocate memory for cdrom_changer_info structure.\n5. Read the mechanical status of the CD-ROM device.\n6. Return the change status of the specified disc slot.\n7. Free the allocated memory for cdrom_changer_info structure.",
      "CVE_id": "CVE-2018-10940",
      "code_before_change": "static int cdrom_ioctl_media_changed(struct cdrom_device_info *cdi,\n\t\tunsigned long arg)\n{\n\tstruct cdrom_changer_info *info;\n\tint ret;\n\n\tcd_dbg(CD_DO_IOCTL, \"entering CDROM_MEDIA_CHANGED\\n\");\n\n\tif (!CDROM_CAN(CDC_MEDIA_CHANGED))\n\t\treturn -ENOSYS;\n\n\t/* cannot select disc or select current disc */\n\tif (!CDROM_CAN(CDC_SELECT_DISC) || arg == CDSL_CURRENT)\n\t\treturn media_changed(cdi, 1);\n\n\tif ((unsigned int)arg >= cdi->capacity)\n\t\treturn -EINVAL;\n\n\tinfo = kmalloc(sizeof(*info), GFP_KERNEL);\n\tif (!info)\n\t\treturn -ENOMEM;\n\n\tret = cdrom_read_mech_status(cdi, info);\n\tif (!ret)\n\t\tret = info->slots[arg].change;\n\tkfree(info);\n\treturn ret;\n}",
      "code_after_change": "static int cdrom_ioctl_media_changed(struct cdrom_device_info *cdi,\n\t\tunsigned long arg)\n{\n\tstruct cdrom_changer_info *info;\n\tint ret;\n\n\tcd_dbg(CD_DO_IOCTL, \"entering CDROM_MEDIA_CHANGED\\n\");\n\n\tif (!CDROM_CAN(CDC_MEDIA_CHANGED))\n\t\treturn -ENOSYS;\n\n\t/* cannot select disc or select current disc */\n\tif (!CDROM_CAN(CDC_SELECT_DISC) || arg == CDSL_CURRENT)\n\t\treturn media_changed(cdi, 1);\n\n\tif (arg >= cdi->capacity)\n\t\treturn -EINVAL;\n\n\tinfo = kmalloc(sizeof(*info), GFP_KERNEL);\n\tif (!info)\n\t\treturn -ENOMEM;\n\n\tret = cdrom_read_mech_status(cdi, info);\n\tif (!ret)\n\t\tret = info->slots[arg].change;\n\tkfree(info);\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\tif (arg >= cdi->capacity)"
        ],
        "deleted": [
          "\tif ((unsigned int)arg >= cdi->capacity)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper bounds checking for user-supplied input in the CDROM driver ioctl function.",
      "trigger_condition": "An attacker provides a malicious or out-of-bounds value as an argument to the CDROM_MEDIA_CHANGED ioctl, leading to an incorrect bounds check and potential out-of-bounds read access.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the user-supplied argument against the capacity value, allowing for a potential out-of-bounds read access if the argument exceeds the capacity.",
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper bounds checking for user-supplied input in the CDROM driver ioctl function. Specifically, the code should validate the argument against the capacity value to prevent out-of-bounds access. In this case, the solution involves modifying the bounds check condition to compare the argument directly with the capacity value.",
      "id": 132,
      "code_after_change_normalized": "static int FUN1(struct cdrom_device_info *VAR1,\nunsigned long VAR2)\n{\nstruct cdrom_changer_info *VAR3;\nint VAR4;\nFUN2(VAR5, \"STR\");\nif (!FUN3(VAR6))\nreturn -VAR7;\nif (!FUN3(VAR8) || VAR2 == VAR9)\nreturn FUN4(VAR1, 1);\nif (VAR2 >= VAR1->VAR10)\nreturn -VAR11;\nVAR3 = FUN5(sizeof(*VAR3), VAR12);\nif (!VAR3)\nreturn -VAR13;\nVAR4 = FUN6(VAR1, VAR3);\nif (!VAR4)\nVAR4 = VAR3->VAR14[VAR2].VAR15;\nFUN7(VAR3);\nreturn VAR4;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct cdrom_device_info *VAR1,\nunsigned long VAR2)\n{\nstruct cdrom_changer_info *VAR3;\nint VAR4;\nFUN2(VAR5, \"STR\");\nif (!FUN3(VAR6))\nreturn -VAR7;\nif (!FUN3(VAR8) || VAR2 == VAR9)\nreturn FUN4(VAR1, 1);\nif ((unsigned int)VAR2 >= VAR1->VAR10)\nreturn -VAR11;\nVAR3 = FUN5(sizeof(*VAR3), VAR12);\nif (!VAR3)\nreturn -VAR13;\nVAR4 = FUN6(VAR1, VAR3);\nif (!VAR4)\nVAR4 = VAR3->VAR14[VAR2].VAR15;\nFUN7(VAR3);\nreturn VAR4;\n}\n",
      "code_after_change_raw": "static int cdrom_ioctl_media_changed(struct cdrom_device_info *cdi,\nunsigned long arg)\n{\nstruct cdrom_changer_info *info;\nint ret;\ncd_dbg(CD_DO_IOCTL, \"entering CDROM_MEDIA_CHANGED\\n\");\nif (!CDROM_CAN(CDC_MEDIA_CHANGED))\nreturn -ENOSYS;\nif (!CDROM_CAN(CDC_SELECT_DISC) || arg == CDSL_CURRENT)\nreturn media_changed(cdi, 1);\nif (arg >= cdi->capacity)\nreturn -EINVAL;\ninfo = kmalloc(sizeof(*info), GFP_KERNEL);\nif (!info)\nreturn -ENOMEM;\nret = cdrom_read_mech_status(cdi, info);\nif (!ret)\nret = info->slots[arg].change;\nkfree(info);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int cdrom_ioctl_media_changed(struct cdrom_device_info *cdi,\nunsigned long arg)\n{\nstruct cdrom_changer_info *info;\nint ret;\ncd_dbg(CD_DO_IOCTL, \"entering CDROM_MEDIA_CHANGED\\n\");\nif (!CDROM_CAN(CDC_MEDIA_CHANGED))\nreturn -ENOSYS;\nif (!CDROM_CAN(CDC_SELECT_DISC) || arg == CDSL_CURRENT)\nreturn media_changed(cdi, 1);\nif ((unsigned int)arg >= cdi->capacity)\nreturn -EINVAL;\ninfo = kmalloc(sizeof(*info), GFP_KERNEL);\nif (!info)\nreturn -ENOMEM;\nret = cdrom_read_mech_status(cdi, info);\nif (!ret)\nret = info->slots[arg].change;\nkfree(info);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2018-1120": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Mmap()ing a FUSE-backed file onto a process's memory containing command line arguments or environment strings.",
        "trigger_condition": "An attacker causes utilities reading /proc/<pid>/cmdline or /proc/<pid>/environ files to block indefinitely or for a controlled time by exploiting the shared memory space.",
        "specific_code_behavior_causing_vulnerability": "The code does not ensure proper access control when reading command line arguments or environment strings from a process's memory, allowing an attacker to exploit the shared memory space and cause denial of service or synchronization issues."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add the FOLL_ANON flag to the access_remote_vm() calls in the code snippet. This flag ensures that memory access is done in an anonymous memory mapping, preventing attackers from exploiting the shared memory space and causing denial of service or synchronization issues. By adding the FOLL_ANON flag, the code is hardened against potential attacks and helps maintain proper access control when reading process memory.",
      "GPT_analysis": "The modification in the code snippet is necessary to address a vulnerability identified as CVE-2018-1120 in the Linux kernel before version 4.17. The vulnerability arises when a FUSE-backed file is mmap()ed onto a process's memory containing command line arguments or environment strings. This vulnerability can be exploited by an attacker to cause utilities like ps or w, or any other program that reads the /proc/<pid>/cmdline or /proc/<pid>/environ files, to block indefinitely (denial of service) or for a controlled period, which can be used as a synchronization primitive for other attacks.\n\nThe modification involves adding the FOLL_ANON flag to the access_remote_vm() calls in the code snippet. This flag ensures that the access to the memory is done in an anonymous memory mapping, which helps prevent the vulnerability from being exploited by malicious actors. By adding the FOLL_ANON flag, the code snippet is hardened against the vulnerability and helps mitigate the risk of denial of service attacks or other potential security threats associated with the original vulnerability.",
      "GPT_purpose": "Read the command line arguments of a process from the /proc/<pid>/cmdline file.",
      "GPT_function": "\n1. Read the command line arguments of a process from the /proc/<pid>/cmdline file.\n2. Check if the process has spawned far enough to have command line arguments.\n3. Copy the command line arguments to the user buffer while handling potential race conditions.",
      "CVE_id": "CVE-2018-1120",
      "code_before_change": "static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,\n\t\t\t\t     size_t _count, loff_t *pos)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tchar *page;\n\tunsigned long count = _count;\n\tunsigned long arg_start, arg_end, env_start, env_end;\n\tunsigned long len1, len2, len;\n\tunsigned long p;\n\tchar c;\n\tssize_t rv;\n\n\tBUG_ON(*pos < 0);\n\n\ttsk = get_proc_task(file_inode(file));\n\tif (!tsk)\n\t\treturn -ESRCH;\n\tmm = get_task_mm(tsk);\n\tput_task_struct(tsk);\n\tif (!mm)\n\t\treturn 0;\n\t/* Check if process spawned far enough to have cmdline. */\n\tif (!mm->env_end) {\n\t\trv = 0;\n\t\tgoto out_mmput;\n\t}\n\n\tpage = (char *)__get_free_page(GFP_KERNEL);\n\tif (!page) {\n\t\trv = -ENOMEM;\n\t\tgoto out_mmput;\n\t}\n\n\tdown_read(&mm->mmap_sem);\n\targ_start = mm->arg_start;\n\targ_end = mm->arg_end;\n\tenv_start = mm->env_start;\n\tenv_end = mm->env_end;\n\tup_read(&mm->mmap_sem);\n\n\tBUG_ON(arg_start > arg_end);\n\tBUG_ON(env_start > env_end);\n\n\tlen1 = arg_end - arg_start;\n\tlen2 = env_end - env_start;\n\n\t/* Empty ARGV. */\n\tif (len1 == 0) {\n\t\trv = 0;\n\t\tgoto out_free_page;\n\t}\n\t/*\n\t * Inherently racy -- command line shares address space\n\t * with code and data.\n\t */\n\trv = access_remote_vm(mm, arg_end - 1, &c, 1, 0);\n\tif (rv <= 0)\n\t\tgoto out_free_page;\n\n\trv = 0;\n\n\tif (c == '\\0') {\n\t\t/* Command line (set of strings) occupies whole ARGV. */\n\t\tif (len1 <= *pos)\n\t\t\tgoto out_free_page;\n\n\t\tp = arg_start + *pos;\n\t\tlen = len1 - *pos;\n\t\twhile (count > 0 && len > 0) {\n\t\t\tunsigned int _count;\n\t\t\tint nr_read;\n\n\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);\n\t\t\tif (nr_read < 0)\n\t\t\t\trv = nr_read;\n\t\t\tif (nr_read <= 0)\n\t\t\t\tgoto out_free_page;\n\n\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\trv = -EFAULT;\n\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\tp\t+= nr_read;\n\t\t\tlen\t-= nr_read;\n\t\t\tbuf\t+= nr_read;\n\t\t\tcount\t-= nr_read;\n\t\t\trv\t+= nr_read;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * Command line (1 string) occupies ARGV and\n\t\t * extends into ENVP.\n\t\t */\n\t\tstruct {\n\t\t\tunsigned long p;\n\t\t\tunsigned long len;\n\t\t} cmdline[2] = {\n\t\t\t{ .p = arg_start, .len = len1 },\n\t\t\t{ .p = env_start, .len = len2 },\n\t\t};\n\t\tloff_t pos1 = *pos;\n\t\tunsigned int i;\n\n\t\ti = 0;\n\t\twhile (i < 2 && pos1 >= cmdline[i].len) {\n\t\t\tpos1 -= cmdline[i].len;\n\t\t\ti++;\n\t\t}\n\t\twhile (i < 2) {\n\t\t\tp = cmdline[i].p + pos1;\n\t\t\tlen = cmdline[i].len - pos1;\n\t\t\twhile (count > 0 && len > 0) {\n\t\t\t\tunsigned int _count, l;\n\t\t\t\tint nr_read;\n\t\t\t\tbool final;\n\n\t\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);\n\t\t\t\tif (nr_read < 0)\n\t\t\t\t\trv = nr_read;\n\t\t\t\tif (nr_read <= 0)\n\t\t\t\t\tgoto out_free_page;\n\n\t\t\t\t/*\n\t\t\t\t * Command line can be shorter than whole ARGV\n\t\t\t\t * even if last \"marker\" byte says it is not.\n\t\t\t\t */\n\t\t\t\tfinal = false;\n\t\t\t\tl = strnlen(page, nr_read);\n\t\t\t\tif (l < nr_read) {\n\t\t\t\t\tnr_read = l;\n\t\t\t\t\tfinal = true;\n\t\t\t\t}\n\n\t\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\t\trv = -EFAULT;\n\t\t\t\t\tgoto out_free_page;\n\t\t\t\t}\n\n\t\t\t\tp\t+= nr_read;\n\t\t\t\tlen\t-= nr_read;\n\t\t\t\tbuf\t+= nr_read;\n\t\t\t\tcount\t-= nr_read;\n\t\t\t\trv\t+= nr_read;\n\n\t\t\t\tif (final)\n\t\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\t/* Only first chunk can be read partially. */\n\t\t\tpos1 = 0;\n\t\t\ti++;\n\t\t}\n\t}\n\nout_free_page:\n\tfree_page((unsigned long)page);\nout_mmput:\n\tmmput(mm);\n\tif (rv > 0)\n\t\t*pos += rv;\n\treturn rv;\n}",
      "code_after_change": "static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,\n\t\t\t\t     size_t _count, loff_t *pos)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tchar *page;\n\tunsigned long count = _count;\n\tunsigned long arg_start, arg_end, env_start, env_end;\n\tunsigned long len1, len2, len;\n\tunsigned long p;\n\tchar c;\n\tssize_t rv;\n\n\tBUG_ON(*pos < 0);\n\n\ttsk = get_proc_task(file_inode(file));\n\tif (!tsk)\n\t\treturn -ESRCH;\n\tmm = get_task_mm(tsk);\n\tput_task_struct(tsk);\n\tif (!mm)\n\t\treturn 0;\n\t/* Check if process spawned far enough to have cmdline. */\n\tif (!mm->env_end) {\n\t\trv = 0;\n\t\tgoto out_mmput;\n\t}\n\n\tpage = (char *)__get_free_page(GFP_KERNEL);\n\tif (!page) {\n\t\trv = -ENOMEM;\n\t\tgoto out_mmput;\n\t}\n\n\tdown_read(&mm->mmap_sem);\n\targ_start = mm->arg_start;\n\targ_end = mm->arg_end;\n\tenv_start = mm->env_start;\n\tenv_end = mm->env_end;\n\tup_read(&mm->mmap_sem);\n\n\tBUG_ON(arg_start > arg_end);\n\tBUG_ON(env_start > env_end);\n\n\tlen1 = arg_end - arg_start;\n\tlen2 = env_end - env_start;\n\n\t/* Empty ARGV. */\n\tif (len1 == 0) {\n\t\trv = 0;\n\t\tgoto out_free_page;\n\t}\n\t/*\n\t * Inherently racy -- command line shares address space\n\t * with code and data.\n\t */\n\trv = access_remote_vm(mm, arg_end - 1, &c, 1, FOLL_ANON);\n\tif (rv <= 0)\n\t\tgoto out_free_page;\n\n\trv = 0;\n\n\tif (c == '\\0') {\n\t\t/* Command line (set of strings) occupies whole ARGV. */\n\t\tif (len1 <= *pos)\n\t\t\tgoto out_free_page;\n\n\t\tp = arg_start + *pos;\n\t\tlen = len1 - *pos;\n\t\twhile (count > 0 && len > 0) {\n\t\t\tunsigned int _count;\n\t\t\tint nr_read;\n\n\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\n\t\t\tif (nr_read < 0)\n\t\t\t\trv = nr_read;\n\t\t\tif (nr_read <= 0)\n\t\t\t\tgoto out_free_page;\n\n\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\trv = -EFAULT;\n\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\tp\t+= nr_read;\n\t\t\tlen\t-= nr_read;\n\t\t\tbuf\t+= nr_read;\n\t\t\tcount\t-= nr_read;\n\t\t\trv\t+= nr_read;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * Command line (1 string) occupies ARGV and\n\t\t * extends into ENVP.\n\t\t */\n\t\tstruct {\n\t\t\tunsigned long p;\n\t\t\tunsigned long len;\n\t\t} cmdline[2] = {\n\t\t\t{ .p = arg_start, .len = len1 },\n\t\t\t{ .p = env_start, .len = len2 },\n\t\t};\n\t\tloff_t pos1 = *pos;\n\t\tunsigned int i;\n\n\t\ti = 0;\n\t\twhile (i < 2 && pos1 >= cmdline[i].len) {\n\t\t\tpos1 -= cmdline[i].len;\n\t\t\ti++;\n\t\t}\n\t\twhile (i < 2) {\n\t\t\tp = cmdline[i].p + pos1;\n\t\t\tlen = cmdline[i].len - pos1;\n\t\t\twhile (count > 0 && len > 0) {\n\t\t\t\tunsigned int _count, l;\n\t\t\t\tint nr_read;\n\t\t\t\tbool final;\n\n\t\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\n\t\t\t\tif (nr_read < 0)\n\t\t\t\t\trv = nr_read;\n\t\t\t\tif (nr_read <= 0)\n\t\t\t\t\tgoto out_free_page;\n\n\t\t\t\t/*\n\t\t\t\t * Command line can be shorter than whole ARGV\n\t\t\t\t * even if last \"marker\" byte says it is not.\n\t\t\t\t */\n\t\t\t\tfinal = false;\n\t\t\t\tl = strnlen(page, nr_read);\n\t\t\t\tif (l < nr_read) {\n\t\t\t\t\tnr_read = l;\n\t\t\t\t\tfinal = true;\n\t\t\t\t}\n\n\t\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\t\trv = -EFAULT;\n\t\t\t\t\tgoto out_free_page;\n\t\t\t\t}\n\n\t\t\t\tp\t+= nr_read;\n\t\t\t\tlen\t-= nr_read;\n\t\t\t\tbuf\t+= nr_read;\n\t\t\t\tcount\t-= nr_read;\n\t\t\t\trv\t+= nr_read;\n\n\t\t\t\tif (final)\n\t\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\t/* Only first chunk can be read partially. */\n\t\t\tpos1 = 0;\n\t\t\ti++;\n\t\t}\n\t}\n\nout_free_page:\n\tfree_page((unsigned long)page);\nout_mmput:\n\tmmput(mm);\n\tif (rv > 0)\n\t\t*pos += rv;\n\treturn rv;\n}",
      "modified_lines": {
        "added": [
          "\trv = access_remote_vm(mm, arg_end - 1, &c, 1, FOLL_ANON);",
          "\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);",
          "\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);"
        ],
        "deleted": [
          "\trv = access_remote_vm(mm, arg_end - 1, &c, 1, 0);",
          "\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);",
          "\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);"
        ]
      },
      "preconditions_for_vulnerability": "Mmap()ing a FUSE-backed file onto a process's memory containing command line arguments or environment strings.",
      "trigger_condition": "An attacker causes utilities reading /proc/<pid>/cmdline or /proc/<pid>/environ files to block indefinitely or for a controlled time by exploiting the shared memory space.",
      "specific_code_behavior_causing_vulnerability": "The code does not ensure proper access control when reading command line arguments or environment strings from a process's memory, allowing an attacker to exploit the shared memory space and cause denial of service or synchronization issues.",
      "id": 133,
      "code_after_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, char __user *VAR2,\nsize_t VAR3, loff_t *VAR4)\n{\nstruct task_struct *VAR5;\nstruct mm_struct *VAR6;\nchar *VAR7;\nunsigned long VAR8 = VAR3;\nunsigned long VAR9, VAR10, VAR11, VAR12;\nunsigned long VAR13, VAR14, VAR15;\nunsigned long VAR16;\nchar VAR17;\nssize_t VAR18;\nFUN2(*VAR4 < 0);\nVAR5 = FUN3(FUN4(VAR1));\nif (!VAR5)\nreturn -VAR19;\nVAR6 = FUN5(VAR5);\nFUN6(VAR5);\nif (!VAR6)\nreturn 0;\nif (!VAR6->VAR12) {\nVAR18 = 0;\ngoto VAR20;\n}\nVAR7 = (char *)FUN7(VAR21);\nif (!VAR7) {\nVAR18 = -VAR22;\ngoto VAR20;\n}\nFUN8(&VAR6->VAR23);\nVAR9 = VAR6->VAR9;\nVAR10 = VAR6->VAR10;\nVAR11 = VAR6->VAR11;\nVAR12 = VAR6->VAR12;\nFUN9(&VAR6->VAR23);\nFUN2(VAR9 > VAR10);\nFUN2(VAR11 > VAR12);\nVAR13 = VAR10 - VAR9;\nVAR14 = VAR12 - VAR11;\nif (VAR13 == 0) {\nVAR18 = 0;\ngoto VAR24;\n}\nVAR18 = FUN10(VAR6, VAR10 - 1, &VAR17, 1, VAR25);\nif (VAR18 <= 0)\ngoto VAR24;\nVAR18 = 0;\nif (VAR17 == ) {\nif (VAR13 <= *VAR4)\ngoto VAR24;\nVAR16 = VAR9 + *VAR4;\nVAR15 = VAR13 - *VAR4;\nwhile (VAR8 > 0 && VAR15 > 0) {\nunsigned int VAR3;\nint VAR26;\nVAR3 = FUN11(VAR8, VAR15, VAR27);\nVAR26 = FUN10(VAR6, VAR16, VAR7, VAR3, VAR25);\nif (VAR26 < 0)\nVAR18 = VAR26;\nif (VAR26 <= 0)\ngoto VAR24;\nif (FUN12(VAR2, VAR7, VAR26)) {\nVAR18 = -VAR28;\ngoto VAR24;\n}\nVAR16\t+= VAR26;\nVAR15\t-= VAR26;\nVAR2\t+= VAR26;\nVAR8\t-= VAR26;\nVAR18\t+= VAR26;\n}\n} else {\nstruct {\nunsigned long VAR16;\nunsigned long VAR15;\n} VAR29[2] = {\n{ .VAR16 = VAR9, .VAR15 = VAR13 },\n{ .VAR16 = VAR11, .VAR15 = VAR14 },\n};\nloff_t VAR30 = *VAR4;\nunsigned int VAR31;\nVAR31 = 0;\nwhile (VAR31 < 2 && VAR30 >= VAR29[VAR31].VAR15) {\nVAR30 -= VAR29[VAR31].VAR15;\nVAR31++;\n}\nwhile (VAR31 < 2) {\nVAR16 = VAR29[VAR31].VAR16 + VAR30;\nVAR15 = VAR29[VAR31].VAR15 - VAR30;\nwhile (VAR8 > 0 && VAR15 > 0) {\nunsigned int VAR3, VAR32;\nint VAR26;\nbool final;\nVAR3 = FUN11(VAR8, VAR15, VAR27);\nVAR26 = FUN10(VAR6, VAR16, VAR7, VAR3, VAR25);\nif (VAR26 < 0)\nVAR18 = VAR26;\nif (VAR26 <= 0)\ngoto VAR24;\nfinal = false;\nVAR32 = FUN13(VAR7, VAR26);\nif (VAR32 < VAR26) {\nVAR26 = VAR32;\nfinal = true;\n}\nif (FUN12(VAR2, VAR7, VAR26)) {\nVAR18 = -VAR28;\ngoto VAR24;\n}\nVAR16\t+= VAR26;\nVAR15\t-= VAR26;\nVAR2\t+= VAR26;\nVAR8\t-= VAR26;\nVAR18\t+= VAR26;\nif (final)\ngoto VAR24;\n}\nVAR30 = 0;\nVAR31++;\n}\n}\nVAR24:\nFUN14((unsigned long)VAR7);\nVAR20:\nFUN15(VAR6);\nif (VAR18 > 0)\n*VAR4 += VAR18;\nreturn VAR18;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, char __user *VAR2,\nsize_t VAR3, loff_t *VAR4)\n{\nstruct task_struct *VAR5;\nstruct mm_struct *VAR6;\nchar *VAR7;\nunsigned long VAR8 = VAR3;\nunsigned long VAR9, VAR10, VAR11, VAR12;\nunsigned long VAR13, VAR14, VAR15;\nunsigned long VAR16;\nchar VAR17;\nssize_t VAR18;\nFUN2(*VAR4 < 0);\nVAR5 = FUN3(FUN4(VAR1));\nif (!VAR5)\nreturn -VAR19;\nVAR6 = FUN5(VAR5);\nFUN6(VAR5);\nif (!VAR6)\nreturn 0;\nif (!VAR6->VAR12) {\nVAR18 = 0;\ngoto VAR20;\n}\nVAR7 = (char *)FUN7(VAR21);\nif (!VAR7) {\nVAR18 = -VAR22;\ngoto VAR20;\n}\nFUN8(&VAR6->VAR23);\nVAR9 = VAR6->VAR9;\nVAR10 = VAR6->VAR10;\nVAR11 = VAR6->VAR11;\nVAR12 = VAR6->VAR12;\nFUN9(&VAR6->VAR23);\nFUN2(VAR9 > VAR10);\nFUN2(VAR11 > VAR12);\nVAR13 = VAR10 - VAR9;\nVAR14 = VAR12 - VAR11;\nif (VAR13 == 0) {\nVAR18 = 0;\ngoto VAR24;\n}\nVAR18 = FUN10(VAR6, VAR10 - 1, &VAR17, 1, 0);\nif (VAR18 <= 0)\ngoto VAR24;\nVAR18 = 0;\nif (VAR17 == ) {\nif (VAR13 <= *VAR4)\ngoto VAR24;\nVAR16 = VAR9 + *VAR4;\nVAR15 = VAR13 - *VAR4;\nwhile (VAR8 > 0 && VAR15 > 0) {\nunsigned int VAR3;\nint VAR25;\nVAR3 = FUN11(VAR8, VAR15, VAR26);\nVAR25 = FUN10(VAR6, VAR16, VAR7, VAR3, 0);\nif (VAR25 < 0)\nVAR18 = VAR25;\nif (VAR25 <= 0)\ngoto VAR24;\nif (FUN12(VAR2, VAR7, VAR25)) {\nVAR18 = -VAR27;\ngoto VAR24;\n}\nVAR16\t+= VAR25;\nVAR15\t-= VAR25;\nVAR2\t+= VAR25;\nVAR8\t-= VAR25;\nVAR18\t+= VAR25;\n}\n} else {\nstruct {\nunsigned long VAR16;\nunsigned long VAR15;\n} VAR28[2] = {\n{ .VAR16 = VAR9, .VAR15 = VAR13 },\n{ .VAR16 = VAR11, .VAR15 = VAR14 },\n};\nloff_t VAR29 = *VAR4;\nunsigned int VAR30;\nVAR30 = 0;\nwhile (VAR30 < 2 && VAR29 >= VAR28[VAR30].VAR15) {\nVAR29 -= VAR28[VAR30].VAR15;\nVAR30++;\n}\nwhile (VAR30 < 2) {\nVAR16 = VAR28[VAR30].VAR16 + VAR29;\nVAR15 = VAR28[VAR30].VAR15 - VAR29;\nwhile (VAR8 > 0 && VAR15 > 0) {\nunsigned int VAR3, VAR31;\nint VAR25;\nbool final;\nVAR3 = FUN11(VAR8, VAR15, VAR26);\nVAR25 = FUN10(VAR6, VAR16, VAR7, VAR3, 0);\nif (VAR25 < 0)\nVAR18 = VAR25;\nif (VAR25 <= 0)\ngoto VAR24;\nfinal = false;\nVAR31 = FUN13(VAR7, VAR25);\nif (VAR31 < VAR25) {\nVAR25 = VAR31;\nfinal = true;\n}\nif (FUN12(VAR2, VAR7, VAR25)) {\nVAR18 = -VAR27;\ngoto VAR24;\n}\nVAR16\t+= VAR25;\nVAR15\t-= VAR25;\nVAR2\t+= VAR25;\nVAR8\t-= VAR25;\nVAR18\t+= VAR25;\nif (final)\ngoto VAR24;\n}\nVAR29 = 0;\nVAR30++;\n}\n}\nVAR24:\nFUN14((unsigned long)VAR7);\nVAR20:\nFUN15(VAR6);\nif (VAR18 > 0)\n*VAR4 += VAR18;\nreturn VAR18;\n}\n",
      "code_after_change_raw": "static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,\nsize_t _count, loff_t *pos)\n{\nstruct task_struct *tsk;\nstruct mm_struct *mm;\nchar *page;\nunsigned long count = _count;\nunsigned long arg_start, arg_end, env_start, env_end;\nunsigned long len1, len2, len;\nunsigned long p;\nchar c;\nssize_t rv;\nBUG_ON(*pos < 0);\ntsk = get_proc_task(file_inode(file));\nif (!tsk)\nreturn -ESRCH;\nmm = get_task_mm(tsk);\nput_task_struct(tsk);\nif (!mm)\nreturn 0;\nif (!mm->env_end) {\nrv = 0;\ngoto out_mmput;\n}\npage = (char *)__get_free_page(GFP_KERNEL);\nif (!page) {\nrv = -ENOMEM;\ngoto out_mmput;\n}\ndown_read(&mm->mmap_sem);\narg_start = mm->arg_start;\narg_end = mm->arg_end;\nenv_start = mm->env_start;\nenv_end = mm->env_end;\nup_read(&mm->mmap_sem);\nBUG_ON(arg_start > arg_end);\nBUG_ON(env_start > env_end);\nlen1 = arg_end - arg_start;\nlen2 = env_end - env_start;\nif (len1 == 0) {\nrv = 0;\ngoto out_free_page;\n}\nrv = access_remote_vm(mm, arg_end - 1, &c, 1, FOLL_ANON);\nif (rv <= 0)\ngoto out_free_page;\nrv = 0;\nif (c == '\\0') {\nif (len1 <= *pos)\ngoto out_free_page;\np = arg_start + *pos;\nlen = len1 - *pos;\nwhile (count > 0 && len > 0) {\nunsigned int _count;\nint nr_read;\n_count = min3(count, len, PAGE_SIZE);\nnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\nif (nr_read < 0)\nrv = nr_read;\nif (nr_read <= 0)\ngoto out_free_page;\nif (copy_to_user(buf, page, nr_read)) {\nrv = -EFAULT;\ngoto out_free_page;\n}\np\t+= nr_read;\nlen\t-= nr_read;\nbuf\t+= nr_read;\ncount\t-= nr_read;\nrv\t+= nr_read;\n}\n} else {\nstruct {\nunsigned long p;\nunsigned long len;\n} cmdline[2] = {\n{ .p = arg_start, .len = len1 },\n{ .p = env_start, .len = len2 },\n};\nloff_t pos1 = *pos;\nunsigned int i;\ni = 0;\nwhile (i < 2 && pos1 >= cmdline[i].len) {\npos1 -= cmdline[i].len;\ni++;\n}\nwhile (i < 2) {\np = cmdline[i].p + pos1;\nlen = cmdline[i].len - pos1;\nwhile (count > 0 && len > 0) {\nunsigned int _count, l;\nint nr_read;\nbool final;\n_count = min3(count, len, PAGE_SIZE);\nnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\nif (nr_read < 0)\nrv = nr_read;\nif (nr_read <= 0)\ngoto out_free_page;\nfinal = false;\nl = strnlen(page, nr_read);\nif (l < nr_read) {\nnr_read = l;\nfinal = true;\n}\nif (copy_to_user(buf, page, nr_read)) {\nrv = -EFAULT;\ngoto out_free_page;\n}\np\t+= nr_read;\nlen\t-= nr_read;\nbuf\t+= nr_read;\ncount\t-= nr_read;\nrv\t+= nr_read;\nif (final)\ngoto out_free_page;\n}\npos1 = 0;\ni++;\n}\n}\nout_free_page:\nfree_page((unsigned long)page);\nout_mmput:\nmmput(mm);\nif (rv > 0)\n*pos += rv;\nreturn rv;\n}\n",
      "code_before_change_raw": "static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,\nsize_t _count, loff_t *pos)\n{\nstruct task_struct *tsk;\nstruct mm_struct *mm;\nchar *page;\nunsigned long count = _count;\nunsigned long arg_start, arg_end, env_start, env_end;\nunsigned long len1, len2, len;\nunsigned long p;\nchar c;\nssize_t rv;\nBUG_ON(*pos < 0);\ntsk = get_proc_task(file_inode(file));\nif (!tsk)\nreturn -ESRCH;\nmm = get_task_mm(tsk);\nput_task_struct(tsk);\nif (!mm)\nreturn 0;\nif (!mm->env_end) {\nrv = 0;\ngoto out_mmput;\n}\npage = (char *)__get_free_page(GFP_KERNEL);\nif (!page) {\nrv = -ENOMEM;\ngoto out_mmput;\n}\ndown_read(&mm->mmap_sem);\narg_start = mm->arg_start;\narg_end = mm->arg_end;\nenv_start = mm->env_start;\nenv_end = mm->env_end;\nup_read(&mm->mmap_sem);\nBUG_ON(arg_start > arg_end);\nBUG_ON(env_start > env_end);\nlen1 = arg_end - arg_start;\nlen2 = env_end - env_start;\nif (len1 == 0) {\nrv = 0;\ngoto out_free_page;\n}\nrv = access_remote_vm(mm, arg_end - 1, &c, 1, 0);\nif (rv <= 0)\ngoto out_free_page;\nrv = 0;\nif (c == '\\0') {\nif (len1 <= *pos)\ngoto out_free_page;\np = arg_start + *pos;\nlen = len1 - *pos;\nwhile (count > 0 && len > 0) {\nunsigned int _count;\nint nr_read;\n_count = min3(count, len, PAGE_SIZE);\nnr_read = access_remote_vm(mm, p, page, _count, 0);\nif (nr_read < 0)\nrv = nr_read;\nif (nr_read <= 0)\ngoto out_free_page;\nif (copy_to_user(buf, page, nr_read)) {\nrv = -EFAULT;\ngoto out_free_page;\n}\np\t+= nr_read;\nlen\t-= nr_read;\nbuf\t+= nr_read;\ncount\t-= nr_read;\nrv\t+= nr_read;\n}\n} else {\nstruct {\nunsigned long p;\nunsigned long len;\n} cmdline[2] = {\n{ .p = arg_start, .len = len1 },\n{ .p = env_start, .len = len2 },\n};\nloff_t pos1 = *pos;\nunsigned int i;\ni = 0;\nwhile (i < 2 && pos1 >= cmdline[i].len) {\npos1 -= cmdline[i].len;\ni++;\n}\nwhile (i < 2) {\np = cmdline[i].p + pos1;\nlen = cmdline[i].len - pos1;\nwhile (count > 0 && len > 0) {\nunsigned int _count, l;\nint nr_read;\nbool final;\n_count = min3(count, len, PAGE_SIZE);\nnr_read = access_remote_vm(mm, p, page, _count, 0);\nif (nr_read < 0)\nrv = nr_read;\nif (nr_read <= 0)\ngoto out_free_page;\nfinal = false;\nl = strnlen(page, nr_read);\nif (l < nr_read) {\nnr_read = l;\nfinal = true;\n}\nif (copy_to_user(buf, page, nr_read)) {\nrv = -EFAULT;\ngoto out_free_page;\n}\np\t+= nr_read;\nlen\t-= nr_read;\nbuf\t+= nr_read;\ncount\t-= nr_read;\nrv\t+= nr_read;\nif (final)\ngoto out_free_page;\n}\npos1 = 0;\ni++;\n}\n}\nout_free_page:\nfree_page((unsigned long)page);\nout_mmput:\nmmput(mm);\nif (rv > 0)\n*pos += rv;\nreturn rv;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Mmap()ing a FUSE-backed file onto a process's memory containing command line arguments or environment strings.",
        "trigger_condition": "An attacker mmap()s a FUSE-backed file onto a process's memory containing sensitive information, causing utilities like ps or w to block indefinitely or for a controlled time.",
        "specific_code_behavior_causing_vulnerability": "The code does not check for the FOLL_ANON flag and the VMA not being anonymous, allowing an attacker to exploit the vulnerability by mmap()ing a FUSE-backed file onto a process's memory containing sensitive information."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check for the FOLL_ANON flag and ensure that the VMA is anonymous before allowing the mmap() operation to proceed. By adding the specific check in the code, the vulnerability can be prevented from being exploited, thus safeguarding against denial of service attacks.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2018-1120, which could lead to a denial of service attack. The vulnerability arises from the possibility of mmap()ing a FUSE-backed file onto a process's memory containing command line arguments or environment strings. This action can cause utilities like ps or w, which read from /proc/<pid>/cmdline or /proc/<pid>/environ, to block indefinitely or for a controlled time, leading to a denial of service.\n\nThe modification specifically adds the following line to the code:\n```c\nif (gup_flags & FOLL_ANON && !vma_is_anonymous(vma))\n    return -EFAULT;\n```\nThis addition checks if the FOLL_ANON flag is set and if the VMA is not anonymous. If this condition is met, it returns an error code (-EFAULT), preventing the vulnerability from being exploited.\n\nBy including this check, the code ensures that the FUSE-backed file cannot be mmap()ed onto a process's memory containing sensitive information like command line arguments or environment strings, thus mitigating the potential denial of service attack described in the vulnerability.",
      "GPT_purpose": "Check the flags of a virtual memory area to determine if certain access permissions are allowed.",
      "GPT_function": "\n1. Check the virtual memory area flags for specific conditions.\n2. Handle write permissions based on flags and force conditions.\n3. Handle read permissions based on flags and force conditions.\n4. Ensure data access permissions for the virtual memory area.",
      "CVE_id": "CVE-2018-1120",
      "code_before_change": "static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)\n{\n\tvm_flags_t vm_flags = vma->vm_flags;\n\tint write = (gup_flags & FOLL_WRITE);\n\tint foreign = (gup_flags & FOLL_REMOTE);\n\n\tif (vm_flags & (VM_IO | VM_PFNMAP))\n\t\treturn -EFAULT;\n\n\tif (write) {\n\t\tif (!(vm_flags & VM_WRITE)) {\n\t\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\t\treturn -EFAULT;\n\t\t\t/*\n\t\t\t * We used to let the write,force case do COW in a\n\t\t\t * VM_MAYWRITE VM_SHARED !VM_WRITE vma, so ptrace could\n\t\t\t * set a breakpoint in a read-only mapping of an\n\t\t\t * executable, without corrupting the file (yet only\n\t\t\t * when that file had been opened for writing!).\n\t\t\t * Anon pages in shared mappings are surprising: now\n\t\t\t * just reject it.\n\t\t\t */\n\t\t\tif (!is_cow_mapping(vm_flags))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t} else if (!(vm_flags & VM_READ)) {\n\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\treturn -EFAULT;\n\t\t/*\n\t\t * Is there actually any vma we can reach here which does not\n\t\t * have VM_MAYREAD set?\n\t\t */\n\t\tif (!(vm_flags & VM_MAYREAD))\n\t\t\treturn -EFAULT;\n\t}\n\t/*\n\t * gups are always data accesses, not instruction\n\t * fetches, so execute=false here\n\t */\n\tif (!arch_vma_access_permitted(vma, write, false, foreign))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
      "code_after_change": "static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)\n{\n\tvm_flags_t vm_flags = vma->vm_flags;\n\tint write = (gup_flags & FOLL_WRITE);\n\tint foreign = (gup_flags & FOLL_REMOTE);\n\n\tif (vm_flags & (VM_IO | VM_PFNMAP))\n\t\treturn -EFAULT;\n\n\tif (gup_flags & FOLL_ANON && !vma_is_anonymous(vma))\n\t\treturn -EFAULT;\n\n\tif (write) {\n\t\tif (!(vm_flags & VM_WRITE)) {\n\t\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\t\treturn -EFAULT;\n\t\t\t/*\n\t\t\t * We used to let the write,force case do COW in a\n\t\t\t * VM_MAYWRITE VM_SHARED !VM_WRITE vma, so ptrace could\n\t\t\t * set a breakpoint in a read-only mapping of an\n\t\t\t * executable, without corrupting the file (yet only\n\t\t\t * when that file had been opened for writing!).\n\t\t\t * Anon pages in shared mappings are surprising: now\n\t\t\t * just reject it.\n\t\t\t */\n\t\t\tif (!is_cow_mapping(vm_flags))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t} else if (!(vm_flags & VM_READ)) {\n\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\treturn -EFAULT;\n\t\t/*\n\t\t * Is there actually any vma we can reach here which does not\n\t\t * have VM_MAYREAD set?\n\t\t */\n\t\tif (!(vm_flags & VM_MAYREAD))\n\t\t\treturn -EFAULT;\n\t}\n\t/*\n\t * gups are always data accesses, not instruction\n\t * fetches, so execute=false here\n\t */\n\tif (!arch_vma_access_permitted(vma, write, false, foreign))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\treturn -EFAULT;",
          "",
          "\tif (gup_flags & FOLL_ANON && !vma_is_anonymous(vma))"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Mmap()ing a FUSE-backed file onto a process's memory containing command line arguments or environment strings.",
      "trigger_condition": "An attacker mmap()s a FUSE-backed file onto a process's memory containing sensitive information, causing utilities like ps or w to block indefinitely or for a controlled time.",
      "specific_code_behavior_causing_vulnerability": "The code does not check for the FOLL_ANON flag and the VMA not being anonymous, allowing an attacker to exploit the vulnerability by mmap()ing a FUSE-backed file onto a process's memory containing sensitive information.",
      "id": 134,
      "code_after_change_normalized": "static int FUN1(struct vm_area_struct *VAR1, unsigned long VAR2)\n{\nvm_flags_t VAR3 = VAR1->VAR3;\nint VAR4 = (VAR2 & VAR5);\nint VAR6 = (VAR2 & VAR7);\nif (VAR3 & (VAR8 | VAR9))\nreturn -VAR10;\nif (VAR2 & VAR11 && !FUN2(VAR1))\nreturn -VAR10;\nif (VAR4) {\nif (!(VAR3 & VAR12)) {\nif (!(VAR2 & VAR13))\nreturn -VAR10;\nif (!FUN3(VAR3))\nreturn -VAR10;\n}\n} else if (!(VAR3 & VAR14)) {\nif (!(VAR2 & VAR13))\nreturn -VAR10;\nif (!(VAR3 & VAR15))\nreturn -VAR10;\n}\nif (!FUN4(VAR1, VAR4, false, VAR6))\nreturn -VAR10;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct vm_area_struct *VAR1, unsigned long VAR2)\n{\nvm_flags_t VAR3 = VAR1->VAR3;\nint VAR4 = (VAR2 & VAR5);\nint VAR6 = (VAR2 & VAR7);\nif (VAR3 & (VAR8 | VAR9))\nreturn -VAR10;\nif (VAR4) {\nif (!(VAR3 & VAR11)) {\nif (!(VAR2 & VAR12))\nreturn -VAR10;\nif (!FUN2(VAR3))\nreturn -VAR10;\n}\n} else if (!(VAR3 & VAR13)) {\nif (!(VAR2 & VAR12))\nreturn -VAR10;\nif (!(VAR3 & VAR14))\nreturn -VAR10;\n}\nif (!FUN3(VAR1, VAR4, false, VAR6))\nreturn -VAR10;\nreturn 0;\n}\n",
      "code_after_change_raw": "static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)\n{\nvm_flags_t vm_flags = vma->vm_flags;\nint write = (gup_flags & FOLL_WRITE);\nint foreign = (gup_flags & FOLL_REMOTE);\nif (vm_flags & (VM_IO | VM_PFNMAP))\nreturn -EFAULT;\nif (gup_flags & FOLL_ANON && !vma_is_anonymous(vma))\nreturn -EFAULT;\nif (write) {\nif (!(vm_flags & VM_WRITE)) {\nif (!(gup_flags & FOLL_FORCE))\nreturn -EFAULT;\nif (!is_cow_mapping(vm_flags))\nreturn -EFAULT;\n}\n} else if (!(vm_flags & VM_READ)) {\nif (!(gup_flags & FOLL_FORCE))\nreturn -EFAULT;\nif (!(vm_flags & VM_MAYREAD))\nreturn -EFAULT;\n}\nif (!arch_vma_access_permitted(vma, write, false, foreign))\nreturn -EFAULT;\nreturn 0;\n}\n",
      "code_before_change_raw": "static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)\n{\nvm_flags_t vm_flags = vma->vm_flags;\nint write = (gup_flags & FOLL_WRITE);\nint foreign = (gup_flags & FOLL_REMOTE);\nif (vm_flags & (VM_IO | VM_PFNMAP))\nreturn -EFAULT;\nif (write) {\nif (!(vm_flags & VM_WRITE)) {\nif (!(gup_flags & FOLL_FORCE))\nreturn -EFAULT;\nif (!is_cow_mapping(vm_flags))\nreturn -EFAULT;\n}\n} else if (!(vm_flags & VM_READ)) {\nif (!(gup_flags & FOLL_FORCE))\nreturn -EFAULT;\nif (!(vm_flags & VM_MAYREAD))\nreturn -EFAULT;\n}\nif (!arch_vma_access_permitted(vma, write, false, foreign))\nreturn -EFAULT;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2018-12233": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Inadequate memory allocation strategy leading to a memory corruption bug in JFS.",
        "trigger_condition": "Calling setxattr twice with two different extended attribute names on the same file.",
        "specific_code_behavior_causing_vulnerability": "The vulnerable code snippet incorrectly allocates memory using kmalloc without ensuring the buffer size is large enough to accommodate the whole extent, potentially leading to a slab-out-of-bounds issue in jfs_xattr."
      },
      "solution": "To mitigate the vulnerability, it is necessary to modify the kmalloc call to allocate a buffer size that is large enough to make use of the whole extent. This ensures correct memory allocation and alignment, reducing the risk of memory corruption and preventing potential security vulnerabilities. By adjusting the buffer size allocation, the code becomes more robust and less susceptible to exploitation.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2018-12233, which involves a memory corruption bug in JFS triggered by calling setxattr twice with two different extended attribute names on the same file. The vulnerability can lead to a slab-out-of-bounds issue in jfs_xattr.\n\nThe specific change made in the code snippet is related to the kmalloc call. By modifying the kmalloc call to allocate a buffer size that is large enough to make use of the whole extent (ea_buf->max_size), the code aims to prevent potential memory corruption that could occur due to incorrect memory allocation.\n\nEnsuring that the allocated buffer size is appropriate and aligned correctly helps to mitigate the risk of memory corruption and potential security vulnerabilities. By making this adjustment, the code becomes more robust and less susceptible to exploitation, thereby improving the overall security of the system.",
      "GPT_purpose": "Retrieve extended attributes for a given inode in the JFS filesystem.",
      "GPT_function": "\n1. Retrieve extended attributes for a given inode.\n2. Handle different cases based on the size and type of extended attributes.\n3. Allocate memory for extended attributes if the size exceeds a certain threshold.\n4. Allocate new blocks to quota if needed for storing extended attributes.\n5. Check and validate the size of extended attributes before returning.",
      "CVE_id": "CVE-2018-12233",
      "code_before_change": "static int ea_get(struct inode *inode, struct ea_buffer *ea_buf, int min_size)\n{\n\tstruct jfs_inode_info *ji = JFS_IP(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tint size;\n\tint ea_size = sizeDXD(&ji->ea);\n\tint blocks_needed, current_blocks;\n\ts64 blkno;\n\tint rc;\n\tint quota_allocation = 0;\n\n\t/* When fsck.jfs clears a bad ea, it doesn't clear the size */\n\tif (ji->ea.flag == 0)\n\t\tea_size = 0;\n\n\tif (ea_size == 0) {\n\t\tif (min_size == 0) {\n\t\t\tea_buf->flag = 0;\n\t\t\tea_buf->max_size = 0;\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn 0;\n\t\t}\n\t\tif ((min_size <= sizeof (ji->i_inline_ea)) &&\n\t\t    (ji->mode2 & INLINEEA)) {\n\t\t\tea_buf->flag = EA_INLINE | EA_NEW;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tDXDlength(&ea_buf->new_ea, 0);\n\t\t\tDXDaddress(&ea_buf->new_ea, 0);\n\t\t\tea_buf->new_ea.flag = DXD_INLINE;\n\t\t\tDXDsize(&ea_buf->new_ea, min_size);\n\t\t\treturn 0;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else if (ji->ea.flag & DXD_INLINE) {\n\t\tif (min_size <= sizeof (ji->i_inline_ea)) {\n\t\t\tea_buf->flag = EA_INLINE;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tgoto size_check;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else {\n\t\tif (!(ji->ea.flag & DXD_EXTENT)) {\n\t\t\tjfs_error(sb, \"invalid ea.flag\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tcurrent_blocks = (ea_size + sb->s_blocksize - 1) >>\n\t\t    sb->s_blocksize_bits;\n\t}\n\tsize = max(min_size, ea_size);\n\n\tif (size > PSIZE) {\n\t\t/*\n\t\t * To keep the rest of the code simple.  Allocate a\n\t\t * contiguous buffer to work with\n\t\t */\n\t\tea_buf->xattr = kmalloc(size, GFP_KERNEL);\n\t\tif (ea_buf->xattr == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tea_buf->flag = EA_MALLOC;\n\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tkfree(ea_buf->xattr);\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn rc;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tblocks_needed = (min_size + sb->s_blocksize - 1) >>\n\t    sb->s_blocksize_bits;\n\n\tif (blocks_needed > current_blocks) {\n\t\t/* Allocate new blocks to quota. */\n\t\trc = dquot_alloc_block(inode, blocks_needed);\n\t\tif (rc)\n\t\t\treturn -EDQUOT;\n\n\t\tquota_allocation = blocks_needed;\n\n\t\trc = dbAlloc(inode, INOHINT(inode), (s64) blocks_needed,\n\t\t\t     &blkno);\n\t\tif (rc)\n\t\t\tgoto clean_up;\n\n\t\tDXDlength(&ea_buf->new_ea, blocks_needed);\n\t\tDXDaddress(&ea_buf->new_ea, blkno);\n\t\tea_buf->new_ea.flag = DXD_EXTENT;\n\t\tDXDsize(&ea_buf->new_ea, min_size);\n\n\t\tea_buf->flag = EA_EXTENT | EA_NEW;\n\n\t\tea_buf->mp = get_metapage(inode, blkno,\n\t\t\t\t\t  blocks_needed << sb->s_blocksize_bits,\n\t\t\t\t\t  1);\n\t\tif (ea_buf->mp == NULL) {\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\trc = -EIO;\n\t\t\tgoto clean_up;\n\t\t}\n\t\tea_buf->xattr = ea_buf->mp->data;\n\t\tea_buf->max_size = (min_size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tdiscard_metapage(ea_buf->mp);\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\tgoto clean_up;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tea_buf->flag = EA_EXTENT;\n\tea_buf->mp = read_metapage(inode, addressDXD(&ji->ea),\n\t\t\t\t   lengthDXD(&ji->ea) << sb->s_blocksize_bits,\n\t\t\t\t   1);\n\tif (ea_buf->mp == NULL) {\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\tea_buf->xattr = ea_buf->mp->data;\n\tea_buf->max_size = (ea_size + sb->s_blocksize - 1) &\n\t    ~(sb->s_blocksize - 1);\n\n      size_check:\n\tif (EALIST_SIZE(ea_buf->xattr) != ea_size) {\n\t\tprintk(KERN_ERR \"ea_get: invalid extended attribute\\n\");\n\t\tprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_ADDRESS, 16, 1,\n\t\t\t\t     ea_buf->xattr, ea_size, 1);\n\t\tea_release(inode, ea_buf);\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\n\treturn ea_size;\n\n      clean_up:\n\t/* Rollback quota allocation */\n\tif (quota_allocation)\n\t\tdquot_free_block(inode, quota_allocation);\n\n\treturn (rc);\n}",
      "code_after_change": "static int ea_get(struct inode *inode, struct ea_buffer *ea_buf, int min_size)\n{\n\tstruct jfs_inode_info *ji = JFS_IP(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tint size;\n\tint ea_size = sizeDXD(&ji->ea);\n\tint blocks_needed, current_blocks;\n\ts64 blkno;\n\tint rc;\n\tint quota_allocation = 0;\n\n\t/* When fsck.jfs clears a bad ea, it doesn't clear the size */\n\tif (ji->ea.flag == 0)\n\t\tea_size = 0;\n\n\tif (ea_size == 0) {\n\t\tif (min_size == 0) {\n\t\t\tea_buf->flag = 0;\n\t\t\tea_buf->max_size = 0;\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn 0;\n\t\t}\n\t\tif ((min_size <= sizeof (ji->i_inline_ea)) &&\n\t\t    (ji->mode2 & INLINEEA)) {\n\t\t\tea_buf->flag = EA_INLINE | EA_NEW;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tDXDlength(&ea_buf->new_ea, 0);\n\t\t\tDXDaddress(&ea_buf->new_ea, 0);\n\t\t\tea_buf->new_ea.flag = DXD_INLINE;\n\t\t\tDXDsize(&ea_buf->new_ea, min_size);\n\t\t\treturn 0;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else if (ji->ea.flag & DXD_INLINE) {\n\t\tif (min_size <= sizeof (ji->i_inline_ea)) {\n\t\t\tea_buf->flag = EA_INLINE;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tgoto size_check;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else {\n\t\tif (!(ji->ea.flag & DXD_EXTENT)) {\n\t\t\tjfs_error(sb, \"invalid ea.flag\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tcurrent_blocks = (ea_size + sb->s_blocksize - 1) >>\n\t\t    sb->s_blocksize_bits;\n\t}\n\tsize = max(min_size, ea_size);\n\n\tif (size > PSIZE) {\n\t\t/*\n\t\t * To keep the rest of the code simple.  Allocate a\n\t\t * contiguous buffer to work with. Make the buffer large\n\t\t * enough to make use of the whole extent.\n\t\t */\n\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\n\t\tea_buf->xattr = kmalloc(ea_buf->max_size, GFP_KERNEL);\n\t\tif (ea_buf->xattr == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tea_buf->flag = EA_MALLOC;\n\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tkfree(ea_buf->xattr);\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn rc;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tblocks_needed = (min_size + sb->s_blocksize - 1) >>\n\t    sb->s_blocksize_bits;\n\n\tif (blocks_needed > current_blocks) {\n\t\t/* Allocate new blocks to quota. */\n\t\trc = dquot_alloc_block(inode, blocks_needed);\n\t\tif (rc)\n\t\t\treturn -EDQUOT;\n\n\t\tquota_allocation = blocks_needed;\n\n\t\trc = dbAlloc(inode, INOHINT(inode), (s64) blocks_needed,\n\t\t\t     &blkno);\n\t\tif (rc)\n\t\t\tgoto clean_up;\n\n\t\tDXDlength(&ea_buf->new_ea, blocks_needed);\n\t\tDXDaddress(&ea_buf->new_ea, blkno);\n\t\tea_buf->new_ea.flag = DXD_EXTENT;\n\t\tDXDsize(&ea_buf->new_ea, min_size);\n\n\t\tea_buf->flag = EA_EXTENT | EA_NEW;\n\n\t\tea_buf->mp = get_metapage(inode, blkno,\n\t\t\t\t\t  blocks_needed << sb->s_blocksize_bits,\n\t\t\t\t\t  1);\n\t\tif (ea_buf->mp == NULL) {\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\trc = -EIO;\n\t\t\tgoto clean_up;\n\t\t}\n\t\tea_buf->xattr = ea_buf->mp->data;\n\t\tea_buf->max_size = (min_size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tdiscard_metapage(ea_buf->mp);\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\tgoto clean_up;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tea_buf->flag = EA_EXTENT;\n\tea_buf->mp = read_metapage(inode, addressDXD(&ji->ea),\n\t\t\t\t   lengthDXD(&ji->ea) << sb->s_blocksize_bits,\n\t\t\t\t   1);\n\tif (ea_buf->mp == NULL) {\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\tea_buf->xattr = ea_buf->mp->data;\n\tea_buf->max_size = (ea_size + sb->s_blocksize - 1) &\n\t    ~(sb->s_blocksize - 1);\n\n      size_check:\n\tif (EALIST_SIZE(ea_buf->xattr) != ea_size) {\n\t\tprintk(KERN_ERR \"ea_get: invalid extended attribute\\n\");\n\t\tprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_ADDRESS, 16, 1,\n\t\t\t\t     ea_buf->xattr, ea_size, 1);\n\t\tea_release(inode, ea_buf);\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\n\treturn ea_size;\n\n      clean_up:\n\t/* Rollback quota allocation */\n\tif (quota_allocation)\n\t\tdquot_free_block(inode, quota_allocation);\n\n\treturn (rc);\n}",
      "modified_lines": {
        "added": [
          "\t\t * contiguous buffer to work with. Make the buffer large",
          "\t\t * enough to make use of the whole extent.",
          "\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &",
          "\t\t    ~(sb->s_blocksize - 1);",
          "",
          "\t\tea_buf->xattr = kmalloc(ea_buf->max_size, GFP_KERNEL);"
        ],
        "deleted": [
          "\t\t * contiguous buffer to work with",
          "\t\tea_buf->xattr = kmalloc(size, GFP_KERNEL);",
          "\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &",
          "\t\t    ~(sb->s_blocksize - 1);"
        ]
      },
      "preconditions_for_vulnerability": "Inadequate memory allocation strategy leading to a memory corruption bug in JFS.",
      "trigger_condition": "Calling setxattr twice with two different extended attribute names on the same file.",
      "specific_code_behavior_causing_vulnerability": "The vulnerable code snippet incorrectly allocates memory using kmalloc without ensuring the buffer size is large enough to accommodate the whole extent, potentially leading to a slab-out-of-bounds issue in jfs_xattr.",
      "id": 135,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1, struct ea_buffer *VAR2, int VAR3)\n{\nstruct jfs_inode_info *VAR4 = FUN2(VAR1);\nstruct super_block *VAR5 = VAR1->VAR6;\nint VAR7;\nint VAR8 = FUN3(&VAR4->VAR9);\nint VAR10, VAR11;\ns64 VAR12;\nint VAR13;\nint VAR14 = 0;\nif (VAR4->VAR9.VAR15 == 0)\nVAR8 = 0;\nif (VAR8 == 0) {\nif (VAR3 == 0) {\nVAR2->VAR15 = 0;\nVAR2->VAR16 = 0;\nVAR2->VAR17 = NULL;\nreturn 0;\n}\nif ((VAR3 <= sizeof (VAR4->VAR18)) &&\n(VAR4->VAR19 & VAR20)) {\nVAR2->VAR15 = VAR21 | VAR22;\nVAR2->VAR16 = sizeof (VAR4->VAR18);\nVAR2->VAR17 = (struct VAR23 *) VAR4->VAR18;\nFUN4(&VAR2->VAR24, 0);\nFUN5(&VAR2->VAR24, 0);\nVAR2->VAR24.VAR15 = VAR25;\nFUN6(&VAR2->VAR24, VAR3);\nreturn 0;\n}\nVAR11 = 0;\n} else if (VAR4->VAR9.VAR15 & VAR25) {\nif (VAR3 <= sizeof (VAR4->VAR18)) {\nVAR2->VAR15 = VAR21;\nVAR2->VAR16 = sizeof (VAR4->VAR18);\nVAR2->VAR17 = (struct VAR23 *) VAR4->VAR18;\ngoto VAR26;\n}\nVAR11 = 0;\n} else {\nif (!(VAR4->VAR9.VAR15 & VAR27)) {\nFUN7(VAR5, \"STR\");\nreturn -VAR28;\n}\nVAR11 = (VAR8 + VAR5->VAR29 - 1) >>\nVAR5->VAR30;\n}\nVAR7 = FUN8(VAR3, VAR8);\nif (VAR7 > VAR31) {\nVAR2->VAR16 = (VAR7 + VAR5->VAR29 - 1) &\n~(VAR5->VAR29 - 1);\nVAR2->VAR17 = FUN9(VAR2->VAR16, VAR32);\nif (VAR2->VAR17 == NULL)\nreturn -VAR33;\nVAR2->VAR15 = VAR34;\nif (VAR8 == 0)\nreturn 0;\nif ((VAR13 = FUN10(VAR1, VAR2->VAR17))) {\nFUN11(VAR2->VAR17);\nVAR2->VAR17 = NULL;\nreturn VAR13;\n}\ngoto VAR26;\n}\nVAR10 = (VAR3 + VAR5->VAR29 - 1) >>\nVAR5->VAR30;\nif (VAR10 > VAR11) {\nVAR13 = FUN12(VAR1, VAR10);\nif (VAR13)\nreturn -VAR35;\nVAR14 = VAR10;\nVAR13 = FUN13(VAR1, FUN14(VAR1), (VAR36) VAR10,\n&VAR12);\nif (VAR13)\ngoto VAR37;\nFUN4(&VAR2->VAR24, VAR10);\nFUN5(&VAR2->VAR24, VAR12);\nVAR2->VAR24.VAR15 = VAR27;\nFUN6(&VAR2->VAR24, VAR3);\nVAR2->VAR15 = VAR38 | VAR22;\nVAR2->VAR39 = FUN15(VAR1, VAR12,\nVAR10 << VAR5->VAR30,\n1);\nif (VAR2->VAR39 == NULL) {\nFUN16(VAR1, VAR12, (VAR36) VAR10);\nVAR13 = -VAR28;\ngoto VAR37;\n}\nVAR2->VAR17 = VAR2->VAR39->VAR40;\nVAR2->VAR16 = (VAR3 + VAR5->VAR29 - 1) &\n~(VAR5->VAR29 - 1);\nif (VAR8 == 0)\nreturn 0;\nif ((VAR13 = FUN10(VAR1, VAR2->VAR17))) {\nFUN17(VAR2->VAR39);\nFUN16(VAR1, VAR12, (VAR36) VAR10);\ngoto VAR37;\n}\ngoto VAR26;\n}\nVAR2->VAR15 = VAR38;\nVAR2->VAR39 = FUN18(VAR1, FUN19(&VAR4->VAR9),\nFUN20(&VAR4->VAR9) << VAR5->VAR30,\n1);\nif (VAR2->VAR39 == NULL) {\nVAR13 = -VAR28;\ngoto VAR37;\n}\nVAR2->VAR17 = VAR2->VAR39->VAR40;\nVAR2->VAR16 = (VAR8 + VAR5->VAR29 - 1) &\n~(VAR5->VAR29 - 1);\nVAR26:\nif (FUN21(VAR2->VAR17) != VAR8) {\nFUN22(VAR41 \"STR\");\nFUN23(VAR41, \"STR\", VAR42, 16, 1,\nVAR2->VAR17, VAR8, 1);\nFUN24(VAR1, VAR2);\nVAR13 = -VAR28;\ngoto VAR37;\n}\nreturn VAR8;\nVAR37:\nif (VAR14)\nFUN25(VAR1, VAR14);\nreturn (VAR13);\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1, struct ea_buffer *VAR2, int VAR3)\n{\nstruct jfs_inode_info *VAR4 = FUN2(VAR1);\nstruct super_block *VAR5 = VAR1->VAR6;\nint VAR7;\nint VAR8 = FUN3(&VAR4->VAR9);\nint VAR10, VAR11;\ns64 VAR12;\nint VAR13;\nint VAR14 = 0;\nif (VAR4->VAR9.VAR15 == 0)\nVAR8 = 0;\nif (VAR8 == 0) {\nif (VAR3 == 0) {\nVAR2->VAR15 = 0;\nVAR2->VAR16 = 0;\nVAR2->VAR17 = NULL;\nreturn 0;\n}\nif ((VAR3 <= sizeof (VAR4->VAR18)) &&\n(VAR4->VAR19 & VAR20)) {\nVAR2->VAR15 = VAR21 | VAR22;\nVAR2->VAR16 = sizeof (VAR4->VAR18);\nVAR2->VAR17 = (struct VAR23 *) VAR4->VAR18;\nFUN4(&VAR2->VAR24, 0);\nFUN5(&VAR2->VAR24, 0);\nVAR2->VAR24.VAR15 = VAR25;\nFUN6(&VAR2->VAR24, VAR3);\nreturn 0;\n}\nVAR11 = 0;\n} else if (VAR4->VAR9.VAR15 & VAR25) {\nif (VAR3 <= sizeof (VAR4->VAR18)) {\nVAR2->VAR15 = VAR21;\nVAR2->VAR16 = sizeof (VAR4->VAR18);\nVAR2->VAR17 = (struct VAR23 *) VAR4->VAR18;\ngoto VAR26;\n}\nVAR11 = 0;\n} else {\nif (!(VAR4->VAR9.VAR15 & VAR27)) {\nFUN7(VAR5, \"STR\");\nreturn -VAR28;\n}\nVAR11 = (VAR8 + VAR5->VAR29 - 1) >>\nVAR5->VAR30;\n}\nVAR7 = FUN8(VAR3, VAR8);\nif (VAR7 > VAR31) {\nVAR2->VAR17 = FUN9(VAR7, VAR32);\nif (VAR2->VAR17 == NULL)\nreturn -VAR33;\nVAR2->VAR15 = VAR34;\nVAR2->VAR16 = (VAR7 + VAR5->VAR29 - 1) &\n~(VAR5->VAR29 - 1);\nif (VAR8 == 0)\nreturn 0;\nif ((VAR13 = FUN10(VAR1, VAR2->VAR17))) {\nFUN11(VAR2->VAR17);\nVAR2->VAR17 = NULL;\nreturn VAR13;\n}\ngoto VAR26;\n}\nVAR10 = (VAR3 + VAR5->VAR29 - 1) >>\nVAR5->VAR30;\nif (VAR10 > VAR11) {\nVAR13 = FUN12(VAR1, VAR10);\nif (VAR13)\nreturn -VAR35;\nVAR14 = VAR10;\nVAR13 = FUN13(VAR1, FUN14(VAR1), (VAR36) VAR10,\n&VAR12);\nif (VAR13)\ngoto VAR37;\nFUN4(&VAR2->VAR24, VAR10);\nFUN5(&VAR2->VAR24, VAR12);\nVAR2->VAR24.VAR15 = VAR27;\nFUN6(&VAR2->VAR24, VAR3);\nVAR2->VAR15 = VAR38 | VAR22;\nVAR2->VAR39 = FUN15(VAR1, VAR12,\nVAR10 << VAR5->VAR30,\n1);\nif (VAR2->VAR39 == NULL) {\nFUN16(VAR1, VAR12, (VAR36) VAR10);\nVAR13 = -VAR28;\ngoto VAR37;\n}\nVAR2->VAR17 = VAR2->VAR39->VAR40;\nVAR2->VAR16 = (VAR3 + VAR5->VAR29 - 1) &\n~(VAR5->VAR29 - 1);\nif (VAR8 == 0)\nreturn 0;\nif ((VAR13 = FUN10(VAR1, VAR2->VAR17))) {\nFUN17(VAR2->VAR39);\nFUN16(VAR1, VAR12, (VAR36) VAR10);\ngoto VAR37;\n}\ngoto VAR26;\n}\nVAR2->VAR15 = VAR38;\nVAR2->VAR39 = FUN18(VAR1, FUN19(&VAR4->VAR9),\nFUN20(&VAR4->VAR9) << VAR5->VAR30,\n1);\nif (VAR2->VAR39 == NULL) {\nVAR13 = -VAR28;\ngoto VAR37;\n}\nVAR2->VAR17 = VAR2->VAR39->VAR40;\nVAR2->VAR16 = (VAR8 + VAR5->VAR29 - 1) &\n~(VAR5->VAR29 - 1);\nVAR26:\nif (FUN21(VAR2->VAR17) != VAR8) {\nFUN22(VAR41 \"STR\");\nFUN23(VAR41, \"STR\", VAR42, 16, 1,\nVAR2->VAR17, VAR8, 1);\nFUN24(VAR1, VAR2);\nVAR13 = -VAR28;\ngoto VAR37;\n}\nreturn VAR8;\nVAR37:\nif (VAR14)\nFUN25(VAR1, VAR14);\nreturn (VAR13);\n}\n",
      "code_after_change_raw": "static int ea_get(struct inode *inode, struct ea_buffer *ea_buf, int min_size)\n{\nstruct jfs_inode_info *ji = JFS_IP(inode);\nstruct super_block *sb = inode->i_sb;\nint size;\nint ea_size = sizeDXD(&ji->ea);\nint blocks_needed, current_blocks;\ns64 blkno;\nint rc;\nint quota_allocation = 0;\nif (ji->ea.flag == 0)\nea_size = 0;\nif (ea_size == 0) {\nif (min_size == 0) {\nea_buf->flag = 0;\nea_buf->max_size = 0;\nea_buf->xattr = NULL;\nreturn 0;\n}\nif ((min_size <= sizeof (ji->i_inline_ea)) &&\n(ji->mode2 & INLINEEA)) {\nea_buf->flag = EA_INLINE | EA_NEW;\nea_buf->max_size = sizeof (ji->i_inline_ea);\nea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\nDXDlength(&ea_buf->new_ea, 0);\nDXDaddress(&ea_buf->new_ea, 0);\nea_buf->new_ea.flag = DXD_INLINE;\nDXDsize(&ea_buf->new_ea, min_size);\nreturn 0;\n}\ncurrent_blocks = 0;\n} else if (ji->ea.flag & DXD_INLINE) {\nif (min_size <= sizeof (ji->i_inline_ea)) {\nea_buf->flag = EA_INLINE;\nea_buf->max_size = sizeof (ji->i_inline_ea);\nea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\ngoto size_check;\n}\ncurrent_blocks = 0;\n} else {\nif (!(ji->ea.flag & DXD_EXTENT)) {\njfs_error(sb, \"invalid ea.flag\\n\");\nreturn -EIO;\n}\ncurrent_blocks = (ea_size + sb->s_blocksize - 1) >>\nsb->s_blocksize_bits;\n}\nsize = max(min_size, ea_size);\nif (size > PSIZE) {\nea_buf->max_size = (size + sb->s_blocksize - 1) &\n~(sb->s_blocksize - 1);\nea_buf->xattr = kmalloc(ea_buf->max_size, GFP_KERNEL);\nif (ea_buf->xattr == NULL)\nreturn -ENOMEM;\nea_buf->flag = EA_MALLOC;\nif (ea_size == 0)\nreturn 0;\nif ((rc = ea_read(inode, ea_buf->xattr))) {\nkfree(ea_buf->xattr);\nea_buf->xattr = NULL;\nreturn rc;\n}\ngoto size_check;\n}\nblocks_needed = (min_size + sb->s_blocksize - 1) >>\nsb->s_blocksize_bits;\nif (blocks_needed > current_blocks) {\nrc = dquot_alloc_block(inode, blocks_needed);\nif (rc)\nreturn -EDQUOT;\nquota_allocation = blocks_needed;\nrc = dbAlloc(inode, INOHINT(inode), (s64) blocks_needed,\n&blkno);\nif (rc)\ngoto clean_up;\nDXDlength(&ea_buf->new_ea, blocks_needed);\nDXDaddress(&ea_buf->new_ea, blkno);\nea_buf->new_ea.flag = DXD_EXTENT;\nDXDsize(&ea_buf->new_ea, min_size);\nea_buf->flag = EA_EXTENT | EA_NEW;\nea_buf->mp = get_metapage(inode, blkno,\nblocks_needed << sb->s_blocksize_bits,\n1);\nif (ea_buf->mp == NULL) {\ndbFree(inode, blkno, (s64) blocks_needed);\nrc = -EIO;\ngoto clean_up;\n}\nea_buf->xattr = ea_buf->mp->data;\nea_buf->max_size = (min_size + sb->s_blocksize - 1) &\n~(sb->s_blocksize - 1);\nif (ea_size == 0)\nreturn 0;\nif ((rc = ea_read(inode, ea_buf->xattr))) {\ndiscard_metapage(ea_buf->mp);\ndbFree(inode, blkno, (s64) blocks_needed);\ngoto clean_up;\n}\ngoto size_check;\n}\nea_buf->flag = EA_EXTENT;\nea_buf->mp = read_metapage(inode, addressDXD(&ji->ea),\nlengthDXD(&ji->ea) << sb->s_blocksize_bits,\n1);\nif (ea_buf->mp == NULL) {\nrc = -EIO;\ngoto clean_up;\n}\nea_buf->xattr = ea_buf->mp->data;\nea_buf->max_size = (ea_size + sb->s_blocksize - 1) &\n~(sb->s_blocksize - 1);\nsize_check:\nif (EALIST_SIZE(ea_buf->xattr) != ea_size) {\nprintk(KERN_ERR \"ea_get: invalid extended attribute\\n\");\nprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_ADDRESS, 16, 1,\nea_buf->xattr, ea_size, 1);\nea_release(inode, ea_buf);\nrc = -EIO;\ngoto clean_up;\n}\nreturn ea_size;\nclean_up:\nif (quota_allocation)\ndquot_free_block(inode, quota_allocation);\nreturn (rc);\n}\n",
      "code_before_change_raw": "static int ea_get(struct inode *inode, struct ea_buffer *ea_buf, int min_size)\n{\nstruct jfs_inode_info *ji = JFS_IP(inode);\nstruct super_block *sb = inode->i_sb;\nint size;\nint ea_size = sizeDXD(&ji->ea);\nint blocks_needed, current_blocks;\ns64 blkno;\nint rc;\nint quota_allocation = 0;\nif (ji->ea.flag == 0)\nea_size = 0;\nif (ea_size == 0) {\nif (min_size == 0) {\nea_buf->flag = 0;\nea_buf->max_size = 0;\nea_buf->xattr = NULL;\nreturn 0;\n}\nif ((min_size <= sizeof (ji->i_inline_ea)) &&\n(ji->mode2 & INLINEEA)) {\nea_buf->flag = EA_INLINE | EA_NEW;\nea_buf->max_size = sizeof (ji->i_inline_ea);\nea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\nDXDlength(&ea_buf->new_ea, 0);\nDXDaddress(&ea_buf->new_ea, 0);\nea_buf->new_ea.flag = DXD_INLINE;\nDXDsize(&ea_buf->new_ea, min_size);\nreturn 0;\n}\ncurrent_blocks = 0;\n} else if (ji->ea.flag & DXD_INLINE) {\nif (min_size <= sizeof (ji->i_inline_ea)) {\nea_buf->flag = EA_INLINE;\nea_buf->max_size = sizeof (ji->i_inline_ea);\nea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\ngoto size_check;\n}\ncurrent_blocks = 0;\n} else {\nif (!(ji->ea.flag & DXD_EXTENT)) {\njfs_error(sb, \"invalid ea.flag\\n\");\nreturn -EIO;\n}\ncurrent_blocks = (ea_size + sb->s_blocksize - 1) >>\nsb->s_blocksize_bits;\n}\nsize = max(min_size, ea_size);\nif (size > PSIZE) {\nea_buf->xattr = kmalloc(size, GFP_KERNEL);\nif (ea_buf->xattr == NULL)\nreturn -ENOMEM;\nea_buf->flag = EA_MALLOC;\nea_buf->max_size = (size + sb->s_blocksize - 1) &\n~(sb->s_blocksize - 1);\nif (ea_size == 0)\nreturn 0;\nif ((rc = ea_read(inode, ea_buf->xattr))) {\nkfree(ea_buf->xattr);\nea_buf->xattr = NULL;\nreturn rc;\n}\ngoto size_check;\n}\nblocks_needed = (min_size + sb->s_blocksize - 1) >>\nsb->s_blocksize_bits;\nif (blocks_needed > current_blocks) {\nrc = dquot_alloc_block(inode, blocks_needed);\nif (rc)\nreturn -EDQUOT;\nquota_allocation = blocks_needed;\nrc = dbAlloc(inode, INOHINT(inode), (s64) blocks_needed,\n&blkno);\nif (rc)\ngoto clean_up;\nDXDlength(&ea_buf->new_ea, blocks_needed);\nDXDaddress(&ea_buf->new_ea, blkno);\nea_buf->new_ea.flag = DXD_EXTENT;\nDXDsize(&ea_buf->new_ea, min_size);\nea_buf->flag = EA_EXTENT | EA_NEW;\nea_buf->mp = get_metapage(inode, blkno,\nblocks_needed << sb->s_blocksize_bits,\n1);\nif (ea_buf->mp == NULL) {\ndbFree(inode, blkno, (s64) blocks_needed);\nrc = -EIO;\ngoto clean_up;\n}\nea_buf->xattr = ea_buf->mp->data;\nea_buf->max_size = (min_size + sb->s_blocksize - 1) &\n~(sb->s_blocksize - 1);\nif (ea_size == 0)\nreturn 0;\nif ((rc = ea_read(inode, ea_buf->xattr))) {\ndiscard_metapage(ea_buf->mp);\ndbFree(inode, blkno, (s64) blocks_needed);\ngoto clean_up;\n}\ngoto size_check;\n}\nea_buf->flag = EA_EXTENT;\nea_buf->mp = read_metapage(inode, addressDXD(&ji->ea),\nlengthDXD(&ji->ea) << sb->s_blocksize_bits,\n1);\nif (ea_buf->mp == NULL) {\nrc = -EIO;\ngoto clean_up;\n}\nea_buf->xattr = ea_buf->mp->data;\nea_buf->max_size = (ea_size + sb->s_blocksize - 1) &\n~(sb->s_blocksize - 1);\nsize_check:\nif (EALIST_SIZE(ea_buf->xattr) != ea_size) {\nprintk(KERN_ERR \"ea_get: invalid extended attribute\\n\");\nprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_ADDRESS, 16, 1,\nea_buf->xattr, ea_size, 1);\nea_release(inode, ea_buf);\nrc = -EIO;\ngoto clean_up;\n}\nreturn ea_size;\nclean_up:\nif (quota_allocation)\ndquot_free_block(inode, quota_allocation);\nreturn (rc);\n}\n"
    }
  ],
  "CVE-2018-14615": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation and bounds checking for a specific field in the f2fs_inode_info structure.",
        "trigger_condition": "During unmounting of an f2fs image, a negative value is assigned to the specific field in the f2fs_inode_info structure, leading to a buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not validate the i_extra_isize field in the f2fs_inode_info structure to ensure it is within valid bounds and properly aligned. This allows a negative value to trigger a buffer overflow vulnerability during unmounting of the f2fs image."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a validation check for the i_extra_isize field in the f2fs_inode_info structure to ensure it is within valid bounds and aligned properly. By performing this validation, the code can prevent buffer overflows caused by negative values during unmounting of the f2fs image. The solution involves adding a conditional check for the i_extra_isize field and returning false if it exceeds the valid bounds or is not properly aligned.",
      "GPT_analysis": "The above modification is necessary to address the vulnerability CVE-2018-14615, which involves a buffer overflow in the `truncate_inline_inode()` function in the `fs/f2fs/inline.c` file. The vulnerability occurs when unmounting an f2fs image, as a length value may become negative, leading to a buffer overflow.\n\nTo fix this vulnerability, the modification adds the following lines to the code snippet:\n```c\nstruct f2fs_inode_info *fi = F2FS_I(inode);\n\nif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||\n    fi->i_extra_isize % sizeof(__le32)) {\n    set_sbi_flag(sbi, SBI_NEED_FSCK);\n    f2fs_msg(sbi->sb, KERN_WARNING,\n        \"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, \"\n        \"max: %zu\",\n        __func__, inode->i_ino, fi->i_extra_isize,\n        F2FS_TOTAL_EXTRA_ATTR_SIZE);\n    return false;\n}\n```\n\nThis modification introduces a check on the `i_extra_isize` field of the `f2fs_inode_info` structure to ensure that it is within valid bounds and aligned properly. By performing this additional validation, the code can prevent potential buffer overflows that may occur due to negative length values during unmounting of the f2fs image.",
      "GPT_purpose": "Perform sanity checks on an inode to detect and handle potential corruption issues.",
      "GPT_function": "\n1. Check if the inode's i_blocks field is corrupted and set a flag for filesystem check if it is.\n2. Check if the inode's footer is corrupted and set a flag for filesystem check if it is.\n3. Check for corrupted inode attributes and set a flag for filesystem check if found.\n4. Check for inconsistencies in inode's extent information and set a flag for filesystem check if any issues are detected.",
      "CVE_id": "CVE-2018-14615",
      "code_before_change": "static bool sanity_check_inode(struct inode *inode, struct page *node_page)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tunsigned long long iblocks;\n\n\tiblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\n\tif (!iblocks) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode i_blocks i_ino=%lx iblocks=%llu, \"\n\t\t\t\"run fsck to fix.\",\n\t\t\t__func__, inode->i_ino, iblocks);\n\t\treturn false;\n\t}\n\n\tif (ino_of_node(node_page) != nid_of_node(node_page)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode footer i_ino=%lx, ino,nid: \"\n\t\t\t\"[%u, %u] run fsck to fix.\",\n\t\t\t__func__, inode->i_ino,\n\t\t\tino_of_node(node_page), nid_of_node(node_page));\n\t\treturn false;\n\t}\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n\t\t\t&& !f2fs_has_extra_attr(inode)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (f2fs_has_extra_attr(inode) &&\n\t\t\t!f2fs_sb_has_extra_attr(sbi->sb)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: inode (ino=%lx) is with extra_attr, \"\n\t\t\t\"but extra_attr feature is off\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (F2FS_I(inode)->extent_tree) {\n\t\tstruct extent_info *ei = &F2FS_I(inode)->extent_tree->largest;\n\n\t\tif (ei->len &&\n\t\t\t(!f2fs_is_valid_blkaddr(sbi, ei->blk, DATA_GENERIC) ||\n\t\t\t!f2fs_is_valid_blkaddr(sbi, ei->blk + ei->len - 1,\n\t\t\t\t\t\t\tDATA_GENERIC))) {\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\t\"%s: inode (ino=%lx) extent info [%u, %u, %u] \"\n\t\t\t\t\"is incorrect, run fsck to fix\",\n\t\t\t\t__func__, inode->i_ino,\n\t\t\t\tei->blk, ei->fofs, ei->len);\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}",
      "code_after_change": "static bool sanity_check_inode(struct inode *inode, struct page *node_page)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\tunsigned long long iblocks;\n\n\tiblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\n\tif (!iblocks) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode i_blocks i_ino=%lx iblocks=%llu, \"\n\t\t\t\"run fsck to fix.\",\n\t\t\t__func__, inode->i_ino, iblocks);\n\t\treturn false;\n\t}\n\n\tif (ino_of_node(node_page) != nid_of_node(node_page)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode footer i_ino=%lx, ino,nid: \"\n\t\t\t\"[%u, %u] run fsck to fix.\",\n\t\t\t__func__, inode->i_ino,\n\t\t\tino_of_node(node_page), nid_of_node(node_page));\n\t\treturn false;\n\t}\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n\t\t\t&& !f2fs_has_extra_attr(inode)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (f2fs_has_extra_attr(inode) &&\n\t\t\t!f2fs_sb_has_extra_attr(sbi->sb)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: inode (ino=%lx) is with extra_attr, \"\n\t\t\t\"but extra_attr feature is off\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||\n\t\t\tfi->i_extra_isize % sizeof(__le32)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, \"\n\t\t\t\"max: %zu\",\n\t\t\t__func__, inode->i_ino, fi->i_extra_isize,\n\t\t\tF2FS_TOTAL_EXTRA_ATTR_SIZE);\n\t\treturn false;\n\t}\n\n\tif (F2FS_I(inode)->extent_tree) {\n\t\tstruct extent_info *ei = &F2FS_I(inode)->extent_tree->largest;\n\n\t\tif (ei->len &&\n\t\t\t(!f2fs_is_valid_blkaddr(sbi, ei->blk, DATA_GENERIC) ||\n\t\t\t!f2fs_is_valid_blkaddr(sbi, ei->blk + ei->len - 1,\n\t\t\t\t\t\t\tDATA_GENERIC))) {\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\t\"%s: inode (ino=%lx) extent info [%u, %u, %u] \"\n\t\t\t\t\"is incorrect, run fsck to fix\",\n\t\t\t\t__func__, inode->i_ino,\n\t\t\t\tei->blk, ei->fofs, ei->len);\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}",
      "modified_lines": {
        "added": [
          "\tstruct f2fs_inode_info *fi = F2FS_I(inode);",
          "\tif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||",
          "\t\t\tfi->i_extra_isize % sizeof(__le32)) {",
          "\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);",
          "\t\tf2fs_msg(sbi->sb, KERN_WARNING,",
          "\t\t\t\"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, \"",
          "\t\t\t\"max: %zu\",",
          "\t\t\t__func__, inode->i_ino, fi->i_extra_isize,",
          "\t\t\tF2FS_TOTAL_EXTRA_ATTR_SIZE);",
          "\t\treturn false;",
          "\t}",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper validation and bounds checking for a specific field in the f2fs_inode_info structure.",
      "trigger_condition": "During unmounting of an f2fs image, a negative value is assigned to the specific field in the f2fs_inode_info structure, leading to a buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not validate the i_extra_isize field in the f2fs_inode_info structure to ensure it is within valid bounds and properly aligned. This allows a negative value to trigger a buffer overflow vulnerability during unmounting of the f2fs image.",
      "id": 136,
      "code_after_change_normalized": "static bool FUN1(struct VAR1 *VAR1, struct page *VAR2)\n{\nstruct f2fs_sb_info *VAR3 = FUN2(VAR1);\nstruct f2fs_inode_info *VAR4 = FUN3(VAR1);\nunsigned long long VAR5;\nVAR5 = FUN4(FUN5(VAR2)->VAR6);\nif (!VAR5) {\nFUN6(VAR3, VAR7);\nFUN7(VAR3->VAR8, VAR9,\n\"STR\"\n\"STR\",\nVAR10, VAR1->VAR11, VAR5);\nreturn false;\n}\nif (FUN8(VAR2) != FUN9(VAR2)) {\nFUN6(VAR3, VAR7);\nFUN7(VAR3->VAR8, VAR9,\n\"STR\"\n\"STR\",\nVAR10, VAR1->VAR11,\nFUN8(VAR2), FUN9(VAR2));\nreturn false;\n}\nif (FUN10(VAR3->VAR8)\n&& !FUN11(VAR1)) {\nFUN6(VAR3, VAR7);\nFUN7(VAR3->VAR8, VAR9,\n\"STR\",\nVAR10, VAR1->VAR11);\nreturn false;\n}\nif (FUN11(VAR1) &&\n!FUN12(VAR3->VAR8)) {\nFUN6(VAR3, VAR7);\nFUN7(VAR3->VAR8, VAR9,\n\"STR\"\n\"STR\",\nVAR10, VAR1->VAR11);\nreturn false;\n}\nif (VAR4->VAR12 > VAR13 ||\nVAR4->VAR12 % sizeof(VAR14)) {\nFUN6(VAR3, VAR7);\nFUN7(VAR3->VAR8, VAR9,\n\"STR\"\n\"STR\",\nVAR10, VAR1->VAR11, VAR4->VAR12,\nVAR13);\nreturn false;\n}\nif (FUN3(VAR1)->VAR15) {\nstruct extent_info *VAR16 = &FUN3(VAR1)->VAR15->VAR17;\nif (VAR16->VAR18 &&\n(!FUN13(VAR3, VAR16->VAR19, VAR20) ||\n!FUN13(VAR3, VAR16->VAR19 + VAR16->VAR18 - 1,\nVAR20))) {\nFUN6(VAR3, VAR7);\nFUN7(VAR3->VAR8, VAR9,\n\"STR\"\n\"STR\",\nVAR10, VAR1->VAR11,\nVAR16->VAR19, VAR16->VAR21, VAR16->VAR18);\nreturn false;\n}\n}\nreturn true;\n}\n",
      "code_before_change_normalized": "static bool FUN1(struct VAR1 *VAR1, struct page *VAR2)\n{\nstruct f2fs_sb_info *VAR3 = FUN2(VAR1);\nunsigned long long VAR4;\nVAR4 = FUN3(FUN4(VAR2)->VAR5);\nif (!VAR4) {\nFUN5(VAR3, VAR6);\nFUN6(VAR3->VAR7, VAR8,\n\"STR\"\n\"STR\",\nVAR9, VAR1->VAR10, VAR4);\nreturn false;\n}\nif (FUN7(VAR2) != FUN8(VAR2)) {\nFUN5(VAR3, VAR6);\nFUN6(VAR3->VAR7, VAR8,\n\"STR\"\n\"STR\",\nVAR9, VAR1->VAR10,\nFUN7(VAR2), FUN8(VAR2));\nreturn false;\n}\nif (FUN9(VAR3->VAR7)\n&& !FUN10(VAR1)) {\nFUN5(VAR3, VAR6);\nFUN6(VAR3->VAR7, VAR8,\n\"STR\",\nVAR9, VAR1->VAR10);\nreturn false;\n}\nif (FUN10(VAR1) &&\n!FUN11(VAR3->VAR7)) {\nFUN5(VAR3, VAR6);\nFUN6(VAR3->VAR7, VAR8,\n\"STR\"\n\"STR\",\nVAR9, VAR1->VAR10);\nreturn false;\n}\nif (FUN12(VAR1)->VAR11) {\nstruct extent_info *VAR12 = &FUN12(VAR1)->VAR11->VAR13;\nif (VAR12->VAR14 &&\n(!FUN13(VAR3, VAR12->VAR15, VAR16) ||\n!FUN13(VAR3, VAR12->VAR15 + VAR12->VAR14 - 1,\nVAR16))) {\nFUN5(VAR3, VAR6);\nFUN6(VAR3->VAR7, VAR8,\n\"STR\"\n\"STR\",\nVAR9, VAR1->VAR10,\nVAR12->VAR15, VAR12->VAR17, VAR12->VAR14);\nreturn false;\n}\n}\nreturn true;\n}\n",
      "code_after_change_raw": "static bool sanity_check_inode(struct inode *inode, struct page *node_page)\n{\nstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\nstruct f2fs_inode_info *fi = F2FS_I(inode);\nunsigned long long iblocks;\niblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\nif (!iblocks) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: corrupted inode i_blocks i_ino=%lx iblocks=%llu, \"\n\"run fsck to fix.\",\n__func__, inode->i_ino, iblocks);\nreturn false;\n}\nif (ino_of_node(node_page) != nid_of_node(node_page)) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: corrupted inode footer i_ino=%lx, ino,nid: \"\n\"[%u, %u] run fsck to fix.\",\n__func__, inode->i_ino,\nino_of_node(node_page), nid_of_node(node_page));\nreturn false;\n}\nif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n&& !f2fs_has_extra_attr(inode)) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n__func__, inode->i_ino);\nreturn false;\n}\nif (f2fs_has_extra_attr(inode) &&\n!f2fs_sb_has_extra_attr(sbi->sb)) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: inode (ino=%lx) is with extra_attr, \"\n\"but extra_attr feature is off\",\n__func__, inode->i_ino);\nreturn false;\n}\nif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||\nfi->i_extra_isize % sizeof(__le32)) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, \"\n\"max: %zu\",\n__func__, inode->i_ino, fi->i_extra_isize,\nF2FS_TOTAL_EXTRA_ATTR_SIZE);\nreturn false;\n}\nif (F2FS_I(inode)->extent_tree) {\nstruct extent_info *ei = &F2FS_I(inode)->extent_tree->largest;\nif (ei->len &&\n(!f2fs_is_valid_blkaddr(sbi, ei->blk, DATA_GENERIC) ||\n!f2fs_is_valid_blkaddr(sbi, ei->blk + ei->len - 1,\nDATA_GENERIC))) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: inode (ino=%lx) extent info [%u, %u, %u] \"\n\"is incorrect, run fsck to fix\",\n__func__, inode->i_ino,\nei->blk, ei->fofs, ei->len);\nreturn false;\n}\n}\nreturn true;\n}\n",
      "code_before_change_raw": "static bool sanity_check_inode(struct inode *inode, struct page *node_page)\n{\nstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\nunsigned long long iblocks;\niblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\nif (!iblocks) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: corrupted inode i_blocks i_ino=%lx iblocks=%llu, \"\n\"run fsck to fix.\",\n__func__, inode->i_ino, iblocks);\nreturn false;\n}\nif (ino_of_node(node_page) != nid_of_node(node_page)) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: corrupted inode footer i_ino=%lx, ino,nid: \"\n\"[%u, %u] run fsck to fix.\",\n__func__, inode->i_ino,\nino_of_node(node_page), nid_of_node(node_page));\nreturn false;\n}\nif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n&& !f2fs_has_extra_attr(inode)) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n__func__, inode->i_ino);\nreturn false;\n}\nif (f2fs_has_extra_attr(inode) &&\n!f2fs_sb_has_extra_attr(sbi->sb)) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: inode (ino=%lx) is with extra_attr, \"\n\"but extra_attr feature is off\",\n__func__, inode->i_ino);\nreturn false;\n}\nif (F2FS_I(inode)->extent_tree) {\nstruct extent_info *ei = &F2FS_I(inode)->extent_tree->largest;\nif (ei->len &&\n(!f2fs_is_valid_blkaddr(sbi, ei->blk, DATA_GENERIC) ||\n!f2fs_is_valid_blkaddr(sbi, ei->blk + ei->len - 1,\nDATA_GENERIC))) {\nset_sbi_flag(sbi, SBI_NEED_FSCK);\nf2fs_msg(sbi->sb, KERN_WARNING,\n\"%s: inode (ino=%lx) extent info [%u, %u, %u] \"\n\"is incorrect, run fsck to fix\",\n__func__, inode->i_ino,\nei->blk, ei->fofs, ei->len);\nreturn false;\n}\n}\nreturn true;\n}\n"
    }
  ],
  "CVE-2018-20855": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper initialization of a struct variable in a function.",
        "trigger_condition": "The uninitialized struct variable is used without being properly initialized, leading to a memory leak of stack data to userspace.",
        "specific_code_behavior_causing_vulnerability": "The code does not initialize a specific struct variable of type struct mlx5_ib_create_qp_resp, resulting in a memory leak of stack data to userspace when the uninitialized variable is used."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper initialization of the struct variable struct mlx5_ib_create_qp_resp before its usage. By initializing the variable, the code prevents the memory leak of stack data to userspace and addresses the vulnerability. In this case, the solution involves adding the initialization of the struct variable struct mlx5_ib_create_qp_resp resp = {}; before its usage in the function.",
      "GPT_analysis": "The modification is necessary to fix a vulnerability (CVE-2018-20855) where the `resp` variable of type `struct mlx5_ib_create_qp_resp` was not initialized in the `create_qp_common` function. This uninitialized variable could lead to leaking stack memory to userspace, potentially exposing sensitive information.\n\nBy adding `struct mlx5_ib_create_qp_resp resp = {};` before its usage, we ensure that the `resp` variable is properly initialized, preventing any potential information leakage and addressing the vulnerability.",
      "GPT_purpose": "Create a queue pair (QP) for InfiniBand devices using mlx5_ib_dev and related structures.",
      "GPT_function": "\n1. Initialize various structures and variables for creating a QP.\n2. Check and set different flags and configurations based on the QP attributes.\n3. Handle user and kernel QP creation, including setting parameters and resources.\n4. Handle specific configurations and capabilities for different QP types.\n5. Manage CQs and maintain device-QP and CQ-QP relationships.\n6. Handle error cases and cleanup resources appropriately.",
      "CVE_id": "CVE-2018-20855",
      "code_before_change": "static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,\n\t\t\t    struct ib_qp_init_attr *init_attr,\n\t\t\t    struct ib_udata *udata, struct mlx5_ib_qp *qp)\n{\n\tstruct mlx5_ib_resources *devr = &dev->devr;\n\tint inlen = MLX5_ST_SZ_BYTES(create_qp_in);\n\tstruct mlx5_core_dev *mdev = dev->mdev;\n\tstruct mlx5_ib_create_qp_resp resp;\n\tstruct mlx5_ib_cq *send_cq;\n\tstruct mlx5_ib_cq *recv_cq;\n\tunsigned long flags;\n\tu32 uidx = MLX5_IB_DEFAULT_UIDX;\n\tstruct mlx5_ib_create_qp ucmd;\n\tstruct mlx5_ib_qp_base *base;\n\tint mlx5_st;\n\tvoid *qpc;\n\tu32 *in;\n\tint err;\n\n\tmutex_init(&qp->mutex);\n\tspin_lock_init(&qp->sq.lock);\n\tspin_lock_init(&qp->rq.lock);\n\n\tmlx5_st = to_mlx5_st(init_attr->qp_type);\n\tif (mlx5_st < 0)\n\t\treturn -EINVAL;\n\n\tif (init_attr->rwq_ind_tbl) {\n\t\tif (!udata)\n\t\t\treturn -ENOSYS;\n\n\t\terr = create_rss_raw_qp_tir(dev, qp, pd, init_attr, udata);\n\t\treturn err;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK) {\n\t\tif (!MLX5_CAP_GEN(mdev, block_lb_mc)) {\n\t\t\tmlx5_ib_dbg(dev, \"block multicast loopback isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK;\n\t\t}\n\t}\n\n\tif (init_attr->create_flags &\n\t\t\t(IB_QP_CREATE_CROSS_CHANNEL |\n\t\t\t IB_QP_CREATE_MANAGED_SEND |\n\t\t\t IB_QP_CREATE_MANAGED_RECV)) {\n\t\tif (!MLX5_CAP_GEN(mdev, cd)) {\n\t\t\tmlx5_ib_dbg(dev, \"cross-channel isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (init_attr->create_flags & IB_QP_CREATE_CROSS_CHANNEL)\n\t\t\tqp->flags |= MLX5_IB_QP_CROSS_CHANNEL;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_SEND)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_SEND;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_RECV)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_RECV;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO))\n\t\tif (!MLX5_CAP_GEN(mdev, ipoib_basic_offloads)) {\n\t\t\tmlx5_ib_dbg(dev, \"ipoib UD lso qp isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_SCATTER_FCS) {\n\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS is supported only for Raw Packet QPs\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (!MLX5_CAP_GEN(dev->mdev, eth_net_offloads) ||\n\t\t    !MLX5_CAP_ETH(dev->mdev, scatter_fcs)) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tqp->flags |= MLX5_IB_QP_CAP_SCATTER_FCS;\n\t}\n\n\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)\n\t\tqp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;\n\n\tif (init_attr->create_flags & IB_QP_CREATE_CVLAN_STRIPPING) {\n\t\tif (!(MLX5_CAP_GEN(dev->mdev, eth_net_offloads) &&\n\t\t      MLX5_CAP_ETH(dev->mdev, vlan_cap)) ||\n\t\t    (init_attr->qp_type != IB_QPT_RAW_PACKET))\n\t\t\treturn -EOPNOTSUPP;\n\t\tqp->flags |= MLX5_IB_QP_CVLAN_STRIPPING;\n\t}\n\n\tif (pd && pd->uobject) {\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {\n\t\t\tmlx5_ib_dbg(dev, \"copy failed\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\terr = get_qp_user_index(to_mucontext(pd->uobject->context),\n\t\t\t\t\t&ucmd, udata->inlen, &uidx);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tqp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);\n\t\tqp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);\n\t\tif (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {\n\t\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET ||\n\t\t\t    !tunnel_offload_supported(mdev)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Tunnel offload isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t\tqp->tunnel_offload_en = true;\n\t\t}\n\n\t\tif (init_attr->create_flags & IB_QP_CREATE_SOURCE_QPN) {\n\t\t\tif (init_attr->qp_type != IB_QPT_UD ||\n\t\t\t    (MLX5_CAP_GEN(dev->mdev, port_type) !=\n\t\t\t     MLX5_CAP_PORT_TYPE_IB) ||\n\t\t\t    !mlx5_get_flow_namespace(dev->mdev, MLX5_FLOW_NAMESPACE_BYPASS)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Source QP option isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\tqp->flags |= MLX5_IB_QP_UNDERLAY;\n\t\t\tqp->underlay_qpn = init_attr->source_qpn;\n\t\t}\n\t} else {\n\t\tqp->wq_sig = !!wq_signature;\n\t}\n\n\tbase = (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t\tqp->flags & MLX5_IB_QP_UNDERLAY) ?\n\t       &qp->raw_packet_qp.rq.base :\n\t       &qp->trans_qp.base;\n\n\tqp->has_rq = qp_has_rq(init_attr);\n\terr = set_rq_size(dev, &init_attr->cap, qp->has_rq,\n\t\t\t  qp, (pd && pd->uobject) ? &ucmd : NULL);\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tif (pd) {\n\t\tif (pd->uobject) {\n\t\t\t__u32 max_wqes =\n\t\t\t\t1 << MLX5_CAP_GEN(mdev, log_max_qp_sz);\n\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d)\\n\", ucmd.sq_wqe_count);\n\t\t\tif (ucmd.rq_wqe_shift != qp->rq.wqe_shift ||\n\t\t\t    ucmd.rq_wqe_count != qp->rq.wqe_cnt) {\n\t\t\t\tmlx5_ib_dbg(dev, \"invalid rq params\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (ucmd.sq_wqe_count > max_wqes) {\n\t\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d) > max allowed (%d)\\n\",\n\t\t\t\t\t    ucmd.sq_wqe_count, max_wqes);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (init_attr->create_flags &\n\t\t\t    mlx5_ib_create_qp_sqpn_qp1()) {\n\t\t\t\tmlx5_ib_dbg(dev, \"user-space is not allowed to create UD QPs spoofing as QP1\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\terr = create_user_qp(dev, pd, qp, udata, init_attr, &in,\n\t\t\t\t\t     &resp, &inlen, base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t} else {\n\t\t\terr = create_kernel_qp(dev, init_attr, qp, &in, &inlen,\n\t\t\t\t\t       base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t}\n\n\t\tif (err)\n\t\t\treturn err;\n\t} else {\n\t\tin = kvzalloc(inlen, GFP_KERNEL);\n\t\tif (!in)\n\t\t\treturn -ENOMEM;\n\n\t\tqp->create_type = MLX5_QP_EMPTY;\n\t}\n\n\tif (is_sqp(init_attr->qp_type))\n\t\tqp->port = init_attr->port_num;\n\n\tqpc = MLX5_ADDR_OF(create_qp_in, in, qpc);\n\n\tMLX5_SET(qpc, qpc, st, mlx5_st);\n\tMLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);\n\n\tif (init_attr->qp_type != MLX5_IB_QPT_REG_UMR)\n\t\tMLX5_SET(qpc, qpc, pd, to_mpd(pd ? pd : devr->p0)->pdn);\n\telse\n\t\tMLX5_SET(qpc, qpc, latency_sensitive, 1);\n\n\n\tif (qp->wq_sig)\n\t\tMLX5_SET(qpc, qpc, wq_signature, 1);\n\n\tif (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)\n\t\tMLX5_SET(qpc, qpc, block_lb_mc, 1);\n\n\tif (qp->flags & MLX5_IB_QP_CROSS_CHANNEL)\n\t\tMLX5_SET(qpc, qpc, cd_master, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_SEND)\n\t\tMLX5_SET(qpc, qpc, cd_slave_send, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_RECV)\n\t\tMLX5_SET(qpc, qpc, cd_slave_receive, 1);\n\n\tif (qp->scat_cqe && is_connected(init_attr->qp_type)) {\n\t\tint rcqe_sz;\n\t\tint scqe_sz;\n\n\t\trcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);\n\t\tscqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);\n\n\t\tif (rcqe_sz == 128)\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA64_CQE);\n\t\telse\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA32_CQE);\n\n\t\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR) {\n\t\t\tif (scqe_sz == 128)\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA64_CQE);\n\t\t\telse\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA32_CQE);\n\t\t}\n\t}\n\n\tif (qp->rq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);\n\t\tMLX5_SET(qpc, qpc, log_rq_size, ilog2(qp->rq.wqe_cnt));\n\t}\n\n\tMLX5_SET(qpc, qpc, rq_type, get_rx_type(qp, init_attr));\n\n\tif (qp->sq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_sq_size, ilog2(qp->sq.wqe_cnt));\n\t} else {\n\t\tMLX5_SET(qpc, qpc, no_sq, 1);\n\t\tif (init_attr->srq &&\n\t\t    init_attr->srq->srq_type == IB_SRQT_TM)\n\t\t\tMLX5_SET(qpc, qpc, offload_type,\n\t\t\t\t MLX5_QPC_OFFLOAD_TYPE_RNDV);\n\t}\n\n\t/* Set default resources */\n\tswitch (init_attr->qp_type) {\n\tcase IB_QPT_XRC_TGT:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(init_attr->xrcd)->xrcdn);\n\t\tbreak;\n\tcase IB_QPT_XRC_INI:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tbreak;\n\tdefault:\n\t\tif (init_attr->srq) {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x0)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(init_attr->srq)->msrq.srqn);\n\t\t} else {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s1)->msrq.srqn);\n\t\t}\n\t}\n\n\tif (init_attr->send_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(init_attr->send_cq)->mcq.cqn);\n\n\tif (init_attr->recv_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(init_attr->recv_cq)->mcq.cqn);\n\n\tMLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);\n\n\t/* 0xffffff means we ask to work with cqe version 0 */\n\tif (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)\n\t\tMLX5_SET(qpc, qpc, user_index, uidx);\n\n\t/* we use IB_QP_CREATE_IPOIB_UD_LSO to indicates ipoib qp */\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO)) {\n\t\tMLX5_SET(qpc, qpc, ulp_stateless_offload_mode, 1);\n\t\tqp->flags |= MLX5_IB_QP_LSO;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_PCI_WRITE_END_PADDING) {\n\t\tif (!MLX5_CAP_GEN(dev->mdev, end_pad)) {\n\t\t\tmlx5_ib_dbg(dev, \"scatter end padding is not supported\\n\");\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto err;\n\t\t} else if (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tMLX5_SET(qpc, qpc, end_padding_mode,\n\t\t\t\t MLX5_WQ_END_PAD_MODE_ALIGN);\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_PCI_WRITE_END_PADDING;\n\t\t}\n\t}\n\n\tif (inlen < 0) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t    qp->flags & MLX5_IB_QP_UNDERLAY) {\n\t\tqp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd.sq_buf_addr;\n\t\traw_packet_qp_copy_info(qp, &qp->raw_packet_qp);\n\t\terr = create_raw_packet_qp(dev, qp, in, inlen, pd);\n\t} else {\n\t\terr = mlx5_core_create_qp(dev->mdev, &base->mqp, in, inlen);\n\t}\n\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"create qp failed\\n\");\n\t\tgoto err_create;\n\t}\n\n\tkvfree(in);\n\n\tbase->container_mibqp = qp;\n\tbase->mqp.event = mlx5_ib_qp_event;\n\n\tget_cqs(init_attr->qp_type, init_attr->send_cq, init_attr->recv_cq,\n\t\t&send_cq, &recv_cq);\n\tspin_lock_irqsave(&dev->reset_flow_resource_lock, flags);\n\tmlx5_ib_lock_cqs(send_cq, recv_cq);\n\t/* Maintain device to QPs access, needed for further handling via reset\n\t * flow\n\t */\n\tlist_add_tail(&qp->qps_list, &dev->qp_list);\n\t/* Maintain CQ to QPs access, needed for further handling via reset flow\n\t */\n\tif (send_cq)\n\t\tlist_add_tail(&qp->cq_send_list, &send_cq->list_send_qp);\n\tif (recv_cq)\n\t\tlist_add_tail(&qp->cq_recv_list, &recv_cq->list_recv_qp);\n\tmlx5_ib_unlock_cqs(send_cq, recv_cq);\n\tspin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);\n\n\treturn 0;\n\nerr_create:\n\tif (qp->create_type == MLX5_QP_USER)\n\t\tdestroy_qp_user(dev, pd, qp, base);\n\telse if (qp->create_type == MLX5_QP_KERNEL)\n\t\tdestroy_qp_kernel(dev, qp);\n\nerr:\n\tkvfree(in);\n\treturn err;\n}",
      "code_after_change": "static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,\n\t\t\t    struct ib_qp_init_attr *init_attr,\n\t\t\t    struct ib_udata *udata, struct mlx5_ib_qp *qp)\n{\n\tstruct mlx5_ib_resources *devr = &dev->devr;\n\tint inlen = MLX5_ST_SZ_BYTES(create_qp_in);\n\tstruct mlx5_core_dev *mdev = dev->mdev;\n\tstruct mlx5_ib_create_qp_resp resp = {};\n\tstruct mlx5_ib_cq *send_cq;\n\tstruct mlx5_ib_cq *recv_cq;\n\tunsigned long flags;\n\tu32 uidx = MLX5_IB_DEFAULT_UIDX;\n\tstruct mlx5_ib_create_qp ucmd;\n\tstruct mlx5_ib_qp_base *base;\n\tint mlx5_st;\n\tvoid *qpc;\n\tu32 *in;\n\tint err;\n\n\tmutex_init(&qp->mutex);\n\tspin_lock_init(&qp->sq.lock);\n\tspin_lock_init(&qp->rq.lock);\n\n\tmlx5_st = to_mlx5_st(init_attr->qp_type);\n\tif (mlx5_st < 0)\n\t\treturn -EINVAL;\n\n\tif (init_attr->rwq_ind_tbl) {\n\t\tif (!udata)\n\t\t\treturn -ENOSYS;\n\n\t\terr = create_rss_raw_qp_tir(dev, qp, pd, init_attr, udata);\n\t\treturn err;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK) {\n\t\tif (!MLX5_CAP_GEN(mdev, block_lb_mc)) {\n\t\t\tmlx5_ib_dbg(dev, \"block multicast loopback isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK;\n\t\t}\n\t}\n\n\tif (init_attr->create_flags &\n\t\t\t(IB_QP_CREATE_CROSS_CHANNEL |\n\t\t\t IB_QP_CREATE_MANAGED_SEND |\n\t\t\t IB_QP_CREATE_MANAGED_RECV)) {\n\t\tif (!MLX5_CAP_GEN(mdev, cd)) {\n\t\t\tmlx5_ib_dbg(dev, \"cross-channel isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (init_attr->create_flags & IB_QP_CREATE_CROSS_CHANNEL)\n\t\t\tqp->flags |= MLX5_IB_QP_CROSS_CHANNEL;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_SEND)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_SEND;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_RECV)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_RECV;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO))\n\t\tif (!MLX5_CAP_GEN(mdev, ipoib_basic_offloads)) {\n\t\t\tmlx5_ib_dbg(dev, \"ipoib UD lso qp isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_SCATTER_FCS) {\n\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS is supported only for Raw Packet QPs\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (!MLX5_CAP_GEN(dev->mdev, eth_net_offloads) ||\n\t\t    !MLX5_CAP_ETH(dev->mdev, scatter_fcs)) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tqp->flags |= MLX5_IB_QP_CAP_SCATTER_FCS;\n\t}\n\n\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)\n\t\tqp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;\n\n\tif (init_attr->create_flags & IB_QP_CREATE_CVLAN_STRIPPING) {\n\t\tif (!(MLX5_CAP_GEN(dev->mdev, eth_net_offloads) &&\n\t\t      MLX5_CAP_ETH(dev->mdev, vlan_cap)) ||\n\t\t    (init_attr->qp_type != IB_QPT_RAW_PACKET))\n\t\t\treturn -EOPNOTSUPP;\n\t\tqp->flags |= MLX5_IB_QP_CVLAN_STRIPPING;\n\t}\n\n\tif (pd && pd->uobject) {\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {\n\t\t\tmlx5_ib_dbg(dev, \"copy failed\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\terr = get_qp_user_index(to_mucontext(pd->uobject->context),\n\t\t\t\t\t&ucmd, udata->inlen, &uidx);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tqp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);\n\t\tqp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);\n\t\tif (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {\n\t\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET ||\n\t\t\t    !tunnel_offload_supported(mdev)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Tunnel offload isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t\tqp->tunnel_offload_en = true;\n\t\t}\n\n\t\tif (init_attr->create_flags & IB_QP_CREATE_SOURCE_QPN) {\n\t\t\tif (init_attr->qp_type != IB_QPT_UD ||\n\t\t\t    (MLX5_CAP_GEN(dev->mdev, port_type) !=\n\t\t\t     MLX5_CAP_PORT_TYPE_IB) ||\n\t\t\t    !mlx5_get_flow_namespace(dev->mdev, MLX5_FLOW_NAMESPACE_BYPASS)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Source QP option isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\tqp->flags |= MLX5_IB_QP_UNDERLAY;\n\t\t\tqp->underlay_qpn = init_attr->source_qpn;\n\t\t}\n\t} else {\n\t\tqp->wq_sig = !!wq_signature;\n\t}\n\n\tbase = (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t\tqp->flags & MLX5_IB_QP_UNDERLAY) ?\n\t       &qp->raw_packet_qp.rq.base :\n\t       &qp->trans_qp.base;\n\n\tqp->has_rq = qp_has_rq(init_attr);\n\terr = set_rq_size(dev, &init_attr->cap, qp->has_rq,\n\t\t\t  qp, (pd && pd->uobject) ? &ucmd : NULL);\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tif (pd) {\n\t\tif (pd->uobject) {\n\t\t\t__u32 max_wqes =\n\t\t\t\t1 << MLX5_CAP_GEN(mdev, log_max_qp_sz);\n\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d)\\n\", ucmd.sq_wqe_count);\n\t\t\tif (ucmd.rq_wqe_shift != qp->rq.wqe_shift ||\n\t\t\t    ucmd.rq_wqe_count != qp->rq.wqe_cnt) {\n\t\t\t\tmlx5_ib_dbg(dev, \"invalid rq params\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (ucmd.sq_wqe_count > max_wqes) {\n\t\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d) > max allowed (%d)\\n\",\n\t\t\t\t\t    ucmd.sq_wqe_count, max_wqes);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (init_attr->create_flags &\n\t\t\t    mlx5_ib_create_qp_sqpn_qp1()) {\n\t\t\t\tmlx5_ib_dbg(dev, \"user-space is not allowed to create UD QPs spoofing as QP1\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\terr = create_user_qp(dev, pd, qp, udata, init_attr, &in,\n\t\t\t\t\t     &resp, &inlen, base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t} else {\n\t\t\terr = create_kernel_qp(dev, init_attr, qp, &in, &inlen,\n\t\t\t\t\t       base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t}\n\n\t\tif (err)\n\t\t\treturn err;\n\t} else {\n\t\tin = kvzalloc(inlen, GFP_KERNEL);\n\t\tif (!in)\n\t\t\treturn -ENOMEM;\n\n\t\tqp->create_type = MLX5_QP_EMPTY;\n\t}\n\n\tif (is_sqp(init_attr->qp_type))\n\t\tqp->port = init_attr->port_num;\n\n\tqpc = MLX5_ADDR_OF(create_qp_in, in, qpc);\n\n\tMLX5_SET(qpc, qpc, st, mlx5_st);\n\tMLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);\n\n\tif (init_attr->qp_type != MLX5_IB_QPT_REG_UMR)\n\t\tMLX5_SET(qpc, qpc, pd, to_mpd(pd ? pd : devr->p0)->pdn);\n\telse\n\t\tMLX5_SET(qpc, qpc, latency_sensitive, 1);\n\n\n\tif (qp->wq_sig)\n\t\tMLX5_SET(qpc, qpc, wq_signature, 1);\n\n\tif (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)\n\t\tMLX5_SET(qpc, qpc, block_lb_mc, 1);\n\n\tif (qp->flags & MLX5_IB_QP_CROSS_CHANNEL)\n\t\tMLX5_SET(qpc, qpc, cd_master, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_SEND)\n\t\tMLX5_SET(qpc, qpc, cd_slave_send, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_RECV)\n\t\tMLX5_SET(qpc, qpc, cd_slave_receive, 1);\n\n\tif (qp->scat_cqe && is_connected(init_attr->qp_type)) {\n\t\tint rcqe_sz;\n\t\tint scqe_sz;\n\n\t\trcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);\n\t\tscqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);\n\n\t\tif (rcqe_sz == 128)\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA64_CQE);\n\t\telse\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA32_CQE);\n\n\t\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR) {\n\t\t\tif (scqe_sz == 128)\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA64_CQE);\n\t\t\telse\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA32_CQE);\n\t\t}\n\t}\n\n\tif (qp->rq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);\n\t\tMLX5_SET(qpc, qpc, log_rq_size, ilog2(qp->rq.wqe_cnt));\n\t}\n\n\tMLX5_SET(qpc, qpc, rq_type, get_rx_type(qp, init_attr));\n\n\tif (qp->sq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_sq_size, ilog2(qp->sq.wqe_cnt));\n\t} else {\n\t\tMLX5_SET(qpc, qpc, no_sq, 1);\n\t\tif (init_attr->srq &&\n\t\t    init_attr->srq->srq_type == IB_SRQT_TM)\n\t\t\tMLX5_SET(qpc, qpc, offload_type,\n\t\t\t\t MLX5_QPC_OFFLOAD_TYPE_RNDV);\n\t}\n\n\t/* Set default resources */\n\tswitch (init_attr->qp_type) {\n\tcase IB_QPT_XRC_TGT:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(init_attr->xrcd)->xrcdn);\n\t\tbreak;\n\tcase IB_QPT_XRC_INI:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tbreak;\n\tdefault:\n\t\tif (init_attr->srq) {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x0)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(init_attr->srq)->msrq.srqn);\n\t\t} else {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s1)->msrq.srqn);\n\t\t}\n\t}\n\n\tif (init_attr->send_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(init_attr->send_cq)->mcq.cqn);\n\n\tif (init_attr->recv_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(init_attr->recv_cq)->mcq.cqn);\n\n\tMLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);\n\n\t/* 0xffffff means we ask to work with cqe version 0 */\n\tif (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)\n\t\tMLX5_SET(qpc, qpc, user_index, uidx);\n\n\t/* we use IB_QP_CREATE_IPOIB_UD_LSO to indicates ipoib qp */\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO)) {\n\t\tMLX5_SET(qpc, qpc, ulp_stateless_offload_mode, 1);\n\t\tqp->flags |= MLX5_IB_QP_LSO;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_PCI_WRITE_END_PADDING) {\n\t\tif (!MLX5_CAP_GEN(dev->mdev, end_pad)) {\n\t\t\tmlx5_ib_dbg(dev, \"scatter end padding is not supported\\n\");\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto err;\n\t\t} else if (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tMLX5_SET(qpc, qpc, end_padding_mode,\n\t\t\t\t MLX5_WQ_END_PAD_MODE_ALIGN);\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_PCI_WRITE_END_PADDING;\n\t\t}\n\t}\n\n\tif (inlen < 0) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t    qp->flags & MLX5_IB_QP_UNDERLAY) {\n\t\tqp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd.sq_buf_addr;\n\t\traw_packet_qp_copy_info(qp, &qp->raw_packet_qp);\n\t\terr = create_raw_packet_qp(dev, qp, in, inlen, pd);\n\t} else {\n\t\terr = mlx5_core_create_qp(dev->mdev, &base->mqp, in, inlen);\n\t}\n\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"create qp failed\\n\");\n\t\tgoto err_create;\n\t}\n\n\tkvfree(in);\n\n\tbase->container_mibqp = qp;\n\tbase->mqp.event = mlx5_ib_qp_event;\n\n\tget_cqs(init_attr->qp_type, init_attr->send_cq, init_attr->recv_cq,\n\t\t&send_cq, &recv_cq);\n\tspin_lock_irqsave(&dev->reset_flow_resource_lock, flags);\n\tmlx5_ib_lock_cqs(send_cq, recv_cq);\n\t/* Maintain device to QPs access, needed for further handling via reset\n\t * flow\n\t */\n\tlist_add_tail(&qp->qps_list, &dev->qp_list);\n\t/* Maintain CQ to QPs access, needed for further handling via reset flow\n\t */\n\tif (send_cq)\n\t\tlist_add_tail(&qp->cq_send_list, &send_cq->list_send_qp);\n\tif (recv_cq)\n\t\tlist_add_tail(&qp->cq_recv_list, &recv_cq->list_recv_qp);\n\tmlx5_ib_unlock_cqs(send_cq, recv_cq);\n\tspin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);\n\n\treturn 0;\n\nerr_create:\n\tif (qp->create_type == MLX5_QP_USER)\n\t\tdestroy_qp_user(dev, pd, qp, base);\n\telse if (qp->create_type == MLX5_QP_KERNEL)\n\t\tdestroy_qp_kernel(dev, qp);\n\nerr:\n\tkvfree(in);\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\tstruct mlx5_ib_create_qp_resp resp = {};"
        ],
        "deleted": [
          "\tstruct mlx5_ib_create_qp_resp resp;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper initialization of a struct variable in a function.",
      "trigger_condition": "The uninitialized struct variable is used without being properly initialized, leading to a memory leak of stack data to userspace.",
      "specific_code_behavior_causing_vulnerability": "The code does not initialize a specific struct variable of type struct mlx5_ib_create_qp_resp, resulting in a memory leak of stack data to userspace when the uninitialized variable is used.",
      "id": 137,
      "code_after_change_normalized": "static int FUN1(struct mlx5_ib_dev *VAR1, struct ib_pd *VAR2,\nstruct ib_qp_init_attr *VAR3,\nstruct ib_udata *VAR4, struct mlx5_ib_qp *VAR5)\n{\nstruct mlx5_ib_resources *VAR6 = &VAR1->VAR6;\nint VAR7 = FUN2(VAR8);\nstruct mlx5_core_dev *VAR9 = VAR1->VAR9;\nstruct mlx5_ib_create_qp_resp VAR10 = {};\nstruct mlx5_ib_cq *VAR11;\nstruct mlx5_ib_cq *VAR12;\nunsigned long VAR13;\nu32 VAR14 = VAR15;\nstruct mlx5_ib_create_qp VAR16;\nstruct mlx5_ib_qp_base *VAR17;\nint VAR18;\nvoid *VAR19;\nu32 *VAR20;\nint VAR21;\nFUN3(&VAR5->VAR22);\nFUN4(&VAR5->VAR23.VAR24);\nFUN4(&VAR5->VAR25.VAR24);\nVAR18 = FUN5(VAR3->VAR26);\nif (VAR18 < 0)\nreturn -VAR27;\nif (VAR3->VAR28) {\nif (!VAR4)\nreturn -VAR29;\nVAR21 = FUN6(VAR1, VAR5, VAR2, VAR3, VAR4);\nreturn VAR21;\n}\nif (VAR3->VAR30 & VAR31) {\nif (!FUN7(VAR9, VAR32)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n} else {\nVAR5->VAR13 |= VAR33;\n}\n}\nif (VAR3->VAR30 &\n(VAR34 |\nVAR35 |\nVAR36)) {\nif (!FUN7(VAR9, VAR37)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n}\nif (VAR3->VAR30 & VAR34)\nVAR5->VAR13 |= VAR38;\nif (VAR3->VAR30 & VAR35)\nVAR5->VAR13 |= VAR39;\nif (VAR3->VAR30 & VAR36)\nVAR5->VAR13 |= VAR40;\n}\nif (VAR3->VAR26 == VAR41 &&\n(VAR3->VAR30 & VAR42))\nif (!FUN7(VAR9, VAR43)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nif (VAR3->VAR30 & VAR45) {\nif (VAR3->VAR26 != VAR46) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nif (!FUN7(VAR1->VAR9, VAR47) ||\n!FUN9(VAR1->VAR9, VAR48)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nVAR5->VAR13 |= VAR49;\n}\nif (VAR3->VAR50 == VAR51)\nVAR5->VAR52 = VAR53;\nif (VAR3->VAR30 & VAR54) {\nif (!(FUN7(VAR1->VAR9, VAR47) &&\nFUN9(VAR1->VAR9, VAR55)) ||\n(VAR3->VAR26 != VAR46))\nreturn -VAR44;\nVAR5->VAR13 |= VAR56;\n}\nif (VAR2 && VAR2->VAR57) {\nif (FUN10(&VAR16, VAR4, sizeof(VAR16))) {\nFUN8(VAR1, \"STR\");\nreturn -VAR58;\n}\nVAR21 = FUN11(FUN12(VAR2->VAR57->VAR59),\n&VAR16, VAR4->VAR7, &VAR14);\nif (VAR21)\nreturn VAR21;\nVAR5->VAR60 = !!(VAR16.VAR13 & VAR61);\nVAR5->VAR62 = !!(VAR16.VAR13 & VAR63);\nif (VAR16.VAR13 & VAR64) {\nif (VAR3->VAR26 != VAR46 ||\n!FUN13(VAR9)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nVAR5->VAR65 = true;\n}\nif (VAR3->VAR30 & VAR66) {\nif (VAR3->VAR26 != VAR41 ||\n(FUN7(VAR1->VAR9, VAR67) !=\nVAR68) ||\n!FUN14(VAR1->VAR9, VAR69)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nVAR5->VAR13 |= VAR70;\nVAR5->VAR71 = VAR3->VAR72;\n}\n} else {\nVAR5->VAR60 = !!VAR73;\n}\nVAR17 = (VAR3->VAR26 == VAR46 ||\nVAR5->VAR13 & VAR70) ?\n&VAR5->VAR74.VAR25.VAR17 :\n&VAR5->VAR75.VAR17;\nVAR5->VAR76 = FUN15(VAR3);\nVAR21 = FUN16(VAR1, &VAR3->VAR77, VAR5->VAR76,\nVAR5, (VAR2 && VAR2->VAR57) ? &VAR16 : NULL);\nif (VAR21) {\nFUN8(VAR1, \"STR\", VAR21);\nreturn VAR21;\n}\nif (VAR2) {\nif (VAR2->VAR57) {\n__u32 VAR78 =\n1 << FUN7(VAR9, VAR79);\nFUN8(VAR1, \"STR\", VAR16.VAR80);\nif (VAR16.VAR81 != VAR5->VAR25.VAR82 ||\nVAR16.VAR83 != VAR5->VAR25.VAR84) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n}\nif (VAR16.VAR80 > VAR78) {\nFUN8(VAR1, \"STR\",\nVAR16.VAR80, VAR78);\nreturn -VAR27;\n}\nif (VAR3->VAR30 &\nFUN17()) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n}\nVAR21 = FUN18(VAR1, VAR2, VAR5, VAR4, VAR3, &VAR20,\n&VAR10, &VAR7, VAR17);\nif (VAR21)\nFUN8(VAR1, \"STR\", VAR21);\n} else {\nVAR21 = FUN19(VAR1, VAR3, VAR5, &VAR20, &VAR7,\nVAR17);\nif (VAR21)\nFUN8(VAR1, \"STR\", VAR21);\n}\nif (VAR21)\nreturn VAR21;\n} else {\nVAR20 = FUN20(VAR7, VAR85);\nif (!VAR20)\nreturn -VAR86;\nVAR5->VAR87 = VAR88;\n}\nif (FUN21(VAR3->VAR26))\nVAR5->VAR89 = VAR3->VAR90;\nVAR19 = FUN22(VAR8, VAR20, VAR19);\nFUN23(VAR19, VAR19, VAR91, VAR18);\nFUN23(VAR19, VAR19, VAR92, VAR93);\nif (VAR3->VAR26 != VAR94)\nFUN23(VAR19, VAR19, VAR2, FUN24(VAR2 ? VAR2 : VAR6->VAR95)->VAR96);\nelse\nFUN23(VAR19, VAR19, VAR97, 1);\nif (VAR5->VAR60)\nFUN23(VAR19, VAR19, VAR73, 1);\nif (VAR5->VAR13 & VAR33)\nFUN23(VAR19, VAR19, VAR32, 1);\nif (VAR5->VAR13 & VAR38)\nFUN23(VAR19, VAR19, VAR98, 1);\nif (VAR5->VAR13 & VAR39)\nFUN23(VAR19, VAR19, VAR99, 1);\nif (VAR5->VAR13 & VAR40)\nFUN23(VAR19, VAR19, VAR100, 1);\nif (VAR5->VAR62 && FUN25(VAR3->VAR26)) {\nint VAR101;\nint VAR102;\nVAR101 = FUN26(VAR1, VAR3->VAR12);\nVAR102 = FUN26(VAR1, VAR3->VAR11);\nif (VAR101 == 128)\nFUN23(VAR19, VAR19, VAR103, VAR104);\nelse\nFUN23(VAR19, VAR19, VAR103, VAR105);\nif (VAR3->VAR50 == VAR51) {\nif (VAR102 == 128)\nFUN23(VAR19, VAR19, VAR106, VAR107);\nelse\nFUN23(VAR19, VAR19, VAR106, VAR108);\n}\n}\nif (VAR5->VAR25.VAR84) {\nFUN23(VAR19, VAR19, VAR109, VAR5->VAR25.VAR82 - 4);\nFUN23(VAR19, VAR19, VAR110, FUN27(VAR5->VAR25.VAR84));\n}\nFUN23(VAR19, VAR19, VAR111, FUN28(VAR5, VAR3));\nif (VAR5->VAR23.VAR84) {\nFUN23(VAR19, VAR19, VAR112, FUN27(VAR5->VAR23.VAR84));\n} else {\nFUN23(VAR19, VAR19, VAR113, 1);\nif (VAR3->VAR114 &&\nVAR3->VAR114->VAR115 == VAR116)\nFUN23(VAR19, VAR19, VAR117,\nVAR118);\n}\nswitch (VAR3->VAR26) {\ncase VAR119:\nFUN23(VAR19, VAR19, VAR120, FUN29(VAR6->VAR121)->VAR122.VAR123);\nFUN23(VAR19, VAR19, VAR124, FUN29(VAR6->VAR121)->VAR122.VAR123);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR6->VAR126)->VAR127.VAR128);\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR3->VAR129)->VAR130);\nbreak;\ncase VAR131:\nFUN23(VAR19, VAR19, VAR120, FUN29(VAR6->VAR121)->VAR122.VAR123);\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR6->VAR132)->VAR130);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR6->VAR126)->VAR127.VAR128);\nbreak;\ndefault:\nif (VAR3->VAR114) {\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR6->VAR133)->VAR130);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR3->VAR114)->VAR127.VAR128);\n} else {\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR6->VAR132)->VAR130);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR6->VAR134)->VAR127.VAR128);\n}\n}\nif (VAR3->VAR11)\nFUN23(VAR19, VAR19, VAR124, FUN29(VAR3->VAR11)->VAR122.VAR123);\nif (VAR3->VAR12)\nFUN23(VAR19, VAR19, VAR120, FUN29(VAR3->VAR12)->VAR122.VAR123);\nFUN32(VAR19, VAR19, VAR135, VAR5->VAR136.VAR137);\nif (FUN7(VAR9, VAR138) == VAR139)\nFUN23(VAR19, VAR19, VAR140, VAR14);\nif (VAR3->VAR26 == VAR41 &&\n(VAR3->VAR30 & VAR42)) {\nFUN23(VAR19, VAR19, VAR141, 1);\nVAR5->VAR13 |= VAR142;\n}\nif (VAR3->VAR30 & VAR143) {\nif (!FUN7(VAR1->VAR9, VAR144)) {\nFUN8(VAR1, \"STR\");\nVAR21 = -VAR44;\ngoto VAR21;\n} else if (VAR3->VAR26 != VAR46) {\nFUN23(VAR19, VAR19, VAR145,\nVAR146);\n} else {\nVAR5->VAR13 |= VAR147;\n}\n}\nif (VAR7 < 0) {\nVAR21 = -VAR27;\ngoto VAR21;\n}\nif (VAR3->VAR26 == VAR46 ||\nVAR5->VAR13 & VAR70) {\nVAR5->VAR74.VAR23.VAR148.VAR149 = VAR16.VAR150;\nFUN33(VAR5, &VAR5->VAR74);\nVAR21 = FUN34(VAR1, VAR5, VAR20, VAR7, VAR2);\n} else {\nVAR21 = FUN35(VAR1->VAR9, &VAR17->VAR151, VAR20, VAR7);\n}\nif (VAR21) {\nFUN8(VAR1, \"STR\");\ngoto VAR152;\n}\nFUN36(VAR20);\nVAR17->VAR153 = VAR5;\nVAR17->VAR151.VAR154 = VAR155;\nFUN37(VAR3->VAR26, VAR3->VAR11, VAR3->VAR12,\n&VAR11, &VAR12);\nFUN38(&VAR1->VAR156, VAR13);\nFUN39(VAR11, VAR12);\nFUN40(&VAR5->VAR157, &VAR1->VAR158);\nif (VAR11)\nFUN40(&VAR5->VAR159, &VAR11->VAR160);\nif (VAR12)\nFUN40(&VAR5->VAR161, &VAR12->VAR162);\nFUN41(VAR11, VAR12);\nFUN42(&VAR1->VAR156, VAR13);\nreturn 0;\nVAR152:\nif (VAR5->VAR87 == VAR163)\nFUN43(VAR1, VAR2, VAR5, VAR17);\nelse if (VAR5->VAR87 == VAR164)\nFUN44(VAR1, VAR5);\nVAR21:\nFUN36(VAR20);\nreturn VAR21;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct mlx5_ib_dev *VAR1, struct ib_pd *VAR2,\nstruct ib_qp_init_attr *VAR3,\nstruct ib_udata *VAR4, struct mlx5_ib_qp *VAR5)\n{\nstruct mlx5_ib_resources *VAR6 = &VAR1->VAR6;\nint VAR7 = FUN2(VAR8);\nstruct mlx5_core_dev *VAR9 = VAR1->VAR9;\nstruct mlx5_ib_create_qp_resp VAR10;\nstruct mlx5_ib_cq *VAR11;\nstruct mlx5_ib_cq *VAR12;\nunsigned long VAR13;\nu32 VAR14 = VAR15;\nstruct mlx5_ib_create_qp VAR16;\nstruct mlx5_ib_qp_base *VAR17;\nint VAR18;\nvoid *VAR19;\nu32 *VAR20;\nint VAR21;\nFUN3(&VAR5->VAR22);\nFUN4(&VAR5->VAR23.VAR24);\nFUN4(&VAR5->VAR25.VAR24);\nVAR18 = FUN5(VAR3->VAR26);\nif (VAR18 < 0)\nreturn -VAR27;\nif (VAR3->VAR28) {\nif (!VAR4)\nreturn -VAR29;\nVAR21 = FUN6(VAR1, VAR5, VAR2, VAR3, VAR4);\nreturn VAR21;\n}\nif (VAR3->VAR30 & VAR31) {\nif (!FUN7(VAR9, VAR32)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n} else {\nVAR5->VAR13 |= VAR33;\n}\n}\nif (VAR3->VAR30 &\n(VAR34 |\nVAR35 |\nVAR36)) {\nif (!FUN7(VAR9, VAR37)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n}\nif (VAR3->VAR30 & VAR34)\nVAR5->VAR13 |= VAR38;\nif (VAR3->VAR30 & VAR35)\nVAR5->VAR13 |= VAR39;\nif (VAR3->VAR30 & VAR36)\nVAR5->VAR13 |= VAR40;\n}\nif (VAR3->VAR26 == VAR41 &&\n(VAR3->VAR30 & VAR42))\nif (!FUN7(VAR9, VAR43)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nif (VAR3->VAR30 & VAR45) {\nif (VAR3->VAR26 != VAR46) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nif (!FUN7(VAR1->VAR9, VAR47) ||\n!FUN9(VAR1->VAR9, VAR48)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nVAR5->VAR13 |= VAR49;\n}\nif (VAR3->VAR50 == VAR51)\nVAR5->VAR52 = VAR53;\nif (VAR3->VAR30 & VAR54) {\nif (!(FUN7(VAR1->VAR9, VAR47) &&\nFUN9(VAR1->VAR9, VAR55)) ||\n(VAR3->VAR26 != VAR46))\nreturn -VAR44;\nVAR5->VAR13 |= VAR56;\n}\nif (VAR2 && VAR2->VAR57) {\nif (FUN10(&VAR16, VAR4, sizeof(VAR16))) {\nFUN8(VAR1, \"STR\");\nreturn -VAR58;\n}\nVAR21 = FUN11(FUN12(VAR2->VAR57->VAR59),\n&VAR16, VAR4->VAR7, &VAR14);\nif (VAR21)\nreturn VAR21;\nVAR5->VAR60 = !!(VAR16.VAR13 & VAR61);\nVAR5->VAR62 = !!(VAR16.VAR13 & VAR63);\nif (VAR16.VAR13 & VAR64) {\nif (VAR3->VAR26 != VAR46 ||\n!FUN13(VAR9)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nVAR5->VAR65 = true;\n}\nif (VAR3->VAR30 & VAR66) {\nif (VAR3->VAR26 != VAR41 ||\n(FUN7(VAR1->VAR9, VAR67) !=\nVAR68) ||\n!FUN14(VAR1->VAR9, VAR69)) {\nFUN8(VAR1, \"STR\");\nreturn -VAR44;\n}\nVAR5->VAR13 |= VAR70;\nVAR5->VAR71 = VAR3->VAR72;\n}\n} else {\nVAR5->VAR60 = !!VAR73;\n}\nVAR17 = (VAR3->VAR26 == VAR46 ||\nVAR5->VAR13 & VAR70) ?\n&VAR5->VAR74.VAR25.VAR17 :\n&VAR5->VAR75.VAR17;\nVAR5->VAR76 = FUN15(VAR3);\nVAR21 = FUN16(VAR1, &VAR3->VAR77, VAR5->VAR76,\nVAR5, (VAR2 && VAR2->VAR57) ? &VAR16 : NULL);\nif (VAR21) {\nFUN8(VAR1, \"STR\", VAR21);\nreturn VAR21;\n}\nif (VAR2) {\nif (VAR2->VAR57) {\n__u32 VAR78 =\n1 << FUN7(VAR9, VAR79);\nFUN8(VAR1, \"STR\", VAR16.VAR80);\nif (VAR16.VAR81 != VAR5->VAR25.VAR82 ||\nVAR16.VAR83 != VAR5->VAR25.VAR84) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n}\nif (VAR16.VAR80 > VAR78) {\nFUN8(VAR1, \"STR\",\nVAR16.VAR80, VAR78);\nreturn -VAR27;\n}\nif (VAR3->VAR30 &\nFUN17()) {\nFUN8(VAR1, \"STR\");\nreturn -VAR27;\n}\nVAR21 = FUN18(VAR1, VAR2, VAR5, VAR4, VAR3, &VAR20,\n&VAR10, &VAR7, VAR17);\nif (VAR21)\nFUN8(VAR1, \"STR\", VAR21);\n} else {\nVAR21 = FUN19(VAR1, VAR3, VAR5, &VAR20, &VAR7,\nVAR17);\nif (VAR21)\nFUN8(VAR1, \"STR\", VAR21);\n}\nif (VAR21)\nreturn VAR21;\n} else {\nVAR20 = FUN20(VAR7, VAR85);\nif (!VAR20)\nreturn -VAR86;\nVAR5->VAR87 = VAR88;\n}\nif (FUN21(VAR3->VAR26))\nVAR5->VAR89 = VAR3->VAR90;\nVAR19 = FUN22(VAR8, VAR20, VAR19);\nFUN23(VAR19, VAR19, VAR91, VAR18);\nFUN23(VAR19, VAR19, VAR92, VAR93);\nif (VAR3->VAR26 != VAR94)\nFUN23(VAR19, VAR19, VAR2, FUN24(VAR2 ? VAR2 : VAR6->VAR95)->VAR96);\nelse\nFUN23(VAR19, VAR19, VAR97, 1);\nif (VAR5->VAR60)\nFUN23(VAR19, VAR19, VAR73, 1);\nif (VAR5->VAR13 & VAR33)\nFUN23(VAR19, VAR19, VAR32, 1);\nif (VAR5->VAR13 & VAR38)\nFUN23(VAR19, VAR19, VAR98, 1);\nif (VAR5->VAR13 & VAR39)\nFUN23(VAR19, VAR19, VAR99, 1);\nif (VAR5->VAR13 & VAR40)\nFUN23(VAR19, VAR19, VAR100, 1);\nif (VAR5->VAR62 && FUN25(VAR3->VAR26)) {\nint VAR101;\nint VAR102;\nVAR101 = FUN26(VAR1, VAR3->VAR12);\nVAR102 = FUN26(VAR1, VAR3->VAR11);\nif (VAR101 == 128)\nFUN23(VAR19, VAR19, VAR103, VAR104);\nelse\nFUN23(VAR19, VAR19, VAR103, VAR105);\nif (VAR3->VAR50 == VAR51) {\nif (VAR102 == 128)\nFUN23(VAR19, VAR19, VAR106, VAR107);\nelse\nFUN23(VAR19, VAR19, VAR106, VAR108);\n}\n}\nif (VAR5->VAR25.VAR84) {\nFUN23(VAR19, VAR19, VAR109, VAR5->VAR25.VAR82 - 4);\nFUN23(VAR19, VAR19, VAR110, FUN27(VAR5->VAR25.VAR84));\n}\nFUN23(VAR19, VAR19, VAR111, FUN28(VAR5, VAR3));\nif (VAR5->VAR23.VAR84) {\nFUN23(VAR19, VAR19, VAR112, FUN27(VAR5->VAR23.VAR84));\n} else {\nFUN23(VAR19, VAR19, VAR113, 1);\nif (VAR3->VAR114 &&\nVAR3->VAR114->VAR115 == VAR116)\nFUN23(VAR19, VAR19, VAR117,\nVAR118);\n}\nswitch (VAR3->VAR26) {\ncase VAR119:\nFUN23(VAR19, VAR19, VAR120, FUN29(VAR6->VAR121)->VAR122.VAR123);\nFUN23(VAR19, VAR19, VAR124, FUN29(VAR6->VAR121)->VAR122.VAR123);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR6->VAR126)->VAR127.VAR128);\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR3->VAR129)->VAR130);\nbreak;\ncase VAR131:\nFUN23(VAR19, VAR19, VAR120, FUN29(VAR6->VAR121)->VAR122.VAR123);\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR6->VAR132)->VAR130);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR6->VAR126)->VAR127.VAR128);\nbreak;\ndefault:\nif (VAR3->VAR114) {\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR6->VAR133)->VAR130);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR3->VAR114)->VAR127.VAR128);\n} else {\nFUN23(VAR19, VAR19, VAR129, FUN31(VAR6->VAR132)->VAR130);\nFUN23(VAR19, VAR19, VAR125, FUN30(VAR6->VAR134)->VAR127.VAR128);\n}\n}\nif (VAR3->VAR11)\nFUN23(VAR19, VAR19, VAR124, FUN29(VAR3->VAR11)->VAR122.VAR123);\nif (VAR3->VAR12)\nFUN23(VAR19, VAR19, VAR120, FUN29(VAR3->VAR12)->VAR122.VAR123);\nFUN32(VAR19, VAR19, VAR135, VAR5->VAR136.VAR137);\nif (FUN7(VAR9, VAR138) == VAR139)\nFUN23(VAR19, VAR19, VAR140, VAR14);\nif (VAR3->VAR26 == VAR41 &&\n(VAR3->VAR30 & VAR42)) {\nFUN23(VAR19, VAR19, VAR141, 1);\nVAR5->VAR13 |= VAR142;\n}\nif (VAR3->VAR30 & VAR143) {\nif (!FUN7(VAR1->VAR9, VAR144)) {\nFUN8(VAR1, \"STR\");\nVAR21 = -VAR44;\ngoto VAR21;\n} else if (VAR3->VAR26 != VAR46) {\nFUN23(VAR19, VAR19, VAR145,\nVAR146);\n} else {\nVAR5->VAR13 |= VAR147;\n}\n}\nif (VAR7 < 0) {\nVAR21 = -VAR27;\ngoto VAR21;\n}\nif (VAR3->VAR26 == VAR46 ||\nVAR5->VAR13 & VAR70) {\nVAR5->VAR74.VAR23.VAR148.VAR149 = VAR16.VAR150;\nFUN33(VAR5, &VAR5->VAR74);\nVAR21 = FUN34(VAR1, VAR5, VAR20, VAR7, VAR2);\n} else {\nVAR21 = FUN35(VAR1->VAR9, &VAR17->VAR151, VAR20, VAR7);\n}\nif (VAR21) {\nFUN8(VAR1, \"STR\");\ngoto VAR152;\n}\nFUN36(VAR20);\nVAR17->VAR153 = VAR5;\nVAR17->VAR151.VAR154 = VAR155;\nFUN37(VAR3->VAR26, VAR3->VAR11, VAR3->VAR12,\n&VAR11, &VAR12);\nFUN38(&VAR1->VAR156, VAR13);\nFUN39(VAR11, VAR12);\nFUN40(&VAR5->VAR157, &VAR1->VAR158);\nif (VAR11)\nFUN40(&VAR5->VAR159, &VAR11->VAR160);\nif (VAR12)\nFUN40(&VAR5->VAR161, &VAR12->VAR162);\nFUN41(VAR11, VAR12);\nFUN42(&VAR1->VAR156, VAR13);\nreturn 0;\nVAR152:\nif (VAR5->VAR87 == VAR163)\nFUN43(VAR1, VAR2, VAR5, VAR17);\nelse if (VAR5->VAR87 == VAR164)\nFUN44(VAR1, VAR5);\nVAR21:\nFUN36(VAR20);\nreturn VAR21;\n}\n",
      "code_after_change_raw": "static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,\nstruct ib_qp_init_attr *init_attr,\nstruct ib_udata *udata, struct mlx5_ib_qp *qp)\n{\nstruct mlx5_ib_resources *devr = &dev->devr;\nint inlen = MLX5_ST_SZ_BYTES(create_qp_in);\nstruct mlx5_core_dev *mdev = dev->mdev;\nstruct mlx5_ib_create_qp_resp resp = {};\nstruct mlx5_ib_cq *send_cq;\nstruct mlx5_ib_cq *recv_cq;\nunsigned long flags;\nu32 uidx = MLX5_IB_DEFAULT_UIDX;\nstruct mlx5_ib_create_qp ucmd;\nstruct mlx5_ib_qp_base *base;\nint mlx5_st;\nvoid *qpc;\nu32 *in;\nint err;\nmutex_init(&qp->mutex);\nspin_lock_init(&qp->sq.lock);\nspin_lock_init(&qp->rq.lock);\nmlx5_st = to_mlx5_st(init_attr->qp_type);\nif (mlx5_st < 0)\nreturn -EINVAL;\nif (init_attr->rwq_ind_tbl) {\nif (!udata)\nreturn -ENOSYS;\nerr = create_rss_raw_qp_tir(dev, qp, pd, init_attr, udata);\nreturn err;\n}\nif (init_attr->create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK) {\nif (!MLX5_CAP_GEN(mdev, block_lb_mc)) {\nmlx5_ib_dbg(dev, \"block multicast loopback isn't supported\\n\");\nreturn -EINVAL;\n} else {\nqp->flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK;\n}\n}\nif (init_attr->create_flags &\n(IB_QP_CREATE_CROSS_CHANNEL |\nIB_QP_CREATE_MANAGED_SEND |\nIB_QP_CREATE_MANAGED_RECV)) {\nif (!MLX5_CAP_GEN(mdev, cd)) {\nmlx5_ib_dbg(dev, \"cross-channel isn't supported\\n\");\nreturn -EINVAL;\n}\nif (init_attr->create_flags & IB_QP_CREATE_CROSS_CHANNEL)\nqp->flags |= MLX5_IB_QP_CROSS_CHANNEL;\nif (init_attr->create_flags & IB_QP_CREATE_MANAGED_SEND)\nqp->flags |= MLX5_IB_QP_MANAGED_SEND;\nif (init_attr->create_flags & IB_QP_CREATE_MANAGED_RECV)\nqp->flags |= MLX5_IB_QP_MANAGED_RECV;\n}\nif (init_attr->qp_type == IB_QPT_UD &&\n(init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO))\nif (!MLX5_CAP_GEN(mdev, ipoib_basic_offloads)) {\nmlx5_ib_dbg(dev, \"ipoib UD lso qp isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nif (init_attr->create_flags & IB_QP_CREATE_SCATTER_FCS) {\nif (init_attr->qp_type != IB_QPT_RAW_PACKET) {\nmlx5_ib_dbg(dev, \"Scatter FCS is supported only for Raw Packet QPs\");\nreturn -EOPNOTSUPP;\n}\nif (!MLX5_CAP_GEN(dev->mdev, eth_net_offloads) ||\n!MLX5_CAP_ETH(dev->mdev, scatter_fcs)) {\nmlx5_ib_dbg(dev, \"Scatter FCS isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nqp->flags |= MLX5_IB_QP_CAP_SCATTER_FCS;\n}\nif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)\nqp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;\nif (init_attr->create_flags & IB_QP_CREATE_CVLAN_STRIPPING) {\nif (!(MLX5_CAP_GEN(dev->mdev, eth_net_offloads) &&\nMLX5_CAP_ETH(dev->mdev, vlan_cap)) ||\n(init_attr->qp_type != IB_QPT_RAW_PACKET))\nreturn -EOPNOTSUPP;\nqp->flags |= MLX5_IB_QP_CVLAN_STRIPPING;\n}\nif (pd && pd->uobject) {\nif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {\nmlx5_ib_dbg(dev, \"copy failed\\n\");\nreturn -EFAULT;\n}\nerr = get_qp_user_index(to_mucontext(pd->uobject->context),\n&ucmd, udata->inlen, &uidx);\nif (err)\nreturn err;\nqp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);\nqp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);\nif (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {\nif (init_attr->qp_type != IB_QPT_RAW_PACKET ||\n!tunnel_offload_supported(mdev)) {\nmlx5_ib_dbg(dev, \"Tunnel offload isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nqp->tunnel_offload_en = true;\n}\nif (init_attr->create_flags & IB_QP_CREATE_SOURCE_QPN) {\nif (init_attr->qp_type != IB_QPT_UD ||\n(MLX5_CAP_GEN(dev->mdev, port_type) !=\nMLX5_CAP_PORT_TYPE_IB) ||\n!mlx5_get_flow_namespace(dev->mdev, MLX5_FLOW_NAMESPACE_BYPASS)) {\nmlx5_ib_dbg(dev, \"Source QP option isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nqp->flags |= MLX5_IB_QP_UNDERLAY;\nqp->underlay_qpn = init_attr->source_qpn;\n}\n} else {\nqp->wq_sig = !!wq_signature;\n}\nbase = (init_attr->qp_type == IB_QPT_RAW_PACKET ||\nqp->flags & MLX5_IB_QP_UNDERLAY) ?\n&qp->raw_packet_qp.rq.base :\n&qp->trans_qp.base;\nqp->has_rq = qp_has_rq(init_attr);\nerr = set_rq_size(dev, &init_attr->cap, qp->has_rq,\nqp, (pd && pd->uobject) ? &ucmd : NULL);\nif (err) {\nmlx5_ib_dbg(dev, \"err %d\\n\", err);\nreturn err;\n}\nif (pd) {\nif (pd->uobject) {\n__u32 max_wqes =\n1 << MLX5_CAP_GEN(mdev, log_max_qp_sz);\nmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d)\\n\", ucmd.sq_wqe_count);\nif (ucmd.rq_wqe_shift != qp->rq.wqe_shift ||\nucmd.rq_wqe_count != qp->rq.wqe_cnt) {\nmlx5_ib_dbg(dev, \"invalid rq params\\n\");\nreturn -EINVAL;\n}\nif (ucmd.sq_wqe_count > max_wqes) {\nmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d) > max allowed (%d)\\n\",\nucmd.sq_wqe_count, max_wqes);\nreturn -EINVAL;\n}\nif (init_attr->create_flags &\nmlx5_ib_create_qp_sqpn_qp1()) {\nmlx5_ib_dbg(dev, \"user-space is not allowed to create UD QPs spoofing as QP1\\n\");\nreturn -EINVAL;\n}\nerr = create_user_qp(dev, pd, qp, udata, init_attr, &in,\n&resp, &inlen, base);\nif (err)\nmlx5_ib_dbg(dev, \"err %d\\n\", err);\n} else {\nerr = create_kernel_qp(dev, init_attr, qp, &in, &inlen,\nbase);\nif (err)\nmlx5_ib_dbg(dev, \"err %d\\n\", err);\n}\nif (err)\nreturn err;\n} else {\nin = kvzalloc(inlen, GFP_KERNEL);\nif (!in)\nreturn -ENOMEM;\nqp->create_type = MLX5_QP_EMPTY;\n}\nif (is_sqp(init_attr->qp_type))\nqp->port = init_attr->port_num;\nqpc = MLX5_ADDR_OF(create_qp_in, in, qpc);\nMLX5_SET(qpc, qpc, st, mlx5_st);\nMLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);\nif (init_attr->qp_type != MLX5_IB_QPT_REG_UMR)\nMLX5_SET(qpc, qpc, pd, to_mpd(pd ? pd : devr->p0)->pdn);\nelse\nMLX5_SET(qpc, qpc, latency_sensitive, 1);\nif (qp->wq_sig)\nMLX5_SET(qpc, qpc, wq_signature, 1);\nif (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)\nMLX5_SET(qpc, qpc, block_lb_mc, 1);\nif (qp->flags & MLX5_IB_QP_CROSS_CHANNEL)\nMLX5_SET(qpc, qpc, cd_master, 1);\nif (qp->flags & MLX5_IB_QP_MANAGED_SEND)\nMLX5_SET(qpc, qpc, cd_slave_send, 1);\nif (qp->flags & MLX5_IB_QP_MANAGED_RECV)\nMLX5_SET(qpc, qpc, cd_slave_receive, 1);\nif (qp->scat_cqe && is_connected(init_attr->qp_type)) {\nint rcqe_sz;\nint scqe_sz;\nrcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);\nscqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);\nif (rcqe_sz == 128)\nMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA64_CQE);\nelse\nMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA32_CQE);\nif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR) {\nif (scqe_sz == 128)\nMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA64_CQE);\nelse\nMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA32_CQE);\n}\n}\nif (qp->rq.wqe_cnt) {\nMLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);\nMLX5_SET(qpc, qpc, log_rq_size, ilog2(qp->rq.wqe_cnt));\n}\nMLX5_SET(qpc, qpc, rq_type, get_rx_type(qp, init_attr));\nif (qp->sq.wqe_cnt) {\nMLX5_SET(qpc, qpc, log_sq_size, ilog2(qp->sq.wqe_cnt));\n} else {\nMLX5_SET(qpc, qpc, no_sq, 1);\nif (init_attr->srq &&\ninit_attr->srq->srq_type == IB_SRQT_TM)\nMLX5_SET(qpc, qpc, offload_type,\nMLX5_QPC_OFFLOAD_TYPE_RNDV);\n}\nswitch (init_attr->qp_type) {\ncase IB_QPT_XRC_TGT:\nMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\nMLX5_SET(qpc, qpc, cqn_snd, to_mcq(devr->c0)->mcq.cqn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(init_attr->xrcd)->xrcdn);\nbreak;\ncase IB_QPT_XRC_INI:\nMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\nbreak;\ndefault:\nif (init_attr->srq) {\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x0)->xrcdn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(init_attr->srq)->msrq.srqn);\n} else {\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s1)->msrq.srqn);\n}\n}\nif (init_attr->send_cq)\nMLX5_SET(qpc, qpc, cqn_snd, to_mcq(init_attr->send_cq)->mcq.cqn);\nif (init_attr->recv_cq)\nMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(init_attr->recv_cq)->mcq.cqn);\nMLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);\nif (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)\nMLX5_SET(qpc, qpc, user_index, uidx);\nif (init_attr->qp_type == IB_QPT_UD &&\n(init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO)) {\nMLX5_SET(qpc, qpc, ulp_stateless_offload_mode, 1);\nqp->flags |= MLX5_IB_QP_LSO;\n}\nif (init_attr->create_flags & IB_QP_CREATE_PCI_WRITE_END_PADDING) {\nif (!MLX5_CAP_GEN(dev->mdev, end_pad)) {\nmlx5_ib_dbg(dev, \"scatter end padding is not supported\\n\");\nerr = -EOPNOTSUPP;\ngoto err;\n} else if (init_attr->qp_type != IB_QPT_RAW_PACKET) {\nMLX5_SET(qpc, qpc, end_padding_mode,\nMLX5_WQ_END_PAD_MODE_ALIGN);\n} else {\nqp->flags |= MLX5_IB_QP_PCI_WRITE_END_PADDING;\n}\n}\nif (inlen < 0) {\nerr = -EINVAL;\ngoto err;\n}\nif (init_attr->qp_type == IB_QPT_RAW_PACKET ||\nqp->flags & MLX5_IB_QP_UNDERLAY) {\nqp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd.sq_buf_addr;\nraw_packet_qp_copy_info(qp, &qp->raw_packet_qp);\nerr = create_raw_packet_qp(dev, qp, in, inlen, pd);\n} else {\nerr = mlx5_core_create_qp(dev->mdev, &base->mqp, in, inlen);\n}\nif (err) {\nmlx5_ib_dbg(dev, \"create qp failed\\n\");\ngoto err_create;\n}\nkvfree(in);\nbase->container_mibqp = qp;\nbase->mqp.event = mlx5_ib_qp_event;\nget_cqs(init_attr->qp_type, init_attr->send_cq, init_attr->recv_cq,\n&send_cq, &recv_cq);\nspin_lock_irqsave(&dev->reset_flow_resource_lock, flags);\nmlx5_ib_lock_cqs(send_cq, recv_cq);\nlist_add_tail(&qp->qps_list, &dev->qp_list);\nif (send_cq)\nlist_add_tail(&qp->cq_send_list, &send_cq->list_send_qp);\nif (recv_cq)\nlist_add_tail(&qp->cq_recv_list, &recv_cq->list_recv_qp);\nmlx5_ib_unlock_cqs(send_cq, recv_cq);\nspin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);\nreturn 0;\nerr_create:\nif (qp->create_type == MLX5_QP_USER)\ndestroy_qp_user(dev, pd, qp, base);\nelse if (qp->create_type == MLX5_QP_KERNEL)\ndestroy_qp_kernel(dev, qp);\nerr:\nkvfree(in);\nreturn err;\n}\n",
      "code_before_change_raw": "static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,\nstruct ib_qp_init_attr *init_attr,\nstruct ib_udata *udata, struct mlx5_ib_qp *qp)\n{\nstruct mlx5_ib_resources *devr = &dev->devr;\nint inlen = MLX5_ST_SZ_BYTES(create_qp_in);\nstruct mlx5_core_dev *mdev = dev->mdev;\nstruct mlx5_ib_create_qp_resp resp;\nstruct mlx5_ib_cq *send_cq;\nstruct mlx5_ib_cq *recv_cq;\nunsigned long flags;\nu32 uidx = MLX5_IB_DEFAULT_UIDX;\nstruct mlx5_ib_create_qp ucmd;\nstruct mlx5_ib_qp_base *base;\nint mlx5_st;\nvoid *qpc;\nu32 *in;\nint err;\nmutex_init(&qp->mutex);\nspin_lock_init(&qp->sq.lock);\nspin_lock_init(&qp->rq.lock);\nmlx5_st = to_mlx5_st(init_attr->qp_type);\nif (mlx5_st < 0)\nreturn -EINVAL;\nif (init_attr->rwq_ind_tbl) {\nif (!udata)\nreturn -ENOSYS;\nerr = create_rss_raw_qp_tir(dev, qp, pd, init_attr, udata);\nreturn err;\n}\nif (init_attr->create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK) {\nif (!MLX5_CAP_GEN(mdev, block_lb_mc)) {\nmlx5_ib_dbg(dev, \"block multicast loopback isn't supported\\n\");\nreturn -EINVAL;\n} else {\nqp->flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK;\n}\n}\nif (init_attr->create_flags &\n(IB_QP_CREATE_CROSS_CHANNEL |\nIB_QP_CREATE_MANAGED_SEND |\nIB_QP_CREATE_MANAGED_RECV)) {\nif (!MLX5_CAP_GEN(mdev, cd)) {\nmlx5_ib_dbg(dev, \"cross-channel isn't supported\\n\");\nreturn -EINVAL;\n}\nif (init_attr->create_flags & IB_QP_CREATE_CROSS_CHANNEL)\nqp->flags |= MLX5_IB_QP_CROSS_CHANNEL;\nif (init_attr->create_flags & IB_QP_CREATE_MANAGED_SEND)\nqp->flags |= MLX5_IB_QP_MANAGED_SEND;\nif (init_attr->create_flags & IB_QP_CREATE_MANAGED_RECV)\nqp->flags |= MLX5_IB_QP_MANAGED_RECV;\n}\nif (init_attr->qp_type == IB_QPT_UD &&\n(init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO))\nif (!MLX5_CAP_GEN(mdev, ipoib_basic_offloads)) {\nmlx5_ib_dbg(dev, \"ipoib UD lso qp isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nif (init_attr->create_flags & IB_QP_CREATE_SCATTER_FCS) {\nif (init_attr->qp_type != IB_QPT_RAW_PACKET) {\nmlx5_ib_dbg(dev, \"Scatter FCS is supported only for Raw Packet QPs\");\nreturn -EOPNOTSUPP;\n}\nif (!MLX5_CAP_GEN(dev->mdev, eth_net_offloads) ||\n!MLX5_CAP_ETH(dev->mdev, scatter_fcs)) {\nmlx5_ib_dbg(dev, \"Scatter FCS isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nqp->flags |= MLX5_IB_QP_CAP_SCATTER_FCS;\n}\nif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)\nqp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;\nif (init_attr->create_flags & IB_QP_CREATE_CVLAN_STRIPPING) {\nif (!(MLX5_CAP_GEN(dev->mdev, eth_net_offloads) &&\nMLX5_CAP_ETH(dev->mdev, vlan_cap)) ||\n(init_attr->qp_type != IB_QPT_RAW_PACKET))\nreturn -EOPNOTSUPP;\nqp->flags |= MLX5_IB_QP_CVLAN_STRIPPING;\n}\nif (pd && pd->uobject) {\nif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {\nmlx5_ib_dbg(dev, \"copy failed\\n\");\nreturn -EFAULT;\n}\nerr = get_qp_user_index(to_mucontext(pd->uobject->context),\n&ucmd, udata->inlen, &uidx);\nif (err)\nreturn err;\nqp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);\nqp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);\nif (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {\nif (init_attr->qp_type != IB_QPT_RAW_PACKET ||\n!tunnel_offload_supported(mdev)) {\nmlx5_ib_dbg(dev, \"Tunnel offload isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nqp->tunnel_offload_en = true;\n}\nif (init_attr->create_flags & IB_QP_CREATE_SOURCE_QPN) {\nif (init_attr->qp_type != IB_QPT_UD ||\n(MLX5_CAP_GEN(dev->mdev, port_type) !=\nMLX5_CAP_PORT_TYPE_IB) ||\n!mlx5_get_flow_namespace(dev->mdev, MLX5_FLOW_NAMESPACE_BYPASS)) {\nmlx5_ib_dbg(dev, \"Source QP option isn't supported\\n\");\nreturn -EOPNOTSUPP;\n}\nqp->flags |= MLX5_IB_QP_UNDERLAY;\nqp->underlay_qpn = init_attr->source_qpn;\n}\n} else {\nqp->wq_sig = !!wq_signature;\n}\nbase = (init_attr->qp_type == IB_QPT_RAW_PACKET ||\nqp->flags & MLX5_IB_QP_UNDERLAY) ?\n&qp->raw_packet_qp.rq.base :\n&qp->trans_qp.base;\nqp->has_rq = qp_has_rq(init_attr);\nerr = set_rq_size(dev, &init_attr->cap, qp->has_rq,\nqp, (pd && pd->uobject) ? &ucmd : NULL);\nif (err) {\nmlx5_ib_dbg(dev, \"err %d\\n\", err);\nreturn err;\n}\nif (pd) {\nif (pd->uobject) {\n__u32 max_wqes =\n1 << MLX5_CAP_GEN(mdev, log_max_qp_sz);\nmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d)\\n\", ucmd.sq_wqe_count);\nif (ucmd.rq_wqe_shift != qp->rq.wqe_shift ||\nucmd.rq_wqe_count != qp->rq.wqe_cnt) {\nmlx5_ib_dbg(dev, \"invalid rq params\\n\");\nreturn -EINVAL;\n}\nif (ucmd.sq_wqe_count > max_wqes) {\nmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d) > max allowed (%d)\\n\",\nucmd.sq_wqe_count, max_wqes);\nreturn -EINVAL;\n}\nif (init_attr->create_flags &\nmlx5_ib_create_qp_sqpn_qp1()) {\nmlx5_ib_dbg(dev, \"user-space is not allowed to create UD QPs spoofing as QP1\\n\");\nreturn -EINVAL;\n}\nerr = create_user_qp(dev, pd, qp, udata, init_attr, &in,\n&resp, &inlen, base);\nif (err)\nmlx5_ib_dbg(dev, \"err %d\\n\", err);\n} else {\nerr = create_kernel_qp(dev, init_attr, qp, &in, &inlen,\nbase);\nif (err)\nmlx5_ib_dbg(dev, \"err %d\\n\", err);\n}\nif (err)\nreturn err;\n} else {\nin = kvzalloc(inlen, GFP_KERNEL);\nif (!in)\nreturn -ENOMEM;\nqp->create_type = MLX5_QP_EMPTY;\n}\nif (is_sqp(init_attr->qp_type))\nqp->port = init_attr->port_num;\nqpc = MLX5_ADDR_OF(create_qp_in, in, qpc);\nMLX5_SET(qpc, qpc, st, mlx5_st);\nMLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);\nif (init_attr->qp_type != MLX5_IB_QPT_REG_UMR)\nMLX5_SET(qpc, qpc, pd, to_mpd(pd ? pd : devr->p0)->pdn);\nelse\nMLX5_SET(qpc, qpc, latency_sensitive, 1);\nif (qp->wq_sig)\nMLX5_SET(qpc, qpc, wq_signature, 1);\nif (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)\nMLX5_SET(qpc, qpc, block_lb_mc, 1);\nif (qp->flags & MLX5_IB_QP_CROSS_CHANNEL)\nMLX5_SET(qpc, qpc, cd_master, 1);\nif (qp->flags & MLX5_IB_QP_MANAGED_SEND)\nMLX5_SET(qpc, qpc, cd_slave_send, 1);\nif (qp->flags & MLX5_IB_QP_MANAGED_RECV)\nMLX5_SET(qpc, qpc, cd_slave_receive, 1);\nif (qp->scat_cqe && is_connected(init_attr->qp_type)) {\nint rcqe_sz;\nint scqe_sz;\nrcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);\nscqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);\nif (rcqe_sz == 128)\nMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA64_CQE);\nelse\nMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA32_CQE);\nif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR) {\nif (scqe_sz == 128)\nMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA64_CQE);\nelse\nMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA32_CQE);\n}\n}\nif (qp->rq.wqe_cnt) {\nMLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);\nMLX5_SET(qpc, qpc, log_rq_size, ilog2(qp->rq.wqe_cnt));\n}\nMLX5_SET(qpc, qpc, rq_type, get_rx_type(qp, init_attr));\nif (qp->sq.wqe_cnt) {\nMLX5_SET(qpc, qpc, log_sq_size, ilog2(qp->sq.wqe_cnt));\n} else {\nMLX5_SET(qpc, qpc, no_sq, 1);\nif (init_attr->srq &&\ninit_attr->srq->srq_type == IB_SRQT_TM)\nMLX5_SET(qpc, qpc, offload_type,\nMLX5_QPC_OFFLOAD_TYPE_RNDV);\n}\nswitch (init_attr->qp_type) {\ncase IB_QPT_XRC_TGT:\nMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\nMLX5_SET(qpc, qpc, cqn_snd, to_mcq(devr->c0)->mcq.cqn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(init_attr->xrcd)->xrcdn);\nbreak;\ncase IB_QPT_XRC_INI:\nMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\nbreak;\ndefault:\nif (init_attr->srq) {\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x0)->xrcdn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(init_attr->srq)->msrq.srqn);\n} else {\nMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\nMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s1)->msrq.srqn);\n}\n}\nif (init_attr->send_cq)\nMLX5_SET(qpc, qpc, cqn_snd, to_mcq(init_attr->send_cq)->mcq.cqn);\nif (init_attr->recv_cq)\nMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(init_attr->recv_cq)->mcq.cqn);\nMLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);\nif (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)\nMLX5_SET(qpc, qpc, user_index, uidx);\nif (init_attr->qp_type == IB_QPT_UD &&\n(init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO)) {\nMLX5_SET(qpc, qpc, ulp_stateless_offload_mode, 1);\nqp->flags |= MLX5_IB_QP_LSO;\n}\nif (init_attr->create_flags & IB_QP_CREATE_PCI_WRITE_END_PADDING) {\nif (!MLX5_CAP_GEN(dev->mdev, end_pad)) {\nmlx5_ib_dbg(dev, \"scatter end padding is not supported\\n\");\nerr = -EOPNOTSUPP;\ngoto err;\n} else if (init_attr->qp_type != IB_QPT_RAW_PACKET) {\nMLX5_SET(qpc, qpc, end_padding_mode,\nMLX5_WQ_END_PAD_MODE_ALIGN);\n} else {\nqp->flags |= MLX5_IB_QP_PCI_WRITE_END_PADDING;\n}\n}\nif (inlen < 0) {\nerr = -EINVAL;\ngoto err;\n}\nif (init_attr->qp_type == IB_QPT_RAW_PACKET ||\nqp->flags & MLX5_IB_QP_UNDERLAY) {\nqp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd.sq_buf_addr;\nraw_packet_qp_copy_info(qp, &qp->raw_packet_qp);\nerr = create_raw_packet_qp(dev, qp, in, inlen, pd);\n} else {\nerr = mlx5_core_create_qp(dev->mdev, &base->mqp, in, inlen);\n}\nif (err) {\nmlx5_ib_dbg(dev, \"create qp failed\\n\");\ngoto err_create;\n}\nkvfree(in);\nbase->container_mibqp = qp;\nbase->mqp.event = mlx5_ib_qp_event;\nget_cqs(init_attr->qp_type, init_attr->send_cq, init_attr->recv_cq,\n&send_cq, &recv_cq);\nspin_lock_irqsave(&dev->reset_flow_resource_lock, flags);\nmlx5_ib_lock_cqs(send_cq, recv_cq);\nlist_add_tail(&qp->qps_list, &dev->qp_list);\nif (send_cq)\nlist_add_tail(&qp->cq_send_list, &send_cq->list_send_qp);\nif (recv_cq)\nlist_add_tail(&qp->cq_recv_list, &recv_cq->list_recv_qp);\nmlx5_ib_unlock_cqs(send_cq, recv_cq);\nspin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);\nreturn 0;\nerr_create:\nif (qp->create_type == MLX5_QP_USER)\ndestroy_qp_user(dev, pd, qp, base);\nelse if (qp->create_type == MLX5_QP_KERNEL)\ndestroy_qp_kernel(dev, qp);\nerr:\nkvfree(in);\nreturn err;\n}\n"
    }
  ],
  "CVE-2018-5848": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for the length parameter in a memory allocation operation.",
        "trigger_condition": "Passing a large value for the 'ie_len' parameter can cause an unsigned integer overflow during the calculation of the buffer length, leading to insufficient memory allocation.",
        "specific_code_behavior_causing_vulnerability": "The code does not handle the possibility of an unsigned integer overflow when calculating the buffer length, potentially resulting in a buffer overflow vulnerability if 'ie_len' is a large value."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the calculated buffer length is not smaller than the specified 'ie_len' value. This check prevents the unsigned integer overflow and ensures that sufficient memory is allocated for the buffer. In this case, the solution involves adding a conditional statement to verify that the calculated length is not less than the provided 'ie_len' before proceeding with memory allocation.",
      "GPT_analysis": "The modification is necessary to prevent a buffer overflow vulnerability in the code. In the original code snippet, the calculation of the 'len' variable is susceptible to an unsigned integer overflow. If a large value of 'ie_len' is provided, it can cause 'len' to wrap around and become smaller than 'ie_len', leading to insufficient memory allocation for the 'cmd' buffer.\n\nBy adding the check `if (len < ie_len)` in the modified code, we ensure that the calculation of 'len' does not overflow and that it is large enough to accommodate the required memory for the 'cmd' buffer. This check helps prevent buffer overflow issues that could potentially be exploited by malicious actors to execute arbitrary code or crash the system.",
      "GPT_purpose": "Set Information Element (IE) in a wireless management frame.",
      "GPT_function": "\n1. Set the names for different WMI frame types.\n2. Allocate memory for a WMI command structure.\n3. Copy information into the allocated memory and send the command to the firmware.",
      "CVE_id": "CVE-2018-5848",
      "code_before_change": "int wmi_set_ie(struct wil6210_priv *wil, u8 type, u16 ie_len, const void *ie)\n{\n\tstatic const char *const names[] = {\n\t\t[WMI_FRAME_BEACON]\t= \"BEACON\",\n\t\t[WMI_FRAME_PROBE_REQ]\t= \"PROBE_REQ\",\n\t\t[WMI_FRAME_PROBE_RESP]\t= \"WMI_FRAME_PROBE_RESP\",\n\t\t[WMI_FRAME_ASSOC_REQ]\t= \"WMI_FRAME_ASSOC_REQ\",\n\t\t[WMI_FRAME_ASSOC_RESP]\t= \"WMI_FRAME_ASSOC_RESP\",\n\t};\n\tint rc;\n\tu16 len = sizeof(struct wmi_set_appie_cmd) + ie_len;\n\tstruct wmi_set_appie_cmd *cmd = kzalloc(len, GFP_KERNEL);\n\n\tif (!cmd) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\tif (!ie)\n\t\tie_len = 0;\n\n\tcmd->mgmt_frm_type = type;\n\t/* BUG: FW API define ieLen as u8. Will fix FW */\n\tcmd->ie_len = cpu_to_le16(ie_len);\n\tmemcpy(cmd->ie_info, ie, ie_len);\n\trc = wmi_send(wil, WMI_SET_APPIE_CMDID, cmd, len);\n\tkfree(cmd);\nout:\n\tif (rc) {\n\t\tconst char *name = type < ARRAY_SIZE(names) ?\n\t\t\t\t   names[type] : \"??\";\n\t\twil_err(wil, \"set_ie(%d %s) failed : %d\\n\", type, name, rc);\n\t}\n\n\treturn rc;\n}",
      "code_after_change": "int wmi_set_ie(struct wil6210_priv *wil, u8 type, u16 ie_len, const void *ie)\n{\n\tstatic const char *const names[] = {\n\t\t[WMI_FRAME_BEACON]\t= \"BEACON\",\n\t\t[WMI_FRAME_PROBE_REQ]\t= \"PROBE_REQ\",\n\t\t[WMI_FRAME_PROBE_RESP]\t= \"WMI_FRAME_PROBE_RESP\",\n\t\t[WMI_FRAME_ASSOC_REQ]\t= \"WMI_FRAME_ASSOC_REQ\",\n\t\t[WMI_FRAME_ASSOC_RESP]\t= \"WMI_FRAME_ASSOC_RESP\",\n\t};\n\tint rc;\n\tu16 len = sizeof(struct wmi_set_appie_cmd) + ie_len;\n\tstruct wmi_set_appie_cmd *cmd;\n\n\tif (len < ie_len) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tcmd = kzalloc(len, GFP_KERNEL);\n\tif (!cmd) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\tif (!ie)\n\t\tie_len = 0;\n\n\tcmd->mgmt_frm_type = type;\n\t/* BUG: FW API define ieLen as u8. Will fix FW */\n\tcmd->ie_len = cpu_to_le16(ie_len);\n\tmemcpy(cmd->ie_info, ie, ie_len);\n\trc = wmi_send(wil, WMI_SET_APPIE_CMDID, cmd, len);\n\tkfree(cmd);\nout:\n\tif (rc) {\n\t\tconst char *name = type < ARRAY_SIZE(names) ?\n\t\t\t\t   names[type] : \"??\";\n\t\twil_err(wil, \"set_ie(%d %s) failed : %d\\n\", type, name, rc);\n\t}\n\n\treturn rc;\n}",
      "modified_lines": {
        "added": [
          "\tstruct wmi_set_appie_cmd *cmd;",
          "\tif (len < ie_len) {",
          "\t\trc = -EINVAL;",
          "\t\tgoto out;",
          "\t}",
          "",
          "\tcmd = kzalloc(len, GFP_KERNEL);"
        ],
        "deleted": [
          "\tstruct wmi_set_appie_cmd *cmd = kzalloc(len, GFP_KERNEL);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for the length parameter in a memory allocation operation.",
      "trigger_condition": "Passing a large value for the 'ie_len' parameter can cause an unsigned integer overflow during the calculation of the buffer length, leading to insufficient memory allocation.",
      "specific_code_behavior_causing_vulnerability": "The code does not handle the possibility of an unsigned integer overflow when calculating the buffer length, potentially resulting in a buffer overflow vulnerability if 'ie_len' is a large value.",
      "id": 138,
      "code_after_change_normalized": "int FUN1(struct wil6210_priv *VAR1, u8 VAR2, u16 VAR3, const void *VAR4)\n{\nstatic const char *const VAR5[] = {\n[VAR6]\t= \"STR\",\n[VAR7]\t= \"STR\",\n[VAR8]\t= \"STR\",\n[VAR9]\t= \"STR\",\n[VAR10]\t= \"STR\",\n};\nint VAR11;\nu16 VAR12 = sizeof(struct VAR13) + VAR3;\nstruct wmi_set_appie_cmd *VAR14;\nif (VAR12 < VAR3) {\nVAR11 = -VAR15;\ngoto VAR16;\n}\nVAR14 = FUN2(VAR12, VAR17);\nif (!VAR14) {\nVAR11 = -VAR18;\ngoto VAR16;\n}\nif (!VAR4)\nVAR3 = 0;\nVAR14->VAR19 = VAR2;\nVAR14->VAR3 = FUN3(VAR3);\nFUN4(VAR14->VAR20, VAR4, VAR3);\nVAR11 = FUN5(VAR1, VAR21, VAR14, VAR12);\nFUN6(VAR14);\nVAR16:\nif (VAR11) {\nconst char *VAR22 = VAR2 < FUN7(VAR5) ?\nVAR5[VAR2] : \"STR\";\nFUN8(VAR1, \"STR\", VAR2, VAR22, VAR11);\n}\nreturn VAR11;\n}\n",
      "code_before_change_normalized": "int FUN1(struct wil6210_priv *VAR1, u8 VAR2, u16 VAR3, const void *VAR4)\n{\nstatic const char *const VAR5[] = {\n[VAR6]\t= \"STR\",\n[VAR7]\t= \"STR\",\n[VAR8]\t= \"STR\",\n[VAR9]\t= \"STR\",\n[VAR10]\t= \"STR\",\n};\nint VAR11;\nu16 VAR12 = sizeof(struct VAR13) + VAR3;\nstruct wmi_set_appie_cmd *VAR14 = FUN2(VAR12, VAR15);\nif (!VAR14) {\nVAR11 = -VAR16;\ngoto VAR17;\n}\nif (!VAR4)\nVAR3 = 0;\nVAR14->VAR18 = VAR2;\nVAR14->VAR3 = FUN3(VAR3);\nFUN4(VAR14->VAR19, VAR4, VAR3);\nVAR11 = FUN5(VAR1, VAR20, VAR14, VAR12);\nFUN6(VAR14);\nVAR17:\nif (VAR11) {\nconst char *VAR21 = VAR2 < FUN7(VAR5) ?\nVAR5[VAR2] : \"STR\";\nFUN8(VAR1, \"STR\", VAR2, VAR21, VAR11);\n}\nreturn VAR11;\n}\n",
      "code_after_change_raw": "int wmi_set_ie(struct wil6210_priv *wil, u8 type, u16 ie_len, const void *ie)\n{\nstatic const char *const names[] = {\n[WMI_FRAME_BEACON]\t= \"BEACON\",\n[WMI_FRAME_PROBE_REQ]\t= \"PROBE_REQ\",\n[WMI_FRAME_PROBE_RESP]\t= \"WMI_FRAME_PROBE_RESP\",\n[WMI_FRAME_ASSOC_REQ]\t= \"WMI_FRAME_ASSOC_REQ\",\n[WMI_FRAME_ASSOC_RESP]\t= \"WMI_FRAME_ASSOC_RESP\",\n};\nint rc;\nu16 len = sizeof(struct wmi_set_appie_cmd) + ie_len;\nstruct wmi_set_appie_cmd *cmd;\nif (len < ie_len) {\nrc = -EINVAL;\ngoto out;\n}\ncmd = kzalloc(len, GFP_KERNEL);\nif (!cmd) {\nrc = -ENOMEM;\ngoto out;\n}\nif (!ie)\nie_len = 0;\ncmd->mgmt_frm_type = type;\ncmd->ie_len = cpu_to_le16(ie_len);\nmemcpy(cmd->ie_info, ie, ie_len);\nrc = wmi_send(wil, WMI_SET_APPIE_CMDID, cmd, len);\nkfree(cmd);\nout:\nif (rc) {\nconst char *name = type < ARRAY_SIZE(names) ?\nnames[type] : \"??\";\nwil_err(wil, \"set_ie(%d %s) failed : %d\\n\", type, name, rc);\n}\nreturn rc;\n}\n",
      "code_before_change_raw": "int wmi_set_ie(struct wil6210_priv *wil, u8 type, u16 ie_len, const void *ie)\n{\nstatic const char *const names[] = {\n[WMI_FRAME_BEACON]\t= \"BEACON\",\n[WMI_FRAME_PROBE_REQ]\t= \"PROBE_REQ\",\n[WMI_FRAME_PROBE_RESP]\t= \"WMI_FRAME_PROBE_RESP\",\n[WMI_FRAME_ASSOC_REQ]\t= \"WMI_FRAME_ASSOC_REQ\",\n[WMI_FRAME_ASSOC_RESP]\t= \"WMI_FRAME_ASSOC_RESP\",\n};\nint rc;\nu16 len = sizeof(struct wmi_set_appie_cmd) + ie_len;\nstruct wmi_set_appie_cmd *cmd = kzalloc(len, GFP_KERNEL);\nif (!cmd) {\nrc = -ENOMEM;\ngoto out;\n}\nif (!ie)\nie_len = 0;\ncmd->mgmt_frm_type = type;\ncmd->ie_len = cpu_to_le16(ie_len);\nmemcpy(cmd->ie_info, ie, ie_len);\nrc = wmi_send(wil, WMI_SET_APPIE_CMDID, cmd, len);\nkfree(cmd);\nout:\nif (rc) {\nconst char *name = type < ARRAY_SIZE(names) ?\nnames[type] : \"??\";\nwil_err(wil, \"set_ie(%d %s) failed : %d\\n\", type, name, rc);\n}\nreturn rc;\n}\n"
    }
  ],
  "CVE-2018-7566": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper synchronization mechanism during pool initialization process.",
        "trigger_condition": "A local user triggers an SNDRV_SEQ_IOCTL_SET_CLIENT_POOL ioctl write operation to /dev/snd/seq.",
        "specific_code_behavior_causing_vulnerability": "The code lacks proper synchronization when initializing the pool, which can lead to a race condition and potential buffer overflow vulnerability. Without proper synchronization, multiple threads could access and modify the pool concurrently, causing buffer overflow issues."
      },
      "solution": "To mitigate the vulnerability, it is necessary to introduce a mutex lock during the pool initialization process. By adding a mutex lock, the code ensures that only one thread can access and modify the pool at a time, preventing race conditions and reducing the risk of buffer overflow vulnerabilities. In this case, the solution involves adding mutex_lock and mutex_unlock around the pool initialization code to enforce proper synchronization.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2018-7566, which involves a Buffer Overflow via an SNDRV_SEQ_IOCTL_SET_CLIENT_POOL ioctl write operation to /dev/snd/seq by a local user. \n\nTo fix this vulnerability, the modification adds the following lines:\n```\nmutex_lock(&client->ioctl_mutex);\nerr = snd_seq_pool_init(client->pool);\nmutex_unlock(&client->ioctl_mutex);\n```\nThese lines introduce a mutex lock to ensure that the initialization of the pool is done atomically and prevent potential race conditions that could lead to a buffer overflow. By adding this mutex lock, the code ensures that only one thread can access and modify the pool at a time, reducing the risk of buffer overflow vulnerabilities.",
      "GPT_purpose": "Write events to the ALSA sequencer.",
      "GPT_function": "\n1. Write data to the ALSA sequencer device file.\n2. Check if the file has output capabilities.\n3. Check client structures and pool availability.\n4. Allocate a pool if not already allocated.\n5. Process whole events from the user input.\n6. Fill in client number in the event.\n7. Check event type and length for validity.\n8. Handle special events and reserved events.\n9. Handle variable events and user space pointers.\n10. Enqueue the event for processing.\n11. Update pointers and counts during event processing.",
      "CVE_id": "CVE-2018-7566",
      "code_before_change": "static ssize_t snd_seq_write(struct file *file, const char __user *buf,\n\t\t\t     size_t count, loff_t *offset)\n{\n\tstruct snd_seq_client *client = file->private_data;\n\tint written = 0, len;\n\tint err = -EINVAL;\n\tstruct snd_seq_event event;\n\n\tif (!(snd_seq_file_flags(file) & SNDRV_SEQ_LFLG_OUTPUT))\n\t\treturn -ENXIO;\n\n\t/* check client structures are in place */\n\tif (snd_BUG_ON(!client))\n\t\treturn -ENXIO;\n\t\t\n\tif (!client->accept_output || client->pool == NULL)\n\t\treturn -ENXIO;\n\n\t/* allocate the pool now if the pool is not allocated yet */ \n\tif (client->pool->size > 0 && !snd_seq_write_pool_allocated(client)) {\n\t\tif (snd_seq_pool_init(client->pool) < 0)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/* only process whole events */\n\twhile (count >= sizeof(struct snd_seq_event)) {\n\t\t/* Read in the event header from the user */\n\t\tlen = sizeof(event);\n\t\tif (copy_from_user(&event, buf, len)) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tevent.source.client = client->number;\t/* fill in client number */\n\t\t/* Check for extension data length */\n\t\tif (check_event_type_and_length(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* check for special events */\n\t\tif (event.type == SNDRV_SEQ_EVENT_NONE)\n\t\t\tgoto __skip_event;\n\t\telse if (snd_seq_ev_is_reserved(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (snd_seq_ev_is_variable(&event)) {\n\t\t\tint extlen = event.data.ext.len & ~SNDRV_SEQ_EXT_MASK;\n\t\t\tif ((size_t)(extlen + len) > count) {\n\t\t\t\t/* back out, will get an error this time or next */\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* set user space pointer */\n\t\t\tevent.data.ext.len = extlen | SNDRV_SEQ_EXT_USRPTR;\n\t\t\tevent.data.ext.ptr = (char __force *)buf\n\t\t\t\t\t\t+ sizeof(struct snd_seq_event);\n\t\t\tlen += extlen; /* increment data length */\n\t\t} else {\n#ifdef CONFIG_COMPAT\n\t\t\tif (client->convert32 && snd_seq_ev_is_varusr(&event)) {\n\t\t\t\tvoid *ptr = (void __force *)compat_ptr(event.data.raw32.d[1]);\n\t\t\t\tevent.data.ext.ptr = ptr;\n\t\t\t}\n#endif\n\t\t}\n\n\t\t/* ok, enqueue it */\n\t\terr = snd_seq_client_enqueue_event(client, &event, file,\n\t\t\t\t\t\t   !(file->f_flags & O_NONBLOCK),\n\t\t\t\t\t\t   0, 0);\n\t\tif (err < 0)\n\t\t\tbreak;\n\n\t__skip_event:\n\t\t/* Update pointers and counts */\n\t\tcount -= len;\n\t\tbuf += len;\n\t\twritten += len;\n\t}\n\n\treturn written ? written : err;\n}",
      "code_after_change": "static ssize_t snd_seq_write(struct file *file, const char __user *buf,\n\t\t\t     size_t count, loff_t *offset)\n{\n\tstruct snd_seq_client *client = file->private_data;\n\tint written = 0, len;\n\tint err;\n\tstruct snd_seq_event event;\n\n\tif (!(snd_seq_file_flags(file) & SNDRV_SEQ_LFLG_OUTPUT))\n\t\treturn -ENXIO;\n\n\t/* check client structures are in place */\n\tif (snd_BUG_ON(!client))\n\t\treturn -ENXIO;\n\t\t\n\tif (!client->accept_output || client->pool == NULL)\n\t\treturn -ENXIO;\n\n\t/* allocate the pool now if the pool is not allocated yet */ \n\tif (client->pool->size > 0 && !snd_seq_write_pool_allocated(client)) {\n\t\tmutex_lock(&client->ioctl_mutex);\n\t\terr = snd_seq_pool_init(client->pool);\n\t\tmutex_unlock(&client->ioctl_mutex);\n\t\tif (err < 0)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/* only process whole events */\n\terr = -EINVAL;\n\twhile (count >= sizeof(struct snd_seq_event)) {\n\t\t/* Read in the event header from the user */\n\t\tlen = sizeof(event);\n\t\tif (copy_from_user(&event, buf, len)) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tevent.source.client = client->number;\t/* fill in client number */\n\t\t/* Check for extension data length */\n\t\tif (check_event_type_and_length(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* check for special events */\n\t\tif (event.type == SNDRV_SEQ_EVENT_NONE)\n\t\t\tgoto __skip_event;\n\t\telse if (snd_seq_ev_is_reserved(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (snd_seq_ev_is_variable(&event)) {\n\t\t\tint extlen = event.data.ext.len & ~SNDRV_SEQ_EXT_MASK;\n\t\t\tif ((size_t)(extlen + len) > count) {\n\t\t\t\t/* back out, will get an error this time or next */\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* set user space pointer */\n\t\t\tevent.data.ext.len = extlen | SNDRV_SEQ_EXT_USRPTR;\n\t\t\tevent.data.ext.ptr = (char __force *)buf\n\t\t\t\t\t\t+ sizeof(struct snd_seq_event);\n\t\t\tlen += extlen; /* increment data length */\n\t\t} else {\n#ifdef CONFIG_COMPAT\n\t\t\tif (client->convert32 && snd_seq_ev_is_varusr(&event)) {\n\t\t\t\tvoid *ptr = (void __force *)compat_ptr(event.data.raw32.d[1]);\n\t\t\t\tevent.data.ext.ptr = ptr;\n\t\t\t}\n#endif\n\t\t}\n\n\t\t/* ok, enqueue it */\n\t\terr = snd_seq_client_enqueue_event(client, &event, file,\n\t\t\t\t\t\t   !(file->f_flags & O_NONBLOCK),\n\t\t\t\t\t\t   0, 0);\n\t\tif (err < 0)\n\t\t\tbreak;\n\n\t__skip_event:\n\t\t/* Update pointers and counts */\n\t\tcount -= len;\n\t\tbuf += len;\n\t\twritten += len;\n\t}\n\n\treturn written ? written : err;\n}",
      "modified_lines": {
        "added": [
          "\tint err;",
          "\t\tmutex_lock(&client->ioctl_mutex);",
          "\t\terr = snd_seq_pool_init(client->pool);",
          "\t\tmutex_unlock(&client->ioctl_mutex);",
          "\t\tif (err < 0)",
          "\terr = -EINVAL;"
        ],
        "deleted": [
          "\tint err = -EINVAL;",
          "\t\tif (snd_seq_pool_init(client->pool) < 0)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper synchronization mechanism during pool initialization process.",
      "trigger_condition": "A local user triggers an SNDRV_SEQ_IOCTL_SET_CLIENT_POOL ioctl write operation to /dev/snd/seq.",
      "specific_code_behavior_causing_vulnerability": "The code lacks proper synchronization when initializing the pool, which can lead to a race condition and potential buffer overflow vulnerability. Without proper synchronization, multiple threads could access and modify the pool concurrently, causing buffer overflow issues.",
      "id": 139,
      "code_after_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, const char __user *VAR2,\nsize_t VAR3, loff_t *VAR4)\n{\nstruct snd_seq_client *VAR5 = VAR1->VAR6;\nint VAR7 = 0, VAR8;\nint VAR9;\nstruct snd_seq_event VAR10;\nif (!(FUN2(VAR1) & VAR11))\nreturn -VAR12;\nif (FUN3(!VAR5))\nreturn -VAR12;\nif (!VAR5->VAR13 || VAR5->VAR14 == NULL)\nreturn -VAR12;\nif (VAR5->VAR14->VAR15 > 0 && !FUN4(VAR5)) {\nFUN5(&VAR5->VAR16);\nVAR9 = FUN6(VAR5->VAR14);\nFUN7(&VAR5->VAR16);\nif (VAR9 < 0)\nreturn -VAR17;\n}\nVAR9 = -VAR18;\nwhile (VAR3 >= sizeof(struct VAR19)) {\nVAR8 = sizeof(VAR10);\nif (FUN8(&VAR10, VAR2, VAR8)) {\nVAR9 = -VAR20;\nbreak;\n}\nVAR10.VAR21.VAR5 = VAR5->VAR22;\t\nif (FUN9(&VAR10)) {\nVAR9 = -VAR18;\nbreak;\n}\nif (VAR10.VAR23 == VAR24)\ngoto VAR25;\nelse if (FUN10(&VAR10)) {\nVAR9 = -VAR18;\nbreak;\n}\nif (FUN11(&VAR10)) {\nint VAR26 = VAR10.VAR27.VAR28.VAR8 & ~VAR29;\nif ((VAR30)(VAR26 + VAR8) > VAR3) {\nVAR9 = -VAR18;\nbreak;\n}\nVAR10.VAR27.VAR28.VAR8 = VAR26 | VAR31;\nVAR10.VAR27.VAR28.VAR32 = (char VAR33 *)VAR2\n+ sizeof(struct VAR19);\nVAR8 += VAR26; \n} else {\n#ifdef VAR34\nif (VAR5->VAR35 && FUN12(&VAR10)) {\nvoid *VAR32 = (void VAR33 *)FUN13(VAR10.VAR27.VAR36.VAR37[1]);\nVAR10.VAR27.VAR28.VAR32 = VAR32;\n}\n#VAR38\n}\nVAR9 = FUN14(VAR5, &VAR10, VAR1,\n!(VAR1->VAR39 & VAR40),\n0, 0);\nif (VAR9 < 0)\nbreak;\nVAR25:\nVAR3 -= VAR8;\nVAR2 += VAR8;\nVAR7 += VAR8;\n}\nreturn VAR7 ? VAR7 : VAR9;\n}\n",
      "code_before_change_normalized": "static ssize_t FUN1(struct VAR1 *VAR1, const char __user *VAR2,\nsize_t VAR3, loff_t *VAR4)\n{\nstruct snd_seq_client *VAR5 = VAR1->VAR6;\nint VAR7 = 0, VAR8;\nint VAR9 = -VAR10;\nstruct snd_seq_event VAR11;\nif (!(FUN2(VAR1) & VAR12))\nreturn -VAR13;\nif (FUN3(!VAR5))\nreturn -VAR13;\nif (!VAR5->VAR14 || VAR5->VAR15 == NULL)\nreturn -VAR13;\nif (VAR5->VAR15->VAR16 > 0 && !FUN4(VAR5)) {\nif (FUN5(VAR5->VAR15) < 0)\nreturn -VAR17;\n}\nwhile (VAR3 >= sizeof(struct VAR18)) {\nVAR8 = sizeof(VAR11);\nif (FUN6(&VAR11, VAR2, VAR8)) {\nVAR9 = -VAR19;\nbreak;\n}\nVAR11.VAR20.VAR5 = VAR5->VAR21;\t\nif (FUN7(&VAR11)) {\nVAR9 = -VAR10;\nbreak;\n}\nif (VAR11.VAR22 == VAR23)\ngoto VAR24;\nelse if (FUN8(&VAR11)) {\nVAR9 = -VAR10;\nbreak;\n}\nif (FUN9(&VAR11)) {\nint VAR25 = VAR11.VAR26.VAR27.VAR8 & ~VAR28;\nif ((VAR29)(VAR25 + VAR8) > VAR3) {\nVAR9 = -VAR10;\nbreak;\n}\nVAR11.VAR26.VAR27.VAR8 = VAR25 | VAR30;\nVAR11.VAR26.VAR27.VAR31 = (char VAR32 *)VAR2\n+ sizeof(struct VAR18);\nVAR8 += VAR25; \n} else {\n#ifdef VAR33\nif (VAR5->VAR34 && FUN10(&VAR11)) {\nvoid *VAR31 = (void VAR32 *)FUN11(VAR11.VAR26.VAR35.VAR36[1]);\nVAR11.VAR26.VAR27.VAR31 = VAR31;\n}\n#VAR37\n}\nVAR9 = FUN12(VAR5, &VAR11, VAR1,\n!(VAR1->VAR38 & VAR39),\n0, 0);\nif (VAR9 < 0)\nbreak;\nVAR24:\nVAR3 -= VAR8;\nVAR2 += VAR8;\nVAR7 += VAR8;\n}\nreturn VAR7 ? VAR7 : VAR9;\n}\n",
      "code_after_change_raw": "static ssize_t snd_seq_write(struct file *file, const char __user *buf,\nsize_t count, loff_t *offset)\n{\nstruct snd_seq_client *client = file->private_data;\nint written = 0, len;\nint err;\nstruct snd_seq_event event;\nif (!(snd_seq_file_flags(file) & SNDRV_SEQ_LFLG_OUTPUT))\nreturn -ENXIO;\nif (snd_BUG_ON(!client))\nreturn -ENXIO;\nif (!client->accept_output || client->pool == NULL)\nreturn -ENXIO;\nif (client->pool->size > 0 && !snd_seq_write_pool_allocated(client)) {\nmutex_lock(&client->ioctl_mutex);\nerr = snd_seq_pool_init(client->pool);\nmutex_unlock(&client->ioctl_mutex);\nif (err < 0)\nreturn -ENOMEM;\n}\nerr = -EINVAL;\nwhile (count >= sizeof(struct snd_seq_event)) {\nlen = sizeof(event);\nif (copy_from_user(&event, buf, len)) {\nerr = -EFAULT;\nbreak;\n}\nevent.source.client = client->number;\t\nif (check_event_type_and_length(&event)) {\nerr = -EINVAL;\nbreak;\n}\nif (event.type == SNDRV_SEQ_EVENT_NONE)\ngoto __skip_event;\nelse if (snd_seq_ev_is_reserved(&event)) {\nerr = -EINVAL;\nbreak;\n}\nif (snd_seq_ev_is_variable(&event)) {\nint extlen = event.data.ext.len & ~SNDRV_SEQ_EXT_MASK;\nif ((size_t)(extlen + len) > count) {\nerr = -EINVAL;\nbreak;\n}\nevent.data.ext.len = extlen | SNDRV_SEQ_EXT_USRPTR;\nevent.data.ext.ptr = (char __force *)buf\n+ sizeof(struct snd_seq_event);\nlen += extlen; \n} else {\n#ifdef CONFIG_COMPAT\nif (client->convert32 && snd_seq_ev_is_varusr(&event)) {\nvoid *ptr = (void __force *)compat_ptr(event.data.raw32.d[1]);\nevent.data.ext.ptr = ptr;\n}\n#endif\n}\nerr = snd_seq_client_enqueue_event(client, &event, file,\n!(file->f_flags & O_NONBLOCK),\n0, 0);\nif (err < 0)\nbreak;\n__skip_event:\ncount -= len;\nbuf += len;\nwritten += len;\n}\nreturn written ? written : err;\n}\n",
      "code_before_change_raw": "static ssize_t snd_seq_write(struct file *file, const char __user *buf,\nsize_t count, loff_t *offset)\n{\nstruct snd_seq_client *client = file->private_data;\nint written = 0, len;\nint err = -EINVAL;\nstruct snd_seq_event event;\nif (!(snd_seq_file_flags(file) & SNDRV_SEQ_LFLG_OUTPUT))\nreturn -ENXIO;\nif (snd_BUG_ON(!client))\nreturn -ENXIO;\nif (!client->accept_output || client->pool == NULL)\nreturn -ENXIO;\nif (client->pool->size > 0 && !snd_seq_write_pool_allocated(client)) {\nif (snd_seq_pool_init(client->pool) < 0)\nreturn -ENOMEM;\n}\nwhile (count >= sizeof(struct snd_seq_event)) {\nlen = sizeof(event);\nif (copy_from_user(&event, buf, len)) {\nerr = -EFAULT;\nbreak;\n}\nevent.source.client = client->number;\t\nif (check_event_type_and_length(&event)) {\nerr = -EINVAL;\nbreak;\n}\nif (event.type == SNDRV_SEQ_EVENT_NONE)\ngoto __skip_event;\nelse if (snd_seq_ev_is_reserved(&event)) {\nerr = -EINVAL;\nbreak;\n}\nif (snd_seq_ev_is_variable(&event)) {\nint extlen = event.data.ext.len & ~SNDRV_SEQ_EXT_MASK;\nif ((size_t)(extlen + len) > count) {\nerr = -EINVAL;\nbreak;\n}\nevent.data.ext.len = extlen | SNDRV_SEQ_EXT_USRPTR;\nevent.data.ext.ptr = (char __force *)buf\n+ sizeof(struct snd_seq_event);\nlen += extlen; \n} else {\n#ifdef CONFIG_COMPAT\nif (client->convert32 && snd_seq_ev_is_varusr(&event)) {\nvoid *ptr = (void __force *)compat_ptr(event.data.raw32.d[1]);\nevent.data.ext.ptr = ptr;\n}\n#endif\n}\nerr = snd_seq_client_enqueue_event(client, &event, file,\n!(file->f_flags & O_NONBLOCK),\n0, 0);\nif (err < 0)\nbreak;\n__skip_event:\ncount -= len;\nbuf += len;\nwritten += len;\n}\nreturn written ? written : err;\n}\n"
    }
  ],
  "CVE-2018-7740": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of page-based offset conversion in the mmap system call process.",
        "trigger_condition": "A crafted application with a large pgoff argument makes mmap system calls, leading to a potential integer overflow and denial of service vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate the page-based offset in vm_pgoff, allowing it to potentially overflow a (l)off_t when converted to a byte offset. This lack of validation can lead to unexpected behavior and system crashes."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the page-based offset in vm_pgoff is within a safe range before converting it to a byte offset. By validating the pgoff value, the code can prevent potential integer overflow issues and ensure the secure handling of mmap system calls. In this case, the solution involves adding a check to verify that the vm_pgoff value is within a safe range to prevent overflow.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2018-7740 related to the resv_map_release function in mm/hugetlb.c in the Linux kernel. The vulnerability allows local users to cause a denial of service (BUG) via a crafted application that makes mmap system calls and has a large pgoff argument to the remap_file_pages system call.\n\nThe specific change made in the code snippet is to address the potential overflow issue when converting the page-based offset in vm_pgoff to a byte offset. By checking if the vm_pgoff value is within a safe range (PGOFF_LOFFT_MAX), the code ensures that the conversion to a byte offset does not result in an overflow of the (l)off_t data type.\n\nThis modification helps prevent the vulnerability by adding a check for the validity of the pgoff value, ensuring that it does not lead to unexpected behavior or system crashes due to integer overflow. By making this adjustment, the code becomes more robust and secure against potential exploitation of the vulnerability.",
      "GPT_purpose": "Map a hugetlbfs file into a process's address space for memory mapping.",
      "GPT_function": "\n1. Map a file into a huge page-backed VMA.\n2. Set VM flags for huge pages and prevent expansion.\n3. Check for errors related to page offset alignment and length calculations.\n4. Reserve huge pages for the VMA.\n5. Update inode size if necessary.\n6. Handle locking and return appropriate error codes.",
      "CVE_id": "CVE-2018-7740",
      "code_before_change": "static int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct inode *inode = file_inode(file);\n\tloff_t len, vma_len;\n\tint ret;\n\tstruct hstate *h = hstate_file(file);\n\n\t/*\n\t * vma address alignment (but not the pgoff alignment) has\n\t * already been checked by prepare_hugepage_range.  If you add\n\t * any error returns here, do so after setting VM_HUGETLB, so\n\t * is_vm_hugetlb_page tests below unmap_region go the right\n\t * way when do_mmap_pgoff unwinds (may be important on powerpc\n\t * and ia64).\n\t */\n\tvma->vm_flags |= VM_HUGETLB | VM_DONTEXPAND;\n\tvma->vm_ops = &hugetlb_vm_ops;\n\n\t/*\n\t * Offset passed to mmap (before page shift) could have been\n\t * negative when represented as a (l)off_t.\n\t */\n\tif (((loff_t)vma->vm_pgoff << PAGE_SHIFT) < 0)\n\t\treturn -EINVAL;\n\n\tif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\n\t\treturn -EINVAL;\n\n\tvma_len = (loff_t)(vma->vm_end - vma->vm_start);\n\tlen = vma_len + ((loff_t)vma->vm_pgoff << PAGE_SHIFT);\n\t/* check for overflow */\n\tif (len < vma_len)\n\t\treturn -EINVAL;\n\n\tinode_lock(inode);\n\tfile_accessed(file);\n\n\tret = -ENOMEM;\n\tif (hugetlb_reserve_pages(inode,\n\t\t\t\tvma->vm_pgoff >> huge_page_order(h),\n\t\t\t\tlen >> huge_page_shift(h), vma,\n\t\t\t\tvma->vm_flags))\n\t\tgoto out;\n\n\tret = 0;\n\tif (vma->vm_flags & VM_WRITE && inode->i_size < len)\n\t\ti_size_write(inode, len);\nout:\n\tinode_unlock(inode);\n\n\treturn ret;\n}",
      "code_after_change": "static int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct inode *inode = file_inode(file);\n\tloff_t len, vma_len;\n\tint ret;\n\tstruct hstate *h = hstate_file(file);\n\n\t/*\n\t * vma address alignment (but not the pgoff alignment) has\n\t * already been checked by prepare_hugepage_range.  If you add\n\t * any error returns here, do so after setting VM_HUGETLB, so\n\t * is_vm_hugetlb_page tests below unmap_region go the right\n\t * way when do_mmap_pgoff unwinds (may be important on powerpc\n\t * and ia64).\n\t */\n\tvma->vm_flags |= VM_HUGETLB | VM_DONTEXPAND;\n\tvma->vm_ops = &hugetlb_vm_ops;\n\n\t/*\n\t * page based offset in vm_pgoff could be sufficiently large to\n\t * overflow a (l)off_t when converted to byte offset.\n\t */\n\tif (vma->vm_pgoff & PGOFF_LOFFT_MAX)\n\t\treturn -EINVAL;\n\n\t/* must be huge page aligned */\n\tif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\n\t\treturn -EINVAL;\n\n\tvma_len = (loff_t)(vma->vm_end - vma->vm_start);\n\tlen = vma_len + ((loff_t)vma->vm_pgoff << PAGE_SHIFT);\n\t/* check for overflow */\n\tif (len < vma_len)\n\t\treturn -EINVAL;\n\n\tinode_lock(inode);\n\tfile_accessed(file);\n\n\tret = -ENOMEM;\n\tif (hugetlb_reserve_pages(inode,\n\t\t\t\tvma->vm_pgoff >> huge_page_order(h),\n\t\t\t\tlen >> huge_page_shift(h), vma,\n\t\t\t\tvma->vm_flags))\n\t\tgoto out;\n\n\tret = 0;\n\tif (vma->vm_flags & VM_WRITE && inode->i_size < len)\n\t\ti_size_write(inode, len);\nout:\n\tinode_unlock(inode);\n\n\treturn ret;\n}",
      "modified_lines": {
        "added": [
          "\t * page based offset in vm_pgoff could be sufficiently large to",
          "\t * overflow a (l)off_t when converted to byte offset.",
          "\tif (vma->vm_pgoff & PGOFF_LOFFT_MAX)",
          "\t/* must be huge page aligned */"
        ],
        "deleted": [
          "\t * Offset passed to mmap (before page shift) could have been",
          "\t * negative when represented as a (l)off_t.",
          "\tif (((loff_t)vma->vm_pgoff << PAGE_SHIFT) < 0)"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of page-based offset conversion in the mmap system call process.",
      "trigger_condition": "A crafted application with a large pgoff argument makes mmap system calls, leading to a potential integer overflow and denial of service vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate the page-based offset in vm_pgoff, allowing it to potentially overflow a (l)off_t when converted to a byte offset. This lack of validation can lead to unexpected behavior and system crashes.",
      "id": 140,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1, struct vm_area_struct *VAR2)\n{\nstruct VAR3 *VAR3 = FUN2(VAR1);\nloff_t VAR4, VAR5;\nint VAR6;\nstruct hstate *VAR7 = FUN3(VAR1);\nVAR2->VAR8 |= VAR9 | VAR10;\nVAR2->VAR11 = &VAR12;\nif (VAR2->VAR13 & VAR14)\nreturn -VAR15;\nif (VAR2->VAR13 & (~FUN4(VAR7) >> VAR16))\nreturn -VAR15;\nVAR5 = (VAR17)(VAR2->VAR18 - VAR2->VAR19);\nVAR4 = VAR5 + ((VAR17)VAR2->VAR13 << VAR16);\nif (VAR4 < VAR5)\nreturn -VAR15;\nFUN5(VAR3);\nFUN6(VAR1);\nVAR6 = -VAR20;\nif (FUN7(VAR3,\nVAR2->VAR13 >> FUN8(VAR7),\nVAR4 >> FUN9(VAR7), VAR2,\nVAR2->VAR8))\ngoto VAR21;\nVAR6 = 0;\nif (VAR2->VAR8 & VAR22 && VAR3->VAR23 < VAR4)\nFUN10(VAR3, VAR4);\nVAR21:\nFUN11(VAR3);\nreturn VAR6;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1, struct vm_area_struct *VAR2)\n{\nstruct VAR3 *VAR3 = FUN2(VAR1);\nloff_t VAR4, VAR5;\nint VAR6;\nstruct hstate *VAR7 = FUN3(VAR1);\nVAR2->VAR8 |= VAR9 | VAR10;\nVAR2->VAR11 = &VAR12;\nif (((VAR13)VAR2->VAR14 << VAR15) < 0)\nreturn -VAR16;\nif (VAR2->VAR14 & (~FUN4(VAR7) >> VAR15))\nreturn -VAR16;\nVAR5 = (VAR13)(VAR2->VAR17 - VAR2->VAR18);\nVAR4 = VAR5 + ((VAR13)VAR2->VAR14 << VAR15);\nif (VAR4 < VAR5)\nreturn -VAR16;\nFUN5(VAR3);\nFUN6(VAR1);\nVAR6 = -VAR19;\nif (FUN7(VAR3,\nVAR2->VAR14 >> FUN8(VAR7),\nVAR4 >> FUN9(VAR7), VAR2,\nVAR2->VAR8))\ngoto VAR20;\nVAR6 = 0;\nif (VAR2->VAR8 & VAR21 && VAR3->VAR22 < VAR4)\nFUN10(VAR3, VAR4);\nVAR20:\nFUN11(VAR3);\nreturn VAR6;\n}\n",
      "code_after_change_raw": "static int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\nstruct inode *inode = file_inode(file);\nloff_t len, vma_len;\nint ret;\nstruct hstate *h = hstate_file(file);\nvma->vm_flags |= VM_HUGETLB | VM_DONTEXPAND;\nvma->vm_ops = &hugetlb_vm_ops;\nif (vma->vm_pgoff & PGOFF_LOFFT_MAX)\nreturn -EINVAL;\nif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\nreturn -EINVAL;\nvma_len = (loff_t)(vma->vm_end - vma->vm_start);\nlen = vma_len + ((loff_t)vma->vm_pgoff << PAGE_SHIFT);\nif (len < vma_len)\nreturn -EINVAL;\ninode_lock(inode);\nfile_accessed(file);\nret = -ENOMEM;\nif (hugetlb_reserve_pages(inode,\nvma->vm_pgoff >> huge_page_order(h),\nlen >> huge_page_shift(h), vma,\nvma->vm_flags))\ngoto out;\nret = 0;\nif (vma->vm_flags & VM_WRITE && inode->i_size < len)\ni_size_write(inode, len);\nout:\ninode_unlock(inode);\nreturn ret;\n}\n",
      "code_before_change_raw": "static int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\nstruct inode *inode = file_inode(file);\nloff_t len, vma_len;\nint ret;\nstruct hstate *h = hstate_file(file);\nvma->vm_flags |= VM_HUGETLB | VM_DONTEXPAND;\nvma->vm_ops = &hugetlb_vm_ops;\nif (((loff_t)vma->vm_pgoff << PAGE_SHIFT) < 0)\nreturn -EINVAL;\nif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\nreturn -EINVAL;\nvma_len = (loff_t)(vma->vm_end - vma->vm_start);\nlen = vma_len + ((loff_t)vma->vm_pgoff << PAGE_SHIFT);\nif (len < vma_len)\nreturn -EINVAL;\ninode_lock(inode);\nfile_accessed(file);\nret = -ENOMEM;\nif (hugetlb_reserve_pages(inode,\nvma->vm_pgoff >> huge_page_order(h),\nlen >> huge_page_shift(h), vma,\nvma->vm_flags))\ngoto out;\nret = 0;\nif (vma->vm_flags & VM_WRITE && inode->i_size < len)\ni_size_write(inode, len);\nout:\ninode_unlock(inode);\nreturn ret;\n}\n"
    }
  ],
  "CVE-2018-8822": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect buffer length handling in a specific function.",
        "trigger_condition": "Malicious NCPFS servers sending more data than expected during a read operation, leading to a potential buffer overflow.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly check the number of bytes read from the server against the specified length to be read, allowing for a buffer overflow situation where data can be copied beyond the allocated buffer size."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that the number of bytes read from the server does not exceed the expected length specified for reading. By verifying this condition and returning an error if the check fails, the code enforces proper bounds checking and prevents potential buffer overflow scenarios. In this case, the solution involves adding a check to compare the number of bytes read with the specified length and returning an error if the read length exceeds the expected value.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2018-8822, which involves incorrect buffer length handling in the `ncp_read_kernel` function. By adding the check `if (*bytes_read > to_read)` and setting `result` to `-EINVAL` if the condition is true, the code ensures that the number of bytes read from the server does not exceed the specified `to_read` parameter. This prevents a potential buffer overflow situation where the server could send more data than expected, leading to a crash or potential code execution in the kernel.\n\nBy verifying that the number of bytes read does not exceed the expected length, the modified code mitigates the vulnerability by enforcing proper bounds checking on the data being copied into the `target` buffer. This helps prevent malicious NCPFS servers from exploiting the vulnerability to manipulate memory beyond the allocated buffer size, thereby enhancing the security and stability of the system.",
      "GPT_purpose": "Read data from an NCP server into a target buffer with specified offset and length.",
      "GPT_function": "\n1. Read data from an NCP server using specified parameters.\n2. Initialize an NCP request and add necessary data to the request.\n3. Process the NCP request response and copy data to the target buffer.\n4. Unlock the NCP server after completing the operation.",
      "CVE_id": "CVE-2018-8822",
      "code_before_change": "int\nncp_read_kernel(struct ncp_server *server, const char *file_id,\n\t     __u32 offset, __u16 to_read, char *target, int *bytes_read)\n{\n\tconst char *source;\n\tint result;\n\n\tncp_init_request(server);\n\tncp_add_byte(server, 0);\n\tncp_add_mem(server, file_id, 6);\n\tncp_add_be32(server, offset);\n\tncp_add_be16(server, to_read);\n\n\tif ((result = ncp_request(server, 72)) != 0) {\n\t\tgoto out;\n\t}\n\t*bytes_read = ncp_reply_be16(server, 0);\n\tsource = ncp_reply_data(server, 2 + (offset & 1));\n\n\tmemcpy(target, source, *bytes_read);\nout:\n\tncp_unlock_server(server);\n\treturn result;\n}",
      "code_after_change": "int\nncp_read_kernel(struct ncp_server *server, const char *file_id,\n\t     __u32 offset, __u16 to_read, char *target, int *bytes_read)\n{\n\tconst char *source;\n\tint result;\n\n\tncp_init_request(server);\n\tncp_add_byte(server, 0);\n\tncp_add_mem(server, file_id, 6);\n\tncp_add_be32(server, offset);\n\tncp_add_be16(server, to_read);\n\n\tif ((result = ncp_request(server, 72)) != 0) {\n\t\tgoto out;\n\t}\n\t*bytes_read = ncp_reply_be16(server, 0);\n\tif (*bytes_read > to_read) {\n\t\tresult = -EINVAL;\n\t\tgoto out;\n\t}\n\tsource = ncp_reply_data(server, 2 + (offset & 1));\n\n\tmemcpy(target, source, *bytes_read);\nout:\n\tncp_unlock_server(server);\n\treturn result;\n}",
      "modified_lines": {
        "added": [
          "\tif (*bytes_read > to_read) {",
          "\t\tresult = -EINVAL;",
          "\t\tgoto out;",
          "\t}"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Incorrect buffer length handling in a specific function.",
      "trigger_condition": "Malicious NCPFS servers sending more data than expected during a read operation, leading to a potential buffer overflow.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly check the number of bytes read from the server against the specified length to be read, allowing for a buffer overflow situation where data can be copied beyond the allocated buffer size.",
      "id": 141,
      "code_after_change_normalized": "int\nFUN1(struct ncp_server *VAR1, const char *VAR2,\n__u32 VAR3, __u16 VAR4, char *VAR5, int *VAR6)\n{\nconst char *VAR7;\nint VAR8;\nFUN2(VAR1);\nFUN3(VAR1, 0);\nFUN4(VAR1, VAR2, 6);\nFUN5(VAR1, VAR3);\nFUN6(VAR1, VAR4);\nif ((VAR8 = FUN7(VAR1, 72)) != 0) {\ngoto VAR9;\n}\n*VAR6 = FUN8(VAR1, 0);\nif (*VAR6 > VAR4) {\nVAR8 = -VAR10;\ngoto VAR9;\n}\nVAR7 = FUN9(VAR1, 2 + (VAR3 & 1));\nFUN10(VAR5, VAR7, *VAR6);\nVAR9:\nFUN11(VAR1);\nreturn VAR8;\n}\n",
      "code_before_change_normalized": "int\nFUN1(struct ncp_server *VAR1, const char *VAR2,\n__u32 VAR3, __u16 VAR4, char *VAR5, int *VAR6)\n{\nconst char *VAR7;\nint VAR8;\nFUN2(VAR1);\nFUN3(VAR1, 0);\nFUN4(VAR1, VAR2, 6);\nFUN5(VAR1, VAR3);\nFUN6(VAR1, VAR4);\nif ((VAR8 = FUN7(VAR1, 72)) != 0) {\ngoto VAR9;\n}\n*VAR6 = FUN8(VAR1, 0);\nVAR7 = FUN9(VAR1, 2 + (VAR3 & 1));\nFUN10(VAR5, VAR7, *VAR6);\nVAR9:\nFUN11(VAR1);\nreturn VAR8;\n}\n",
      "code_after_change_raw": "int\nncp_read_kernel(struct ncp_server *server, const char *file_id,\n__u32 offset, __u16 to_read, char *target, int *bytes_read)\n{\nconst char *source;\nint result;\nncp_init_request(server);\nncp_add_byte(server, 0);\nncp_add_mem(server, file_id, 6);\nncp_add_be32(server, offset);\nncp_add_be16(server, to_read);\nif ((result = ncp_request(server, 72)) != 0) {\ngoto out;\n}\n*bytes_read = ncp_reply_be16(server, 0);\nif (*bytes_read > to_read) {\nresult = -EINVAL;\ngoto out;\n}\nsource = ncp_reply_data(server, 2 + (offset & 1));\nmemcpy(target, source, *bytes_read);\nout:\nncp_unlock_server(server);\nreturn result;\n}\n",
      "code_before_change_raw": "int\nncp_read_kernel(struct ncp_server *server, const char *file_id,\n__u32 offset, __u16 to_read, char *target, int *bytes_read)\n{\nconst char *source;\nint result;\nncp_init_request(server);\nncp_add_byte(server, 0);\nncp_add_mem(server, file_id, 6);\nncp_add_be32(server, offset);\nncp_add_be16(server, to_read);\nif ((result = ncp_request(server, 72)) != 0) {\ngoto out;\n}\n*bytes_read = ncp_reply_be16(server, 0);\nsource = ncp_reply_data(server, 2 + (offset & 1));\nmemcpy(target, source, *bytes_read);\nout:\nncp_unlock_server(server);\nreturn result;\n}\n"
    }
  ],
  "CVE-2019-15117": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation of descriptor length before processing.",
        "trigger_condition": "A short descriptor is encountered, leading to out-of-bounds memory access when accessing fields beyond the descriptor boundaries.",
        "specific_code_behavior_causing_vulnerability": "The code does not adequately check if the descriptor length is sufficient to accommodate the required fields, potentially allowing access to memory beyond the descriptor bounds.",
        "specific_solution_to_fix_vulnerability": "To mitigate the vulnerability, it is necessary to add a validation check to ensure that the descriptor length is at least the size of the base descriptor plus the number of input pins before proceeding with further operations. This prevents out-of-bounds memory access by verifying that the descriptor length is adequate to access the required fields."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2019-15117, which involves mishandling a short descriptor that leads to out-of-bounds memory access. By adding the condition `if (desc->bLength < sizeof(*desc) + desc->bNrInPins)` before the switch statement, the code ensures that the descriptor length is checked properly before proceeding with further operations.\n\nThis additional check ensures that the descriptor length is sufficient to accommodate the required fields, including `desc->bNrInPins`. Without this check, there is a risk of accessing memory beyond the bounds of the descriptor, which can lead to security vulnerabilities such as buffer overflows or out-of-bounds memory access.\n\nBy verifying that the descriptor length is at least `sizeof(*desc) + desc->bNrInPins`, the modified code snippet prevents potential out-of-bounds memory access issues and helps in securing the application against the identified vulnerability.",
      "GPT_purpose": "This function is used to determine the number of channels for a USB audio mixer unit based on the provided descriptor and protocol version.",
      "GPT_function": "\n1. Check if the descriptor length is less than the size of the descriptor.\n2. Check if the number of input pins is zero.\n3. Determine the number of channels based on the USB Audio Class version.\n4. Retrieve the bmControls field for the mixer unit.\n5. Perform bounds checking on the bmControls field to avoid out-of-bounds memory access.",
      "CVE_id": "CVE-2019-15117",
      "code_before_change": "static int uac_mixer_unit_get_channels(struct mixer_build *state,\n\t\t\t\t       struct uac_mixer_unit_descriptor *desc)\n{\n\tint mu_channels;\n\tvoid *c;\n\n\tif (desc->bLength < sizeof(*desc))\n\t\treturn -EINVAL;\n\tif (!desc->bNrInPins)\n\t\treturn -EINVAL;\n\n\tswitch (state->mixer->protocol) {\n\tcase UAC_VERSION_1:\n\tcase UAC_VERSION_2:\n\tdefault:\n\t\tif (desc->bLength < sizeof(*desc) + desc->bNrInPins + 1)\n\t\t\treturn 0; /* no bmControls -> skip */\n\t\tmu_channels = uac_mixer_unit_bNrChannels(desc);\n\t\tbreak;\n\tcase UAC_VERSION_3:\n\t\tmu_channels = get_cluster_channels_v3(state,\n\t\t\t\tuac3_mixer_unit_wClusterDescrID(desc));\n\t\tbreak;\n\t}\n\n\tif (!mu_channels)\n\t\treturn 0;\n\n\tc = uac_mixer_unit_bmControls(desc, state->mixer->protocol);\n\tif (c - (void *)desc + (mu_channels - 1) / 8 >= desc->bLength)\n\t\treturn 0; /* no bmControls -> skip */\n\n\treturn mu_channels;\n}",
      "code_after_change": "static int uac_mixer_unit_get_channels(struct mixer_build *state,\n\t\t\t\t       struct uac_mixer_unit_descriptor *desc)\n{\n\tint mu_channels;\n\tvoid *c;\n\n\tif (desc->bLength < sizeof(*desc))\n\t\treturn -EINVAL;\n\tif (!desc->bNrInPins)\n\t\treturn -EINVAL;\n\tif (desc->bLength < sizeof(*desc) + desc->bNrInPins)\n\t\treturn -EINVAL;\n\n\tswitch (state->mixer->protocol) {\n\tcase UAC_VERSION_1:\n\tcase UAC_VERSION_2:\n\tdefault:\n\t\tif (desc->bLength < sizeof(*desc) + desc->bNrInPins + 1)\n\t\t\treturn 0; /* no bmControls -> skip */\n\t\tmu_channels = uac_mixer_unit_bNrChannels(desc);\n\t\tbreak;\n\tcase UAC_VERSION_3:\n\t\tmu_channels = get_cluster_channels_v3(state,\n\t\t\t\tuac3_mixer_unit_wClusterDescrID(desc));\n\t\tbreak;\n\t}\n\n\tif (!mu_channels)\n\t\treturn 0;\n\n\tc = uac_mixer_unit_bmControls(desc, state->mixer->protocol);\n\tif (c - (void *)desc + (mu_channels - 1) / 8 >= desc->bLength)\n\t\treturn 0; /* no bmControls -> skip */\n\n\treturn mu_channels;\n}",
      "modified_lines": {
        "added": [
          "\t\treturn -EINVAL;",
          "\tif (desc->bLength < sizeof(*desc) + desc->bNrInPins)"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper validation of descriptor length before processing.",
      "trigger_condition": "A short descriptor is encountered, leading to out-of-bounds memory access when accessing fields beyond the descriptor boundaries.",
      "specific_code_behavior_causing_vulnerability": "The code does not adequately check if the descriptor length is sufficient to accommodate the required fields, potentially allowing access to memory beyond the descriptor bounds.",
      "id": 142,
      "code_after_change_normalized": "static int FUN1(struct mixer_build *VAR1,\nstruct uac_mixer_unit_descriptor *VAR2)\n{\nint VAR3;\nvoid *VAR4;\nif (VAR2->VAR5 < sizeof(*VAR2))\nreturn -VAR6;\nif (!VAR2->VAR7)\nreturn -VAR6;\nif (VAR2->VAR5 < sizeof(*VAR2) + VAR2->VAR7)\nreturn -VAR6;\nswitch (VAR1->VAR8->VAR9) {\ncase VAR10:\ncase VAR11:\ndefault:\nif (VAR2->VAR5 < sizeof(*VAR2) + VAR2->VAR7 + 1)\nreturn 0; \nVAR3 = FUN2(VAR2);\nbreak;\ncase VAR12:\nVAR3 = FUN3(VAR1,\nFUN4(VAR2));\nbreak;\n}\nif (!VAR3)\nreturn 0;\nVAR4 = FUN5(VAR2, VAR1->VAR8->VAR9);\nif (VAR4 - (void *)VAR2 + (VAR3 - 1) / 8 >= VAR2->VAR5)\nreturn 0; \nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct mixer_build *VAR1,\nstruct uac_mixer_unit_descriptor *VAR2)\n{\nint VAR3;\nvoid *VAR4;\nif (VAR2->VAR5 < sizeof(*VAR2))\nreturn -VAR6;\nif (!VAR2->VAR7)\nreturn -VAR6;\nswitch (VAR1->VAR8->VAR9) {\ncase VAR10:\ncase VAR11:\ndefault:\nif (VAR2->VAR5 < sizeof(*VAR2) + VAR2->VAR7 + 1)\nreturn 0; \nVAR3 = FUN2(VAR2);\nbreak;\ncase VAR12:\nVAR3 = FUN3(VAR1,\nFUN4(VAR2));\nbreak;\n}\nif (!VAR3)\nreturn 0;\nVAR4 = FUN5(VAR2, VAR1->VAR8->VAR9);\nif (VAR4 - (void *)VAR2 + (VAR3 - 1) / 8 >= VAR2->VAR5)\nreturn 0; \nreturn VAR3;\n}\n",
      "code_after_change_raw": "static int uac_mixer_unit_get_channels(struct mixer_build *state,\nstruct uac_mixer_unit_descriptor *desc)\n{\nint mu_channels;\nvoid *c;\nif (desc->bLength < sizeof(*desc))\nreturn -EINVAL;\nif (!desc->bNrInPins)\nreturn -EINVAL;\nif (desc->bLength < sizeof(*desc) + desc->bNrInPins)\nreturn -EINVAL;\nswitch (state->mixer->protocol) {\ncase UAC_VERSION_1:\ncase UAC_VERSION_2:\ndefault:\nif (desc->bLength < sizeof(*desc) + desc->bNrInPins + 1)\nreturn 0; \nmu_channels = uac_mixer_unit_bNrChannels(desc);\nbreak;\ncase UAC_VERSION_3:\nmu_channels = get_cluster_channels_v3(state,\nuac3_mixer_unit_wClusterDescrID(desc));\nbreak;\n}\nif (!mu_channels)\nreturn 0;\nc = uac_mixer_unit_bmControls(desc, state->mixer->protocol);\nif (c - (void *)desc + (mu_channels - 1) / 8 >= desc->bLength)\nreturn 0; \nreturn mu_channels;\n}\n",
      "code_before_change_raw": "static int uac_mixer_unit_get_channels(struct mixer_build *state,\nstruct uac_mixer_unit_descriptor *desc)\n{\nint mu_channels;\nvoid *c;\nif (desc->bLength < sizeof(*desc))\nreturn -EINVAL;\nif (!desc->bNrInPins)\nreturn -EINVAL;\nswitch (state->mixer->protocol) {\ncase UAC_VERSION_1:\ncase UAC_VERSION_2:\ndefault:\nif (desc->bLength < sizeof(*desc) + desc->bNrInPins + 1)\nreturn 0; \nmu_channels = uac_mixer_unit_bNrChannels(desc);\nbreak;\ncase UAC_VERSION_3:\nmu_channels = get_cluster_channels_v3(state,\nuac3_mixer_unit_wClusterDescrID(desc));\nbreak;\n}\nif (!mu_channels)\nreturn 0;\nc = uac_mixer_unit_bmControls(desc, state->mixer->protocol);\nif (c - (void *)desc + (mu_channels - 1) / 8 >= desc->bLength)\nreturn 0; \nreturn mu_channels;\n}\n"
    }
  ],
  "CVE-2019-19602": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Incorrect caching of fpu_fpregs_owner_ctx in the code.",
        "trigger_condition": "Usage of the incorrect fpu_fpregs_owner_ctx caching when GCC 9 is used.",
        "specific_code_behavior_causing_vulnerability": "The code relies on the stable read of fpu_fpregs_owner_ctx using this_cpu_read_stable, which can lead to memory corruption or other unspecified impacts due to mishandling of signal-based non-cooperative preemption.",
        "solution": "To mitigate the vulnerability, it is necessary to read fpu_fpregs_owner_ctx directly from the current CPU's context using this_cpu_read. This change ensures that the cached value is up-to-date and prevents potential issues related to signal-based preemption scenarios."
      },
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2019-19602. The vulnerability arises due to incorrect caching of fpu_fpregs_owner_ctx, leading to a potential denial of service (memory corruption) or other unspecified impacts.\n\nBy changing `this_cpu_read_stable` to `this_cpu_read`, the code ensures that the fpu_fpregs_owner_ctx is read directly from the current CPU's context without relying on potentially stale or incorrect cached values. This change helps prevent the mishandling of signal-based non-cooperative preemption scenarios, which could lead to memory corruption or other issues.\n\nTherefore, the modification is crucial to mitigate the vulnerability and improve the reliability and security of the code.",
      "GPT_purpose": "Check if the FPU register state is valid for a specific CPU.",
      "GPT_function": "\n1. Check if the fpu register state is valid.\n2. Verify if the fpu belongs to the current CPU.\n3. Ensure correct caching of fpu_fpregs_owner_ctx.",
      "CVE_id": "CVE-2019-19602",
      "code_before_change": "static inline int fpregs_state_valid(struct fpu *fpu, unsigned int cpu)\n{\n\treturn fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n}",
      "code_after_change": "static inline int fpregs_state_valid(struct fpu *fpu, unsigned int cpu)\n{\n\treturn fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n}",
      "modified_lines": {
        "added": [
          "\treturn fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;"
        ],
        "deleted": [
          "\treturn fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;"
        ]
      },
      "preconditions_for_vulnerability": "Incorrect caching of fpu_fpregs_owner_ctx in the code.",
      "trigger_condition": "Usage of the incorrect fpu_fpregs_owner_ctx caching when GCC 9 is used.",
      "specific_code_behavior_causing_vulnerability": "The code relies on the stable read of fpu_fpregs_owner_ctx using this_cpu_read_stable, which can lead to memory corruption or other unspecified impacts due to mishandling of signal-based non-cooperative preemption.",
      "solution": "To mitigate the vulnerability, it is necessary to read fpu_fpregs_owner_ctx directly from the current CPU's context using this_cpu_read. This change ensures that the cached value is up-to-date and prevents potential issues related to signal-based preemption scenarios.",
      "id": 143,
      "code_after_change_normalized": "static inline int FUN1(struct VAR1 *VAR1, unsigned int VAR2)\n{\nreturn VAR1 == FUN2(VAR3) && VAR2 == VAR1->VAR4;\n}\n",
      "code_before_change_normalized": "static inline int FUN1(struct VAR1 *VAR1, unsigned int VAR2)\n{\nreturn VAR1 == FUN2(VAR3) && VAR2 == VAR1->VAR4;\n}\n",
      "code_after_change_raw": "static inline int fpregs_state_valid(struct fpu *fpu, unsigned int cpu)\n{\nreturn fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n}\n",
      "code_before_change_raw": "static inline int fpregs_state_valid(struct fpu *fpu, unsigned int cpu)\n{\nreturn fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n}\n"
    }
  ],
  "CVE-2020-10757": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of DAX Huge Pages in the Linux Kernel code.",
        "trigger_condition": "A local attacker with access to a DAX enabled storage escalates their privileges by exploiting the vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly handle DAX Huge Pages, allowing a local attacker to escalate their privileges on the system."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a condition to check for device-mapped pages in addition to existing checks related to Huge Pages. This ensures that the code correctly identifies and handles DAX Huge Pages, preventing privilege escalation by attackers with access to DAX enabled storage.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2020-10757 related to handling DAX Huge Pages in the Linux Kernel. By adding the condition `pmd_devmap(*old_pmd)` to the existing check, the code now properly handles the case where the page table entry refers to a device-mapped page. This modification ensures that the privilege escalation issue associated with DAX Huge Pages is mitigated, thereby enhancing the security of the system.",
      "GPT_purpose": "Move page tables from one virtual memory area to another, potentially allocating new page tables and handling huge pages.",
      "GPT_function": "\n1. move_page_tables: Moves page tables from one virtual memory area to another, potentially allocating new page tables and handling huge pages.",
      "CVE_id": "CVE-2020-10757",
      "code_before_change": "unsigned long move_page_tables(struct vm_area_struct *vma,\n\t\tunsigned long old_addr, struct vm_area_struct *new_vma,\n\t\tunsigned long new_addr, unsigned long len,\n\t\tbool need_rmap_locks)\n{\n\tunsigned long extent, next, old_end;\n\tstruct mmu_notifier_range range;\n\tpmd_t *old_pmd, *new_pmd;\n\n\told_end = old_addr + len;\n\tflush_cache_range(vma, old_addr, old_end);\n\n\tmmu_notifier_range_init(&range, MMU_NOTIFY_UNMAP, 0, vma, vma->vm_mm,\n\t\t\t\told_addr, old_end);\n\tmmu_notifier_invalidate_range_start(&range);\n\n\tfor (; old_addr < old_end; old_addr += extent, new_addr += extent) {\n\t\tcond_resched();\n\t\tnext = (old_addr + PMD_SIZE) & PMD_MASK;\n\t\t/* even if next overflowed, extent below will be ok */\n\t\textent = next - old_addr;\n\t\tif (extent > old_end - old_addr)\n\t\t\textent = old_end - old_addr;\n\t\told_pmd = get_old_pmd(vma->vm_mm, old_addr);\n\t\tif (!old_pmd)\n\t\t\tcontinue;\n\t\tnew_pmd = alloc_new_pmd(vma->vm_mm, vma, new_addr);\n\t\tif (!new_pmd)\n\t\t\tbreak;\n\t\tif (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd)) {\n\t\t\tif (extent == HPAGE_PMD_SIZE) {\n\t\t\t\tbool moved;\n\t\t\t\t/* See comment in move_ptes() */\n\t\t\t\tif (need_rmap_locks)\n\t\t\t\t\ttake_rmap_locks(vma);\n\t\t\t\tmoved = move_huge_pmd(vma, old_addr, new_addr,\n\t\t\t\t\t\t    old_end, old_pmd, new_pmd);\n\t\t\t\tif (need_rmap_locks)\n\t\t\t\t\tdrop_rmap_locks(vma);\n\t\t\t\tif (moved)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tsplit_huge_pmd(vma, old_pmd, old_addr);\n\t\t\tif (pmd_trans_unstable(old_pmd))\n\t\t\t\tcontinue;\n\t\t} else if (extent == PMD_SIZE) {\n#ifdef CONFIG_HAVE_MOVE_PMD\n\t\t\t/*\n\t\t\t * If the extent is PMD-sized, try to speed the move by\n\t\t\t * moving at the PMD level if possible.\n\t\t\t */\n\t\t\tbool moved;\n\n\t\t\tif (need_rmap_locks)\n\t\t\t\ttake_rmap_locks(vma);\n\t\t\tmoved = move_normal_pmd(vma, old_addr, new_addr,\n\t\t\t\t\told_end, old_pmd, new_pmd);\n\t\t\tif (need_rmap_locks)\n\t\t\t\tdrop_rmap_locks(vma);\n\t\t\tif (moved)\n\t\t\t\tcontinue;\n#endif\n\t\t}\n\n\t\tif (pte_alloc(new_vma->vm_mm, new_pmd))\n\t\t\tbreak;\n\t\tnext = (new_addr + PMD_SIZE) & PMD_MASK;\n\t\tif (extent > next - new_addr)\n\t\t\textent = next - new_addr;\n\t\tmove_ptes(vma, old_pmd, old_addr, old_addr + extent, new_vma,\n\t\t\t  new_pmd, new_addr, need_rmap_locks);\n\t}\n\n\tmmu_notifier_invalidate_range_end(&range);\n\n\treturn len + old_addr - old_end;\t/* how much done */\n}",
      "code_after_change": "unsigned long move_page_tables(struct vm_area_struct *vma,\n\t\tunsigned long old_addr, struct vm_area_struct *new_vma,\n\t\tunsigned long new_addr, unsigned long len,\n\t\tbool need_rmap_locks)\n{\n\tunsigned long extent, next, old_end;\n\tstruct mmu_notifier_range range;\n\tpmd_t *old_pmd, *new_pmd;\n\n\told_end = old_addr + len;\n\tflush_cache_range(vma, old_addr, old_end);\n\n\tmmu_notifier_range_init(&range, MMU_NOTIFY_UNMAP, 0, vma, vma->vm_mm,\n\t\t\t\told_addr, old_end);\n\tmmu_notifier_invalidate_range_start(&range);\n\n\tfor (; old_addr < old_end; old_addr += extent, new_addr += extent) {\n\t\tcond_resched();\n\t\tnext = (old_addr + PMD_SIZE) & PMD_MASK;\n\t\t/* even if next overflowed, extent below will be ok */\n\t\textent = next - old_addr;\n\t\tif (extent > old_end - old_addr)\n\t\t\textent = old_end - old_addr;\n\t\told_pmd = get_old_pmd(vma->vm_mm, old_addr);\n\t\tif (!old_pmd)\n\t\t\tcontinue;\n\t\tnew_pmd = alloc_new_pmd(vma->vm_mm, vma, new_addr);\n\t\tif (!new_pmd)\n\t\t\tbreak;\n\t\tif (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd) || pmd_devmap(*old_pmd)) {\n\t\t\tif (extent == HPAGE_PMD_SIZE) {\n\t\t\t\tbool moved;\n\t\t\t\t/* See comment in move_ptes() */\n\t\t\t\tif (need_rmap_locks)\n\t\t\t\t\ttake_rmap_locks(vma);\n\t\t\t\tmoved = move_huge_pmd(vma, old_addr, new_addr,\n\t\t\t\t\t\t    old_end, old_pmd, new_pmd);\n\t\t\t\tif (need_rmap_locks)\n\t\t\t\t\tdrop_rmap_locks(vma);\n\t\t\t\tif (moved)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tsplit_huge_pmd(vma, old_pmd, old_addr);\n\t\t\tif (pmd_trans_unstable(old_pmd))\n\t\t\t\tcontinue;\n\t\t} else if (extent == PMD_SIZE) {\n#ifdef CONFIG_HAVE_MOVE_PMD\n\t\t\t/*\n\t\t\t * If the extent is PMD-sized, try to speed the move by\n\t\t\t * moving at the PMD level if possible.\n\t\t\t */\n\t\t\tbool moved;\n\n\t\t\tif (need_rmap_locks)\n\t\t\t\ttake_rmap_locks(vma);\n\t\t\tmoved = move_normal_pmd(vma, old_addr, new_addr,\n\t\t\t\t\told_end, old_pmd, new_pmd);\n\t\t\tif (need_rmap_locks)\n\t\t\t\tdrop_rmap_locks(vma);\n\t\t\tif (moved)\n\t\t\t\tcontinue;\n#endif\n\t\t}\n\n\t\tif (pte_alloc(new_vma->vm_mm, new_pmd))\n\t\t\tbreak;\n\t\tnext = (new_addr + PMD_SIZE) & PMD_MASK;\n\t\tif (extent > next - new_addr)\n\t\t\textent = next - new_addr;\n\t\tmove_ptes(vma, old_pmd, old_addr, old_addr + extent, new_vma,\n\t\t\t  new_pmd, new_addr, need_rmap_locks);\n\t}\n\n\tmmu_notifier_invalidate_range_end(&range);\n\n\treturn len + old_addr - old_end;\t/* how much done */\n}",
      "modified_lines": {
        "added": [
          "\t\tif (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd) || pmd_devmap(*old_pmd)) {"
        ],
        "deleted": [
          "\t\tif (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd)) {"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of DAX Huge Pages in the Linux Kernel code.",
      "trigger_condition": "A local attacker with access to a DAX enabled storage escalates their privileges by exploiting the vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly handle DAX Huge Pages, allowing a local attacker to escalate their privileges on the system.",
      "id": 144,
      "code_after_change_normalized": "unsigned long FUN1(struct vm_area_struct *VAR1,\nunsigned long VAR2, struct vm_area_struct *VAR3,\nunsigned long VAR4, unsigned long VAR5,\nbool VAR6)\n{\nunsigned long VAR7, VAR8, VAR9;\nstruct mmu_notifier_range VAR10;\npmd_t *VAR11, *VAR12;\nVAR9 = VAR2 + VAR5;\nFUN2(VAR1, VAR2, VAR9);\nFUN3(&VAR10, VAR13, 0, VAR1, VAR1->VAR14,\nVAR2, VAR9);\nFUN4(&VAR10);\nfor (; VAR2 < VAR9; VAR2 += VAR7, VAR4 += VAR7) {\nFUN5();\nVAR8 = (VAR2 + VAR15) & VAR16;\nVAR7 = VAR8 - VAR2;\nif (VAR7 > VAR9 - VAR2)\nVAR7 = VAR9 - VAR2;\nVAR11 = FUN6(VAR1->VAR14, VAR2);\nif (!VAR11)\ncontinue;\nVAR12 = FUN7(VAR1->VAR14, VAR1, VAR4);\nif (!VAR12)\nbreak;\nif (FUN8(*VAR11) || FUN9(*VAR11) || FUN10(*VAR11)) {\nif (VAR7 == VAR17) {\nbool VAR18;\nif (VAR6)\nFUN11(VAR1);\nVAR18 = FUN12(VAR1, VAR2, VAR4,\nVAR9, VAR11, VAR12);\nif (VAR6)\nFUN13(VAR1);\nif (VAR18)\ncontinue;\n}\nFUN14(VAR1, VAR11, VAR2);\nif (FUN15(VAR11))\ncontinue;\n} else if (VAR7 == VAR15) {\n#ifdef VAR19\nbool VAR18;\nif (VAR6)\nFUN11(VAR1);\nVAR18 = FUN16(VAR1, VAR2, VAR4,\nVAR9, VAR11, VAR12);\nif (VAR6)\nFUN13(VAR1);\nif (VAR18)\ncontinue;\n#VAR20\n}\nif (FUN17(VAR3->VAR14, VAR12))\nbreak;\nVAR8 = (VAR4 + VAR15) & VAR16;\nif (VAR7 > VAR8 - VAR4)\nVAR7 = VAR8 - VAR4;\nFUN18(VAR1, VAR11, VAR2, VAR2 + VAR7, VAR3,\nVAR12, VAR4, VAR6);\n}\nFUN19(&VAR10);\nreturn VAR5 + VAR2 - VAR9;\t\n}\n",
      "code_before_change_normalized": "unsigned long FUN1(struct vm_area_struct *VAR1,\nunsigned long VAR2, struct vm_area_struct *VAR3,\nunsigned long VAR4, unsigned long VAR5,\nbool VAR6)\n{\nunsigned long VAR7, VAR8, VAR9;\nstruct mmu_notifier_range VAR10;\npmd_t *VAR11, *VAR12;\nVAR9 = VAR2 + VAR5;\nFUN2(VAR1, VAR2, VAR9);\nFUN3(&VAR10, VAR13, 0, VAR1, VAR1->VAR14,\nVAR2, VAR9);\nFUN4(&VAR10);\nfor (; VAR2 < VAR9; VAR2 += VAR7, VAR4 += VAR7) {\nFUN5();\nVAR8 = (VAR2 + VAR15) & VAR16;\nVAR7 = VAR8 - VAR2;\nif (VAR7 > VAR9 - VAR2)\nVAR7 = VAR9 - VAR2;\nVAR11 = FUN6(VAR1->VAR14, VAR2);\nif (!VAR11)\ncontinue;\nVAR12 = FUN7(VAR1->VAR14, VAR1, VAR4);\nif (!VAR12)\nbreak;\nif (FUN8(*VAR11) || FUN9(*VAR11)) {\nif (VAR7 == VAR17) {\nbool VAR18;\nif (VAR6)\nFUN10(VAR1);\nVAR18 = FUN11(VAR1, VAR2, VAR4,\nVAR9, VAR11, VAR12);\nif (VAR6)\nFUN12(VAR1);\nif (VAR18)\ncontinue;\n}\nFUN13(VAR1, VAR11, VAR2);\nif (FUN14(VAR11))\ncontinue;\n} else if (VAR7 == VAR15) {\n#ifdef VAR19\nbool VAR18;\nif (VAR6)\nFUN10(VAR1);\nVAR18 = FUN15(VAR1, VAR2, VAR4,\nVAR9, VAR11, VAR12);\nif (VAR6)\nFUN12(VAR1);\nif (VAR18)\ncontinue;\n#VAR20\n}\nif (FUN16(VAR3->VAR14, VAR12))\nbreak;\nVAR8 = (VAR4 + VAR15) & VAR16;\nif (VAR7 > VAR8 - VAR4)\nVAR7 = VAR8 - VAR4;\nFUN17(VAR1, VAR11, VAR2, VAR2 + VAR7, VAR3,\nVAR12, VAR4, VAR6);\n}\nFUN18(&VAR10);\nreturn VAR5 + VAR2 - VAR9;\t\n}\n",
      "code_after_change_raw": "unsigned long move_page_tables(struct vm_area_struct *vma,\nunsigned long old_addr, struct vm_area_struct *new_vma,\nunsigned long new_addr, unsigned long len,\nbool need_rmap_locks)\n{\nunsigned long extent, next, old_end;\nstruct mmu_notifier_range range;\npmd_t *old_pmd, *new_pmd;\nold_end = old_addr + len;\nflush_cache_range(vma, old_addr, old_end);\nmmu_notifier_range_init(&range, MMU_NOTIFY_UNMAP, 0, vma, vma->vm_mm,\nold_addr, old_end);\nmmu_notifier_invalidate_range_start(&range);\nfor (; old_addr < old_end; old_addr += extent, new_addr += extent) {\ncond_resched();\nnext = (old_addr + PMD_SIZE) & PMD_MASK;\nextent = next - old_addr;\nif (extent > old_end - old_addr)\nextent = old_end - old_addr;\nold_pmd = get_old_pmd(vma->vm_mm, old_addr);\nif (!old_pmd)\ncontinue;\nnew_pmd = alloc_new_pmd(vma->vm_mm, vma, new_addr);\nif (!new_pmd)\nbreak;\nif (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd) || pmd_devmap(*old_pmd)) {\nif (extent == HPAGE_PMD_SIZE) {\nbool moved;\nif (need_rmap_locks)\ntake_rmap_locks(vma);\nmoved = move_huge_pmd(vma, old_addr, new_addr,\nold_end, old_pmd, new_pmd);\nif (need_rmap_locks)\ndrop_rmap_locks(vma);\nif (moved)\ncontinue;\n}\nsplit_huge_pmd(vma, old_pmd, old_addr);\nif (pmd_trans_unstable(old_pmd))\ncontinue;\n} else if (extent == PMD_SIZE) {\n#ifdef CONFIG_HAVE_MOVE_PMD\nbool moved;\nif (need_rmap_locks)\ntake_rmap_locks(vma);\nmoved = move_normal_pmd(vma, old_addr, new_addr,\nold_end, old_pmd, new_pmd);\nif (need_rmap_locks)\ndrop_rmap_locks(vma);\nif (moved)\ncontinue;\n#endif\n}\nif (pte_alloc(new_vma->vm_mm, new_pmd))\nbreak;\nnext = (new_addr + PMD_SIZE) & PMD_MASK;\nif (extent > next - new_addr)\nextent = next - new_addr;\nmove_ptes(vma, old_pmd, old_addr, old_addr + extent, new_vma,\nnew_pmd, new_addr, need_rmap_locks);\n}\nmmu_notifier_invalidate_range_end(&range);\nreturn len + old_addr - old_end;\t\n}\n",
      "code_before_change_raw": "unsigned long move_page_tables(struct vm_area_struct *vma,\nunsigned long old_addr, struct vm_area_struct *new_vma,\nunsigned long new_addr, unsigned long len,\nbool need_rmap_locks)\n{\nunsigned long extent, next, old_end;\nstruct mmu_notifier_range range;\npmd_t *old_pmd, *new_pmd;\nold_end = old_addr + len;\nflush_cache_range(vma, old_addr, old_end);\nmmu_notifier_range_init(&range, MMU_NOTIFY_UNMAP, 0, vma, vma->vm_mm,\nold_addr, old_end);\nmmu_notifier_invalidate_range_start(&range);\nfor (; old_addr < old_end; old_addr += extent, new_addr += extent) {\ncond_resched();\nnext = (old_addr + PMD_SIZE) & PMD_MASK;\nextent = next - old_addr;\nif (extent > old_end - old_addr)\nextent = old_end - old_addr;\nold_pmd = get_old_pmd(vma->vm_mm, old_addr);\nif (!old_pmd)\ncontinue;\nnew_pmd = alloc_new_pmd(vma->vm_mm, vma, new_addr);\nif (!new_pmd)\nbreak;\nif (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd)) {\nif (extent == HPAGE_PMD_SIZE) {\nbool moved;\nif (need_rmap_locks)\ntake_rmap_locks(vma);\nmoved = move_huge_pmd(vma, old_addr, new_addr,\nold_end, old_pmd, new_pmd);\nif (need_rmap_locks)\ndrop_rmap_locks(vma);\nif (moved)\ncontinue;\n}\nsplit_huge_pmd(vma, old_pmd, old_addr);\nif (pmd_trans_unstable(old_pmd))\ncontinue;\n} else if (extent == PMD_SIZE) {\n#ifdef CONFIG_HAVE_MOVE_PMD\nbool moved;\nif (need_rmap_locks)\ntake_rmap_locks(vma);\nmoved = move_normal_pmd(vma, old_addr, new_addr,\nold_end, old_pmd, new_pmd);\nif (need_rmap_locks)\ndrop_rmap_locks(vma);\nif (moved)\ncontinue;\n#endif\n}\nif (pte_alloc(new_vma->vm_mm, new_pmd))\nbreak;\nnext = (new_addr + PMD_SIZE) & PMD_MASK;\nif (extent > next - new_addr)\nextent = next - new_addr;\nmove_ptes(vma, old_pmd, old_addr, old_addr + extent, new_vma,\nnew_pmd, new_addr, need_rmap_locks);\n}\nmmu_notifier_invalidate_range_end(&range);\nreturn len + old_addr - old_end;\t\n}\n"
    }
  ],
  "CVE-2021-22543": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of VM_IO|VM_PFNMAP vmas in KVM.",
        "trigger_condition": "Accessing pages backed with valid struct pages but allocated without proper refcounting, leading to potential memory corruption and unauthorized access.",
        "specific_code_behavior_causing_vulnerability": "The code does not perform a check to ensure that the page frame number (PFN) obtained is valid before accessing it, allowing for potential underflow of the refcount when the caller does the required put_page."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to verify the validity of the PFN obtained before accessing the page. This check ensures that pages backed with valid struct pages but allocated without proper refcounting are not accessed, preventing potential memory corruption and unauthorized access. In this case, the solution involves adding a check to verify the validity of the PFN obtained and returning an error code if the PFN is not valid.",
      "GPT_analysis": "The above modification is necessary to address the vulnerability CVE-2021-22543 in the code snippet. The vulnerability arises from improper handling of VM_IO|VM_PFNMAP vmas in KVM, which can bypass read-only (RO) checks and lead to pages being freed while still accessible by the VMM and guest. This vulnerability allows users with the ability to start and control a VM to read/write random pages of memory, potentially resulting in local privilege escalation.\n\nThe modification addresses this vulnerability by adding the following lines:\n```\nif (!kvm_try_get_pfn(pfn))\n    r = -EFAULT;\n```\nThese lines check if the page frame number (PFN) obtained is valid and can be safely referenced. If the PFN is not valid, the function returns an error code (-EFAULT) to indicate the issue. This additional check ensures that pages backed with valid struct pages but allocated without proper refcounting are not accessed, preventing potential memory corruption and unauthorized access.\n\nBy incorporating this modification, the code enhances the security and integrity of the system by preventing unauthorized access to memory pages and mitigating the risk of local privilege escalation through the described vulnerability.",
      "GPT_purpose": "This function is used to translate a guest virtual address to a physical frame number (PFN) in a remapped memory area for Kernel-based Virtual Machine (KVM) operations.",
      "GPT_function": "\n1. Retrieve the physical frame number (PFN) of a given virtual address in a remapped memory area.\n2. Handle faults and fix them if necessary during the PFN retrieval process.\n3. Ensure proper permissions for accessing the PFN and handle cases where the page is read-only.",
      "CVE_id": "CVE-2021-22543",
      "code_before_change": "static int hva_to_pfn_remapped(struct vm_area_struct *vma,\n\t\t\t       unsigned long addr, bool *async,\n\t\t\t       bool write_fault, bool *writable,\n\t\t\t       kvm_pfn_t *p_pfn)\n{\n\tkvm_pfn_t pfn;\n\tpte_t *ptep;\n\tspinlock_t *ptl;\n\tint r;\n\n\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\tif (r) {\n\t\t/*\n\t\t * get_user_pages fails for VM_IO and VM_PFNMAP vmas and does\n\t\t * not call the fault handler, so do it here.\n\t\t */\n\t\tbool unlocked = false;\n\t\tr = fixup_user_fault(current->mm, addr,\n\t\t\t\t     (write_fault ? FAULT_FLAG_WRITE : 0),\n\t\t\t\t     &unlocked);\n\t\tif (unlocked)\n\t\t\treturn -EAGAIN;\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tif (write_fault && !pte_write(*ptep)) {\n\t\tpfn = KVM_PFN_ERR_RO_FAULT;\n\t\tgoto out;\n\t}\n\n\tif (writable)\n\t\t*writable = pte_write(*ptep);\n\tpfn = pte_pfn(*ptep);\n\n\t/*\n\t * Get a reference here because callers of *hva_to_pfn* and\n\t * *gfn_to_pfn* ultimately call kvm_release_pfn_clean on the\n\t * returned pfn.  This is only needed if the VMA has VM_MIXEDMAP\n\t * set, but the kvm_get_pfn/kvm_release_pfn_clean pair will\n\t * simply do nothing for reserved pfns.\n\t *\n\t * Whoever called remap_pfn_range is also going to call e.g.\n\t * unmap_mapping_range before the underlying pages are freed,\n\t * causing a call to our MMU notifier.\n\t */ \n\tkvm_get_pfn(pfn);\n\nout:\n\tpte_unmap_unlock(ptep, ptl);\n\t*p_pfn = pfn;\n\treturn 0;\n}",
      "code_after_change": "static int hva_to_pfn_remapped(struct vm_area_struct *vma,\n\t\t\t       unsigned long addr, bool *async,\n\t\t\t       bool write_fault, bool *writable,\n\t\t\t       kvm_pfn_t *p_pfn)\n{\n\tkvm_pfn_t pfn;\n\tpte_t *ptep;\n\tspinlock_t *ptl;\n\tint r;\n\n\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\tif (r) {\n\t\t/*\n\t\t * get_user_pages fails for VM_IO and VM_PFNMAP vmas and does\n\t\t * not call the fault handler, so do it here.\n\t\t */\n\t\tbool unlocked = false;\n\t\tr = fixup_user_fault(current->mm, addr,\n\t\t\t\t     (write_fault ? FAULT_FLAG_WRITE : 0),\n\t\t\t\t     &unlocked);\n\t\tif (unlocked)\n\t\t\treturn -EAGAIN;\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tif (write_fault && !pte_write(*ptep)) {\n\t\tpfn = KVM_PFN_ERR_RO_FAULT;\n\t\tgoto out;\n\t}\n\n\tif (writable)\n\t\t*writable = pte_write(*ptep);\n\tpfn = pte_pfn(*ptep);\n\n\t/*\n\t * Get a reference here because callers of *hva_to_pfn* and\n\t * *gfn_to_pfn* ultimately call kvm_release_pfn_clean on the\n\t * returned pfn.  This is only needed if the VMA has VM_MIXEDMAP\n\t * set, but the kvm_get_pfn/kvm_release_pfn_clean pair will\n\t * simply do nothing for reserved pfns.\n\t *\n\t * Whoever called remap_pfn_range is also going to call e.g.\n\t * unmap_mapping_range before the underlying pages are freed,\n\t * causing a call to our MMU notifier.\n\t *\n\t * Certain IO or PFNMAP mappings can be backed with valid\n\t * struct pages, but be allocated without refcounting e.g.,\n\t * tail pages of non-compound higher order allocations, which\n\t * would then underflow the refcount when the caller does the\n\t * required put_page. Don't allow those pages here.\n\t */ \n\tif (!kvm_try_get_pfn(pfn))\n\t\tr = -EFAULT;\n\nout:\n\tpte_unmap_unlock(ptep, ptl);\n\t*p_pfn = pfn;\n\n\treturn r;\n}",
      "modified_lines": {
        "added": [
          "\t *",
          "\t * Certain IO or PFNMAP mappings can be backed with valid",
          "\t * struct pages, but be allocated without refcounting e.g.,",
          "\t * tail pages of non-compound higher order allocations, which",
          "\t * would then underflow the refcount when the caller does the",
          "\t * required put_page. Don't allow those pages here.",
          "\tif (!kvm_try_get_pfn(pfn))",
          "\t\tr = -EFAULT;",
          "",
          "\treturn r;"
        ],
        "deleted": [
          "\tkvm_get_pfn(pfn);",
          "\treturn 0;"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of VM_IO|VM_PFNMAP vmas in KVM.",
      "trigger_condition": "Accessing pages backed with valid struct pages but allocated without proper refcounting, leading to potential memory corruption and unauthorized access.",
      "specific_code_behavior_causing_vulnerability": "The code does not perform a check to ensure that the page frame number (PFN) obtained is valid before accessing it, allowing for potential underflow of the refcount when the caller does the required put_page.",
      "id": 145,
      "code_after_change_normalized": "static int FUN1(struct vm_area_struct *VAR1,\nunsigned long VAR2, bool *VAR3,\nbool VAR4, bool *VAR5,\nkvm_pfn_t *VAR6)\n{\nkvm_pfn_t VAR7;\npte_t *VAR8;\nspinlock_t *VAR9;\nint VAR10;\nVAR10 = FUN2(VAR1->VAR11, VAR2, &VAR8, &VAR9);\nif (VAR10) {\nbool VAR12 = false;\nVAR10 = FUN3(VAR13->VAR14, VAR2,\n(VAR4 ? VAR15 : 0),\n&VAR12);\nif (VAR12)\nreturn -VAR16;\nif (VAR10)\nreturn VAR10;\nVAR10 = FUN2(VAR1->VAR11, VAR2, &VAR8, &VAR9);\nif (VAR10)\nreturn VAR10;\n}\nif (VAR4 && !FUN4(*VAR8)) {\nVAR7 = VAR17;\ngoto VAR18;\n}\nif (VAR5)\n*VAR5 = FUN4(*VAR8);\nVAR7 = FUN5(*VAR8);\nif (!FUN6(VAR7))\nVAR10 = -VAR19;\nVAR18:\nFUN7(VAR8, VAR9);\n*VAR6 = VAR7;\nreturn VAR10;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct vm_area_struct *VAR1,\nunsigned long VAR2, bool *VAR3,\nbool VAR4, bool *VAR5,\nkvm_pfn_t *VAR6)\n{\nkvm_pfn_t VAR7;\npte_t *VAR8;\nspinlock_t *VAR9;\nint VAR10;\nVAR10 = FUN2(VAR1->VAR11, VAR2, &VAR8, &VAR9);\nif (VAR10) {\nbool VAR12 = false;\nVAR10 = FUN3(VAR13->VAR14, VAR2,\n(VAR4 ? VAR15 : 0),\n&VAR12);\nif (VAR12)\nreturn -VAR16;\nif (VAR10)\nreturn VAR10;\nVAR10 = FUN2(VAR1->VAR11, VAR2, &VAR8, &VAR9);\nif (VAR10)\nreturn VAR10;\n}\nif (VAR4 && !FUN4(*VAR8)) {\nVAR7 = VAR17;\ngoto VAR18;\n}\nif (VAR5)\n*VAR5 = FUN4(*VAR8);\nVAR7 = FUN5(*VAR8);\nFUN6(VAR7);\nVAR18:\nFUN7(VAR8, VAR9);\n*VAR6 = VAR7;\nreturn 0;\n}\n",
      "code_after_change_raw": "static int hva_to_pfn_remapped(struct vm_area_struct *vma,\nunsigned long addr, bool *async,\nbool write_fault, bool *writable,\nkvm_pfn_t *p_pfn)\n{\nkvm_pfn_t pfn;\npte_t *ptep;\nspinlock_t *ptl;\nint r;\nr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\nif (r) {\nbool unlocked = false;\nr = fixup_user_fault(current->mm, addr,\n(write_fault ? FAULT_FLAG_WRITE : 0),\n&unlocked);\nif (unlocked)\nreturn -EAGAIN;\nif (r)\nreturn r;\nr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\nif (r)\nreturn r;\n}\nif (write_fault && !pte_write(*ptep)) {\npfn = KVM_PFN_ERR_RO_FAULT;\ngoto out;\n}\nif (writable)\n*writable = pte_write(*ptep);\npfn = pte_pfn(*ptep);\nif (!kvm_try_get_pfn(pfn))\nr = -EFAULT;\nout:\npte_unmap_unlock(ptep, ptl);\n*p_pfn = pfn;\nreturn r;\n}\n",
      "code_before_change_raw": "static int hva_to_pfn_remapped(struct vm_area_struct *vma,\nunsigned long addr, bool *async,\nbool write_fault, bool *writable,\nkvm_pfn_t *p_pfn)\n{\nkvm_pfn_t pfn;\npte_t *ptep;\nspinlock_t *ptl;\nint r;\nr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\nif (r) {\nbool unlocked = false;\nr = fixup_user_fault(current->mm, addr,\n(write_fault ? FAULT_FLAG_WRITE : 0),\n&unlocked);\nif (unlocked)\nreturn -EAGAIN;\nif (r)\nreturn r;\nr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\nif (r)\nreturn r;\n}\nif (write_fault && !pte_write(*ptep)) {\npfn = KVM_PFN_ERR_RO_FAULT;\ngoto out;\n}\nif (writable)\n*writable = pte_write(*ptep);\npfn = pte_pfn(*ptep);\nkvm_get_pfn(pfn);\nout:\npte_unmap_unlock(ptep, ptl);\n*p_pfn = pfn;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2021-3635": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for active objects before deletion in the netfilter netflow commands.",
        "trigger_condition": "A user with root (CAP_SYS_ADMIN) access issues netfilter netflow commands, leading to a panic in the system due to improper handling of object deletion.",
        "specific_code_behavior_causing_vulnerability": "The code attempts to delete objects without verifying if they are active, allowing unauthorized users to trigger a panic by manipulating the deletion process.",
        "specific_solution": "To mitigate the vulnerability, it is necessary to add a validation step to check if the object is active before proceeding with the deletion operation. This ensures that only active objects are deleted, preventing unauthorized users from causing a system panic."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2021-3635 in the Linux kernel netfilter implementation. The vulnerability allows a user with root (CAP_SYS_ADMIN) access to panic the system when issuing netfilter netflow commands. \n\nThe modification involves adding the condition `if (!nft_is_active_next(ctx->net, obj)) continue;` before attempting to delete an object in the `list_for_each_entry_safe(obj, ne, &ctx->table->objects, list)` loop. This condition ensures that the deletion operation is only performed on active objects, preventing the vulnerability from being exploited by unauthorized users to panic the system.\n\nBy adding this condition, the code ensures that only active objects are deleted, thereby mitigating the vulnerability and enhancing the security of the netfilter implementation in the Linux kernel.",
      "GPT_purpose": "This function is used to flush all rules, sets, flowtables, objects, and chains from a given netfilter table.",
      "GPT_function": "\n1. Flush all rules in a netfilter table.\n2. Delete all sets in a netfilter table.\n3. Delete all flowtables in a netfilter table.\n4. Delete all objects in a netfilter table.\n5. Delete all chains in a netfilter table.\n6. Delete the netfilter table.",
      "CVE_id": "CVE-2021-3635",
      "code_before_change": "static int nft_flush_table(struct nft_ctx *ctx)\n{\n\tstruct nft_flowtable *flowtable, *nft;\n\tstruct nft_chain *chain, *nc;\n\tstruct nft_object *obj, *ne;\n\tstruct nft_set *set, *ns;\n\tint err;\n\n\tlist_for_each_entry(chain, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delrule_by_chain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(set, ns, &ctx->table->sets, list) {\n\t\tif (!nft_is_active_next(ctx->net, set))\n\t\t\tcontinue;\n\n\t\tif (nft_set_is_anonymous(set) &&\n\t\t    !list_empty(&set->bindings))\n\t\t\tcontinue;\n\n\t\terr = nft_delset(ctx, set);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(flowtable, nft, &ctx->table->flowtables, list) {\n\t\terr = nft_delflowtable(ctx, flowtable);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(obj, ne, &ctx->table->objects, list) {\n\t\terr = nft_delobj(ctx, obj);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delchain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\terr = nft_deltable(ctx);\nout:\n\treturn err;\n}",
      "code_after_change": "static int nft_flush_table(struct nft_ctx *ctx)\n{\n\tstruct nft_flowtable *flowtable, *nft;\n\tstruct nft_chain *chain, *nc;\n\tstruct nft_object *obj, *ne;\n\tstruct nft_set *set, *ns;\n\tint err;\n\n\tlist_for_each_entry(chain, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delrule_by_chain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(set, ns, &ctx->table->sets, list) {\n\t\tif (!nft_is_active_next(ctx->net, set))\n\t\t\tcontinue;\n\n\t\tif (nft_set_is_anonymous(set) &&\n\t\t    !list_empty(&set->bindings))\n\t\t\tcontinue;\n\n\t\terr = nft_delset(ctx, set);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(flowtable, nft, &ctx->table->flowtables, list) {\n\t\tif (!nft_is_active_next(ctx->net, flowtable))\n\t\t\tcontinue;\n\n\t\terr = nft_delflowtable(ctx, flowtable);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(obj, ne, &ctx->table->objects, list) {\n\t\tif (!nft_is_active_next(ctx->net, obj))\n\t\t\tcontinue;\n\n\t\terr = nft_delobj(ctx, obj);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delchain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\terr = nft_deltable(ctx);\nout:\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\t\tif (!nft_is_active_next(ctx->net, flowtable))",
          "\t\t\tcontinue;",
          "",
          "\t\tif (!nft_is_active_next(ctx->net, obj))",
          "\t\t\tcontinue;",
          ""
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of proper validation for active objects before deletion in the netfilter netflow commands.",
      "trigger_condition": "A user with root (CAP_SYS_ADMIN) access issues netfilter netflow commands, leading to a panic in the system due to improper handling of object deletion.",
      "specific_code_behavior_causing_vulnerability": "The code attempts to delete objects without verifying if they are active, allowing unauthorized users to trigger a panic by manipulating the deletion process.",
      "id": 146,
      "code_after_change_normalized": "static int FUN1(struct nft_ctx *VAR1)\n{\nstruct nft_flowtable *VAR2, *VAR3;\nstruct nft_chain *VAR4, *VAR5;\nstruct nft_object *VAR6, *VAR7;\nstruct nft_set *VAR8, *VAR9;\nint VAR10;\nFUN2(VAR4, &VAR1->VAR11->VAR12, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR4))\ncontinue;\nVAR1->VAR4 = VAR4;\nVAR10 = FUN4(VAR1);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR8, VAR9, &VAR1->VAR11->VAR16, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR8))\ncontinue;\nif (FUN6(VAR8) &&\n!FUN7(&VAR8->VAR17))\ncontinue;\nVAR10 = FUN8(VAR1, VAR8);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR2, VAR3, &VAR1->VAR11->VAR18, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR2))\ncontinue;\nVAR10 = FUN9(VAR1, VAR2);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR6, VAR7, &VAR1->VAR11->VAR19, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR6))\ncontinue;\nVAR10 = FUN10(VAR1, VAR6);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR4, VAR5, &VAR1->VAR11->VAR12, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR4))\ncontinue;\nVAR1->VAR4 = VAR4;\nVAR10 = FUN11(VAR1);\nif (VAR10 < 0)\ngoto VAR15;\n}\nVAR10 = FUN12(VAR1);\nVAR15:\nreturn VAR10;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct nft_ctx *VAR1)\n{\nstruct nft_flowtable *VAR2, *VAR3;\nstruct nft_chain *VAR4, *VAR5;\nstruct nft_object *VAR6, *VAR7;\nstruct nft_set *VAR8, *VAR9;\nint VAR10;\nFUN2(VAR4, &VAR1->VAR11->VAR12, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR4))\ncontinue;\nVAR1->VAR4 = VAR4;\nVAR10 = FUN4(VAR1);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR8, VAR9, &VAR1->VAR11->VAR16, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR8))\ncontinue;\nif (FUN6(VAR8) &&\n!FUN7(&VAR8->VAR17))\ncontinue;\nVAR10 = FUN8(VAR1, VAR8);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR2, VAR3, &VAR1->VAR11->VAR18, VAR13) {\nVAR10 = FUN9(VAR1, VAR2);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR6, VAR7, &VAR1->VAR11->VAR19, VAR13) {\nVAR10 = FUN10(VAR1, VAR6);\nif (VAR10 < 0)\ngoto VAR15;\n}\nFUN5(VAR4, VAR5, &VAR1->VAR11->VAR12, VAR13) {\nif (!FUN3(VAR1->VAR14, VAR4))\ncontinue;\nVAR1->VAR4 = VAR4;\nVAR10 = FUN11(VAR1);\nif (VAR10 < 0)\ngoto VAR15;\n}\nVAR10 = FUN12(VAR1);\nVAR15:\nreturn VAR10;\n}\n",
      "code_after_change_raw": "static int nft_flush_table(struct nft_ctx *ctx)\n{\nstruct nft_flowtable *flowtable, *nft;\nstruct nft_chain *chain, *nc;\nstruct nft_object *obj, *ne;\nstruct nft_set *set, *ns;\nint err;\nlist_for_each_entry(chain, &ctx->table->chains, list) {\nif (!nft_is_active_next(ctx->net, chain))\ncontinue;\nctx->chain = chain;\nerr = nft_delrule_by_chain(ctx);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(set, ns, &ctx->table->sets, list) {\nif (!nft_is_active_next(ctx->net, set))\ncontinue;\nif (nft_set_is_anonymous(set) &&\n!list_empty(&set->bindings))\ncontinue;\nerr = nft_delset(ctx, set);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(flowtable, nft, &ctx->table->flowtables, list) {\nif (!nft_is_active_next(ctx->net, flowtable))\ncontinue;\nerr = nft_delflowtable(ctx, flowtable);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(obj, ne, &ctx->table->objects, list) {\nif (!nft_is_active_next(ctx->net, obj))\ncontinue;\nerr = nft_delobj(ctx, obj);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\nif (!nft_is_active_next(ctx->net, chain))\ncontinue;\nctx->chain = chain;\nerr = nft_delchain(ctx);\nif (err < 0)\ngoto out;\n}\nerr = nft_deltable(ctx);\nout:\nreturn err;\n}\n",
      "code_before_change_raw": "static int nft_flush_table(struct nft_ctx *ctx)\n{\nstruct nft_flowtable *flowtable, *nft;\nstruct nft_chain *chain, *nc;\nstruct nft_object *obj, *ne;\nstruct nft_set *set, *ns;\nint err;\nlist_for_each_entry(chain, &ctx->table->chains, list) {\nif (!nft_is_active_next(ctx->net, chain))\ncontinue;\nctx->chain = chain;\nerr = nft_delrule_by_chain(ctx);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(set, ns, &ctx->table->sets, list) {\nif (!nft_is_active_next(ctx->net, set))\ncontinue;\nif (nft_set_is_anonymous(set) &&\n!list_empty(&set->bindings))\ncontinue;\nerr = nft_delset(ctx, set);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(flowtable, nft, &ctx->table->flowtables, list) {\nerr = nft_delflowtable(ctx, flowtable);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(obj, ne, &ctx->table->objects, list) {\nerr = nft_delobj(ctx, obj);\nif (err < 0)\ngoto out;\n}\nlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\nif (!nft_is_active_next(ctx->net, chain))\ncontinue;\nctx->chain = chain;\nerr = nft_delchain(ctx);\nif (err < 0)\ngoto out;\n}\nerr = nft_deltable(ctx);\nout:\nreturn err;\n}\n"
    }
  ],
  "CVE-2021-38201": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Inadequate bounds checking and handling of buffer lengths in the code.",
        "trigger_condition": "Performing many NFS 4.2 READ_PLUS operations can trigger a denial of service due to a slab-out-of-bounds access issue.",
        "specific_code_behavior_causing_vulnerability": "The vulnerability arises from incorrect calculation of the 'maxlen' variable, which can lead to accessing memory beyond the bounds of the allocated buffer when 'len' is greater than 'maxlen'. This can result in a denial of service due to a slab-out-of-bounds access issue."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper bounds checking and handling of buffer lengths in the code. Specifically, the modification made to the code snippet involves returning 0 immediately if 'base' is greater than or equal to 'maxlen', preventing further calculations that could lead to the vulnerability. This change helps to prevent the out-of-bounds access issue and improves the security of the code.",
      "GPT_analysis": "The modification made to the code snippet is necessary to address the vulnerability CVE-2021-38201, which allows remote attackers to cause a denial of service by performing many NFS 4.2 READ_PLUS operations. \n\nIn the original code snippet, there is a vulnerability in the calculation of the `maxlen` variable, which can lead to a slab-out-of-bounds access issue. By allowing `maxlen` to be set to 0 if `base` is greater than or equal to `maxlen`, the vulnerability can be triggered when `len` is greater than `maxlen`. This can result in accessing memory beyond the bounds of the allocated buffer, leading to a denial of service.\n\nThe modification ensures that if `base` is greater than or equal to `maxlen`, the function returns 0 immediately, preventing further calculations that could lead to the vulnerability. This change helps to prevent the out-of-bounds access issue and improves the security of the code.",
      "GPT_purpose": "Set the base position and length for an XDR stream page.",
      "GPT_function": "\n1. Set the base position for the XDR stream.\n2. Calculate the page number, maximum length, page offset, and page end.\n3. Set the pointers for the XDR stream based on the calculated values.",
      "CVE_id": "CVE-2021-38201",
      "code_before_change": "static unsigned int xdr_set_page_base(struct xdr_stream *xdr,\n\t\t\t\t      unsigned int base, unsigned int len)\n{\n\tunsigned int pgnr;\n\tunsigned int maxlen;\n\tunsigned int pgoff;\n\tunsigned int pgend;\n\tvoid *kaddr;\n\n\tmaxlen = xdr->buf->page_len;\n\tif (base >= maxlen) {\n\t\tbase = maxlen;\n\t\tmaxlen = 0;\n\t} else\n\t\tmaxlen -= base;\n\tif (len > maxlen)\n\t\tlen = maxlen;\n\n\txdr_stream_page_set_pos(xdr, base);\n\tbase += xdr->buf->page_base;\n\n\tpgnr = base >> PAGE_SHIFT;\n\txdr->page_ptr = &xdr->buf->pages[pgnr];\n\tkaddr = page_address(*xdr->page_ptr);\n\n\tpgoff = base & ~PAGE_MASK;\n\txdr->p = (__be32*)(kaddr + pgoff);\n\n\tpgend = pgoff + len;\n\tif (pgend > PAGE_SIZE)\n\t\tpgend = PAGE_SIZE;\n\txdr->end = (__be32*)(kaddr + pgend);\n\txdr->iov = NULL;\n\treturn len;\n}",
      "code_after_change": "static unsigned int xdr_set_page_base(struct xdr_stream *xdr,\n\t\t\t\t      unsigned int base, unsigned int len)\n{\n\tunsigned int pgnr;\n\tunsigned int maxlen;\n\tunsigned int pgoff;\n\tunsigned int pgend;\n\tvoid *kaddr;\n\n\tmaxlen = xdr->buf->page_len;\n\tif (base >= maxlen)\n\t\treturn 0;\n\telse\n\t\tmaxlen -= base;\n\tif (len > maxlen)\n\t\tlen = maxlen;\n\n\txdr_stream_page_set_pos(xdr, base);\n\tbase += xdr->buf->page_base;\n\n\tpgnr = base >> PAGE_SHIFT;\n\txdr->page_ptr = &xdr->buf->pages[pgnr];\n\tkaddr = page_address(*xdr->page_ptr);\n\n\tpgoff = base & ~PAGE_MASK;\n\txdr->p = (__be32*)(kaddr + pgoff);\n\n\tpgend = pgoff + len;\n\tif (pgend > PAGE_SIZE)\n\t\tpgend = PAGE_SIZE;\n\txdr->end = (__be32*)(kaddr + pgend);\n\txdr->iov = NULL;\n\treturn len;\n}",
      "modified_lines": {
        "added": [
          "\tif (base >= maxlen)",
          "\t\treturn 0;",
          "\telse"
        ],
        "deleted": [
          "\tif (base >= maxlen) {",
          "\t\tbase = maxlen;",
          "\t\tmaxlen = 0;",
          "\t} else"
        ]
      },
      "preconditions_for_vulnerability": "Inadequate bounds checking and handling of buffer lengths in the code.",
      "trigger_condition": "Performing many NFS 4.2 READ_PLUS operations can trigger a denial of service due to a slab-out-of-bounds access issue.",
      "specific_code_behavior_causing_vulnerability": "The vulnerability arises from incorrect calculation of the 'maxlen' variable, which can lead to accessing memory beyond the bounds of the allocated buffer when 'len' is greater than 'maxlen'. This can result in a denial of service due to a slab-out-of-bounds access issue.",
      "id": 147,
      "code_after_change_normalized": "static unsigned int FUN1(struct xdr_stream *VAR1,\nunsigned int VAR2, unsigned int VAR3)\n{\nunsigned int VAR4;\nunsigned int VAR5;\nunsigned int VAR6;\nunsigned int VAR7;\nvoid *VAR8;\nVAR5 = VAR1->VAR9->VAR10;\nif (VAR2 >= VAR5)\nreturn 0;\nelse\nVAR5 -= VAR2;\nif (VAR3 > VAR5)\nVAR3 = VAR5;\nFUN2(VAR1, VAR2);\nVAR2 += VAR1->VAR9->VAR11;\nVAR4 = VAR2 >> VAR12;\nVAR1->VAR13 = &VAR1->VAR9->VAR14[VAR4];\nVAR8 = FUN3(*VAR1->VAR13);\nVAR6 = VAR2 & ~VAR15;\nVAR1->VAR16 = (VAR17*)(VAR8 + VAR6);\nVAR7 = VAR6 + VAR3;\nif (VAR7 > VAR18)\nVAR7 = VAR18;\nVAR1->VAR19 = (VAR17*)(VAR8 + VAR7);\nVAR1->VAR20 = NULL;\nreturn VAR3;\n}\n",
      "code_before_change_normalized": "static unsigned int FUN1(struct xdr_stream *VAR1,\nunsigned int VAR2, unsigned int VAR3)\n{\nunsigned int VAR4;\nunsigned int VAR5;\nunsigned int VAR6;\nunsigned int VAR7;\nvoid *VAR8;\nVAR5 = VAR1->VAR9->VAR10;\nif (VAR2 >= VAR5) {\nVAR2 = VAR5;\nVAR5 = 0;\n} else\nVAR5 -= VAR2;\nif (VAR3 > VAR5)\nVAR3 = VAR5;\nFUN2(VAR1, VAR2);\nVAR2 += VAR1->VAR9->VAR11;\nVAR4 = VAR2 >> VAR12;\nVAR1->VAR13 = &VAR1->VAR9->VAR14[VAR4];\nVAR8 = FUN3(*VAR1->VAR13);\nVAR6 = VAR2 & ~VAR15;\nVAR1->VAR16 = (VAR17*)(VAR8 + VAR6);\nVAR7 = VAR6 + VAR3;\nif (VAR7 > VAR18)\nVAR7 = VAR18;\nVAR1->VAR19 = (VAR17*)(VAR8 + VAR7);\nVAR1->VAR20 = NULL;\nreturn VAR3;\n}\n",
      "code_after_change_raw": "static unsigned int xdr_set_page_base(struct xdr_stream *xdr,\nunsigned int base, unsigned int len)\n{\nunsigned int pgnr;\nunsigned int maxlen;\nunsigned int pgoff;\nunsigned int pgend;\nvoid *kaddr;\nmaxlen = xdr->buf->page_len;\nif (base >= maxlen)\nreturn 0;\nelse\nmaxlen -= base;\nif (len > maxlen)\nlen = maxlen;\nxdr_stream_page_set_pos(xdr, base);\nbase += xdr->buf->page_base;\npgnr = base >> PAGE_SHIFT;\nxdr->page_ptr = &xdr->buf->pages[pgnr];\nkaddr = page_address(*xdr->page_ptr);\npgoff = base & ~PAGE_MASK;\nxdr->p = (__be32*)(kaddr + pgoff);\npgend = pgoff + len;\nif (pgend > PAGE_SIZE)\npgend = PAGE_SIZE;\nxdr->end = (__be32*)(kaddr + pgend);\nxdr->iov = NULL;\nreturn len;\n}\n",
      "code_before_change_raw": "static unsigned int xdr_set_page_base(struct xdr_stream *xdr,\nunsigned int base, unsigned int len)\n{\nunsigned int pgnr;\nunsigned int maxlen;\nunsigned int pgoff;\nunsigned int pgend;\nvoid *kaddr;\nmaxlen = xdr->buf->page_len;\nif (base >= maxlen) {\nbase = maxlen;\nmaxlen = 0;\n} else\nmaxlen -= base;\nif (len > maxlen)\nlen = maxlen;\nxdr_stream_page_set_pos(xdr, base);\nbase += xdr->buf->page_base;\npgnr = base >> PAGE_SHIFT;\nxdr->page_ptr = &xdr->buf->pages[pgnr];\nkaddr = page_address(*xdr->page_ptr);\npgoff = base & ~PAGE_MASK;\nxdr->p = (__be32*)(kaddr + pgoff);\npgend = pgoff + len;\nif (pgend > PAGE_SIZE)\npgend = PAGE_SIZE;\nxdr->end = (__be32*)(kaddr + pgend);\nxdr->iov = NULL;\nreturn len;\n}\n"
    }
  ],
  "CVE-2021-39633": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of validation for memory access in the offload handling function.",
        "trigger_condition": "When a specific condition is met where the checksum start pointer is before the data pointer in the packet buffer, it can lead to an invalid memory access.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the checksum start pointer is within the valid memory range before proceeding with offload handling. This oversight can result in a potential page fault due to an invalid memory access, leading to local information disclosure.",
        "solution": "To mitigate the vulnerability, it is necessary to add a validation check to ensure that the checksum start pointer is within the valid memory range before continuing with the offload handling. By adding the condition to check if the checksum start pointer is before the data pointer in the packet buffer, the code can prevent the possibility of an invalid memory access and potential page fault."
      },
      "GPT_analysis": "The modification is necessary to prevent a possible page fault due to an invalid memory access in the `gre_handle_offloads` function. By adding the condition `if (csum && skb_checksum_start(skb) < skb->data)`, the code checks if the checksum start pointer is before the data pointer in the packet buffer. If this condition is true, it indicates an invalid memory access, and the function returns `-EINVAL` to handle this error case appropriately.\n\nThis modification ensures that the code handles the potential vulnerability described in CVE-2021-39633 by validating the memory access before proceeding with the offload handling, thus preventing local information disclosure without requiring additional execution privileges or user interaction for exploitation.",
      "GPT_purpose": "Handling offloads for Generic Routing Encapsulation (GRE) packets.",
      "GPT_function": "\n1. Handling offloads for Generic Routing Encapsulation (GRE) packets\n2. Invoking iptunnel_handle_offloads function with specific parameters based on the checksum condition",
      "CVE_id": "CVE-2021-39633",
      "code_before_change": "static int gre_handle_offloads(struct sk_buff *skb, bool csum)\n{\n\treturn iptunnel_handle_offloads(skb, csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);\n}",
      "code_after_change": "static int gre_handle_offloads(struct sk_buff *skb, bool csum)\n{\n\tif (csum && skb_checksum_start(skb) < skb->data)\n\t\treturn -EINVAL;\n\treturn iptunnel_handle_offloads(skb, csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);\n}",
      "modified_lines": {
        "added": [
          "\tif (csum && skb_checksum_start(skb) < skb->data)",
          "\t\treturn -EINVAL;"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Lack of validation for memory access in the offload handling function.",
      "trigger_condition": "When a specific condition is met where the checksum start pointer is before the data pointer in the packet buffer, it can lead to an invalid memory access.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the checksum start pointer is within the valid memory range before proceeding with offload handling. This oversight can result in a potential page fault due to an invalid memory access, leading to local information disclosure.",
      "solution": "To mitigate the vulnerability, it is necessary to add a validation check to ensure that the checksum start pointer is within the valid memory range before continuing with the offload handling. By adding the condition to check if the checksum start pointer is before the data pointer in the packet buffer, the code can prevent the possibility of an invalid memory access and potential page fault.",
      "id": 148,
      "code_after_change_normalized": "static int FUN1(struct sk_buff *VAR1, bool VAR2)\n{\nif (VAR2 && FUN2(VAR1) < VAR1->VAR3)\nreturn -VAR4;\nreturn FUN3(VAR1, VAR2 ? VAR5 : VAR6);\n}\n",
      "code_before_change_normalized": "static int FUN1(struct sk_buff *VAR1, bool VAR2)\n{\nreturn FUN2(VAR1, VAR2 ? VAR3 : VAR4);\n}\n",
      "code_after_change_raw": "static int gre_handle_offloads(struct sk_buff *skb, bool csum)\n{\nif (csum && skb_checksum_start(skb) < skb->data)\nreturn -EINVAL;\nreturn iptunnel_handle_offloads(skb, csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);\n}\n",
      "code_before_change_raw": "static int gre_handle_offloads(struct sk_buff *skb, bool csum)\n{\nreturn iptunnel_handle_offloads(skb, csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);\n}\n"
    }
  ],
  "CVE-2021-4157": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper size validation for the data being copied into the nfs_fh data structure.",
        "trigger_condition": "An attacker with access to the NFS mount sends a specially crafted request with a size value larger than the maximum allowed size for an NFS file handle.",
        "specific_code_behavior_causing_vulnerability": "The code does not check if the size of the data being copied into the nfs_fh data structure exceeds the maximum allowed size, leading to a potential buffer overflow and out-of-bounds memory write vulnerability."
      },
      "solution": "To mitigate the vulnerability, it is necessary to validate the size of the data being copied into the nfs_fh data structure against the maximum allowed size (NFS_MAXFHSIZE) before performing the copy operation. This ensures that the code prevents buffer overflows and out-of-bounds memory writes. In this case, the solution involves modifying the code to compare the size of the data against NFS_MAXFHSIZE and returning an error if the size exceeds the maximum allowed value.",
      "GPT_analysis": "The modification is necessary to prevent the out-of-bounds memory write vulnerability (CVE-2021-4157) in the Linux kernel NFS subsystem. By checking if the `fh->size` is greater than `NFS_MAXFHSIZE` instead of `sizeof(struct nfs_fh)`, the code ensures that the size of the data being copied into `fh->data` does not exceed the maximum allowed size for an NFS file handle.\n\nBy making this change, the code prevents a potential buffer overflow that could be exploited by a user with access to the NFS mount to crash the system or escalate privileges. This modification helps to ensure the security and stability of the system when handling NFS file handles.",
      "GPT_purpose": "Decode and copy NFS file handle data from an XDR stream into a structure.",
      "GPT_function": "\n1. Decode NFS file handle from XDR stream.\n2. Check the size of the NFS file handle.\n3. Copy the NFS file handle data into the structure.",
      "CVE_id": "CVE-2021-4157",
      "code_before_change": "static int decode_nfs_fh(struct xdr_stream *xdr, struct nfs_fh *fh)\n{\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, 4);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tfh->size = be32_to_cpup(p++);\n\tif (fh->size > sizeof(struct nfs_fh)) {\n\t\tprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\n\t\t       fh->size);\n\t\treturn -EOVERFLOW;\n\t}\n\t/* fh.data */\n\tp = xdr_inline_decode(xdr, fh->size);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tmemcpy(&fh->data, p, fh->size);\n\tdprintk(\"%s: fh len %d\\n\", __func__, fh->size);\n\n\treturn 0;\n}",
      "code_after_change": "static int decode_nfs_fh(struct xdr_stream *xdr, struct nfs_fh *fh)\n{\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, 4);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tfh->size = be32_to_cpup(p++);\n\tif (fh->size > NFS_MAXFHSIZE) {\n\t\tprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\n\t\t       fh->size);\n\t\treturn -EOVERFLOW;\n\t}\n\t/* fh.data */\n\tp = xdr_inline_decode(xdr, fh->size);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tmemcpy(&fh->data, p, fh->size);\n\tdprintk(\"%s: fh len %d\\n\", __func__, fh->size);\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\tif (fh->size > NFS_MAXFHSIZE) {"
        ],
        "deleted": [
          "\tif (fh->size > sizeof(struct nfs_fh)) {"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper size validation for the data being copied into the nfs_fh data structure.",
      "trigger_condition": "An attacker with access to the NFS mount sends a specially crafted request with a size value larger than the maximum allowed size for an NFS file handle.",
      "specific_code_behavior_causing_vulnerability": "The code does not check if the size of the data being copied into the nfs_fh data structure exceeds the maximum allowed size, leading to a potential buffer overflow and out-of-bounds memory write vulnerability.",
      "id": 149,
      "code_after_change_normalized": "static int FUN1(struct xdr_stream *VAR1, struct nfs_fh *VAR2)\n{\n__be32 *VAR3;\nVAR3 = FUN2(VAR1, 4);\nif (FUN3(!VAR3))\nreturn -VAR4;\nVAR2->VAR5 = FUN4(VAR3++);\nif (VAR2->VAR5 > VAR6) {\nFUN5(VAR7 \"STR\",\nVAR2->VAR5);\nreturn -VAR8;\n}\nVAR3 = FUN2(VAR1, VAR2->VAR5);\nif (FUN3(!VAR3))\nreturn -VAR4;\nFUN6(&VAR2->VAR9, VAR3, VAR2->VAR5);\nFUN7(\"STR\", VAR10, VAR2->VAR5);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct xdr_stream *VAR1, struct nfs_fh *VAR2)\n{\n__be32 *VAR3;\nVAR3 = FUN2(VAR1, 4);\nif (FUN3(!VAR3))\nreturn -VAR4;\nVAR2->VAR5 = FUN4(VAR3++);\nif (VAR2->VAR5 > sizeof(struct VAR6)) {\nFUN5(VAR7 \"STR\",\nVAR2->VAR5);\nreturn -VAR8;\n}\nVAR3 = FUN2(VAR1, VAR2->VAR5);\nif (FUN3(!VAR3))\nreturn -VAR4;\nFUN6(&VAR2->VAR9, VAR3, VAR2->VAR5);\nFUN7(\"STR\", VAR10, VAR2->VAR5);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int decode_nfs_fh(struct xdr_stream *xdr, struct nfs_fh *fh)\n{\n__be32 *p;\np = xdr_inline_decode(xdr, 4);\nif (unlikely(!p))\nreturn -ENOBUFS;\nfh->size = be32_to_cpup(p++);\nif (fh->size > NFS_MAXFHSIZE) {\nprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\nfh->size);\nreturn -EOVERFLOW;\n}\np = xdr_inline_decode(xdr, fh->size);\nif (unlikely(!p))\nreturn -ENOBUFS;\nmemcpy(&fh->data, p, fh->size);\ndprintk(\"%s: fh len %d\\n\", __func__, fh->size);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int decode_nfs_fh(struct xdr_stream *xdr, struct nfs_fh *fh)\n{\n__be32 *p;\np = xdr_inline_decode(xdr, 4);\nif (unlikely(!p))\nreturn -ENOBUFS;\nfh->size = be32_to_cpup(p++);\nif (fh->size > sizeof(struct nfs_fh)) {\nprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\nfh->size);\nreturn -EOVERFLOW;\n}\np = xdr_inline_decode(xdr, fh->size);\nif (unlikely(!p))\nreturn -ENOBUFS;\nmemcpy(&fh->data, p, fh->size);\ndprintk(\"%s: fh len %d\\n\", __func__, fh->size);\nreturn 0;\n}\n"
    }
  ],
  "CVE-2021-4204": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper input validation in the code leads to an out-of-bounds (OOB) memory access flaw.",
        "trigger_condition": "A local attacker with special privileges can exploit the vulnerability to crash the system or leak internal information by manipulating the input data.",
        "specific_code_behavior_causing_vulnerability": "The code does not properly validate input data, allowing for an OOB memory access vulnerability to occur when processing function arguments.",
        "solution": "To mitigate the vulnerability, it is necessary to ensure proper input validation in the code. Specifically, the function call should be modified to validate the pointer offset correctly, preventing the OOB memory access flaw. By changing the function call from check_ctx_reg to check_ptr_off_reg, the code addresses the vulnerability and enhances security."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2021-4204, which involves an out-of-bounds (OOB) memory access flaw in the Linux kernel's eBPF due to improper input validation. By changing the function call from `check_ctx_reg(env, reg, regno)` to `check_ptr_off_reg(env, reg, regno)`, we ensure that the function is validating the pointer offset correctly, thus preventing the OOB memory access vulnerability. This modification helps to enhance the security of the code and prevent potential exploitation by attackers with special privileges.",
      "GPT_purpose": "Verify if the BTF function arguments match the actual types seen by the verifier.",
      "GPT_function": "\n1. Check if BTF function arguments match actual types\n2. Handle different types of function arguments and their validation\n3. Perform various checks on function arguments and their types",
      "CVE_id": "CVE-2021-4204",
      "code_before_change": "static int btf_check_func_arg_match(struct bpf_verifier_env *env,\n\t\t\t\t    const struct btf *btf, u32 func_id,\n\t\t\t\t    struct bpf_reg_state *regs,\n\t\t\t\t    bool ptr_to_mem_ok)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tbool is_kfunc = btf_is_kernel(btf);\n\tconst char *func_name, *ref_tname;\n\tconst struct btf_type *t, *ref_t;\n\tconst struct btf_param *args;\n\tu32 i, nargs, ref_id;\n\n\tt = btf_type_by_id(btf, func_id);\n\tif (!t || !btf_type_is_func(t)) {\n\t\t/* These checks were already done by the verifier while loading\n\t\t * struct bpf_func_info or in add_kfunc_call().\n\t\t */\n\t\tbpf_log(log, \"BTF of func_id %u doesn't point to KIND_FUNC\\n\",\n\t\t\tfunc_id);\n\t\treturn -EFAULT;\n\t}\n\tfunc_name = btf_name_by_offset(btf, t->name_off);\n\n\tt = btf_type_by_id(btf, t->type);\n\tif (!t || !btf_type_is_func_proto(t)) {\n\t\tbpf_log(log, \"Invalid BTF of func %s\\n\", func_name);\n\t\treturn -EFAULT;\n\t}\n\targs = (const struct btf_param *)(t + 1);\n\tnargs = btf_type_vlen(t);\n\tif (nargs > MAX_BPF_FUNC_REG_ARGS) {\n\t\tbpf_log(log, \"Function %s has %d > %d args\\n\", func_name, nargs,\n\t\t\tMAX_BPF_FUNC_REG_ARGS);\n\t\treturn -EINVAL;\n\t}\n\n\t/* check that BTF function arguments match actual types that the\n\t * verifier sees.\n\t */\n\tfor (i = 0; i < nargs; i++) {\n\t\tu32 regno = i + 1;\n\t\tstruct bpf_reg_state *reg = &regs[regno];\n\n\t\tt = btf_type_skip_modifiers(btf, args[i].type, NULL);\n\t\tif (btf_type_is_scalar(t)) {\n\t\t\tif (reg->type == SCALAR_VALUE)\n\t\t\t\tcontinue;\n\t\t\tbpf_log(log, \"R%d is not a scalar\\n\", regno);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!btf_type_is_ptr(t)) {\n\t\t\tbpf_log(log, \"Unrecognized arg#%d type %s\\n\",\n\t\t\t\ti, btf_type_str(t));\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tref_t = btf_type_skip_modifiers(btf, t->type, &ref_id);\n\t\tref_tname = btf_name_by_offset(btf, ref_t->name_off);\n\t\tif (btf_get_prog_ctx_type(log, btf, t,\n\t\t\t\t\t  env->prog->type, i)) {\n\t\t\t/* If function expects ctx type in BTF check that caller\n\t\t\t * is passing PTR_TO_CTX.\n\t\t\t */\n\t\t\tif (reg->type != PTR_TO_CTX) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"arg#%d expected pointer to ctx, but got %s\\n\",\n\t\t\t\t\ti, btf_type_str(t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (check_ctx_reg(env, reg, regno))\n\t\t\t\treturn -EINVAL;\n\t\t} else if (is_kfunc && (reg->type == PTR_TO_BTF_ID || reg2btf_ids[reg->type])) {\n\t\t\tconst struct btf_type *reg_ref_t;\n\t\t\tconst struct btf *reg_btf;\n\t\t\tconst char *reg_ref_tname;\n\t\t\tu32 reg_ref_id;\n\n\t\t\tif (!btf_type_is_struct(ref_t)) {\n\t\t\t\tbpf_log(log, \"kernel function %s args#%d pointer type %s %s is not supported\\n\",\n\t\t\t\t\tfunc_name, i, btf_type_str(ref_t),\n\t\t\t\t\tref_tname);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (reg->type == PTR_TO_BTF_ID) {\n\t\t\t\treg_btf = reg->btf;\n\t\t\t\treg_ref_id = reg->btf_id;\n\t\t\t} else {\n\t\t\t\treg_btf = btf_vmlinux;\n\t\t\t\treg_ref_id = *reg2btf_ids[reg->type];\n\t\t\t}\n\n\t\t\treg_ref_t = btf_type_skip_modifiers(reg_btf, reg_ref_id,\n\t\t\t\t\t\t\t    &reg_ref_id);\n\t\t\treg_ref_tname = btf_name_by_offset(reg_btf,\n\t\t\t\t\t\t\t   reg_ref_t->name_off);\n\t\t\tif (!btf_struct_ids_match(log, reg_btf, reg_ref_id,\n\t\t\t\t\t\t  reg->off, btf, ref_id)) {\n\t\t\t\tbpf_log(log, \"kernel function %s args#%d expected pointer to %s %s but R%d has a pointer to %s %s\\n\",\n\t\t\t\t\tfunc_name, i,\n\t\t\t\t\tbtf_type_str(ref_t), ref_tname,\n\t\t\t\t\tregno, btf_type_str(reg_ref_t),\n\t\t\t\t\treg_ref_tname);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else if (ptr_to_mem_ok) {\n\t\t\tconst struct btf_type *resolve_ret;\n\t\t\tu32 type_size;\n\n\t\t\tif (is_kfunc) {\n\t\t\t\t/* Permit pointer to mem, but only when argument\n\t\t\t\t * type is pointer to scalar, or struct composed\n\t\t\t\t * (recursively) of scalars.\n\t\t\t\t */\n\t\t\t\tif (!btf_type_is_scalar(ref_t) &&\n\t\t\t\t    !__btf_type_is_scalar_struct(log, btf, ref_t, 0)) {\n\t\t\t\t\tbpf_log(log,\n\t\t\t\t\t\t\"arg#%d pointer type %s %s must point to scalar or struct with scalar\\n\",\n\t\t\t\t\t\ti, btf_type_str(ref_t), ref_tname);\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tresolve_ret = btf_resolve_size(btf, ref_t, &type_size);\n\t\t\tif (IS_ERR(resolve_ret)) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"arg#%d reference type('%s %s') size cannot be determined: %ld\\n\",\n\t\t\t\t\ti, btf_type_str(ref_t), ref_tname,\n\t\t\t\t\tPTR_ERR(resolve_ret));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (check_mem_reg(env, reg, regno, type_size))\n\t\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tbpf_log(log, \"reg type unsupported for arg#%d %sfunction %s#%d\\n\", i,\n\t\t\t\tis_kfunc ? \"kernel \" : \"\", func_name, func_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}",
      "code_after_change": "static int btf_check_func_arg_match(struct bpf_verifier_env *env,\n\t\t\t\t    const struct btf *btf, u32 func_id,\n\t\t\t\t    struct bpf_reg_state *regs,\n\t\t\t\t    bool ptr_to_mem_ok)\n{\n\tstruct bpf_verifier_log *log = &env->log;\n\tbool is_kfunc = btf_is_kernel(btf);\n\tconst char *func_name, *ref_tname;\n\tconst struct btf_type *t, *ref_t;\n\tconst struct btf_param *args;\n\tu32 i, nargs, ref_id;\n\n\tt = btf_type_by_id(btf, func_id);\n\tif (!t || !btf_type_is_func(t)) {\n\t\t/* These checks were already done by the verifier while loading\n\t\t * struct bpf_func_info or in add_kfunc_call().\n\t\t */\n\t\tbpf_log(log, \"BTF of func_id %u doesn't point to KIND_FUNC\\n\",\n\t\t\tfunc_id);\n\t\treturn -EFAULT;\n\t}\n\tfunc_name = btf_name_by_offset(btf, t->name_off);\n\n\tt = btf_type_by_id(btf, t->type);\n\tif (!t || !btf_type_is_func_proto(t)) {\n\t\tbpf_log(log, \"Invalid BTF of func %s\\n\", func_name);\n\t\treturn -EFAULT;\n\t}\n\targs = (const struct btf_param *)(t + 1);\n\tnargs = btf_type_vlen(t);\n\tif (nargs > MAX_BPF_FUNC_REG_ARGS) {\n\t\tbpf_log(log, \"Function %s has %d > %d args\\n\", func_name, nargs,\n\t\t\tMAX_BPF_FUNC_REG_ARGS);\n\t\treturn -EINVAL;\n\t}\n\n\t/* check that BTF function arguments match actual types that the\n\t * verifier sees.\n\t */\n\tfor (i = 0; i < nargs; i++) {\n\t\tu32 regno = i + 1;\n\t\tstruct bpf_reg_state *reg = &regs[regno];\n\n\t\tt = btf_type_skip_modifiers(btf, args[i].type, NULL);\n\t\tif (btf_type_is_scalar(t)) {\n\t\t\tif (reg->type == SCALAR_VALUE)\n\t\t\t\tcontinue;\n\t\t\tbpf_log(log, \"R%d is not a scalar\\n\", regno);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!btf_type_is_ptr(t)) {\n\t\t\tbpf_log(log, \"Unrecognized arg#%d type %s\\n\",\n\t\t\t\ti, btf_type_str(t));\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tref_t = btf_type_skip_modifiers(btf, t->type, &ref_id);\n\t\tref_tname = btf_name_by_offset(btf, ref_t->name_off);\n\t\tif (btf_get_prog_ctx_type(log, btf, t,\n\t\t\t\t\t  env->prog->type, i)) {\n\t\t\t/* If function expects ctx type in BTF check that caller\n\t\t\t * is passing PTR_TO_CTX.\n\t\t\t */\n\t\t\tif (reg->type != PTR_TO_CTX) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"arg#%d expected pointer to ctx, but got %s\\n\",\n\t\t\t\t\ti, btf_type_str(t));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (check_ptr_off_reg(env, reg, regno))\n\t\t\t\treturn -EINVAL;\n\t\t} else if (is_kfunc && (reg->type == PTR_TO_BTF_ID || reg2btf_ids[reg->type])) {\n\t\t\tconst struct btf_type *reg_ref_t;\n\t\t\tconst struct btf *reg_btf;\n\t\t\tconst char *reg_ref_tname;\n\t\t\tu32 reg_ref_id;\n\n\t\t\tif (!btf_type_is_struct(ref_t)) {\n\t\t\t\tbpf_log(log, \"kernel function %s args#%d pointer type %s %s is not supported\\n\",\n\t\t\t\t\tfunc_name, i, btf_type_str(ref_t),\n\t\t\t\t\tref_tname);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (reg->type == PTR_TO_BTF_ID) {\n\t\t\t\treg_btf = reg->btf;\n\t\t\t\treg_ref_id = reg->btf_id;\n\t\t\t} else {\n\t\t\t\treg_btf = btf_vmlinux;\n\t\t\t\treg_ref_id = *reg2btf_ids[reg->type];\n\t\t\t}\n\n\t\t\treg_ref_t = btf_type_skip_modifiers(reg_btf, reg_ref_id,\n\t\t\t\t\t\t\t    &reg_ref_id);\n\t\t\treg_ref_tname = btf_name_by_offset(reg_btf,\n\t\t\t\t\t\t\t   reg_ref_t->name_off);\n\t\t\tif (!btf_struct_ids_match(log, reg_btf, reg_ref_id,\n\t\t\t\t\t\t  reg->off, btf, ref_id)) {\n\t\t\t\tbpf_log(log, \"kernel function %s args#%d expected pointer to %s %s but R%d has a pointer to %s %s\\n\",\n\t\t\t\t\tfunc_name, i,\n\t\t\t\t\tbtf_type_str(ref_t), ref_tname,\n\t\t\t\t\tregno, btf_type_str(reg_ref_t),\n\t\t\t\t\treg_ref_tname);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else if (ptr_to_mem_ok) {\n\t\t\tconst struct btf_type *resolve_ret;\n\t\t\tu32 type_size;\n\n\t\t\tif (is_kfunc) {\n\t\t\t\t/* Permit pointer to mem, but only when argument\n\t\t\t\t * type is pointer to scalar, or struct composed\n\t\t\t\t * (recursively) of scalars.\n\t\t\t\t */\n\t\t\t\tif (!btf_type_is_scalar(ref_t) &&\n\t\t\t\t    !__btf_type_is_scalar_struct(log, btf, ref_t, 0)) {\n\t\t\t\t\tbpf_log(log,\n\t\t\t\t\t\t\"arg#%d pointer type %s %s must point to scalar or struct with scalar\\n\",\n\t\t\t\t\t\ti, btf_type_str(ref_t), ref_tname);\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tresolve_ret = btf_resolve_size(btf, ref_t, &type_size);\n\t\t\tif (IS_ERR(resolve_ret)) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"arg#%d reference type('%s %s') size cannot be determined: %ld\\n\",\n\t\t\t\t\ti, btf_type_str(ref_t), ref_tname,\n\t\t\t\t\tPTR_ERR(resolve_ret));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (check_mem_reg(env, reg, regno, type_size))\n\t\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tbpf_log(log, \"reg type unsupported for arg#%d %sfunction %s#%d\\n\", i,\n\t\t\t\tis_kfunc ? \"kernel \" : \"\", func_name, func_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\t\tif (check_ptr_off_reg(env, reg, regno))"
        ],
        "deleted": [
          "\t\t\tif (check_ctx_reg(env, reg, regno))"
        ]
      },
      "preconditions_for_vulnerability": "Improper input validation in the code leads to an out-of-bounds (OOB) memory access flaw.",
      "trigger_condition": "A local attacker with special privileges can exploit the vulnerability to crash the system or leak internal information by manipulating the input data.",
      "specific_code_behavior_causing_vulnerability": "The code does not properly validate input data, allowing for an OOB memory access vulnerability to occur when processing function arguments.",
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper input validation in the code. Specifically, the function call should be modified to validate the pointer offset correctly, preventing the OOB memory access flaw. By changing the function call from check_ctx_reg to check_ptr_off_reg, the code addresses the vulnerability and enhances security.",
      "id": 150,
      "code_after_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1,\nconst struct VAR2 *VAR2, u32 VAR3,\nstruct bpf_reg_state *VAR4,\nbool VAR5)\n{\nstruct bpf_verifier_log *VAR6 = &VAR1->VAR6;\nbool VAR7 = FUN2(VAR2);\nconst char *VAR8, *VAR9;\nconst struct btf_type *VAR10, *VAR11;\nconst struct btf_param *VAR12;\nu32 VAR13, VAR14, VAR15;\nVAR10 = FUN3(VAR2, VAR3);\nif (!VAR10 || !FUN4(VAR10)) {\nFUN5(VAR6, \"STR\",\nVAR3);\nreturn -VAR16;\n}\nVAR8 = FUN6(VAR2, VAR10->VAR17);\nVAR10 = FUN3(VAR2, VAR10->VAR18);\nif (!VAR10 || !FUN7(VAR10)) {\nFUN5(VAR6, \"STR\", VAR8);\nreturn -VAR16;\n}\nVAR12 = (const struct VAR19 *)(VAR10 + 1);\nVAR14 = FUN8(VAR10);\nif (VAR14 > VAR20) {\nFUN5(VAR6, \"STR\", VAR8, VAR14,\nVAR20);\nreturn -VAR21;\n}\nfor (VAR13 = 0; VAR13 < VAR14; VAR13++) {\nu32 VAR22 = VAR13 + 1;\nstruct bpf_reg_state *VAR23 = &VAR4[VAR22];\nVAR10 = FUN9(VAR2, VAR12[VAR13].VAR18, NULL);\nif (FUN10(VAR10)) {\nif (VAR23->VAR18 == VAR24)\ncontinue;\nFUN5(VAR6, \"STR\", VAR22);\nreturn -VAR21;\n}\nif (!FUN11(VAR10)) {\nFUN5(VAR6, \"STR\",\nVAR13, FUN12(VAR10));\nreturn -VAR21;\n}\nVAR11 = FUN9(VAR2, VAR10->VAR18, &VAR15);\nVAR9 = FUN6(VAR2, VAR11->VAR17);\nif (FUN13(VAR6, VAR2, VAR10,\nVAR1->VAR25->VAR18, VAR13)) {\nif (VAR23->VAR18 != VAR26) {\nFUN5(VAR6,\n\"STR\",\nVAR13, FUN12(VAR10));\nreturn -VAR21;\n}\nif (FUN14(VAR1, VAR23, VAR22))\nreturn -VAR21;\n} else if (VAR7 && (VAR23->VAR18 == VAR27 || VAR28[VAR23->VAR18])) {\nconst struct btf_type *VAR29;\nconst struct btf *VAR30;\nconst char *VAR31;\nu32 VAR32;\nif (!FUN15(VAR11)) {\nFUN5(VAR6, \"STR\",\nVAR8, VAR13, FUN12(VAR11),\nVAR9);\nreturn -VAR21;\n}\nif (VAR23->VAR18 == VAR27) {\nVAR30 = VAR23->VAR2;\nVAR32 = VAR23->VAR33;\n} else {\nVAR30 = VAR34;\nVAR32 = *VAR28[VAR23->VAR18];\n}\nVAR29 = FUN9(VAR30, VAR32,\n&VAR32);\nVAR31 = FUN6(VAR30,\nVAR29->VAR17);\nif (!FUN16(VAR6, VAR30, VAR32,\nVAR23->VAR35, VAR2, VAR15)) {\nFUN5(VAR6, \"STR\",\nVAR8, VAR13,\nFUN12(VAR11), VAR9,\nVAR22, FUN12(VAR29),\nVAR31);\nreturn -VAR21;\n}\n} else if (VAR5) {\nconst struct btf_type *VAR36;\nu32 VAR37;\nif (VAR7) {\nif (!FUN10(VAR11) &&\n!FUN17(VAR6, VAR2, VAR11, 0)) {\nFUN5(VAR6,\n\"STR\",\nVAR13, FUN12(VAR11), VAR9);\nreturn -VAR21;\n}\n}\nVAR36 = FUN18(VAR2, VAR11, &VAR37);\nif (FUN19(VAR36)) {\nFUN5(VAR6,\n\"STR\",\nVAR13, FUN12(VAR11), VAR9,\nFUN20(VAR36));\nreturn -VAR21;\n}\nif (FUN21(VAR1, VAR23, VAR22, VAR37))\nreturn -VAR21;\n} else {\nFUN5(VAR6, \"STR\", VAR13,\nVAR7 ? \"STR\" : \"STR\", VAR8, VAR3);\nreturn -VAR21;\n}\n}\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1,\nconst struct VAR2 *VAR2, u32 VAR3,\nstruct bpf_reg_state *VAR4,\nbool VAR5)\n{\nstruct bpf_verifier_log *VAR6 = &VAR1->VAR6;\nbool VAR7 = FUN2(VAR2);\nconst char *VAR8, *VAR9;\nconst struct btf_type *VAR10, *VAR11;\nconst struct btf_param *VAR12;\nu32 VAR13, VAR14, VAR15;\nVAR10 = FUN3(VAR2, VAR3);\nif (!VAR10 || !FUN4(VAR10)) {\nFUN5(VAR6, \"STR\",\nVAR3);\nreturn -VAR16;\n}\nVAR8 = FUN6(VAR2, VAR10->VAR17);\nVAR10 = FUN3(VAR2, VAR10->VAR18);\nif (!VAR10 || !FUN7(VAR10)) {\nFUN5(VAR6, \"STR\", VAR8);\nreturn -VAR16;\n}\nVAR12 = (const struct VAR19 *)(VAR10 + 1);\nVAR14 = FUN8(VAR10);\nif (VAR14 > VAR20) {\nFUN5(VAR6, \"STR\", VAR8, VAR14,\nVAR20);\nreturn -VAR21;\n}\nfor (VAR13 = 0; VAR13 < VAR14; VAR13++) {\nu32 VAR22 = VAR13 + 1;\nstruct bpf_reg_state *VAR23 = &VAR4[VAR22];\nVAR10 = FUN9(VAR2, VAR12[VAR13].VAR18, NULL);\nif (FUN10(VAR10)) {\nif (VAR23->VAR18 == VAR24)\ncontinue;\nFUN5(VAR6, \"STR\", VAR22);\nreturn -VAR21;\n}\nif (!FUN11(VAR10)) {\nFUN5(VAR6, \"STR\",\nVAR13, FUN12(VAR10));\nreturn -VAR21;\n}\nVAR11 = FUN9(VAR2, VAR10->VAR18, &VAR15);\nVAR9 = FUN6(VAR2, VAR11->VAR17);\nif (FUN13(VAR6, VAR2, VAR10,\nVAR1->VAR25->VAR18, VAR13)) {\nif (VAR23->VAR18 != VAR26) {\nFUN5(VAR6,\n\"STR\",\nVAR13, FUN12(VAR10));\nreturn -VAR21;\n}\nif (FUN14(VAR1, VAR23, VAR22))\nreturn -VAR21;\n} else if (VAR7 && (VAR23->VAR18 == VAR27 || VAR28[VAR23->VAR18])) {\nconst struct btf_type *VAR29;\nconst struct btf *VAR30;\nconst char *VAR31;\nu32 VAR32;\nif (!FUN15(VAR11)) {\nFUN5(VAR6, \"STR\",\nVAR8, VAR13, FUN12(VAR11),\nVAR9);\nreturn -VAR21;\n}\nif (VAR23->VAR18 == VAR27) {\nVAR30 = VAR23->VAR2;\nVAR32 = VAR23->VAR33;\n} else {\nVAR30 = VAR34;\nVAR32 = *VAR28[VAR23->VAR18];\n}\nVAR29 = FUN9(VAR30, VAR32,\n&VAR32);\nVAR31 = FUN6(VAR30,\nVAR29->VAR17);\nif (!FUN16(VAR6, VAR30, VAR32,\nVAR23->VAR35, VAR2, VAR15)) {\nFUN5(VAR6, \"STR\",\nVAR8, VAR13,\nFUN12(VAR11), VAR9,\nVAR22, FUN12(VAR29),\nVAR31);\nreturn -VAR21;\n}\n} else if (VAR5) {\nconst struct btf_type *VAR36;\nu32 VAR37;\nif (VAR7) {\nif (!FUN10(VAR11) &&\n!FUN17(VAR6, VAR2, VAR11, 0)) {\nFUN5(VAR6,\n\"STR\",\nVAR13, FUN12(VAR11), VAR9);\nreturn -VAR21;\n}\n}\nVAR36 = FUN18(VAR2, VAR11, &VAR37);\nif (FUN19(VAR36)) {\nFUN5(VAR6,\n\"STR\",\nVAR13, FUN12(VAR11), VAR9,\nFUN20(VAR36));\nreturn -VAR21;\n}\nif (FUN21(VAR1, VAR23, VAR22, VAR37))\nreturn -VAR21;\n} else {\nFUN5(VAR6, \"STR\", VAR13,\nVAR7 ? \"STR\" : \"STR\", VAR8, VAR3);\nreturn -VAR21;\n}\n}\nreturn 0;\n}\n",
      "code_after_change_raw": "static int btf_check_func_arg_match(struct bpf_verifier_env *env,\nconst struct btf *btf, u32 func_id,\nstruct bpf_reg_state *regs,\nbool ptr_to_mem_ok)\n{\nstruct bpf_verifier_log *log = &env->log;\nbool is_kfunc = btf_is_kernel(btf);\nconst char *func_name, *ref_tname;\nconst struct btf_type *t, *ref_t;\nconst struct btf_param *args;\nu32 i, nargs, ref_id;\nt = btf_type_by_id(btf, func_id);\nif (!t || !btf_type_is_func(t)) {\nbpf_log(log, \"BTF of func_id %u doesn't point to KIND_FUNC\\n\",\nfunc_id);\nreturn -EFAULT;\n}\nfunc_name = btf_name_by_offset(btf, t->name_off);\nt = btf_type_by_id(btf, t->type);\nif (!t || !btf_type_is_func_proto(t)) {\nbpf_log(log, \"Invalid BTF of func %s\\n\", func_name);\nreturn -EFAULT;\n}\nargs = (const struct btf_param *)(t + 1);\nnargs = btf_type_vlen(t);\nif (nargs > MAX_BPF_FUNC_REG_ARGS) {\nbpf_log(log, \"Function %s has %d > %d args\\n\", func_name, nargs,\nMAX_BPF_FUNC_REG_ARGS);\nreturn -EINVAL;\n}\nfor (i = 0; i < nargs; i++) {\nu32 regno = i + 1;\nstruct bpf_reg_state *reg = &regs[regno];\nt = btf_type_skip_modifiers(btf, args[i].type, NULL);\nif (btf_type_is_scalar(t)) {\nif (reg->type == SCALAR_VALUE)\ncontinue;\nbpf_log(log, \"R%d is not a scalar\\n\", regno);\nreturn -EINVAL;\n}\nif (!btf_type_is_ptr(t)) {\nbpf_log(log, \"Unrecognized arg#%d type %s\\n\",\ni, btf_type_str(t));\nreturn -EINVAL;\n}\nref_t = btf_type_skip_modifiers(btf, t->type, &ref_id);\nref_tname = btf_name_by_offset(btf, ref_t->name_off);\nif (btf_get_prog_ctx_type(log, btf, t,\nenv->prog->type, i)) {\nif (reg->type != PTR_TO_CTX) {\nbpf_log(log,\n\"arg#%d expected pointer to ctx, but got %s\\n\",\ni, btf_type_str(t));\nreturn -EINVAL;\n}\nif (check_ptr_off_reg(env, reg, regno))\nreturn -EINVAL;\n} else if (is_kfunc && (reg->type == PTR_TO_BTF_ID || reg2btf_ids[reg->type])) {\nconst struct btf_type *reg_ref_t;\nconst struct btf *reg_btf;\nconst char *reg_ref_tname;\nu32 reg_ref_id;\nif (!btf_type_is_struct(ref_t)) {\nbpf_log(log, \"kernel function %s args#%d pointer type %s %s is not supported\\n\",\nfunc_name, i, btf_type_str(ref_t),\nref_tname);\nreturn -EINVAL;\n}\nif (reg->type == PTR_TO_BTF_ID) {\nreg_btf = reg->btf;\nreg_ref_id = reg->btf_id;\n} else {\nreg_btf = btf_vmlinux;\nreg_ref_id = *reg2btf_ids[reg->type];\n}\nreg_ref_t = btf_type_skip_modifiers(reg_btf, reg_ref_id,\n&reg_ref_id);\nreg_ref_tname = btf_name_by_offset(reg_btf,\nreg_ref_t->name_off);\nif (!btf_struct_ids_match(log, reg_btf, reg_ref_id,\nreg->off, btf, ref_id)) {\nbpf_log(log, \"kernel function %s args#%d expected pointer to %s %s but R%d has a pointer to %s %s\\n\",\nfunc_name, i,\nbtf_type_str(ref_t), ref_tname,\nregno, btf_type_str(reg_ref_t),\nreg_ref_tname);\nreturn -EINVAL;\n}\n} else if (ptr_to_mem_ok) {\nconst struct btf_type *resolve_ret;\nu32 type_size;\nif (is_kfunc) {\nif (!btf_type_is_scalar(ref_t) &&\n!__btf_type_is_scalar_struct(log, btf, ref_t, 0)) {\nbpf_log(log,\n\"arg#%d pointer type %s %s must point to scalar or struct with scalar\\n\",\ni, btf_type_str(ref_t), ref_tname);\nreturn -EINVAL;\n}\n}\nresolve_ret = btf_resolve_size(btf, ref_t, &type_size);\nif (IS_ERR(resolve_ret)) {\nbpf_log(log,\n\"arg#%d reference type('%s %s') size cannot be determined: %ld\\n\",\ni, btf_type_str(ref_t), ref_tname,\nPTR_ERR(resolve_ret));\nreturn -EINVAL;\n}\nif (check_mem_reg(env, reg, regno, type_size))\nreturn -EINVAL;\n} else {\nbpf_log(log, \"reg type unsupported for arg#%d %sfunction %s#%d\\n\", i,\nis_kfunc ? \"kernel \" : \"\", func_name, func_id);\nreturn -EINVAL;\n}\n}\nreturn 0;\n}\n",
      "code_before_change_raw": "static int btf_check_func_arg_match(struct bpf_verifier_env *env,\nconst struct btf *btf, u32 func_id,\nstruct bpf_reg_state *regs,\nbool ptr_to_mem_ok)\n{\nstruct bpf_verifier_log *log = &env->log;\nbool is_kfunc = btf_is_kernel(btf);\nconst char *func_name, *ref_tname;\nconst struct btf_type *t, *ref_t;\nconst struct btf_param *args;\nu32 i, nargs, ref_id;\nt = btf_type_by_id(btf, func_id);\nif (!t || !btf_type_is_func(t)) {\nbpf_log(log, \"BTF of func_id %u doesn't point to KIND_FUNC\\n\",\nfunc_id);\nreturn -EFAULT;\n}\nfunc_name = btf_name_by_offset(btf, t->name_off);\nt = btf_type_by_id(btf, t->type);\nif (!t || !btf_type_is_func_proto(t)) {\nbpf_log(log, \"Invalid BTF of func %s\\n\", func_name);\nreturn -EFAULT;\n}\nargs = (const struct btf_param *)(t + 1);\nnargs = btf_type_vlen(t);\nif (nargs > MAX_BPF_FUNC_REG_ARGS) {\nbpf_log(log, \"Function %s has %d > %d args\\n\", func_name, nargs,\nMAX_BPF_FUNC_REG_ARGS);\nreturn -EINVAL;\n}\nfor (i = 0; i < nargs; i++) {\nu32 regno = i + 1;\nstruct bpf_reg_state *reg = &regs[regno];\nt = btf_type_skip_modifiers(btf, args[i].type, NULL);\nif (btf_type_is_scalar(t)) {\nif (reg->type == SCALAR_VALUE)\ncontinue;\nbpf_log(log, \"R%d is not a scalar\\n\", regno);\nreturn -EINVAL;\n}\nif (!btf_type_is_ptr(t)) {\nbpf_log(log, \"Unrecognized arg#%d type %s\\n\",\ni, btf_type_str(t));\nreturn -EINVAL;\n}\nref_t = btf_type_skip_modifiers(btf, t->type, &ref_id);\nref_tname = btf_name_by_offset(btf, ref_t->name_off);\nif (btf_get_prog_ctx_type(log, btf, t,\nenv->prog->type, i)) {\nif (reg->type != PTR_TO_CTX) {\nbpf_log(log,\n\"arg#%d expected pointer to ctx, but got %s\\n\",\ni, btf_type_str(t));\nreturn -EINVAL;\n}\nif (check_ctx_reg(env, reg, regno))\nreturn -EINVAL;\n} else if (is_kfunc && (reg->type == PTR_TO_BTF_ID || reg2btf_ids[reg->type])) {\nconst struct btf_type *reg_ref_t;\nconst struct btf *reg_btf;\nconst char *reg_ref_tname;\nu32 reg_ref_id;\nif (!btf_type_is_struct(ref_t)) {\nbpf_log(log, \"kernel function %s args#%d pointer type %s %s is not supported\\n\",\nfunc_name, i, btf_type_str(ref_t),\nref_tname);\nreturn -EINVAL;\n}\nif (reg->type == PTR_TO_BTF_ID) {\nreg_btf = reg->btf;\nreg_ref_id = reg->btf_id;\n} else {\nreg_btf = btf_vmlinux;\nreg_ref_id = *reg2btf_ids[reg->type];\n}\nreg_ref_t = btf_type_skip_modifiers(reg_btf, reg_ref_id,\n&reg_ref_id);\nreg_ref_tname = btf_name_by_offset(reg_btf,\nreg_ref_t->name_off);\nif (!btf_struct_ids_match(log, reg_btf, reg_ref_id,\nreg->off, btf, ref_id)) {\nbpf_log(log, \"kernel function %s args#%d expected pointer to %s %s but R%d has a pointer to %s %s\\n\",\nfunc_name, i,\nbtf_type_str(ref_t), ref_tname,\nregno, btf_type_str(reg_ref_t),\nreg_ref_tname);\nreturn -EINVAL;\n}\n} else if (ptr_to_mem_ok) {\nconst struct btf_type *resolve_ret;\nu32 type_size;\nif (is_kfunc) {\nif (!btf_type_is_scalar(ref_t) &&\n!__btf_type_is_scalar_struct(log, btf, ref_t, 0)) {\nbpf_log(log,\n\"arg#%d pointer type %s %s must point to scalar or struct with scalar\\n\",\ni, btf_type_str(ref_t), ref_tname);\nreturn -EINVAL;\n}\n}\nresolve_ret = btf_resolve_size(btf, ref_t, &type_size);\nif (IS_ERR(resolve_ret)) {\nbpf_log(log,\n\"arg#%d reference type('%s %s') size cannot be determined: %ld\\n\",\ni, btf_type_str(ref_t), ref_tname,\nPTR_ERR(resolve_ret));\nreturn -EINVAL;\n}\nif (check_mem_reg(env, reg, regno, type_size))\nreturn -EINVAL;\n} else {\nbpf_log(log, \"reg type unsupported for arg#%d %sfunction %s#%d\\n\", i,\nis_kfunc ? \"kernel \" : \"\", func_name, func_id);\nreturn -EINVAL;\n}\n}\nreturn 0;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper input validation in the code snippet allows for an out-of-bounds (OOB) memory access vulnerability.",
        "trigger_condition": "A local attacker with special privileges can exploit the vulnerability by manipulating certain parameters to trigger an OOB memory access, potentially crashing the system or leaking internal information.",
        "specific_code_behavior_causing_vulnerability": "The code snippet lacks proper bounds checking and validation for memory accesses, leading to the possibility of accessing memory locations outside the allocated regions, which can be exploited by an attacker to cause harm."
      },
      "solution": "To mitigate the vulnerability, it is essential to enhance input validation and bounds checking in the code snippet to ensure that memory accesses are within the allocated memory regions. By adding appropriate checks and validations, the code can prevent OOB memory accesses and strengthen the security of the system.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2021-4204, which involves an out-of-bounds (OOB) memory access flaw in the Linux kernel's eBPF due to improper input validation. By making the specified changes in the code snippet, you are implementing a fix to prevent a local attacker with special privileges from exploiting the vulnerability to crash the system or leak internal information. The modifications aim to improve input validation and ensure that memory accesses are properly bounded within the allocated memory regions, thereby enhancing the security and stability of the system.",
      "GPT_purpose": "Check memory access permissions for eBPF programs.",
      "GPT_function": "\n1. Check memory access for various types of pointers.\n2. Perform alignment checks.\n3. Handle different types of memory access operations like read and write.\n4. Check access to different memory regions such as maps, stack, packet data, etc.\n5. Handle special cases like context access and buffer access.\n6. Perform bounds checks for stack and packet data access.\n7. Handle different error conditions and return appropriate error codes.",
      "CVE_id": "CVE-2021-4204",
      "code_before_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_KEY) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"write to change key R%d not allowed\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->map_ptr->key_size, false);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_map_access_type(env, regno, off, size, t);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\tstruct bpf_map *map = reg->map_ptr;\n\n\t\t\t/* if map is read-only, track its contents as scalars */\n\t\t\tif (tnum_is_const(reg->var_off) &&\n\t\t\t    bpf_map_is_rdonly(map) &&\n\t\t\t    map->ops->map_direct_value_addr) {\n\t\t\t\tint map_off = off + reg->var_off.value;\n\t\t\t\tu64 val = 0;\n\n\t\t\t\terr = bpf_map_direct_read(map, map_off, size,\n\t\t\t\t\t\t\t  &val);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tregs[value_regno].type = SCALAR_VALUE;\n\t\t\t\t__mark_reg_known(&regs[value_regno], val);\n\t\t\t} else {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t}\n\t\t}\n\t} else if (base_type(reg->type) == PTR_TO_MEM) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\n\t\tif (type_may_be_null(reg->type)) {\n\t\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\t\treg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && rdonly_mem) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->mem_size, false);\n\t\tif (!err && value_regno >= 0 && (t == BPF_READ || rdonly_mem))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\t\tstruct btf *btf = NULL;\n\t\tu32 btf_id = 0;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\n\t\tif (err)\n\t\t\tverbose_linfo(env, insn_idx, \"; \");\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE) {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t} else {\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\t\tif (type_may_be_null(reg_type))\n\t\t\t\t\tregs[value_regno].id = ++env->id_gen;\n\t\t\t\t/* A load of ctx field could have different\n\t\t\t\t * actual load size with the one encoded in the\n\t\t\t\t * insn. When the dst is PTR, it is for sure not\n\t\t\t\t * a sub-register.\n\t\t\t\t */\n\t\t\t\tregs[value_regno].subreg_def = DEF_NOT_SUBREG;\n\t\t\t\tif (base_type(reg_type) == PTR_TO_BTF_ID) {\n\t\t\t\t\tregs[value_regno].btf = btf;\n\t\t\t\t\tregs[value_regno].btf_id = btf_id;\n\t\t\t\t}\n\t\t\t}\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* Basic bounds checks. */\n\t\terr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_READ)\n\t\t\terr = check_stack_read(env, regno, off, size,\n\t\t\t\t\t       value_regno);\n\t\telse\n\t\t\terr = check_stack_write(env, regno, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_FLOW_KEYS) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into flow keys\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_flow_keys_access(env, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (type_is_sk_pointer(reg->type)) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_sock_access(env, insn_idx, regno, off, size, t);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_TP_BUFFER) {\n\t\terr = check_tp_buffer_access(env, reg, regno, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_BTF_ID) {\n\t\terr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == CONST_PTR_TO_MAP) {\n\t\terr = check_ptr_to_map_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (base_type(reg->type) == PTR_TO_BUF) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\t\tconst char *buf_info;\n\t\tu32 *max_access;\n\n\t\tif (rdonly_mem) {\n\t\t\tif (t == BPF_WRITE) {\n\t\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\t\t\tbuf_info = \"rdonly\";\n\t\t\tmax_access = &env->prog->aux->max_rdonly_access;\n\t\t} else {\n\t\t\tbuf_info = \"rdwr\";\n\t\t\tmax_access = &env->prog->aux->max_rdwr_access;\n\t\t}\n\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  buf_info, max_access);\n\n\t\tif (!err && value_regno >= 0 && (rdonly_mem || t == BPF_READ))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str(env, reg->type));\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
      "code_after_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_KEY) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"write to change key R%d not allowed\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->map_ptr->key_size, false);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_map_access_type(env, regno, off, size, t);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\tstruct bpf_map *map = reg->map_ptr;\n\n\t\t\t/* if map is read-only, track its contents as scalars */\n\t\t\tif (tnum_is_const(reg->var_off) &&\n\t\t\t    bpf_map_is_rdonly(map) &&\n\t\t\t    map->ops->map_direct_value_addr) {\n\t\t\t\tint map_off = off + reg->var_off.value;\n\t\t\t\tu64 val = 0;\n\n\t\t\t\terr = bpf_map_direct_read(map, map_off, size,\n\t\t\t\t\t\t\t  &val);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tregs[value_regno].type = SCALAR_VALUE;\n\t\t\t\t__mark_reg_known(&regs[value_regno], val);\n\t\t\t} else {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t}\n\t\t}\n\t} else if (base_type(reg->type) == PTR_TO_MEM) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\n\t\tif (type_may_be_null(reg->type)) {\n\t\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\t\treg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && rdonly_mem) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->mem_size, false);\n\t\tif (!err && value_regno >= 0 && (t == BPF_READ || rdonly_mem))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\t\tstruct btf *btf = NULL;\n\t\tu32 btf_id = 0;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_ptr_off_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\n\t\tif (err)\n\t\t\tverbose_linfo(env, insn_idx, \"; \");\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE) {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t} else {\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\t\tif (type_may_be_null(reg_type))\n\t\t\t\t\tregs[value_regno].id = ++env->id_gen;\n\t\t\t\t/* A load of ctx field could have different\n\t\t\t\t * actual load size with the one encoded in the\n\t\t\t\t * insn. When the dst is PTR, it is for sure not\n\t\t\t\t * a sub-register.\n\t\t\t\t */\n\t\t\t\tregs[value_regno].subreg_def = DEF_NOT_SUBREG;\n\t\t\t\tif (base_type(reg_type) == PTR_TO_BTF_ID) {\n\t\t\t\t\tregs[value_regno].btf = btf;\n\t\t\t\t\tregs[value_regno].btf_id = btf_id;\n\t\t\t\t}\n\t\t\t}\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* Basic bounds checks. */\n\t\terr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_READ)\n\t\t\terr = check_stack_read(env, regno, off, size,\n\t\t\t\t\t       value_regno);\n\t\telse\n\t\t\terr = check_stack_write(env, regno, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_FLOW_KEYS) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into flow keys\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_flow_keys_access(env, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (type_is_sk_pointer(reg->type)) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_sock_access(env, insn_idx, regno, off, size, t);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_TP_BUFFER) {\n\t\terr = check_tp_buffer_access(env, reg, regno, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_BTF_ID) {\n\t\terr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == CONST_PTR_TO_MAP) {\n\t\terr = check_ptr_to_map_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (base_type(reg->type) == PTR_TO_BUF) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\t\tconst char *buf_info;\n\t\tu32 *max_access;\n\n\t\tif (rdonly_mem) {\n\t\t\tif (t == BPF_WRITE) {\n\t\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\t\t\tbuf_info = \"rdonly\";\n\t\t\tmax_access = &env->prog->aux->max_rdonly_access;\n\t\t} else {\n\t\t\tbuf_info = \"rdwr\";\n\t\t\tmax_access = &env->prog->aux->max_rdwr_access;\n\t\t}\n\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  buf_info, max_access);\n\n\t\tif (!err && value_regno >= 0 && (rdonly_mem || t == BPF_READ))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str(env, reg->type));\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
      "modified_lines": {
        "added": [
          "\t\terr = check_ptr_off_reg(env, reg, regno);"
        ],
        "deleted": [
          "\t\terr = check_ctx_reg(env, reg, regno);"
        ]
      },
      "preconditions_for_vulnerability": "Improper input validation in the code snippet allows for an out-of-bounds (OOB) memory access vulnerability.",
      "trigger_condition": "A local attacker with special privileges can exploit the vulnerability by manipulating certain parameters to trigger an OOB memory access, potentially crashing the system or leaking internal information.",
      "specific_code_behavior_causing_vulnerability": "The code snippet lacks proper bounds checking and validation for memory accesses, leading to the possibility of accessing memory locations outside the allocated regions, which can be exploited by an attacker to cause harm.",
      "id": 151,
      "code_after_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1, int VAR2, u32 VAR3,\nint VAR4, int VAR5, enum bpf_access_type VAR6,\nint VAR7, bool VAR8)\n{\nstruct bpf_reg_state *VAR9 = FUN2(VAR1);\nstruct bpf_reg_state *VAR10 = VAR9 + VAR3;\nstruct bpf_func_state *VAR11;\nint VAR12, VAR13 = 0;\nVAR12 = FUN3(VAR5);\nif (VAR12 < 0)\nreturn VAR12;\nVAR13 = FUN4(VAR1, VAR10, VAR4, VAR12, VAR8);\nif (VAR13)\nreturn VAR13;\nVAR4 += VAR10->VAR4;\nif (VAR10->VAR14 == VAR15) {\nif (VAR6 == VAR16) {\nFUN5(VAR1, \"STR\", VAR3);\nreturn -VAR17;\n}\nVAR13 = FUN6(VAR1, VAR3, VAR4, VAR12,\nVAR10->VAR18->VAR19, false);\nif (VAR13)\nreturn VAR13;\nif (VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR20) {\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\", VAR7);\nreturn -VAR17;\n}\nVAR13 = FUN9(VAR1, VAR3, VAR4, VAR12, VAR6);\nif (VAR13)\nreturn VAR13;\nVAR13 = FUN10(VAR1, VAR3, VAR4, VAR12, false);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0) {\nstruct bpf_map *VAR22 = VAR10->VAR18;\nif (FUN11(VAR10->VAR23) &&\nFUN12(VAR22) &&\nVAR22->VAR24->VAR25) {\nint VAR26 = VAR4 + VAR10->VAR23.VAR27;\nu64 VAR28 = 0;\nVAR13 = FUN13(VAR22, VAR26, VAR12,\n&VAR28);\nif (VAR13)\nreturn VAR13;\nVAR9[VAR7].VAR14 = VAR29;\nFUN14(&VAR9[VAR7], VAR28);\n} else {\nFUN7(VAR1, VAR9, VAR7);\n}\n}\n} else if (FUN15(VAR10->VAR14) == VAR30) {\nbool VAR31 = FUN16(VAR10->VAR14);\nif (FUN17(VAR10->VAR14)) {\nFUN5(VAR1, \"STR\", VAR3,\nFUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nif (VAR6 == VAR16 && VAR31) {\nFUN5(VAR1, \"STR\",\nVAR3, FUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\", VAR7);\nreturn -VAR17;\n}\nVAR13 = FUN6(VAR1, VAR3, VAR4, VAR12,\nVAR10->VAR32, false);\nif (!VAR13 && VAR7 >= 0 && (VAR6 == VAR21 || VAR31))\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR33) {\nenum bpf_reg_type VAR34 = VAR29;\nstruct VAR35 *VAR35 = NULL;\nu32 VAR36 = 0;\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\", VAR7);\nreturn -VAR17;\n}\nVAR13 = FUN19(VAR1, VAR10, VAR3);\nif (VAR13 < 0)\nreturn VAR13;\nVAR13 = FUN20(VAR1, VAR2, VAR4, VAR12, VAR6, &VAR34, &VAR35, &VAR36);\nif (VAR13)\nFUN21(VAR1, VAR2, \"STR\");\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0) {\nif (VAR34 == VAR29) {\nFUN7(VAR1, VAR9, VAR7);\n} else {\nFUN22(VAR1, VAR9,\nVAR7);\nif (FUN17(VAR34))\nVAR9[VAR7].VAR37 = ++VAR1->VAR38;\nVAR9[VAR7].VAR39 = VAR40;\nif (FUN15(VAR34) == VAR41) {\nVAR9[VAR7].VAR35 = VAR35;\nVAR9[VAR7].VAR36 = VAR36;\n}\n}\nVAR9[VAR7].VAR14 = VAR34;\n}\n} else if (VAR10->VAR14 == VAR42) {\nVAR13 = FUN23(VAR1, VAR3, VAR4, VAR12, VAR43, VAR6);\nif (VAR13)\nreturn VAR13;\nVAR11 = FUN24(VAR1, VAR10);\nVAR13 = FUN25(VAR1, VAR11, VAR4);\nif (VAR13)\nreturn VAR13;\nif (VAR6 == VAR21)\nVAR13 = FUN26(VAR1, VAR3, VAR4, VAR12,\nVAR7);\nelse\nVAR13 = FUN27(VAR1, VAR3, VAR4, VAR12,\nVAR7, VAR2);\n} else if (FUN28(VAR10)) {\nif (VAR6 == VAR16 && !FUN29(VAR1, NULL, VAR6)) {\nFUN5(VAR1, \"STR\");\nreturn -VAR17;\n}\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\",\nVAR7);\nreturn -VAR17;\n}\nVAR13 = FUN30(VAR1, VAR3, VAR4, VAR12, false);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR44) {\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\",\nVAR7);\nreturn -VAR17;\n}\nVAR13 = FUN31(VAR1, VAR4, VAR12);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (FUN32(VAR10->VAR14)) {\nif (VAR6 == VAR16) {\nFUN5(VAR1, \"STR\",\nVAR3, FUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nVAR13 = FUN33(VAR1, VAR2, VAR3, VAR4, VAR12, VAR6);\nif (!VAR13 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR45) {\nVAR13 = FUN34(VAR1, VAR10, VAR3, VAR4, VAR12);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR41) {\nVAR13 = FUN35(VAR1, VAR9, VAR3, VAR4, VAR12, VAR6,\nVAR7);\n} else if (VAR10->VAR14 == VAR46) {\nVAR13 = FUN36(VAR1, VAR9, VAR3, VAR4, VAR12, VAR6,\nVAR7);\n} else if (FUN15(VAR10->VAR14) == VAR47) {\nbool VAR31 = FUN16(VAR10->VAR14);\nconst char *VAR48;\nu32 *VAR49;\nif (VAR31) {\nif (VAR6 == VAR16) {\nFUN5(VAR1, \"STR\",\nVAR3, FUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nVAR48 = \"STR\";\nVAR49 = &VAR1->VAR50->VAR51->VAR52;\n} else {\nVAR48 = \"STR\";\nVAR49 = &VAR1->VAR50->VAR51->VAR53;\n}\nVAR13 = FUN37(VAR1, VAR10, VAR3, VAR4, VAR12, false,\nVAR48, VAR49);\nif (!VAR13 && VAR7 >= 0 && (VAR31 || VAR6 == VAR21))\nFUN7(VAR1, VAR9, VAR7);\n} else {\nFUN5(VAR1, \"STR\", VAR3,\nFUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nif (!VAR13 && VAR12 < VAR54 && VAR7 >= 0 && VAR6 == VAR21 &&\nVAR9[VAR7].VAR14 == VAR29) {\nFUN38(&VAR9[VAR7], VAR12);\n}\nreturn VAR13;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1, int VAR2, u32 VAR3,\nint VAR4, int VAR5, enum bpf_access_type VAR6,\nint VAR7, bool VAR8)\n{\nstruct bpf_reg_state *VAR9 = FUN2(VAR1);\nstruct bpf_reg_state *VAR10 = VAR9 + VAR3;\nstruct bpf_func_state *VAR11;\nint VAR12, VAR13 = 0;\nVAR12 = FUN3(VAR5);\nif (VAR12 < 0)\nreturn VAR12;\nVAR13 = FUN4(VAR1, VAR10, VAR4, VAR12, VAR8);\nif (VAR13)\nreturn VAR13;\nVAR4 += VAR10->VAR4;\nif (VAR10->VAR14 == VAR15) {\nif (VAR6 == VAR16) {\nFUN5(VAR1, \"STR\", VAR3);\nreturn -VAR17;\n}\nVAR13 = FUN6(VAR1, VAR3, VAR4, VAR12,\nVAR10->VAR18->VAR19, false);\nif (VAR13)\nreturn VAR13;\nif (VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR20) {\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\", VAR7);\nreturn -VAR17;\n}\nVAR13 = FUN9(VAR1, VAR3, VAR4, VAR12, VAR6);\nif (VAR13)\nreturn VAR13;\nVAR13 = FUN10(VAR1, VAR3, VAR4, VAR12, false);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0) {\nstruct bpf_map *VAR22 = VAR10->VAR18;\nif (FUN11(VAR10->VAR23) &&\nFUN12(VAR22) &&\nVAR22->VAR24->VAR25) {\nint VAR26 = VAR4 + VAR10->VAR23.VAR27;\nu64 VAR28 = 0;\nVAR13 = FUN13(VAR22, VAR26, VAR12,\n&VAR28);\nif (VAR13)\nreturn VAR13;\nVAR9[VAR7].VAR14 = VAR29;\nFUN14(&VAR9[VAR7], VAR28);\n} else {\nFUN7(VAR1, VAR9, VAR7);\n}\n}\n} else if (FUN15(VAR10->VAR14) == VAR30) {\nbool VAR31 = FUN16(VAR10->VAR14);\nif (FUN17(VAR10->VAR14)) {\nFUN5(VAR1, \"STR\", VAR3,\nFUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nif (VAR6 == VAR16 && VAR31) {\nFUN5(VAR1, \"STR\",\nVAR3, FUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\", VAR7);\nreturn -VAR17;\n}\nVAR13 = FUN6(VAR1, VAR3, VAR4, VAR12,\nVAR10->VAR32, false);\nif (!VAR13 && VAR7 >= 0 && (VAR6 == VAR21 || VAR31))\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR33) {\nenum bpf_reg_type VAR34 = VAR29;\nstruct VAR35 *VAR35 = NULL;\nu32 VAR36 = 0;\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\", VAR7);\nreturn -VAR17;\n}\nVAR13 = FUN19(VAR1, VAR10, VAR3);\nif (VAR13 < 0)\nreturn VAR13;\nVAR13 = FUN20(VAR1, VAR2, VAR4, VAR12, VAR6, &VAR34, &VAR35, &VAR36);\nif (VAR13)\nFUN21(VAR1, VAR2, \"STR\");\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0) {\nif (VAR34 == VAR29) {\nFUN7(VAR1, VAR9, VAR7);\n} else {\nFUN22(VAR1, VAR9,\nVAR7);\nif (FUN17(VAR34))\nVAR9[VAR7].VAR37 = ++VAR1->VAR38;\nVAR9[VAR7].VAR39 = VAR40;\nif (FUN15(VAR34) == VAR41) {\nVAR9[VAR7].VAR35 = VAR35;\nVAR9[VAR7].VAR36 = VAR36;\n}\n}\nVAR9[VAR7].VAR14 = VAR34;\n}\n} else if (VAR10->VAR14 == VAR42) {\nVAR13 = FUN23(VAR1, VAR3, VAR4, VAR12, VAR43, VAR6);\nif (VAR13)\nreturn VAR13;\nVAR11 = FUN24(VAR1, VAR10);\nVAR13 = FUN25(VAR1, VAR11, VAR4);\nif (VAR13)\nreturn VAR13;\nif (VAR6 == VAR21)\nVAR13 = FUN26(VAR1, VAR3, VAR4, VAR12,\nVAR7);\nelse\nVAR13 = FUN27(VAR1, VAR3, VAR4, VAR12,\nVAR7, VAR2);\n} else if (FUN28(VAR10)) {\nif (VAR6 == VAR16 && !FUN29(VAR1, NULL, VAR6)) {\nFUN5(VAR1, \"STR\");\nreturn -VAR17;\n}\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\",\nVAR7);\nreturn -VAR17;\n}\nVAR13 = FUN30(VAR1, VAR3, VAR4, VAR12, false);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR44) {\nif (VAR6 == VAR16 && VAR7 >= 0 &&\nFUN8(VAR1, VAR7)) {\nFUN5(VAR1, \"STR\",\nVAR7);\nreturn -VAR17;\n}\nVAR13 = FUN31(VAR1, VAR4, VAR12);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (FUN32(VAR10->VAR14)) {\nif (VAR6 == VAR16) {\nFUN5(VAR1, \"STR\",\nVAR3, FUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nVAR13 = FUN33(VAR1, VAR2, VAR3, VAR4, VAR12, VAR6);\nif (!VAR13 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR45) {\nVAR13 = FUN34(VAR1, VAR10, VAR3, VAR4, VAR12);\nif (!VAR13 && VAR6 == VAR21 && VAR7 >= 0)\nFUN7(VAR1, VAR9, VAR7);\n} else if (VAR10->VAR14 == VAR41) {\nVAR13 = FUN35(VAR1, VAR9, VAR3, VAR4, VAR12, VAR6,\nVAR7);\n} else if (VAR10->VAR14 == VAR46) {\nVAR13 = FUN36(VAR1, VAR9, VAR3, VAR4, VAR12, VAR6,\nVAR7);\n} else if (FUN15(VAR10->VAR14) == VAR47) {\nbool VAR31 = FUN16(VAR10->VAR14);\nconst char *VAR48;\nu32 *VAR49;\nif (VAR31) {\nif (VAR6 == VAR16) {\nFUN5(VAR1, \"STR\",\nVAR3, FUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nVAR48 = \"STR\";\nVAR49 = &VAR1->VAR50->VAR51->VAR52;\n} else {\nVAR48 = \"STR\";\nVAR49 = &VAR1->VAR50->VAR51->VAR53;\n}\nVAR13 = FUN37(VAR1, VAR10, VAR3, VAR4, VAR12, false,\nVAR48, VAR49);\nif (!VAR13 && VAR7 >= 0 && (VAR31 || VAR6 == VAR21))\nFUN7(VAR1, VAR9, VAR7);\n} else {\nFUN5(VAR1, \"STR\", VAR3,\nFUN18(VAR1, VAR10->VAR14));\nreturn -VAR17;\n}\nif (!VAR13 && VAR12 < VAR54 && VAR7 >= 0 && VAR6 == VAR21 &&\nVAR9[VAR7].VAR14 == VAR29) {\nFUN38(&VAR9[VAR7], VAR12);\n}\nreturn VAR13;\n}\n",
      "code_after_change_raw": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\nint off, int bpf_size, enum bpf_access_type t,\nint value_regno, bool strict_alignment_once)\n{\nstruct bpf_reg_state *regs = cur_regs(env);\nstruct bpf_reg_state *reg = regs + regno;\nstruct bpf_func_state *state;\nint size, err = 0;\nsize = bpf_size_to_bytes(bpf_size);\nif (size < 0)\nreturn size;\nerr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\nif (err)\nreturn err;\noff += reg->off;\nif (reg->type == PTR_TO_MAP_KEY) {\nif (t == BPF_WRITE) {\nverbose(env, \"write to change key R%d not allowed\\n\", regno);\nreturn -EACCES;\n}\nerr = check_mem_region_access(env, regno, off, size,\nreg->map_ptr->key_size, false);\nif (err)\nreturn err;\nif (value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_MAP_VALUE) {\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into map\\n\", value_regno);\nreturn -EACCES;\n}\nerr = check_map_access_type(env, regno, off, size, t);\nif (err)\nreturn err;\nerr = check_map_access(env, regno, off, size, false);\nif (!err && t == BPF_READ && value_regno >= 0) {\nstruct bpf_map *map = reg->map_ptr;\nif (tnum_is_const(reg->var_off) &&\nbpf_map_is_rdonly(map) &&\nmap->ops->map_direct_value_addr) {\nint map_off = off + reg->var_off.value;\nu64 val = 0;\nerr = bpf_map_direct_read(map, map_off, size,\n&val);\nif (err)\nreturn err;\nregs[value_regno].type = SCALAR_VALUE;\n__mark_reg_known(&regs[value_regno], val);\n} else {\nmark_reg_unknown(env, regs, value_regno);\n}\n}\n} else if (base_type(reg->type) == PTR_TO_MEM) {\nbool rdonly_mem = type_is_rdonly_mem(reg->type);\nif (type_may_be_null(reg->type)) {\nverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\nreg_type_str(env, reg->type));\nreturn -EACCES;\n}\nif (t == BPF_WRITE && rdonly_mem) {\nverbose(env, \"R%d cannot write into %s\\n\",\nregno, reg_type_str(env, reg->type));\nreturn -EACCES;\n}\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\nreturn -EACCES;\n}\nerr = check_mem_region_access(env, regno, off, size,\nreg->mem_size, false);\nif (!err && value_regno >= 0 && (t == BPF_READ || rdonly_mem))\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_CTX) {\nenum bpf_reg_type reg_type = SCALAR_VALUE;\nstruct btf *btf = NULL;\nu32 btf_id = 0;\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\nreturn -EACCES;\n}\nerr = check_ptr_off_reg(env, reg, regno);\nif (err < 0)\nreturn err;\nerr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\nif (err)\nverbose_linfo(env, insn_idx, \"; \");\nif (!err && t == BPF_READ && value_regno >= 0) {\nif (reg_type == SCALAR_VALUE) {\nmark_reg_unknown(env, regs, value_regno);\n} else {\nmark_reg_known_zero(env, regs,\nvalue_regno);\nif (type_may_be_null(reg_type))\nregs[value_regno].id = ++env->id_gen;\nregs[value_regno].subreg_def = DEF_NOT_SUBREG;\nif (base_type(reg_type) == PTR_TO_BTF_ID) {\nregs[value_regno].btf = btf;\nregs[value_regno].btf_id = btf_id;\n}\n}\nregs[value_regno].type = reg_type;\n}\n} else if (reg->type == PTR_TO_STACK) {\nerr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\nif (err)\nreturn err;\nstate = func(env, reg);\nerr = update_stack_depth(env, state, off);\nif (err)\nreturn err;\nif (t == BPF_READ)\nerr = check_stack_read(env, regno, off, size,\nvalue_regno);\nelse\nerr = check_stack_write(env, regno, off, size,\nvalue_regno, insn_idx);\n} else if (reg_is_pkt_pointer(reg)) {\nif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\nverbose(env, \"cannot write into packet\\n\");\nreturn -EACCES;\n}\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into packet\\n\",\nvalue_regno);\nreturn -EACCES;\n}\nerr = check_packet_access(env, regno, off, size, false);\nif (!err && t == BPF_READ && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_FLOW_KEYS) {\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into flow keys\\n\",\nvalue_regno);\nreturn -EACCES;\n}\nerr = check_flow_keys_access(env, off, size);\nif (!err && t == BPF_READ && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (type_is_sk_pointer(reg->type)) {\nif (t == BPF_WRITE) {\nverbose(env, \"R%d cannot write into %s\\n\",\nregno, reg_type_str(env, reg->type));\nreturn -EACCES;\n}\nerr = check_sock_access(env, insn_idx, regno, off, size, t);\nif (!err && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_TP_BUFFER) {\nerr = check_tp_buffer_access(env, reg, regno, off, size);\nif (!err && t == BPF_READ && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_BTF_ID) {\nerr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\nvalue_regno);\n} else if (reg->type == CONST_PTR_TO_MAP) {\nerr = check_ptr_to_map_access(env, regs, regno, off, size, t,\nvalue_regno);\n} else if (base_type(reg->type) == PTR_TO_BUF) {\nbool rdonly_mem = type_is_rdonly_mem(reg->type);\nconst char *buf_info;\nu32 *max_access;\nif (rdonly_mem) {\nif (t == BPF_WRITE) {\nverbose(env, \"R%d cannot write into %s\\n\",\nregno, reg_type_str(env, reg->type));\nreturn -EACCES;\n}\nbuf_info = \"rdonly\";\nmax_access = &env->prog->aux->max_rdonly_access;\n} else {\nbuf_info = \"rdwr\";\nmax_access = &env->prog->aux->max_rdwr_access;\n}\nerr = check_buffer_access(env, reg, regno, off, size, false,\nbuf_info, max_access);\nif (!err && value_regno >= 0 && (rdonly_mem || t == BPF_READ))\nmark_reg_unknown(env, regs, value_regno);\n} else {\nverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\nreg_type_str(env, reg->type));\nreturn -EACCES;\n}\nif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\nregs[value_regno].type == SCALAR_VALUE) {\ncoerce_reg_to_size(&regs[value_regno], size);\n}\nreturn err;\n}\n",
      "code_before_change_raw": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\nint off, int bpf_size, enum bpf_access_type t,\nint value_regno, bool strict_alignment_once)\n{\nstruct bpf_reg_state *regs = cur_regs(env);\nstruct bpf_reg_state *reg = regs + regno;\nstruct bpf_func_state *state;\nint size, err = 0;\nsize = bpf_size_to_bytes(bpf_size);\nif (size < 0)\nreturn size;\nerr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\nif (err)\nreturn err;\noff += reg->off;\nif (reg->type == PTR_TO_MAP_KEY) {\nif (t == BPF_WRITE) {\nverbose(env, \"write to change key R%d not allowed\\n\", regno);\nreturn -EACCES;\n}\nerr = check_mem_region_access(env, regno, off, size,\nreg->map_ptr->key_size, false);\nif (err)\nreturn err;\nif (value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_MAP_VALUE) {\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into map\\n\", value_regno);\nreturn -EACCES;\n}\nerr = check_map_access_type(env, regno, off, size, t);\nif (err)\nreturn err;\nerr = check_map_access(env, regno, off, size, false);\nif (!err && t == BPF_READ && value_regno >= 0) {\nstruct bpf_map *map = reg->map_ptr;\nif (tnum_is_const(reg->var_off) &&\nbpf_map_is_rdonly(map) &&\nmap->ops->map_direct_value_addr) {\nint map_off = off + reg->var_off.value;\nu64 val = 0;\nerr = bpf_map_direct_read(map, map_off, size,\n&val);\nif (err)\nreturn err;\nregs[value_regno].type = SCALAR_VALUE;\n__mark_reg_known(&regs[value_regno], val);\n} else {\nmark_reg_unknown(env, regs, value_regno);\n}\n}\n} else if (base_type(reg->type) == PTR_TO_MEM) {\nbool rdonly_mem = type_is_rdonly_mem(reg->type);\nif (type_may_be_null(reg->type)) {\nverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\nreg_type_str(env, reg->type));\nreturn -EACCES;\n}\nif (t == BPF_WRITE && rdonly_mem) {\nverbose(env, \"R%d cannot write into %s\\n\",\nregno, reg_type_str(env, reg->type));\nreturn -EACCES;\n}\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\nreturn -EACCES;\n}\nerr = check_mem_region_access(env, regno, off, size,\nreg->mem_size, false);\nif (!err && value_regno >= 0 && (t == BPF_READ || rdonly_mem))\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_CTX) {\nenum bpf_reg_type reg_type = SCALAR_VALUE;\nstruct btf *btf = NULL;\nu32 btf_id = 0;\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\nreturn -EACCES;\n}\nerr = check_ctx_reg(env, reg, regno);\nif (err < 0)\nreturn err;\nerr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\nif (err)\nverbose_linfo(env, insn_idx, \"; \");\nif (!err && t == BPF_READ && value_regno >= 0) {\nif (reg_type == SCALAR_VALUE) {\nmark_reg_unknown(env, regs, value_regno);\n} else {\nmark_reg_known_zero(env, regs,\nvalue_regno);\nif (type_may_be_null(reg_type))\nregs[value_regno].id = ++env->id_gen;\nregs[value_regno].subreg_def = DEF_NOT_SUBREG;\nif (base_type(reg_type) == PTR_TO_BTF_ID) {\nregs[value_regno].btf = btf;\nregs[value_regno].btf_id = btf_id;\n}\n}\nregs[value_regno].type = reg_type;\n}\n} else if (reg->type == PTR_TO_STACK) {\nerr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\nif (err)\nreturn err;\nstate = func(env, reg);\nerr = update_stack_depth(env, state, off);\nif (err)\nreturn err;\nif (t == BPF_READ)\nerr = check_stack_read(env, regno, off, size,\nvalue_regno);\nelse\nerr = check_stack_write(env, regno, off, size,\nvalue_regno, insn_idx);\n} else if (reg_is_pkt_pointer(reg)) {\nif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\nverbose(env, \"cannot write into packet\\n\");\nreturn -EACCES;\n}\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into packet\\n\",\nvalue_regno);\nreturn -EACCES;\n}\nerr = check_packet_access(env, regno, off, size, false);\nif (!err && t == BPF_READ && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_FLOW_KEYS) {\nif (t == BPF_WRITE && value_regno >= 0 &&\nis_pointer_value(env, value_regno)) {\nverbose(env, \"R%d leaks addr into flow keys\\n\",\nvalue_regno);\nreturn -EACCES;\n}\nerr = check_flow_keys_access(env, off, size);\nif (!err && t == BPF_READ && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (type_is_sk_pointer(reg->type)) {\nif (t == BPF_WRITE) {\nverbose(env, \"R%d cannot write into %s\\n\",\nregno, reg_type_str(env, reg->type));\nreturn -EACCES;\n}\nerr = check_sock_access(env, insn_idx, regno, off, size, t);\nif (!err && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_TP_BUFFER) {\nerr = check_tp_buffer_access(env, reg, regno, off, size);\nif (!err && t == BPF_READ && value_regno >= 0)\nmark_reg_unknown(env, regs, value_regno);\n} else if (reg->type == PTR_TO_BTF_ID) {\nerr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\nvalue_regno);\n} else if (reg->type == CONST_PTR_TO_MAP) {\nerr = check_ptr_to_map_access(env, regs, regno, off, size, t,\nvalue_regno);\n} else if (base_type(reg->type) == PTR_TO_BUF) {\nbool rdonly_mem = type_is_rdonly_mem(reg->type);\nconst char *buf_info;\nu32 *max_access;\nif (rdonly_mem) {\nif (t == BPF_WRITE) {\nverbose(env, \"R%d cannot write into %s\\n\",\nregno, reg_type_str(env, reg->type));\nreturn -EACCES;\n}\nbuf_info = \"rdonly\";\nmax_access = &env->prog->aux->max_rdonly_access;\n} else {\nbuf_info = \"rdwr\";\nmax_access = &env->prog->aux->max_rdwr_access;\n}\nerr = check_buffer_access(env, reg, regno, off, size, false,\nbuf_info, max_access);\nif (!err && value_regno >= 0 && (rdonly_mem || t == BPF_READ))\nmark_reg_unknown(env, regs, value_regno);\n} else {\nverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\nreg_type_str(env, reg->type));\nreturn -EACCES;\n}\nif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\nregs[value_regno].type == SCALAR_VALUE) {\ncoerce_reg_to_size(&regs[value_regno], size);\n}\nreturn err;\n}\n"
    },
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for pointer offsets in the code.",
        "trigger_condition": "An attacker with special privileges exploits the lack of validation to perform an out-of-bounds memory access.",
        "specific_code_behavior_causing_vulnerability": "The code does not include proper validation for pointer offsets, allowing potential out-of-bounds memory access vulnerabilities to occur."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add proper validation for pointer offsets in the code. This ensures that potential out-of-bounds memory access vulnerabilities are prevented. In this case, the solution involves adding a function call to check and validate pointer offsets before proceeding with memory access operations.",
      "GPT_analysis": "The above modification is necessary to fix the vulnerability CVE-2021-4204 in the code snippet provided. The vulnerability is related to an out-of-bounds (OOB) memory access flaw in the Linux kernel's eBPF due to improper input validation. \n\nIn the original code snippet, the function `check_ld_abs` did not include proper validation for pointer offsets, which could potentially lead to out-of-bounds memory access if not handled correctly. By adding the `check_ptr_off_reg` function call in the modified code, we ensure that proper validation is performed on the pointer offsets, helping to prevent potential OOB memory access vulnerabilities.\n\nTherefore, the modification is necessary to enhance the security of the code and prevent local attackers with special privileges from exploiting the vulnerability to crash the system or leak internal information.",
      "GPT_purpose": "Check the validity of BPF_LD_ABS and BPF_LD_IND instructions for a given eBPF program.",
      "GPT_function": "\n1. Check if BPF_LD_[ABS|IND] instructions are allowed for the program type.\n2. Verify the configuration of the BPF verifier.\n3. Validate the usage of BPF_LD_[ABS|IND] instructions and check for reserved fields.\n4. Ensure the implicit source operand (register R6) is readable.\n5. Prevent mixing BPF_LD_[ABS|IND] with socket references to avoid reference leaks.\n6. Restrict the use of BPF_LD_[ABS|IND] inside a bpf_spin_lock-ed region.\n7. Verify that R6 is pointing to the skb before BPF_LD_ABS|IND.\n8. Check explicit source operand if the mode is BPF_IND.\n9. Reset caller saved registers to unreadable state.\n10. Mark destination register R0 as readable and set subreg_def for ld_abs load.",
      "CVE_id": "CVE-2021-4204",
      "code_before_change": "static int check_ld_abs(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstatic const int ctx_reg = BPF_REG_6;\n\tu8 mode = BPF_MODE(insn->code);\n\tint i, err;\n\n\tif (!may_access_skb(resolve_prog_type(env->prog))) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] instructions not allowed for this program type\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env->ops->gen_ld_abs) {\n\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (insn->dst_reg != BPF_REG_0 || insn->off != 0 ||\n\t    BPF_SIZE(insn->code) == BPF_DW ||\n\t    (mode == BPF_ABS && insn->src_reg != BPF_REG_0)) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] uses reserved fields\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* check whether implicit source operand (register R6) is readable */\n\terr = check_reg_arg(env, ctx_reg, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\t/* Disallow usage of BPF_LD_[ABS|IND] with reference tracking, as\n\t * gen_ld_abs() may terminate the program at runtime, leading to\n\t * reference leak.\n\t */\n\terr = check_reference_leak(env);\n\tif (err) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be mixed with socket references\\n\");\n\t\treturn err;\n\t}\n\n\tif (env->cur_state->active_spin_lock) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be used inside bpf_spin_lock-ed region\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (regs[ctx_reg].type != PTR_TO_CTX) {\n\t\tverbose(env,\n\t\t\t\"at the time of BPF_LD_ABS|IND R6 != pointer to skb\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (mode == BPF_IND) {\n\t\t/* check explicit source operand */\n\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = check_ctx_reg(env, &regs[ctx_reg], ctx_reg);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* reset caller saved regs to unreadable */\n\tfor (i = 0; i < CALLER_SAVED_REGS; i++) {\n\t\tmark_reg_not_init(env, regs, caller_saved[i]);\n\t\tcheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n\t}\n\n\t/* mark destination R0 register as readable, since it contains\n\t * the value fetched from the packet.\n\t * Already marked as written above.\n\t */\n\tmark_reg_unknown(env, regs, BPF_REG_0);\n\t/* ld_abs load up to 32-bit skb data. */\n\tregs[BPF_REG_0].subreg_def = env->insn_idx + 1;\n\treturn 0;\n}",
      "code_after_change": "static int check_ld_abs(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstatic const int ctx_reg = BPF_REG_6;\n\tu8 mode = BPF_MODE(insn->code);\n\tint i, err;\n\n\tif (!may_access_skb(resolve_prog_type(env->prog))) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] instructions not allowed for this program type\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env->ops->gen_ld_abs) {\n\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (insn->dst_reg != BPF_REG_0 || insn->off != 0 ||\n\t    BPF_SIZE(insn->code) == BPF_DW ||\n\t    (mode == BPF_ABS && insn->src_reg != BPF_REG_0)) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] uses reserved fields\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* check whether implicit source operand (register R6) is readable */\n\terr = check_reg_arg(env, ctx_reg, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\t/* Disallow usage of BPF_LD_[ABS|IND] with reference tracking, as\n\t * gen_ld_abs() may terminate the program at runtime, leading to\n\t * reference leak.\n\t */\n\terr = check_reference_leak(env);\n\tif (err) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be mixed with socket references\\n\");\n\t\treturn err;\n\t}\n\n\tif (env->cur_state->active_spin_lock) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be used inside bpf_spin_lock-ed region\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (regs[ctx_reg].type != PTR_TO_CTX) {\n\t\tverbose(env,\n\t\t\t\"at the time of BPF_LD_ABS|IND R6 != pointer to skb\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (mode == BPF_IND) {\n\t\t/* check explicit source operand */\n\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = check_ptr_off_reg(env, &regs[ctx_reg], ctx_reg);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* reset caller saved regs to unreadable */\n\tfor (i = 0; i < CALLER_SAVED_REGS; i++) {\n\t\tmark_reg_not_init(env, regs, caller_saved[i]);\n\t\tcheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n\t}\n\n\t/* mark destination R0 register as readable, since it contains\n\t * the value fetched from the packet.\n\t * Already marked as written above.\n\t */\n\tmark_reg_unknown(env, regs, BPF_REG_0);\n\t/* ld_abs load up to 32-bit skb data. */\n\tregs[BPF_REG_0].subreg_def = env->insn_idx + 1;\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\terr = check_ptr_off_reg(env, &regs[ctx_reg], ctx_reg);"
        ],
        "deleted": [
          "\terr = check_ctx_reg(env, &regs[ctx_reg], ctx_reg);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for pointer offsets in the code.",
      "trigger_condition": "An attacker with special privileges exploits the lack of validation to perform an out-of-bounds memory access.",
      "specific_code_behavior_causing_vulnerability": "The code does not include proper validation for pointer offsets, allowing potential out-of-bounds memory access vulnerabilities to occur.",
      "id": 152,
      "code_after_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1, struct bpf_insn *VAR2)\n{\nstruct bpf_reg_state *VAR3 = FUN2(VAR1);\nstatic const int VAR4 = VAR5;\nu8 VAR6 = FUN3(VAR2->VAR7);\nint VAR8, VAR9;\nif (!FUN4(FUN5(VAR1->VAR10))) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nif (!VAR1->VAR12->VAR13) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nif (VAR2->VAR14 != VAR15 || VAR2->VAR16 != 0 ||\nFUN7(VAR2->VAR7) == VAR17 ||\n(VAR6 == VAR18 && VAR2->VAR19 != VAR15)) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nVAR9 = FUN8(VAR1, VAR4, VAR20);\nif (VAR9)\nreturn VAR9;\nVAR9 = FUN9(VAR1);\nif (VAR9) {\nFUN6(VAR1, \"STR\");\nreturn VAR9;\n}\nif (VAR1->VAR21->VAR22) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nif (VAR3[VAR4].VAR23 != VAR24) {\nFUN6(VAR1,\n\"STR\");\nreturn -VAR11;\n}\nif (VAR6 == VAR25) {\nVAR9 = FUN8(VAR1, VAR2->VAR19, VAR20);\nif (VAR9)\nreturn VAR9;\n}\nVAR9 = FUN10(VAR1, &VAR3[VAR4], VAR4);\nif (VAR9 < 0)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR26; VAR8++) {\nFUN11(VAR1, VAR3, VAR27[VAR8]);\nFUN8(VAR1, VAR27[VAR8], VAR28);\n}\nFUN12(VAR1, VAR3, VAR15);\nVAR3[VAR15].VAR29 = VAR1->VAR30 + 1;\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct bpf_verifier_env *VAR1, struct bpf_insn *VAR2)\n{\nstruct bpf_reg_state *VAR3 = FUN2(VAR1);\nstatic const int VAR4 = VAR5;\nu8 VAR6 = FUN3(VAR2->VAR7);\nint VAR8, VAR9;\nif (!FUN4(FUN5(VAR1->VAR10))) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nif (!VAR1->VAR12->VAR13) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nif (VAR2->VAR14 != VAR15 || VAR2->VAR16 != 0 ||\nFUN7(VAR2->VAR7) == VAR17 ||\n(VAR6 == VAR18 && VAR2->VAR19 != VAR15)) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nVAR9 = FUN8(VAR1, VAR4, VAR20);\nif (VAR9)\nreturn VAR9;\nVAR9 = FUN9(VAR1);\nif (VAR9) {\nFUN6(VAR1, \"STR\");\nreturn VAR9;\n}\nif (VAR1->VAR21->VAR22) {\nFUN6(VAR1, \"STR\");\nreturn -VAR11;\n}\nif (VAR3[VAR4].VAR23 != VAR24) {\nFUN6(VAR1,\n\"STR\");\nreturn -VAR11;\n}\nif (VAR6 == VAR25) {\nVAR9 = FUN8(VAR1, VAR2->VAR19, VAR20);\nif (VAR9)\nreturn VAR9;\n}\nVAR9 = FUN10(VAR1, &VAR3[VAR4], VAR4);\nif (VAR9 < 0)\nreturn VAR9;\nfor (VAR8 = 0; VAR8 < VAR26; VAR8++) {\nFUN11(VAR1, VAR3, VAR27[VAR8]);\nFUN8(VAR1, VAR27[VAR8], VAR28);\n}\nFUN12(VAR1, VAR3, VAR15);\nVAR3[VAR15].VAR29 = VAR1->VAR30 + 1;\nreturn 0;\n}\n",
      "code_after_change_raw": "static int check_ld_abs(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\nstruct bpf_reg_state *regs = cur_regs(env);\nstatic const int ctx_reg = BPF_REG_6;\nu8 mode = BPF_MODE(insn->code);\nint i, err;\nif (!may_access_skb(resolve_prog_type(env->prog))) {\nverbose(env, \"BPF_LD_[ABS|IND] instructions not allowed for this program type\\n\");\nreturn -EINVAL;\n}\nif (!env->ops->gen_ld_abs) {\nverbose(env, \"bpf verifier is misconfigured\\n\");\nreturn -EINVAL;\n}\nif (insn->dst_reg != BPF_REG_0 || insn->off != 0 ||\nBPF_SIZE(insn->code) == BPF_DW ||\n(mode == BPF_ABS && insn->src_reg != BPF_REG_0)) {\nverbose(env, \"BPF_LD_[ABS|IND] uses reserved fields\\n\");\nreturn -EINVAL;\n}\nerr = check_reg_arg(env, ctx_reg, SRC_OP);\nif (err)\nreturn err;\nerr = check_reference_leak(env);\nif (err) {\nverbose(env, \"BPF_LD_[ABS|IND] cannot be mixed with socket references\\n\");\nreturn err;\n}\nif (env->cur_state->active_spin_lock) {\nverbose(env, \"BPF_LD_[ABS|IND] cannot be used inside bpf_spin_lock-ed region\\n\");\nreturn -EINVAL;\n}\nif (regs[ctx_reg].type != PTR_TO_CTX) {\nverbose(env,\n\"at the time of BPF_LD_ABS|IND R6 != pointer to skb\\n\");\nreturn -EINVAL;\n}\nif (mode == BPF_IND) {\nerr = check_reg_arg(env, insn->src_reg, SRC_OP);\nif (err)\nreturn err;\n}\nerr = check_ptr_off_reg(env, &regs[ctx_reg], ctx_reg);\nif (err < 0)\nreturn err;\nfor (i = 0; i < CALLER_SAVED_REGS; i++) {\nmark_reg_not_init(env, regs, caller_saved[i]);\ncheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n}\nmark_reg_unknown(env, regs, BPF_REG_0);\nregs[BPF_REG_0].subreg_def = env->insn_idx + 1;\nreturn 0;\n}\n",
      "code_before_change_raw": "static int check_ld_abs(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\nstruct bpf_reg_state *regs = cur_regs(env);\nstatic const int ctx_reg = BPF_REG_6;\nu8 mode = BPF_MODE(insn->code);\nint i, err;\nif (!may_access_skb(resolve_prog_type(env->prog))) {\nverbose(env, \"BPF_LD_[ABS|IND] instructions not allowed for this program type\\n\");\nreturn -EINVAL;\n}\nif (!env->ops->gen_ld_abs) {\nverbose(env, \"bpf verifier is misconfigured\\n\");\nreturn -EINVAL;\n}\nif (insn->dst_reg != BPF_REG_0 || insn->off != 0 ||\nBPF_SIZE(insn->code) == BPF_DW ||\n(mode == BPF_ABS && insn->src_reg != BPF_REG_0)) {\nverbose(env, \"BPF_LD_[ABS|IND] uses reserved fields\\n\");\nreturn -EINVAL;\n}\nerr = check_reg_arg(env, ctx_reg, SRC_OP);\nif (err)\nreturn err;\nerr = check_reference_leak(env);\nif (err) {\nverbose(env, \"BPF_LD_[ABS|IND] cannot be mixed with socket references\\n\");\nreturn err;\n}\nif (env->cur_state->active_spin_lock) {\nverbose(env, \"BPF_LD_[ABS|IND] cannot be used inside bpf_spin_lock-ed region\\n\");\nreturn -EINVAL;\n}\nif (regs[ctx_reg].type != PTR_TO_CTX) {\nverbose(env,\n\"at the time of BPF_LD_ABS|IND R6 != pointer to skb\\n\");\nreturn -EINVAL;\n}\nif (mode == BPF_IND) {\nerr = check_reg_arg(env, insn->src_reg, SRC_OP);\nif (err)\nreturn err;\n}\nerr = check_ctx_reg(env, &regs[ctx_reg], ctx_reg);\nif (err < 0)\nreturn err;\nfor (i = 0; i < CALLER_SAVED_REGS; i++) {\nmark_reg_not_init(env, regs, caller_saved[i]);\ncheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n}\nmark_reg_unknown(env, regs, BPF_REG_0);\nregs[BPF_REG_0].subreg_def = env->insn_idx + 1;\nreturn 0;\n}\n"
    }
  ],
  "CVE-2022-2964": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper bounds checking and validation for packet metadata array within the SKB.",
        "trigger_condition": "Receiving packets with metadata that can lead to out-of-bounds reads and writes in the packet processing function.",
        "specific_code_behavior_causing_vulnerability": "The code does not adequately validate the bounds of the metadata array and packet lengths, allowing for potential out-of-bounds reads and writes during packet processing."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add proper bounds checking and validation for the packet metadata array within the SKB. This involves ensuring that the metadata array is within the SKB bounds, packets do not overlap with the metadata array, and packet lengths are valid. Additionally, CRC errors and runt packets should be handled appropriately. The solution includes implementing checks to verify the bounds of the metadata array, packet lengths, and handling packets securely within the SKB.",
      "GPT_analysis": "The above modification is necessary to address the vulnerability CVE-2022-2964 in the code snippet provided. The vulnerability involves multiple out-of-bounds reads and possible out-of-bounds writes in the driver for the ASIX AX88179_178A-based USB Gigabit Ethernet Devices.\n\nThe modification addresses the vulnerability by implementing the following changes:\n1. Adding checks to ensure that the bounds of the metadata array are inside the SKB and in front of the counter at the end.\n2. Ensuring that packets do not overlap with the metadata array.\n3. Verifying that the packet length is within the bounds of the SKB.\n4. Checking for CRC errors or runt packets and ensuring that the packet length is greater than or equal to 2 + ETH_HLEN.\n5. Handling the last packet separately and returning early if it is the last packet.\n6. Trimming the packet away from the SKB after processing.\n\nThese modifications help prevent out-of-bounds reads and writes by ensuring that the packet processing is done within the bounds of the SKB and metadata array. By implementing these checks and adjustments, the code is made more secure and less susceptible to the identified vulnerability.",
      "GPT_purpose": "The function ax88179_rx_fixup is responsible for processing received packets in the ASIX AX88179_178A-based USB Ethernet driver, handling packet headers and performing various checks and manipulations on the packets.",
      "GPT_function": "\n1. Perform packet processing and error checking for received packets.\n2. Handle packet cloning and processing for valid packets.\n3. Address potential CRC errors and runt packets in the received data.\n4. Update packet length and perform IP alignment adjustments for valid packets.\n5. Return processed packets to the USB network device.",
      "CVE_id": "CVE-2022-2964",
      "code_before_change": "static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)\n{\n\tstruct sk_buff *ax_skb;\n\tint pkt_cnt;\n\tu32 rx_hdr;\n\tu16 hdr_off;\n\tu32 *pkt_hdr;\n\n\t/* This check is no longer done by usbnet */\n\tif (skb->len < dev->net->hard_header_len)\n\t\treturn 0;\n\n\tskb_trim(skb, skb->len - 4);\n\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\n\n\tpkt_cnt = (u16)rx_hdr;\n\thdr_off = (u16)(rx_hdr >> 16);\n\tpkt_hdr = (u32 *)(skb->data + hdr_off);\n\n\twhile (pkt_cnt--) {\n\t\tu16 pkt_len;\n\n\t\tle32_to_cpus(pkt_hdr);\n\t\tpkt_len = (*pkt_hdr >> 16) & 0x1fff;\n\n\t\t/* Check CRC or runt packet */\n\t\tif ((*pkt_hdr & AX_RXHDR_CRC_ERR) ||\n\t\t    (*pkt_hdr & AX_RXHDR_DROP_ERR)) {\n\t\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);\n\t\t\tpkt_hdr++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (pkt_cnt == 0) {\n\t\t\tskb->len = pkt_len;\n\t\t\t/* Skip IP alignment pseudo header */\n\t\t\tskb_pull(skb, 2);\n\t\t\tskb_set_tail_pointer(skb, skb->len);\n\t\t\tskb->truesize = pkt_len + sizeof(struct sk_buff);\n\t\t\tax88179_rx_checksum(skb, pkt_hdr);\n\t\t\treturn 1;\n\t\t}\n\n\t\tax_skb = skb_clone(skb, GFP_ATOMIC);\n\t\tif (ax_skb) {\n\t\t\tax_skb->len = pkt_len;\n\t\t\t/* Skip IP alignment pseudo header */\n\t\t\tskb_pull(ax_skb, 2);\n\t\t\tskb_set_tail_pointer(ax_skb, ax_skb->len);\n\t\t\tax_skb->truesize = pkt_len + sizeof(struct sk_buff);\n\t\t\tax88179_rx_checksum(ax_skb, pkt_hdr);\n\t\t\tusbnet_skb_return(dev, ax_skb);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\n\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);\n\t\tpkt_hdr++;\n\t}\n\treturn 1;\n}",
      "code_after_change": "static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)\n{\n\tstruct sk_buff *ax_skb;\n\tint pkt_cnt;\n\tu32 rx_hdr;\n\tu16 hdr_off;\n\tu32 *pkt_hdr;\n\n\t/* At the end of the SKB, there's a header telling us how many packets\n\t * are bundled into this buffer and where we can find an array of\n\t * per-packet metadata (which contains elements encoded into u16).\n\t */\n\tif (skb->len < 4)\n\t\treturn 0;\n\tskb_trim(skb, skb->len - 4);\n\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\n\tpkt_cnt = (u16)rx_hdr;\n\thdr_off = (u16)(rx_hdr >> 16);\n\n\tif (pkt_cnt == 0)\n\t\treturn 0;\n\n\t/* Make sure that the bounds of the metadata array are inside the SKB\n\t * (and in front of the counter at the end).\n\t */\n\tif (pkt_cnt * 2 + hdr_off > skb->len)\n\t\treturn 0;\n\tpkt_hdr = (u32 *)(skb->data + hdr_off);\n\n\t/* Packets must not overlap the metadata array */\n\tskb_trim(skb, hdr_off);\n\n\tfor (; ; pkt_cnt--, pkt_hdr++) {\n\t\tu16 pkt_len;\n\n\t\tle32_to_cpus(pkt_hdr);\n\t\tpkt_len = (*pkt_hdr >> 16) & 0x1fff;\n\n\t\tif (pkt_len > skb->len)\n\t\t\treturn 0;\n\n\t\t/* Check CRC or runt packet */\n\t\tif (((*pkt_hdr & (AX_RXHDR_CRC_ERR | AX_RXHDR_DROP_ERR)) == 0) &&\n\t\t    pkt_len >= 2 + ETH_HLEN) {\n\t\t\tbool last = (pkt_cnt == 0);\n\n\t\t\tif (last) {\n\t\t\t\tax_skb = skb;\n\t\t\t} else {\n\t\t\t\tax_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\tif (!ax_skb)\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tax_skb->len = pkt_len;\n\t\t\t/* Skip IP alignment pseudo header */\n\t\t\tskb_pull(ax_skb, 2);\n\t\t\tskb_set_tail_pointer(ax_skb, ax_skb->len);\n\t\t\tax_skb->truesize = pkt_len + sizeof(struct sk_buff);\n\t\t\tax88179_rx_checksum(ax_skb, pkt_hdr);\n\n\t\t\tif (last)\n\t\t\t\treturn 1;\n\n\t\t\tusbnet_skb_return(dev, ax_skb);\n\t\t}\n\n\t\t/* Trim this packet away from the SKB */\n\t\tif (!skb_pull(skb, (pkt_len + 7) & 0xFFF8))\n\t\t\treturn 0;\n\t}\n}",
      "modified_lines": {
        "added": [
          "\t/* At the end of the SKB, there's a header telling us how many packets",
          "\t * are bundled into this buffer and where we can find an array of",
          "\t * per-packet metadata (which contains elements encoded into u16).",
          "\t */",
          "\tif (skb->len < 4)",
          "\t\treturn 0;",
          "\tskb_trim(skb, skb->len - 4);",
          "\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));",
          "\tpkt_cnt = (u16)rx_hdr;",
          "\thdr_off = (u16)(rx_hdr >> 16);",
          "",
          "\tif (pkt_cnt == 0)",
          "\t/* Make sure that the bounds of the metadata array are inside the SKB",
          "\t * (and in front of the counter at the end).",
          "\t */",
          "\tif (pkt_cnt * 2 + hdr_off > skb->len)",
          "\t\treturn 0;",
          "\t/* Packets must not overlap the metadata array */",
          "\tskb_trim(skb, hdr_off);",
          "",
          "\tfor (; ; pkt_cnt--, pkt_hdr++) {",
          "\t\tif (pkt_len > skb->len)",
          "\t\t\treturn 0;",
          "",
          "\t\tif (((*pkt_hdr & (AX_RXHDR_CRC_ERR | AX_RXHDR_DROP_ERR)) == 0) &&",
          "\t\t    pkt_len >= 2 + ETH_HLEN) {",
          "\t\t\tbool last = (pkt_cnt == 0);",
          "\t\t\tif (last) {",
          "\t\t\t\tax_skb = skb;",
          "\t\t\t} else {",
          "\t\t\t\tax_skb = skb_clone(skb, GFP_ATOMIC);",
          "\t\t\t\tif (!ax_skb)",
          "\t\t\t\t\treturn 0;",
          "\t\t\t}",
          "",
          "\t\t\tif (last)",
          "\t\t\t\treturn 1;",
          "",
          "\t\t/* Trim this packet away from the SKB */",
          "\t\tif (!skb_pull(skb, (pkt_len + 7) & 0xFFF8))",
          "\t\t\treturn 0;"
        ],
        "deleted": [
          "\t/* This check is no longer done by usbnet */",
          "\tif (skb->len < dev->net->hard_header_len)",
          "\tskb_trim(skb, skb->len - 4);",
          "\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));",
          "",
          "\tpkt_cnt = (u16)rx_hdr;",
          "\thdr_off = (u16)(rx_hdr >> 16);",
          "\twhile (pkt_cnt--) {",
          "\t\tif ((*pkt_hdr & AX_RXHDR_CRC_ERR) ||",
          "\t\t    (*pkt_hdr & AX_RXHDR_DROP_ERR)) {",
          "\t\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);",
          "\t\t\tpkt_hdr++;",
          "\t\t\tcontinue;",
          "\t\t}",
          "\t\tif (pkt_cnt == 0) {",
          "\t\t\tskb->len = pkt_len;",
          "\t\t\t/* Skip IP alignment pseudo header */",
          "\t\t\tskb_pull(skb, 2);",
          "\t\t\tskb_set_tail_pointer(skb, skb->len);",
          "\t\t\tskb->truesize = pkt_len + sizeof(struct sk_buff);",
          "\t\t\tax88179_rx_checksum(skb, pkt_hdr);",
          "\t\t\treturn 1;",
          "\t\t}",
          "",
          "\t\tax_skb = skb_clone(skb, GFP_ATOMIC);",
          "\t\tif (ax_skb) {",
          "\t\t} else {",
          "\t\t\treturn 0;",
          "\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);",
          "\t\tpkt_hdr++;",
          "\treturn 1;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper bounds checking and validation for packet metadata array within the SKB.",
      "trigger_condition": "Receiving packets with metadata that can lead to out-of-bounds reads and writes in the packet processing function.",
      "specific_code_behavior_causing_vulnerability": "The code does not adequately validate the bounds of the metadata array and packet lengths, allowing for potential out-of-bounds reads and writes during packet processing.",
      "id": 153,
      "code_after_change_normalized": "static int FUN1(struct usbnet *VAR1, struct sk_buff *VAR2)\n{\nstruct sk_buff *VAR3;\nint VAR4;\nu32 VAR5;\nu16 VAR6;\nu32 *VAR7;\nif (VAR2->VAR8 < 4)\nreturn 0;\nFUN2(VAR2, VAR2->VAR8 - 4);\nVAR5 = FUN3(FUN4(VAR2));\nVAR4 = (VAR9)VAR5;\nVAR6 = (VAR9)(VAR5 >> 16);\nif (VAR4 == 0)\nreturn 0;\nif (VAR4 * 2 + VAR6 > VAR2->VAR8)\nreturn 0;\nVAR7 = (VAR10 *)(VAR2->VAR11 + VAR6);\nFUN2(VAR2, VAR6);\nfor (; ; VAR4--, VAR7++) {\nu16 VAR12;\nFUN5(VAR7);\nVAR12 = (*VAR7 >> 16) & VAR13;\nif (VAR12 > VAR2->VAR8)\nreturn 0;\nif (((*VAR7 & (VAR14 | VAR15)) == 0) &&\nVAR12 >= 2 + VAR16) {\nbool VAR17 = (VAR4 == 0);\nif (VAR17) {\nVAR3 = VAR2;\n} else {\nVAR3 = FUN6(VAR2, VAR18);\nif (!VAR3)\nreturn 0;\n}\nVAR3->VAR8 = VAR12;\nFUN7(VAR3, 2);\nFUN8(VAR3, VAR3->VAR8);\nVAR3->VAR19 = VAR12 + sizeof(struct VAR20);\nFUN9(VAR3, VAR7);\nif (VAR17)\nreturn 1;\nFUN10(VAR1, VAR3);\n}\nif (!FUN7(VAR2, (VAR12 + 7) & VAR13))\nreturn 0;\n}\n}\n",
      "code_before_change_normalized": "static int FUN1(struct usbnet *VAR1, struct sk_buff *VAR2)\n{\nstruct sk_buff *VAR3;\nint VAR4;\nu32 VAR5;\nu16 VAR6;\nu32 *VAR7;\nif (VAR2->VAR8 < VAR1->VAR9->VAR10)\nreturn 0;\nFUN2(VAR2, VAR2->VAR8 - 4);\nVAR5 = FUN3(FUN4(VAR2));\nVAR4 = (VAR11)VAR5;\nVAR6 = (VAR11)(VAR5 >> 16);\nVAR7 = (VAR12 *)(VAR2->VAR13 + VAR6);\nwhile (VAR4--) {\nu16 VAR14;\nFUN5(VAR7);\nVAR14 = (*VAR7 >> 16) & VAR15;\nif ((*VAR7 & VAR16) ||\n(*VAR7 & VAR17)) {\nFUN6(VAR2, (VAR14 + 7) & VAR15);\nVAR7++;\ncontinue;\n}\nif (VAR4 == 0) {\nVAR2->VAR8 = VAR14;\nFUN6(VAR2, 2);\nFUN7(VAR2, VAR2->VAR8);\nVAR2->VAR18 = VAR14 + sizeof(struct VAR19);\nFUN8(VAR2, VAR7);\nreturn 1;\n}\nVAR3 = FUN9(VAR2, VAR20);\nif (VAR3) {\nVAR3->VAR8 = VAR14;\nFUN6(VAR3, 2);\nFUN7(VAR3, VAR3->VAR8);\nVAR3->VAR18 = VAR14 + sizeof(struct VAR19);\nFUN8(VAR3, VAR7);\nFUN10(VAR1, VAR3);\n} else {\nreturn 0;\n}\nFUN6(VAR2, (VAR14 + 7) & VAR15);\nVAR7++;\n}\nreturn 1;\n}\n",
      "code_after_change_raw": "static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)\n{\nstruct sk_buff *ax_skb;\nint pkt_cnt;\nu32 rx_hdr;\nu16 hdr_off;\nu32 *pkt_hdr;\nif (skb->len < 4)\nreturn 0;\nskb_trim(skb, skb->len - 4);\nrx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\npkt_cnt = (u16)rx_hdr;\nhdr_off = (u16)(rx_hdr >> 16);\nif (pkt_cnt == 0)\nreturn 0;\nif (pkt_cnt * 2 + hdr_off > skb->len)\nreturn 0;\npkt_hdr = (u32 *)(skb->data + hdr_off);\nskb_trim(skb, hdr_off);\nfor (; ; pkt_cnt--, pkt_hdr++) {\nu16 pkt_len;\nle32_to_cpus(pkt_hdr);\npkt_len = (*pkt_hdr >> 16) & 0x1fff;\nif (pkt_len > skb->len)\nreturn 0;\nif (((*pkt_hdr & (AX_RXHDR_CRC_ERR | AX_RXHDR_DROP_ERR)) == 0) &&\npkt_len >= 2 + ETH_HLEN) {\nbool last = (pkt_cnt == 0);\nif (last) {\nax_skb = skb;\n} else {\nax_skb = skb_clone(skb, GFP_ATOMIC);\nif (!ax_skb)\nreturn 0;\n}\nax_skb->len = pkt_len;\nskb_pull(ax_skb, 2);\nskb_set_tail_pointer(ax_skb, ax_skb->len);\nax_skb->truesize = pkt_len + sizeof(struct sk_buff);\nax88179_rx_checksum(ax_skb, pkt_hdr);\nif (last)\nreturn 1;\nusbnet_skb_return(dev, ax_skb);\n}\nif (!skb_pull(skb, (pkt_len + 7) & 0xFFF8))\nreturn 0;\n}\n}\n",
      "code_before_change_raw": "static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)\n{\nstruct sk_buff *ax_skb;\nint pkt_cnt;\nu32 rx_hdr;\nu16 hdr_off;\nu32 *pkt_hdr;\nif (skb->len < dev->net->hard_header_len)\nreturn 0;\nskb_trim(skb, skb->len - 4);\nrx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\npkt_cnt = (u16)rx_hdr;\nhdr_off = (u16)(rx_hdr >> 16);\npkt_hdr = (u32 *)(skb->data + hdr_off);\nwhile (pkt_cnt--) {\nu16 pkt_len;\nle32_to_cpus(pkt_hdr);\npkt_len = (*pkt_hdr >> 16) & 0x1fff;\nif ((*pkt_hdr & AX_RXHDR_CRC_ERR) ||\n(*pkt_hdr & AX_RXHDR_DROP_ERR)) {\nskb_pull(skb, (pkt_len + 7) & 0xFFF8);\npkt_hdr++;\ncontinue;\n}\nif (pkt_cnt == 0) {\nskb->len = pkt_len;\nskb_pull(skb, 2);\nskb_set_tail_pointer(skb, skb->len);\nskb->truesize = pkt_len + sizeof(struct sk_buff);\nax88179_rx_checksum(skb, pkt_hdr);\nreturn 1;\n}\nax_skb = skb_clone(skb, GFP_ATOMIC);\nif (ax_skb) {\nax_skb->len = pkt_len;\nskb_pull(ax_skb, 2);\nskb_set_tail_pointer(ax_skb, ax_skb->len);\nax_skb->truesize = pkt_len + sizeof(struct sk_buff);\nax88179_rx_checksum(ax_skb, pkt_hdr);\nusbnet_skb_return(dev, ax_skb);\n} else {\nreturn 0;\n}\nskb_pull(skb, (pkt_len + 7) & 0xFFF8);\npkt_hdr++;\n}\nreturn 1;\n}\n"
    }
  ],
  "CVE-2022-3435": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Accessing 'nh' without ensuring its existence, leading to an out-of-bounds read vulnerability.",
        "trigger_condition": "The code attempts to access 'nh' without checking if it exists, potentially causing out-of-bounds read access.",
        "specific_code_behavior_causing_vulnerability": "The code does not verify the existence of 'nh' before accessing it, which can result in out-of-bounds read access and a security issue."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to verify the existence of 'nh' before attempting to access it. By adding the check 'if (fi->nh)' before accessing 'nh', the code ensures that it only proceeds if 'nh' is valid, preventing the out-of-bounds read vulnerability.",
      "GPT_analysis": "The modification is necessary to address the vulnerability identified as CVE-2022-3435 in the code snippet provided. The vulnerability involves an out-of-bounds read in the `fib_nh_match` function of the Linux Kernel's IPv4 Handler component. \n\nThe vulnerability arises from the code attempting to access `nh` without ensuring its existence, which can lead to out-of-bounds read access and potentially result in a security issue. By adding the check `if (fi->nh)` before accessing `nh`, we ensure that the code only proceeds if `nh` is valid, thus preventing the out-of-bounds read vulnerability.\n\nTherefore, the modification is crucial to prevent potential security risks and ensure the proper functioning of the code without exposing it to vulnerabilities.",
      "GPT_purpose": "Matching and checking criteria for next hops in the Fib (Forwarding Information Base) table.",
      "GPT_function": "\n1. Check if the priority of the configuration matches the priority of the fib_info.\n2. Check if the nexthop ID in the configuration matches the nexthop ID in the fib_info.\n3. Match on various attributes such as output interface, gateway family, encap, flow, and gateway addresses.\n4. Handle multipath routing by iterating over multiple nexthops and checking their attributes.",
      "CVE_id": "CVE-2022-3435",
      "code_before_change": "int fib_nh_match(struct net *net, struct fib_config *cfg, struct fib_info *fi,\n\t\t struct netlink_ext_ack *extack)\n{\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tstruct rtnexthop *rtnh;\n\tint remaining;\n#endif\n\n\tif (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)\n\t\treturn 1;\n\n\tif (cfg->fc_nh_id) {\n\t\tif (fi->nh && cfg->fc_nh_id == fi->nh->id)\n\t\t\treturn 0;\n\t\treturn 1;\n\t}\n\n\tif (cfg->fc_oif || cfg->fc_gw_family) {\n\t\tstruct fib_nh *nh;\n\n\t\t/* cannot match on nexthop object attributes */\n\t\tif (fi->nh)\n\t\t\treturn 1;\n\n\t\tnh = fib_info_nh(fi, 0);\n\t\tif (cfg->fc_encap) {\n\t\t\tif (fib_encap_match(net, cfg->fc_encap_type,\n\t\t\t\t\t    cfg->fc_encap, nh, cfg, extack))\n\t\t\t\treturn 1;\n\t\t}\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\tif (cfg->fc_flow &&\n\t\t    cfg->fc_flow != nh->nh_tclassid)\n\t\t\treturn 1;\n#endif\n\t\tif ((cfg->fc_oif && cfg->fc_oif != nh->fib_nh_oif) ||\n\t\t    (cfg->fc_gw_family &&\n\t\t     cfg->fc_gw_family != nh->fib_nh_gw_family))\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET &&\n\t\t    cfg->fc_gw4 != nh->fib_nh_gw4)\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET6 &&\n\t\t    ipv6_addr_cmp(&cfg->fc_gw6, &nh->fib_nh_gw6))\n\t\t\treturn 1;\n\n\t\treturn 0;\n\t}\n\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tif (!cfg->fc_mp)\n\t\treturn 0;\n\n\trtnh = cfg->fc_mp;\n\tremaining = cfg->fc_mp_len;\n\n\tfor_nexthops(fi) {\n\t\tint attrlen;\n\n\t\tif (!rtnh_ok(rtnh, remaining))\n\t\t\treturn -EINVAL;\n\n\t\tif (rtnh->rtnh_ifindex && rtnh->rtnh_ifindex != nh->fib_nh_oif)\n\t\t\treturn 1;\n\n\t\tattrlen = rtnh_attrlen(rtnh);\n\t\tif (attrlen > 0) {\n\t\t\tstruct nlattr *nla, *nlav, *attrs = rtnh_attrs(rtnh);\n\t\t\tint err;\n\n\t\t\tnla = nla_find(attrs, attrlen, RTA_GATEWAY);\n\t\t\tnlav = nla_find(attrs, attrlen, RTA_VIA);\n\t\t\tif (nla && nlav) {\n\t\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t\t       \"Nexthop configuration can not contain both GATEWAY and VIA\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (nla) {\n\t\t\t\t__be32 gw;\n\n\t\t\t\terr = fib_gw_from_attr(&gw, nla, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tif (nh->fib_nh_gw_family != AF_INET ||\n\t\t\t\t    gw != nh->fib_nh_gw4)\n\t\t\t\t\treturn 1;\n\t\t\t} else if (nlav) {\n\t\t\t\tstruct fib_config cfg2;\n\n\t\t\t\terr = fib_gw_from_via(&cfg2, nlav, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tswitch (nh->fib_nh_gw_family) {\n\t\t\t\tcase AF_INET:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET ||\n\t\t\t\t\t    cfg2.fc_gw4 != nh->fib_nh_gw4)\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase AF_INET6:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET6 ||\n\t\t\t\t\t    ipv6_addr_cmp(&cfg2.fc_gw6,\n\t\t\t\t\t\t\t  &nh->fib_nh_gw6))\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\t\tnla = nla_find(attrs, attrlen, RTA_FLOW);\n\t\t\tif (nla) {\n\t\t\t\tif (nla_len(nla) < sizeof(u32)) {\n\t\t\t\t\tNL_SET_ERR_MSG(extack, \"Invalid RTA_FLOW\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\tif (nla_get_u32(nla) != nh->nh_tclassid)\n\t\t\t\t\treturn 1;\n\t\t\t}\n#endif\n\t\t}\n\n\t\trtnh = rtnh_next(rtnh, &remaining);\n\t} endfor_nexthops(fi);\n#endif\n\treturn 0;\n}",
      "code_after_change": "int fib_nh_match(struct net *net, struct fib_config *cfg, struct fib_info *fi,\n\t\t struct netlink_ext_ack *extack)\n{\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tstruct rtnexthop *rtnh;\n\tint remaining;\n#endif\n\n\tif (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)\n\t\treturn 1;\n\n\tif (cfg->fc_nh_id) {\n\t\tif (fi->nh && cfg->fc_nh_id == fi->nh->id)\n\t\t\treturn 0;\n\t\treturn 1;\n\t}\n\n\t/* cannot match on nexthop object attributes */\n\tif (fi->nh)\n\t\treturn 1;\n\n\tif (cfg->fc_oif || cfg->fc_gw_family) {\n\t\tstruct fib_nh *nh;\n\n\t\tnh = fib_info_nh(fi, 0);\n\t\tif (cfg->fc_encap) {\n\t\t\tif (fib_encap_match(net, cfg->fc_encap_type,\n\t\t\t\t\t    cfg->fc_encap, nh, cfg, extack))\n\t\t\t\treturn 1;\n\t\t}\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\tif (cfg->fc_flow &&\n\t\t    cfg->fc_flow != nh->nh_tclassid)\n\t\t\treturn 1;\n#endif\n\t\tif ((cfg->fc_oif && cfg->fc_oif != nh->fib_nh_oif) ||\n\t\t    (cfg->fc_gw_family &&\n\t\t     cfg->fc_gw_family != nh->fib_nh_gw_family))\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET &&\n\t\t    cfg->fc_gw4 != nh->fib_nh_gw4)\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET6 &&\n\t\t    ipv6_addr_cmp(&cfg->fc_gw6, &nh->fib_nh_gw6))\n\t\t\treturn 1;\n\n\t\treturn 0;\n\t}\n\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tif (!cfg->fc_mp)\n\t\treturn 0;\n\n\trtnh = cfg->fc_mp;\n\tremaining = cfg->fc_mp_len;\n\n\tfor_nexthops(fi) {\n\t\tint attrlen;\n\n\t\tif (!rtnh_ok(rtnh, remaining))\n\t\t\treturn -EINVAL;\n\n\t\tif (rtnh->rtnh_ifindex && rtnh->rtnh_ifindex != nh->fib_nh_oif)\n\t\t\treturn 1;\n\n\t\tattrlen = rtnh_attrlen(rtnh);\n\t\tif (attrlen > 0) {\n\t\t\tstruct nlattr *nla, *nlav, *attrs = rtnh_attrs(rtnh);\n\t\t\tint err;\n\n\t\t\tnla = nla_find(attrs, attrlen, RTA_GATEWAY);\n\t\t\tnlav = nla_find(attrs, attrlen, RTA_VIA);\n\t\t\tif (nla && nlav) {\n\t\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t\t       \"Nexthop configuration can not contain both GATEWAY and VIA\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (nla) {\n\t\t\t\t__be32 gw;\n\n\t\t\t\terr = fib_gw_from_attr(&gw, nla, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tif (nh->fib_nh_gw_family != AF_INET ||\n\t\t\t\t    gw != nh->fib_nh_gw4)\n\t\t\t\t\treturn 1;\n\t\t\t} else if (nlav) {\n\t\t\t\tstruct fib_config cfg2;\n\n\t\t\t\terr = fib_gw_from_via(&cfg2, nlav, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tswitch (nh->fib_nh_gw_family) {\n\t\t\t\tcase AF_INET:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET ||\n\t\t\t\t\t    cfg2.fc_gw4 != nh->fib_nh_gw4)\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase AF_INET6:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET6 ||\n\t\t\t\t\t    ipv6_addr_cmp(&cfg2.fc_gw6,\n\t\t\t\t\t\t\t  &nh->fib_nh_gw6))\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\t\tnla = nla_find(attrs, attrlen, RTA_FLOW);\n\t\t\tif (nla) {\n\t\t\t\tif (nla_len(nla) < sizeof(u32)) {\n\t\t\t\t\tNL_SET_ERR_MSG(extack, \"Invalid RTA_FLOW\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\tif (nla_get_u32(nla) != nh->nh_tclassid)\n\t\t\t\t\treturn 1;\n\t\t\t}\n#endif\n\t\t}\n\n\t\trtnh = rtnh_next(rtnh, &remaining);\n\t} endfor_nexthops(fi);\n#endif\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t/* cannot match on nexthop object attributes */",
          "\tif (fi->nh)",
          "\t\treturn 1;",
          ""
        ],
        "deleted": [
          "",
          "\t\t/* cannot match on nexthop object attributes */",
          "\t\tif (fi->nh)",
          "\t\t\treturn 1;"
        ]
      },
      "preconditions_for_vulnerability": "Accessing 'nh' without ensuring its existence, leading to an out-of-bounds read vulnerability.",
      "trigger_condition": "The code attempts to access 'nh' without checking if it exists, potentially causing out-of-bounds read access.",
      "specific_code_behavior_causing_vulnerability": "The code does not verify the existence of 'nh' before accessing it, which can result in out-of-bounds read access and a security issue.",
      "id": 154,
      "code_after_change_normalized": "int FUN1(struct VAR1 *VAR1, struct fib_config *VAR2, struct fib_info *VAR3,\nstruct netlink_ext_ack *VAR4)\n{\n#ifdef VAR5\nstruct rtnexthop *VAR6;\nint VAR7;\n#VAR8\nif (VAR2->VAR9 && VAR2->VAR9 != VAR3->VAR10)\nreturn 1;\nif (VAR2->VAR11) {\nif (VAR3->VAR12 && VAR2->VAR11 == VAR3->VAR12->VAR13)\nreturn 0;\nreturn 1;\n}\nif (VAR3->VAR12)\nreturn 1;\nif (VAR2->VAR14 || VAR2->VAR15) {\nstruct fib_nh *VAR12;\nVAR12 = FUN2(VAR3, 0);\nif (VAR2->VAR16) {\nif (FUN3(VAR1, VAR2->VAR17,\nVAR2->VAR16, VAR12, VAR2, VAR4))\nreturn 1;\n}\n#ifdef VAR18\nif (VAR2->VAR19 &&\nVAR2->VAR19 != VAR12->VAR20)\nreturn 1;\n#VAR8\nif ((VAR2->VAR14 && VAR2->VAR14 != VAR12->VAR21) ||\n(VAR2->VAR15 &&\nVAR2->VAR15 != VAR12->VAR22))\nreturn 1;\nif (VAR2->VAR15 == VAR23 &&\nVAR2->VAR24 != VAR12->VAR25)\nreturn 1;\nif (VAR2->VAR15 == VAR26 &&\nFUN4(&VAR2->VAR27, &VAR12->VAR28))\nreturn 1;\nreturn 0;\n}\n#ifdef VAR5\nif (!VAR2->VAR29)\nreturn 0;\nVAR6 = VAR2->VAR29;\nVAR7 = VAR2->VAR30;\nFUN5(VAR3) {\nint VAR31;\nif (!FUN6(VAR6, VAR7))\nreturn -VAR32;\nif (VAR6->VAR33 && VAR6->VAR33 != VAR12->VAR21)\nreturn 1;\nVAR31 = FUN7(VAR6);\nif (VAR31 > 0) {\nstruct nlattr *VAR34, *VAR35, *VAR36 = FUN8(VAR6);\nint VAR37;\nVAR34 = FUN9(VAR36, VAR31, VAR38);\nVAR35 = FUN9(VAR36, VAR31, VAR39);\nif (VAR34 && VAR35) {\nFUN10(VAR4,\n\"STR\");\nreturn -VAR32;\n}\nif (VAR34) {\n__be32 VAR40;\nVAR37 = FUN11(&VAR40, VAR34, VAR4);\nif (VAR37)\nreturn VAR37;\nif (VAR12->VAR22 != VAR23 ||\nVAR40 != VAR12->VAR25)\nreturn 1;\n} else if (VAR35) {\nstruct fib_config VAR41;\nVAR37 = FUN12(&VAR41, VAR35, VAR4);\nif (VAR37)\nreturn VAR37;\nswitch (VAR12->VAR22) {\ncase VAR23:\nif (VAR41.VAR15 != VAR23 ||\nVAR41.VAR24 != VAR12->VAR25)\nreturn 1;\nbreak;\ncase VAR26:\nif (VAR41.VAR15 != VAR26 ||\nFUN4(&VAR41.VAR27,\n&VAR12->VAR28))\nreturn 1;\nbreak;\n}\n}\n#ifdef VAR18\nVAR34 = FUN9(VAR36, VAR31, VAR42);\nif (VAR34) {\nif (FUN13(VAR34) < sizeof(VAR43)) {\nFUN10(VAR4, \"STR\");\nreturn -VAR32;\n}\nif (FUN14(VAR34) != VAR12->VAR20)\nreturn 1;\n}\n#VAR8\n}\nVAR6 = FUN15(VAR6, &VAR7);\n} FUN16(VAR3);\n#VAR8\nreturn 0;\n}\n",
      "code_before_change_normalized": "int FUN1(struct VAR1 *VAR1, struct fib_config *VAR2, struct fib_info *VAR3,\nstruct netlink_ext_ack *VAR4)\n{\n#ifdef VAR5\nstruct rtnexthop *VAR6;\nint VAR7;\n#VAR8\nif (VAR2->VAR9 && VAR2->VAR9 != VAR3->VAR10)\nreturn 1;\nif (VAR2->VAR11) {\nif (VAR3->VAR12 && VAR2->VAR11 == VAR3->VAR12->VAR13)\nreturn 0;\nreturn 1;\n}\nif (VAR2->VAR14 || VAR2->VAR15) {\nstruct fib_nh *VAR12;\nif (VAR3->VAR12)\nreturn 1;\nVAR12 = FUN2(VAR3, 0);\nif (VAR2->VAR16) {\nif (FUN3(VAR1, VAR2->VAR17,\nVAR2->VAR16, VAR12, VAR2, VAR4))\nreturn 1;\n}\n#ifdef VAR18\nif (VAR2->VAR19 &&\nVAR2->VAR19 != VAR12->VAR20)\nreturn 1;\n#VAR8\nif ((VAR2->VAR14 && VAR2->VAR14 != VAR12->VAR21) ||\n(VAR2->VAR15 &&\nVAR2->VAR15 != VAR12->VAR22))\nreturn 1;\nif (VAR2->VAR15 == VAR23 &&\nVAR2->VAR24 != VAR12->VAR25)\nreturn 1;\nif (VAR2->VAR15 == VAR26 &&\nFUN4(&VAR2->VAR27, &VAR12->VAR28))\nreturn 1;\nreturn 0;\n}\n#ifdef VAR5\nif (!VAR2->VAR29)\nreturn 0;\nVAR6 = VAR2->VAR29;\nVAR7 = VAR2->VAR30;\nFUN5(VAR3) {\nint VAR31;\nif (!FUN6(VAR6, VAR7))\nreturn -VAR32;\nif (VAR6->VAR33 && VAR6->VAR33 != VAR12->VAR21)\nreturn 1;\nVAR31 = FUN7(VAR6);\nif (VAR31 > 0) {\nstruct nlattr *VAR34, *VAR35, *VAR36 = FUN8(VAR6);\nint VAR37;\nVAR34 = FUN9(VAR36, VAR31, VAR38);\nVAR35 = FUN9(VAR36, VAR31, VAR39);\nif (VAR34 && VAR35) {\nFUN10(VAR4,\n\"STR\");\nreturn -VAR32;\n}\nif (VAR34) {\n__be32 VAR40;\nVAR37 = FUN11(&VAR40, VAR34, VAR4);\nif (VAR37)\nreturn VAR37;\nif (VAR12->VAR22 != VAR23 ||\nVAR40 != VAR12->VAR25)\nreturn 1;\n} else if (VAR35) {\nstruct fib_config VAR41;\nVAR37 = FUN12(&VAR41, VAR35, VAR4);\nif (VAR37)\nreturn VAR37;\nswitch (VAR12->VAR22) {\ncase VAR23:\nif (VAR41.VAR15 != VAR23 ||\nVAR41.VAR24 != VAR12->VAR25)\nreturn 1;\nbreak;\ncase VAR26:\nif (VAR41.VAR15 != VAR26 ||\nFUN4(&VAR41.VAR27,\n&VAR12->VAR28))\nreturn 1;\nbreak;\n}\n}\n#ifdef VAR18\nVAR34 = FUN9(VAR36, VAR31, VAR42);\nif (VAR34) {\nif (FUN13(VAR34) < sizeof(VAR43)) {\nFUN10(VAR4, \"STR\");\nreturn -VAR32;\n}\nif (FUN14(VAR34) != VAR12->VAR20)\nreturn 1;\n}\n#VAR8\n}\nVAR6 = FUN15(VAR6, &VAR7);\n} FUN16(VAR3);\n#VAR8\nreturn 0;\n}\n",
      "code_after_change_raw": "int fib_nh_match(struct net *net, struct fib_config *cfg, struct fib_info *fi,\nstruct netlink_ext_ack *extack)\n{\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\nstruct rtnexthop *rtnh;\nint remaining;\n#endif\nif (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)\nreturn 1;\nif (cfg->fc_nh_id) {\nif (fi->nh && cfg->fc_nh_id == fi->nh->id)\nreturn 0;\nreturn 1;\n}\nif (fi->nh)\nreturn 1;\nif (cfg->fc_oif || cfg->fc_gw_family) {\nstruct fib_nh *nh;\nnh = fib_info_nh(fi, 0);\nif (cfg->fc_encap) {\nif (fib_encap_match(net, cfg->fc_encap_type,\ncfg->fc_encap, nh, cfg, extack))\nreturn 1;\n}\n#ifdef CONFIG_IP_ROUTE_CLASSID\nif (cfg->fc_flow &&\ncfg->fc_flow != nh->nh_tclassid)\nreturn 1;\n#endif\nif ((cfg->fc_oif && cfg->fc_oif != nh->fib_nh_oif) ||\n(cfg->fc_gw_family &&\ncfg->fc_gw_family != nh->fib_nh_gw_family))\nreturn 1;\nif (cfg->fc_gw_family == AF_INET &&\ncfg->fc_gw4 != nh->fib_nh_gw4)\nreturn 1;\nif (cfg->fc_gw_family == AF_INET6 &&\nipv6_addr_cmp(&cfg->fc_gw6, &nh->fib_nh_gw6))\nreturn 1;\nreturn 0;\n}\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\nif (!cfg->fc_mp)\nreturn 0;\nrtnh = cfg->fc_mp;\nremaining = cfg->fc_mp_len;\nfor_nexthops(fi) {\nint attrlen;\nif (!rtnh_ok(rtnh, remaining))\nreturn -EINVAL;\nif (rtnh->rtnh_ifindex && rtnh->rtnh_ifindex != nh->fib_nh_oif)\nreturn 1;\nattrlen = rtnh_attrlen(rtnh);\nif (attrlen > 0) {\nstruct nlattr *nla, *nlav, *attrs = rtnh_attrs(rtnh);\nint err;\nnla = nla_find(attrs, attrlen, RTA_GATEWAY);\nnlav = nla_find(attrs, attrlen, RTA_VIA);\nif (nla && nlav) {\nNL_SET_ERR_MSG(extack,\n\"Nexthop configuration can not contain both GATEWAY and VIA\");\nreturn -EINVAL;\n}\nif (nla) {\n__be32 gw;\nerr = fib_gw_from_attr(&gw, nla, extack);\nif (err)\nreturn err;\nif (nh->fib_nh_gw_family != AF_INET ||\ngw != nh->fib_nh_gw4)\nreturn 1;\n} else if (nlav) {\nstruct fib_config cfg2;\nerr = fib_gw_from_via(&cfg2, nlav, extack);\nif (err)\nreturn err;\nswitch (nh->fib_nh_gw_family) {\ncase AF_INET:\nif (cfg2.fc_gw_family != AF_INET ||\ncfg2.fc_gw4 != nh->fib_nh_gw4)\nreturn 1;\nbreak;\ncase AF_INET6:\nif (cfg2.fc_gw_family != AF_INET6 ||\nipv6_addr_cmp(&cfg2.fc_gw6,\n&nh->fib_nh_gw6))\nreturn 1;\nbreak;\n}\n}\n#ifdef CONFIG_IP_ROUTE_CLASSID\nnla = nla_find(attrs, attrlen, RTA_FLOW);\nif (nla) {\nif (nla_len(nla) < sizeof(u32)) {\nNL_SET_ERR_MSG(extack, \"Invalid RTA_FLOW\");\nreturn -EINVAL;\n}\nif (nla_get_u32(nla) != nh->nh_tclassid)\nreturn 1;\n}\n#endif\n}\nrtnh = rtnh_next(rtnh, &remaining);\n} endfor_nexthops(fi);\n#endif\nreturn 0;\n}\n",
      "code_before_change_raw": "int fib_nh_match(struct net *net, struct fib_config *cfg, struct fib_info *fi,\nstruct netlink_ext_ack *extack)\n{\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\nstruct rtnexthop *rtnh;\nint remaining;\n#endif\nif (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)\nreturn 1;\nif (cfg->fc_nh_id) {\nif (fi->nh && cfg->fc_nh_id == fi->nh->id)\nreturn 0;\nreturn 1;\n}\nif (cfg->fc_oif || cfg->fc_gw_family) {\nstruct fib_nh *nh;\nif (fi->nh)\nreturn 1;\nnh = fib_info_nh(fi, 0);\nif (cfg->fc_encap) {\nif (fib_encap_match(net, cfg->fc_encap_type,\ncfg->fc_encap, nh, cfg, extack))\nreturn 1;\n}\n#ifdef CONFIG_IP_ROUTE_CLASSID\nif (cfg->fc_flow &&\ncfg->fc_flow != nh->nh_tclassid)\nreturn 1;\n#endif\nif ((cfg->fc_oif && cfg->fc_oif != nh->fib_nh_oif) ||\n(cfg->fc_gw_family &&\ncfg->fc_gw_family != nh->fib_nh_gw_family))\nreturn 1;\nif (cfg->fc_gw_family == AF_INET &&\ncfg->fc_gw4 != nh->fib_nh_gw4)\nreturn 1;\nif (cfg->fc_gw_family == AF_INET6 &&\nipv6_addr_cmp(&cfg->fc_gw6, &nh->fib_nh_gw6))\nreturn 1;\nreturn 0;\n}\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\nif (!cfg->fc_mp)\nreturn 0;\nrtnh = cfg->fc_mp;\nremaining = cfg->fc_mp_len;\nfor_nexthops(fi) {\nint attrlen;\nif (!rtnh_ok(rtnh, remaining))\nreturn -EINVAL;\nif (rtnh->rtnh_ifindex && rtnh->rtnh_ifindex != nh->fib_nh_oif)\nreturn 1;\nattrlen = rtnh_attrlen(rtnh);\nif (attrlen > 0) {\nstruct nlattr *nla, *nlav, *attrs = rtnh_attrs(rtnh);\nint err;\nnla = nla_find(attrs, attrlen, RTA_GATEWAY);\nnlav = nla_find(attrs, attrlen, RTA_VIA);\nif (nla && nlav) {\nNL_SET_ERR_MSG(extack,\n\"Nexthop configuration can not contain both GATEWAY and VIA\");\nreturn -EINVAL;\n}\nif (nla) {\n__be32 gw;\nerr = fib_gw_from_attr(&gw, nla, extack);\nif (err)\nreturn err;\nif (nh->fib_nh_gw_family != AF_INET ||\ngw != nh->fib_nh_gw4)\nreturn 1;\n} else if (nlav) {\nstruct fib_config cfg2;\nerr = fib_gw_from_via(&cfg2, nlav, extack);\nif (err)\nreturn err;\nswitch (nh->fib_nh_gw_family) {\ncase AF_INET:\nif (cfg2.fc_gw_family != AF_INET ||\ncfg2.fc_gw4 != nh->fib_nh_gw4)\nreturn 1;\nbreak;\ncase AF_INET6:\nif (cfg2.fc_gw_family != AF_INET6 ||\nipv6_addr_cmp(&cfg2.fc_gw6,\n&nh->fib_nh_gw6))\nreturn 1;\nbreak;\n}\n}\n#ifdef CONFIG_IP_ROUTE_CLASSID\nnla = nla_find(attrs, attrlen, RTA_FLOW);\nif (nla) {\nif (nla_len(nla) < sizeof(u32)) {\nNL_SET_ERR_MSG(extack, \"Invalid RTA_FLOW\");\nreturn -EINVAL;\n}\nif (nla_get_u32(nla) != nh->nh_tclassid)\nreturn 1;\n}\n#endif\n}\nrtnh = rtnh_next(rtnh, &remaining);\n} endfor_nexthops(fi);\n#endif\nreturn 0;\n}\n"
    }
  ],
  "CVE-2022-3541": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of memory deallocation when an invalid MAC address is detected, leading to a use-after-free vulnerability.",
        "trigger_condition": "Detection of an invalid MAC address triggers the premature deallocation of memory for the MAC address, potentially leading to a use-after-free scenario.",
        "specific_code_behavior_causing_vulnerability": "The code frees the memory for the MAC address when an invalid length or invalid MAC address is detected, without considering that the memory may be accessed later in the function. This premature deallocation can result in a use-after-free vulnerability if the memory is accessed after being freed."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that memory deallocation for the MAC address is only performed once, at the end of the function, to prevent a use-after-free scenario. Specifically, the code should avoid freeing the memory for the MAC address when an invalid MAC address is detected and only free the memory at the end of the function after all checks and operations have been completed.",
      "GPT_analysis": "The modification is necessary to fix the vulnerability CVE-2022-3541, which is a critical use-after-free vulnerability found in the function `spl2sw_nvmem_get_mac_address` of the file `drivers/net/ethernet/sunplus/spl2sw_driver.c`. The vulnerability occurs when the `mac` variable is freed multiple times, leading to a use-after-free scenario.\n\nIn the original code snippet, the `mac` variable is freed twice: once when an invalid MAC address is detected and again at the end of the function. This can lead to memory corruption and potential exploitation by an attacker.\n\nThe correct way to fix this issue is to remove the `kfree(mac)` call when an invalid MAC address is detected and only free the memory at the end of the function. By making this modification, the vulnerability is mitigated, and the use-after-free scenario is prevented.\n\nTherefore, the modification is necessary to address the identified vulnerability and ensure the proper handling of memory allocation and deallocation in the function.",
      "GPT_purpose": "Retrieve and validate a MAC address stored in an nvmem cell from the device tree source (DTS).",
      "GPT_function": "\n1. Retrieve the MAC address from the device tree using nvmem.\n2. Read the MAC address from the nvmem cell and perform validations.\n3. Copy the validated MAC address to the provided buffer.",
      "CVE_id": "CVE-2022-3541",
      "code_before_change": "static int spl2sw_nvmem_get_mac_address(struct device *dev, struct device_node *np,\n\t\t\t\t\tvoid *addrbuf)\n{\n\tstruct nvmem_cell *cell;\n\tssize_t len;\n\tu8 *mac;\n\n\t/* Get nvmem cell of mac-address from dts. */\n\tcell = of_nvmem_cell_get(np, \"mac-address\");\n\tif (IS_ERR(cell))\n\t\treturn PTR_ERR(cell);\n\n\t/* Read mac address from nvmem cell. */\n\tmac = nvmem_cell_read(cell, &len);\n\tnvmem_cell_put(cell);\n\tif (IS_ERR(mac))\n\t\treturn PTR_ERR(mac);\n\n\tif (len != ETH_ALEN) {\n\t\tkfree(mac);\n\t\tdev_info(dev, \"Invalid length of mac address in nvmem!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Byte order of some samples are reversed.\n\t * Convert byte order here.\n\t */\n\tspl2sw_check_mac_vendor_id_and_convert(mac);\n\n\t/* Check if mac address is valid */\n\tif (!is_valid_ether_addr(mac)) {\n\t\tkfree(mac);\n\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\n\t\treturn -EINVAL;\n\t}\n\n\tether_addr_copy(addrbuf, mac);\n\tkfree(mac);\n\treturn 0;\n}",
      "code_after_change": "static int spl2sw_nvmem_get_mac_address(struct device *dev, struct device_node *np,\n\t\t\t\t\tvoid *addrbuf)\n{\n\tstruct nvmem_cell *cell;\n\tssize_t len;\n\tu8 *mac;\n\n\t/* Get nvmem cell of mac-address from dts. */\n\tcell = of_nvmem_cell_get(np, \"mac-address\");\n\tif (IS_ERR(cell))\n\t\treturn PTR_ERR(cell);\n\n\t/* Read mac address from nvmem cell. */\n\tmac = nvmem_cell_read(cell, &len);\n\tnvmem_cell_put(cell);\n\tif (IS_ERR(mac))\n\t\treturn PTR_ERR(mac);\n\n\tif (len != ETH_ALEN) {\n\t\tkfree(mac);\n\t\tdev_info(dev, \"Invalid length of mac address in nvmem!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Byte order of some samples are reversed.\n\t * Convert byte order here.\n\t */\n\tspl2sw_check_mac_vendor_id_and_convert(mac);\n\n\t/* Check if mac address is valid */\n\tif (!is_valid_ether_addr(mac)) {\n\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\n\t\tkfree(mac);\n\t\treturn -EINVAL;\n\t}\n\n\tether_addr_copy(addrbuf, mac);\n\tkfree(mac);\n\treturn 0;\n}",
      "modified_lines": {
        "added": [
          "\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);"
        ],
        "deleted": [
          "\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of memory deallocation when an invalid MAC address is detected, leading to a use-after-free vulnerability.",
      "trigger_condition": "Detection of an invalid MAC address triggers the premature deallocation of memory for the MAC address, potentially leading to a use-after-free scenario.",
      "specific_code_behavior_causing_vulnerability": "The code frees the memory for the MAC address when an invalid length or invalid MAC address is detected, without considering that the memory may be accessed later in the function. This premature deallocation can result in a use-after-free vulnerability if the memory is accessed after being freed.",
      "id": 155,
      "code_after_change_normalized": "static int FUN1(struct device *VAR1, struct device_node *VAR2,\nvoid *VAR3)\n{\nstruct nvmem_cell *VAR4;\nssize_t VAR5;\nu8 *VAR6;\nVAR4 = FUN2(VAR2, \"STR\");\nif (FUN3(VAR4))\nreturn FUN4(VAR4);\nVAR6 = FUN5(VAR4, &VAR5);\nFUN6(VAR4);\nif (FUN3(VAR6))\nreturn FUN4(VAR6);\nif (VAR5 != VAR7) {\nFUN7(VAR6);\nFUN8(VAR1, \"STR\");\nreturn -VAR8;\n}\nFUN9(VAR6);\nif (!FUN10(VAR6)) {\nFUN8(VAR1, \"STR\", VAR6);\nFUN7(VAR6);\nreturn -VAR8;\n}\nFUN11(VAR3, VAR6);\nFUN7(VAR6);\nreturn 0;\n}\n",
      "code_before_change_normalized": "static int FUN1(struct device *VAR1, struct device_node *VAR2,\nvoid *VAR3)\n{\nstruct nvmem_cell *VAR4;\nssize_t VAR5;\nu8 *VAR6;\nVAR4 = FUN2(VAR2, \"STR\");\nif (FUN3(VAR4))\nreturn FUN4(VAR4);\nVAR6 = FUN5(VAR4, &VAR5);\nFUN6(VAR4);\nif (FUN3(VAR6))\nreturn FUN4(VAR6);\nif (VAR5 != VAR7) {\nFUN7(VAR6);\nFUN8(VAR1, \"STR\");\nreturn -VAR8;\n}\nFUN9(VAR6);\nif (!FUN10(VAR6)) {\nFUN7(VAR6);\nFUN8(VAR1, \"STR\", VAR6);\nreturn -VAR8;\n}\nFUN11(VAR3, VAR6);\nFUN7(VAR6);\nreturn 0;\n}\n",
      "code_after_change_raw": "static int spl2sw_nvmem_get_mac_address(struct device *dev, struct device_node *np,\nvoid *addrbuf)\n{\nstruct nvmem_cell *cell;\nssize_t len;\nu8 *mac;\ncell = of_nvmem_cell_get(np, \"mac-address\");\nif (IS_ERR(cell))\nreturn PTR_ERR(cell);\nmac = nvmem_cell_read(cell, &len);\nnvmem_cell_put(cell);\nif (IS_ERR(mac))\nreturn PTR_ERR(mac);\nif (len != ETH_ALEN) {\nkfree(mac);\ndev_info(dev, \"Invalid length of mac address in nvmem!\\n\");\nreturn -EINVAL;\n}\nspl2sw_check_mac_vendor_id_and_convert(mac);\nif (!is_valid_ether_addr(mac)) {\ndev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\nkfree(mac);\nreturn -EINVAL;\n}\nether_addr_copy(addrbuf, mac);\nkfree(mac);\nreturn 0;\n}\n",
      "code_before_change_raw": "static int spl2sw_nvmem_get_mac_address(struct device *dev, struct device_node *np,\nvoid *addrbuf)\n{\nstruct nvmem_cell *cell;\nssize_t len;\nu8 *mac;\ncell = of_nvmem_cell_get(np, \"mac-address\");\nif (IS_ERR(cell))\nreturn PTR_ERR(cell);\nmac = nvmem_cell_read(cell, &len);\nnvmem_cell_put(cell);\nif (IS_ERR(mac))\nreturn PTR_ERR(mac);\nif (len != ETH_ALEN) {\nkfree(mac);\ndev_info(dev, \"Invalid length of mac address in nvmem!\\n\");\nreturn -EINVAL;\n}\nspl2sw_check_mac_vendor_id_and_convert(mac);\nif (!is_valid_ether_addr(mac)) {\nkfree(mac);\ndev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\nreturn -EINVAL;\n}\nether_addr_copy(addrbuf, mac);\nkfree(mac);\nreturn 0;\n}\n"
    }
  ],
  "CVE-2022-3545": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper handling for releasing cache area resources without updating associated metadata fields.",
        "trigger_condition": "Releasing the cache area without updating the cache ID and address fields, leading to a use-after-free vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code snippet releases the cache area without updating the cache ID and address fields, potentially allowing access to memory that has already been freed, resulting in undefined behavior and security risks."
      },
      "solution": "To mitigate the vulnerability, it is necessary to update the cache ID and address fields after releasing the cache area. This ensures that the metadata associated with the cache area remains valid and prevents the use-after-free vulnerability. In this case, the solution involves removing the assignment of cache->id = 0 before releasing cache->area and updating the cache->id after acquiring the area.",
      "GPT_analysis": "The modification to the code snippet is necessary to address the vulnerability CVE-2022-3545, which is classified as critical and leads to a use-after-free issue in the Linux Kernel component IPsec. The vulnerability occurs in the function `area_cache_get` of the file `drivers/net/ethernet/netronome/nfp/nfpcore/nfp_cppcore.c`.\n\nThe vulnerability arises from the potential use-after-free scenario when releasing the `cache->area` without updating the `cache->id` and `cache->addr` fields. This can lead to accessing memory that has already been freed, resulting in undefined behavior and potential security risks.\n\nTo fix this issue, the modification involves removing the assignment of `cache->id = 0` before releasing `cache->area` and updating the `cache->id` after acquiring the area. This ensures that the `cache->id` is correctly maintained throughout the process and prevents the use-after-free vulnerability.\n\nBy making these changes as described in the modified code snippet, the vulnerability is addressed, and the code is more secure and less prone to memory-related issues.",
      "GPT_purpose": "The function area_cache_get is responsible for retrieving and managing cached memory areas associated with a specific NFP CPP device.",
      "GPT_function": "\n1. Check if the length is 0 or the ID is 0 and return NULL if true.\n2. Remap from cpp_island to cpp_target.\n3. Lock the area cache mutex and check for a match in the cache list.",
      "CVE_id": "CVE-2022-3545",
      "code_before_change": "static struct nfp_cpp_area_cache *\narea_cache_get(struct nfp_cpp *cpp, u32 id,\n\t       u64 addr, unsigned long *offset, size_t length)\n{\n\tstruct nfp_cpp_area_cache *cache;\n\tint err;\n\n\t/* Early exit when length == 0, which prevents\n\t * the need for special case code below when\n\t * checking against available cache size.\n\t */\n\tif (length == 0 || id == 0)\n\t\treturn NULL;\n\n\t/* Remap from cpp_island to cpp_target */\n\terr = nfp_target_cpp(id, addr, &id, &addr, cpp->imb_cat_table);\n\tif (err < 0)\n\t\treturn NULL;\n\n\tmutex_lock(&cpp->area_cache_mutex);\n\n\tif (list_empty(&cpp->area_cache_list)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\taddr += *offset;\n\n\t/* See if we have a match */\n\tlist_for_each_entry(cache, &cpp->area_cache_list, entry) {\n\t\tif (id == cache->id &&\n\t\t    addr >= cache->addr &&\n\t\t    addr + length <= cache->addr + cache->size)\n\t\t\tgoto exit;\n\t}\n\n\t/* No matches - inspect the tail of the LRU */\n\tcache = list_entry(cpp->area_cache_list.prev,\n\t\t\t   struct nfp_cpp_area_cache, entry);\n\n\t/* Can we fit in the cache entry? */\n\tif (round_down(addr + length - 1, cache->size) !=\n\t    round_down(addr, cache->size)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\t/* If id != 0, we will need to release it */\n\tif (cache->id) {\n\t\tnfp_cpp_area_release(cache->area);\n\t\tcache->id = 0;\n\t\tcache->addr = 0;\n\t}\n\n\t/* Adjust the start address to be cache size aligned */\n\tcache->id = id;\n\tcache->addr = addr & ~(u64)(cache->size - 1);\n\n\t/* Re-init to the new ID and address */\n\tif (cpp->op->area_init) {\n\t\terr = cpp->op->area_init(cache->area,\n\t\t\t\t\t id, cache->addr, cache->size);\n\t\tif (err < 0) {\n\t\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* Attempt to acquire */\n\terr = nfp_cpp_area_acquire(cache->area);\n\tif (err < 0) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\nexit:\n\t/* Adjust offset */\n\t*offset = addr - cache->addr;\n\treturn cache;\n}",
      "code_after_change": "static struct nfp_cpp_area_cache *\narea_cache_get(struct nfp_cpp *cpp, u32 id,\n\t       u64 addr, unsigned long *offset, size_t length)\n{\n\tstruct nfp_cpp_area_cache *cache;\n\tint err;\n\n\t/* Early exit when length == 0, which prevents\n\t * the need for special case code below when\n\t * checking against available cache size.\n\t */\n\tif (length == 0 || id == 0)\n\t\treturn NULL;\n\n\t/* Remap from cpp_island to cpp_target */\n\terr = nfp_target_cpp(id, addr, &id, &addr, cpp->imb_cat_table);\n\tif (err < 0)\n\t\treturn NULL;\n\n\tmutex_lock(&cpp->area_cache_mutex);\n\n\tif (list_empty(&cpp->area_cache_list)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\taddr += *offset;\n\n\t/* See if we have a match */\n\tlist_for_each_entry(cache, &cpp->area_cache_list, entry) {\n\t\tif (id == cache->id &&\n\t\t    addr >= cache->addr &&\n\t\t    addr + length <= cache->addr + cache->size)\n\t\t\tgoto exit;\n\t}\n\n\t/* No matches - inspect the tail of the LRU */\n\tcache = list_entry(cpp->area_cache_list.prev,\n\t\t\t   struct nfp_cpp_area_cache, entry);\n\n\t/* Can we fit in the cache entry? */\n\tif (round_down(addr + length - 1, cache->size) !=\n\t    round_down(addr, cache->size)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\t/* If id != 0, we will need to release it */\n\tif (cache->id) {\n\t\tnfp_cpp_area_release(cache->area);\n\t\tcache->id = 0;\n\t\tcache->addr = 0;\n\t}\n\n\t/* Adjust the start address to be cache size aligned */\n\tcache->addr = addr & ~(u64)(cache->size - 1);\n\n\t/* Re-init to the new ID and address */\n\tif (cpp->op->area_init) {\n\t\terr = cpp->op->area_init(cache->area,\n\t\t\t\t\t id, cache->addr, cache->size);\n\t\tif (err < 0) {\n\t\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* Attempt to acquire */\n\terr = nfp_cpp_area_acquire(cache->area);\n\tif (err < 0) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\tcache->id = id;\n\nexit:\n\t/* Adjust offset */\n\t*offset = addr - cache->addr;\n\treturn cache;\n}",
      "modified_lines": {
        "added": [
          "\tcache->id = id;",
          ""
        ],
        "deleted": [
          "\tcache->id = id;"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper handling for releasing cache area resources without updating associated metadata fields.",
      "trigger_condition": "Releasing the cache area without updating the cache ID and address fields, leading to a use-after-free vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code snippet releases the cache area without updating the cache ID and address fields, potentially allowing access to memory that has already been freed, resulting in undefined behavior and security risks.",
      "id": 156,
      "code_after_change_normalized": "static struct VAR1 *\nFUN1(struct nfp_cpp *VAR2, u32 VAR3,\nu64 VAR4, unsigned long *VAR5, size_t VAR6)\n{\nstruct nfp_cpp_area_cache *VAR7;\nint VAR8;\nif (VAR6 == 0 || VAR3 == 0)\nreturn NULL;\nVAR8 = FUN2(VAR3, VAR4, &VAR3, &VAR4, VAR2->VAR9);\nif (VAR8 < 0)\nreturn NULL;\nFUN3(&VAR2->VAR10);\nif (FUN4(&VAR2->VAR11)) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\nVAR4 += *VAR5;\nFUN6(VAR7, &VAR2->VAR11, VAR12) {\nif (VAR3 == VAR7->VAR3 &&\nVAR4 >= VAR7->VAR4 &&\nVAR4 + VAR6 <= VAR7->VAR4 + VAR7->VAR13)\ngoto VAR14;\n}\nVAR7 = FUN7(VAR2->VAR11.VAR15,\nstruct VAR1, VAR12);\nif (FUN8(VAR4 + VAR6 - 1, VAR7->VAR13) !=\nFUN8(VAR4, VAR7->VAR13)) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\nif (VAR7->VAR3) {\nFUN9(VAR7->VAR16);\nVAR7->VAR3 = 0;\nVAR7->VAR4 = 0;\n}\nVAR7->VAR4 = VAR4 & ~(VAR17)(VAR7->VAR13 - 1);\nif (VAR2->VAR18->VAR19) {\nVAR8 = VAR2->VAR18->FUN10(VAR7->VAR16,\nVAR3, VAR7->VAR4, VAR7->VAR13);\nif (VAR8 < 0) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\n}\nVAR8 = FUN11(VAR7->VAR16);\nif (VAR8 < 0) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\nVAR7->VAR3 = VAR3;\nVAR14:\n*VAR5 = VAR4 - VAR7->VAR4;\nreturn VAR7;\n}\n",
      "code_before_change_normalized": "static struct VAR1 *\nFUN1(struct nfp_cpp *VAR2, u32 VAR3,\nu64 VAR4, unsigned long *VAR5, size_t VAR6)\n{\nstruct nfp_cpp_area_cache *VAR7;\nint VAR8;\nif (VAR6 == 0 || VAR3 == 0)\nreturn NULL;\nVAR8 = FUN2(VAR3, VAR4, &VAR3, &VAR4, VAR2->VAR9);\nif (VAR8 < 0)\nreturn NULL;\nFUN3(&VAR2->VAR10);\nif (FUN4(&VAR2->VAR11)) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\nVAR4 += *VAR5;\nFUN6(VAR7, &VAR2->VAR11, VAR12) {\nif (VAR3 == VAR7->VAR3 &&\nVAR4 >= VAR7->VAR4 &&\nVAR4 + VAR6 <= VAR7->VAR4 + VAR7->VAR13)\ngoto VAR14;\n}\nVAR7 = FUN7(VAR2->VAR11.VAR15,\nstruct VAR1, VAR12);\nif (FUN8(VAR4 + VAR6 - 1, VAR7->VAR13) !=\nFUN8(VAR4, VAR7->VAR13)) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\nif (VAR7->VAR3) {\nFUN9(VAR7->VAR16);\nVAR7->VAR3 = 0;\nVAR7->VAR4 = 0;\n}\nVAR7->VAR3 = VAR3;\nVAR7->VAR4 = VAR4 & ~(VAR17)(VAR7->VAR13 - 1);\nif (VAR2->VAR18->VAR19) {\nVAR8 = VAR2->VAR18->FUN10(VAR7->VAR16,\nVAR3, VAR7->VAR4, VAR7->VAR13);\nif (VAR8 < 0) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\n}\nVAR8 = FUN11(VAR7->VAR16);\nif (VAR8 < 0) {\nFUN5(&VAR2->VAR10);\nreturn NULL;\n}\nVAR14:\n*VAR5 = VAR4 - VAR7->VAR4;\nreturn VAR7;\n}\n",
      "code_after_change_raw": "static struct nfp_cpp_area_cache *\narea_cache_get(struct nfp_cpp *cpp, u32 id,\nu64 addr, unsigned long *offset, size_t length)\n{\nstruct nfp_cpp_area_cache *cache;\nint err;\nif (length == 0 || id == 0)\nreturn NULL;\nerr = nfp_target_cpp(id, addr, &id, &addr, cpp->imb_cat_table);\nif (err < 0)\nreturn NULL;\nmutex_lock(&cpp->area_cache_mutex);\nif (list_empty(&cpp->area_cache_list)) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\naddr += *offset;\nlist_for_each_entry(cache, &cpp->area_cache_list, entry) {\nif (id == cache->id &&\naddr >= cache->addr &&\naddr + length <= cache->addr + cache->size)\ngoto exit;\n}\ncache = list_entry(cpp->area_cache_list.prev,\nstruct nfp_cpp_area_cache, entry);\nif (round_down(addr + length - 1, cache->size) !=\nround_down(addr, cache->size)) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\nif (cache->id) {\nnfp_cpp_area_release(cache->area);\ncache->id = 0;\ncache->addr = 0;\n}\ncache->addr = addr & ~(u64)(cache->size - 1);\nif (cpp->op->area_init) {\nerr = cpp->op->area_init(cache->area,\nid, cache->addr, cache->size);\nif (err < 0) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\n}\nerr = nfp_cpp_area_acquire(cache->area);\nif (err < 0) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\ncache->id = id;\nexit:\n*offset = addr - cache->addr;\nreturn cache;\n}\n",
      "code_before_change_raw": "static struct nfp_cpp_area_cache *\narea_cache_get(struct nfp_cpp *cpp, u32 id,\nu64 addr, unsigned long *offset, size_t length)\n{\nstruct nfp_cpp_area_cache *cache;\nint err;\nif (length == 0 || id == 0)\nreturn NULL;\nerr = nfp_target_cpp(id, addr, &id, &addr, cpp->imb_cat_table);\nif (err < 0)\nreturn NULL;\nmutex_lock(&cpp->area_cache_mutex);\nif (list_empty(&cpp->area_cache_list)) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\naddr += *offset;\nlist_for_each_entry(cache, &cpp->area_cache_list, entry) {\nif (id == cache->id &&\naddr >= cache->addr &&\naddr + length <= cache->addr + cache->size)\ngoto exit;\n}\ncache = list_entry(cpp->area_cache_list.prev,\nstruct nfp_cpp_area_cache, entry);\nif (round_down(addr + length - 1, cache->size) !=\nround_down(addr, cache->size)) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\nif (cache->id) {\nnfp_cpp_area_release(cache->area);\ncache->id = 0;\ncache->addr = 0;\n}\ncache->id = id;\ncache->addr = addr & ~(u64)(cache->size - 1);\nif (cpp->op->area_init) {\nerr = cpp->op->area_init(cache->area,\nid, cache->addr, cache->size);\nif (err < 0) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\n}\nerr = nfp_cpp_area_acquire(cache->area);\nif (err < 0) {\nmutex_unlock(&cpp->area_cache_mutex);\nreturn NULL;\n}\nexit:\n*offset = addr - cache->addr;\nreturn cache;\n}\n"
    }
  ],
  "CVE-2022-3625": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for a specific condition related to device reload failure.",
        "trigger_condition": "The code attempts to call a function pointer without checking for a specific condition, leading to a use-after-free vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code does not verify the status of a flag indicating device reload failure before invoking a function pointer. This oversight can result in a use-after-free scenario if the flag is set at a critical moment."
      },
      "solution": "To mitigate the vulnerability, it is necessary to include a check for the flag indicating device reload failure before calling the function pointer. By adding this validation, the code can prevent the use-after-free vulnerability from occurring. In this case, the solution involves modifying the code to include a conditional check for the flag before invoking the function pointer.",
      "GPT_analysis": "The modification you provided is necessary to address the vulnerability identified as CVE-2022-3625. The vulnerability involves a use-after-free issue in the `devlink_param_get` function of the Linux Kernel's `net/core/devlink.c` file. \n\nBy adding the condition `devlink->reload_failed` to the `if` statement in the `devlink_param_get` function, you are checking if the `reload_failed` flag of the `devlink` structure is set. This additional check helps prevent the use-after-free vulnerability by ensuring that the `param->get` function is not called if the `reload_failed` flag is set. \n\nIn this context, the modification acts as a safeguard to prevent the use-after-free vulnerability from being exploited when the `reload_failed` condition is met. This helps improve the security of the code and mitigates the risk associated with the vulnerability.",
      "GPT_purpose": "Get a specific parameter value for a given devlink instance using the provided parameter and context.",
      "GPT_function": "\n1. Retrieve a parameter value for a given devlink instance.\n2. Check if the parameter has a getter function implemented.\n3. Return the parameter value using the getter function if available.",
      "CVE_id": "CVE-2022-3625",
      "code_before_change": "static int devlink_param_get(struct devlink *devlink,\n\t\t\t     const struct devlink_param *param,\n\t\t\t     struct devlink_param_gset_ctx *ctx)\n{\n\tif (!param->get)\n\t\treturn -EOPNOTSUPP;\n\treturn param->get(devlink, param->id, ctx);\n}",
      "code_after_change": "static int devlink_param_get(struct devlink *devlink,\n\t\t\t     const struct devlink_param *param,\n\t\t\t     struct devlink_param_gset_ctx *ctx)\n{\n\tif (!param->get || devlink->reload_failed)\n\t\treturn -EOPNOTSUPP;\n\treturn param->get(devlink, param->id, ctx);\n}",
      "modified_lines": {
        "added": [
          "\tif (!param->get || devlink->reload_failed)"
        ],
        "deleted": [
          "\tif (!param->get)"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for a specific condition related to device reload failure.",
      "trigger_condition": "The code attempts to call a function pointer without checking for a specific condition, leading to a use-after-free vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code does not verify the status of a flag indicating device reload failure before invoking a function pointer. This oversight can result in a use-after-free scenario if the flag is set at a critical moment.",
      "id": 157,
      "code_after_change_normalized": "static int FUN1(struct VAR1 *VAR1,\nconst struct devlink_param *VAR2,\nstruct devlink_param_gset_ctx *VAR3)\n{\nif (!VAR2->VAR4 || VAR1->VAR5)\nreturn -VAR6;\nreturn VAR2->FUN2(VAR1, VAR2->VAR7, VAR3);\n}\n",
      "code_before_change_normalized": "static int FUN1(struct VAR1 *VAR1,\nconst struct devlink_param *VAR2,\nstruct devlink_param_gset_ctx *VAR3)\n{\nif (!VAR2->VAR4)\nreturn -VAR5;\nreturn VAR2->FUN2(VAR1, VAR2->VAR6, VAR3);\n}\n",
      "code_after_change_raw": "static int devlink_param_get(struct devlink *devlink,\nconst struct devlink_param *param,\nstruct devlink_param_gset_ctx *ctx)\n{\nif (!param->get || devlink->reload_failed)\nreturn -EOPNOTSUPP;\nreturn param->get(devlink, param->id, ctx);\n}\n",
      "code_before_change_raw": "static int devlink_param_get(struct devlink *devlink,\nconst struct devlink_param *param,\nstruct devlink_param_gset_ctx *ctx)\n{\nif (!param->get)\nreturn -EOPNOTSUPP;\nreturn param->get(devlink, param->id, ctx);\n}\n"
    }
  ],
  "CVE-2022-3636": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of linked list traversal without safe iteration mechanism.",
        "trigger_condition": "A situation where an entry in the linked list is freed or modified during traversal, leading to a use-after-free vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code iterates over a linked list using hlist_for_each_entry without using hlist_for_each_entry_safe, which can result in accessing freed memory if an entry is deleted or modified during the iteration."
      },
      "solution": "To mitigate the vulnerability, it is necessary to use a safe iteration mechanism like hlist_for_each_entry_safe when traversing the linked list. This ensures that the code can handle scenarios where entries are deleted or modified during the iteration without risking a use-after-free vulnerability. In this case, the solution involves replacing hlist_for_each_entry with hlist_for_each_entry_safe to provide a safe traversal method for the linked list.",
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2022-3636, which involves a use-after-free issue in the Linux Kernel's Ethernet Handler component. The vulnerability occurs due to improper handling of network packets in the __mtk_ppe_check_skb function. By iterating over the linked list using hlist_for_each_entry without using hlist_for_each_entry_safe, the code may encounter a situation where the current entry is freed or removed while still being accessed, leading to a use-after-free scenario.\n\nBy modifying the code to use hlist_for_each_entry_safe instead of hlist_for_each_entry, the code ensures that the list traversal is safe even if entries are deleted or modified during the iteration. This change helps prevent the use-after-free vulnerability by providing a safe way to iterate over the list without risking accessing freed memory.\n\nTherefore, the modification is crucial to fixing the vulnerability and ensuring the proper handling of network packets in the Linux Kernel's Ethernet Handler component.",
      "GPT_purpose": "Check and process network packets in a MediaTek PPE (Packet Processing Engine) structure for Ethernet handling.",
      "GPT_function": "\n1. Check the state of a specific entry in the foe_table.\n2. Iterate through a list of flow entries to find a match based on criteria.\n3. Handle VLAN tagging based on the protocol of the incoming skb.\n4. Look up a flow entry in the l2_flows hashtable using a specific key.\n5. Commit a subflow entry if found, otherwise unlock the spin lock.",
      "CVE_id": "CVE-2022-3636",
      "code_before_change": "void __mtk_ppe_check_skb(struct mtk_ppe *ppe, struct sk_buff *skb, u16 hash)\n{\n\tstruct hlist_head *head = &ppe->foe_flow[hash / 2];\n\tstruct mtk_foe_entry *hwe = &ppe->foe_table[hash];\n\tstruct mtk_flow_entry *entry;\n\tstruct mtk_foe_bridge key = {};\n\tstruct ethhdr *eh;\n\tbool found = false;\n\tu8 *tag;\n\n\tspin_lock_bh(&ppe_lock);\n\n\tif (FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) == MTK_FOE_STATE_BIND)\n\t\tgoto out;\n\n\thlist_for_each_entry(entry, head, list) {\n\t\tif (entry->type == MTK_FLOW_TYPE_L2_SUBFLOW) {\n\t\t\tif (unlikely(FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) ==\n\t\t\t\t     MTK_FOE_STATE_BIND))\n\t\t\t\tcontinue;\n\n\t\t\tentry->hash = 0xffff;\n\t\t\t__mtk_foe_entry_clear(ppe, entry);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (found || !mtk_flow_entry_match(entry, hwe)) {\n\t\t\tif (entry->hash != 0xffff)\n\t\t\t\tentry->hash = 0xffff;\n\t\t\tcontinue;\n\t\t}\n\n\t\tentry->hash = hash;\n\t\t__mtk_foe_entry_commit(ppe, &entry->data, hash);\n\t\tfound = true;\n\t}\n\n\tif (found)\n\t\tgoto out;\n\n\teh = eth_hdr(skb);\n\tether_addr_copy(key.dest_mac, eh->h_dest);\n\tether_addr_copy(key.src_mac, eh->h_source);\n\ttag = skb->data - 2;\n\tkey.vlan = 0;\n\tswitch (skb->protocol) {\n#if IS_ENABLED(CONFIG_NET_DSA)\n\tcase htons(ETH_P_XDSA):\n\t\tif (!netdev_uses_dsa(skb->dev) ||\n\t\t    skb->dev->dsa_ptr->tag_ops->proto != DSA_TAG_PROTO_MTK)\n\t\t\tgoto out;\n\n\t\ttag += 4;\n\t\tif (get_unaligned_be16(tag) != ETH_P_8021Q)\n\t\t\tbreak;\n\n\t\tfallthrough;\n#endif\n\tcase htons(ETH_P_8021Q):\n\t\tkey.vlan = get_unaligned_be16(tag + 2) & VLAN_VID_MASK;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tentry = rhashtable_lookup_fast(&ppe->l2_flows, &key, mtk_flow_l2_ht_params);\n\tif (!entry)\n\t\tgoto out;\n\n\tmtk_foe_entry_commit_subflow(ppe, entry, hash);\n\nout:\n\tspin_unlock_bh(&ppe_lock);\n}",
      "code_after_change": "void __mtk_ppe_check_skb(struct mtk_ppe *ppe, struct sk_buff *skb, u16 hash)\n{\n\tstruct hlist_head *head = &ppe->foe_flow[hash / 2];\n\tstruct mtk_foe_entry *hwe = &ppe->foe_table[hash];\n\tstruct mtk_flow_entry *entry;\n\tstruct mtk_foe_bridge key = {};\n\tstruct hlist_node *n;\n\tstruct ethhdr *eh;\n\tbool found = false;\n\tu8 *tag;\n\n\tspin_lock_bh(&ppe_lock);\n\n\tif (FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) == MTK_FOE_STATE_BIND)\n\t\tgoto out;\n\n\thlist_for_each_entry_safe(entry, n, head, list) {\n\t\tif (entry->type == MTK_FLOW_TYPE_L2_SUBFLOW) {\n\t\t\tif (unlikely(FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) ==\n\t\t\t\t     MTK_FOE_STATE_BIND))\n\t\t\t\tcontinue;\n\n\t\t\tentry->hash = 0xffff;\n\t\t\t__mtk_foe_entry_clear(ppe, entry);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (found || !mtk_flow_entry_match(entry, hwe)) {\n\t\t\tif (entry->hash != 0xffff)\n\t\t\t\tentry->hash = 0xffff;\n\t\t\tcontinue;\n\t\t}\n\n\t\tentry->hash = hash;\n\t\t__mtk_foe_entry_commit(ppe, &entry->data, hash);\n\t\tfound = true;\n\t}\n\n\tif (found)\n\t\tgoto out;\n\n\teh = eth_hdr(skb);\n\tether_addr_copy(key.dest_mac, eh->h_dest);\n\tether_addr_copy(key.src_mac, eh->h_source);\n\ttag = skb->data - 2;\n\tkey.vlan = 0;\n\tswitch (skb->protocol) {\n#if IS_ENABLED(CONFIG_NET_DSA)\n\tcase htons(ETH_P_XDSA):\n\t\tif (!netdev_uses_dsa(skb->dev) ||\n\t\t    skb->dev->dsa_ptr->tag_ops->proto != DSA_TAG_PROTO_MTK)\n\t\t\tgoto out;\n\n\t\ttag += 4;\n\t\tif (get_unaligned_be16(tag) != ETH_P_8021Q)\n\t\t\tbreak;\n\n\t\tfallthrough;\n#endif\n\tcase htons(ETH_P_8021Q):\n\t\tkey.vlan = get_unaligned_be16(tag + 2) & VLAN_VID_MASK;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tentry = rhashtable_lookup_fast(&ppe->l2_flows, &key, mtk_flow_l2_ht_params);\n\tif (!entry)\n\t\tgoto out;\n\n\tmtk_foe_entry_commit_subflow(ppe, entry, hash);\n\nout:\n\tspin_unlock_bh(&ppe_lock);\n}",
      "modified_lines": {
        "added": [
          "\tstruct hlist_node *n;",
          "\thlist_for_each_entry_safe(entry, n, head, list) {"
        ],
        "deleted": [
          "\thlist_for_each_entry(entry, head, list) {"
        ]
      },
      "preconditions_for_vulnerability": "Improper handling of linked list traversal without safe iteration mechanism.",
      "trigger_condition": "A situation where an entry in the linked list is freed or modified during traversal, leading to a use-after-free vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code iterates over a linked list using hlist_for_each_entry without using hlist_for_each_entry_safe, which can result in accessing freed memory if an entry is deleted or modified during the iteration.",
      "id": 158,
      "code_after_change_normalized": "void FUN1(struct mtk_ppe *VAR1, struct sk_buff *VAR2, u16 VAR3)\n{\nstruct hlist_head *VAR4 = &VAR1->VAR5[VAR3 / 2];\nstruct mtk_foe_entry *VAR6 = &VAR1->VAR7[VAR3];\nstruct mtk_flow_entry *VAR8;\nstruct mtk_foe_bridge VAR9 = {};\nstruct hlist_node *VAR10;\nstruct ethhdr *VAR11;\nbool VAR12 = false;\nu8 *VAR13;\nFUN2(&VAR14);\nif (FUN3(VAR15, VAR6->VAR16) == VAR17)\ngoto VAR18;\nFUN4(VAR8, VAR10, VAR4, VAR19) {\nif (VAR8->VAR20 == VAR21) {\nif (FUN5(FUN3(VAR15, VAR6->VAR16) ==\nVAR17))\ncontinue;\nVAR8->VAR3 = VAR22;\nFUN6(VAR1, VAR8);\ncontinue;\n}\nif (VAR12 || !FUN7(VAR8, VAR6)) {\nif (VAR8->VAR3 != VAR22)\nVAR8->VAR3 = VAR22;\ncontinue;\n}\nVAR8->VAR3 = VAR3;\nFUN8(VAR1, &VAR8->VAR23, VAR3);\nVAR12 = true;\n}\nif (VAR12)\ngoto VAR18;\nVAR11 = FUN9(VAR2);\nFUN10(VAR9.VAR24, VAR11->VAR25);\nFUN10(VAR9.VAR26, VAR11->VAR27);\nVAR13 = VAR2->VAR23 - 2;\nVAR9.VAR28 = 0;\nswitch (VAR2->VAR29) {\n#if FUN11(VAR30)\ncase FUN12(VAR31):\nif (!FUN13(VAR2->VAR32) ||\nVAR2->VAR32->VAR33->VAR34->VAR35 != VAR36)\ngoto VAR18;\nVAR13 += 4;\nif (FUN14(VAR13) != VAR37)\nbreak;\nVAR38;\n#VAR39\ncase FUN12(VAR37):\nVAR9.VAR28 = FUN14(VAR13 + 2) & VAR40;\nbreak;\ndefault:\nbreak;\n}\nVAR8 = FUN15(&VAR1->VAR41, &VAR9, VAR42);\nif (!VAR8)\ngoto VAR18;\nFUN16(VAR1, VAR8, VAR3);\nVAR18:\nFUN17(&VAR14);\n}\n",
      "code_before_change_normalized": "void FUN1(struct mtk_ppe *VAR1, struct sk_buff *VAR2, u16 VAR3)\n{\nstruct hlist_head *VAR4 = &VAR1->VAR5[VAR3 / 2];\nstruct mtk_foe_entry *VAR6 = &VAR1->VAR7[VAR3];\nstruct mtk_flow_entry *VAR8;\nstruct mtk_foe_bridge VAR9 = {};\nstruct ethhdr *VAR10;\nbool VAR11 = false;\nu8 *VAR12;\nFUN2(&VAR13);\nif (FUN3(VAR14, VAR6->VAR15) == VAR16)\ngoto VAR17;\nFUN4(VAR8, VAR4, VAR18) {\nif (VAR8->VAR19 == VAR20) {\nif (FUN5(FUN3(VAR14, VAR6->VAR15) ==\nVAR16))\ncontinue;\nVAR8->VAR3 = VAR21;\nFUN6(VAR1, VAR8);\ncontinue;\n}\nif (VAR11 || !FUN7(VAR8, VAR6)) {\nif (VAR8->VAR3 != VAR21)\nVAR8->VAR3 = VAR21;\ncontinue;\n}\nVAR8->VAR3 = VAR3;\nFUN8(VAR1, &VAR8->VAR22, VAR3);\nVAR11 = true;\n}\nif (VAR11)\ngoto VAR17;\nVAR10 = FUN9(VAR2);\nFUN10(VAR9.VAR23, VAR10->VAR24);\nFUN10(VAR9.VAR25, VAR10->VAR26);\nVAR12 = VAR2->VAR22 - 2;\nVAR9.VAR27 = 0;\nswitch (VAR2->VAR28) {\n#if FUN11(VAR29)\ncase FUN12(VAR30):\nif (!FUN13(VAR2->VAR31) ||\nVAR2->VAR31->VAR32->VAR33->VAR34 != VAR35)\ngoto VAR17;\nVAR12 += 4;\nif (FUN14(VAR12) != VAR36)\nbreak;\nVAR37;\n#VAR38\ncase FUN12(VAR36):\nVAR9.VAR27 = FUN14(VAR12 + 2) & VAR39;\nbreak;\ndefault:\nbreak;\n}\nVAR8 = FUN15(&VAR1->VAR40, &VAR9, VAR41);\nif (!VAR8)\ngoto VAR17;\nFUN16(VAR1, VAR8, VAR3);\nVAR17:\nFUN17(&VAR13);\n}\n",
      "code_after_change_raw": "void __mtk_ppe_check_skb(struct mtk_ppe *ppe, struct sk_buff *skb, u16 hash)\n{\nstruct hlist_head *head = &ppe->foe_flow[hash / 2];\nstruct mtk_foe_entry *hwe = &ppe->foe_table[hash];\nstruct mtk_flow_entry *entry;\nstruct mtk_foe_bridge key = {};\nstruct hlist_node *n;\nstruct ethhdr *eh;\nbool found = false;\nu8 *tag;\nspin_lock_bh(&ppe_lock);\nif (FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) == MTK_FOE_STATE_BIND)\ngoto out;\nhlist_for_each_entry_safe(entry, n, head, list) {\nif (entry->type == MTK_FLOW_TYPE_L2_SUBFLOW) {\nif (unlikely(FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) ==\nMTK_FOE_STATE_BIND))\ncontinue;\nentry->hash = 0xffff;\n__mtk_foe_entry_clear(ppe, entry);\ncontinue;\n}\nif (found || !mtk_flow_entry_match(entry, hwe)) {\nif (entry->hash != 0xffff)\nentry->hash = 0xffff;\ncontinue;\n}\nentry->hash = hash;\n__mtk_foe_entry_commit(ppe, &entry->data, hash);\nfound = true;\n}\nif (found)\ngoto out;\neh = eth_hdr(skb);\nether_addr_copy(key.dest_mac, eh->h_dest);\nether_addr_copy(key.src_mac, eh->h_source);\ntag = skb->data - 2;\nkey.vlan = 0;\nswitch (skb->protocol) {\n#if IS_ENABLED(CONFIG_NET_DSA)\ncase htons(ETH_P_XDSA):\nif (!netdev_uses_dsa(skb->dev) ||\nskb->dev->dsa_ptr->tag_ops->proto != DSA_TAG_PROTO_MTK)\ngoto out;\ntag += 4;\nif (get_unaligned_be16(tag) != ETH_P_8021Q)\nbreak;\nfallthrough;\n#endif\ncase htons(ETH_P_8021Q):\nkey.vlan = get_unaligned_be16(tag + 2) & VLAN_VID_MASK;\nbreak;\ndefault:\nbreak;\n}\nentry = rhashtable_lookup_fast(&ppe->l2_flows, &key, mtk_flow_l2_ht_params);\nif (!entry)\ngoto out;\nmtk_foe_entry_commit_subflow(ppe, entry, hash);\nout:\nspin_unlock_bh(&ppe_lock);\n}\n",
      "code_before_change_raw": "void __mtk_ppe_check_skb(struct mtk_ppe *ppe, struct sk_buff *skb, u16 hash)\n{\nstruct hlist_head *head = &ppe->foe_flow[hash / 2];\nstruct mtk_foe_entry *hwe = &ppe->foe_table[hash];\nstruct mtk_flow_entry *entry;\nstruct mtk_foe_bridge key = {};\nstruct ethhdr *eh;\nbool found = false;\nu8 *tag;\nspin_lock_bh(&ppe_lock);\nif (FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) == MTK_FOE_STATE_BIND)\ngoto out;\nhlist_for_each_entry(entry, head, list) {\nif (entry->type == MTK_FLOW_TYPE_L2_SUBFLOW) {\nif (unlikely(FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) ==\nMTK_FOE_STATE_BIND))\ncontinue;\nentry->hash = 0xffff;\n__mtk_foe_entry_clear(ppe, entry);\ncontinue;\n}\nif (found || !mtk_flow_entry_match(entry, hwe)) {\nif (entry->hash != 0xffff)\nentry->hash = 0xffff;\ncontinue;\n}\nentry->hash = hash;\n__mtk_foe_entry_commit(ppe, &entry->data, hash);\nfound = true;\n}\nif (found)\ngoto out;\neh = eth_hdr(skb);\nether_addr_copy(key.dest_mac, eh->h_dest);\nether_addr_copy(key.src_mac, eh->h_source);\ntag = skb->data - 2;\nkey.vlan = 0;\nswitch (skb->protocol) {\n#if IS_ENABLED(CONFIG_NET_DSA)\ncase htons(ETH_P_XDSA):\nif (!netdev_uses_dsa(skb->dev) ||\nskb->dev->dsa_ptr->tag_ops->proto != DSA_TAG_PROTO_MTK)\ngoto out;\ntag += 4;\nif (get_unaligned_be16(tag) != ETH_P_8021Q)\nbreak;\nfallthrough;\n#endif\ncase htons(ETH_P_8021Q):\nkey.vlan = get_unaligned_be16(tag + 2) & VLAN_VID_MASK;\nbreak;\ndefault:\nbreak;\n}\nentry = rhashtable_lookup_fast(&ppe->l2_flows, &key, mtk_flow_l2_ht_params);\nif (!entry)\ngoto out;\nmtk_foe_entry_commit_subflow(ppe, entry, hash);\nout:\nspin_unlock_bh(&ppe_lock);\n}\n"
    }
  ],
  "CVE-2022-3640": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper handling of the Bluetooth L2CAP channel object after potential deallocation.",
        "trigger_condition": "The channel object is accessed after it has been potentially freed by kfree_skb(skb) in the drop label, leading to a use-after-free vulnerability.",
        "specific_code_behavior_causing_vulnerability": "The code snippet does not properly manage the lifetime of the L2CAP channel object, leading to a scenario where the object can be accessed after it has been deallocated. This can result in a use-after-free vulnerability, potentially allowing for crashes or arbitrary code execution."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure that the L2CAP channel object remains valid and accessible throughout the function. The solution involves increasing the reference count of the channel object by adding l2cap_chan_hold(chan) before l2cap_chan_lock(chan). This change helps prevent premature deallocation of the object and mitigates the use-after-free vulnerability by properly managing the object's lifetime and ensuring safe access.",
      "GPT_analysis": "The above modification is necessary to address the vulnerability CVE-2022-3640, which is a critical use-after-free vulnerability found in the Linux Kernel's Bluetooth component. The vulnerability specifically affects the function `l2cap_conn_del` in the file `net/bluetooth/l2cap_core.c`.\n\nThe vulnerability arises due to improper handling of the Bluetooth L2CAP channel object (`struct l2cap_chan`) when it is being accessed after it has been freed. In the original code snippet provided, the `chan` object is being unlocked and put after it has been potentially freed by `kfree_skb(skb)` in the `drop` label. This can lead to a use-after-free scenario where the `chan` object is accessed after it has been deallocated, potentially resulting in a crash or allowing an attacker to execute arbitrary code.\n\nTo fix this vulnerability, the modification involves adding the line `l2cap_chan_hold(chan)` before `l2cap_chan_lock(chan)` in the code snippet. By adding this line, the reference count of the `chan` object is increased before it is locked, ensuring that the object remains valid and preventing it from being prematurely freed. This change helps to mitigate the use-after-free vulnerability by properly managing the object's lifetime and ensuring that it is safely accessed throughout the function.\n\nTherefore, the modification is necessary to prevent the exploitation of the use-after-free vulnerability and ensure the secure handling of the Bluetooth L2CAP channel objects in the Linux Kernel.",
      "GPT_purpose": "Handle data received on an L2CAP channel, including creating a new channel if necessary and processing the received data based on the channel's mode.",
      "GPT_function": "\n1. Handle incoming data on an L2CAP data channel.\n2. Check if the channel is known or create a new channel if it is an A2MP channel.\n3. Process the received data based on the channel's mode and type.\n4. Handle different modes of operation for the L2CAP channel.\n5. Free the socket buffer if needed and unlock the channel.\n6. Drop the packet if necessary and release the channel.",
      "CVE_id": "CVE-2022-3640",
      "code_before_change": "static void l2cap_data_channel(struct l2cap_conn *conn, u16 cid,\n\t\t\t       struct sk_buff *skb)\n{\n\tstruct l2cap_chan *chan;\n\n\tchan = l2cap_get_chan_by_scid(conn, cid);\n\tif (!chan) {\n\t\tif (cid == L2CAP_CID_A2MP) {\n\t\t\tchan = a2mp_channel_create(conn, skb);\n\t\t\tif (!chan) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tl2cap_chan_lock(chan);\n\t\t} else {\n\t\t\tBT_DBG(\"unknown cid 0x%4.4x\", cid);\n\t\t\t/* Drop packet and return */\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tBT_DBG(\"chan %p, len %d\", chan, skb->len);\n\n\t/* If we receive data on a fixed channel before the info req/rsp\n\t * procedure is done simply assume that the channel is supported\n\t * and mark it as ready.\n\t */\n\tif (chan->chan_type == L2CAP_CHAN_FIXED)\n\t\tl2cap_chan_ready(chan);\n\n\tif (chan->state != BT_CONNECTED)\n\t\tgoto drop;\n\n\tswitch (chan->mode) {\n\tcase L2CAP_MODE_LE_FLOWCTL:\n\tcase L2CAP_MODE_EXT_FLOWCTL:\n\t\tif (l2cap_ecred_data_rcv(chan, skb) < 0)\n\t\t\tgoto drop;\n\n\t\tgoto done;\n\n\tcase L2CAP_MODE_BASIC:\n\t\t/* If socket recv buffers overflows we drop data here\n\t\t * which is *bad* because L2CAP has to be reliable.\n\t\t * But we don't have any other choice. L2CAP doesn't\n\t\t * provide flow control mechanism. */\n\n\t\tif (chan->imtu < skb->len) {\n\t\t\tBT_ERR(\"Dropping L2CAP data: receive buffer overflow\");\n\t\t\tgoto drop;\n\t\t}\n\n\t\tif (!chan->ops->recv(chan, skb))\n\t\t\tgoto done;\n\t\tbreak;\n\n\tcase L2CAP_MODE_ERTM:\n\tcase L2CAP_MODE_STREAMING:\n\t\tl2cap_data_rcv(chan, skb);\n\t\tgoto done;\n\n\tdefault:\n\t\tBT_DBG(\"chan %p: bad mode 0x%2.2x\", chan, chan->mode);\n\t\tbreak;\n\t}\n\ndrop:\n\tkfree_skb(skb);\n\ndone:\n\tl2cap_chan_unlock(chan);\n\tl2cap_chan_put(chan);\n}",
      "code_after_change": "static void l2cap_data_channel(struct l2cap_conn *conn, u16 cid,\n\t\t\t       struct sk_buff *skb)\n{\n\tstruct l2cap_chan *chan;\n\n\tchan = l2cap_get_chan_by_scid(conn, cid);\n\tif (!chan) {\n\t\tif (cid == L2CAP_CID_A2MP) {\n\t\t\tchan = a2mp_channel_create(conn, skb);\n\t\t\tif (!chan) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tl2cap_chan_hold(chan);\n\t\t\tl2cap_chan_lock(chan);\n\t\t} else {\n\t\t\tBT_DBG(\"unknown cid 0x%4.4x\", cid);\n\t\t\t/* Drop packet and return */\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tBT_DBG(\"chan %p, len %d\", chan, skb->len);\n\n\t/* If we receive data on a fixed channel before the info req/rsp\n\t * procedure is done simply assume that the channel is supported\n\t * and mark it as ready.\n\t */\n\tif (chan->chan_type == L2CAP_CHAN_FIXED)\n\t\tl2cap_chan_ready(chan);\n\n\tif (chan->state != BT_CONNECTED)\n\t\tgoto drop;\n\n\tswitch (chan->mode) {\n\tcase L2CAP_MODE_LE_FLOWCTL:\n\tcase L2CAP_MODE_EXT_FLOWCTL:\n\t\tif (l2cap_ecred_data_rcv(chan, skb) < 0)\n\t\t\tgoto drop;\n\n\t\tgoto done;\n\n\tcase L2CAP_MODE_BASIC:\n\t\t/* If socket recv buffers overflows we drop data here\n\t\t * which is *bad* because L2CAP has to be reliable.\n\t\t * But we don't have any other choice. L2CAP doesn't\n\t\t * provide flow control mechanism. */\n\n\t\tif (chan->imtu < skb->len) {\n\t\t\tBT_ERR(\"Dropping L2CAP data: receive buffer overflow\");\n\t\t\tgoto drop;\n\t\t}\n\n\t\tif (!chan->ops->recv(chan, skb))\n\t\t\tgoto done;\n\t\tbreak;\n\n\tcase L2CAP_MODE_ERTM:\n\tcase L2CAP_MODE_STREAMING:\n\t\tl2cap_data_rcv(chan, skb);\n\t\tgoto done;\n\n\tdefault:\n\t\tBT_DBG(\"chan %p: bad mode 0x%2.2x\", chan, chan->mode);\n\t\tbreak;\n\t}\n\ndrop:\n\tkfree_skb(skb);\n\ndone:\n\tl2cap_chan_unlock(chan);\n\tl2cap_chan_put(chan);\n}",
      "modified_lines": {
        "added": [
          "\t\t\tl2cap_chan_hold(chan);"
        ],
        "deleted": []
      },
      "preconditions_for_vulnerability": "Improper handling of the Bluetooth L2CAP channel object after potential deallocation.",
      "trigger_condition": "The channel object is accessed after it has been potentially freed by kfree_skb(skb) in the drop label, leading to a use-after-free vulnerability.",
      "specific_code_behavior_causing_vulnerability": "The code snippet does not properly manage the lifetime of the L2CAP channel object, leading to a scenario where the object can be accessed after it has been deallocated. This can result in a use-after-free vulnerability, potentially allowing for crashes or arbitrary code execution.",
      "id": 159,
      "code_after_change_normalized": "static void FUN1(struct l2cap_conn *VAR1, u16 VAR2,\nstruct sk_buff *VAR3)\n{\nstruct l2cap_chan *VAR4;\nVAR4 = FUN2(VAR1, VAR2);\nif (!VAR4) {\nif (VAR2 == VAR5) {\nVAR4 = FUN3(VAR1, VAR3);\nif (!VAR4) {\nFUN4(VAR3);\nreturn;\n}\nFUN5(VAR4);\nFUN6(VAR4);\n} else {\nFUN7(\"STR\", VAR2);\nFUN4(VAR3);\nreturn;\n}\n}\nFUN7(\"STR\", VAR4, VAR3->VAR6);\nif (VAR4->VAR7 == VAR8)\nFUN8(VAR4);\nif (VAR4->VAR9 != VAR10)\ngoto VAR11;\nswitch (VAR4->VAR12) {\ncase VAR13:\ncase VAR14:\nif (FUN9(VAR4, VAR3) < 0)\ngoto VAR11;\ngoto VAR15;\ncase VAR16:\nif (VAR4->VAR17 < VAR3->VAR6) {\nFUN10(\"STR\");\ngoto VAR11;\n}\nif (!VAR4->VAR18->FUN11(VAR4, VAR3))\ngoto VAR15;\nbreak;\ncase VAR19:\ncase VAR20:\nFUN12(VAR4, VAR3);\ngoto VAR15;\ndefault:\nFUN7(\"STR\", VAR4, VAR4->VAR12);\nbreak;\n}\nVAR11:\nFUN4(VAR3);\nVAR15:\nFUN13(VAR4);\nFUN14(VAR4);\n}\n",
      "code_before_change_normalized": "static void FUN1(struct l2cap_conn *VAR1, u16 VAR2,\nstruct sk_buff *VAR3)\n{\nstruct l2cap_chan *VAR4;\nVAR4 = FUN2(VAR1, VAR2);\nif (!VAR4) {\nif (VAR2 == VAR5) {\nVAR4 = FUN3(VAR1, VAR3);\nif (!VAR4) {\nFUN4(VAR3);\nreturn;\n}\nFUN5(VAR4);\n} else {\nFUN6(\"STR\", VAR2);\nFUN4(VAR3);\nreturn;\n}\n}\nFUN6(\"STR\", VAR4, VAR3->VAR6);\nif (VAR4->VAR7 == VAR8)\nFUN7(VAR4);\nif (VAR4->VAR9 != VAR10)\ngoto VAR11;\nswitch (VAR4->VAR12) {\ncase VAR13:\ncase VAR14:\nif (FUN8(VAR4, VAR3) < 0)\ngoto VAR11;\ngoto VAR15;\ncase VAR16:\nif (VAR4->VAR17 < VAR3->VAR6) {\nFUN9(\"STR\");\ngoto VAR11;\n}\nif (!VAR4->VAR18->FUN10(VAR4, VAR3))\ngoto VAR15;\nbreak;\ncase VAR19:\ncase VAR20:\nFUN11(VAR4, VAR3);\ngoto VAR15;\ndefault:\nFUN6(\"STR\", VAR4, VAR4->VAR12);\nbreak;\n}\nVAR11:\nFUN4(VAR3);\nVAR15:\nFUN12(VAR4);\nFUN13(VAR4);\n}\n",
      "code_after_change_raw": "static void l2cap_data_channel(struct l2cap_conn *conn, u16 cid,\nstruct sk_buff *skb)\n{\nstruct l2cap_chan *chan;\nchan = l2cap_get_chan_by_scid(conn, cid);\nif (!chan) {\nif (cid == L2CAP_CID_A2MP) {\nchan = a2mp_channel_create(conn, skb);\nif (!chan) {\nkfree_skb(skb);\nreturn;\n}\nl2cap_chan_hold(chan);\nl2cap_chan_lock(chan);\n} else {\nBT_DBG(\"unknown cid 0x%4.4x\", cid);\nkfree_skb(skb);\nreturn;\n}\n}\nBT_DBG(\"chan %p, len %d\", chan, skb->len);\nif (chan->chan_type == L2CAP_CHAN_FIXED)\nl2cap_chan_ready(chan);\nif (chan->state != BT_CONNECTED)\ngoto drop;\nswitch (chan->mode) {\ncase L2CAP_MODE_LE_FLOWCTL:\ncase L2CAP_MODE_EXT_FLOWCTL:\nif (l2cap_ecred_data_rcv(chan, skb) < 0)\ngoto drop;\ngoto done;\ncase L2CAP_MODE_BASIC:\nif (chan->imtu < skb->len) {\nBT_ERR(\"Dropping L2CAP data: receive buffer overflow\");\ngoto drop;\n}\nif (!chan->ops->recv(chan, skb))\ngoto done;\nbreak;\ncase L2CAP_MODE_ERTM:\ncase L2CAP_MODE_STREAMING:\nl2cap_data_rcv(chan, skb);\ngoto done;\ndefault:\nBT_DBG(\"chan %p: bad mode 0x%2.2x\", chan, chan->mode);\nbreak;\n}\ndrop:\nkfree_skb(skb);\ndone:\nl2cap_chan_unlock(chan);\nl2cap_chan_put(chan);\n}\n",
      "code_before_change_raw": "static void l2cap_data_channel(struct l2cap_conn *conn, u16 cid,\nstruct sk_buff *skb)\n{\nstruct l2cap_chan *chan;\nchan = l2cap_get_chan_by_scid(conn, cid);\nif (!chan) {\nif (cid == L2CAP_CID_A2MP) {\nchan = a2mp_channel_create(conn, skb);\nif (!chan) {\nkfree_skb(skb);\nreturn;\n}\nl2cap_chan_lock(chan);\n} else {\nBT_DBG(\"unknown cid 0x%4.4x\", cid);\nkfree_skb(skb);\nreturn;\n}\n}\nBT_DBG(\"chan %p, len %d\", chan, skb->len);\nif (chan->chan_type == L2CAP_CHAN_FIXED)\nl2cap_chan_ready(chan);\nif (chan->state != BT_CONNECTED)\ngoto drop;\nswitch (chan->mode) {\ncase L2CAP_MODE_LE_FLOWCTL:\ncase L2CAP_MODE_EXT_FLOWCTL:\nif (l2cap_ecred_data_rcv(chan, skb) < 0)\ngoto drop;\ngoto done;\ncase L2CAP_MODE_BASIC:\nif (chan->imtu < skb->len) {\nBT_ERR(\"Dropping L2CAP data: receive buffer overflow\");\ngoto drop;\n}\nif (!chan->ops->recv(chan, skb))\ngoto done;\nbreak;\ncase L2CAP_MODE_ERTM:\ncase L2CAP_MODE_STREAMING:\nl2cap_data_rcv(chan, skb);\ngoto done;\ndefault:\nBT_DBG(\"chan %p: bad mode 0x%2.2x\", chan, chan->mode);\nbreak;\n}\ndrop:\nkfree_skb(skb);\ndone:\nl2cap_chan_unlock(chan);\nl2cap_chan_put(chan);\n}\n"
    }
  ],
  "CVE-2022-3649": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper buffer head handling during inode creation process.",
        "trigger_condition": "An error occurs during inode creation, leading to a use-after-free scenario due to improper handling of the buffer head.",
        "specific_code_behavior_causing_vulnerability": "The code does not handle the buffer head associated with inode creation properly, potentially resulting in a situation where the buffer head is used after being released. This can lead to a use-after-free vulnerability if an error occurs during inode creation."
      },
      "solution": "To mitigate the vulnerability, it is necessary to ensure proper handling of the buffer head during inode creation. Specifically, the code should introduce a buffer head variable to manage the buffer head associated with inode creation and include checks to verify the validity of the inode number. Additionally, a repair mechanism should be implemented to address any inconsistencies in the inode bitmap for reserved inodes. By making these modifications, the code prevents the use-after-free vulnerability by correctly managing the buffer head and performing necessary checks during inode creation.",
      "GPT_analysis": "The modification in the code snippet is necessary to address the vulnerability CVE-2022-3649, which is classified as problematic and can lead to a use-after-free issue in the Linux Kernel. The vulnerability affects the function `nilfs_new_inode` in the file `fs/nilfs2/inode.c` of the component BPF.\n\nThe vulnerability arises from the fact that the `nilfs_ifile_create_inode` function call may result in a use-after-free scenario if an error occurs during inode creation. Specifically, if an error occurs, the `bh` buffer head is not properly handled, potentially leading to a situation where the buffer head is used after it has been released.\n\nTo fix this issue, the modification adds a `bh` buffer head variable to properly handle the buffer head associated with the inode creation process. Additionally, it introduces a check to ensure that the `ino` value is within a valid range (`NILFS_USER_INO`) and attempts to repair the inode bitmap for reserved inodes if necessary.\n\nBy making these modifications, the code addresses the use-after-free vulnerability by ensuring proper handling of the buffer head and performing necessary checks during inode creation, thus preventing potential exploitation of the vulnerability.",
      "GPT_purpose": "Create a new inode in the NILFS filesystem.",
      "GPT_function": "\n1. Allocate a new inode within the nilfs filesystem.\n2. Initialize various attributes of the new inode.\n3. Handle errors and return the inode or an error pointer.",
      "CVE_id": "CVE-2022-3649",
      "code_before_change": "struct inode *nilfs_new_inode(struct inode *dir, umode_t mode)\n{\n\tstruct super_block *sb = dir->i_sb;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct inode *inode;\n\tstruct nilfs_inode_info *ii;\n\tstruct nilfs_root *root;\n\tint err = -ENOMEM;\n\tino_t ino;\n\n\tinode = new_inode(sb);\n\tif (unlikely(!inode))\n\t\tgoto failed;\n\n\tmapping_set_gfp_mask(inode->i_mapping,\n\t\t\t   mapping_gfp_constraint(inode->i_mapping, ~__GFP_FS));\n\n\troot = NILFS_I(dir)->i_root;\n\tii = NILFS_I(inode);\n\tii->i_state = BIT(NILFS_I_NEW);\n\tii->i_root = root;\n\n\terr = nilfs_ifile_create_inode(root->ifile, &ino, &ii->i_bh);\n\tif (unlikely(err))\n\t\tgoto failed_ifile_create_inode;\n\t/* reference count of i_bh inherits from nilfs_mdt_read_block() */\n\n\tatomic64_inc(&root->inodes_count);\n\tinode_init_owner(&init_user_ns, inode, dir, mode);\n\tinode->i_ino = ino;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\n\tif (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)) {\n\t\terr = nilfs_bmap_read(ii->i_bmap, NULL);\n\t\tif (err < 0)\n\t\t\tgoto failed_after_creation;\n\n\t\tset_bit(NILFS_I_BMAP, &ii->i_state);\n\t\t/* No lock is needed; iget() ensures it. */\n\t}\n\n\tii->i_flags = nilfs_mask_flags(\n\t\tmode, NILFS_I(dir)->i_flags & NILFS_FL_INHERITED);\n\n\t/* ii->i_file_acl = 0; */\n\t/* ii->i_dir_acl = 0; */\n\tii->i_dir_start_lookup = 0;\n\tnilfs_set_inode_flags(inode);\n\tspin_lock(&nilfs->ns_next_gen_lock);\n\tinode->i_generation = nilfs->ns_next_generation++;\n\tspin_unlock(&nilfs->ns_next_gen_lock);\n\tif (nilfs_insert_inode_locked(inode, root, ino) < 0) {\n\t\terr = -EIO;\n\t\tgoto failed_after_creation;\n\t}\n\n\terr = nilfs_init_acl(inode, dir);\n\tif (unlikely(err))\n\t\t/*\n\t\t * Never occur.  When supporting nilfs_init_acl(),\n\t\t * proper cancellation of above jobs should be considered.\n\t\t */\n\t\tgoto failed_after_creation;\n\n\treturn inode;\n\n failed_after_creation:\n\tclear_nlink(inode);\n\tif (inode->i_state & I_NEW)\n\t\tunlock_new_inode(inode);\n\tiput(inode);  /*\n\t\t       * raw_inode will be deleted through\n\t\t       * nilfs_evict_inode().\n\t\t       */\n\tgoto failed;\n\n failed_ifile_create_inode:\n\tmake_bad_inode(inode);\n\tiput(inode);\n failed:\n\treturn ERR_PTR(err);\n}",
      "code_after_change": "struct inode *nilfs_new_inode(struct inode *dir, umode_t mode)\n{\n\tstruct super_block *sb = dir->i_sb;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct inode *inode;\n\tstruct nilfs_inode_info *ii;\n\tstruct nilfs_root *root;\n\tstruct buffer_head *bh;\n\tint err = -ENOMEM;\n\tino_t ino;\n\n\tinode = new_inode(sb);\n\tif (unlikely(!inode))\n\t\tgoto failed;\n\n\tmapping_set_gfp_mask(inode->i_mapping,\n\t\t\t   mapping_gfp_constraint(inode->i_mapping, ~__GFP_FS));\n\n\troot = NILFS_I(dir)->i_root;\n\tii = NILFS_I(inode);\n\tii->i_state = BIT(NILFS_I_NEW);\n\tii->i_root = root;\n\n\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\n\tif (unlikely(err))\n\t\tgoto failed_ifile_create_inode;\n\t/* reference count of i_bh inherits from nilfs_mdt_read_block() */\n\n\tif (unlikely(ino < NILFS_USER_INO)) {\n\t\tnilfs_warn(sb,\n\t\t\t   \"inode bitmap is inconsistent for reserved inodes\");\n\t\tdo {\n\t\t\tbrelse(bh);\n\t\t\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\n\t\t\tif (unlikely(err))\n\t\t\t\tgoto failed_ifile_create_inode;\n\t\t} while (ino < NILFS_USER_INO);\n\n\t\tnilfs_info(sb, \"repaired inode bitmap for reserved inodes\");\n\t}\n\tii->i_bh = bh;\n\n\tatomic64_inc(&root->inodes_count);\n\tinode_init_owner(&init_user_ns, inode, dir, mode);\n\tinode->i_ino = ino;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\n\tif (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)) {\n\t\terr = nilfs_bmap_read(ii->i_bmap, NULL);\n\t\tif (err < 0)\n\t\t\tgoto failed_after_creation;\n\n\t\tset_bit(NILFS_I_BMAP, &ii->i_state);\n\t\t/* No lock is needed; iget() ensures it. */\n\t}\n\n\tii->i_flags = nilfs_mask_flags(\n\t\tmode, NILFS_I(dir)->i_flags & NILFS_FL_INHERITED);\n\n\t/* ii->i_file_acl = 0; */\n\t/* ii->i_dir_acl = 0; */\n\tii->i_dir_start_lookup = 0;\n\tnilfs_set_inode_flags(inode);\n\tspin_lock(&nilfs->ns_next_gen_lock);\n\tinode->i_generation = nilfs->ns_next_generation++;\n\tspin_unlock(&nilfs->ns_next_gen_lock);\n\tif (nilfs_insert_inode_locked(inode, root, ino) < 0) {\n\t\terr = -EIO;\n\t\tgoto failed_after_creation;\n\t}\n\n\terr = nilfs_init_acl(inode, dir);\n\tif (unlikely(err))\n\t\t/*\n\t\t * Never occur.  When supporting nilfs_init_acl(),\n\t\t * proper cancellation of above jobs should be considered.\n\t\t */\n\t\tgoto failed_after_creation;\n\n\treturn inode;\n\n failed_after_creation:\n\tclear_nlink(inode);\n\tif (inode->i_state & I_NEW)\n\t\tunlock_new_inode(inode);\n\tiput(inode);  /*\n\t\t       * raw_inode will be deleted through\n\t\t       * nilfs_evict_inode().\n\t\t       */\n\tgoto failed;\n\n failed_ifile_create_inode:\n\tmake_bad_inode(inode);\n\tiput(inode);\n failed:\n\treturn ERR_PTR(err);\n}",
      "modified_lines": {
        "added": [
          "\tstruct buffer_head *bh;",
          "\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);",
          "",
          "\tif (unlikely(ino < NILFS_USER_INO)) {",
          "\t\tnilfs_warn(sb,",
          "\t\t\t   \"inode bitmap is inconsistent for reserved inodes\");",
          "\t\tdo {",
          "\t\t\tbrelse(bh);",
          "\t\t\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);",
          "\t\t\tif (unlikely(err))",
          "\t\t\t\tgoto failed_ifile_create_inode;",
          "\t\t} while (ino < NILFS_USER_INO);",
          "",
          "\t\tnilfs_info(sb, \"repaired inode bitmap for reserved inodes\");",
          "\t}",
          "\tii->i_bh = bh;"
        ],
        "deleted": [
          "\terr = nilfs_ifile_create_inode(root->ifile, &ino, &ii->i_bh);"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper buffer head handling during inode creation process.",
      "trigger_condition": "An error occurs during inode creation, leading to a use-after-free scenario due to improper handling of the buffer head.",
      "specific_code_behavior_causing_vulnerability": "The code does not handle the buffer head associated with inode creation properly, potentially resulting in a situation where the buffer head is used after being released. This can lead to a use-after-free vulnerability if an error occurs during inode creation.",
      "id": 160,
      "code_after_change_normalized": "struct inode *FUN1(struct inode *VAR1, umode_t VAR2)\n{\nstruct super_block *VAR3 = VAR1->VAR4;\nstruct the_nilfs *VAR5 = VAR3->VAR6;\nstruct VAR7 *VAR7;\nstruct nilfs_inode_info *VAR8;\nstruct nilfs_root *VAR9;\nstruct buffer_head *VAR10;\nint VAR11 = -VAR12;\nino_t VAR13;\nVAR7 = FUN2(VAR3);\nif (FUN3(!VAR7))\ngoto VAR14;\nFUN4(VAR7->VAR15,\nFUN5(VAR7->VAR15, ~VAR16));\nVAR9 = FUN6(VAR1)->VAR17;\nVAR8 = FUN6(VAR7);\nVAR8->VAR18 = FUN7(VAR19);\nVAR8->VAR17 = VAR9;\nVAR11 = FUN8(VAR9->VAR20, &VAR13, &VAR10);\nif (FUN3(VAR11))\ngoto VAR21;\nif (FUN3(VAR13 < VAR22)) {\nFUN9(VAR3,\n\"STR\");\ndo {\nFUN10(VAR10);\nVAR11 = FUN8(VAR9->VAR20, &VAR13, &VAR10);\nif (FUN3(VAR11))\ngoto VAR21;\n} while (VAR13 < VAR22);\nFUN11(VAR3, \"STR\");\n}\nVAR8->VAR23 = VAR10;\nFUN12(&VAR9->VAR24);\nFUN13(&VAR25, VAR7, VAR1, VAR2);\nVAR7->VAR26 = VAR13;\nVAR7->VAR27 = VAR7->VAR28 = VAR7->VAR29 = FUN14(VAR7);\nif (FUN15(VAR2) || FUN16(VAR2) || FUN17(VAR2)) {\nVAR11 = FUN18(VAR8->VAR30, NULL);\nif (VAR11 < 0)\ngoto VAR31;\nFUN19(VAR32, &VAR8->VAR18);\n}\nVAR8->VAR33 = FUN20(\nVAR2, FUN6(VAR1)->VAR33 & VAR34);\nVAR8->VAR35 = 0;\nFUN21(VAR7);\nFUN22(&VAR5->VAR36);\nVAR7->VAR37 = VAR5->VAR38++;\nFUN23(&VAR5->VAR36);\nif (FUN24(VAR7, VAR9, VAR13) < 0) {\nVAR11 = -VAR39;\ngoto VAR31;\n}\nVAR11 = FUN25(VAR7, VAR1);\nif (FUN3(VAR11))\ngoto VAR31;\nreturn VAR7;\nVAR31:\nFUN26(VAR7);\nif (VAR7->VAR18 & VAR40)\nFUN27(VAR7);\nFUN28(VAR7);  \ngoto VAR14;\nVAR21:\nFUN29(VAR7);\nFUN28(VAR7);\nVAR14:\nreturn FUN30(VAR11);\n}\n",
      "code_before_change_normalized": "struct inode *FUN1(struct inode *VAR1, umode_t VAR2)\n{\nstruct super_block *VAR3 = VAR1->VAR4;\nstruct the_nilfs *VAR5 = VAR3->VAR6;\nstruct VAR7 *VAR7;\nstruct nilfs_inode_info *VAR8;\nstruct nilfs_root *VAR9;\nint VAR10 = -VAR11;\nino_t VAR12;\nVAR7 = FUN2(VAR3);\nif (FUN3(!VAR7))\ngoto VAR13;\nFUN4(VAR7->VAR14,\nFUN5(VAR7->VAR14, ~VAR15));\nVAR9 = FUN6(VAR1)->VAR16;\nVAR8 = FUN6(VAR7);\nVAR8->VAR17 = FUN7(VAR18);\nVAR8->VAR16 = VAR9;\nVAR10 = FUN8(VAR9->VAR19, &VAR12, &VAR8->VAR20);\nif (FUN3(VAR10))\ngoto VAR21;\nFUN9(&VAR9->VAR22);\nFUN10(&VAR23, VAR7, VAR1, VAR2);\nVAR7->VAR24 = VAR12;\nVAR7->VAR25 = VAR7->VAR26 = VAR7->VAR27 = FUN11(VAR7);\nif (FUN12(VAR2) || FUN13(VAR2) || FUN14(VAR2)) {\nVAR10 = FUN15(VAR8->VAR28, NULL);\nif (VAR10 < 0)\ngoto VAR29;\nFUN16(VAR30, &VAR8->VAR17);\n}\nVAR8->VAR31 = FUN17(\nVAR2, FUN6(VAR1)->VAR31 & VAR32);\nVAR8->VAR33 = 0;\nFUN18(VAR7);\nFUN19(&VAR5->VAR34);\nVAR7->VAR35 = VAR5->VAR36++;\nFUN20(&VAR5->VAR34);\nif (FUN21(VAR7, VAR9, VAR12) < 0) {\nVAR10 = -VAR37;\ngoto VAR29;\n}\nVAR10 = FUN22(VAR7, VAR1);\nif (FUN3(VAR10))\ngoto VAR29;\nreturn VAR7;\nVAR29:\nFUN23(VAR7);\nif (VAR7->VAR17 & VAR38)\nFUN24(VAR7);\nFUN25(VAR7);  \ngoto VAR13;\nVAR21:\nFUN26(VAR7);\nFUN25(VAR7);\nVAR13:\nreturn FUN27(VAR10);\n}\n",
      "code_after_change_raw": "struct inode *nilfs_new_inode(struct inode *dir, umode_t mode)\n{\nstruct super_block *sb = dir->i_sb;\nstruct the_nilfs *nilfs = sb->s_fs_info;\nstruct inode *inode;\nstruct nilfs_inode_info *ii;\nstruct nilfs_root *root;\nstruct buffer_head *bh;\nint err = -ENOMEM;\nino_t ino;\ninode = new_inode(sb);\nif (unlikely(!inode))\ngoto failed;\nmapping_set_gfp_mask(inode->i_mapping,\nmapping_gfp_constraint(inode->i_mapping, ~__GFP_FS));\nroot = NILFS_I(dir)->i_root;\nii = NILFS_I(inode);\nii->i_state = BIT(NILFS_I_NEW);\nii->i_root = root;\nerr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\nif (unlikely(err))\ngoto failed_ifile_create_inode;\nif (unlikely(ino < NILFS_USER_INO)) {\nnilfs_warn(sb,\n\"inode bitmap is inconsistent for reserved inodes\");\ndo {\nbrelse(bh);\nerr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\nif (unlikely(err))\ngoto failed_ifile_create_inode;\n} while (ino < NILFS_USER_INO);\nnilfs_info(sb, \"repaired inode bitmap for reserved inodes\");\n}\nii->i_bh = bh;\natomic64_inc(&root->inodes_count);\ninode_init_owner(&init_user_ns, inode, dir, mode);\ninode->i_ino = ino;\ninode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\nif (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)) {\nerr = nilfs_bmap_read(ii->i_bmap, NULL);\nif (err < 0)\ngoto failed_after_creation;\nset_bit(NILFS_I_BMAP, &ii->i_state);\n}\nii->i_flags = nilfs_mask_flags(\nmode, NILFS_I(dir)->i_flags & NILFS_FL_INHERITED);\nii->i_dir_start_lookup = 0;\nnilfs_set_inode_flags(inode);\nspin_lock(&nilfs->ns_next_gen_lock);\ninode->i_generation = nilfs->ns_next_generation++;\nspin_unlock(&nilfs->ns_next_gen_lock);\nif (nilfs_insert_inode_locked(inode, root, ino) < 0) {\nerr = -EIO;\ngoto failed_after_creation;\n}\nerr = nilfs_init_acl(inode, dir);\nif (unlikely(err))\ngoto failed_after_creation;\nreturn inode;\nfailed_after_creation:\nclear_nlink(inode);\nif (inode->i_state & I_NEW)\nunlock_new_inode(inode);\niput(inode);  \ngoto failed;\nfailed_ifile_create_inode:\nmake_bad_inode(inode);\niput(inode);\nfailed:\nreturn ERR_PTR(err);\n}\n",
      "code_before_change_raw": "struct inode *nilfs_new_inode(struct inode *dir, umode_t mode)\n{\nstruct super_block *sb = dir->i_sb;\nstruct the_nilfs *nilfs = sb->s_fs_info;\nstruct inode *inode;\nstruct nilfs_inode_info *ii;\nstruct nilfs_root *root;\nint err = -ENOMEM;\nino_t ino;\ninode = new_inode(sb);\nif (unlikely(!inode))\ngoto failed;\nmapping_set_gfp_mask(inode->i_mapping,\nmapping_gfp_constraint(inode->i_mapping, ~__GFP_FS));\nroot = NILFS_I(dir)->i_root;\nii = NILFS_I(inode);\nii->i_state = BIT(NILFS_I_NEW);\nii->i_root = root;\nerr = nilfs_ifile_create_inode(root->ifile, &ino, &ii->i_bh);\nif (unlikely(err))\ngoto failed_ifile_create_inode;\natomic64_inc(&root->inodes_count);\ninode_init_owner(&init_user_ns, inode, dir, mode);\ninode->i_ino = ino;\ninode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\nif (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)) {\nerr = nilfs_bmap_read(ii->i_bmap, NULL);\nif (err < 0)\ngoto failed_after_creation;\nset_bit(NILFS_I_BMAP, &ii->i_state);\n}\nii->i_flags = nilfs_mask_flags(\nmode, NILFS_I(dir)->i_flags & NILFS_FL_INHERITED);\nii->i_dir_start_lookup = 0;\nnilfs_set_inode_flags(inode);\nspin_lock(&nilfs->ns_next_gen_lock);\ninode->i_generation = nilfs->ns_next_generation++;\nspin_unlock(&nilfs->ns_next_gen_lock);\nif (nilfs_insert_inode_locked(inode, root, ino) < 0) {\nerr = -EIO;\ngoto failed_after_creation;\n}\nerr = nilfs_init_acl(inode, dir);\nif (unlikely(err))\ngoto failed_after_creation;\nreturn inode;\nfailed_after_creation:\nclear_nlink(inode);\nif (inode->i_state & I_NEW)\nunlock_new_inode(inode);\niput(inode);  \ngoto failed;\nfailed_ifile_create_inode:\nmake_bad_inode(inode);\niput(inode);\nfailed:\nreturn ERR_PTR(err);\n}\n"
    }
  ],
  "CVE-2023-21264": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Improper memory access check in multiple functions of the code.",
        "trigger_condition": "Accessing hypervisor memory due to the memory access check being in the wrong place.",
        "specific_code_behavior_causing_vulnerability": "The code fails to correctly validate memory access, allowing unauthorized access to hypervisor memory, potentially leading to local escalation of privilege.",
        "specific_solution": "The vulnerability can be mitigated by ensuring that the memory access check is performed correctly in the code. By modifying the code to include the additional parameter ctx->addr in the d->get_page_state function call, the memory access check is correctly conducted, preventing unauthorized access to hypervisor memory and mitigating the security risk."
      },
      "GPT_analysis": "The modification is necessary to address the vulnerability CVE-2023-21264 by fixing the memory access check issue in the code snippet. The vulnerability arises from the incorrect memory access check in the original code, which allows unauthorized access to hypervisor memory. By modifying the code to include the additional parameter `ctx->addr` in the `d->get_page_state` function call, the memory access check is correctly performed, preventing unauthorized access and potential local escalation of privilege. This modification ensures that the memory access check is done in the right place and helps mitigate the security risk associated with the vulnerability.",
      "GPT_purpose": "Check the page state during a visit to the kernel page table.",
      "GPT_function": "\n1. __check_page_state_visitor",
      "CVE_id": "CVE-2023-21264",
      "code_before_change": "static int __check_page_state_visitor(const struct kvm_pgtable_visit_ctx *ctx,\n\t\t\t\t      enum kvm_pgtable_walk_flags visit)\n{\n\tstruct check_walk_data *d = ctx->arg;\n\n\tif (kvm_pte_valid(ctx->old) && !addr_is_allowed_memory(kvm_pte_to_phys(ctx->old)))\n\t\treturn -EINVAL;\n\n\treturn d->get_page_state(ctx->old) == d->desired ? 0 : -EPERM;\n}",
      "code_after_change": "static int __check_page_state_visitor(const struct kvm_pgtable_visit_ctx *ctx,\n\t\t\t\t      enum kvm_pgtable_walk_flags visit)\n{\n\tstruct check_walk_data *d = ctx->arg;\n\n\treturn d->get_page_state(ctx->old, ctx->addr) == d->desired ? 0 : -EPERM;\n}",
      "modified_lines": {
        "added": [
          "\treturn d->get_page_state(ctx->old, ctx->addr) == d->desired ? 0 : -EPERM;"
        ],
        "deleted": [
          "\tif (kvm_pte_valid(ctx->old) && !addr_is_allowed_memory(kvm_pte_to_phys(ctx->old)))",
          "\t\treturn -EINVAL;",
          "",
          "\treturn d->get_page_state(ctx->old) == d->desired ? 0 : -EPERM;"
        ]
      },
      "preconditions_for_vulnerability": "Improper memory access check in multiple functions of the code.",
      "trigger_condition": "Accessing hypervisor memory due to the memory access check being in the wrong place.",
      "specific_code_behavior_causing_vulnerability": "The code fails to correctly validate memory access, allowing unauthorized access to hypervisor memory, potentially leading to local escalation of privilege.",
      "id": 161,
      "code_after_change_normalized": "static int FUN1(const struct kvm_pgtable_visit_ctx *VAR1,\nenum kvm_pgtable_walk_flags VAR2)\n{\nstruct check_walk_data *VAR3 = VAR1->VAR4;\nreturn VAR3->FUN2(VAR1->VAR5, VAR1->VAR6) == VAR3->VAR7 ? 0 : -VAR8;\n}\n",
      "code_before_change_normalized": "static int FUN1(const struct kvm_pgtable_visit_ctx *VAR1,\nenum kvm_pgtable_walk_flags VAR2)\n{\nstruct check_walk_data *VAR3 = VAR1->VAR4;\nif (FUN2(VAR1->VAR5) && !FUN3(FUN4(VAR1->VAR5)))\nreturn -VAR6;\nreturn VAR3->FUN5(VAR1->VAR5) == VAR3->VAR7 ? 0 : -VAR8;\n}\n",
      "code_after_change_raw": "static int __check_page_state_visitor(const struct kvm_pgtable_visit_ctx *ctx,\nenum kvm_pgtable_walk_flags visit)\n{\nstruct check_walk_data *d = ctx->arg;\nreturn d->get_page_state(ctx->old, ctx->addr) == d->desired ? 0 : -EPERM;\n}\n",
      "code_before_change_raw": "static int __check_page_state_visitor(const struct kvm_pgtable_visit_ctx *ctx,\nenum kvm_pgtable_walk_flags visit)\n{\nstruct check_walk_data *d = ctx->arg;\nif (kvm_pte_valid(ctx->old) && !addr_is_allowed_memory(kvm_pte_to_phys(ctx->old)))\nreturn -EINVAL;\nreturn d->get_page_state(ctx->old) == d->desired ? 0 : -EPERM;\n}\n"
    }
  ],
  "CVE-2023-6560": [
    {
      "vulnerability_behavior": {
        "preconditions_for_vulnerability": "Lack of proper validation for memory access boundaries in the code handling io_uring SQ/CQ rings functionality.",
        "trigger_condition": "The code does not verify the contiguity of pages in the page_array, allowing for potential out-of-bounds memory access.",
        "specific_code_behavior_causing_vulnerability": "The code does not ensure that all pages in the page_array are contiguous, leading to a vulnerability where a local user could crash the system by exploiting the lack of proper bounds checking."
      },
      "solution": "To mitigate the vulnerability, it is necessary to add a check to ensure that all pages in the page_array are contiguous. This check should compare the address of each page with the address of the first page and verify that they are contiguous. If any page is not contiguous, the function should return an error to prevent out-of-bounds memory access. By enforcing contiguity of pages in the page_array, the code can prevent the vulnerability and improve system security.",
      "GPT_analysis": "The above modification is necessary to address the out-of-bounds memory access vulnerability in the io_uring SQ/CQ rings functionality in the Linux kernel. The vulnerability could allow a local user to crash the system by exploiting the lack of proper bounds checking in the original code snippet.\n\nThe modification includes the following changes:\n1. Added a `page_addr` variable to store the address of the first page in the `page_array`.\n2. Inside the loop that checks for highmem pages, added a check to ensure that all pages in the `page_array` are contiguous. This check compares the address of each page with the `page_addr` and increments `page_addr` by `PAGE_SIZE` to verify contiguity.\n3. If any page in the `page_array` is not contiguous with the previous page, the function will return an error to prevent out-of-bounds memory access.\n\nBy making these modifications, the code now ensures that all pages in the `page_array` are contiguous and prevents any potential out-of-bounds memory access, thereby addressing the vulnerability and improving the security of the code.",
      "GPT_purpose": "Map user space memory to kernel space for io_uring SQ/CQ rings functionality.",
      "GPT_function": "\n1. Map user space address to kernel space pages.\n2. Check for alignment and size validity.\n3. Pin user pages and handle errors appropriately.\n4. Verify contiguity of mapped pages.\n5. Check for highmem pages on 32-bit architectures.",
      "CVE_id": "CVE-2023-6560",
      "code_before_change": "static void *__io_uaddr_map(struct page ***pages, unsigned short *npages,\n\t\t\t    unsigned long uaddr, size_t size)\n{\n\tstruct page **page_array;\n\tunsigned int nr_pages;\n\tint ret, i;\n\n\t*npages = 0;\n\n\tif (uaddr & (PAGE_SIZE - 1) || !size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnr_pages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tif (nr_pages > USHRT_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\tpage_array = kvmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!page_array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = pin_user_pages_fast(uaddr, nr_pages, FOLL_WRITE | FOLL_LONGTERM,\n\t\t\t\t\tpage_array);\n\tif (ret != nr_pages) {\nerr:\n\t\tio_pages_free(&page_array, ret > 0 ? ret : 0);\n\t\treturn ret < 0 ? ERR_PTR(ret) : ERR_PTR(-EFAULT);\n\t}\n\t/*\n\t * Should be a single page. If the ring is small enough that we can\n\t * use a normal page, that is fine. If we need multiple pages, then\n\t * userspace should use a huge page. That's the only way to guarantee\n\t * that we get contigious memory, outside of just being lucky or\n\t * (currently) having low memory fragmentation.\n\t */\n\tif (page_array[0] != page_array[ret - 1])\n\t\tgoto err;\n\n\t/*\n\t * Can't support mapping user allocated ring memory on 32-bit archs\n\t * where it could potentially reside in highmem. Just fail those with\n\t * -EINVAL, just like we did on kernels that didn't support this\n\t * feature.\n\t */\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tif (PageHighMem(page_array[i])) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\t*pages = page_array;\n\t*npages = nr_pages;\n\treturn page_to_virt(page_array[0]);\n}",
      "code_after_change": "static void *__io_uaddr_map(struct page ***pages, unsigned short *npages,\n\t\t\t    unsigned long uaddr, size_t size)\n{\n\tstruct page **page_array;\n\tunsigned int nr_pages;\n\tvoid *page_addr;\n\tint ret, i;\n\n\t*npages = 0;\n\n\tif (uaddr & (PAGE_SIZE - 1) || !size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnr_pages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tif (nr_pages > USHRT_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\tpage_array = kvmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!page_array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = pin_user_pages_fast(uaddr, nr_pages, FOLL_WRITE | FOLL_LONGTERM,\n\t\t\t\t\tpage_array);\n\tif (ret != nr_pages) {\nerr:\n\t\tio_pages_free(&page_array, ret > 0 ? ret : 0);\n\t\treturn ret < 0 ? ERR_PTR(ret) : ERR_PTR(-EFAULT);\n\t}\n\n\tpage_addr = page_address(page_array[0]);\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tret = -EINVAL;\n\n\t\t/*\n\t\t * Can't support mapping user allocated ring memory on 32-bit\n\t\t * archs where it could potentially reside in highmem. Just\n\t\t * fail those with -EINVAL, just like we did on kernels that\n\t\t * didn't support this feature.\n\t\t */\n\t\tif (PageHighMem(page_array[i]))\n\t\t\tgoto err;\n\n\t\t/*\n\t\t * No support for discontig pages for now, should either be a\n\t\t * single normal page, or a huge page. Later on we can add\n\t\t * support for remapping discontig pages, for now we will\n\t\t * just fail them with EINVAL.\n\t\t */\n\t\tif (page_address(page_array[i]) != page_addr)\n\t\t\tgoto err;\n\t\tpage_addr += PAGE_SIZE;\n\t}\n\n\t*pages = page_array;\n\t*npages = nr_pages;\n\treturn page_to_virt(page_array[0]);\n}",
      "modified_lines": {
        "added": [
          "\tvoid *page_addr;",
          "\tpage_addr = page_address(page_array[0]);",
          "\t\tret = -EINVAL;",
          "",
          "\t\t/*",
          "\t\t * Can't support mapping user allocated ring memory on 32-bit",
          "\t\t * archs where it could potentially reside in highmem. Just",
          "\t\t * fail those with -EINVAL, just like we did on kernels that",
          "\t\t * didn't support this feature.",
          "\t\t */",
          "\t\tif (PageHighMem(page_array[i]))",
          "",
          "\t\t/*",
          "\t\t * No support for discontig pages for now, should either be a",
          "\t\t * single normal page, or a huge page. Later on we can add",
          "\t\t * support for remapping discontig pages, for now we will",
          "\t\t * just fail them with EINVAL.",
          "\t\t */",
          "\t\tif (page_address(page_array[i]) != page_addr)",
          "\t\t\tgoto err;",
          "\t\tpage_addr += PAGE_SIZE;"
        ],
        "deleted": [
          "\t/*",
          "\t * Should be a single page. If the ring is small enough that we can",
          "\t * use a normal page, that is fine. If we need multiple pages, then",
          "\t * userspace should use a huge page. That's the only way to guarantee",
          "\t * that we get contigious memory, outside of just being lucky or",
          "\t * (currently) having low memory fragmentation.",
          "\t */",
          "\tif (page_array[0] != page_array[ret - 1])",
          "\t\tgoto err;",
          "\t/*",
          "\t * Can't support mapping user allocated ring memory on 32-bit archs",
          "\t * where it could potentially reside in highmem. Just fail those with",
          "\t * -EINVAL, just like we did on kernels that didn't support this",
          "\t * feature.",
          "\t */",
          "\t\tif (PageHighMem(page_array[i])) {",
          "\t\t\tret = -EINVAL;",
          "\t\t}"
        ]
      },
      "preconditions_for_vulnerability": "Lack of proper validation for memory access boundaries in the code handling io_uring SQ/CQ rings functionality.",
      "trigger_condition": "The code does not verify the contiguity of pages in the page_array, allowing for potential out-of-bounds memory access.",
      "specific_code_behavior_causing_vulnerability": "The code does not ensure that all pages in the page_array are contiguous, leading to a vulnerability where a local user could crash the system by exploiting the lack of proper bounds checking.",
      "id": 162,
      "code_after_change_normalized": "static void *FUN1(struct page ***VAR1, unsigned short *VAR2,\nunsigned long VAR3, size_t VAR4)\n{\nstruct page **VAR5;\nunsigned int VAR6;\nvoid *VAR7;\nint VAR8, VAR9;\n*VAR2 = 0;\nif (VAR3 & (VAR10 - 1) || !VAR4)\nreturn FUN2(-VAR11);\nVAR6 = (VAR4 + VAR10 - 1) >> VAR12;\nif (VAR6 > VAR13)\nreturn FUN2(-VAR11);\nVAR5 = FUN3(VAR6, sizeof(struct VAR14 *), VAR15);\nif (!VAR5)\nreturn FUN2(-VAR16);\nVAR8 = FUN4(VAR3, VAR6, VAR17 | VAR18,\nVAR5);\nif (VAR8 != VAR6) {\nVAR19:\nFUN5(&VAR5, VAR8 > 0 ? VAR8 : 0);\nreturn VAR8 < 0 ? FUN2(VAR8) : FUN2(-VAR20);\n}\nVAR7 = FUN6(VAR5[0]);\nfor (VAR9 = 0; VAR9 < VAR6; VAR9++) {\nVAR8 = -VAR11;\nif (FUN7(VAR5[VAR9]))\ngoto VAR19;\nif (FUN6(VAR5[VAR9]) != VAR7)\ngoto VAR19;\nVAR7 += VAR10;\n}\n*VAR1 = VAR5;\n*VAR2 = VAR6;\nreturn FUN8(VAR5[0]);\n}\n",
      "code_before_change_normalized": "static void *FUN1(struct page ***VAR1, unsigned short *VAR2,\nunsigned long VAR3, size_t VAR4)\n{\nstruct page **VAR5;\nunsigned int VAR6;\nint VAR7, VAR8;\n*VAR2 = 0;\nif (VAR3 & (VAR9 - 1) || !VAR4)\nreturn FUN2(-VAR10);\nVAR6 = (VAR4 + VAR9 - 1) >> VAR11;\nif (VAR6 > VAR12)\nreturn FUN2(-VAR10);\nVAR5 = FUN3(VAR6, sizeof(struct VAR13 *), VAR14);\nif (!VAR5)\nreturn FUN2(-VAR15);\nVAR7 = FUN4(VAR3, VAR6, VAR16 | VAR17,\nVAR5);\nif (VAR7 != VAR6) {\nVAR18:\nFUN5(&VAR5, VAR7 > 0 ? VAR7 : 0);\nreturn VAR7 < 0 ? FUN2(VAR7) : FUN2(-VAR19);\n}\nif (VAR5[0] != VAR5[VAR7 - 1])\ngoto VAR18;\nfor (VAR8 = 0; VAR8 < VAR6; VAR8++) {\nif (FUN6(VAR5[VAR8])) {\nVAR7 = -VAR10;\ngoto VAR18;\n}\n}\n*VAR1 = VAR5;\n*VAR2 = VAR6;\nreturn FUN7(VAR5[0]);\n}\n",
      "code_after_change_raw": "static void *__io_uaddr_map(struct page ***pages, unsigned short *npages,\nunsigned long uaddr, size_t size)\n{\nstruct page **page_array;\nunsigned int nr_pages;\nvoid *page_addr;\nint ret, i;\n*npages = 0;\nif (uaddr & (PAGE_SIZE - 1) || !size)\nreturn ERR_PTR(-EINVAL);\nnr_pages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\nif (nr_pages > USHRT_MAX)\nreturn ERR_PTR(-EINVAL);\npage_array = kvmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);\nif (!page_array)\nreturn ERR_PTR(-ENOMEM);\nret = pin_user_pages_fast(uaddr, nr_pages, FOLL_WRITE | FOLL_LONGTERM,\npage_array);\nif (ret != nr_pages) {\nerr:\nio_pages_free(&page_array, ret > 0 ? ret : 0);\nreturn ret < 0 ? ERR_PTR(ret) : ERR_PTR(-EFAULT);\n}\npage_addr = page_address(page_array[0]);\nfor (i = 0; i < nr_pages; i++) {\nret = -EINVAL;\nif (PageHighMem(page_array[i]))\ngoto err;\nif (page_address(page_array[i]) != page_addr)\ngoto err;\npage_addr += PAGE_SIZE;\n}\n*pages = page_array;\n*npages = nr_pages;\nreturn page_to_virt(page_array[0]);\n}\n",
      "code_before_change_raw": "static void *__io_uaddr_map(struct page ***pages, unsigned short *npages,\nunsigned long uaddr, size_t size)\n{\nstruct page **page_array;\nunsigned int nr_pages;\nint ret, i;\n*npages = 0;\nif (uaddr & (PAGE_SIZE - 1) || !size)\nreturn ERR_PTR(-EINVAL);\nnr_pages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\nif (nr_pages > USHRT_MAX)\nreturn ERR_PTR(-EINVAL);\npage_array = kvmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);\nif (!page_array)\nreturn ERR_PTR(-ENOMEM);\nret = pin_user_pages_fast(uaddr, nr_pages, FOLL_WRITE | FOLL_LONGTERM,\npage_array);\nif (ret != nr_pages) {\nerr:\nio_pages_free(&page_array, ret > 0 ? ret : 0);\nreturn ret < 0 ? ERR_PTR(ret) : ERR_PTR(-EFAULT);\n}\nif (page_array[0] != page_array[ret - 1])\ngoto err;\nfor (i = 0; i < nr_pages; i++) {\nif (PageHighMem(page_array[i])) {\nret = -EINVAL;\ngoto err;\n}\n}\n*pages = page_array;\n*npages = nr_pages;\nreturn page_to_virt(page_array[0]);\n}\n"
    }
  ]
}